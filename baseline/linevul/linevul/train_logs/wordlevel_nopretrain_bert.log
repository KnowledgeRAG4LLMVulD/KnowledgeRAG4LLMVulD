(hf_xfmr) michael@m4:~/HDD18TB/vul_msr/codebert$ python codebert_main.py     --output_dir=./saved_models     --model_type=roberta     --tokenizer_name=microsoft/codebert-base     --model_name_or_path=microsoft/codebert-base     --do_train     --do_test     --train_data_file=../data/big-vul_dataset/train.csv     --eval_data_file=../data/big-vul_dataset/val.csv     --test_data_file=../data/big-vul_dataset/test.csv     --num_attention_heads=12     --epochs 10     --block_size 512     --train_batch_size 16     --eval_batch_size 16     --learning_rate 2e-5     --max_grad_norm 1.0     --evaluate_during_training     --use_non_pretrained_model     --use_word_level_tokenizer     --seed 123456  2>&1 | tee train.log
01/19/2022 08:19:22 - WARNING - __main__ -   device: cuda, n_gpu: 1
01/19/2022 08:19:27 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../data/big-vul_dataset/train.csv', output_dir='./saved_models', model_type='roberta', block_size=512, eval_data_file='../data/big-vul_dataset/val.csv', test_data_file='../data/big-vul_dataset/test.csv', model_name='model.bin', model_name_or_path='microsoft/codebert-base', config_name='', use_non_pretrained_model=True, tokenizer_name='microsoft/codebert-base', code_length=256, do_train=True, do_eval=False, do_test=True, evaluate_during_training=True, do_local_explanation=False, reasoning_method=None, train_batch_size=16, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=123456, epochs=10, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=True, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
using wordlevel tokenizer!
100%|██████████| 150908/150908 [00:20<00:00, 7520.04it/s]
01/19/2022 08:20:19 - INFO - __main__ -   *** Example ***
01/19/2022 08:20:19 - INFO - __main__ -   label: 0
01/19/2022 08:20:19 - INFO - __main__ -   input_tokens: []
01/19/2022 08:20:19 - INFO - __main__ -   input_ids: 0 38 53 15 38908 5 28 50 10 12 0 2438 1993 37250 7 18951 4122 7 14 59 50 141 17 10 47 5 50 34 0 35 12 14 59 50 40 11719 10 47 5 0 21 50 77 1500 23 11719 35 12 0 5 0 6 0 11 18 5 32 11 13 18 5 0 21 50 77 4022 11 13 46 14 5 1871 23 32 10 18 5 32 11 46 12 2438 16 86 9 0 7 2438 16 390 9 20 4122 7 4122 16 1500 9 50 7 37250 9 0 5 1871 295 2438 11 14 5 37250 40 32 10 18 5 37250 8 390 8 4022 11 46 12 0 5 0 6 0 11 18 5 32 11 13 13 13 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
01/19/2022 08:20:19 - INFO - __main__ -   *** Example ***
01/19/2022 08:20:19 - INFO - __main__ -   label: 0
01/19/2022 08:20:19 - INFO - __main__ -   input_tokens: []
01/19/2022 08:20:19 - INFO - __main__ -   input_ids: 0 36 0 5 30 0 15 246 10 12 900 45 21972 11 2751 45 246 8 0 6 20 0 16 0 11 734 45 21972 11 13 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
01/19/2022 08:20:19 - INFO - __main__ -   *** Example ***
01/19/2022 08:20:19 - INFO - __main__ -   label: 0
01/19/2022 08:20:19 - INFO - __main__ -   input_tokens: []
01/19/2022 08:20:19 - INFO - __main__ -   input_ids: 0 4618 842 4618 55 12 7092 8 0 5 91 11 14 5 0 19 0 55 23 7092 10 0 19 0 5 17 11 706 20968 7 20968 9 17 7 706 0 7 0 9 17 7 706 0 7 0 9 17 7 706 0 7 0 9 17 7 8950 9 17 7 706 3546 7 3546 9 17 7 706 38233 7 38233 9 17 7 706 0 7 0 9 17 7 706 0 7 0 9 17 7 706 16325 7 16325 9 17 7 706 34198 7 34198 9 17 7 62 14 110 236 5 0 10 61 110 0 706 39735 7 39735 9 17 7 62 132 0 19 523 92 0 5 95 11 13 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
100%|██████████| 18864/18864 [00:02<00:00, 7894.38it/s]
01/19/2022 08:20:28 - INFO - __main__ -   ***** Running training *****
01/19/2022 08:20:28 - INFO - __main__ -     Num examples = 150908
01/19/2022 08:20:28 - INFO - __main__ -     Num Epochs = 10
01/19/2022 08:20:28 - INFO - __main__ -     Instantaneous batch size per GPU = 16
01/19/2022 08:20:28 - INFO - __main__ -     Total train batch size = 16
01/19/2022 08:20:28 - INFO - __main__ -     Gradient Accumulation steps = 1
01/19/2022 08:20:28 - INFO - __main__ -     Total optimization steps = 94320
epoch 0 loss 0.21262: 100%|█████████▉| 9431/9432 [42:31<00:00,  3.69it/s]01/19/2022 09:03:00 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 09:03:00 - INFO - __main__ -     Num examples = 18864
01/19/2022 09:03:00 - INFO - __main__ -     Batch size = 16
01/19/2022 09:04:44 - INFO - __main__ -   ***** Eval results *****
01/19/2022 09:04:44 - INFO - __main__ -     eval_f1 = 0.2381
01/19/2022 09:04:44 - INFO - __main__ -     eval_precision = 0.5957
01/19/2022 09:04:44 - INFO - __main__ -     eval_recall = 0.1488
01/19/2022 09:04:44 - INFO - __main__ -     eval_threshold = 0.5
01/19/2022 09:04:44 - INFO - __main__ -     ********************
01/19/2022 09:04:44 - INFO - __main__ -     Best f1:0.2381
01/19/2022 09:04:44 - INFO - __main__ -     ********************
01/19/2022 09:04:45 - INFO - __main__ -   Saving model checkpoint to ./saved_models/checkpoint-best-f1/model.bin
epoch 0 loss 0.21262: 100%|██████████| 9432/9432 [44:17<00:00,  3.55it/s]
epoch 1 loss 0.19328: 100%|█████████▉| 9431/9432 [42:34<00:00,  3.69it/s]01/19/2022 09:47:20 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 09:47:20 - INFO - __main__ -     Num examples = 18864
01/19/2022 09:47:20 - INFO - __main__ -     Batch size = 16
01/19/2022 09:49:04 - INFO - __main__ -   ***** Eval results *****
01/19/2022 09:49:04 - INFO - __main__ -     eval_f1 = 0.0712
01/19/2022 09:49:04 - INFO - __main__ -     eval_precision = 0.9762
01/19/2022 09:49:04 - INFO - __main__ -     eval_recall = 0.037
01/19/2022 09:49:04 - INFO - __main__ -     eval_threshold = 0.5
epoch 1 loss 0.19328: 100%|██████████| 9432/9432 [44:18<00:00,  3.55it/s]
epoch 2 loss 0.19968: 100%|█████████▉| 9431/9432 [42:33<00:00,  3.69it/s]01/19/2022 10:31:37 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 10:31:37 - INFO - __main__ -     Num examples = 18864
01/19/2022 10:31:37 - INFO - __main__ -     Batch size = 16
01/19/2022 10:33:21 - INFO - __main__ -   ***** Eval results *****
01/19/2022 10:33:21 - INFO - __main__ -     eval_f1 = 0.3506
01/19/2022 10:33:21 - INFO - __main__ -     eval_precision = 0.6265
01/19/2022 10:33:21 - INFO - __main__ -     eval_recall = 0.2435
01/19/2022 10:33:21 - INFO - __main__ -     eval_threshold = 0.5
01/19/2022 10:33:21 - INFO - __main__ -     ********************
01/19/2022 10:33:21 - INFO - __main__ -     Best f1:0.3506
01/19/2022 10:33:21 - INFO - __main__ -     ********************
01/19/2022 10:33:23 - INFO - __main__ -   Saving model checkpoint to ./saved_models/checkpoint-best-f1/model.bin
epoch 2 loss 0.19968: 100%|██████████| 9432/9432 [44:18<00:00,  3.55it/s]
epoch 3 loss 0.17526: 100%|█████████▉| 9431/9432 [42:34<00:00,  3.69it/s]01/19/2022 11:15:57 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 11:15:57 - INFO - __main__ -     Num examples = 18864
01/19/2022 11:15:57 - INFO - __main__ -     Batch size = 16
01/19/2022 11:17:41 - INFO - __main__ -   ***** Eval results *****
01/19/2022 11:17:41 - INFO - __main__ -     eval_f1 = 0.379
01/19/2022 11:17:41 - INFO - __main__ -     eval_precision = 0.6759
01/19/2022 11:17:41 - INFO - __main__ -     eval_recall = 0.2633
01/19/2022 11:17:41 - INFO - __main__ -     eval_threshold = 0.5
01/19/2022 11:17:41 - INFO - __main__ -     ********************
01/19/2022 11:17:41 - INFO - __main__ -     Best f1:0.379
01/19/2022 11:17:41 - INFO - __main__ -     ********************
01/19/2022 11:17:43 - INFO - __main__ -   Saving model checkpoint to ./saved_models/checkpoint-best-f1/model.bin
epoch 3 loss 0.17526: 100%|██████████| 9432/9432 [44:19<00:00,  3.55it/s]
epoch 4 loss 0.14859: 100%|█████████▉| 9431/9432 [42:34<00:00,  3.69it/s]01/19/2022 12:00:17 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 12:00:17 - INFO - __main__ -     Num examples = 18864
01/19/2022 12:00:17 - INFO - __main__ -     Batch size = 16
01/19/2022 12:02:01 - INFO - __main__ -   ***** Eval results *****
01/19/2022 12:02:01 - INFO - __main__ -     eval_f1 = 0.4152
01/19/2022 12:02:01 - INFO - __main__ -     eval_precision = 0.594
01/19/2022 12:02:01 - INFO - __main__ -     eval_recall = 0.3192
01/19/2022 12:02:01 - INFO - __main__ -     eval_threshold = 0.5
01/19/2022 12:02:01 - INFO - __main__ -     ********************
01/19/2022 12:02:01 - INFO - __main__ -     Best f1:0.4152
01/19/2022 12:02:01 - INFO - __main__ -     ********************
01/19/2022 12:02:03 - INFO - __main__ -   Saving model checkpoint to ./saved_models/checkpoint-best-f1/model.bin
epoch 4 loss 0.14859: 100%|██████████| 9432/9432 [44:20<00:00,  3.55it/s]
epoch 5 loss 0.13473: 100%|█████████▉| 9431/9432 [42:35<00:00,  3.69it/s]01/19/2022 12:44:38 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 12:44:38 - INFO - __main__ -     Num examples = 18864
01/19/2022 12:44:38 - INFO - __main__ -     Batch size = 16
01/19/2022 12:46:22 - INFO - __main__ -   ***** Eval results *****
01/19/2022 12:46:22 - INFO - __main__ -     eval_f1 = 0.404
01/19/2022 12:46:22 - INFO - __main__ -     eval_precision = 0.5823
01/19/2022 12:46:22 - INFO - __main__ -     eval_recall = 0.3093
01/19/2022 12:46:22 - INFO - __main__ -     eval_threshold = 0.5
epoch 5 loss 0.13473: 100%|██████████| 9432/9432 [44:19<00:00,  3.55it/s]
epoch 6 loss 0.12385: 100%|█████████▉| 9431/9432 [42:35<00:00,  3.69it/s]01/19/2022 13:28:57 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 13:28:57 - INFO - __main__ -     Num examples = 18864
01/19/2022 13:28:57 - INFO - __main__ -     Batch size = 16
01/19/2022 13:30:41 - INFO - __main__ -   ***** Eval results *****
01/19/2022 13:30:41 - INFO - __main__ -     eval_f1 = 0.4286
01/19/2022 13:30:41 - INFO - __main__ -     eval_precision = 0.4846
01/19/2022 13:30:41 - INFO - __main__ -     eval_recall = 0.3841
01/19/2022 13:30:41 - INFO - __main__ -     eval_threshold = 0.5
01/19/2022 13:30:41 - INFO - __main__ -     ********************
01/19/2022 13:30:41 - INFO - __main__ -     Best f1:0.4286
01/19/2022 13:30:41 - INFO - __main__ -     ********************
01/19/2022 13:30:42 - INFO - __main__ -   Saving model checkpoint to ./saved_models/checkpoint-best-f1/model.bin
epoch 6 loss 0.12385: 100%|██████████| 9432/9432 [44:20<00:00,  3.55it/s]
epoch 7 loss 0.11183: 100%|█████████▉| 9431/9432 [42:35<00:00,  3.69it/s]01/19/2022 14:13:18 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 14:13:18 - INFO - __main__ -     Num examples = 18864
01/19/2022 14:13:18 - INFO - __main__ -     Batch size = 16
01/19/2022 14:15:03 - INFO - __main__ -   ***** Eval results *****
01/19/2022 14:15:03 - INFO - __main__ -     eval_f1 = 0.4247
01/19/2022 14:15:03 - INFO - __main__ -     eval_precision = 0.5056
01/19/2022 14:15:03 - INFO - __main__ -     eval_recall = 0.3661
01/19/2022 14:15:03 - INFO - __main__ -     eval_threshold = 0.5
epoch 7 loss 0.11183: 100%|██████████| 9432/9432 [44:20<00:00,  3.55it/s]
epoch 8 loss 0.10039: 100%|█████████▉| 9431/9432 [42:35<00:00,  3.69it/s]01/19/2022 14:57:38 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 14:57:38 - INFO - __main__ -     Num examples = 18864
01/19/2022 14:57:38 - INFO - __main__ -     Batch size = 16
01/19/2022 14:59:22 - INFO - __main__ -   ***** Eval results *****
01/19/2022 14:59:22 - INFO - __main__ -     eval_f1 = 0.4178
01/19/2022 14:59:22 - INFO - __main__ -     eval_precision = 0.4834
01/19/2022 14:59:22 - INFO - __main__ -     eval_recall = 0.3679
01/19/2022 14:59:22 - INFO - __main__ -     eval_threshold = 0.5
epoch 8 loss 0.10039: 100%|██████████| 9432/9432 [44:19<00:00,  3.55it/s]
epoch 9 loss 0.09353: 100%|█████████▉| 9431/9432 [42:34<00:00,  3.69it/s]01/19/2022 15:41:57 - INFO - __main__ -   ***** Running evaluation *****
01/19/2022 15:41:57 - INFO - __main__ -     Num examples = 18864
01/19/2022 15:41:57 - INFO - __main__ -     Batch size = 16
01/19/2022 15:43:41 - INFO - __main__ -   ***** Eval results *****
01/19/2022 15:43:41 - INFO - __main__ -     eval_f1 = 0.4169
01/19/2022 15:43:41 - INFO - __main__ -     eval_precision = 0.4938
01/19/2022 15:43:41 - INFO - __main__ -     eval_recall = 0.3607
01/19/2022 15:43:41 - INFO - __main__ -     eval_threshold = 0.5
epoch 9 loss 0.09353: 100%|██████████| 9432/9432 [44:18<00:00,  3.55it/s]
100%|██████████| 18864/18864 [00:02<00:00, 8032.63it/s]
01/19/2022 15:43:48 - INFO - __main__ -   ***** Running Test *****
01/19/2022 15:43:48 - INFO - __main__ -     Num examples = 18864
01/19/2022 15:43:48 - INFO - __main__ -     Batch size = 16
01/19/2022 15:45:32 - INFO - __main__ -   ***** Test results *****
01/19/2022 15:45:32 - INFO - __main__ -     test_accuracy = 0.9373
01/19/2022 15:45:32 - INFO - __main__ -     test_f1 = 0.3936
01/19/2022 15:45:32 - INFO - __main__ -     test_precision = 0.4286
01/19/2022 15:45:32 - INFO - __main__ -     test_recall = 0.364
01/19/2022 15:45:32 - INFO - __main__ -     test_threshold = 0.5