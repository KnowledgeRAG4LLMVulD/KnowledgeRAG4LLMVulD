[
    {
        "cve_id": "CVE-2012-3400",
        "code_before_change": "static int udf_load_logicalvol(struct super_block *sb, sector_t block,\n\t\t\t       struct kernel_lb_addr *fileset)\n{\n\tstruct logicalVolDesc *lvd;\n\tint i, j, offset;\n\tuint8_t type;\n\tstruct udf_sb_info *sbi = UDF_SB(sb);\n\tstruct genericPartitionMap *gpm;\n\tuint16_t ident;\n\tstruct buffer_head *bh;\n\tunsigned int table_len;\n\tint ret = 0;\n\n\tbh = udf_read_tagged(sb, block, block, &ident);\n\tif (!bh)\n\t\treturn 1;\n\tBUG_ON(ident != TAG_IDENT_LVD);\n\tlvd = (struct logicalVolDesc *)bh->b_data;\n\ttable_len = le32_to_cpu(lvd->mapTableLength);\n\tif (sizeof(*lvd) + table_len > sb->s_blocksize) {\n\t\tudf_err(sb, \"error loading logical volume descriptor: \"\n\t\t\t\"Partition table too long (%u > %lu)\\n\", table_len,\n\t\t\tsb->s_blocksize - sizeof(*lvd));\n\t\tgoto out_bh;\n\t}\n\n\tret = udf_sb_alloc_partition_maps(sb, le32_to_cpu(lvd->numPartitionMaps));\n\tif (ret)\n\t\tgoto out_bh;\n\n\tfor (i = 0, offset = 0;\n\t     i < sbi->s_partitions && offset < table_len;\n\t     i++, offset += gpm->partitionMapLength) {\n\t\tstruct udf_part_map *map = &sbi->s_partmaps[i];\n\t\tgpm = (struct genericPartitionMap *)\n\t\t\t\t&(lvd->partitionMaps[offset]);\n\t\ttype = gpm->partitionMapType;\n\t\tif (type == 1) {\n\t\t\tstruct genericPartitionMap1 *gpm1 =\n\t\t\t\t(struct genericPartitionMap1 *)gpm;\n\t\t\tmap->s_partition_type = UDF_TYPE1_MAP15;\n\t\t\tmap->s_volumeseqnum = le16_to_cpu(gpm1->volSeqNum);\n\t\t\tmap->s_partition_num = le16_to_cpu(gpm1->partitionNum);\n\t\t\tmap->s_partition_func = NULL;\n\t\t} else if (type == 2) {\n\t\t\tstruct udfPartitionMap2 *upm2 =\n\t\t\t\t\t\t(struct udfPartitionMap2 *)gpm;\n\t\t\tif (!strncmp(upm2->partIdent.ident, UDF_ID_VIRTUAL,\n\t\t\t\t\t\tstrlen(UDF_ID_VIRTUAL))) {\n\t\t\t\tu16 suf =\n\t\t\t\t\tle16_to_cpu(((__le16 *)upm2->partIdent.\n\t\t\t\t\t\t\tidentSuffix)[0]);\n\t\t\t\tif (suf < 0x0200) {\n\t\t\t\t\tmap->s_partition_type =\n\t\t\t\t\t\t\tUDF_VIRTUAL_MAP15;\n\t\t\t\t\tmap->s_partition_func =\n\t\t\t\t\t\t\tudf_get_pblock_virt15;\n\t\t\t\t} else {\n\t\t\t\t\tmap->s_partition_type =\n\t\t\t\t\t\t\tUDF_VIRTUAL_MAP20;\n\t\t\t\t\tmap->s_partition_func =\n\t\t\t\t\t\t\tudf_get_pblock_virt20;\n\t\t\t\t}\n\t\t\t} else if (!strncmp(upm2->partIdent.ident,\n\t\t\t\t\t\tUDF_ID_SPARABLE,\n\t\t\t\t\t\tstrlen(UDF_ID_SPARABLE))) {\n\t\t\t\tuint32_t loc;\n\t\t\t\tstruct sparingTable *st;\n\t\t\t\tstruct sparablePartitionMap *spm =\n\t\t\t\t\t(struct sparablePartitionMap *)gpm;\n\n\t\t\t\tmap->s_partition_type = UDF_SPARABLE_MAP15;\n\t\t\t\tmap->s_type_specific.s_sparing.s_packet_len =\n\t\t\t\t\t\tle16_to_cpu(spm->packetLength);\n\t\t\t\tfor (j = 0; j < spm->numSparingTables; j++) {\n\t\t\t\t\tstruct buffer_head *bh2;\n\n\t\t\t\t\tloc = le32_to_cpu(\n\t\t\t\t\t\tspm->locSparingTable[j]);\n\t\t\t\t\tbh2 = udf_read_tagged(sb, loc, loc,\n\t\t\t\t\t\t\t     &ident);\n\t\t\t\t\tmap->s_type_specific.s_sparing.\n\t\t\t\t\t\t\ts_spar_map[j] = bh2;\n\n\t\t\t\t\tif (bh2 == NULL)\n\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\tst = (struct sparingTable *)bh2->b_data;\n\t\t\t\t\tif (ident != 0 || strncmp(\n\t\t\t\t\t\tst->sparingIdent.ident,\n\t\t\t\t\t\tUDF_ID_SPARING,\n\t\t\t\t\t\tstrlen(UDF_ID_SPARING))) {\n\t\t\t\t\t\tbrelse(bh2);\n\t\t\t\t\t\tmap->s_type_specific.s_sparing.\n\t\t\t\t\t\t\ts_spar_map[j] = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tmap->s_partition_func = udf_get_pblock_spar15;\n\t\t\t} else if (!strncmp(upm2->partIdent.ident,\n\t\t\t\t\t\tUDF_ID_METADATA,\n\t\t\t\t\t\tstrlen(UDF_ID_METADATA))) {\n\t\t\t\tstruct udf_meta_data *mdata =\n\t\t\t\t\t&map->s_type_specific.s_metadata;\n\t\t\t\tstruct metadataPartitionMap *mdm =\n\t\t\t\t\t\t(struct metadataPartitionMap *)\n\t\t\t\t\t\t&(lvd->partitionMaps[offset]);\n\t\t\t\tudf_debug(\"Parsing Logical vol part %d type %d  id=%s\\n\",\n\t\t\t\t\t  i, type, UDF_ID_METADATA);\n\n\t\t\t\tmap->s_partition_type = UDF_METADATA_MAP25;\n\t\t\t\tmap->s_partition_func = udf_get_pblock_meta25;\n\n\t\t\t\tmdata->s_meta_file_loc   =\n\t\t\t\t\tle32_to_cpu(mdm->metadataFileLoc);\n\t\t\t\tmdata->s_mirror_file_loc =\n\t\t\t\t\tle32_to_cpu(mdm->metadataMirrorFileLoc);\n\t\t\t\tmdata->s_bitmap_file_loc =\n\t\t\t\t\tle32_to_cpu(mdm->metadataBitmapFileLoc);\n\t\t\t\tmdata->s_alloc_unit_size =\n\t\t\t\t\tle32_to_cpu(mdm->allocUnitSize);\n\t\t\t\tmdata->s_align_unit_size =\n\t\t\t\t\tle16_to_cpu(mdm->alignUnitSize);\n\t\t\t\tif (mdm->flags & 0x01)\n\t\t\t\t\tmdata->s_flags |= MF_DUPLICATE_MD;\n\n\t\t\t\tudf_debug(\"Metadata Ident suffix=0x%x\\n\",\n\t\t\t\t\t  le16_to_cpu(*(__le16 *)\n\t\t\t\t\t\t      mdm->partIdent.identSuffix));\n\t\t\t\tudf_debug(\"Metadata part num=%d\\n\",\n\t\t\t\t\t  le16_to_cpu(mdm->partitionNum));\n\t\t\t\tudf_debug(\"Metadata part alloc unit size=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->allocUnitSize));\n\t\t\t\tudf_debug(\"Metadata file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataFileLoc));\n\t\t\t\tudf_debug(\"Mirror file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataMirrorFileLoc));\n\t\t\t\tudf_debug(\"Bitmap file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataBitmapFileLoc));\n\t\t\t\tudf_debug(\"Flags: %d %d\\n\",\n\t\t\t\t\t  mdata->s_flags, mdm->flags);\n\t\t\t} else {\n\t\t\t\tudf_debug(\"Unknown ident: %s\\n\",\n\t\t\t\t\t  upm2->partIdent.ident);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmap->s_volumeseqnum = le16_to_cpu(upm2->volSeqNum);\n\t\t\tmap->s_partition_num = le16_to_cpu(upm2->partitionNum);\n\t\t}\n\t\tudf_debug(\"Partition (%d:%d) type %d on volume %d\\n\",\n\t\t\t  i, map->s_partition_num, type, map->s_volumeseqnum);\n\t}\n\n\tif (fileset) {\n\t\tstruct long_ad *la = (struct long_ad *)&(lvd->logicalVolContentsUse[0]);\n\n\t\t*fileset = lelb_to_cpu(la->extLocation);\n\t\tudf_debug(\"FileSet found in LogicalVolDesc at block=%d, partition=%d\\n\",\n\t\t\t  fileset->logicalBlockNum,\n\t\t\t  fileset->partitionReferenceNum);\n\t}\n\tif (lvd->integritySeqExt.extLength)\n\t\tudf_load_logicalvolint(sb, leea_to_cpu(lvd->integritySeqExt));\n\nout_bh:\n\tbrelse(bh);\n\treturn ret;\n}",
        "code_after_change": "static int udf_load_logicalvol(struct super_block *sb, sector_t block,\n\t\t\t       struct kernel_lb_addr *fileset)\n{\n\tstruct logicalVolDesc *lvd;\n\tint i, offset;\n\tuint8_t type;\n\tstruct udf_sb_info *sbi = UDF_SB(sb);\n\tstruct genericPartitionMap *gpm;\n\tuint16_t ident;\n\tstruct buffer_head *bh;\n\tunsigned int table_len;\n\tint ret = 0;\n\n\tbh = udf_read_tagged(sb, block, block, &ident);\n\tif (!bh)\n\t\treturn 1;\n\tBUG_ON(ident != TAG_IDENT_LVD);\n\tlvd = (struct logicalVolDesc *)bh->b_data;\n\ttable_len = le32_to_cpu(lvd->mapTableLength);\n\tif (sizeof(*lvd) + table_len > sb->s_blocksize) {\n\t\tudf_err(sb, \"error loading logical volume descriptor: \"\n\t\t\t\"Partition table too long (%u > %lu)\\n\", table_len,\n\t\t\tsb->s_blocksize - sizeof(*lvd));\n\t\tgoto out_bh;\n\t}\n\n\tret = udf_sb_alloc_partition_maps(sb, le32_to_cpu(lvd->numPartitionMaps));\n\tif (ret)\n\t\tgoto out_bh;\n\n\tfor (i = 0, offset = 0;\n\t     i < sbi->s_partitions && offset < table_len;\n\t     i++, offset += gpm->partitionMapLength) {\n\t\tstruct udf_part_map *map = &sbi->s_partmaps[i];\n\t\tgpm = (struct genericPartitionMap *)\n\t\t\t\t&(lvd->partitionMaps[offset]);\n\t\ttype = gpm->partitionMapType;\n\t\tif (type == 1) {\n\t\t\tstruct genericPartitionMap1 *gpm1 =\n\t\t\t\t(struct genericPartitionMap1 *)gpm;\n\t\t\tmap->s_partition_type = UDF_TYPE1_MAP15;\n\t\t\tmap->s_volumeseqnum = le16_to_cpu(gpm1->volSeqNum);\n\t\t\tmap->s_partition_num = le16_to_cpu(gpm1->partitionNum);\n\t\t\tmap->s_partition_func = NULL;\n\t\t} else if (type == 2) {\n\t\t\tstruct udfPartitionMap2 *upm2 =\n\t\t\t\t\t\t(struct udfPartitionMap2 *)gpm;\n\t\t\tif (!strncmp(upm2->partIdent.ident, UDF_ID_VIRTUAL,\n\t\t\t\t\t\tstrlen(UDF_ID_VIRTUAL))) {\n\t\t\t\tu16 suf =\n\t\t\t\t\tle16_to_cpu(((__le16 *)upm2->partIdent.\n\t\t\t\t\t\t\tidentSuffix)[0]);\n\t\t\t\tif (suf < 0x0200) {\n\t\t\t\t\tmap->s_partition_type =\n\t\t\t\t\t\t\tUDF_VIRTUAL_MAP15;\n\t\t\t\t\tmap->s_partition_func =\n\t\t\t\t\t\t\tudf_get_pblock_virt15;\n\t\t\t\t} else {\n\t\t\t\t\tmap->s_partition_type =\n\t\t\t\t\t\t\tUDF_VIRTUAL_MAP20;\n\t\t\t\t\tmap->s_partition_func =\n\t\t\t\t\t\t\tudf_get_pblock_virt20;\n\t\t\t\t}\n\t\t\t} else if (!strncmp(upm2->partIdent.ident,\n\t\t\t\t\t\tUDF_ID_SPARABLE,\n\t\t\t\t\t\tstrlen(UDF_ID_SPARABLE))) {\n\t\t\t\tif (udf_load_sparable_map(sb, map,\n\t\t\t\t    (struct sparablePartitionMap *)gpm) < 0)\n\t\t\t\t\tgoto out_bh;\n\t\t\t} else if (!strncmp(upm2->partIdent.ident,\n\t\t\t\t\t\tUDF_ID_METADATA,\n\t\t\t\t\t\tstrlen(UDF_ID_METADATA))) {\n\t\t\t\tstruct udf_meta_data *mdata =\n\t\t\t\t\t&map->s_type_specific.s_metadata;\n\t\t\t\tstruct metadataPartitionMap *mdm =\n\t\t\t\t\t\t(struct metadataPartitionMap *)\n\t\t\t\t\t\t&(lvd->partitionMaps[offset]);\n\t\t\t\tudf_debug(\"Parsing Logical vol part %d type %d  id=%s\\n\",\n\t\t\t\t\t  i, type, UDF_ID_METADATA);\n\n\t\t\t\tmap->s_partition_type = UDF_METADATA_MAP25;\n\t\t\t\tmap->s_partition_func = udf_get_pblock_meta25;\n\n\t\t\t\tmdata->s_meta_file_loc   =\n\t\t\t\t\tle32_to_cpu(mdm->metadataFileLoc);\n\t\t\t\tmdata->s_mirror_file_loc =\n\t\t\t\t\tle32_to_cpu(mdm->metadataMirrorFileLoc);\n\t\t\t\tmdata->s_bitmap_file_loc =\n\t\t\t\t\tle32_to_cpu(mdm->metadataBitmapFileLoc);\n\t\t\t\tmdata->s_alloc_unit_size =\n\t\t\t\t\tle32_to_cpu(mdm->allocUnitSize);\n\t\t\t\tmdata->s_align_unit_size =\n\t\t\t\t\tle16_to_cpu(mdm->alignUnitSize);\n\t\t\t\tif (mdm->flags & 0x01)\n\t\t\t\t\tmdata->s_flags |= MF_DUPLICATE_MD;\n\n\t\t\t\tudf_debug(\"Metadata Ident suffix=0x%x\\n\",\n\t\t\t\t\t  le16_to_cpu(*(__le16 *)\n\t\t\t\t\t\t      mdm->partIdent.identSuffix));\n\t\t\t\tudf_debug(\"Metadata part num=%d\\n\",\n\t\t\t\t\t  le16_to_cpu(mdm->partitionNum));\n\t\t\t\tudf_debug(\"Metadata part alloc unit size=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->allocUnitSize));\n\t\t\t\tudf_debug(\"Metadata file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataFileLoc));\n\t\t\t\tudf_debug(\"Mirror file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataMirrorFileLoc));\n\t\t\t\tudf_debug(\"Bitmap file loc=%d\\n\",\n\t\t\t\t\t  le32_to_cpu(mdm->metadataBitmapFileLoc));\n\t\t\t\tudf_debug(\"Flags: %d %d\\n\",\n\t\t\t\t\t  mdata->s_flags, mdm->flags);\n\t\t\t} else {\n\t\t\t\tudf_debug(\"Unknown ident: %s\\n\",\n\t\t\t\t\t  upm2->partIdent.ident);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmap->s_volumeseqnum = le16_to_cpu(upm2->volSeqNum);\n\t\t\tmap->s_partition_num = le16_to_cpu(upm2->partitionNum);\n\t\t}\n\t\tudf_debug(\"Partition (%d:%d) type %d on volume %d\\n\",\n\t\t\t  i, map->s_partition_num, type, map->s_volumeseqnum);\n\t}\n\n\tif (fileset) {\n\t\tstruct long_ad *la = (struct long_ad *)&(lvd->logicalVolContentsUse[0]);\n\n\t\t*fileset = lelb_to_cpu(la->extLocation);\n\t\tudf_debug(\"FileSet found in LogicalVolDesc at block=%d, partition=%d\\n\",\n\t\t\t  fileset->logicalBlockNum,\n\t\t\t  fileset->partitionReferenceNum);\n\t}\n\tif (lvd->integritySeqExt.extLength)\n\t\tudf_load_logicalvolint(sb, leea_to_cpu(lvd->integritySeqExt));\n\nout_bh:\n\tbrelse(bh);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t       struct kernel_lb_addr *fileset)\n {\n \tstruct logicalVolDesc *lvd;\n-\tint i, j, offset;\n+\tint i, offset;\n \tuint8_t type;\n \tstruct udf_sb_info *sbi = UDF_SB(sb);\n \tstruct genericPartitionMap *gpm;\n@@ -64,38 +64,9 @@\n \t\t\t} else if (!strncmp(upm2->partIdent.ident,\n \t\t\t\t\t\tUDF_ID_SPARABLE,\n \t\t\t\t\t\tstrlen(UDF_ID_SPARABLE))) {\n-\t\t\t\tuint32_t loc;\n-\t\t\t\tstruct sparingTable *st;\n-\t\t\t\tstruct sparablePartitionMap *spm =\n-\t\t\t\t\t(struct sparablePartitionMap *)gpm;\n-\n-\t\t\t\tmap->s_partition_type = UDF_SPARABLE_MAP15;\n-\t\t\t\tmap->s_type_specific.s_sparing.s_packet_len =\n-\t\t\t\t\t\tle16_to_cpu(spm->packetLength);\n-\t\t\t\tfor (j = 0; j < spm->numSparingTables; j++) {\n-\t\t\t\t\tstruct buffer_head *bh2;\n-\n-\t\t\t\t\tloc = le32_to_cpu(\n-\t\t\t\t\t\tspm->locSparingTable[j]);\n-\t\t\t\t\tbh2 = udf_read_tagged(sb, loc, loc,\n-\t\t\t\t\t\t\t     &ident);\n-\t\t\t\t\tmap->s_type_specific.s_sparing.\n-\t\t\t\t\t\t\ts_spar_map[j] = bh2;\n-\n-\t\t\t\t\tif (bh2 == NULL)\n-\t\t\t\t\t\tcontinue;\n-\n-\t\t\t\t\tst = (struct sparingTable *)bh2->b_data;\n-\t\t\t\t\tif (ident != 0 || strncmp(\n-\t\t\t\t\t\tst->sparingIdent.ident,\n-\t\t\t\t\t\tUDF_ID_SPARING,\n-\t\t\t\t\t\tstrlen(UDF_ID_SPARING))) {\n-\t\t\t\t\t\tbrelse(bh2);\n-\t\t\t\t\t\tmap->s_type_specific.s_sparing.\n-\t\t\t\t\t\t\ts_spar_map[j] = NULL;\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\tmap->s_partition_func = udf_get_pblock_spar15;\n+\t\t\t\tif (udf_load_sparable_map(sb, map,\n+\t\t\t\t    (struct sparablePartitionMap *)gpm) < 0)\n+\t\t\t\t\tgoto out_bh;\n \t\t\t} else if (!strncmp(upm2->partIdent.ident,\n \t\t\t\t\t\tUDF_ID_METADATA,\n \t\t\t\t\t\tstrlen(UDF_ID_METADATA))) {",
        "function_modified_lines": {
            "added": [
                "\tint i, offset;",
                "\t\t\t\tif (udf_load_sparable_map(sb, map,",
                "\t\t\t\t    (struct sparablePartitionMap *)gpm) < 0)",
                "\t\t\t\t\tgoto out_bh;"
            ],
            "deleted": [
                "\tint i, j, offset;",
                "\t\t\t\tuint32_t loc;",
                "\t\t\t\tstruct sparingTable *st;",
                "\t\t\t\tstruct sparablePartitionMap *spm =",
                "\t\t\t\t\t(struct sparablePartitionMap *)gpm;",
                "",
                "\t\t\t\tmap->s_partition_type = UDF_SPARABLE_MAP15;",
                "\t\t\t\tmap->s_type_specific.s_sparing.s_packet_len =",
                "\t\t\t\t\t\tle16_to_cpu(spm->packetLength);",
                "\t\t\t\tfor (j = 0; j < spm->numSparingTables; j++) {",
                "\t\t\t\t\tstruct buffer_head *bh2;",
                "",
                "\t\t\t\t\tloc = le32_to_cpu(",
                "\t\t\t\t\t\tspm->locSparingTable[j]);",
                "\t\t\t\t\tbh2 = udf_read_tagged(sb, loc, loc,",
                "\t\t\t\t\t\t\t     &ident);",
                "\t\t\t\t\tmap->s_type_specific.s_sparing.",
                "\t\t\t\t\t\t\ts_spar_map[j] = bh2;",
                "",
                "\t\t\t\t\tif (bh2 == NULL)",
                "\t\t\t\t\t\tcontinue;",
                "",
                "\t\t\t\t\tst = (struct sparingTable *)bh2->b_data;",
                "\t\t\t\t\tif (ident != 0 || strncmp(",
                "\t\t\t\t\t\tst->sparingIdent.ident,",
                "\t\t\t\t\t\tUDF_ID_SPARING,",
                "\t\t\t\t\t\tstrlen(UDF_ID_SPARING))) {",
                "\t\t\t\t\t\tbrelse(bh2);",
                "\t\t\t\t\t\tmap->s_type_specific.s_sparing.",
                "\t\t\t\t\t\t\ts_spar_map[j] = NULL;",
                "\t\t\t\t\t}",
                "\t\t\t\t}",
                "\t\t\t\tmap->s_partition_func = udf_get_pblock_spar15;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Heap-based buffer overflow in the udf_load_logicalvol function in fs/udf/super.c in the Linux kernel before 3.4.5 allows remote attackers to cause a denial of service (system crash) or possibly have unspecified other impact via a crafted UDF filesystem."
    },
    {
        "cve_id": "CVE-2014-0077",
        "code_before_change": "static void handle_rx(struct vhost_net *net)\n{\n\tstruct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_RX];\n\tstruct vhost_virtqueue *vq = &nvq->vq;\n\tunsigned uninitialized_var(in), log;\n\tstruct vhost_log *vq_log;\n\tstruct msghdr msg = {\n\t\t.msg_name = NULL,\n\t\t.msg_namelen = 0,\n\t\t.msg_control = NULL, /* FIXME: get and handle RX aux data. */\n\t\t.msg_controllen = 0,\n\t\t.msg_iov = vq->iov,\n\t\t.msg_flags = MSG_DONTWAIT,\n\t};\n\tstruct virtio_net_hdr_mrg_rxbuf hdr = {\n\t\t.hdr.flags = 0,\n\t\t.hdr.gso_type = VIRTIO_NET_HDR_GSO_NONE\n\t};\n\tsize_t total_len = 0;\n\tint err, mergeable;\n\ts16 headcount;\n\tsize_t vhost_hlen, sock_hlen;\n\tsize_t vhost_len, sock_len;\n\tstruct socket *sock;\n\n\tmutex_lock(&vq->mutex);\n\tsock = vq->private_data;\n\tif (!sock)\n\t\tgoto out;\n\tvhost_disable_notify(&net->dev, vq);\n\n\tvhost_hlen = nvq->vhost_hlen;\n\tsock_hlen = nvq->sock_hlen;\n\n\tvq_log = unlikely(vhost_has_feature(&net->dev, VHOST_F_LOG_ALL)) ?\n\t\tvq->log : NULL;\n\tmergeable = vhost_has_feature(&net->dev, VIRTIO_NET_F_MRG_RXBUF);\n\n\twhile ((sock_len = peek_head_len(sock->sk))) {\n\t\tsock_len += sock_hlen;\n\t\tvhost_len = sock_len + vhost_hlen;\n\t\theadcount = get_rx_bufs(vq, vq->heads, vhost_len,\n\t\t\t\t\t&in, vq_log, &log,\n\t\t\t\t\tlikely(mergeable) ? UIO_MAXIOV : 1);\n\t\t/* On error, stop handling until the next kick. */\n\t\tif (unlikely(headcount < 0))\n\t\t\tbreak;\n\t\t/* OK, now we need to know about added descriptors. */\n\t\tif (!headcount) {\n\t\t\tif (unlikely(vhost_enable_notify(&net->dev, vq))) {\n\t\t\t\t/* They have slipped one in as we were\n\t\t\t\t * doing that: check again. */\n\t\t\t\tvhost_disable_notify(&net->dev, vq);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* Nothing new?  Wait for eventfd to tell us\n\t\t\t * they refilled. */\n\t\t\tbreak;\n\t\t}\n\t\t/* We don't need to be notified again. */\n\t\tif (unlikely((vhost_hlen)))\n\t\t\t/* Skip header. TODO: support TSO. */\n\t\t\tmove_iovec_hdr(vq->iov, nvq->hdr, vhost_hlen, in);\n\t\telse\n\t\t\t/* Copy the header for use in VIRTIO_NET_F_MRG_RXBUF:\n\t\t\t * needed because recvmsg can modify msg_iov. */\n\t\t\tcopy_iovec_hdr(vq->iov, nvq->hdr, sock_hlen, in);\n\t\tmsg.msg_iovlen = in;\n\t\terr = sock->ops->recvmsg(NULL, sock, &msg,\n\t\t\t\t\t sock_len, MSG_DONTWAIT | MSG_TRUNC);\n\t\t/* Userspace might have consumed the packet meanwhile:\n\t\t * it's not supposed to do this usually, but might be hard\n\t\t * to prevent. Discard data we got (if any) and keep going. */\n\t\tif (unlikely(err != sock_len)) {\n\t\t\tpr_debug(\"Discarded rx packet: \"\n\t\t\t\t \" len %d, expected %zd\\n\", err, sock_len);\n\t\t\tvhost_discard_vq_desc(vq, headcount);\n\t\t\tcontinue;\n\t\t}\n\t\tif (unlikely(vhost_hlen) &&\n\t\t    memcpy_toiovecend(nvq->hdr, (unsigned char *)&hdr, 0,\n\t\t\t\t      vhost_hlen)) {\n\t\t\tvq_err(vq, \"Unable to write vnet_hdr at addr %p\\n\",\n\t\t\t       vq->iov->iov_base);\n\t\t\tbreak;\n\t\t}\n\t\t/* TODO: Should check and handle checksum. */\n\t\tif (likely(mergeable) &&\n\t\t    memcpy_toiovecend(nvq->hdr, (unsigned char *)&headcount,\n\t\t\t\t      offsetof(typeof(hdr), num_buffers),\n\t\t\t\t      sizeof hdr.num_buffers)) {\n\t\t\tvq_err(vq, \"Failed num_buffers write\");\n\t\t\tvhost_discard_vq_desc(vq, headcount);\n\t\t\tbreak;\n\t\t}\n\t\tvhost_add_used_and_signal_n(&net->dev, vq, vq->heads,\n\t\t\t\t\t    headcount);\n\t\tif (unlikely(vq_log))\n\t\t\tvhost_log_write(vq, vq_log, log, vhost_len);\n\t\ttotal_len += vhost_len;\n\t\tif (unlikely(total_len >= VHOST_NET_WEIGHT)) {\n\t\t\tvhost_poll_queue(&vq->poll);\n\t\t\tbreak;\n\t\t}\n\t}\nout:\n\tmutex_unlock(&vq->mutex);\n}",
        "code_after_change": "static void handle_rx(struct vhost_net *net)\n{\n\tstruct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_RX];\n\tstruct vhost_virtqueue *vq = &nvq->vq;\n\tunsigned uninitialized_var(in), log;\n\tstruct vhost_log *vq_log;\n\tstruct msghdr msg = {\n\t\t.msg_name = NULL,\n\t\t.msg_namelen = 0,\n\t\t.msg_control = NULL, /* FIXME: get and handle RX aux data. */\n\t\t.msg_controllen = 0,\n\t\t.msg_iov = vq->iov,\n\t\t.msg_flags = MSG_DONTWAIT,\n\t};\n\tstruct virtio_net_hdr_mrg_rxbuf hdr = {\n\t\t.hdr.flags = 0,\n\t\t.hdr.gso_type = VIRTIO_NET_HDR_GSO_NONE\n\t};\n\tsize_t total_len = 0;\n\tint err, mergeable;\n\ts16 headcount;\n\tsize_t vhost_hlen, sock_hlen;\n\tsize_t vhost_len, sock_len;\n\tstruct socket *sock;\n\n\tmutex_lock(&vq->mutex);\n\tsock = vq->private_data;\n\tif (!sock)\n\t\tgoto out;\n\tvhost_disable_notify(&net->dev, vq);\n\n\tvhost_hlen = nvq->vhost_hlen;\n\tsock_hlen = nvq->sock_hlen;\n\n\tvq_log = unlikely(vhost_has_feature(&net->dev, VHOST_F_LOG_ALL)) ?\n\t\tvq->log : NULL;\n\tmergeable = vhost_has_feature(&net->dev, VIRTIO_NET_F_MRG_RXBUF);\n\n\twhile ((sock_len = peek_head_len(sock->sk))) {\n\t\tsock_len += sock_hlen;\n\t\tvhost_len = sock_len + vhost_hlen;\n\t\theadcount = get_rx_bufs(vq, vq->heads, vhost_len,\n\t\t\t\t\t&in, vq_log, &log,\n\t\t\t\t\tlikely(mergeable) ? UIO_MAXIOV : 1);\n\t\t/* On error, stop handling until the next kick. */\n\t\tif (unlikely(headcount < 0))\n\t\t\tbreak;\n\t\t/* On overrun, truncate and discard */\n\t\tif (unlikely(headcount > UIO_MAXIOV)) {\n\t\t\tmsg.msg_iovlen = 1;\n\t\t\terr = sock->ops->recvmsg(NULL, sock, &msg,\n\t\t\t\t\t\t 1, MSG_DONTWAIT | MSG_TRUNC);\n\t\t\tpr_debug(\"Discarded rx packet: len %zd\\n\", sock_len);\n\t\t\tcontinue;\n\t\t}\n\t\t/* OK, now we need to know about added descriptors. */\n\t\tif (!headcount) {\n\t\t\tif (unlikely(vhost_enable_notify(&net->dev, vq))) {\n\t\t\t\t/* They have slipped one in as we were\n\t\t\t\t * doing that: check again. */\n\t\t\t\tvhost_disable_notify(&net->dev, vq);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* Nothing new?  Wait for eventfd to tell us\n\t\t\t * they refilled. */\n\t\t\tbreak;\n\t\t}\n\t\t/* We don't need to be notified again. */\n\t\tif (unlikely((vhost_hlen)))\n\t\t\t/* Skip header. TODO: support TSO. */\n\t\t\tmove_iovec_hdr(vq->iov, nvq->hdr, vhost_hlen, in);\n\t\telse\n\t\t\t/* Copy the header for use in VIRTIO_NET_F_MRG_RXBUF:\n\t\t\t * needed because recvmsg can modify msg_iov. */\n\t\t\tcopy_iovec_hdr(vq->iov, nvq->hdr, sock_hlen, in);\n\t\tmsg.msg_iovlen = in;\n\t\terr = sock->ops->recvmsg(NULL, sock, &msg,\n\t\t\t\t\t sock_len, MSG_DONTWAIT | MSG_TRUNC);\n\t\t/* Userspace might have consumed the packet meanwhile:\n\t\t * it's not supposed to do this usually, but might be hard\n\t\t * to prevent. Discard data we got (if any) and keep going. */\n\t\tif (unlikely(err != sock_len)) {\n\t\t\tpr_debug(\"Discarded rx packet: \"\n\t\t\t\t \" len %d, expected %zd\\n\", err, sock_len);\n\t\t\tvhost_discard_vq_desc(vq, headcount);\n\t\t\tcontinue;\n\t\t}\n\t\tif (unlikely(vhost_hlen) &&\n\t\t    memcpy_toiovecend(nvq->hdr, (unsigned char *)&hdr, 0,\n\t\t\t\t      vhost_hlen)) {\n\t\t\tvq_err(vq, \"Unable to write vnet_hdr at addr %p\\n\",\n\t\t\t       vq->iov->iov_base);\n\t\t\tbreak;\n\t\t}\n\t\t/* TODO: Should check and handle checksum. */\n\t\tif (likely(mergeable) &&\n\t\t    memcpy_toiovecend(nvq->hdr, (unsigned char *)&headcount,\n\t\t\t\t      offsetof(typeof(hdr), num_buffers),\n\t\t\t\t      sizeof hdr.num_buffers)) {\n\t\t\tvq_err(vq, \"Failed num_buffers write\");\n\t\t\tvhost_discard_vq_desc(vq, headcount);\n\t\t\tbreak;\n\t\t}\n\t\tvhost_add_used_and_signal_n(&net->dev, vq, vq->heads,\n\t\t\t\t\t    headcount);\n\t\tif (unlikely(vq_log))\n\t\t\tvhost_log_write(vq, vq_log, log, vhost_len);\n\t\ttotal_len += vhost_len;\n\t\tif (unlikely(total_len >= VHOST_NET_WEIGHT)) {\n\t\t\tvhost_poll_queue(&vq->poll);\n\t\t\tbreak;\n\t\t}\n\t}\nout:\n\tmutex_unlock(&vq->mutex);\n}",
        "patch": "--- code before\n+++ code after\n@@ -45,6 +45,14 @@\n \t\t/* On error, stop handling until the next kick. */\n \t\tif (unlikely(headcount < 0))\n \t\t\tbreak;\n+\t\t/* On overrun, truncate and discard */\n+\t\tif (unlikely(headcount > UIO_MAXIOV)) {\n+\t\t\tmsg.msg_iovlen = 1;\n+\t\t\terr = sock->ops->recvmsg(NULL, sock, &msg,\n+\t\t\t\t\t\t 1, MSG_DONTWAIT | MSG_TRUNC);\n+\t\t\tpr_debug(\"Discarded rx packet: len %zd\\n\", sock_len);\n+\t\t\tcontinue;\n+\t\t}\n \t\t/* OK, now we need to know about added descriptors. */\n \t\tif (!headcount) {\n \t\t\tif (unlikely(vhost_enable_notify(&net->dev, vq))) {",
        "function_modified_lines": {
            "added": [
                "\t\t/* On overrun, truncate and discard */",
                "\t\tif (unlikely(headcount > UIO_MAXIOV)) {",
                "\t\t\tmsg.msg_iovlen = 1;",
                "\t\t\terr = sock->ops->recvmsg(NULL, sock, &msg,",
                "\t\t\t\t\t\t 1, MSG_DONTWAIT | MSG_TRUNC);",
                "\t\t\tpr_debug(\"Discarded rx packet: len %zd\\n\", sock_len);",
                "\t\t\tcontinue;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "drivers/vhost/net.c in the Linux kernel before 3.13.10, when mergeable buffers are disabled, does not properly validate packet lengths, which allows guest OS users to cause a denial of service (memory corruption and host OS crash) or possibly gain privileges on the host OS via crafted packets, related to the handle_rx and get_rx_bufs functions."
    },
    {
        "cve_id": "CVE-2016-9755",
        "code_before_change": "int nf_ct_frag6_gather(struct net *net, struct sk_buff *skb, u32 user)\n{\n\tstruct net_device *dev = skb->dev;\n\tint fhoff, nhoff, ret;\n\tstruct frag_hdr *fhdr;\n\tstruct frag_queue *fq;\n\tstruct ipv6hdr *hdr;\n\tu8 prevhdr;\n\n\t/* Jumbo payload inhibits frag. header */\n\tif (ipv6_hdr(skb)->payload_len == 0) {\n\t\tpr_debug(\"payload len = 0\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (find_prev_fhdr(skb, &prevhdr, &nhoff, &fhoff) < 0)\n\t\treturn -EINVAL;\n\n\tif (!pskb_may_pull(skb, fhoff + sizeof(*fhdr)))\n\t\treturn -ENOMEM;\n\n\tskb_set_transport_header(skb, fhoff);\n\thdr = ipv6_hdr(skb);\n\tfhdr = (struct frag_hdr *)skb_transport_header(skb);\n\n\tfq = fq_find(net, fhdr->identification, user, &hdr->saddr, &hdr->daddr,\n\t\t     skb->dev ? skb->dev->ifindex : 0, ip6_frag_ecn(hdr));\n\tif (fq == NULL) {\n\t\tpr_debug(\"Can't find and can't create new queue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock_bh(&fq->q.lock);\n\n\tif (nf_ct_frag6_queue(fq, skb, fhdr, nhoff) < 0) {\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\t/* after queue has assumed skb ownership, only 0 or -EINPROGRESS\n\t * must be returned.\n\t */\n\tret = -EINPROGRESS;\n\tif (fq->q.flags == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&\n\t    fq->q.meat == fq->q.len &&\n\t    nf_ct_frag6_reasm(fq, skb, dev))\n\t\tret = 0;\n\nout_unlock:\n\tspin_unlock_bh(&fq->q.lock);\n\tinet_frag_put(&fq->q, &nf_frags);\n\treturn ret;\n}",
        "code_after_change": "int nf_ct_frag6_gather(struct net *net, struct sk_buff *skb, u32 user)\n{\n\tstruct net_device *dev = skb->dev;\n\tint fhoff, nhoff, ret;\n\tstruct frag_hdr *fhdr;\n\tstruct frag_queue *fq;\n\tstruct ipv6hdr *hdr;\n\tu8 prevhdr;\n\n\t/* Jumbo payload inhibits frag. header */\n\tif (ipv6_hdr(skb)->payload_len == 0) {\n\t\tpr_debug(\"payload len = 0\\n\");\n\t\treturn 0;\n\t}\n\n\tif (find_prev_fhdr(skb, &prevhdr, &nhoff, &fhoff) < 0)\n\t\treturn 0;\n\n\tif (!pskb_may_pull(skb, fhoff + sizeof(*fhdr)))\n\t\treturn -ENOMEM;\n\n\tskb_set_transport_header(skb, fhoff);\n\thdr = ipv6_hdr(skb);\n\tfhdr = (struct frag_hdr *)skb_transport_header(skb);\n\n\tfq = fq_find(net, fhdr->identification, user, &hdr->saddr, &hdr->daddr,\n\t\t     skb->dev ? skb->dev->ifindex : 0, ip6_frag_ecn(hdr));\n\tif (fq == NULL) {\n\t\tpr_debug(\"Can't find and can't create new queue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tspin_lock_bh(&fq->q.lock);\n\n\tif (nf_ct_frag6_queue(fq, skb, fhdr, nhoff) < 0) {\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\t/* after queue has assumed skb ownership, only 0 or -EINPROGRESS\n\t * must be returned.\n\t */\n\tret = -EINPROGRESS;\n\tif (fq->q.flags == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&\n\t    fq->q.meat == fq->q.len &&\n\t    nf_ct_frag6_reasm(fq, skb, dev))\n\t\tret = 0;\n\nout_unlock:\n\tspin_unlock_bh(&fq->q.lock);\n\tinet_frag_put(&fq->q, &nf_frags);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,11 +10,11 @@\n \t/* Jumbo payload inhibits frag. header */\n \tif (ipv6_hdr(skb)->payload_len == 0) {\n \t\tpr_debug(\"payload len = 0\\n\");\n-\t\treturn -EINVAL;\n+\t\treturn 0;\n \t}\n \n \tif (find_prev_fhdr(skb, &prevhdr, &nhoff, &fhoff) < 0)\n-\t\treturn -EINVAL;\n+\t\treturn 0;\n \n \tif (!pskb_may_pull(skb, fhoff + sizeof(*fhdr)))\n \t\treturn -ENOMEM;",
        "function_modified_lines": {
            "added": [
                "\t\treturn 0;",
                "\t\treturn 0;"
            ],
            "deleted": [
                "\t\treturn -EINVAL;",
                "\t\treturn -EINVAL;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel before 4.9 mishandles IPv6 reassembly, which allows local users to cause a denial of service (integer overflow, out-of-bounds write, and GPF) or possibly have unspecified other impact via a crafted application that makes socket, connect, and writev system calls, related to net/ipv6/netfilter/nf_conntrack_reasm.c and net/ipv6/netfilter/nf_defrag_ipv6_hooks.c."
    },
    {
        "cve_id": "CVE-2016-9755",
        "code_before_change": "static unsigned int ipv6_defrag(void *priv,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tconst struct nf_hook_state *state)\n{\n\tint err;\n\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\t/* Previously seen (loopback)?\t*/\n\tif (skb->nfct && !nf_ct_is_template((struct nf_conn *)skb->nfct))\n\t\treturn NF_ACCEPT;\n#endif\n\n\terr = nf_ct_frag6_gather(state->net, skb,\n\t\t\t\t nf_ct6_defrag_user(state->hook, skb));\n\t/* queued */\n\tif (err == -EINPROGRESS)\n\t\treturn NF_STOLEN;\n\n\treturn NF_ACCEPT;\n}",
        "code_after_change": "static unsigned int ipv6_defrag(void *priv,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tconst struct nf_hook_state *state)\n{\n\tint err;\n\n#if IS_ENABLED(CONFIG_NF_CONNTRACK)\n\t/* Previously seen (loopback)?\t*/\n\tif (skb->nfct && !nf_ct_is_template((struct nf_conn *)skb->nfct))\n\t\treturn NF_ACCEPT;\n#endif\n\n\terr = nf_ct_frag6_gather(state->net, skb,\n\t\t\t\t nf_ct6_defrag_user(state->hook, skb));\n\t/* queued */\n\tif (err == -EINPROGRESS)\n\t\treturn NF_STOLEN;\n\n\treturn err == 0 ? NF_ACCEPT : NF_DROP;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,5 +16,5 @@\n \tif (err == -EINPROGRESS)\n \t\treturn NF_STOLEN;\n \n-\treturn NF_ACCEPT;\n+\treturn err == 0 ? NF_ACCEPT : NF_DROP;\n }",
        "function_modified_lines": {
            "added": [
                "\treturn err == 0 ? NF_ACCEPT : NF_DROP;"
            ],
            "deleted": [
                "\treturn NF_ACCEPT;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel before 4.9 mishandles IPv6 reassembly, which allows local users to cause a denial of service (integer overflow, out-of-bounds write, and GPF) or possibly have unspecified other impact via a crafted application that makes socket, connect, and writev system calls, related to net/ipv6/netfilter/nf_conntrack_reasm.c and net/ipv6/netfilter/nf_defrag_ipv6_hooks.c."
    },
    {
        "cve_id": "CVE-2017-0750",
        "code_before_change": "static int sanity_check_raw_super(struct super_block *sb,\n\t\t\tstruct f2fs_super_block *raw_super)\n{\n\tunsigned int blocksize;\n\n\tif (F2FS_SUPER_MAGIC != le32_to_cpu(raw_super->magic)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\tF2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_CACHE_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid page_cache_size (%lu), supports only 4KB\\n\",\n\t\t\tPAGE_CACHE_SIZE);\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid blocksize (%u), supports only 4KB\\n\",\n\t\t\tblocksize);\n\t\treturn 1;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO, \"Invalid log sectorsize (%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int sanity_check_raw_super(struct super_block *sb,\n\t\t\tstruct f2fs_super_block *raw_super)\n{\n\tunsigned int blocksize;\n\n\tif (F2FS_SUPER_MAGIC != le32_to_cpu(raw_super->magic)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\tF2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_CACHE_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid page_cache_size (%lu), supports only 4KB\\n\",\n\t\t\tPAGE_CACHE_SIZE);\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid blocksize (%u), supports only 4KB\\n\",\n\t\t\tblocksize);\n\t\treturn 1;\n\t}\n\n\t/* check log blocks per segment */\n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log blocks per segment (%u)\\n\",\n\t\t\tle32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO, \"Invalid log sectorsize (%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\n\t/* check reserved ino info */\n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\tle32_to_cpu(raw_super->node_ino),\n\t\t\tle32_to_cpu(raw_super->meta_ino),\n\t\t\tle32_to_cpu(raw_super->root_ino));\n\t\treturn 1;\n\t}\n\n\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n\tif (sanity_check_area_boundary(sb, raw_super))\n\t\treturn 1;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,6 +27,14 @@\n \t\treturn 1;\n \t}\n \n+\t/* check log blocks per segment */\n+\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n+\t\tf2fs_msg(sb, KERN_INFO,\n+\t\t\t\"Invalid log blocks per segment (%u)\\n\",\n+\t\t\tle32_to_cpu(raw_super->log_blocks_per_seg));\n+\t\treturn 1;\n+\t}\n+\n \t/* Currently, support 512/1024/2048/4096 bytes sector size */\n \tif (le32_to_cpu(raw_super->log_sectorsize) >\n \t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n@@ -45,5 +53,22 @@\n \t\t\tle32_to_cpu(raw_super->log_sectorsize));\n \t\treturn 1;\n \t}\n+\n+\t/* check reserved ino info */\n+\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n+\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n+\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n+\t\tf2fs_msg(sb, KERN_INFO,\n+\t\t\t\"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n+\t\t\tle32_to_cpu(raw_super->node_ino),\n+\t\t\tle32_to_cpu(raw_super->meta_ino),\n+\t\t\tle32_to_cpu(raw_super->root_ino));\n+\t\treturn 1;\n+\t}\n+\n+\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n+\tif (sanity_check_area_boundary(sb, raw_super))\n+\t\treturn 1;\n+\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\t/* check log blocks per segment */",
                "\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {",
                "\t\tf2fs_msg(sb, KERN_INFO,",
                "\t\t\t\"Invalid log blocks per segment (%u)\\n\",",
                "\t\t\tle32_to_cpu(raw_super->log_blocks_per_seg));",
                "\t\treturn 1;",
                "\t}",
                "",
                "",
                "\t/* check reserved ino info */",
                "\tif (le32_to_cpu(raw_super->node_ino) != 1 ||",
                "\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||",
                "\t\tle32_to_cpu(raw_super->root_ino) != 3) {",
                "\t\tf2fs_msg(sb, KERN_INFO,",
                "\t\t\t\"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",",
                "\t\t\tle32_to_cpu(raw_super->node_ino),",
                "\t\t\tle32_to_cpu(raw_super->meta_ino),",
                "\t\t\tle32_to_cpu(raw_super->root_ino));",
                "\t\treturn 1;",
                "\t}",
                "",
                "\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */",
                "\tif (sanity_check_area_boundary(sb, raw_super))",
                "\t\treturn 1;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A elevation of privilege vulnerability in the Upstream Linux file system. Product: Android. Versions: Android kernel. Android ID: A-36817013."
    },
    {
        "cve_id": "CVE-2017-1000111",
        "code_before_change": "static int\npacket_setsockopt(struct socket *sock, int level, int optname, char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct packet_sock *po = pkt_sk(sk);\n\tint ret;\n\n\tif (level != SOL_PACKET)\n\t\treturn -ENOPROTOOPT;\n\n\tswitch (optname) {\n\tcase PACKET_ADD_MEMBERSHIP:\n\tcase PACKET_DROP_MEMBERSHIP:\n\t{\n\t\tstruct packet_mreq_max mreq;\n\t\tint len = optlen;\n\t\tmemset(&mreq, 0, sizeof(mreq));\n\t\tif (len < sizeof(struct packet_mreq))\n\t\t\treturn -EINVAL;\n\t\tif (len > sizeof(mreq))\n\t\t\tlen = sizeof(mreq);\n\t\tif (copy_from_user(&mreq, optval, len))\n\t\t\treturn -EFAULT;\n\t\tif (len < (mreq.mr_alen + offsetof(struct packet_mreq, mr_address)))\n\t\t\treturn -EINVAL;\n\t\tif (optname == PACKET_ADD_MEMBERSHIP)\n\t\t\tret = packet_mc_add(sk, &mreq);\n\t\telse\n\t\t\tret = packet_mc_drop(sk, &mreq);\n\t\treturn ret;\n\t}\n\n\tcase PACKET_RX_RING:\n\tcase PACKET_TX_RING:\n\t{\n\t\tunion tpacket_req_u req_u;\n\t\tint len;\n\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V1:\n\t\tcase TPACKET_V2:\n\t\t\tlen = sizeof(req_u.req);\n\t\t\tbreak;\n\t\tcase TPACKET_V3:\n\t\tdefault:\n\t\t\tlen = sizeof(req_u.req3);\n\t\t\tbreak;\n\t\t}\n\t\tif (optlen < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&req_u.req, optval, len))\n\t\t\treturn -EFAULT;\n\t\treturn packet_set_ring(sk, &req_u, 0,\n\t\t\toptname == PACKET_TX_RING);\n\t}\n\tcase PACKET_COPY_THRESH:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpkt_sk(sk)->copy_thresh = val;\n\t\treturn 0;\n\t}\n\tcase PACKET_VERSION:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tswitch (val) {\n\t\tcase TPACKET_V1:\n\t\tcase TPACKET_V2:\n\t\tcase TPACKET_V3:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlock_sock(sk);\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec) {\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tpo->tp_version = val;\n\t\t\tret = 0;\n\t\t}\n\t\trelease_sock(sk);\n\t\treturn ret;\n\t}\n\tcase PACKET_RESERVE:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tif (val > INT_MAX)\n\t\t\treturn -EINVAL;\n\t\tpo->tp_reserve = val;\n\t\treturn 0;\n\t}\n\tcase PACKET_LOSS:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tpo->tp_loss = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_AUXDATA:\n\t{\n\t\tint val;\n\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->auxdata = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_ORIGDEV:\n\t{\n\t\tint val;\n\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->origdev = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_VNET_HDR:\n\t{\n\t\tint val;\n\n\t\tif (sock->type != SOCK_RAW)\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->has_vnet_hdr = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_TIMESTAMP:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->tp_tstamp = val;\n\t\treturn 0;\n\t}\n\tcase PACKET_FANOUT:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\treturn fanout_add(sk, val & 0xffff, val >> 16);\n\t}\n\tcase PACKET_FANOUT_DATA:\n\t{\n\t\tif (!po->fanout)\n\t\t\treturn -EINVAL;\n\n\t\treturn fanout_set_data(po, optval, optlen);\n\t}\n\tcase PACKET_TX_HAS_OFF:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tpo->tp_tx_has_off = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_QDISC_BYPASS:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->xmit = val ? packet_direct_xmit : dev_queue_xmit;\n\t\treturn 0;\n\t}\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n}",
        "code_after_change": "static int\npacket_setsockopt(struct socket *sock, int level, int optname, char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct packet_sock *po = pkt_sk(sk);\n\tint ret;\n\n\tif (level != SOL_PACKET)\n\t\treturn -ENOPROTOOPT;\n\n\tswitch (optname) {\n\tcase PACKET_ADD_MEMBERSHIP:\n\tcase PACKET_DROP_MEMBERSHIP:\n\t{\n\t\tstruct packet_mreq_max mreq;\n\t\tint len = optlen;\n\t\tmemset(&mreq, 0, sizeof(mreq));\n\t\tif (len < sizeof(struct packet_mreq))\n\t\t\treturn -EINVAL;\n\t\tif (len > sizeof(mreq))\n\t\t\tlen = sizeof(mreq);\n\t\tif (copy_from_user(&mreq, optval, len))\n\t\t\treturn -EFAULT;\n\t\tif (len < (mreq.mr_alen + offsetof(struct packet_mreq, mr_address)))\n\t\t\treturn -EINVAL;\n\t\tif (optname == PACKET_ADD_MEMBERSHIP)\n\t\t\tret = packet_mc_add(sk, &mreq);\n\t\telse\n\t\t\tret = packet_mc_drop(sk, &mreq);\n\t\treturn ret;\n\t}\n\n\tcase PACKET_RX_RING:\n\tcase PACKET_TX_RING:\n\t{\n\t\tunion tpacket_req_u req_u;\n\t\tint len;\n\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V1:\n\t\tcase TPACKET_V2:\n\t\t\tlen = sizeof(req_u.req);\n\t\t\tbreak;\n\t\tcase TPACKET_V3:\n\t\tdefault:\n\t\t\tlen = sizeof(req_u.req3);\n\t\t\tbreak;\n\t\t}\n\t\tif (optlen < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&req_u.req, optval, len))\n\t\t\treturn -EFAULT;\n\t\treturn packet_set_ring(sk, &req_u, 0,\n\t\t\toptname == PACKET_TX_RING);\n\t}\n\tcase PACKET_COPY_THRESH:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpkt_sk(sk)->copy_thresh = val;\n\t\treturn 0;\n\t}\n\tcase PACKET_VERSION:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tswitch (val) {\n\t\tcase TPACKET_V1:\n\t\tcase TPACKET_V2:\n\t\tcase TPACKET_V3:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tlock_sock(sk);\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec) {\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tpo->tp_version = val;\n\t\t\tret = 0;\n\t\t}\n\t\trelease_sock(sk);\n\t\treturn ret;\n\t}\n\tcase PACKET_RESERVE:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tif (val > INT_MAX)\n\t\t\treturn -EINVAL;\n\t\tlock_sock(sk);\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec) {\n\t\t\tret = -EBUSY;\n\t\t} else {\n\t\t\tpo->tp_reserve = val;\n\t\t\tret = 0;\n\t\t}\n\t\trelease_sock(sk);\n\t\treturn ret;\n\t}\n\tcase PACKET_LOSS:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tpo->tp_loss = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_AUXDATA:\n\t{\n\t\tint val;\n\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->auxdata = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_ORIGDEV:\n\t{\n\t\tint val;\n\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->origdev = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_VNET_HDR:\n\t{\n\t\tint val;\n\n\t\tif (sock->type != SOCK_RAW)\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (optlen < sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->has_vnet_hdr = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_TIMESTAMP:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->tp_tstamp = val;\n\t\treturn 0;\n\t}\n\tcase PACKET_FANOUT:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\treturn fanout_add(sk, val & 0xffff, val >> 16);\n\t}\n\tcase PACKET_FANOUT_DATA:\n\t{\n\t\tif (!po->fanout)\n\t\t\treturn -EINVAL;\n\n\t\treturn fanout_set_data(po, optval, optlen);\n\t}\n\tcase PACKET_TX_HAS_OFF:\n\t{\n\t\tunsigned int val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n\t\t\treturn -EBUSY;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\t\tpo->tp_tx_has_off = !!val;\n\t\treturn 0;\n\t}\n\tcase PACKET_QDISC_BYPASS:\n\t{\n\t\tint val;\n\n\t\tif (optlen != sizeof(val))\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&val, optval, sizeof(val)))\n\t\t\treturn -EFAULT;\n\n\t\tpo->xmit = val ? packet_direct_xmit : dev_queue_xmit;\n\t\treturn 0;\n\t}\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -97,14 +97,19 @@\n \n \t\tif (optlen != sizeof(val))\n \t\t\treturn -EINVAL;\n-\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)\n-\t\t\treturn -EBUSY;\n \t\tif (copy_from_user(&val, optval, sizeof(val)))\n \t\t\treturn -EFAULT;\n \t\tif (val > INT_MAX)\n \t\t\treturn -EINVAL;\n-\t\tpo->tp_reserve = val;\n-\t\treturn 0;\n+\t\tlock_sock(sk);\n+\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec) {\n+\t\t\tret = -EBUSY;\n+\t\t} else {\n+\t\t\tpo->tp_reserve = val;\n+\t\t\tret = 0;\n+\t\t}\n+\t\trelease_sock(sk);\n+\t\treturn ret;\n \t}\n \tcase PACKET_LOSS:\n \t{",
        "function_modified_lines": {
            "added": [
                "\t\tlock_sock(sk);",
                "\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec) {",
                "\t\t\tret = -EBUSY;",
                "\t\t} else {",
                "\t\t\tpo->tp_reserve = val;",
                "\t\t\tret = 0;",
                "\t\t}",
                "\t\trelease_sock(sk);",
                "\t\treturn ret;"
            ],
            "deleted": [
                "\t\tif (po->rx_ring.pg_vec || po->tx_ring.pg_vec)",
                "\t\t\treturn -EBUSY;",
                "\t\tpo->tp_reserve = val;",
                "\t\treturn 0;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Linux kernel: heap out-of-bounds in AF_PACKET sockets. This new issue is analogous to previously disclosed CVE-2016-8655. In both cases, a socket option that changes socket state may race with safety checks in packet_set_ring. Previously with PACKET_VERSION. This time with PACKET_RESERVE. The solution is similar: lock the socket for the update. This issue may be exploitable, we did not investigate further. As this issue affects PF_PACKET sockets, it requires CAP_NET_RAW in the process namespace. But note that with user namespaces enabled, any process can create a namespace in which it has CAP_NET_RAW."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static int l2cap_connect_create_rsp(struct l2cap_conn *conn,\n\t\t\t\t    struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t    u8 *data)\n{\n\tstruct l2cap_conn_rsp *rsp = (struct l2cap_conn_rsp *) data;\n\tu16 scid, dcid, result, status;\n\tstruct l2cap_chan *chan;\n\tu8 req[128];\n\tint err;\n\n\tif (cmd_len < sizeof(*rsp))\n\t\treturn -EPROTO;\n\n\tscid   = __le16_to_cpu(rsp->scid);\n\tdcid   = __le16_to_cpu(rsp->dcid);\n\tresult = __le16_to_cpu(rsp->result);\n\tstatus = __le16_to_cpu(rsp->status);\n\n\tBT_DBG(\"dcid 0x%4.4x scid 0x%4.4x result 0x%2.2x status 0x%2.2x\",\n\t       dcid, scid, result, status);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tif (scid) {\n\t\tchan = __l2cap_get_chan_by_scid(conn, scid);\n\t\tif (!chan) {\n\t\t\terr = -EBADSLT;\n\t\t\tgoto unlock;\n\t\t}\n\t} else {\n\t\tchan = __l2cap_get_chan_by_ident(conn, cmd->ident);\n\t\tif (!chan) {\n\t\t\terr = -EBADSLT;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\terr = 0;\n\n\tl2cap_chan_lock(chan);\n\n\tswitch (result) {\n\tcase L2CAP_CR_SUCCESS:\n\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\tchan->ident = 0;\n\t\tchan->dcid = dcid;\n\t\tclear_bit(CONF_CONNECT_PEND, &chan->conf_state);\n\n\t\tif (test_and_set_bit(CONF_REQ_SENT, &chan->conf_state))\n\t\t\tbreak;\n\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, req), req);\n\t\tchan->num_conf_req++;\n\t\tbreak;\n\n\tcase L2CAP_CR_PEND:\n\t\tset_bit(CONF_CONNECT_PEND, &chan->conf_state);\n\t\tbreak;\n\n\tdefault:\n\t\tl2cap_chan_del(chan, ECONNREFUSED);\n\t\tbreak;\n\t}\n\n\tl2cap_chan_unlock(chan);\n\nunlock:\n\tmutex_unlock(&conn->chan_lock);\n\n\treturn err;\n}",
        "code_after_change": "static int l2cap_connect_create_rsp(struct l2cap_conn *conn,\n\t\t\t\t    struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t    u8 *data)\n{\n\tstruct l2cap_conn_rsp *rsp = (struct l2cap_conn_rsp *) data;\n\tu16 scid, dcid, result, status;\n\tstruct l2cap_chan *chan;\n\tu8 req[128];\n\tint err;\n\n\tif (cmd_len < sizeof(*rsp))\n\t\treturn -EPROTO;\n\n\tscid   = __le16_to_cpu(rsp->scid);\n\tdcid   = __le16_to_cpu(rsp->dcid);\n\tresult = __le16_to_cpu(rsp->result);\n\tstatus = __le16_to_cpu(rsp->status);\n\n\tBT_DBG(\"dcid 0x%4.4x scid 0x%4.4x result 0x%2.2x status 0x%2.2x\",\n\t       dcid, scid, result, status);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tif (scid) {\n\t\tchan = __l2cap_get_chan_by_scid(conn, scid);\n\t\tif (!chan) {\n\t\t\terr = -EBADSLT;\n\t\t\tgoto unlock;\n\t\t}\n\t} else {\n\t\tchan = __l2cap_get_chan_by_ident(conn, cmd->ident);\n\t\tif (!chan) {\n\t\t\terr = -EBADSLT;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\terr = 0;\n\n\tl2cap_chan_lock(chan);\n\n\tswitch (result) {\n\tcase L2CAP_CR_SUCCESS:\n\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\tchan->ident = 0;\n\t\tchan->dcid = dcid;\n\t\tclear_bit(CONF_CONNECT_PEND, &chan->conf_state);\n\n\t\tif (test_and_set_bit(CONF_REQ_SENT, &chan->conf_state))\n\t\t\tbreak;\n\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, req, sizeof(req)), req);\n\t\tchan->num_conf_req++;\n\t\tbreak;\n\n\tcase L2CAP_CR_PEND:\n\t\tset_bit(CONF_CONNECT_PEND, &chan->conf_state);\n\t\tbreak;\n\n\tdefault:\n\t\tl2cap_chan_del(chan, ECONNREFUSED);\n\t\tbreak;\n\t}\n\n\tl2cap_chan_unlock(chan);\n\nunlock:\n\tmutex_unlock(&conn->chan_lock);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -50,7 +50,7 @@\n \t\t\tbreak;\n \n \t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n-\t\t\t       l2cap_build_conf_req(chan, req), req);\n+\t\t\t       l2cap_build_conf_req(chan, req, sizeof(req)), req);\n \t\tchan->num_conf_req++;\n \t\tbreak;\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t       l2cap_build_conf_req(chan, req, sizeof(req)), req);"
            ],
            "deleted": [
                "\t\t\t       l2cap_build_conf_req(chan, req), req);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "void __l2cap_connect_rsp_defer(struct l2cap_chan *chan)\n{\n\tstruct l2cap_conn_rsp rsp;\n\tstruct l2cap_conn *conn = chan->conn;\n\tu8 buf[128];\n\tu8 rsp_code;\n\n\trsp.scid   = cpu_to_le16(chan->dcid);\n\trsp.dcid   = cpu_to_le16(chan->scid);\n\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\n\tif (chan->hs_hcon)\n\t\trsp_code = L2CAP_CREATE_CHAN_RSP;\n\telse\n\t\trsp_code = L2CAP_CONN_RSP;\n\n\tBT_DBG(\"chan %p rsp_code %u\", chan, rsp_code);\n\n\tl2cap_send_cmd(conn, chan->ident, rsp_code, sizeof(rsp), &rsp);\n\n\tif (test_and_set_bit(CONF_REQ_SENT, &chan->conf_state))\n\t\treturn;\n\n\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t       l2cap_build_conf_req(chan, buf), buf);\n\tchan->num_conf_req++;\n}",
        "code_after_change": "void __l2cap_connect_rsp_defer(struct l2cap_chan *chan)\n{\n\tstruct l2cap_conn_rsp rsp;\n\tstruct l2cap_conn *conn = chan->conn;\n\tu8 buf[128];\n\tu8 rsp_code;\n\n\trsp.scid   = cpu_to_le16(chan->dcid);\n\trsp.dcid   = cpu_to_le16(chan->scid);\n\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\n\tif (chan->hs_hcon)\n\t\trsp_code = L2CAP_CREATE_CHAN_RSP;\n\telse\n\t\trsp_code = L2CAP_CONN_RSP;\n\n\tBT_DBG(\"chan %p rsp_code %u\", chan, rsp_code);\n\n\tl2cap_send_cmd(conn, chan->ident, rsp_code, sizeof(rsp), &rsp);\n\n\tif (test_and_set_bit(CONF_REQ_SENT, &chan->conf_state))\n\t\treturn;\n\n\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n\tchan->num_conf_req++;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,6 +23,6 @@\n \t\treturn;\n \n \tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n-\t\t       l2cap_build_conf_req(chan, buf), buf);\n+\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n \tchan->num_conf_req++;\n }",
        "function_modified_lines": {
            "added": [
                "\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);"
            ],
            "deleted": [
                "\t\t       l2cap_build_conf_req(chan, buf), buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static struct l2cap_chan *l2cap_connect(struct l2cap_conn *conn,\n\t\t\t\t\tstruct l2cap_cmd_hdr *cmd,\n\t\t\t\t\tu8 *data, u8 rsp_code, u8 amp_id)\n{\n\tstruct l2cap_conn_req *req = (struct l2cap_conn_req *) data;\n\tstruct l2cap_conn_rsp rsp;\n\tstruct l2cap_chan *chan = NULL, *pchan;\n\tint result, status = L2CAP_CS_NO_INFO;\n\n\tu16 dcid = 0, scid = __le16_to_cpu(req->scid);\n\t__le16 psm = req->psm;\n\n\tBT_DBG(\"psm 0x%2.2x scid 0x%4.4x\", __le16_to_cpu(psm), scid);\n\n\t/* Check if we have socket listening on psm */\n\tpchan = l2cap_global_chan_by_psm(BT_LISTEN, psm, &conn->hcon->src,\n\t\t\t\t\t &conn->hcon->dst, ACL_LINK);\n\tif (!pchan) {\n\t\tresult = L2CAP_CR_BAD_PSM;\n\t\tgoto sendresp;\n\t}\n\n\tmutex_lock(&conn->chan_lock);\n\tl2cap_chan_lock(pchan);\n\n\t/* Check if the ACL is secure enough (if not SDP) */\n\tif (psm != cpu_to_le16(L2CAP_PSM_SDP) &&\n\t    !hci_conn_check_link_mode(conn->hcon)) {\n\t\tconn->disc_reason = HCI_ERROR_AUTH_FAILURE;\n\t\tresult = L2CAP_CR_SEC_BLOCK;\n\t\tgoto response;\n\t}\n\n\tresult = L2CAP_CR_NO_MEM;\n\n\t/* Check if we already have channel with that dcid */\n\tif (__l2cap_get_chan_by_dcid(conn, scid))\n\t\tgoto response;\n\n\tchan = pchan->ops->new_connection(pchan);\n\tif (!chan)\n\t\tgoto response;\n\n\t/* For certain devices (ex: HID mouse), support for authentication,\n\t * pairing and bonding is optional. For such devices, inorder to avoid\n\t * the ACL alive for too long after L2CAP disconnection, reset the ACL\n\t * disc_timeout back to HCI_DISCONN_TIMEOUT during L2CAP connect.\n\t */\n\tconn->hcon->disc_timeout = HCI_DISCONN_TIMEOUT;\n\n\tbacpy(&chan->src, &conn->hcon->src);\n\tbacpy(&chan->dst, &conn->hcon->dst);\n\tchan->src_type = bdaddr_src_type(conn->hcon);\n\tchan->dst_type = bdaddr_dst_type(conn->hcon);\n\tchan->psm  = psm;\n\tchan->dcid = scid;\n\tchan->local_amp_id = amp_id;\n\n\t__l2cap_chan_add(conn, chan);\n\n\tdcid = chan->scid;\n\n\t__set_chan_timer(chan, chan->ops->get_sndtimeo(chan));\n\n\tchan->ident = cmd->ident;\n\n\tif (conn->info_state & L2CAP_INFO_FEAT_MASK_REQ_DONE) {\n\t\tif (l2cap_chan_check_security(chan, false)) {\n\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\t\tresult = L2CAP_CR_PEND;\n\t\t\t\tstatus = L2CAP_CS_AUTHOR_PEND;\n\t\t\t\tchan->ops->defer(chan);\n\t\t\t} else {\n\t\t\t\t/* Force pending result for AMP controllers.\n\t\t\t\t * The connection will succeed after the\n\t\t\t\t * physical link is up.\n\t\t\t\t */\n\t\t\t\tif (amp_id == AMP_ID_BREDR) {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\tresult = L2CAP_CR_SUCCESS;\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\t\t\tresult = L2CAP_CR_PEND;\n\t\t\t\t}\n\t\t\t\tstatus = L2CAP_CS_NO_INFO;\n\t\t\t}\n\t\t} else {\n\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\tresult = L2CAP_CR_PEND;\n\t\t\tstatus = L2CAP_CS_AUTHEN_PEND;\n\t\t}\n\t} else {\n\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\tresult = L2CAP_CR_PEND;\n\t\tstatus = L2CAP_CS_NO_INFO;\n\t}\n\nresponse:\n\tl2cap_chan_unlock(pchan);\n\tmutex_unlock(&conn->chan_lock);\n\tl2cap_chan_put(pchan);\n\nsendresp:\n\trsp.scid   = cpu_to_le16(scid);\n\trsp.dcid   = cpu_to_le16(dcid);\n\trsp.result = cpu_to_le16(result);\n\trsp.status = cpu_to_le16(status);\n\tl2cap_send_cmd(conn, cmd->ident, rsp_code, sizeof(rsp), &rsp);\n\n\tif (result == L2CAP_CR_PEND && status == L2CAP_CS_NO_INFO) {\n\t\tstruct l2cap_info_req info;\n\t\tinfo.type = cpu_to_le16(L2CAP_IT_FEAT_MASK);\n\n\t\tconn->info_state |= L2CAP_INFO_FEAT_MASK_REQ_SENT;\n\t\tconn->info_ident = l2cap_get_ident(conn);\n\n\t\tschedule_delayed_work(&conn->info_timer, L2CAP_INFO_TIMEOUT);\n\n\t\tl2cap_send_cmd(conn, conn->info_ident, L2CAP_INFO_REQ,\n\t\t\t       sizeof(info), &info);\n\t}\n\n\tif (chan && !test_bit(CONF_REQ_SENT, &chan->conf_state) &&\n\t    result == L2CAP_CR_SUCCESS) {\n\t\tu8 buf[128];\n\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n\t\tchan->num_conf_req++;\n\t}\n\n\treturn chan;\n}",
        "code_after_change": "static struct l2cap_chan *l2cap_connect(struct l2cap_conn *conn,\n\t\t\t\t\tstruct l2cap_cmd_hdr *cmd,\n\t\t\t\t\tu8 *data, u8 rsp_code, u8 amp_id)\n{\n\tstruct l2cap_conn_req *req = (struct l2cap_conn_req *) data;\n\tstruct l2cap_conn_rsp rsp;\n\tstruct l2cap_chan *chan = NULL, *pchan;\n\tint result, status = L2CAP_CS_NO_INFO;\n\n\tu16 dcid = 0, scid = __le16_to_cpu(req->scid);\n\t__le16 psm = req->psm;\n\n\tBT_DBG(\"psm 0x%2.2x scid 0x%4.4x\", __le16_to_cpu(psm), scid);\n\n\t/* Check if we have socket listening on psm */\n\tpchan = l2cap_global_chan_by_psm(BT_LISTEN, psm, &conn->hcon->src,\n\t\t\t\t\t &conn->hcon->dst, ACL_LINK);\n\tif (!pchan) {\n\t\tresult = L2CAP_CR_BAD_PSM;\n\t\tgoto sendresp;\n\t}\n\n\tmutex_lock(&conn->chan_lock);\n\tl2cap_chan_lock(pchan);\n\n\t/* Check if the ACL is secure enough (if not SDP) */\n\tif (psm != cpu_to_le16(L2CAP_PSM_SDP) &&\n\t    !hci_conn_check_link_mode(conn->hcon)) {\n\t\tconn->disc_reason = HCI_ERROR_AUTH_FAILURE;\n\t\tresult = L2CAP_CR_SEC_BLOCK;\n\t\tgoto response;\n\t}\n\n\tresult = L2CAP_CR_NO_MEM;\n\n\t/* Check if we already have channel with that dcid */\n\tif (__l2cap_get_chan_by_dcid(conn, scid))\n\t\tgoto response;\n\n\tchan = pchan->ops->new_connection(pchan);\n\tif (!chan)\n\t\tgoto response;\n\n\t/* For certain devices (ex: HID mouse), support for authentication,\n\t * pairing and bonding is optional. For such devices, inorder to avoid\n\t * the ACL alive for too long after L2CAP disconnection, reset the ACL\n\t * disc_timeout back to HCI_DISCONN_TIMEOUT during L2CAP connect.\n\t */\n\tconn->hcon->disc_timeout = HCI_DISCONN_TIMEOUT;\n\n\tbacpy(&chan->src, &conn->hcon->src);\n\tbacpy(&chan->dst, &conn->hcon->dst);\n\tchan->src_type = bdaddr_src_type(conn->hcon);\n\tchan->dst_type = bdaddr_dst_type(conn->hcon);\n\tchan->psm  = psm;\n\tchan->dcid = scid;\n\tchan->local_amp_id = amp_id;\n\n\t__l2cap_chan_add(conn, chan);\n\n\tdcid = chan->scid;\n\n\t__set_chan_timer(chan, chan->ops->get_sndtimeo(chan));\n\n\tchan->ident = cmd->ident;\n\n\tif (conn->info_state & L2CAP_INFO_FEAT_MASK_REQ_DONE) {\n\t\tif (l2cap_chan_check_security(chan, false)) {\n\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\t\tresult = L2CAP_CR_PEND;\n\t\t\t\tstatus = L2CAP_CS_AUTHOR_PEND;\n\t\t\t\tchan->ops->defer(chan);\n\t\t\t} else {\n\t\t\t\t/* Force pending result for AMP controllers.\n\t\t\t\t * The connection will succeed after the\n\t\t\t\t * physical link is up.\n\t\t\t\t */\n\t\t\t\tif (amp_id == AMP_ID_BREDR) {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\tresult = L2CAP_CR_SUCCESS;\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\t\t\tresult = L2CAP_CR_PEND;\n\t\t\t\t}\n\t\t\t\tstatus = L2CAP_CS_NO_INFO;\n\t\t\t}\n\t\t} else {\n\t\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\t\tresult = L2CAP_CR_PEND;\n\t\t\tstatus = L2CAP_CS_AUTHEN_PEND;\n\t\t}\n\t} else {\n\t\tl2cap_state_change(chan, BT_CONNECT2);\n\t\tresult = L2CAP_CR_PEND;\n\t\tstatus = L2CAP_CS_NO_INFO;\n\t}\n\nresponse:\n\tl2cap_chan_unlock(pchan);\n\tmutex_unlock(&conn->chan_lock);\n\tl2cap_chan_put(pchan);\n\nsendresp:\n\trsp.scid   = cpu_to_le16(scid);\n\trsp.dcid   = cpu_to_le16(dcid);\n\trsp.result = cpu_to_le16(result);\n\trsp.status = cpu_to_le16(status);\n\tl2cap_send_cmd(conn, cmd->ident, rsp_code, sizeof(rsp), &rsp);\n\n\tif (result == L2CAP_CR_PEND && status == L2CAP_CS_NO_INFO) {\n\t\tstruct l2cap_info_req info;\n\t\tinfo.type = cpu_to_le16(L2CAP_IT_FEAT_MASK);\n\n\t\tconn->info_state |= L2CAP_INFO_FEAT_MASK_REQ_SENT;\n\t\tconn->info_ident = l2cap_get_ident(conn);\n\n\t\tschedule_delayed_work(&conn->info_timer, L2CAP_INFO_TIMEOUT);\n\n\t\tl2cap_send_cmd(conn, conn->info_ident, L2CAP_INFO_REQ,\n\t\t\t       sizeof(info), &info);\n\t}\n\n\tif (chan && !test_bit(CONF_REQ_SENT, &chan->conf_state) &&\n\t    result == L2CAP_CR_SUCCESS) {\n\t\tu8 buf[128];\n\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n\t\tchan->num_conf_req++;\n\t}\n\n\treturn chan;\n}",
        "patch": "--- code before\n+++ code after\n@@ -126,7 +126,7 @@\n \t\tu8 buf[128];\n \t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n \t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n-\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n+\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n \t\tchan->num_conf_req++;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);"
            ],
            "deleted": [
                "\t\t\t       l2cap_build_conf_req(chan, buf), buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static void l2cap_conn_start(struct l2cap_conn *conn)\n{\n\tstruct l2cap_chan *chan, *tmp;\n\n\tBT_DBG(\"conn %p\", conn);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tlist_for_each_entry_safe(chan, tmp, &conn->chan_l, list) {\n\t\tl2cap_chan_lock(chan);\n\n\t\tif (chan->chan_type != L2CAP_CHAN_CONN_ORIENTED) {\n\t\t\tl2cap_chan_ready(chan);\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (chan->state == BT_CONNECT) {\n\t\t\tif (!l2cap_chan_check_security(chan, true) ||\n\t\t\t    !__l2cap_no_conn_pending(chan)) {\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!l2cap_mode_supported(chan->mode, conn->feat_mask)\n\t\t\t    && test_bit(CONF_STATE2_DEVICE,\n\t\t\t\t\t&chan->conf_state)) {\n\t\t\t\tl2cap_chan_close(chan, ECONNRESET);\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tl2cap_start_connection(chan);\n\n\t\t} else if (chan->state == BT_CONNECT2) {\n\t\t\tstruct l2cap_conn_rsp rsp;\n\t\t\tchar buf[128];\n\t\t\trsp.scid = cpu_to_le16(chan->dcid);\n\t\t\trsp.dcid = cpu_to_le16(chan->scid);\n\n\t\t\tif (l2cap_chan_check_security(chan, false)) {\n\t\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_PEND);\n\t\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_AUTHOR_PEND);\n\t\t\t\t\tchan->ops->defer(chan);\n\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\t\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_PEND);\n\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_AUTHEN_PEND);\n\t\t\t}\n\n\t\t\tl2cap_send_cmd(conn, chan->ident, L2CAP_CONN_RSP,\n\t\t\t\t       sizeof(rsp), &rsp);\n\n\t\t\tif (test_bit(CONF_REQ_SENT, &chan->conf_state) ||\n\t\t\t    rsp.result != L2CAP_CR_SUCCESS) {\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n\t\t\tchan->num_conf_req++;\n\t\t}\n\n\t\tl2cap_chan_unlock(chan);\n\t}\n\n\tmutex_unlock(&conn->chan_lock);\n}",
        "code_after_change": "static void l2cap_conn_start(struct l2cap_conn *conn)\n{\n\tstruct l2cap_chan *chan, *tmp;\n\n\tBT_DBG(\"conn %p\", conn);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tlist_for_each_entry_safe(chan, tmp, &conn->chan_l, list) {\n\t\tl2cap_chan_lock(chan);\n\n\t\tif (chan->chan_type != L2CAP_CHAN_CONN_ORIENTED) {\n\t\t\tl2cap_chan_ready(chan);\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (chan->state == BT_CONNECT) {\n\t\t\tif (!l2cap_chan_check_security(chan, true) ||\n\t\t\t    !__l2cap_no_conn_pending(chan)) {\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!l2cap_mode_supported(chan->mode, conn->feat_mask)\n\t\t\t    && test_bit(CONF_STATE2_DEVICE,\n\t\t\t\t\t&chan->conf_state)) {\n\t\t\t\tl2cap_chan_close(chan, ECONNRESET);\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tl2cap_start_connection(chan);\n\n\t\t} else if (chan->state == BT_CONNECT2) {\n\t\t\tstruct l2cap_conn_rsp rsp;\n\t\t\tchar buf[128];\n\t\t\trsp.scid = cpu_to_le16(chan->dcid);\n\t\t\trsp.dcid = cpu_to_le16(chan->scid);\n\n\t\t\tif (l2cap_chan_check_security(chan, false)) {\n\t\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_PEND);\n\t\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_AUTHOR_PEND);\n\t\t\t\t\tchan->ops->defer(chan);\n\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\t\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\trsp.result = cpu_to_le16(L2CAP_CR_PEND);\n\t\t\t\trsp.status = cpu_to_le16(L2CAP_CS_AUTHEN_PEND);\n\t\t\t}\n\n\t\t\tl2cap_send_cmd(conn, chan->ident, L2CAP_CONN_RSP,\n\t\t\t\t       sizeof(rsp), &rsp);\n\n\t\t\tif (test_bit(CONF_REQ_SENT, &chan->conf_state) ||\n\t\t\t    rsp.result != L2CAP_CR_SUCCESS) {\n\t\t\t\tl2cap_chan_unlock(chan);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n\t\t\tchan->num_conf_req++;\n\t\t}\n\n\t\tl2cap_chan_unlock(chan);\n\t}\n\n\tmutex_unlock(&conn->chan_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -65,7 +65,7 @@\n \n \t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n \t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n-\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n+\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n \t\t\tchan->num_conf_req++;\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);"
            ],
            "deleted": [
                "\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static inline int l2cap_config_req(struct l2cap_conn *conn,\n\t\t\t\t   struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t   u8 *data)\n{\n\tstruct l2cap_conf_req *req = (struct l2cap_conf_req *) data;\n\tu16 dcid, flags;\n\tu8 rsp[64];\n\tstruct l2cap_chan *chan;\n\tint len, err = 0;\n\n\tif (cmd_len < sizeof(*req))\n\t\treturn -EPROTO;\n\n\tdcid  = __le16_to_cpu(req->dcid);\n\tflags = __le16_to_cpu(req->flags);\n\n\tBT_DBG(\"dcid 0x%4.4x flags 0x%2.2x\", dcid, flags);\n\n\tchan = l2cap_get_chan_by_scid(conn, dcid);\n\tif (!chan) {\n\t\tcmd_reject_invalid_cid(conn, cmd->ident, dcid, 0);\n\t\treturn 0;\n\t}\n\n\tif (chan->state != BT_CONFIG && chan->state != BT_CONNECT2) {\n\t\tcmd_reject_invalid_cid(conn, cmd->ident, chan->scid,\n\t\t\t\t       chan->dcid);\n\t\tgoto unlock;\n\t}\n\n\t/* Reject if config buffer is too small. */\n\tlen = cmd_len - sizeof(*req);\n\tif (chan->conf_len + len > sizeof(chan->conf_req)) {\n\t\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP,\n\t\t\t       l2cap_build_conf_rsp(chan, rsp,\n\t\t\t       L2CAP_CONF_REJECT, flags), rsp);\n\t\tgoto unlock;\n\t}\n\n\t/* Store config. */\n\tmemcpy(chan->conf_req + chan->conf_len, req->data, len);\n\tchan->conf_len += len;\n\n\tif (flags & L2CAP_CONF_FLAG_CONTINUATION) {\n\t\t/* Incomplete config. Send empty response. */\n\t\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP,\n\t\t\t       l2cap_build_conf_rsp(chan, rsp,\n\t\t\t       L2CAP_CONF_SUCCESS, flags), rsp);\n\t\tgoto unlock;\n\t}\n\n\t/* Complete config. */\n\tlen = l2cap_parse_conf_req(chan, rsp);\n\tif (len < 0) {\n\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\tgoto unlock;\n\t}\n\n\tchan->ident = cmd->ident;\n\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP, len, rsp);\n\tchan->num_conf_rsp++;\n\n\t/* Reset config buffer. */\n\tchan->conf_len = 0;\n\n\tif (!test_bit(CONF_OUTPUT_DONE, &chan->conf_state))\n\t\tgoto unlock;\n\n\tif (test_bit(CONF_INPUT_DONE, &chan->conf_state)) {\n\t\tset_default_fcs(chan);\n\n\t\tif (chan->mode == L2CAP_MODE_ERTM ||\n\t\t    chan->mode == L2CAP_MODE_STREAMING)\n\t\t\terr = l2cap_ertm_init(chan);\n\n\t\tif (err < 0)\n\t\t\tl2cap_send_disconn_req(chan, -err);\n\t\telse\n\t\t\tl2cap_chan_ready(chan);\n\n\t\tgoto unlock;\n\t}\n\n\tif (!test_and_set_bit(CONF_REQ_SENT, &chan->conf_state)) {\n\t\tu8 buf[64];\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n\t\tchan->num_conf_req++;\n\t}\n\n\t/* Got Conf Rsp PENDING from remote side and assume we sent\n\t   Conf Rsp PENDING in the code above */\n\tif (test_bit(CONF_REM_CONF_PEND, &chan->conf_state) &&\n\t    test_bit(CONF_LOC_CONF_PEND, &chan->conf_state)) {\n\n\t\t/* check compatibility */\n\n\t\t/* Send rsp for BR/EDR channel */\n\t\tif (!chan->hs_hcon)\n\t\t\tl2cap_send_efs_conf_rsp(chan, rsp, cmd->ident, flags);\n\t\telse\n\t\t\tchan->ident = cmd->ident;\n\t}\n\nunlock:\n\tl2cap_chan_unlock(chan);\n\treturn err;\n}",
        "code_after_change": "static inline int l2cap_config_req(struct l2cap_conn *conn,\n\t\t\t\t   struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t   u8 *data)\n{\n\tstruct l2cap_conf_req *req = (struct l2cap_conf_req *) data;\n\tu16 dcid, flags;\n\tu8 rsp[64];\n\tstruct l2cap_chan *chan;\n\tint len, err = 0;\n\n\tif (cmd_len < sizeof(*req))\n\t\treturn -EPROTO;\n\n\tdcid  = __le16_to_cpu(req->dcid);\n\tflags = __le16_to_cpu(req->flags);\n\n\tBT_DBG(\"dcid 0x%4.4x flags 0x%2.2x\", dcid, flags);\n\n\tchan = l2cap_get_chan_by_scid(conn, dcid);\n\tif (!chan) {\n\t\tcmd_reject_invalid_cid(conn, cmd->ident, dcid, 0);\n\t\treturn 0;\n\t}\n\n\tif (chan->state != BT_CONFIG && chan->state != BT_CONNECT2) {\n\t\tcmd_reject_invalid_cid(conn, cmd->ident, chan->scid,\n\t\t\t\t       chan->dcid);\n\t\tgoto unlock;\n\t}\n\n\t/* Reject if config buffer is too small. */\n\tlen = cmd_len - sizeof(*req);\n\tif (chan->conf_len + len > sizeof(chan->conf_req)) {\n\t\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP,\n\t\t\t       l2cap_build_conf_rsp(chan, rsp,\n\t\t\t       L2CAP_CONF_REJECT, flags), rsp);\n\t\tgoto unlock;\n\t}\n\n\t/* Store config. */\n\tmemcpy(chan->conf_req + chan->conf_len, req->data, len);\n\tchan->conf_len += len;\n\n\tif (flags & L2CAP_CONF_FLAG_CONTINUATION) {\n\t\t/* Incomplete config. Send empty response. */\n\t\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP,\n\t\t\t       l2cap_build_conf_rsp(chan, rsp,\n\t\t\t       L2CAP_CONF_SUCCESS, flags), rsp);\n\t\tgoto unlock;\n\t}\n\n\t/* Complete config. */\n\tlen = l2cap_parse_conf_req(chan, rsp, sizeof(rsp));\n\tif (len < 0) {\n\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\tgoto unlock;\n\t}\n\n\tchan->ident = cmd->ident;\n\tl2cap_send_cmd(conn, cmd->ident, L2CAP_CONF_RSP, len, rsp);\n\tchan->num_conf_rsp++;\n\n\t/* Reset config buffer. */\n\tchan->conf_len = 0;\n\n\tif (!test_bit(CONF_OUTPUT_DONE, &chan->conf_state))\n\t\tgoto unlock;\n\n\tif (test_bit(CONF_INPUT_DONE, &chan->conf_state)) {\n\t\tset_default_fcs(chan);\n\n\t\tif (chan->mode == L2CAP_MODE_ERTM ||\n\t\t    chan->mode == L2CAP_MODE_STREAMING)\n\t\t\terr = l2cap_ertm_init(chan);\n\n\t\tif (err < 0)\n\t\t\tl2cap_send_disconn_req(chan, -err);\n\t\telse\n\t\t\tl2cap_chan_ready(chan);\n\n\t\tgoto unlock;\n\t}\n\n\tif (!test_and_set_bit(CONF_REQ_SENT, &chan->conf_state)) {\n\t\tu8 buf[64];\n\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n\t\tchan->num_conf_req++;\n\t}\n\n\t/* Got Conf Rsp PENDING from remote side and assume we sent\n\t   Conf Rsp PENDING in the code above */\n\tif (test_bit(CONF_REM_CONF_PEND, &chan->conf_state) &&\n\t    test_bit(CONF_LOC_CONF_PEND, &chan->conf_state)) {\n\n\t\t/* check compatibility */\n\n\t\t/* Send rsp for BR/EDR channel */\n\t\tif (!chan->hs_hcon)\n\t\t\tl2cap_send_efs_conf_rsp(chan, rsp, cmd->ident, flags);\n\t\telse\n\t\t\tchan->ident = cmd->ident;\n\t}\n\nunlock:\n\tl2cap_chan_unlock(chan);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -50,7 +50,7 @@\n \t}\n \n \t/* Complete config. */\n-\tlen = l2cap_parse_conf_req(chan, rsp);\n+\tlen = l2cap_parse_conf_req(chan, rsp, sizeof(rsp));\n \tif (len < 0) {\n \t\tl2cap_send_disconn_req(chan, ECONNRESET);\n \t\tgoto unlock;\n@@ -84,7 +84,7 @@\n \tif (!test_and_set_bit(CONF_REQ_SENT, &chan->conf_state)) {\n \t\tu8 buf[64];\n \t\tl2cap_send_cmd(conn, l2cap_get_ident(conn), L2CAP_CONF_REQ,\n-\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n+\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n \t\tchan->num_conf_req++;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tlen = l2cap_parse_conf_req(chan, rsp, sizeof(rsp));",
                "\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);"
            ],
            "deleted": [
                "\tlen = l2cap_parse_conf_req(chan, rsp);",
                "\t\t\t       l2cap_build_conf_req(chan, buf), buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static inline int l2cap_config_rsp(struct l2cap_conn *conn,\n\t\t\t\t   struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t   u8 *data)\n{\n\tstruct l2cap_conf_rsp *rsp = (struct l2cap_conf_rsp *)data;\n\tu16 scid, flags, result;\n\tstruct l2cap_chan *chan;\n\tint len = cmd_len - sizeof(*rsp);\n\tint err = 0;\n\n\tif (cmd_len < sizeof(*rsp))\n\t\treturn -EPROTO;\n\n\tscid   = __le16_to_cpu(rsp->scid);\n\tflags  = __le16_to_cpu(rsp->flags);\n\tresult = __le16_to_cpu(rsp->result);\n\n\tBT_DBG(\"scid 0x%4.4x flags 0x%2.2x result 0x%2.2x len %d\", scid, flags,\n\t       result, len);\n\n\tchan = l2cap_get_chan_by_scid(conn, scid);\n\tif (!chan)\n\t\treturn 0;\n\n\tswitch (result) {\n\tcase L2CAP_CONF_SUCCESS:\n\t\tl2cap_conf_rfc_get(chan, rsp->data, len);\n\t\tclear_bit(CONF_REM_CONF_PEND, &chan->conf_state);\n\t\tbreak;\n\n\tcase L2CAP_CONF_PENDING:\n\t\tset_bit(CONF_REM_CONF_PEND, &chan->conf_state);\n\n\t\tif (test_bit(CONF_LOC_CONF_PEND, &chan->conf_state)) {\n\t\t\tchar buf[64];\n\n\t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n\t\t\t\t\t\t   buf, &result);\n\t\t\tif (len < 0) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tif (!chan->hs_hcon) {\n\t\t\t\tl2cap_send_efs_conf_rsp(chan, buf, cmd->ident,\n\t\t\t\t\t\t\t0);\n\t\t\t} else {\n\t\t\t\tif (l2cap_check_efs(chan)) {\n\t\t\t\t\tamp_create_logical_link(chan);\n\t\t\t\t\tchan->ident = cmd->ident;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tgoto done;\n\n\tcase L2CAP_CONF_UNACCEPT:\n\t\tif (chan->num_conf_rsp <= L2CAP_CONF_MAX_CONF_RSP) {\n\t\t\tchar req[64];\n\n\t\t\tif (len > sizeof(req) - sizeof(struct l2cap_conf_req)) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* throw out any old stored conf requests */\n\t\t\tresult = L2CAP_CONF_SUCCESS;\n\t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n\t\t\t\t\t\t   req, &result);\n\t\t\tif (len < 0) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn),\n\t\t\t\t       L2CAP_CONF_REQ, len, req);\n\t\t\tchan->num_conf_req++;\n\t\t\tif (result != L2CAP_CONF_SUCCESS)\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\t}\n\n\tdefault:\n\t\tl2cap_chan_set_err(chan, ECONNRESET);\n\n\t\t__set_chan_timer(chan, L2CAP_DISC_REJ_TIMEOUT);\n\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\tgoto done;\n\t}\n\n\tif (flags & L2CAP_CONF_FLAG_CONTINUATION)\n\t\tgoto done;\n\n\tset_bit(CONF_INPUT_DONE, &chan->conf_state);\n\n\tif (test_bit(CONF_OUTPUT_DONE, &chan->conf_state)) {\n\t\tset_default_fcs(chan);\n\n\t\tif (chan->mode == L2CAP_MODE_ERTM ||\n\t\t    chan->mode == L2CAP_MODE_STREAMING)\n\t\t\terr = l2cap_ertm_init(chan);\n\n\t\tif (err < 0)\n\t\t\tl2cap_send_disconn_req(chan, -err);\n\t\telse\n\t\t\tl2cap_chan_ready(chan);\n\t}\n\ndone:\n\tl2cap_chan_unlock(chan);\n\treturn err;\n}",
        "code_after_change": "static inline int l2cap_config_rsp(struct l2cap_conn *conn,\n\t\t\t\t   struct l2cap_cmd_hdr *cmd, u16 cmd_len,\n\t\t\t\t   u8 *data)\n{\n\tstruct l2cap_conf_rsp *rsp = (struct l2cap_conf_rsp *)data;\n\tu16 scid, flags, result;\n\tstruct l2cap_chan *chan;\n\tint len = cmd_len - sizeof(*rsp);\n\tint err = 0;\n\n\tif (cmd_len < sizeof(*rsp))\n\t\treturn -EPROTO;\n\n\tscid   = __le16_to_cpu(rsp->scid);\n\tflags  = __le16_to_cpu(rsp->flags);\n\tresult = __le16_to_cpu(rsp->result);\n\n\tBT_DBG(\"scid 0x%4.4x flags 0x%2.2x result 0x%2.2x len %d\", scid, flags,\n\t       result, len);\n\n\tchan = l2cap_get_chan_by_scid(conn, scid);\n\tif (!chan)\n\t\treturn 0;\n\n\tswitch (result) {\n\tcase L2CAP_CONF_SUCCESS:\n\t\tl2cap_conf_rfc_get(chan, rsp->data, len);\n\t\tclear_bit(CONF_REM_CONF_PEND, &chan->conf_state);\n\t\tbreak;\n\n\tcase L2CAP_CONF_PENDING:\n\t\tset_bit(CONF_REM_CONF_PEND, &chan->conf_state);\n\n\t\tif (test_bit(CONF_LOC_CONF_PEND, &chan->conf_state)) {\n\t\t\tchar buf[64];\n\n\t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n\t\t\t\t\t\t   buf, sizeof(buf), &result);\n\t\t\tif (len < 0) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tif (!chan->hs_hcon) {\n\t\t\t\tl2cap_send_efs_conf_rsp(chan, buf, cmd->ident,\n\t\t\t\t\t\t\t0);\n\t\t\t} else {\n\t\t\t\tif (l2cap_check_efs(chan)) {\n\t\t\t\t\tamp_create_logical_link(chan);\n\t\t\t\t\tchan->ident = cmd->ident;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tgoto done;\n\n\tcase L2CAP_CONF_UNACCEPT:\n\t\tif (chan->num_conf_rsp <= L2CAP_CONF_MAX_CONF_RSP) {\n\t\t\tchar req[64];\n\n\t\t\tif (len > sizeof(req) - sizeof(struct l2cap_conf_req)) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* throw out any old stored conf requests */\n\t\t\tresult = L2CAP_CONF_SUCCESS;\n\t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n\t\t\t\t\t\t   req, sizeof(req), &result);\n\t\t\tif (len < 0) {\n\t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn),\n\t\t\t\t       L2CAP_CONF_REQ, len, req);\n\t\t\tchan->num_conf_req++;\n\t\t\tif (result != L2CAP_CONF_SUCCESS)\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\t}\n\n\tdefault:\n\t\tl2cap_chan_set_err(chan, ECONNRESET);\n\n\t\t__set_chan_timer(chan, L2CAP_DISC_REJ_TIMEOUT);\n\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n\t\tgoto done;\n\t}\n\n\tif (flags & L2CAP_CONF_FLAG_CONTINUATION)\n\t\tgoto done;\n\n\tset_bit(CONF_INPUT_DONE, &chan->conf_state);\n\n\tif (test_bit(CONF_OUTPUT_DONE, &chan->conf_state)) {\n\t\tset_default_fcs(chan);\n\n\t\tif (chan->mode == L2CAP_MODE_ERTM ||\n\t\t    chan->mode == L2CAP_MODE_STREAMING)\n\t\t\terr = l2cap_ertm_init(chan);\n\n\t\tif (err < 0)\n\t\t\tl2cap_send_disconn_req(chan, -err);\n\t\telse\n\t\t\tl2cap_chan_ready(chan);\n\t}\n\ndone:\n\tl2cap_chan_unlock(chan);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,7 +35,7 @@\n \t\t\tchar buf[64];\n \n \t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n-\t\t\t\t\t\t   buf, &result);\n+\t\t\t\t\t\t   buf, sizeof(buf), &result);\n \t\t\tif (len < 0) {\n \t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n \t\t\t\tgoto done;\n@@ -65,7 +65,7 @@\n \t\t\t/* throw out any old stored conf requests */\n \t\t\tresult = L2CAP_CONF_SUCCESS;\n \t\t\tlen = l2cap_parse_conf_rsp(chan, rsp->data, len,\n-\t\t\t\t\t\t   req, &result);\n+\t\t\t\t\t\t   req, sizeof(req), &result);\n \t\t\tif (len < 0) {\n \t\t\t\tl2cap_send_disconn_req(chan, ECONNRESET);\n \t\t\t\tgoto done;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t\t   buf, sizeof(buf), &result);",
                "\t\t\t\t\t\t   req, sizeof(req), &result);"
            ],
            "deleted": [
                "\t\t\t\t\t\t   buf, &result);",
                "\t\t\t\t\t\t   req, &result);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static void l2cap_do_create(struct l2cap_chan *chan, int result,\n\t\t\t    u8 local_amp_id, u8 remote_amp_id)\n{\n\tBT_DBG(\"chan %p state %s %u -> %u\", chan, state_to_string(chan->state),\n\t       local_amp_id, remote_amp_id);\n\n\tchan->fcs = L2CAP_FCS_NONE;\n\n\t/* Outgoing channel on AMP */\n\tif (chan->state == BT_CONNECT) {\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\tchan->local_amp_id = local_amp_id;\n\t\t\tl2cap_send_create_chan_req(chan, remote_amp_id);\n\t\t} else {\n\t\t\t/* Revert to BR/EDR connect */\n\t\t\tl2cap_send_conn_req(chan);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/* Incoming channel on AMP */\n\tif (__l2cap_no_conn_pending(chan)) {\n\t\tstruct l2cap_conn_rsp rsp;\n\t\tchar buf[128];\n\t\trsp.scid = cpu_to_le16(chan->dcid);\n\t\trsp.dcid = cpu_to_le16(chan->scid);\n\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\t/* Send successful response */\n\t\t\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t} else {\n\t\t\t/* Send negative response */\n\t\t\trsp.result = cpu_to_le16(L2CAP_CR_NO_MEM);\n\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t}\n\n\t\tl2cap_send_cmd(chan->conn, chan->ident, L2CAP_CREATE_CHAN_RSP,\n\t\t\t       sizeof(rsp), &rsp);\n\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\tl2cap_send_cmd(chan->conn, l2cap_get_ident(chan->conn),\n\t\t\t\t       L2CAP_CONF_REQ,\n\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n\t\t\tchan->num_conf_req++;\n\t\t}\n\t}\n}",
        "code_after_change": "static void l2cap_do_create(struct l2cap_chan *chan, int result,\n\t\t\t    u8 local_amp_id, u8 remote_amp_id)\n{\n\tBT_DBG(\"chan %p state %s %u -> %u\", chan, state_to_string(chan->state),\n\t       local_amp_id, remote_amp_id);\n\n\tchan->fcs = L2CAP_FCS_NONE;\n\n\t/* Outgoing channel on AMP */\n\tif (chan->state == BT_CONNECT) {\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\tchan->local_amp_id = local_amp_id;\n\t\t\tl2cap_send_create_chan_req(chan, remote_amp_id);\n\t\t} else {\n\t\t\t/* Revert to BR/EDR connect */\n\t\t\tl2cap_send_conn_req(chan);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/* Incoming channel on AMP */\n\tif (__l2cap_no_conn_pending(chan)) {\n\t\tstruct l2cap_conn_rsp rsp;\n\t\tchar buf[128];\n\t\trsp.scid = cpu_to_le16(chan->dcid);\n\t\trsp.dcid = cpu_to_le16(chan->scid);\n\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\t/* Send successful response */\n\t\t\trsp.result = cpu_to_le16(L2CAP_CR_SUCCESS);\n\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t} else {\n\t\t\t/* Send negative response */\n\t\t\trsp.result = cpu_to_le16(L2CAP_CR_NO_MEM);\n\t\t\trsp.status = cpu_to_le16(L2CAP_CS_NO_INFO);\n\t\t}\n\n\t\tl2cap_send_cmd(chan->conn, chan->ident, L2CAP_CREATE_CHAN_RSP,\n\t\t\t       sizeof(rsp), &rsp);\n\n\t\tif (result == L2CAP_CR_SUCCESS) {\n\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\tl2cap_send_cmd(chan->conn, l2cap_get_ident(chan->conn),\n\t\t\t\t       L2CAP_CONF_REQ,\n\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n\t\t\tchan->num_conf_req++;\n\t\t}\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -44,7 +44,7 @@\n \t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n \t\t\tl2cap_send_cmd(chan->conn, l2cap_get_ident(chan->conn),\n \t\t\t\t       L2CAP_CONF_REQ,\n-\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);\n+\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);\n \t\t\tchan->num_conf_req++;\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)), buf);"
            ],
            "deleted": [
                "\t\t\t\t       l2cap_build_conf_req(chan, buf), buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000251",
        "code_before_change": "static void l2cap_security_cfm(struct hci_conn *hcon, u8 status, u8 encrypt)\n{\n\tstruct l2cap_conn *conn = hcon->l2cap_data;\n\tstruct l2cap_chan *chan;\n\n\tif (!conn)\n\t\treturn;\n\n\tBT_DBG(\"conn %p status 0x%2.2x encrypt %u\", conn, status, encrypt);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tlist_for_each_entry(chan, &conn->chan_l, list) {\n\t\tl2cap_chan_lock(chan);\n\n\t\tBT_DBG(\"chan %p scid 0x%4.4x state %s\", chan, chan->scid,\n\t\t       state_to_string(chan->state));\n\n\t\tif (chan->scid == L2CAP_CID_A2MP) {\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!status && encrypt)\n\t\t\tchan->sec_level = hcon->sec_level;\n\n\t\tif (!__l2cap_no_conn_pending(chan)) {\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!status && (chan->state == BT_CONNECTED ||\n\t\t\t\tchan->state == BT_CONFIG)) {\n\t\t\tchan->ops->resume(chan);\n\t\t\tl2cap_check_encryption(chan, encrypt);\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (chan->state == BT_CONNECT) {\n\t\t\tif (!status)\n\t\t\t\tl2cap_start_connection(chan);\n\t\t\telse\n\t\t\t\t__set_chan_timer(chan, L2CAP_DISC_TIMEOUT);\n\t\t} else if (chan->state == BT_CONNECT2 &&\n\t\t\t   chan->mode != L2CAP_MODE_LE_FLOWCTL) {\n\t\t\tstruct l2cap_conn_rsp rsp;\n\t\t\t__u16 res, stat;\n\n\t\t\tif (!status) {\n\t\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\t\tres = L2CAP_CR_PEND;\n\t\t\t\t\tstat = L2CAP_CS_AUTHOR_PEND;\n\t\t\t\t\tchan->ops->defer(chan);\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\tres = L2CAP_CR_SUCCESS;\n\t\t\t\t\tstat = L2CAP_CS_NO_INFO;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tl2cap_state_change(chan, BT_DISCONN);\n\t\t\t\t__set_chan_timer(chan, L2CAP_DISC_TIMEOUT);\n\t\t\t\tres = L2CAP_CR_SEC_BLOCK;\n\t\t\t\tstat = L2CAP_CS_NO_INFO;\n\t\t\t}\n\n\t\t\trsp.scid   = cpu_to_le16(chan->dcid);\n\t\t\trsp.dcid   = cpu_to_le16(chan->scid);\n\t\t\trsp.result = cpu_to_le16(res);\n\t\t\trsp.status = cpu_to_le16(stat);\n\t\t\tl2cap_send_cmd(conn, chan->ident, L2CAP_CONN_RSP,\n\t\t\t\t       sizeof(rsp), &rsp);\n\n\t\t\tif (!test_bit(CONF_REQ_SENT, &chan->conf_state) &&\n\t\t\t    res == L2CAP_CR_SUCCESS) {\n\t\t\t\tchar buf[128];\n\t\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn),\n\t\t\t\t\t       L2CAP_CONF_REQ,\n\t\t\t\t\t       l2cap_build_conf_req(chan, buf),\n\t\t\t\t\t       buf);\n\t\t\t\tchan->num_conf_req++;\n\t\t\t}\n\t\t}\n\n\t\tl2cap_chan_unlock(chan);\n\t}\n\n\tmutex_unlock(&conn->chan_lock);\n}",
        "code_after_change": "static void l2cap_security_cfm(struct hci_conn *hcon, u8 status, u8 encrypt)\n{\n\tstruct l2cap_conn *conn = hcon->l2cap_data;\n\tstruct l2cap_chan *chan;\n\n\tif (!conn)\n\t\treturn;\n\n\tBT_DBG(\"conn %p status 0x%2.2x encrypt %u\", conn, status, encrypt);\n\n\tmutex_lock(&conn->chan_lock);\n\n\tlist_for_each_entry(chan, &conn->chan_l, list) {\n\t\tl2cap_chan_lock(chan);\n\n\t\tBT_DBG(\"chan %p scid 0x%4.4x state %s\", chan, chan->scid,\n\t\t       state_to_string(chan->state));\n\n\t\tif (chan->scid == L2CAP_CID_A2MP) {\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!status && encrypt)\n\t\t\tchan->sec_level = hcon->sec_level;\n\n\t\tif (!__l2cap_no_conn_pending(chan)) {\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!status && (chan->state == BT_CONNECTED ||\n\t\t\t\tchan->state == BT_CONFIG)) {\n\t\t\tchan->ops->resume(chan);\n\t\t\tl2cap_check_encryption(chan, encrypt);\n\t\t\tl2cap_chan_unlock(chan);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (chan->state == BT_CONNECT) {\n\t\t\tif (!status)\n\t\t\t\tl2cap_start_connection(chan);\n\t\t\telse\n\t\t\t\t__set_chan_timer(chan, L2CAP_DISC_TIMEOUT);\n\t\t} else if (chan->state == BT_CONNECT2 &&\n\t\t\t   chan->mode != L2CAP_MODE_LE_FLOWCTL) {\n\t\t\tstruct l2cap_conn_rsp rsp;\n\t\t\t__u16 res, stat;\n\n\t\t\tif (!status) {\n\t\t\t\tif (test_bit(FLAG_DEFER_SETUP, &chan->flags)) {\n\t\t\t\t\tres = L2CAP_CR_PEND;\n\t\t\t\t\tstat = L2CAP_CS_AUTHOR_PEND;\n\t\t\t\t\tchan->ops->defer(chan);\n\t\t\t\t} else {\n\t\t\t\t\tl2cap_state_change(chan, BT_CONFIG);\n\t\t\t\t\tres = L2CAP_CR_SUCCESS;\n\t\t\t\t\tstat = L2CAP_CS_NO_INFO;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tl2cap_state_change(chan, BT_DISCONN);\n\t\t\t\t__set_chan_timer(chan, L2CAP_DISC_TIMEOUT);\n\t\t\t\tres = L2CAP_CR_SEC_BLOCK;\n\t\t\t\tstat = L2CAP_CS_NO_INFO;\n\t\t\t}\n\n\t\t\trsp.scid   = cpu_to_le16(chan->dcid);\n\t\t\trsp.dcid   = cpu_to_le16(chan->scid);\n\t\t\trsp.result = cpu_to_le16(res);\n\t\t\trsp.status = cpu_to_le16(stat);\n\t\t\tl2cap_send_cmd(conn, chan->ident, L2CAP_CONN_RSP,\n\t\t\t\t       sizeof(rsp), &rsp);\n\n\t\t\tif (!test_bit(CONF_REQ_SENT, &chan->conf_state) &&\n\t\t\t    res == L2CAP_CR_SUCCESS) {\n\t\t\t\tchar buf[128];\n\t\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n\t\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn),\n\t\t\t\t\t       L2CAP_CONF_REQ,\n\t\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)),\n\t\t\t\t\t       buf);\n\t\t\t\tchan->num_conf_req++;\n\t\t\t}\n\t\t}\n\n\t\tl2cap_chan_unlock(chan);\n\t}\n\n\tmutex_unlock(&conn->chan_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -77,7 +77,7 @@\n \t\t\t\tset_bit(CONF_REQ_SENT, &chan->conf_state);\n \t\t\t\tl2cap_send_cmd(conn, l2cap_get_ident(conn),\n \t\t\t\t\t       L2CAP_CONF_REQ,\n-\t\t\t\t\t       l2cap_build_conf_req(chan, buf),\n+\t\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)),\n \t\t\t\t\t       buf);\n \t\t\t\tchan->num_conf_req++;\n \t\t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t       l2cap_build_conf_req(chan, buf, sizeof(buf)),"
            ],
            "deleted": [
                "\t\t\t\t\t       l2cap_build_conf_req(chan, buf),"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The native Bluetooth stack in the Linux Kernel (BlueZ), starting at the Linux kernel version 2.6.32 and up to and including 4.13.1, are vulnerable to a stack overflow vulnerability in the processing of L2CAP configuration responses resulting in Remote code execution in kernel space."
    },
    {
        "cve_id": "CVE-2017-1000363",
        "code_before_change": "static int __init lp_setup (char *str)\n{\n\tstatic int parport_ptr;\n\tint x;\n\n\tif (get_option(&str, &x)) {\n\t\tif (x == 0) {\n\t\t\t/* disable driver on \"lp=\" or \"lp=0\" */\n\t\t\tparport_nr[0] = LP_PARPORT_OFF;\n\t\t} else {\n\t\t\tprintk(KERN_WARNING \"warning: 'lp=0x%x' is deprecated, ignored\\n\", x);\n\t\t\treturn 0;\n\t\t}\n\t} else if (!strncmp(str, \"parport\", 7)) {\n\t\tint n = simple_strtoul(str+7, NULL, 10);\n\t\tif (parport_ptr < LP_NO)\n\t\t\tparport_nr[parport_ptr++] = n;\n\t\telse\n\t\t\tprintk(KERN_INFO \"lp: too many ports, %s ignored.\\n\",\n\t\t\t       str);\n\t} else if (!strcmp(str, \"auto\")) {\n\t\tparport_nr[0] = LP_PARPORT_AUTO;\n\t} else if (!strcmp(str, \"none\")) {\n\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;\n\t} else if (!strcmp(str, \"reset\")) {\n\t\treset = 1;\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int __init lp_setup (char *str)\n{\n\tstatic int parport_ptr;\n\tint x;\n\n\tif (get_option(&str, &x)) {\n\t\tif (x == 0) {\n\t\t\t/* disable driver on \"lp=\" or \"lp=0\" */\n\t\t\tparport_nr[0] = LP_PARPORT_OFF;\n\t\t} else {\n\t\t\tprintk(KERN_WARNING \"warning: 'lp=0x%x' is deprecated, ignored\\n\", x);\n\t\t\treturn 0;\n\t\t}\n\t} else if (!strncmp(str, \"parport\", 7)) {\n\t\tint n = simple_strtoul(str+7, NULL, 10);\n\t\tif (parport_ptr < LP_NO)\n\t\t\tparport_nr[parport_ptr++] = n;\n\t\telse\n\t\t\tprintk(KERN_INFO \"lp: too many ports, %s ignored.\\n\",\n\t\t\t       str);\n\t} else if (!strcmp(str, \"auto\")) {\n\t\tparport_nr[0] = LP_PARPORT_AUTO;\n\t} else if (!strcmp(str, \"none\")) {\n\t\tif (parport_ptr < LP_NO)\n\t\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;\n\t\telse\n\t\t\tprintk(KERN_INFO \"lp: too many ports, %s ignored.\\n\",\n\t\t\t       str);\n\t} else if (!strcmp(str, \"reset\")) {\n\t\treset = 1;\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,7 +21,11 @@\n \t} else if (!strcmp(str, \"auto\")) {\n \t\tparport_nr[0] = LP_PARPORT_AUTO;\n \t} else if (!strcmp(str, \"none\")) {\n-\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;\n+\t\tif (parport_ptr < LP_NO)\n+\t\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;\n+\t\telse\n+\t\t\tprintk(KERN_INFO \"lp: too many ports, %s ignored.\\n\",\n+\t\t\t       str);\n \t} else if (!strcmp(str, \"reset\")) {\n \t\treset = 1;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (parport_ptr < LP_NO)",
                "\t\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;",
                "\t\telse",
                "\t\t\tprintk(KERN_INFO \"lp: too many ports, %s ignored.\\n\",",
                "\t\t\t       str);"
            ],
            "deleted": [
                "\t\tparport_nr[parport_ptr++] = LP_PARPORT_NONE;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Linux drivers/char/lp.c Out-of-Bounds Write. Due to a missing bounds check, and the fact that parport_ptr integer is static, a 'secure boot' kernel command line adversary (can happen due to bootloader vulns, e.g. Google Nexus 6's CVE-2016-10277, where due to a vulnerability the adversary has partial control over the command line) can overflow the parport_nr array in the following code, by appending many (>LP_NO) 'lp=none' arguments to the command line."
    },
    {
        "cve_id": "CVE-2017-13166",
        "code_before_change": "static int v4l_try_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tstruct video_device *vfd = video_devdata(file);\n\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n\tint ret;\n\n\tv4l_sanitize_format(p);\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_try_fmt_vid_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_try_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_try_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_try_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_try_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_try_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_try_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_try_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_try_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_try_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_try_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_try_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_try_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_try_fmt_sdr_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_try_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_meta_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n\t\treturn ops->vidioc_try_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "code_after_change": "static int v4l_try_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tint ret = check_fmt(file, p->type);\n\n\tif (ret)\n\t\treturn ret;\n\n\tv4l_sanitize_format(p);\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_try_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_try_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_try_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_try_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_try_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_try_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_try_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_try_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_try_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_try_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_try_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_try_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_try_fmt_meta_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n\t\treturn ops->vidioc_try_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,19 +2,16 @@\n \t\t\t\tstruct file *file, void *fh, void *arg)\n {\n \tstruct v4l2_format *p = arg;\n-\tstruct video_device *vfd = video_devdata(file);\n-\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n-\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n-\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n-\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n-\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n-\tint ret;\n+\tint ret = check_fmt(file, p->type);\n+\n+\tif (ret)\n+\t\treturn ret;\n \n \tv4l_sanitize_format(p);\n \n \tswitch (p->type) {\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n-\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_try_fmt_vid_cap))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n \t\tret = ops->vidioc_try_fmt_vid_cap(file, fh, arg);\n@@ -22,27 +19,27 @@\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_cap_mplane))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap_mplane))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n \t\treturn ops->vidioc_try_fmt_vid_cap_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_overlay))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_overlay))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.win);\n \t\treturn ops->vidioc_try_fmt_vid_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_vbi_cap))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n \t\treturn ops->vidioc_try_fmt_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_cap))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n \t\treturn ops->vidioc_try_fmt_sliced_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n \t\tret = ops->vidioc_try_fmt_vid_out(file, fh, arg);\n@@ -50,37 +47,37 @@\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_mplane))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_mplane))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n \t\treturn ops->vidioc_try_fmt_vid_out_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_overlay))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_overlay))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.win);\n \t\treturn ops->vidioc_try_fmt_vid_out_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_vbi_out))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n \t\treturn ops->vidioc_try_fmt_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_out))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n \t\treturn ops->vidioc_try_fmt_sliced_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_try_fmt_sdr_cap))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n \t\treturn ops->vidioc_try_fmt_sdr_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_try_fmt_sdr_out))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n \t\treturn ops->vidioc_try_fmt_sdr_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_META_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_meta_cap))\n+\t\tif (unlikely(!ops->vidioc_try_fmt_meta_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n \t\treturn ops->vidioc_try_fmt_meta_cap(file, fh, arg);",
        "function_modified_lines": {
            "added": [
                "\tint ret = check_fmt(file, p->type);",
                "",
                "\tif (ret)",
                "\t\treturn ret;",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_overlay))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_cap))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_cap))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vid_out_overlay))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_vbi_out))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_sliced_vbi_out))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_cap))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_sdr_out))",
                "\t\tif (unlikely(!ops->vidioc_try_fmt_meta_cap))"
            ],
            "deleted": [
                "\tstruct video_device *vfd = video_devdata(file);",
                "\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;",
                "\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;",
                "\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;",
                "\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;",
                "\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;",
                "\tint ret;",
                "\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_try_fmt_vid_cap))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_vid_overlay))",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_vbi_cap))",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_cap))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_try_fmt_vid_out_overlay))",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_vbi_out))",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_try_fmt_sliced_vbi_out))",
                "\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_try_fmt_sdr_cap))",
                "\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_try_fmt_sdr_out))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_try_fmt_meta_cap))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An elevation of privilege vulnerability in the kernel v4l2 video driver. Product: Android. Versions: Android kernel. Android ID A-34624167."
    },
    {
        "cve_id": "CVE-2017-13166",
        "code_before_change": "static int v4l_enum_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_fmtdesc *p = arg;\n\tstruct video_device *vfd = video_devdata(file);\n\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n\tint ret = -EINVAL;\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_enum_fmt_vid_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_cap(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_cap_mplane(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_overlay(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_out(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_out_mplane(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_enum_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_sdr_cap(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_enum_fmt_sdr_out))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_sdr_out(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_meta_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_meta_cap(file, fh, arg);\n\t\tbreak;\n\t}\n\tif (ret == 0)\n\t\tv4l_fill_fmtdesc(p);\n\treturn ret;\n}",
        "code_after_change": "static int v4l_enum_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_fmtdesc *p = arg;\n\tint ret = check_fmt(file, p->type);\n\n\tif (ret)\n\t\treturn ret;\n\tret = -EINVAL;\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_cap(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_cap_mplane(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_overlay(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_out(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_vid_out_mplane(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_sdr_cap(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_out))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_sdr_out(file, fh, arg);\n\t\tbreak;\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_enum_fmt_meta_cap))\n\t\t\tbreak;\n\t\tret = ops->vidioc_enum_fmt_meta_cap(file, fh, arg);\n\t\tbreak;\n\t}\n\tif (ret == 0)\n\t\tv4l_fill_fmtdesc(p);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,52 +2,50 @@\n \t\t\t\tstruct file *file, void *fh, void *arg)\n {\n \tstruct v4l2_fmtdesc *p = arg;\n-\tstruct video_device *vfd = video_devdata(file);\n-\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n-\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n-\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n-\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n-\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n-\tint ret = -EINVAL;\n+\tint ret = check_fmt(file, p->type);\n+\n+\tif (ret)\n+\t\treturn ret;\n+\tret = -EINVAL;\n \n \tswitch (p->type) {\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n-\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_enum_fmt_vid_cap))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_vid_cap(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_cap_mplane))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap_mplane))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_vid_cap_mplane(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_overlay))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_overlay))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_vid_overlay(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_vid_out(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out_mplane))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out_mplane))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_vid_out_mplane(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_enum_fmt_sdr_cap))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_cap))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_sdr_cap(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_enum_fmt_sdr_out))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_out))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_sdr_out(file, fh, arg);\n \t\tbreak;\n \tcase V4L2_BUF_TYPE_META_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_meta_cap))\n+\t\tif (unlikely(!ops->vidioc_enum_fmt_meta_cap))\n \t\t\tbreak;\n \t\tret = ops->vidioc_enum_fmt_meta_cap(file, fh, arg);\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\tint ret = check_fmt(file, p->type);",
                "",
                "\tif (ret)",
                "\t\treturn ret;",
                "\tret = -EINVAL;",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_overlay))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_cap))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_sdr_out))",
                "\t\tif (unlikely(!ops->vidioc_enum_fmt_meta_cap))"
            ],
            "deleted": [
                "\tstruct video_device *vfd = video_devdata(file);",
                "\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;",
                "\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;",
                "\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;",
                "\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;",
                "\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;",
                "\tint ret = -EINVAL;",
                "\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_enum_fmt_vid_cap))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_vid_overlay))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_enum_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_enum_fmt_sdr_cap))",
                "\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_enum_fmt_sdr_out))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_enum_fmt_meta_cap))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An elevation of privilege vulnerability in the kernel v4l2 video driver. Product: Android. Versions: Android kernel. Android ID A-34624167."
    },
    {
        "cve_id": "CVE-2017-13166",
        "code_before_change": "static int v4l_s_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tstruct video_device *vfd = video_devdata(file);\n\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n\tint ret;\n\n\tret = v4l_enable_media_source(vfd);\n\tif (ret)\n\t\treturn ret;\n\tv4l_sanitize_format(p);\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_s_fmt_vid_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_s_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tif (is_tch)\n\t\t\tv4l_pix_format_touch(&p->fmt.pix);\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_s_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_s_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_s_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_s_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_s_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_s_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_s_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_s_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_s_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_s_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_s_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_s_fmt_sdr_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_s_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_meta_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n\t\treturn ops->vidioc_s_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "code_after_change": "static int v4l_s_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tstruct video_device *vfd = video_devdata(file);\n\tint ret = check_fmt(file, p->type);\n\n\tif (ret)\n\t\treturn ret;\n\n\tret = v4l_enable_media_source(vfd);\n\tif (ret)\n\t\treturn ret;\n\tv4l_sanitize_format(p);\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_s_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tif (vfd->vfl_type == VFL_TYPE_TOUCH)\n\t\t\tv4l_pix_format_touch(&p->fmt.pix);\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_s_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_s_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_s_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_s_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n\t\tret = ops->vidioc_s_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n\t\treturn ops->vidioc_s_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_overlay))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.win);\n\t\treturn ops->vidioc_s_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n\t\treturn ops->vidioc_s_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n\t\treturn ops->vidioc_s_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_s_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_out))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n\t\treturn ops->vidioc_s_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_s_fmt_meta_cap))\n\t\t\tbreak;\n\t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n\t\treturn ops->vidioc_s_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,12 +3,10 @@\n {\n \tstruct v4l2_format *p = arg;\n \tstruct video_device *vfd = video_devdata(file);\n-\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n-\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n-\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n-\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n-\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n-\tint ret;\n+\tint ret = check_fmt(file, p->type);\n+\n+\tif (ret)\n+\t\treturn ret;\n \n \tret = v4l_enable_media_source(vfd);\n \tif (ret)\n@@ -17,37 +15,37 @@\n \n \tswitch (p->type) {\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n-\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_s_fmt_vid_cap))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n \t\tret = ops->vidioc_s_fmt_vid_cap(file, fh, arg);\n \t\t/* just in case the driver zeroed it again */\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n-\t\tif (is_tch)\n+\t\tif (vfd->vfl_type == VFL_TYPE_TOUCH)\n \t\t\tv4l_pix_format_touch(&p->fmt.pix);\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_cap_mplane))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap_mplane))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n \t\treturn ops->vidioc_s_fmt_vid_cap_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_overlay))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_overlay))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.win);\n \t\treturn ops->vidioc_s_fmt_vid_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_vbi_cap))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n \t\treturn ops->vidioc_s_fmt_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_cap))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n \t\treturn ops->vidioc_s_fmt_sliced_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix);\n \t\tret = ops->vidioc_s_fmt_vid_out(file, fh, arg);\n@@ -55,37 +53,37 @@\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_mplane))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_mplane))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.pix_mp.xfer_func);\n \t\treturn ops->vidioc_s_fmt_vid_out_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_overlay))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_overlay))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.win);\n \t\treturn ops->vidioc_s_fmt_vid_out_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_vbi_out))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.vbi);\n \t\treturn ops->vidioc_s_fmt_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_out))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sliced);\n \t\treturn ops->vidioc_s_fmt_sliced_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_s_fmt_sdr_cap))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n \t\treturn ops->vidioc_s_fmt_sdr_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_s_fmt_sdr_out))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_out))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.sdr);\n \t\treturn ops->vidioc_s_fmt_sdr_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_META_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_meta_cap))\n+\t\tif (unlikely(!ops->vidioc_s_fmt_meta_cap))\n \t\t\tbreak;\n \t\tCLEAR_AFTER_FIELD(p, fmt.meta);\n \t\treturn ops->vidioc_s_fmt_meta_cap(file, fh, arg);",
        "function_modified_lines": {
            "added": [
                "\tint ret = check_fmt(file, p->type);",
                "",
                "\tif (ret)",
                "\t\treturn ret;",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap))",
                "\t\tif (vfd->vfl_type == VFL_TYPE_TOUCH)",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_overlay))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_cap))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_cap))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vid_out_overlay))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_vbi_out))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_sliced_vbi_out))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_cap))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_sdr_out))",
                "\t\tif (unlikely(!ops->vidioc_s_fmt_meta_cap))"
            ],
            "deleted": [
                "\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;",
                "\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;",
                "\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;",
                "\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;",
                "\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;",
                "\tint ret;",
                "\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_s_fmt_vid_cap))",
                "\t\tif (is_tch)",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_cap_mplane))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_vid_overlay))",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_vbi_cap))",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_cap))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_mplane))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_s_fmt_vid_out_overlay))",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_vbi_out))",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_s_fmt_sliced_vbi_out))",
                "\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_s_fmt_sdr_cap))",
                "\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_s_fmt_sdr_out))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_s_fmt_meta_cap))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An elevation of privilege vulnerability in the kernel v4l2 video driver. Product: Android. Versions: Android kernel. Android ID A-34624167."
    },
    {
        "cve_id": "CVE-2017-13166",
        "code_before_change": "static int v4l_g_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tstruct video_device *vfd = video_devdata(file);\n\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n\tint ret;\n\n\t/*\n\t * fmt can't be cleared for these overlay types due to the 'clips'\n\t * 'clipcount' and 'bitmap' pointers in struct v4l2_window.\n\t * Those are provided by the user. So handle these two overlay types\n\t * first, and then just do a simple memset for the other types.\n\t */\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY: {\n\t\tstruct v4l2_clip __user *clips = p->fmt.win.clips;\n\t\tu32 clipcount = p->fmt.win.clipcount;\n\t\tvoid __user *bitmap = p->fmt.win.bitmap;\n\n\t\tmemset(&p->fmt, 0, sizeof(p->fmt));\n\t\tp->fmt.win.clips = clips;\n\t\tp->fmt.win.clipcount = clipcount;\n\t\tp->fmt.win.bitmap = bitmap;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tmemset(&p->fmt, 0, sizeof(p->fmt));\n\t\tbreak;\n\t}\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_g_fmt_vid_cap))\n\t\t\tbreak;\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tret = ops->vidioc_g_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_cap_mplane))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_overlay))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_vbi_cap))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_cap))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out))\n\t\t\tbreak;\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tret = ops->vidioc_g_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_mplane))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_overlay))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_vbi_out))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_out))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_g_fmt_sdr_cap))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_g_fmt_sdr_out))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_meta_cap))\n\t\t\tbreak;\n\t\treturn ops->vidioc_g_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "code_after_change": "static int v4l_g_fmt(const struct v4l2_ioctl_ops *ops,\n\t\t\t\tstruct file *file, void *fh, void *arg)\n{\n\tstruct v4l2_format *p = arg;\n\tint ret = check_fmt(file, p->type);\n\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * fmt can't be cleared for these overlay types due to the 'clips'\n\t * 'clipcount' and 'bitmap' pointers in struct v4l2_window.\n\t * Those are provided by the user. So handle these two overlay types\n\t * first, and then just do a simple memset for the other types.\n\t */\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY: {\n\t\tstruct v4l2_clip __user *clips = p->fmt.win.clips;\n\t\tu32 clipcount = p->fmt.win.clipcount;\n\t\tvoid __user *bitmap = p->fmt.win.bitmap;\n\n\t\tmemset(&p->fmt, 0, sizeof(p->fmt));\n\t\tp->fmt.win.clips = clips;\n\t\tp->fmt.win.clipcount = clipcount;\n\t\tp->fmt.win.bitmap = bitmap;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tmemset(&p->fmt, 0, sizeof(p->fmt));\n\t\tbreak;\n\t}\n\n\tswitch (p->type) {\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n\t\tif (unlikely(!ops->vidioc_g_fmt_vid_cap))\n\t\t\tbreak;\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tret = ops->vidioc_g_fmt_vid_cap(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n\t\treturn ops->vidioc_g_fmt_vid_cap_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n\t\treturn ops->vidioc_g_fmt_vid_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n\t\treturn ops->vidioc_g_fmt_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n\t\treturn ops->vidioc_g_fmt_sliced_vbi_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n\t\tif (unlikely(!ops->vidioc_g_fmt_vid_out))\n\t\t\tbreak;\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\tret = ops->vidioc_g_fmt_vid_out(file, fh, arg);\n\t\t/* just in case the driver zeroed it again */\n\t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n\t\treturn ret;\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n\t\treturn ops->vidioc_g_fmt_vid_out_mplane(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n\t\treturn ops->vidioc_g_fmt_vid_out_overlay(file, fh, arg);\n\tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n\t\treturn ops->vidioc_g_fmt_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n\t\treturn ops->vidioc_g_fmt_sliced_vbi_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n\t\treturn ops->vidioc_g_fmt_sdr_cap(file, fh, arg);\n\tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n\t\treturn ops->vidioc_g_fmt_sdr_out(file, fh, arg);\n\tcase V4L2_BUF_TYPE_META_CAPTURE:\n\t\treturn ops->vidioc_g_fmt_meta_cap(file, fh, arg);\n\t}\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,13 +2,10 @@\n \t\t\t\tstruct file *file, void *fh, void *arg)\n {\n \tstruct v4l2_format *p = arg;\n-\tstruct video_device *vfd = video_devdata(file);\n-\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;\n-\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;\n-\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;\n-\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;\n-\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;\n-\tint ret;\n+\tint ret = check_fmt(file, p->type);\n+\n+\tif (ret)\n+\t\treturn ret;\n \n \t/*\n \t * fmt can't be cleared for these overlay types due to the 'clips'\n@@ -36,7 +33,7 @@\n \n \tswitch (p->type) {\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE:\n-\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_g_fmt_vid_cap))\n+\t\tif (unlikely(!ops->vidioc_g_fmt_vid_cap))\n \t\t\tbreak;\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\tret = ops->vidioc_g_fmt_vid_cap(file, fh, arg);\n@@ -44,23 +41,15 @@\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_cap_mplane))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vid_cap_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OVERLAY:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_overlay))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vid_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_vbi_cap))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:\n-\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_cap))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_sliced_vbi_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out))\n+\t\tif (unlikely(!ops->vidioc_g_fmt_vid_out))\n \t\t\tbreak;\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\tret = ops->vidioc_g_fmt_vid_out(file, fh, arg);\n@@ -68,32 +57,18 @@\n \t\tp->fmt.pix.priv = V4L2_PIX_FMT_PRIV_MAGIC;\n \t\treturn ret;\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_mplane))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vid_out_mplane(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VIDEO_OUTPUT_OVERLAY:\n-\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_overlay))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vid_out_overlay(file, fh, arg);\n \tcase V4L2_BUF_TYPE_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_vbi_out))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:\n-\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_out))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_sliced_vbi_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_g_fmt_sdr_cap))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_sdr_cap(file, fh, arg);\n \tcase V4L2_BUF_TYPE_SDR_OUTPUT:\n-\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_g_fmt_sdr_out))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_sdr_out(file, fh, arg);\n \tcase V4L2_BUF_TYPE_META_CAPTURE:\n-\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_meta_cap))\n-\t\t\tbreak;\n \t\treturn ops->vidioc_g_fmt_meta_cap(file, fh, arg);\n \t}\n \treturn -EINVAL;",
        "function_modified_lines": {
            "added": [
                "\tint ret = check_fmt(file, p->type);",
                "",
                "\tif (ret)",
                "\t\treturn ret;",
                "\t\tif (unlikely(!ops->vidioc_g_fmt_vid_cap))",
                "\t\tif (unlikely(!ops->vidioc_g_fmt_vid_out))"
            ],
            "deleted": [
                "\tstruct video_device *vfd = video_devdata(file);",
                "\tbool is_vid = vfd->vfl_type == VFL_TYPE_GRABBER;",
                "\tbool is_sdr = vfd->vfl_type == VFL_TYPE_SDR;",
                "\tbool is_tch = vfd->vfl_type == VFL_TYPE_TOUCH;",
                "\tbool is_rx = vfd->vfl_dir != VFL_DIR_TX;",
                "\tbool is_tx = vfd->vfl_dir != VFL_DIR_RX;",
                "\tint ret;",
                "\t\tif (unlikely(!is_rx || (!is_vid && !is_tch) || !ops->vidioc_g_fmt_vid_cap))",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_cap_mplane))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_vid_overlay))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_vbi_cap))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_rx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_cap))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out))",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_mplane))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_tx || !is_vid || !ops->vidioc_g_fmt_vid_out_overlay))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_vbi_out))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_tx || is_vid || !ops->vidioc_g_fmt_sliced_vbi_out))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_rx || !is_sdr || !ops->vidioc_g_fmt_sdr_cap))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_tx || !is_sdr || !ops->vidioc_g_fmt_sdr_out))",
                "\t\t\tbreak;",
                "\t\tif (unlikely(!is_rx || !is_vid || !ops->vidioc_g_fmt_meta_cap))",
                "\t\t\tbreak;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An elevation of privilege vulnerability in the kernel v4l2 video driver. Product: Android. Versions: Android kernel. Android ID A-34624167."
    },
    {
        "cve_id": "CVE-2017-13216",
        "code_before_change": "static long ashmem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct ashmem_area *asma = file->private_data;\n\tlong ret = -ENOTTY;\n\n\tswitch (cmd) {\n\tcase ASHMEM_SET_NAME:\n\t\tret = set_name(asma, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_GET_NAME:\n\t\tret = get_name(asma, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_SET_SIZE:\n\t\tret = -EINVAL;\n\t\tif (!asma->file) {\n\t\t\tret = 0;\n\t\t\tasma->size = (size_t)arg;\n\t\t}\n\t\tbreak;\n\tcase ASHMEM_GET_SIZE:\n\t\tret = asma->size;\n\t\tbreak;\n\tcase ASHMEM_SET_PROT_MASK:\n\t\tret = set_prot_mask(asma, arg);\n\t\tbreak;\n\tcase ASHMEM_GET_PROT_MASK:\n\t\tret = asma->prot_mask;\n\t\tbreak;\n\tcase ASHMEM_PIN:\n\tcase ASHMEM_UNPIN:\n\tcase ASHMEM_GET_PIN_STATUS:\n\t\tret = ashmem_pin_unpin(asma, cmd, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_PURGE_ALL_CACHES:\n\t\tret = -EPERM;\n\t\tif (capable(CAP_SYS_ADMIN)) {\n\t\t\tstruct shrink_control sc = {\n\t\t\t\t.gfp_mask = GFP_KERNEL,\n\t\t\t\t.nr_to_scan = LONG_MAX,\n\t\t\t};\n\t\t\tret = ashmem_shrink_count(&ashmem_shrinker, &sc);\n\t\t\tashmem_shrink_scan(&ashmem_shrinker, &sc);\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static long ashmem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct ashmem_area *asma = file->private_data;\n\tlong ret = -ENOTTY;\n\n\tswitch (cmd) {\n\tcase ASHMEM_SET_NAME:\n\t\tret = set_name(asma, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_GET_NAME:\n\t\tret = get_name(asma, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_SET_SIZE:\n\t\tret = -EINVAL;\n\t\tmutex_lock(&ashmem_mutex);\n\t\tif (!asma->file) {\n\t\t\tret = 0;\n\t\t\tasma->size = (size_t)arg;\n\t\t}\n\t\tmutex_unlock(&ashmem_mutex);\n\t\tbreak;\n\tcase ASHMEM_GET_SIZE:\n\t\tret = asma->size;\n\t\tbreak;\n\tcase ASHMEM_SET_PROT_MASK:\n\t\tret = set_prot_mask(asma, arg);\n\t\tbreak;\n\tcase ASHMEM_GET_PROT_MASK:\n\t\tret = asma->prot_mask;\n\t\tbreak;\n\tcase ASHMEM_PIN:\n\tcase ASHMEM_UNPIN:\n\tcase ASHMEM_GET_PIN_STATUS:\n\t\tret = ashmem_pin_unpin(asma, cmd, (void __user *)arg);\n\t\tbreak;\n\tcase ASHMEM_PURGE_ALL_CACHES:\n\t\tret = -EPERM;\n\t\tif (capable(CAP_SYS_ADMIN)) {\n\t\t\tstruct shrink_control sc = {\n\t\t\t\t.gfp_mask = GFP_KERNEL,\n\t\t\t\t.nr_to_scan = LONG_MAX,\n\t\t\t};\n\t\t\tret = ashmem_shrink_count(&ashmem_shrinker, &sc);\n\t\t\tashmem_shrink_scan(&ashmem_shrinker, &sc);\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,10 +12,12 @@\n \t\tbreak;\n \tcase ASHMEM_SET_SIZE:\n \t\tret = -EINVAL;\n+\t\tmutex_lock(&ashmem_mutex);\n \t\tif (!asma->file) {\n \t\t\tret = 0;\n \t\t\tasma->size = (size_t)arg;\n \t\t}\n+\t\tmutex_unlock(&ashmem_mutex);\n \t\tbreak;\n \tcase ASHMEM_GET_SIZE:\n \t\tret = asma->size;",
        "function_modified_lines": {
            "added": [
                "\t\tmutex_lock(&ashmem_mutex);",
                "\t\tmutex_unlock(&ashmem_mutex);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In ashmem_ioctl of ashmem.c, there is an out-of-bounds write due to insufficient locking when accessing asma. This could lead to a local elevation of privilege enabling code execution as a privileged process with no additional execution privileges needed. User interaction is not needed for exploitation. Product: Android. Versions: Android kernel. Android ID: A-66954097."
    },
    {
        "cve_id": "CVE-2017-17558",
        "code_before_change": "static int usb_parse_configuration(struct usb_device *dev, int cfgidx,\n    struct usb_host_config *config, unsigned char *buffer, int size)\n{\n\tstruct device *ddev = &dev->dev;\n\tunsigned char *buffer0 = buffer;\n\tint cfgno;\n\tint nintf, nintf_orig;\n\tint i, j, n;\n\tstruct usb_interface_cache *intfc;\n\tunsigned char *buffer2;\n\tint size2;\n\tstruct usb_descriptor_header *header;\n\tint len, retval;\n\tu8 inums[USB_MAXINTERFACES], nalts[USB_MAXINTERFACES];\n\tunsigned iad_num = 0;\n\n\tmemcpy(&config->desc, buffer, USB_DT_CONFIG_SIZE);\n\tif (config->desc.bDescriptorType != USB_DT_CONFIG ||\n\t    config->desc.bLength < USB_DT_CONFIG_SIZE ||\n\t    config->desc.bLength > size) {\n\t\tdev_err(ddev, \"invalid descriptor for config index %d: \"\n\t\t    \"type = 0x%X, length = %d\\n\", cfgidx,\n\t\t    config->desc.bDescriptorType, config->desc.bLength);\n\t\treturn -EINVAL;\n\t}\n\tcfgno = config->desc.bConfigurationValue;\n\n\tbuffer += config->desc.bLength;\n\tsize -= config->desc.bLength;\n\n\tnintf = nintf_orig = config->desc.bNumInterfaces;\n\tif (nintf > USB_MAXINTERFACES) {\n\t\tdev_warn(ddev, \"config %d has too many interfaces: %d, \"\n\t\t    \"using maximum allowed: %d\\n\",\n\t\t    cfgno, nintf, USB_MAXINTERFACES);\n\t\tnintf = USB_MAXINTERFACES;\n\t}\n\n\t/* Go through the descriptors, checking their length and counting the\n\t * number of altsettings for each interface */\n\tn = 0;\n\tfor ((buffer2 = buffer, size2 = size);\n\t      size2 > 0;\n\t     (buffer2 += header->bLength, size2 -= header->bLength)) {\n\n\t\tif (size2 < sizeof(struct usb_descriptor_header)) {\n\t\t\tdev_warn(ddev, \"config %d descriptor has %d excess \"\n\t\t\t    \"byte%s, ignoring\\n\",\n\t\t\t    cfgno, size2, plural(size2));\n\t\t\tbreak;\n\t\t}\n\n\t\theader = (struct usb_descriptor_header *) buffer2;\n\t\tif ((header->bLength > size2) || (header->bLength < 2)) {\n\t\t\tdev_warn(ddev, \"config %d has an invalid descriptor \"\n\t\t\t    \"of length %d, skipping remainder of the config\\n\",\n\t\t\t    cfgno, header->bLength);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (header->bDescriptorType == USB_DT_INTERFACE) {\n\t\t\tstruct usb_interface_descriptor *d;\n\t\t\tint inum;\n\n\t\t\td = (struct usb_interface_descriptor *) header;\n\t\t\tif (d->bLength < USB_DT_INTERFACE_SIZE) {\n\t\t\t\tdev_warn(ddev, \"config %d has an invalid \"\n\t\t\t\t    \"interface descriptor of length %d, \"\n\t\t\t\t    \"skipping\\n\", cfgno, d->bLength);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tinum = d->bInterfaceNumber;\n\n\t\t\tif ((dev->quirks & USB_QUIRK_HONOR_BNUMINTERFACES) &&\n\t\t\t    n >= nintf_orig) {\n\t\t\t\tdev_warn(ddev, \"config %d has more interface \"\n\t\t\t\t    \"descriptors, than it declares in \"\n\t\t\t\t    \"bNumInterfaces, ignoring interface \"\n\t\t\t\t    \"number: %d\\n\", cfgno, inum);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (inum >= nintf_orig)\n\t\t\t\tdev_warn(ddev, \"config %d has an invalid \"\n\t\t\t\t    \"interface number: %d but max is %d\\n\",\n\t\t\t\t    cfgno, inum, nintf_orig - 1);\n\n\t\t\t/* Have we already encountered this interface?\n\t\t\t * Count its altsettings */\n\t\t\tfor (i = 0; i < n; ++i) {\n\t\t\t\tif (inums[i] == inum)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (i < n) {\n\t\t\t\tif (nalts[i] < 255)\n\t\t\t\t\t++nalts[i];\n\t\t\t} else if (n < USB_MAXINTERFACES) {\n\t\t\t\tinums[n] = inum;\n\t\t\t\tnalts[n] = 1;\n\t\t\t\t++n;\n\t\t\t}\n\n\t\t} else if (header->bDescriptorType ==\n\t\t\t\tUSB_DT_INTERFACE_ASSOCIATION) {\n\t\t\tstruct usb_interface_assoc_descriptor *d;\n\n\t\t\td = (struct usb_interface_assoc_descriptor *)header;\n\t\t\tif (d->bLength < USB_DT_INTERFACE_ASSOCIATION_SIZE) {\n\t\t\t\tdev_warn(ddev,\n\t\t\t\t\t \"config %d has an invalid interface association descriptor of length %d, skipping\\n\",\n\t\t\t\t\t cfgno, d->bLength);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (iad_num == USB_MAXIADS) {\n\t\t\t\tdev_warn(ddev, \"found more Interface \"\n\t\t\t\t\t       \"Association Descriptors \"\n\t\t\t\t\t       \"than allocated for in \"\n\t\t\t\t\t       \"configuration %d\\n\", cfgno);\n\t\t\t} else {\n\t\t\t\tconfig->intf_assoc[iad_num] = d;\n\t\t\t\tiad_num++;\n\t\t\t}\n\n\t\t} else if (header->bDescriptorType == USB_DT_DEVICE ||\n\t\t\t    header->bDescriptorType == USB_DT_CONFIG)\n\t\t\tdev_warn(ddev, \"config %d contains an unexpected \"\n\t\t\t    \"descriptor of type 0x%X, skipping\\n\",\n\t\t\t    cfgno, header->bDescriptorType);\n\n\t}\t/* for ((buffer2 = buffer, size2 = size); ...) */\n\tsize = buffer2 - buffer;\n\tconfig->desc.wTotalLength = cpu_to_le16(buffer2 - buffer0);\n\n\tif (n != nintf)\n\t\tdev_warn(ddev, \"config %d has %d interface%s, different from \"\n\t\t    \"the descriptor's value: %d\\n\",\n\t\t    cfgno, n, plural(n), nintf_orig);\n\telse if (n == 0)\n\t\tdev_warn(ddev, \"config %d has no interfaces?\\n\", cfgno);\n\tconfig->desc.bNumInterfaces = nintf = n;\n\n\t/* Check for missing interface numbers */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tfor (j = 0; j < nintf; ++j) {\n\t\t\tif (inums[j] == i)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (j >= nintf)\n\t\t\tdev_warn(ddev, \"config %d has no interface number \"\n\t\t\t    \"%d\\n\", cfgno, i);\n\t}\n\n\t/* Allocate the usb_interface_caches and altsetting arrays */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tj = nalts[i];\n\t\tif (j > USB_MAXALTSETTING) {\n\t\t\tdev_warn(ddev, \"too many alternate settings for \"\n\t\t\t    \"config %d interface %d: %d, \"\n\t\t\t    \"using maximum allowed: %d\\n\",\n\t\t\t    cfgno, inums[i], j, USB_MAXALTSETTING);\n\t\t\tnalts[i] = j = USB_MAXALTSETTING;\n\t\t}\n\n\t\tlen = sizeof(*intfc) + sizeof(struct usb_host_interface) * j;\n\t\tconfig->intf_cache[i] = intfc = kzalloc(len, GFP_KERNEL);\n\t\tif (!intfc)\n\t\t\treturn -ENOMEM;\n\t\tkref_init(&intfc->ref);\n\t}\n\n\t/* FIXME: parse the BOS descriptor */\n\n\t/* Skip over any Class Specific or Vendor Specific descriptors;\n\t * find the first interface descriptor */\n\tconfig->extra = buffer;\n\ti = find_next_descriptor(buffer, size, USB_DT_INTERFACE,\n\t    USB_DT_INTERFACE, &n);\n\tconfig->extralen = i;\n\tif (n > 0)\n\t\tdev_dbg(ddev, \"skipped %d descriptor%s after %s\\n\",\n\t\t    n, plural(n), \"configuration\");\n\tbuffer += i;\n\tsize -= i;\n\n\t/* Parse all the interface/altsetting descriptors */\n\twhile (size > 0) {\n\t\tretval = usb_parse_interface(ddev, cfgno, config,\n\t\t    buffer, size, inums, nalts);\n\t\tif (retval < 0)\n\t\t\treturn retval;\n\n\t\tbuffer += retval;\n\t\tsize -= retval;\n\t}\n\n\t/* Check for missing altsettings */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tintfc = config->intf_cache[i];\n\t\tfor (j = 0; j < intfc->num_altsetting; ++j) {\n\t\t\tfor (n = 0; n < intfc->num_altsetting; ++n) {\n\t\t\t\tif (intfc->altsetting[n].desc.\n\t\t\t\t    bAlternateSetting == j)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (n >= intfc->num_altsetting)\n\t\t\t\tdev_warn(ddev, \"config %d interface %d has no \"\n\t\t\t\t    \"altsetting %d\\n\", cfgno, inums[i], j);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int usb_parse_configuration(struct usb_device *dev, int cfgidx,\n    struct usb_host_config *config, unsigned char *buffer, int size)\n{\n\tstruct device *ddev = &dev->dev;\n\tunsigned char *buffer0 = buffer;\n\tint cfgno;\n\tint nintf, nintf_orig;\n\tint i, j, n;\n\tstruct usb_interface_cache *intfc;\n\tunsigned char *buffer2;\n\tint size2;\n\tstruct usb_descriptor_header *header;\n\tint len, retval;\n\tu8 inums[USB_MAXINTERFACES], nalts[USB_MAXINTERFACES];\n\tunsigned iad_num = 0;\n\n\tmemcpy(&config->desc, buffer, USB_DT_CONFIG_SIZE);\n\tnintf = nintf_orig = config->desc.bNumInterfaces;\n\tconfig->desc.bNumInterfaces = 0;\t// Adjusted later\n\n\tif (config->desc.bDescriptorType != USB_DT_CONFIG ||\n\t    config->desc.bLength < USB_DT_CONFIG_SIZE ||\n\t    config->desc.bLength > size) {\n\t\tdev_err(ddev, \"invalid descriptor for config index %d: \"\n\t\t    \"type = 0x%X, length = %d\\n\", cfgidx,\n\t\t    config->desc.bDescriptorType, config->desc.bLength);\n\t\treturn -EINVAL;\n\t}\n\tcfgno = config->desc.bConfigurationValue;\n\n\tbuffer += config->desc.bLength;\n\tsize -= config->desc.bLength;\n\n\tif (nintf > USB_MAXINTERFACES) {\n\t\tdev_warn(ddev, \"config %d has too many interfaces: %d, \"\n\t\t    \"using maximum allowed: %d\\n\",\n\t\t    cfgno, nintf, USB_MAXINTERFACES);\n\t\tnintf = USB_MAXINTERFACES;\n\t}\n\n\t/* Go through the descriptors, checking their length and counting the\n\t * number of altsettings for each interface */\n\tn = 0;\n\tfor ((buffer2 = buffer, size2 = size);\n\t      size2 > 0;\n\t     (buffer2 += header->bLength, size2 -= header->bLength)) {\n\n\t\tif (size2 < sizeof(struct usb_descriptor_header)) {\n\t\t\tdev_warn(ddev, \"config %d descriptor has %d excess \"\n\t\t\t    \"byte%s, ignoring\\n\",\n\t\t\t    cfgno, size2, plural(size2));\n\t\t\tbreak;\n\t\t}\n\n\t\theader = (struct usb_descriptor_header *) buffer2;\n\t\tif ((header->bLength > size2) || (header->bLength < 2)) {\n\t\t\tdev_warn(ddev, \"config %d has an invalid descriptor \"\n\t\t\t    \"of length %d, skipping remainder of the config\\n\",\n\t\t\t    cfgno, header->bLength);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (header->bDescriptorType == USB_DT_INTERFACE) {\n\t\t\tstruct usb_interface_descriptor *d;\n\t\t\tint inum;\n\n\t\t\td = (struct usb_interface_descriptor *) header;\n\t\t\tif (d->bLength < USB_DT_INTERFACE_SIZE) {\n\t\t\t\tdev_warn(ddev, \"config %d has an invalid \"\n\t\t\t\t    \"interface descriptor of length %d, \"\n\t\t\t\t    \"skipping\\n\", cfgno, d->bLength);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tinum = d->bInterfaceNumber;\n\n\t\t\tif ((dev->quirks & USB_QUIRK_HONOR_BNUMINTERFACES) &&\n\t\t\t    n >= nintf_orig) {\n\t\t\t\tdev_warn(ddev, \"config %d has more interface \"\n\t\t\t\t    \"descriptors, than it declares in \"\n\t\t\t\t    \"bNumInterfaces, ignoring interface \"\n\t\t\t\t    \"number: %d\\n\", cfgno, inum);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (inum >= nintf_orig)\n\t\t\t\tdev_warn(ddev, \"config %d has an invalid \"\n\t\t\t\t    \"interface number: %d but max is %d\\n\",\n\t\t\t\t    cfgno, inum, nintf_orig - 1);\n\n\t\t\t/* Have we already encountered this interface?\n\t\t\t * Count its altsettings */\n\t\t\tfor (i = 0; i < n; ++i) {\n\t\t\t\tif (inums[i] == inum)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (i < n) {\n\t\t\t\tif (nalts[i] < 255)\n\t\t\t\t\t++nalts[i];\n\t\t\t} else if (n < USB_MAXINTERFACES) {\n\t\t\t\tinums[n] = inum;\n\t\t\t\tnalts[n] = 1;\n\t\t\t\t++n;\n\t\t\t}\n\n\t\t} else if (header->bDescriptorType ==\n\t\t\t\tUSB_DT_INTERFACE_ASSOCIATION) {\n\t\t\tstruct usb_interface_assoc_descriptor *d;\n\n\t\t\td = (struct usb_interface_assoc_descriptor *)header;\n\t\t\tif (d->bLength < USB_DT_INTERFACE_ASSOCIATION_SIZE) {\n\t\t\t\tdev_warn(ddev,\n\t\t\t\t\t \"config %d has an invalid interface association descriptor of length %d, skipping\\n\",\n\t\t\t\t\t cfgno, d->bLength);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (iad_num == USB_MAXIADS) {\n\t\t\t\tdev_warn(ddev, \"found more Interface \"\n\t\t\t\t\t       \"Association Descriptors \"\n\t\t\t\t\t       \"than allocated for in \"\n\t\t\t\t\t       \"configuration %d\\n\", cfgno);\n\t\t\t} else {\n\t\t\t\tconfig->intf_assoc[iad_num] = d;\n\t\t\t\tiad_num++;\n\t\t\t}\n\n\t\t} else if (header->bDescriptorType == USB_DT_DEVICE ||\n\t\t\t    header->bDescriptorType == USB_DT_CONFIG)\n\t\t\tdev_warn(ddev, \"config %d contains an unexpected \"\n\t\t\t    \"descriptor of type 0x%X, skipping\\n\",\n\t\t\t    cfgno, header->bDescriptorType);\n\n\t}\t/* for ((buffer2 = buffer, size2 = size); ...) */\n\tsize = buffer2 - buffer;\n\tconfig->desc.wTotalLength = cpu_to_le16(buffer2 - buffer0);\n\n\tif (n != nintf)\n\t\tdev_warn(ddev, \"config %d has %d interface%s, different from \"\n\t\t    \"the descriptor's value: %d\\n\",\n\t\t    cfgno, n, plural(n), nintf_orig);\n\telse if (n == 0)\n\t\tdev_warn(ddev, \"config %d has no interfaces?\\n\", cfgno);\n\tconfig->desc.bNumInterfaces = nintf = n;\n\n\t/* Check for missing interface numbers */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tfor (j = 0; j < nintf; ++j) {\n\t\t\tif (inums[j] == i)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (j >= nintf)\n\t\t\tdev_warn(ddev, \"config %d has no interface number \"\n\t\t\t    \"%d\\n\", cfgno, i);\n\t}\n\n\t/* Allocate the usb_interface_caches and altsetting arrays */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tj = nalts[i];\n\t\tif (j > USB_MAXALTSETTING) {\n\t\t\tdev_warn(ddev, \"too many alternate settings for \"\n\t\t\t    \"config %d interface %d: %d, \"\n\t\t\t    \"using maximum allowed: %d\\n\",\n\t\t\t    cfgno, inums[i], j, USB_MAXALTSETTING);\n\t\t\tnalts[i] = j = USB_MAXALTSETTING;\n\t\t}\n\n\t\tlen = sizeof(*intfc) + sizeof(struct usb_host_interface) * j;\n\t\tconfig->intf_cache[i] = intfc = kzalloc(len, GFP_KERNEL);\n\t\tif (!intfc)\n\t\t\treturn -ENOMEM;\n\t\tkref_init(&intfc->ref);\n\t}\n\n\t/* FIXME: parse the BOS descriptor */\n\n\t/* Skip over any Class Specific or Vendor Specific descriptors;\n\t * find the first interface descriptor */\n\tconfig->extra = buffer;\n\ti = find_next_descriptor(buffer, size, USB_DT_INTERFACE,\n\t    USB_DT_INTERFACE, &n);\n\tconfig->extralen = i;\n\tif (n > 0)\n\t\tdev_dbg(ddev, \"skipped %d descriptor%s after %s\\n\",\n\t\t    n, plural(n), \"configuration\");\n\tbuffer += i;\n\tsize -= i;\n\n\t/* Parse all the interface/altsetting descriptors */\n\twhile (size > 0) {\n\t\tretval = usb_parse_interface(ddev, cfgno, config,\n\t\t    buffer, size, inums, nalts);\n\t\tif (retval < 0)\n\t\t\treturn retval;\n\n\t\tbuffer += retval;\n\t\tsize -= retval;\n\t}\n\n\t/* Check for missing altsettings */\n\tfor (i = 0; i < nintf; ++i) {\n\t\tintfc = config->intf_cache[i];\n\t\tfor (j = 0; j < intfc->num_altsetting; ++j) {\n\t\t\tfor (n = 0; n < intfc->num_altsetting; ++n) {\n\t\t\t\tif (intfc->altsetting[n].desc.\n\t\t\t\t    bAlternateSetting == j)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (n >= intfc->num_altsetting)\n\t\t\t\tdev_warn(ddev, \"config %d interface %d has no \"\n\t\t\t\t    \"altsetting %d\\n\", cfgno, inums[i], j);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,6 +15,9 @@\n \tunsigned iad_num = 0;\n \n \tmemcpy(&config->desc, buffer, USB_DT_CONFIG_SIZE);\n+\tnintf = nintf_orig = config->desc.bNumInterfaces;\n+\tconfig->desc.bNumInterfaces = 0;\t// Adjusted later\n+\n \tif (config->desc.bDescriptorType != USB_DT_CONFIG ||\n \t    config->desc.bLength < USB_DT_CONFIG_SIZE ||\n \t    config->desc.bLength > size) {\n@@ -28,7 +31,6 @@\n \tbuffer += config->desc.bLength;\n \tsize -= config->desc.bLength;\n \n-\tnintf = nintf_orig = config->desc.bNumInterfaces;\n \tif (nintf > USB_MAXINTERFACES) {\n \t\tdev_warn(ddev, \"config %d has too many interfaces: %d, \"\n \t\t    \"using maximum allowed: %d\\n\",",
        "function_modified_lines": {
            "added": [
                "\tnintf = nintf_orig = config->desc.bNumInterfaces;",
                "\tconfig->desc.bNumInterfaces = 0;\t// Adjusted later",
                ""
            ],
            "deleted": [
                "\tnintf = nintf_orig = config->desc.bNumInterfaces;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The usb_destroy_configuration function in drivers/usb/core/config.c in the USB core subsystem in the Linux kernel through 4.14.5 does not consider the maximum number of configurations and interfaces before attempting to release resources, which allows local users to cause a denial of service (out-of-bounds write access) or possibly have unspecified other impact via a crafted USB device."
    },
    {
        "cve_id": "CVE-2017-17806",
        "code_before_change": "static int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\n\terr = -EINVAL;\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\talg = &salg->base;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}",
        "code_after_change": "static int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\talg = &salg->base;\n\n\t/* The underlying hash algorithm must be unkeyed */\n\terr = -EINVAL;\n\tif (crypto_shash_alg_has_setkey(salg))\n\t\tgoto out_put_alg;\n\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,11 +14,15 @@\n \tsalg = shash_attr_alg(tb[1], 0, 0);\n \tif (IS_ERR(salg))\n \t\treturn PTR_ERR(salg);\n+\talg = &salg->base;\n \n+\t/* The underlying hash algorithm must be unkeyed */\n \terr = -EINVAL;\n+\tif (crypto_shash_alg_has_setkey(salg))\n+\t\tgoto out_put_alg;\n+\n \tds = salg->digestsize;\n \tss = salg->statesize;\n-\talg = &salg->base;\n \tif (ds > alg->cra_blocksize ||\n \t    ss < alg->cra_blocksize)\n \t\tgoto out_put_alg;",
        "function_modified_lines": {
            "added": [
                "\talg = &salg->base;",
                "\t/* The underlying hash algorithm must be unkeyed */",
                "\tif (crypto_shash_alg_has_setkey(salg))",
                "\t\tgoto out_put_alg;",
                ""
            ],
            "deleted": [
                "\talg = &salg->base;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The HMAC implementation (crypto/hmac.c) in the Linux kernel before 4.14.8 does not validate that the underlying cryptographic hash algorithm is unkeyed, allowing a local attacker able to use the AF_ALG-based hash interface (CONFIG_CRYPTO_USER_API_HASH) and the SHA-3 hash algorithm (CONFIG_CRYPTO_SHA3) to cause a kernel stack buffer overflow by executing a crafted sequence of system calls that encounter a missing SHA-3 initialization."
    },
    {
        "cve_id": "CVE-2017-17806",
        "code_before_change": "static int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\treturn -ENOSYS;\n}",
        "code_after_change": "int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n\t\t    unsigned int keylen)\n{\n\treturn -ENOSYS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,5 @@\n-static int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n-\t\t\t   unsigned int keylen)\n+int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,\n+\t\t    unsigned int keylen)\n {\n \treturn -ENOSYS;\n }",
        "function_modified_lines": {
            "added": [
                "int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,",
                "\t\t    unsigned int keylen)"
            ],
            "deleted": [
                "static int shash_no_setkey(struct crypto_shash *tfm, const u8 *key,",
                "\t\t\t   unsigned int keylen)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The HMAC implementation (crypto/hmac.c) in the Linux kernel before 4.14.8 does not validate that the underlying cryptographic hash algorithm is unkeyed, allowing a local attacker able to use the AF_ALG-based hash interface (CONFIG_CRYPTO_USER_API_HASH) and the SHA-3 hash algorithm (CONFIG_CRYPTO_SHA3) to cause a kernel stack buffer overflow by executing a crafted sequence of system calls that encounter a missing SHA-3 initialization."
    },
    {
        "cve_id": "CVE-2017-18551",
        "code_before_change": "static s32 i2c_smbus_xfer_emulated(struct i2c_adapter *adapter, u16 addr,\n\t\t\t\t   unsigned short flags,\n\t\t\t\t   char read_write, u8 command, int size,\n\t\t\t\t   union i2c_smbus_data *data)\n{\n\t/* So we need to generate a series of msgs. In the case of writing, we\n\t  need to use only one message; when reading, we need two. We initialize\n\t  most things with sane defaults, to keep the code below somewhat\n\t  simpler. */\n\tunsigned char msgbuf0[I2C_SMBUS_BLOCK_MAX+3];\n\tunsigned char msgbuf1[I2C_SMBUS_BLOCK_MAX+2];\n\tint num = read_write == I2C_SMBUS_READ ? 2 : 1;\n\tint i;\n\tu8 partial_pec = 0;\n\tint status;\n\tstruct i2c_msg msg[2] = {\n\t\t{\n\t\t\t.addr = addr,\n\t\t\t.flags = flags,\n\t\t\t.len = 1,\n\t\t\t.buf = msgbuf0,\n\t\t}, {\n\t\t\t.addr = addr,\n\t\t\t.flags = flags | I2C_M_RD,\n\t\t\t.len = 0,\n\t\t\t.buf = msgbuf1,\n\t\t},\n\t};\n\n\tmsgbuf0[0] = command;\n\tswitch (size) {\n\tcase I2C_SMBUS_QUICK:\n\t\tmsg[0].len = 0;\n\t\t/* Special case: The read/write field is used as data */\n\t\tmsg[0].flags = flags | (read_write == I2C_SMBUS_READ ?\n\t\t\t\t\tI2C_M_RD : 0);\n\t\tnum = 1;\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\t/* Special case: only a read! */\n\t\t\tmsg[0].flags = I2C_M_RD | flags;\n\t\t\tnum = 1;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 1;\n\t\telse {\n\t\t\tmsg[0].len = 2;\n\t\t\tmsgbuf0[1] = data->byte;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_WORD_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 2;\n\t\telse {\n\t\t\tmsg[0].len = 3;\n\t\t\tmsgbuf0[1] = data->word & 0xff;\n\t\t\tmsgbuf0[2] = data->word >> 8;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_PROC_CALL:\n\t\tnum = 2; /* Special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tmsg[0].len = 3;\n\t\tmsg[1].len = 2;\n\t\tmsgbuf0[1] = data->word & 0xff;\n\t\tmsgbuf0[2] = data->word >> 8;\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t\t   the underlying bus driver */\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 2;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 2) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\tnum = 2; /* Another special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmsg[0].len = data->block[0] + 2;\n\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t   the underlying bus driver */\n\t\tbreak;\n\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].len = data->block[0];\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 1;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i <= data->block[0]; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i];\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&adapter->dev, \"Unsupported transaction %d\\n\", size);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\ti = ((flags & I2C_CLIENT_PEC) && size != I2C_SMBUS_QUICK\n\t\t\t\t      && size != I2C_SMBUS_I2C_BLOCK_DATA);\n\tif (i) {\n\t\t/* Compute PEC if first message is a write */\n\t\tif (!(msg[0].flags & I2C_M_RD)) {\n\t\t\tif (num == 1) /* Write only */\n\t\t\t\ti2c_smbus_add_pec(&msg[0]);\n\t\t\telse /* Write followed by read */\n\t\t\t\tpartial_pec = i2c_smbus_msg_pec(0, &msg[0]);\n\t\t}\n\t\t/* Ask for PEC if last message is a read */\n\t\tif (msg[num-1].flags & I2C_M_RD)\n\t\t\tmsg[num-1].len++;\n\t}\n\n\tstatus = i2c_transfer(adapter, msg, num);\n\tif (status < 0)\n\t\treturn status;\n\n\t/* Check PEC if last message is a read */\n\tif (i && (msg[num-1].flags & I2C_M_RD)) {\n\t\tstatus = i2c_smbus_check_pec(partial_pec, &msg[num-1]);\n\t\tif (status < 0)\n\t\t\treturn status;\n\t}\n\n\tif (read_write == I2C_SMBUS_READ)\n\t\tswitch (size) {\n\t\tcase I2C_SMBUS_BYTE:\n\t\t\tdata->byte = msgbuf0[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BYTE_DATA:\n\t\t\tdata->byte = msgbuf1[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_WORD_DATA:\n\t\tcase I2C_SMBUS_PROC_CALL:\n\t\t\tdata->word = msgbuf1[0] | (msgbuf1[1] << 8);\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\t\tfor (i = 0; i < data->block[0]; i++)\n\t\t\t\tdata->block[i+1] = msgbuf1[i];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\t\tfor (i = 0; i < msgbuf1[0] + 1; i++)\n\t\t\t\tdata->block[i] = msgbuf1[i];\n\t\t\tbreak;\n\t\t}\n\treturn 0;\n}",
        "code_after_change": "static s32 i2c_smbus_xfer_emulated(struct i2c_adapter *adapter, u16 addr,\n\t\t\t\t   unsigned short flags,\n\t\t\t\t   char read_write, u8 command, int size,\n\t\t\t\t   union i2c_smbus_data *data)\n{\n\t/* So we need to generate a series of msgs. In the case of writing, we\n\t  need to use only one message; when reading, we need two. We initialize\n\t  most things with sane defaults, to keep the code below somewhat\n\t  simpler. */\n\tunsigned char msgbuf0[I2C_SMBUS_BLOCK_MAX+3];\n\tunsigned char msgbuf1[I2C_SMBUS_BLOCK_MAX+2];\n\tint num = read_write == I2C_SMBUS_READ ? 2 : 1;\n\tint i;\n\tu8 partial_pec = 0;\n\tint status;\n\tstruct i2c_msg msg[2] = {\n\t\t{\n\t\t\t.addr = addr,\n\t\t\t.flags = flags,\n\t\t\t.len = 1,\n\t\t\t.buf = msgbuf0,\n\t\t}, {\n\t\t\t.addr = addr,\n\t\t\t.flags = flags | I2C_M_RD,\n\t\t\t.len = 0,\n\t\t\t.buf = msgbuf1,\n\t\t},\n\t};\n\n\tmsgbuf0[0] = command;\n\tswitch (size) {\n\tcase I2C_SMBUS_QUICK:\n\t\tmsg[0].len = 0;\n\t\t/* Special case: The read/write field is used as data */\n\t\tmsg[0].flags = flags | (read_write == I2C_SMBUS_READ ?\n\t\t\t\t\tI2C_M_RD : 0);\n\t\tnum = 1;\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\t/* Special case: only a read! */\n\t\t\tmsg[0].flags = I2C_M_RD | flags;\n\t\t\tnum = 1;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 1;\n\t\telse {\n\t\t\tmsg[0].len = 2;\n\t\t\tmsgbuf0[1] = data->byte;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_WORD_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 2;\n\t\telse {\n\t\t\tmsg[0].len = 3;\n\t\t\tmsgbuf0[1] = data->word & 0xff;\n\t\t\tmsgbuf0[2] = data->word >> 8;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_PROC_CALL:\n\t\tnum = 2; /* Special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tmsg[0].len = 3;\n\t\tmsg[1].len = 2;\n\t\tmsgbuf0[1] = data->word & 0xff;\n\t\tmsgbuf0[2] = data->word >> 8;\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t\t   the underlying bus driver */\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 2;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 2) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\tnum = 2; /* Another special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmsg[0].len = data->block[0] + 2;\n\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t   the underlying bus driver */\n\t\tbreak;\n\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",\n\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].len = data->block[0];\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 1;\n\t\t\tfor (i = 1; i <= data->block[0]; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i];\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&adapter->dev, \"Unsupported transaction %d\\n\", size);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\ti = ((flags & I2C_CLIENT_PEC) && size != I2C_SMBUS_QUICK\n\t\t\t\t      && size != I2C_SMBUS_I2C_BLOCK_DATA);\n\tif (i) {\n\t\t/* Compute PEC if first message is a write */\n\t\tif (!(msg[0].flags & I2C_M_RD)) {\n\t\t\tif (num == 1) /* Write only */\n\t\t\t\ti2c_smbus_add_pec(&msg[0]);\n\t\t\telse /* Write followed by read */\n\t\t\t\tpartial_pec = i2c_smbus_msg_pec(0, &msg[0]);\n\t\t}\n\t\t/* Ask for PEC if last message is a read */\n\t\tif (msg[num-1].flags & I2C_M_RD)\n\t\t\tmsg[num-1].len++;\n\t}\n\n\tstatus = i2c_transfer(adapter, msg, num);\n\tif (status < 0)\n\t\treturn status;\n\n\t/* Check PEC if last message is a read */\n\tif (i && (msg[num-1].flags & I2C_M_RD)) {\n\t\tstatus = i2c_smbus_check_pec(partial_pec, &msg[num-1]);\n\t\tif (status < 0)\n\t\t\treturn status;\n\t}\n\n\tif (read_write == I2C_SMBUS_READ)\n\t\tswitch (size) {\n\t\tcase I2C_SMBUS_BYTE:\n\t\t\tdata->byte = msgbuf0[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BYTE_DATA:\n\t\t\tdata->byte = msgbuf1[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_WORD_DATA:\n\t\tcase I2C_SMBUS_PROC_CALL:\n\t\t\tdata->word = msgbuf1[0] | (msgbuf1[1] << 8);\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\t\tfor (i = 0; i < data->block[0]; i++)\n\t\t\t\tdata->block[i+1] = msgbuf1[i];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\t\tfor (i = 0; i < msgbuf1[0] + 1; i++)\n\t\t\t\tdata->block[i] = msgbuf1[i];\n\t\t\tbreak;\n\t\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -102,16 +102,17 @@\n \t\t\t\t   the underlying bus driver */\n \t\tbreak;\n \tcase I2C_SMBUS_I2C_BLOCK_DATA:\n+\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n+\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",\n+\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",\n+\t\t\t\tdata->block[0]);\n+\t\t\treturn -EINVAL;\n+\t\t}\n+\n \t\tif (read_write == I2C_SMBUS_READ) {\n \t\t\tmsg[1].len = data->block[0];\n \t\t} else {\n \t\t\tmsg[0].len = data->block[0] + 1;\n-\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {\n-\t\t\t\tdev_err(&adapter->dev,\n-\t\t\t\t\t\"Invalid block write size %d\\n\",\n-\t\t\t\t\tdata->block[0]);\n-\t\t\t\treturn -EINVAL;\n-\t\t\t}\n \t\t\tfor (i = 1; i <= data->block[0]; i++)\n \t\t\t\tmsgbuf0[i] = data->block[i];\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {",
                "\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",",
                "\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",",
                "\t\t\t\tdata->block[0]);",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                ""
            ],
            "deleted": [
                "\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {",
                "\t\t\t\tdev_err(&adapter->dev,",
                "\t\t\t\t\t\"Invalid block write size %d\\n\",",
                "\t\t\t\t\tdata->block[0]);",
                "\t\t\t\treturn -EINVAL;",
                "\t\t\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in drivers/i2c/i2c-core-smbus.c in the Linux kernel before 4.14.15. There is an out of bounds write in the function i2c_smbus_xfer_emulated."
    },
    {
        "cve_id": "CVE-2017-18552",
        "code_before_change": "static int rds_recv_track_latency(struct rds_sock *rs, char __user *optval,\n\t\t\t\t  int optlen)\n{\n\tstruct rds_rx_trace_so trace;\n\tint i;\n\n\tif (optlen != sizeof(struct rds_rx_trace_so))\n\t\treturn -EFAULT;\n\n\tif (copy_from_user(&trace, optval, sizeof(trace)))\n\t\treturn -EFAULT;\n\n\trs->rs_rx_traces = trace.rx_traces;\n\tfor (i = 0; i < rs->rs_rx_traces; i++) {\n\t\tif (trace.rx_trace_pos[i] > RDS_MSG_RX_DGRAM_TRACE_MAX) {\n\t\t\trs->rs_rx_traces = 0;\n\t\t\treturn -EFAULT;\n\t\t}\n\t\trs->rs_rx_trace[i] = trace.rx_trace_pos[i];\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int rds_recv_track_latency(struct rds_sock *rs, char __user *optval,\n\t\t\t\t  int optlen)\n{\n\tstruct rds_rx_trace_so trace;\n\tint i;\n\n\tif (optlen != sizeof(struct rds_rx_trace_so))\n\t\treturn -EFAULT;\n\n\tif (copy_from_user(&trace, optval, sizeof(trace)))\n\t\treturn -EFAULT;\n\n\tif (trace.rx_traces > RDS_MSG_RX_DGRAM_TRACE_MAX)\n\t\treturn -EFAULT;\n\n\trs->rs_rx_traces = trace.rx_traces;\n\tfor (i = 0; i < rs->rs_rx_traces; i++) {\n\t\tif (trace.rx_trace_pos[i] > RDS_MSG_RX_DGRAM_TRACE_MAX) {\n\t\t\trs->rs_rx_traces = 0;\n\t\t\treturn -EFAULT;\n\t\t}\n\t\trs->rs_rx_trace[i] = trace.rx_trace_pos[i];\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,9 @@\n \t\treturn -EFAULT;\n \n \tif (copy_from_user(&trace, optval, sizeof(trace)))\n+\t\treturn -EFAULT;\n+\n+\tif (trace.rx_traces > RDS_MSG_RX_DGRAM_TRACE_MAX)\n \t\treturn -EFAULT;\n \n \trs->rs_rx_traces = trace.rx_traces;",
        "function_modified_lines": {
            "added": [
                "\t\treturn -EFAULT;",
                "",
                "\tif (trace.rx_traces > RDS_MSG_RX_DGRAM_TRACE_MAX)"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in net/rds/af_rds.c in the Linux kernel before 4.11. There is an out of bounds write and read in the function rds_recv_track_latency."
    },
    {
        "cve_id": "CVE-2017-7294",
        "code_before_change": "int vmw_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_surface_create_arg *arg =\n\t    (union drm_vmw_surface_create_arg *)data;\n\tstruct drm_vmw_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_surface_arg *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tint i, j;\n\tuint32_t cur_bo_offset;\n\tstruct drm_vmw_size *cur_size;\n\tstruct vmw_surface_offset *cur_offset;\n\tuint32_t num_sizes;\n\tuint32_t size;\n\tconst struct svga3d_surface_desc *desc;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tnum_sizes = 0;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)\n\t\tnum_sizes += req->mip_levels[i];\n\n\tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n\t    num_sizes == 0)\n\t\treturn -EINVAL;\n\n\tsize = vmw_user_surface_size + 128 +\n\t\tttm_round_pot(num_sizes * sizeof(struct drm_vmw_size)) +\n\t\tttm_round_pot(num_sizes * sizeof(struct vmw_surface_offset));\n\n\n\tdesc = svga3dsurface_get_desc(req->format);\n\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\tDRM_ERROR(\"Invalid surface format for surface creation.\\n\");\n\t\tDRM_ERROR(\"Format requested is: %d\\n\", req->format);\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\tsrf = &user_srf->srf;\n\tres = &srf->res;\n\n\tsrf->flags = req->flags;\n\tsrf->format = req->format;\n\tsrf->scanout = req->scanout;\n\n\tmemcpy(srf->mip_levels, req->mip_levels, sizeof(srf->mip_levels));\n\tsrf->num_sizes = num_sizes;\n\tuser_srf->size = size;\n\tsrf->sizes = memdup_user((struct drm_vmw_size __user *)(unsigned long)\n\t\t\t\t req->size_addr,\n\t\t\t\t sizeof(*srf->sizes) * srf->num_sizes);\n\tif (IS_ERR(srf->sizes)) {\n\t\tret = PTR_ERR(srf->sizes);\n\t\tgoto out_no_sizes;\n\t}\n\tsrf->offsets = kmalloc_array(srf->num_sizes,\n\t\t\t\t     sizeof(*srf->offsets),\n\t\t\t\t     GFP_KERNEL);\n\tif (unlikely(!srf->offsets)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_offsets;\n\t}\n\n\tsrf->base_size = *srf->sizes;\n\tsrf->autogen_filter = SVGA3D_TEX_FILTER_NONE;\n\tsrf->multisample_count = 0;\n\n\tcur_bo_offset = 0;\n\tcur_offset = srf->offsets;\n\tcur_size = srf->sizes;\n\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tfor (j = 0; j < srf->mip_levels[i]; ++j) {\n\t\t\tuint32_t stride = svga3dsurface_calculate_pitch\n\t\t\t\t(desc, cur_size);\n\n\t\t\tcur_offset->face = i;\n\t\t\tcur_offset->mip = j;\n\t\t\tcur_offset->bo_offset = cur_bo_offset;\n\t\t\tcur_bo_offset += svga3dsurface_get_image_buffer_size\n\t\t\t\t(desc, cur_size, stride);\n\t\t\t++cur_offset;\n\t\t\t++cur_size;\n\t\t}\n\t}\n\tres->backup_size = cur_bo_offset;\n\tif (srf->scanout &&\n\t    srf->num_sizes == 1 &&\n\t    srf->sizes[0].width == 64 &&\n\t    srf->sizes[0].height == 64 &&\n\t    srf->format == SVGA3D_A8R8G8B8) {\n\n\t\tsrf->snooper.image = kzalloc(64 * 64 * 4, GFP_KERNEL);\n\t\tif (!srf->snooper.image) {\n\t\t\tDRM_ERROR(\"Failed to allocate cursor_image\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_no_copy;\n\t\t}\n\t} else {\n\t\tsrf->snooper.image = NULL;\n\t}\n\tsrf->snooper.crtc = NULL;\n\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\t/**\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_unlock;\n\n\t/*\n\t * A gb-aware client referencing a shared surface will\n\t * expect a backup buffer to be present.\n\t */\n\tif (dev_priv->has_mob && req->shareable) {\n\t\tuint32_t backup_handle;\n\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    true,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\ttmp = vmw_resource_reference(&srf->res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->shareable, VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->sid = user_srf->prime.base.hash.key;\n\tvmw_resource_unreference(&res);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn 0;\nout_no_copy:\n\tkfree(srf->offsets);\nout_no_offsets:\n\tkfree(srf->sizes);\nout_no_sizes:\n\tttm_prime_object_kfree(user_srf, prime);\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}",
        "code_after_change": "int vmw_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_surface_create_arg *arg =\n\t    (union drm_vmw_surface_create_arg *)data;\n\tstruct drm_vmw_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_surface_arg *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tint i, j;\n\tuint32_t cur_bo_offset;\n\tstruct drm_vmw_size *cur_size;\n\tstruct vmw_surface_offset *cur_offset;\n\tuint32_t num_sizes;\n\tuint32_t size;\n\tconst struct svga3d_surface_desc *desc;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tnum_sizes = 0;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)\n\t\t\treturn -EINVAL;\n\t\tnum_sizes += req->mip_levels[i];\n\t}\n\n\tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n\t    num_sizes == 0)\n\t\treturn -EINVAL;\n\n\tsize = vmw_user_surface_size + 128 +\n\t\tttm_round_pot(num_sizes * sizeof(struct drm_vmw_size)) +\n\t\tttm_round_pot(num_sizes * sizeof(struct vmw_surface_offset));\n\n\n\tdesc = svga3dsurface_get_desc(req->format);\n\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\tDRM_ERROR(\"Invalid surface format for surface creation.\\n\");\n\t\tDRM_ERROR(\"Format requested is: %d\\n\", req->format);\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\tsrf = &user_srf->srf;\n\tres = &srf->res;\n\n\tsrf->flags = req->flags;\n\tsrf->format = req->format;\n\tsrf->scanout = req->scanout;\n\n\tmemcpy(srf->mip_levels, req->mip_levels, sizeof(srf->mip_levels));\n\tsrf->num_sizes = num_sizes;\n\tuser_srf->size = size;\n\tsrf->sizes = memdup_user((struct drm_vmw_size __user *)(unsigned long)\n\t\t\t\t req->size_addr,\n\t\t\t\t sizeof(*srf->sizes) * srf->num_sizes);\n\tif (IS_ERR(srf->sizes)) {\n\t\tret = PTR_ERR(srf->sizes);\n\t\tgoto out_no_sizes;\n\t}\n\tsrf->offsets = kmalloc_array(srf->num_sizes,\n\t\t\t\t     sizeof(*srf->offsets),\n\t\t\t\t     GFP_KERNEL);\n\tif (unlikely(!srf->offsets)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_offsets;\n\t}\n\n\tsrf->base_size = *srf->sizes;\n\tsrf->autogen_filter = SVGA3D_TEX_FILTER_NONE;\n\tsrf->multisample_count = 0;\n\n\tcur_bo_offset = 0;\n\tcur_offset = srf->offsets;\n\tcur_size = srf->sizes;\n\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tfor (j = 0; j < srf->mip_levels[i]; ++j) {\n\t\t\tuint32_t stride = svga3dsurface_calculate_pitch\n\t\t\t\t(desc, cur_size);\n\n\t\t\tcur_offset->face = i;\n\t\t\tcur_offset->mip = j;\n\t\t\tcur_offset->bo_offset = cur_bo_offset;\n\t\t\tcur_bo_offset += svga3dsurface_get_image_buffer_size\n\t\t\t\t(desc, cur_size, stride);\n\t\t\t++cur_offset;\n\t\t\t++cur_size;\n\t\t}\n\t}\n\tres->backup_size = cur_bo_offset;\n\tif (srf->scanout &&\n\t    srf->num_sizes == 1 &&\n\t    srf->sizes[0].width == 64 &&\n\t    srf->sizes[0].height == 64 &&\n\t    srf->format == SVGA3D_A8R8G8B8) {\n\n\t\tsrf->snooper.image = kzalloc(64 * 64 * 4, GFP_KERNEL);\n\t\tif (!srf->snooper.image) {\n\t\t\tDRM_ERROR(\"Failed to allocate cursor_image\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_no_copy;\n\t\t}\n\t} else {\n\t\tsrf->snooper.image = NULL;\n\t}\n\tsrf->snooper.crtc = NULL;\n\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\t/**\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_unlock;\n\n\t/*\n\t * A gb-aware client referencing a shared surface will\n\t * expect a backup buffer to be present.\n\t */\n\tif (dev_priv->has_mob && req->shareable) {\n\t\tuint32_t backup_handle;\n\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    true,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\ttmp = vmw_resource_reference(&srf->res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->shareable, VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->sid = user_srf->prime.base.hash.key;\n\tvmw_resource_unreference(&res);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn 0;\nout_no_copy:\n\tkfree(srf->offsets);\nout_no_offsets:\n\tkfree(srf->sizes);\nout_no_sizes:\n\tttm_prime_object_kfree(user_srf, prime);\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,11 @@\n \t\t\t128;\n \n \tnum_sizes = 0;\n-\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)\n+\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n+\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)\n+\t\t\treturn -EINVAL;\n \t\tnum_sizes += req->mip_levels[i];\n+\t}\n \n \tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n \t    num_sizes == 0)",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {",
                "\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)",
                "\t\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": [
                "\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "The vmw_surface_define_ioctl function in drivers/gpu/drm/vmwgfx/vmwgfx_surface.c in the Linux kernel through 4.10.6 does not validate addition of certain levels data, which allows local users to trigger an integer overflow and out-of-bounds write, and cause a denial of service (system hang or crash) or possibly gain privileges, via a crafted ioctl call for a /dev/dri/renderD* device."
    },
    {
        "cve_id": "CVE-2017-7308",
        "code_before_change": "static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,\n\t\tint closing, int tx_ring)\n{\n\tstruct pgv *pg_vec = NULL;\n\tstruct packet_sock *po = pkt_sk(sk);\n\tint was_running, order = 0;\n\tstruct packet_ring_buffer *rb;\n\tstruct sk_buff_head *rb_queue;\n\t__be16 num;\n\tint err = -EINVAL;\n\t/* Added to avoid minimal code churn */\n\tstruct tpacket_req *req = &req_u->req;\n\n\tlock_sock(sk);\n\n\trb = tx_ring ? &po->tx_ring : &po->rx_ring;\n\trb_queue = tx_ring ? &sk->sk_write_queue : &sk->sk_receive_queue;\n\n\terr = -EBUSY;\n\tif (!closing) {\n\t\tif (atomic_read(&po->mapped))\n\t\t\tgoto out;\n\t\tif (packet_read_pending(rb))\n\t\t\tgoto out;\n\t}\n\n\tif (req->tp_block_nr) {\n\t\t/* Sanity tests and some calculations */\n\t\terr = -EBUSY;\n\t\tif (unlikely(rb->pg_vec))\n\t\t\tgoto out;\n\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V1:\n\t\t\tpo->tp_hdrlen = TPACKET_HDRLEN;\n\t\t\tbreak;\n\t\tcase TPACKET_V2:\n\t\t\tpo->tp_hdrlen = TPACKET2_HDRLEN;\n\t\t\tbreak;\n\t\tcase TPACKET_V3:\n\t\t\tpo->tp_hdrlen = TPACKET3_HDRLEN;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (unlikely((int)req->tp_block_size <= 0))\n\t\t\tgoto out;\n\t\tif (unlikely(!PAGE_ALIGNED(req->tp_block_size)))\n\t\t\tgoto out;\n\t\tif (po->tp_version >= TPACKET_V3 &&\n\t\t    (int)(req->tp_block_size -\n\t\t\t  BLK_PLUS_PRIV(req_u->req3.tp_sizeof_priv)) <= 0)\n\t\t\tgoto out;\n\t\tif (unlikely(req->tp_frame_size < po->tp_hdrlen +\n\t\t\t\t\tpo->tp_reserve))\n\t\t\tgoto out;\n\t\tif (unlikely(req->tp_frame_size & (TPACKET_ALIGNMENT - 1)))\n\t\t\tgoto out;\n\n\t\trb->frames_per_block = req->tp_block_size / req->tp_frame_size;\n\t\tif (unlikely(rb->frames_per_block == 0))\n\t\t\tgoto out;\n\t\tif (unlikely((rb->frames_per_block * req->tp_block_nr) !=\n\t\t\t\t\treq->tp_frame_nr))\n\t\t\tgoto out;\n\n\t\terr = -ENOMEM;\n\t\torder = get_order(req->tp_block_size);\n\t\tpg_vec = alloc_pg_vec(req, order);\n\t\tif (unlikely(!pg_vec))\n\t\t\tgoto out;\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V3:\n\t\t\t/* Block transmit is not supported yet */\n\t\t\tif (!tx_ring) {\n\t\t\t\tinit_prb_bdqc(po, rb, pg_vec, req_u);\n\t\t\t} else {\n\t\t\t\tstruct tpacket_req3 *req3 = &req_u->req3;\n\n\t\t\t\tif (req3->tp_retire_blk_tov ||\n\t\t\t\t    req3->tp_sizeof_priv ||\n\t\t\t\t    req3->tp_feature_req_word) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\t/* Done */\n\telse {\n\t\terr = -EINVAL;\n\t\tif (unlikely(req->tp_frame_nr))\n\t\t\tgoto out;\n\t}\n\n\n\t/* Detach socket from network */\n\tspin_lock(&po->bind_lock);\n\twas_running = po->running;\n\tnum = po->num;\n\tif (was_running) {\n\t\tpo->num = 0;\n\t\t__unregister_prot_hook(sk, false);\n\t}\n\tspin_unlock(&po->bind_lock);\n\n\tsynchronize_net();\n\n\terr = -EBUSY;\n\tmutex_lock(&po->pg_vec_lock);\n\tif (closing || atomic_read(&po->mapped) == 0) {\n\t\terr = 0;\n\t\tspin_lock_bh(&rb_queue->lock);\n\t\tswap(rb->pg_vec, pg_vec);\n\t\trb->frame_max = (req->tp_frame_nr - 1);\n\t\trb->head = 0;\n\t\trb->frame_size = req->tp_frame_size;\n\t\tspin_unlock_bh(&rb_queue->lock);\n\n\t\tswap(rb->pg_vec_order, order);\n\t\tswap(rb->pg_vec_len, req->tp_block_nr);\n\n\t\trb->pg_vec_pages = req->tp_block_size/PAGE_SIZE;\n\t\tpo->prot_hook.func = (po->rx_ring.pg_vec) ?\n\t\t\t\t\t\ttpacket_rcv : packet_rcv;\n\t\tskb_queue_purge(rb_queue);\n\t\tif (atomic_read(&po->mapped))\n\t\t\tpr_err(\"packet_mmap: vma is busy: %d\\n\",\n\t\t\t       atomic_read(&po->mapped));\n\t}\n\tmutex_unlock(&po->pg_vec_lock);\n\n\tspin_lock(&po->bind_lock);\n\tif (was_running) {\n\t\tpo->num = num;\n\t\tregister_prot_hook(sk);\n\t}\n\tspin_unlock(&po->bind_lock);\n\tif (closing && (po->tp_version > TPACKET_V2)) {\n\t\t/* Because we don't support block-based V3 on tx-ring */\n\t\tif (!tx_ring)\n\t\t\tprb_shutdown_retire_blk_timer(po, rb_queue);\n\t}\n\n\tif (pg_vec)\n\t\tfree_pg_vec(pg_vec, order, req->tp_block_nr);\nout:\n\trelease_sock(sk);\n\treturn err;\n}",
        "code_after_change": "static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,\n\t\tint closing, int tx_ring)\n{\n\tstruct pgv *pg_vec = NULL;\n\tstruct packet_sock *po = pkt_sk(sk);\n\tint was_running, order = 0;\n\tstruct packet_ring_buffer *rb;\n\tstruct sk_buff_head *rb_queue;\n\t__be16 num;\n\tint err = -EINVAL;\n\t/* Added to avoid minimal code churn */\n\tstruct tpacket_req *req = &req_u->req;\n\n\tlock_sock(sk);\n\n\trb = tx_ring ? &po->tx_ring : &po->rx_ring;\n\trb_queue = tx_ring ? &sk->sk_write_queue : &sk->sk_receive_queue;\n\n\terr = -EBUSY;\n\tif (!closing) {\n\t\tif (atomic_read(&po->mapped))\n\t\t\tgoto out;\n\t\tif (packet_read_pending(rb))\n\t\t\tgoto out;\n\t}\n\n\tif (req->tp_block_nr) {\n\t\t/* Sanity tests and some calculations */\n\t\terr = -EBUSY;\n\t\tif (unlikely(rb->pg_vec))\n\t\t\tgoto out;\n\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V1:\n\t\t\tpo->tp_hdrlen = TPACKET_HDRLEN;\n\t\t\tbreak;\n\t\tcase TPACKET_V2:\n\t\t\tpo->tp_hdrlen = TPACKET2_HDRLEN;\n\t\t\tbreak;\n\t\tcase TPACKET_V3:\n\t\t\tpo->tp_hdrlen = TPACKET3_HDRLEN;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = -EINVAL;\n\t\tif (unlikely((int)req->tp_block_size <= 0))\n\t\t\tgoto out;\n\t\tif (unlikely(!PAGE_ALIGNED(req->tp_block_size)))\n\t\t\tgoto out;\n\t\tif (po->tp_version >= TPACKET_V3 &&\n\t\t    req->tp_block_size <=\n\t\t\t  BLK_PLUS_PRIV((u64)req_u->req3.tp_sizeof_priv))\n\t\t\tgoto out;\n\t\tif (unlikely(req->tp_frame_size < po->tp_hdrlen +\n\t\t\t\t\tpo->tp_reserve))\n\t\t\tgoto out;\n\t\tif (unlikely(req->tp_frame_size & (TPACKET_ALIGNMENT - 1)))\n\t\t\tgoto out;\n\n\t\trb->frames_per_block = req->tp_block_size / req->tp_frame_size;\n\t\tif (unlikely(rb->frames_per_block == 0))\n\t\t\tgoto out;\n\t\tif (unlikely((rb->frames_per_block * req->tp_block_nr) !=\n\t\t\t\t\treq->tp_frame_nr))\n\t\t\tgoto out;\n\n\t\terr = -ENOMEM;\n\t\torder = get_order(req->tp_block_size);\n\t\tpg_vec = alloc_pg_vec(req, order);\n\t\tif (unlikely(!pg_vec))\n\t\t\tgoto out;\n\t\tswitch (po->tp_version) {\n\t\tcase TPACKET_V3:\n\t\t\t/* Block transmit is not supported yet */\n\t\t\tif (!tx_ring) {\n\t\t\t\tinit_prb_bdqc(po, rb, pg_vec, req_u);\n\t\t\t} else {\n\t\t\t\tstruct tpacket_req3 *req3 = &req_u->req3;\n\n\t\t\t\tif (req3->tp_retire_blk_tov ||\n\t\t\t\t    req3->tp_sizeof_priv ||\n\t\t\t\t    req3->tp_feature_req_word) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\t/* Done */\n\telse {\n\t\terr = -EINVAL;\n\t\tif (unlikely(req->tp_frame_nr))\n\t\t\tgoto out;\n\t}\n\n\n\t/* Detach socket from network */\n\tspin_lock(&po->bind_lock);\n\twas_running = po->running;\n\tnum = po->num;\n\tif (was_running) {\n\t\tpo->num = 0;\n\t\t__unregister_prot_hook(sk, false);\n\t}\n\tspin_unlock(&po->bind_lock);\n\n\tsynchronize_net();\n\n\terr = -EBUSY;\n\tmutex_lock(&po->pg_vec_lock);\n\tif (closing || atomic_read(&po->mapped) == 0) {\n\t\terr = 0;\n\t\tspin_lock_bh(&rb_queue->lock);\n\t\tswap(rb->pg_vec, pg_vec);\n\t\trb->frame_max = (req->tp_frame_nr - 1);\n\t\trb->head = 0;\n\t\trb->frame_size = req->tp_frame_size;\n\t\tspin_unlock_bh(&rb_queue->lock);\n\n\t\tswap(rb->pg_vec_order, order);\n\t\tswap(rb->pg_vec_len, req->tp_block_nr);\n\n\t\trb->pg_vec_pages = req->tp_block_size/PAGE_SIZE;\n\t\tpo->prot_hook.func = (po->rx_ring.pg_vec) ?\n\t\t\t\t\t\ttpacket_rcv : packet_rcv;\n\t\tskb_queue_purge(rb_queue);\n\t\tif (atomic_read(&po->mapped))\n\t\t\tpr_err(\"packet_mmap: vma is busy: %d\\n\",\n\t\t\t       atomic_read(&po->mapped));\n\t}\n\tmutex_unlock(&po->pg_vec_lock);\n\n\tspin_lock(&po->bind_lock);\n\tif (was_running) {\n\t\tpo->num = num;\n\t\tregister_prot_hook(sk);\n\t}\n\tspin_unlock(&po->bind_lock);\n\tif (closing && (po->tp_version > TPACKET_V2)) {\n\t\t/* Because we don't support block-based V3 on tx-ring */\n\t\tif (!tx_ring)\n\t\t\tprb_shutdown_retire_blk_timer(po, rb_queue);\n\t}\n\n\tif (pg_vec)\n\t\tfree_pg_vec(pg_vec, order, req->tp_block_nr);\nout:\n\trelease_sock(sk);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -48,8 +48,8 @@\n \t\tif (unlikely(!PAGE_ALIGNED(req->tp_block_size)))\n \t\t\tgoto out;\n \t\tif (po->tp_version >= TPACKET_V3 &&\n-\t\t    (int)(req->tp_block_size -\n-\t\t\t  BLK_PLUS_PRIV(req_u->req3.tp_sizeof_priv)) <= 0)\n+\t\t    req->tp_block_size <=\n+\t\t\t  BLK_PLUS_PRIV((u64)req_u->req3.tp_sizeof_priv))\n \t\t\tgoto out;\n \t\tif (unlikely(req->tp_frame_size < po->tp_hdrlen +\n \t\t\t\t\tpo->tp_reserve))",
        "function_modified_lines": {
            "added": [
                "\t\t    req->tp_block_size <=",
                "\t\t\t  BLK_PLUS_PRIV((u64)req_u->req3.tp_sizeof_priv))"
            ],
            "deleted": [
                "\t\t    (int)(req->tp_block_size -",
                "\t\t\t  BLK_PLUS_PRIV(req_u->req3.tp_sizeof_priv)) <= 0)"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-681"
        ],
        "cve_description": "The packet_set_ring function in net/packet/af_packet.c in the Linux kernel through 4.10.6 does not properly validate certain block-size data, which allows local users to cause a denial of service (integer signedness error and out-of-bounds write), or gain privileges (if the CAP_NET_RAW capability is held), via crafted system calls."
    },
    {
        "cve_id": "CVE-2017-8067",
        "code_before_change": "static int put_chars(u32 vtermno, const char *buf, int count)\n{\n\tstruct port *port;\n\tstruct scatterlist sg[1];\n\n\tif (unlikely(early_put_chars))\n\t\treturn early_put_chars(vtermno, buf, count);\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\tsg_init_one(sg, buf, count);\n\treturn __send_to_port(port, sg, 1, count, (void *)buf, false);\n}",
        "code_after_change": "static int put_chars(u32 vtermno, const char *buf, int count)\n{\n\tstruct port *port;\n\tstruct scatterlist sg[1];\n\tvoid *data;\n\tint ret;\n\n\tif (unlikely(early_put_chars))\n\t\treturn early_put_chars(vtermno, buf, count);\n\n\tport = find_port_by_vtermno(vtermno);\n\tif (!port)\n\t\treturn -EPIPE;\n\n\tdata = kmemdup(buf, count, GFP_ATOMIC);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tsg_init_one(sg, data, count);\n\tret = __send_to_port(port, sg, 1, count, data, false);\n\tkfree(data);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,8 @@\n {\n \tstruct port *port;\n \tstruct scatterlist sg[1];\n+\tvoid *data;\n+\tint ret;\n \n \tif (unlikely(early_put_chars))\n \t\treturn early_put_chars(vtermno, buf, count);\n@@ -10,6 +12,12 @@\n \tif (!port)\n \t\treturn -EPIPE;\n \n-\tsg_init_one(sg, buf, count);\n-\treturn __send_to_port(port, sg, 1, count, (void *)buf, false);\n+\tdata = kmemdup(buf, count, GFP_ATOMIC);\n+\tif (!data)\n+\t\treturn -ENOMEM;\n+\n+\tsg_init_one(sg, data, count);\n+\tret = __send_to_port(port, sg, 1, count, data, false);\n+\tkfree(data);\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tvoid *data;",
                "\tint ret;",
                "\tdata = kmemdup(buf, count, GFP_ATOMIC);",
                "\tif (!data)",
                "\t\treturn -ENOMEM;",
                "",
                "\tsg_init_one(sg, data, count);",
                "\tret = __send_to_port(port, sg, 1, count, data, false);",
                "\tkfree(data);",
                "\treturn ret;"
            ],
            "deleted": [
                "\tsg_init_one(sg, buf, count);",
                "\treturn __send_to_port(port, sg, 1, count, (void *)buf, false);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "drivers/char/virtio_console.c in the Linux kernel 4.9.x and 4.10.x before 4.10.12 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist."
    },
    {
        "cve_id": "CVE-2018-1068",
        "code_before_change": "static int size_entry_mwt(struct ebt_entry *entry, const unsigned char *base,\n\t\t\t  unsigned int *total,\n\t\t\t  struct ebt_entries_buf_state *state)\n{\n\tunsigned int i, j, startoff, new_offset = 0;\n\t/* stores match/watchers/targets & offset of next struct ebt_entry: */\n\tunsigned int offsets[4];\n\tunsigned int *offsets_update = NULL;\n\tint ret;\n\tchar *buf_start;\n\n\tif (*total < sizeof(struct ebt_entries))\n\t\treturn -EINVAL;\n\n\tif (!entry->bitmask) {\n\t\t*total -= sizeof(struct ebt_entries);\n\t\treturn ebt_buf_add(state, entry, sizeof(struct ebt_entries));\n\t}\n\tif (*total < sizeof(*entry) || entry->next_offset < sizeof(*entry))\n\t\treturn -EINVAL;\n\n\tstartoff = state->buf_user_offset;\n\t/* pull in most part of ebt_entry, it does not need to be changed. */\n\tret = ebt_buf_add(state, entry,\n\t\t\toffsetof(struct ebt_entry, watchers_offset));\n\tif (ret < 0)\n\t\treturn ret;\n\n\toffsets[0] = sizeof(struct ebt_entry); /* matches come first */\n\tmemcpy(&offsets[1], &entry->watchers_offset,\n\t\t\tsizeof(offsets) - sizeof(offsets[0]));\n\n\tif (state->buf_kern_start) {\n\t\tbuf_start = state->buf_kern_start + state->buf_kern_offset;\n\t\toffsets_update = (unsigned int *) buf_start;\n\t}\n\tret = ebt_buf_add(state, &offsets[1],\n\t\t\tsizeof(offsets) - sizeof(offsets[0]));\n\tif (ret < 0)\n\t\treturn ret;\n\tbuf_start = (char *) entry;\n\t/* 0: matches offset, always follows ebt_entry.\n\t * 1: watchers offset, from ebt_entry structure\n\t * 2: target offset, from ebt_entry structure\n\t * 3: next ebt_entry offset, from ebt_entry structure\n\t *\n\t * offsets are relative to beginning of struct ebt_entry (i.e., 0).\n\t */\n\tfor (i = 0, j = 1 ; j < 4 ; j++, i++) {\n\t\tstruct compat_ebt_entry_mwt *match32;\n\t\tunsigned int size;\n\t\tchar *buf = buf_start + offsets[i];\n\n\t\tif (offsets[i] > offsets[j])\n\t\t\treturn -EINVAL;\n\n\t\tmatch32 = (struct compat_ebt_entry_mwt *) buf;\n\t\tsize = offsets[j] - offsets[i];\n\t\tret = ebt_size_mwt(match32, size, i, state, base);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tnew_offset += ret;\n\t\tif (offsets_update && new_offset) {\n\t\t\tpr_debug(\"change offset %d to %d\\n\",\n\t\t\t\toffsets_update[i], offsets[j] + new_offset);\n\t\t\toffsets_update[i] = offsets[j] + new_offset;\n\t\t}\n\t}\n\n\tif (state->buf_kern_start == NULL) {\n\t\tunsigned int offset = buf_start - (char *) base;\n\n\t\tret = xt_compat_add_offset(NFPROTO_BRIDGE, offset, new_offset);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tstartoff = state->buf_user_offset - startoff;\n\n\tif (WARN_ON(*total < startoff))\n\t\treturn -EINVAL;\n\t*total -= startoff;\n\treturn 0;\n}",
        "code_after_change": "static int size_entry_mwt(struct ebt_entry *entry, const unsigned char *base,\n\t\t\t  unsigned int *total,\n\t\t\t  struct ebt_entries_buf_state *state)\n{\n\tunsigned int i, j, startoff, new_offset = 0;\n\t/* stores match/watchers/targets & offset of next struct ebt_entry: */\n\tunsigned int offsets[4];\n\tunsigned int *offsets_update = NULL;\n\tint ret;\n\tchar *buf_start;\n\n\tif (*total < sizeof(struct ebt_entries))\n\t\treturn -EINVAL;\n\n\tif (!entry->bitmask) {\n\t\t*total -= sizeof(struct ebt_entries);\n\t\treturn ebt_buf_add(state, entry, sizeof(struct ebt_entries));\n\t}\n\tif (*total < sizeof(*entry) || entry->next_offset < sizeof(*entry))\n\t\treturn -EINVAL;\n\n\tstartoff = state->buf_user_offset;\n\t/* pull in most part of ebt_entry, it does not need to be changed. */\n\tret = ebt_buf_add(state, entry,\n\t\t\toffsetof(struct ebt_entry, watchers_offset));\n\tif (ret < 0)\n\t\treturn ret;\n\n\toffsets[0] = sizeof(struct ebt_entry); /* matches come first */\n\tmemcpy(&offsets[1], &entry->watchers_offset,\n\t\t\tsizeof(offsets) - sizeof(offsets[0]));\n\n\tif (state->buf_kern_start) {\n\t\tbuf_start = state->buf_kern_start + state->buf_kern_offset;\n\t\toffsets_update = (unsigned int *) buf_start;\n\t}\n\tret = ebt_buf_add(state, &offsets[1],\n\t\t\tsizeof(offsets) - sizeof(offsets[0]));\n\tif (ret < 0)\n\t\treturn ret;\n\tbuf_start = (char *) entry;\n\t/* 0: matches offset, always follows ebt_entry.\n\t * 1: watchers offset, from ebt_entry structure\n\t * 2: target offset, from ebt_entry structure\n\t * 3: next ebt_entry offset, from ebt_entry structure\n\t *\n\t * offsets are relative to beginning of struct ebt_entry (i.e., 0).\n\t */\n\tfor (i = 0; i < 4 ; ++i) {\n\t\tif (offsets[i] >= *total)\n\t\t\treturn -EINVAL;\n\t\tif (i == 0)\n\t\t\tcontinue;\n\t\tif (offsets[i-1] > offsets[i])\n\t\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0, j = 1 ; j < 4 ; j++, i++) {\n\t\tstruct compat_ebt_entry_mwt *match32;\n\t\tunsigned int size;\n\t\tchar *buf = buf_start + offsets[i];\n\n\t\tif (offsets[i] > offsets[j])\n\t\t\treturn -EINVAL;\n\n\t\tmatch32 = (struct compat_ebt_entry_mwt *) buf;\n\t\tsize = offsets[j] - offsets[i];\n\t\tret = ebt_size_mwt(match32, size, i, state, base);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tnew_offset += ret;\n\t\tif (offsets_update && new_offset) {\n\t\t\tpr_debug(\"change offset %d to %d\\n\",\n\t\t\t\toffsets_update[i], offsets[j] + new_offset);\n\t\t\toffsets_update[i] = offsets[j] + new_offset;\n\t\t}\n\t}\n\n\tif (state->buf_kern_start == NULL) {\n\t\tunsigned int offset = buf_start - (char *) base;\n\n\t\tret = xt_compat_add_offset(NFPROTO_BRIDGE, offset, new_offset);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tstartoff = state->buf_user_offset - startoff;\n\n\tif (WARN_ON(*total < startoff))\n\t\treturn -EINVAL;\n\t*total -= startoff;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -46,6 +46,15 @@\n \t *\n \t * offsets are relative to beginning of struct ebt_entry (i.e., 0).\n \t */\n+\tfor (i = 0; i < 4 ; ++i) {\n+\t\tif (offsets[i] >= *total)\n+\t\t\treturn -EINVAL;\n+\t\tif (i == 0)\n+\t\t\tcontinue;\n+\t\tif (offsets[i-1] > offsets[i])\n+\t\t\treturn -EINVAL;\n+\t}\n+\n \tfor (i = 0, j = 1 ; j < 4 ; j++, i++) {\n \t\tstruct compat_ebt_entry_mwt *match32;\n \t\tunsigned int size;",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < 4 ; ++i) {",
                "\t\tif (offsets[i] >= *total)",
                "\t\t\treturn -EINVAL;",
                "\t\tif (i == 0)",
                "\t\t\tcontinue;",
                "\t\tif (offsets[i-1] > offsets[i])",
                "\t\t\treturn -EINVAL;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux 4.x kernel's implementation of 32-bit syscall interface for bridging. This allowed a privileged user to arbitrarily write to a limited range of kernel memory."
    },
    {
        "cve_id": "CVE-2018-1068",
        "code_before_change": "static int ebt_size_mwt(struct compat_ebt_entry_mwt *match32,\n\t\t\tunsigned int size_left, enum compat_mwt type,\n\t\t\tstruct ebt_entries_buf_state *state, const void *base)\n{\n\tint growth = 0;\n\tchar *buf;\n\n\tif (size_left == 0)\n\t\treturn 0;\n\n\tbuf = (char *) match32;\n\n\twhile (size_left >= sizeof(*match32)) {\n\t\tstruct ebt_entry_match *match_kern;\n\t\tint ret;\n\n\t\tmatch_kern = (struct ebt_entry_match *) state->buf_kern_start;\n\t\tif (match_kern) {\n\t\t\tchar *tmp;\n\t\t\ttmp = state->buf_kern_start + state->buf_kern_offset;\n\t\t\tmatch_kern = (struct ebt_entry_match *) tmp;\n\t\t}\n\t\tret = ebt_buf_add(state, buf, sizeof(*match32));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tsize_left -= sizeof(*match32);\n\n\t\t/* add padding before match->data (if any) */\n\t\tret = ebt_buf_add_pad(state, ebt_compat_entry_padsize());\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (match32->match_size > size_left)\n\t\t\treturn -EINVAL;\n\n\t\tsize_left -= match32->match_size;\n\n\t\tret = compat_mtw_from_user(match32, type, state, base);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (WARN_ON(ret < match32->match_size))\n\t\t\treturn -EINVAL;\n\t\tgrowth += ret - match32->match_size;\n\t\tgrowth += ebt_compat_entry_padsize();\n\n\t\tbuf += sizeof(*match32);\n\t\tbuf += match32->match_size;\n\n\t\tif (match_kern)\n\t\t\tmatch_kern->match_size = ret;\n\n\t\tWARN_ON(type == EBT_COMPAT_TARGET && size_left);\n\t\tmatch32 = (struct compat_ebt_entry_mwt *) buf;\n\t}\n\n\treturn growth;\n}",
        "code_after_change": "static int ebt_size_mwt(struct compat_ebt_entry_mwt *match32,\n\t\t\tunsigned int size_left, enum compat_mwt type,\n\t\t\tstruct ebt_entries_buf_state *state, const void *base)\n{\n\tint growth = 0;\n\tchar *buf;\n\n\tif (size_left == 0)\n\t\treturn 0;\n\n\tbuf = (char *) match32;\n\n\twhile (size_left >= sizeof(*match32)) {\n\t\tstruct ebt_entry_match *match_kern;\n\t\tint ret;\n\n\t\tmatch_kern = (struct ebt_entry_match *) state->buf_kern_start;\n\t\tif (match_kern) {\n\t\t\tchar *tmp;\n\t\t\ttmp = state->buf_kern_start + state->buf_kern_offset;\n\t\t\tmatch_kern = (struct ebt_entry_match *) tmp;\n\t\t}\n\t\tret = ebt_buf_add(state, buf, sizeof(*match32));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tsize_left -= sizeof(*match32);\n\n\t\t/* add padding before match->data (if any) */\n\t\tret = ebt_buf_add_pad(state, ebt_compat_entry_padsize());\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (match32->match_size > size_left)\n\t\t\treturn -EINVAL;\n\n\t\tsize_left -= match32->match_size;\n\n\t\tret = compat_mtw_from_user(match32, type, state, base);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (WARN_ON(ret < match32->match_size))\n\t\t\treturn -EINVAL;\n\t\tgrowth += ret - match32->match_size;\n\t\tgrowth += ebt_compat_entry_padsize();\n\n\t\tbuf += sizeof(*match32);\n\t\tbuf += match32->match_size;\n\n\t\tif (match_kern)\n\t\t\tmatch_kern->match_size = ret;\n\n\t\tif (WARN_ON(type == EBT_COMPAT_TARGET && size_left))\n\t\t\treturn -EINVAL;\n\n\t\tmatch32 = (struct compat_ebt_entry_mwt *) buf;\n\t}\n\n\treturn growth;\n}",
        "patch": "--- code before\n+++ code after\n@@ -50,7 +50,9 @@\n \t\tif (match_kern)\n \t\t\tmatch_kern->match_size = ret;\n \n-\t\tWARN_ON(type == EBT_COMPAT_TARGET && size_left);\n+\t\tif (WARN_ON(type == EBT_COMPAT_TARGET && size_left))\n+\t\t\treturn -EINVAL;\n+\n \t\tmatch32 = (struct compat_ebt_entry_mwt *) buf;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (WARN_ON(type == EBT_COMPAT_TARGET && size_left))",
                "\t\t\treturn -EINVAL;",
                ""
            ],
            "deleted": [
                "\t\tWARN_ON(type == EBT_COMPAT_TARGET && size_left);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux 4.x kernel's implementation of 32-bit syscall interface for bridging. This allowed a privileged user to arbitrarily write to a limited range of kernel memory."
    },
    {
        "cve_id": "CVE-2018-10878",
        "code_before_change": "static int ext4_init_block_bitmap(struct super_block *sb,\n\t\t\t\t   struct buffer_head *bh,\n\t\t\t\t   ext4_group_t block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tunsigned int bit, bit_max;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t start, tmp;\n\tint flex_bg = 0;\n\n\tJ_ASSERT_BH(bh, buffer_locked(bh));\n\n\t/* If checksum is bad mark all blocks used to prevent allocation\n\t * essentially implementing a per-group read-only flag. */\n\tif (!ext4_group_desc_csum_verify(sb, block_group, gdp)) {\n\t\text4_mark_group_bitmap_corrupted(sb, block_group,\n\t\t\t\t\tEXT4_GROUP_INFO_BBITMAP_CORRUPT |\n\t\t\t\t\tEXT4_GROUP_INFO_IBITMAP_CORRUPT);\n\t\treturn -EFSBADCRC;\n\t}\n\tmemset(bh->b_data, 0, sb->s_blocksize);\n\n\tbit_max = ext4_num_base_meta_clusters(sb, block_group);\n\tif ((bit_max >> 3) >= bh->b_size)\n\t\treturn -EFSCORRUPTED;\n\n\tfor (bit = 0; bit < bit_max; bit++)\n\t\text4_set_bit(bit, bh->b_data);\n\n\tstart = ext4_group_first_block_no(sb, block_group);\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tflex_bg = 1;\n\n\t/* Set bits for block and inode bitmaps, and inode table */\n\ttmp = ext4_block_bitmap(sb, gdp);\n\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\n\ttmp = ext4_inode_bitmap(sb, gdp);\n\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\n\ttmp = ext4_inode_table(sb, gdp);\n\tfor (; tmp < ext4_inode_table(sb, gdp) +\n\t\t     sbi->s_itb_per_group; tmp++) {\n\t\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n\t\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\t}\n\n\t/*\n\t * Also if the number of blocks within the group is less than\n\t * the blocksize * 8 ( which is the size of bitmap ), set rest\n\t * of the block bitmap to 1\n\t */\n\text4_mark_bitmap_end(num_clusters_in_group(sb, block_group),\n\t\t\t     sb->s_blocksize * 8, bh->b_data);\n\treturn 0;\n}",
        "code_after_change": "static int ext4_init_block_bitmap(struct super_block *sb,\n\t\t\t\t   struct buffer_head *bh,\n\t\t\t\t   ext4_group_t block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tunsigned int bit, bit_max;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t start, tmp;\n\n\tJ_ASSERT_BH(bh, buffer_locked(bh));\n\n\t/* If checksum is bad mark all blocks used to prevent allocation\n\t * essentially implementing a per-group read-only flag. */\n\tif (!ext4_group_desc_csum_verify(sb, block_group, gdp)) {\n\t\text4_mark_group_bitmap_corrupted(sb, block_group,\n\t\t\t\t\tEXT4_GROUP_INFO_BBITMAP_CORRUPT |\n\t\t\t\t\tEXT4_GROUP_INFO_IBITMAP_CORRUPT);\n\t\treturn -EFSBADCRC;\n\t}\n\tmemset(bh->b_data, 0, sb->s_blocksize);\n\n\tbit_max = ext4_num_base_meta_clusters(sb, block_group);\n\tif ((bit_max >> 3) >= bh->b_size)\n\t\treturn -EFSCORRUPTED;\n\n\tfor (bit = 0; bit < bit_max; bit++)\n\t\text4_set_bit(bit, bh->b_data);\n\n\tstart = ext4_group_first_block_no(sb, block_group);\n\n\t/* Set bits for block and inode bitmaps, and inode table */\n\ttmp = ext4_block_bitmap(sb, gdp);\n\tif (ext4_block_in_group(sb, tmp, block_group))\n\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\n\ttmp = ext4_inode_bitmap(sb, gdp);\n\tif (ext4_block_in_group(sb, tmp, block_group))\n\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\n\ttmp = ext4_inode_table(sb, gdp);\n\tfor (; tmp < ext4_inode_table(sb, gdp) +\n\t\t     sbi->s_itb_per_group; tmp++) {\n\t\tif (ext4_block_in_group(sb, tmp, block_group))\n\t\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n\t}\n\n\t/*\n\t * Also if the number of blocks within the group is less than\n\t * the blocksize * 8 ( which is the size of bitmap ), set rest\n\t * of the block bitmap to 1\n\t */\n\text4_mark_bitmap_end(num_clusters_in_group(sb, block_group),\n\t\t\t     sb->s_blocksize * 8, bh->b_data);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,6 @@\n \tunsigned int bit, bit_max;\n \tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n \text4_fsblk_t start, tmp;\n-\tint flex_bg = 0;\n \n \tJ_ASSERT_BH(bh, buffer_locked(bh));\n \n@@ -29,22 +28,19 @@\n \n \tstart = ext4_group_first_block_no(sb, block_group);\n \n-\tif (ext4_has_feature_flex_bg(sb))\n-\t\tflex_bg = 1;\n-\n \t/* Set bits for block and inode bitmaps, and inode table */\n \ttmp = ext4_block_bitmap(sb, gdp);\n-\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n+\tif (ext4_block_in_group(sb, tmp, block_group))\n \t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n \n \ttmp = ext4_inode_bitmap(sb, gdp);\n-\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n+\tif (ext4_block_in_group(sb, tmp, block_group))\n \t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n \n \ttmp = ext4_inode_table(sb, gdp);\n \tfor (; tmp < ext4_inode_table(sb, gdp) +\n \t\t     sbi->s_itb_per_group; tmp++) {\n-\t\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))\n+\t\tif (ext4_block_in_group(sb, tmp, block_group))\n \t\t\text4_set_bit(EXT4_B2C(sbi, tmp - start), bh->b_data);\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tif (ext4_block_in_group(sb, tmp, block_group))",
                "\tif (ext4_block_in_group(sb, tmp, block_group))",
                "\t\tif (ext4_block_in_group(sb, tmp, block_group))"
            ],
            "deleted": [
                "\tint flex_bg = 0;",
                "\tif (ext4_has_feature_flex_bg(sb))",
                "\t\tflex_bg = 1;",
                "",
                "\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))",
                "\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))",
                "\t\tif (!flex_bg || ext4_block_in_group(sb, tmp, block_group))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bounds write and a denial of service or unspecified other impact is possible by mounting and operating a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-10880",
        "code_before_change": "static int ext4_xattr_make_inode_space(handle_t *handle, struct inode *inode,\n\t\t\t\t       struct ext4_inode *raw_inode,\n\t\t\t\t       int isize_diff, size_t ifree,\n\t\t\t\t       size_t bfree, int *total_ino)\n{\n\tstruct ext4_xattr_ibody_header *header = IHDR(inode, raw_inode);\n\tstruct ext4_xattr_entry *small_entry;\n\tstruct ext4_xattr_entry *entry;\n\tstruct ext4_xattr_entry *last;\n\tunsigned int entry_size;\t/* EA entry size */\n\tunsigned int total_size;\t/* EA entry size + value size */\n\tunsigned int min_total_size;\n\tint error;\n\n\twhile (isize_diff > ifree) {\n\t\tentry = NULL;\n\t\tsmall_entry = NULL;\n\t\tmin_total_size = ~0U;\n\t\tlast = IFIRST(header);\n\t\t/* Find the entry best suited to be pushed into EA block */\n\t\tfor (; !IS_LAST_ENTRY(last); last = EXT4_XATTR_NEXT(last)) {\n\t\t\ttotal_size = EXT4_XATTR_LEN(last->e_name_len);\n\t\t\tif (!last->e_value_inum)\n\t\t\t\ttotal_size += EXT4_XATTR_SIZE(\n\t\t\t\t\t       le32_to_cpu(last->e_value_size));\n\t\t\tif (total_size <= bfree &&\n\t\t\t    total_size < min_total_size) {\n\t\t\t\tif (total_size + ifree < isize_diff) {\n\t\t\t\t\tsmall_entry = last;\n\t\t\t\t} else {\n\t\t\t\t\tentry = last;\n\t\t\t\t\tmin_total_size = total_size;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (entry == NULL) {\n\t\t\tif (small_entry == NULL)\n\t\t\t\treturn -ENOSPC;\n\t\t\tentry = small_entry;\n\t\t}\n\n\t\tentry_size = EXT4_XATTR_LEN(entry->e_name_len);\n\t\ttotal_size = entry_size;\n\t\tif (!entry->e_value_inum)\n\t\t\ttotal_size += EXT4_XATTR_SIZE(\n\t\t\t\t\t      le32_to_cpu(entry->e_value_size));\n\t\terror = ext4_xattr_move_to_block(handle, inode, raw_inode,\n\t\t\t\t\t\t entry);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\t*total_ino -= entry_size;\n\t\tifree += total_size;\n\t\tbfree -= total_size;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int ext4_xattr_make_inode_space(handle_t *handle, struct inode *inode,\n\t\t\t\t       struct ext4_inode *raw_inode,\n\t\t\t\t       int isize_diff, size_t ifree,\n\t\t\t\t       size_t bfree, int *total_ino)\n{\n\tstruct ext4_xattr_ibody_header *header = IHDR(inode, raw_inode);\n\tstruct ext4_xattr_entry *small_entry;\n\tstruct ext4_xattr_entry *entry;\n\tstruct ext4_xattr_entry *last;\n\tunsigned int entry_size;\t/* EA entry size */\n\tunsigned int total_size;\t/* EA entry size + value size */\n\tunsigned int min_total_size;\n\tint error;\n\n\twhile (isize_diff > ifree) {\n\t\tentry = NULL;\n\t\tsmall_entry = NULL;\n\t\tmin_total_size = ~0U;\n\t\tlast = IFIRST(header);\n\t\t/* Find the entry best suited to be pushed into EA block */\n\t\tfor (; !IS_LAST_ENTRY(last); last = EXT4_XATTR_NEXT(last)) {\n\t\t\t/* never move system.data out of the inode */\n\t\t\tif ((last->e_name_len == 4) &&\n\t\t\t    (last->e_name_index == EXT4_XATTR_INDEX_SYSTEM) &&\n\t\t\t    !memcmp(last->e_name, \"data\", 4))\n\t\t\t\tcontinue;\n\t\t\ttotal_size = EXT4_XATTR_LEN(last->e_name_len);\n\t\t\tif (!last->e_value_inum)\n\t\t\t\ttotal_size += EXT4_XATTR_SIZE(\n\t\t\t\t\t       le32_to_cpu(last->e_value_size));\n\t\t\tif (total_size <= bfree &&\n\t\t\t    total_size < min_total_size) {\n\t\t\t\tif (total_size + ifree < isize_diff) {\n\t\t\t\t\tsmall_entry = last;\n\t\t\t\t} else {\n\t\t\t\t\tentry = last;\n\t\t\t\t\tmin_total_size = total_size;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (entry == NULL) {\n\t\t\tif (small_entry == NULL)\n\t\t\t\treturn -ENOSPC;\n\t\t\tentry = small_entry;\n\t\t}\n\n\t\tentry_size = EXT4_XATTR_LEN(entry->e_name_len);\n\t\ttotal_size = entry_size;\n\t\tif (!entry->e_value_inum)\n\t\t\ttotal_size += EXT4_XATTR_SIZE(\n\t\t\t\t\t      le32_to_cpu(entry->e_value_size));\n\t\terror = ext4_xattr_move_to_block(handle, inode, raw_inode,\n\t\t\t\t\t\t entry);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\t*total_ino -= entry_size;\n\t\tifree += total_size;\n\t\tbfree -= total_size;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,11 @@\n \t\tlast = IFIRST(header);\n \t\t/* Find the entry best suited to be pushed into EA block */\n \t\tfor (; !IS_LAST_ENTRY(last); last = EXT4_XATTR_NEXT(last)) {\n+\t\t\t/* never move system.data out of the inode */\n+\t\t\tif ((last->e_name_len == 4) &&\n+\t\t\t    (last->e_name_index == EXT4_XATTR_INDEX_SYSTEM) &&\n+\t\t\t    !memcmp(last->e_name, \"data\", 4))\n+\t\t\t\tcontinue;\n \t\t\ttotal_size = EXT4_XATTR_LEN(last->e_name_len);\n \t\t\tif (!last->e_value_inum)\n \t\t\t\ttotal_size += EXT4_XATTR_SIZE(",
        "function_modified_lines": {
            "added": [
                "\t\t\t/* never move system.data out of the inode */",
                "\t\t\tif ((last->e_name_len == 4) &&",
                "\t\t\t    (last->e_name_index == EXT4_XATTR_INDEX_SYSTEM) &&",
                "\t\t\t    !memcmp(last->e_name, \"data\", 4))",
                "\t\t\t\tcontinue;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Linux kernel is vulnerable to a stack-out-of-bounds write in the ext4 filesystem code when mounting and writing to a crafted ext4 image in ext4_update_inline_data(). An attacker could use this to cause a system crash and a denial of service."
    },
    {
        "cve_id": "CVE-2018-10881",
        "code_before_change": "static int ext4_destroy_inline_data_nolock(handle_t *handle,\n\t\t\t\t\t   struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_xattr_ibody_find is = {\n\t\t.s = { .not_found = 0, },\n\t};\n\tstruct ext4_xattr_info i = {\n\t\t.name_index = EXT4_XATTR_INDEX_SYSTEM,\n\t\t.name = EXT4_XATTR_SYSTEM_DATA,\n\t\t.value = NULL,\n\t\t.value_len = 0,\n\t};\n\tint error;\n\n\tif (!ei->i_inline_off)\n\t\treturn 0;\n\n\terror = ext4_get_inode_loc(inode, &is.iloc);\n\tif (error)\n\t\treturn error;\n\n\terror = ext4_xattr_ibody_find(inode, &i, &is);\n\tif (error)\n\t\tgoto out;\n\n\tBUFFER_TRACE(is.iloc.bh, \"get_write_access\");\n\terror = ext4_journal_get_write_access(handle, is.iloc.bh);\n\tif (error)\n\t\tgoto out;\n\n\terror = ext4_xattr_ibody_inline_set(handle, inode, &i, &is);\n\tif (error)\n\t\tgoto out;\n\n\tmemset((void *)ext4_raw_inode(&is.iloc)->i_block,\n\t\t0, EXT4_MIN_INLINE_DATA_SIZE);\n\n\tif (ext4_has_feature_extents(inode->i_sb)) {\n\t\tif (S_ISDIR(inode->i_mode) ||\n\t\t    S_ISREG(inode->i_mode) || S_ISLNK(inode->i_mode)) {\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_EXTENTS);\n\t\t\text4_ext_tree_init(handle, inode);\n\t\t}\n\t}\n\text4_clear_inode_flag(inode, EXT4_INODE_INLINE_DATA);\n\n\tget_bh(is.iloc.bh);\n\terror = ext4_mark_iloc_dirty(handle, inode, &is.iloc);\n\n\tEXT4_I(inode)->i_inline_off = 0;\n\tEXT4_I(inode)->i_inline_size = 0;\n\text4_clear_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA);\nout:\n\tbrelse(is.iloc.bh);\n\tif (error == -ENODATA)\n\t\terror = 0;\n\treturn error;\n}",
        "code_after_change": "static int ext4_destroy_inline_data_nolock(handle_t *handle,\n\t\t\t\t\t   struct inode *inode)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_xattr_ibody_find is = {\n\t\t.s = { .not_found = 0, },\n\t};\n\tstruct ext4_xattr_info i = {\n\t\t.name_index = EXT4_XATTR_INDEX_SYSTEM,\n\t\t.name = EXT4_XATTR_SYSTEM_DATA,\n\t\t.value = NULL,\n\t\t.value_len = 0,\n\t};\n\tint error;\n\n\tif (!ei->i_inline_off)\n\t\treturn 0;\n\n\terror = ext4_get_inode_loc(inode, &is.iloc);\n\tif (error)\n\t\treturn error;\n\n\terror = ext4_xattr_ibody_find(inode, &i, &is);\n\tif (error)\n\t\tgoto out;\n\n\tBUFFER_TRACE(is.iloc.bh, \"get_write_access\");\n\terror = ext4_journal_get_write_access(handle, is.iloc.bh);\n\tif (error)\n\t\tgoto out;\n\n\terror = ext4_xattr_ibody_inline_set(handle, inode, &i, &is);\n\tif (error)\n\t\tgoto out;\n\n\tmemset((void *)ext4_raw_inode(&is.iloc)->i_block,\n\t\t0, EXT4_MIN_INLINE_DATA_SIZE);\n\tmemset(ei->i_data, 0, EXT4_MIN_INLINE_DATA_SIZE);\n\n\tif (ext4_has_feature_extents(inode->i_sb)) {\n\t\tif (S_ISDIR(inode->i_mode) ||\n\t\t    S_ISREG(inode->i_mode) || S_ISLNK(inode->i_mode)) {\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_EXTENTS);\n\t\t\text4_ext_tree_init(handle, inode);\n\t\t}\n\t}\n\text4_clear_inode_flag(inode, EXT4_INODE_INLINE_DATA);\n\n\tget_bh(is.iloc.bh);\n\terror = ext4_mark_iloc_dirty(handle, inode, &is.iloc);\n\n\tEXT4_I(inode)->i_inline_off = 0;\n\tEXT4_I(inode)->i_inline_size = 0;\n\text4_clear_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA);\nout:\n\tbrelse(is.iloc.bh);\n\tif (error == -ENODATA)\n\t\terror = 0;\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,6 +35,7 @@\n \n \tmemset((void *)ext4_raw_inode(&is.iloc)->i_block,\n \t\t0, EXT4_MIN_INLINE_DATA_SIZE);\n+\tmemset(ei->i_data, 0, EXT4_MIN_INLINE_DATA_SIZE);\n \n \tif (ext4_has_feature_extents(inode->i_sb)) {\n \t\tif (S_ISDIR(inode->i_mode) ||",
        "function_modified_lines": {
            "added": [
                "\tmemset(ei->i_data, 0, EXT4_MIN_INLINE_DATA_SIZE);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bound access in ext4_get_group_info function, a denial of service, and a system crash by mounting and operating on a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-10882",
        "code_before_change": "static inline int ext4_valid_inum(struct super_block *sb, unsigned long ino)\n{\n\treturn ino == EXT4_ROOT_INO ||\n\t\tino == EXT4_USR_QUOTA_INO ||\n\t\tino == EXT4_GRP_QUOTA_INO ||\n\t\tino == EXT4_BOOT_LOADER_INO ||\n\t\tino == EXT4_JOURNAL_INO ||\n\t\tino == EXT4_RESIZE_INO ||\n\t\t(ino >= EXT4_FIRST_INO(sb) &&\n\t\t ino <= le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count));\n}",
        "code_after_change": "static inline int ext4_valid_inum(struct super_block *sb, unsigned long ino)\n{\n\treturn ino == EXT4_ROOT_INO ||\n\t\t(ino >= EXT4_FIRST_INO(sb) &&\n\t\t ino <= le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count));\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,11 +1,6 @@\n static inline int ext4_valid_inum(struct super_block *sb, unsigned long ino)\n {\n \treturn ino == EXT4_ROOT_INO ||\n-\t\tino == EXT4_USR_QUOTA_INO ||\n-\t\tino == EXT4_GRP_QUOTA_INO ||\n-\t\tino == EXT4_BOOT_LOADER_INO ||\n-\t\tino == EXT4_JOURNAL_INO ||\n-\t\tino == EXT4_RESIZE_INO ||\n \t\t(ino >= EXT4_FIRST_INO(sb) &&\n \t\t ino <= le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count));\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tino == EXT4_USR_QUOTA_INO ||",
                "\t\tino == EXT4_GRP_QUOTA_INO ||",
                "\t\tino == EXT4_BOOT_LOADER_INO ||",
                "\t\tino == EXT4_JOURNAL_INO ||",
                "\t\tino == EXT4_RESIZE_INO ||"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bound write in in fs/jbd2/transaction.c code, a denial of service, and a system crash by unmounting a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-10882",
        "code_before_change": "static int __ext4_get_inode_loc(struct inode *inode,\n\t\t\t\tstruct ext4_iloc *iloc, int in_mem)\n{\n\tstruct ext4_group_desc\t*gdp;\n\tstruct buffer_head\t*bh;\n\tstruct super_block\t*sb = inode->i_sb;\n\text4_fsblk_t\t\tblock;\n\tint\t\t\tinodes_per_block, inode_offset;\n\n\tiloc->bh = NULL;\n\tif (!ext4_valid_inum(sb, inode->i_ino))\n\t\treturn -EFSCORRUPTED;\n\n\tiloc->block_group = (inode->i_ino - 1) / EXT4_INODES_PER_GROUP(sb);\n\tgdp = ext4_get_group_desc(sb, iloc->block_group, NULL);\n\tif (!gdp)\n\t\treturn -EIO;\n\n\t/*\n\t * Figure out the offset within the block group inode table\n\t */\n\tinodes_per_block = EXT4_SB(sb)->s_inodes_per_block;\n\tinode_offset = ((inode->i_ino - 1) %\n\t\t\tEXT4_INODES_PER_GROUP(sb));\n\tblock = ext4_inode_table(sb, gdp) + (inode_offset / inodes_per_block);\n\tiloc->offset = (inode_offset % inodes_per_block) * EXT4_INODE_SIZE(sb);\n\n\tbh = sb_getblk(sb, block);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\tif (!buffer_uptodate(bh)) {\n\t\tlock_buffer(bh);\n\n\t\t/*\n\t\t * If the buffer has the write error flag, we have failed\n\t\t * to write out another inode in the same block.  In this\n\t\t * case, we don't have to read the block because we may\n\t\t * read the old inode data successfully.\n\t\t */\n\t\tif (buffer_write_io_error(bh) && !buffer_uptodate(bh))\n\t\t\tset_buffer_uptodate(bh);\n\n\t\tif (buffer_uptodate(bh)) {\n\t\t\t/* someone brought it uptodate while we waited */\n\t\t\tunlock_buffer(bh);\n\t\t\tgoto has_buffer;\n\t\t}\n\n\t\t/*\n\t\t * If we have all information of the inode in memory and this\n\t\t * is the only valid inode in the block, we need not read the\n\t\t * block.\n\t\t */\n\t\tif (in_mem) {\n\t\t\tstruct buffer_head *bitmap_bh;\n\t\t\tint i, start;\n\n\t\t\tstart = inode_offset & ~(inodes_per_block - 1);\n\n\t\t\t/* Is the inode bitmap in cache? */\n\t\t\tbitmap_bh = sb_getblk(sb, ext4_inode_bitmap(sb, gdp));\n\t\t\tif (unlikely(!bitmap_bh))\n\t\t\t\tgoto make_io;\n\n\t\t\t/*\n\t\t\t * If the inode bitmap isn't in cache then the\n\t\t\t * optimisation may end up performing two reads instead\n\t\t\t * of one, so skip it.\n\t\t\t */\n\t\t\tif (!buffer_uptodate(bitmap_bh)) {\n\t\t\t\tbrelse(bitmap_bh);\n\t\t\t\tgoto make_io;\n\t\t\t}\n\t\t\tfor (i = start; i < start + inodes_per_block; i++) {\n\t\t\t\tif (i == inode_offset)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (ext4_test_bit(i, bitmap_bh->b_data))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbrelse(bitmap_bh);\n\t\t\tif (i == start + inodes_per_block) {\n\t\t\t\t/* all other inodes are free, so skip I/O */\n\t\t\t\tmemset(bh->b_data, 0, bh->b_size);\n\t\t\t\tset_buffer_uptodate(bh);\n\t\t\t\tunlock_buffer(bh);\n\t\t\t\tgoto has_buffer;\n\t\t\t}\n\t\t}\n\nmake_io:\n\t\t/*\n\t\t * If we need to do any I/O, try to pre-readahead extra\n\t\t * blocks from the inode table.\n\t\t */\n\t\tif (EXT4_SB(sb)->s_inode_readahead_blks) {\n\t\t\text4_fsblk_t b, end, table;\n\t\t\tunsigned num;\n\t\t\t__u32 ra_blks = EXT4_SB(sb)->s_inode_readahead_blks;\n\n\t\t\ttable = ext4_inode_table(sb, gdp);\n\t\t\t/* s_inode_readahead_blks is always a power of 2 */\n\t\t\tb = block & ~((ext4_fsblk_t) ra_blks - 1);\n\t\t\tif (table > b)\n\t\t\t\tb = table;\n\t\t\tend = b + ra_blks;\n\t\t\tnum = EXT4_INODES_PER_GROUP(sb);\n\t\t\tif (ext4_has_group_desc_csum(sb))\n\t\t\t\tnum -= ext4_itable_unused_count(sb, gdp);\n\t\t\ttable += num / inodes_per_block;\n\t\t\tif (end > table)\n\t\t\t\tend = table;\n\t\t\twhile (b <= end)\n\t\t\t\tsb_breadahead(sb, b++);\n\t\t}\n\n\t\t/*\n\t\t * There are other valid inodes in the buffer, this inode\n\t\t * has in-inode xattrs, or we don't have this inode in memory.\n\t\t * Read the block from disk.\n\t\t */\n\t\ttrace_ext4_load_inode(inode);\n\t\tget_bh(bh);\n\t\tbh->b_end_io = end_buffer_read_sync;\n\t\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\t\twait_on_buffer(bh);\n\t\tif (!buffer_uptodate(bh)) {\n\t\t\tEXT4_ERROR_INODE_BLOCK(inode, block,\n\t\t\t\t\t       \"unable to read itable block\");\n\t\t\tbrelse(bh);\n\t\t\treturn -EIO;\n\t\t}\n\t}\nhas_buffer:\n\tiloc->bh = bh;\n\treturn 0;\n}",
        "code_after_change": "static int __ext4_get_inode_loc(struct inode *inode,\n\t\t\t\tstruct ext4_iloc *iloc, int in_mem)\n{\n\tstruct ext4_group_desc\t*gdp;\n\tstruct buffer_head\t*bh;\n\tstruct super_block\t*sb = inode->i_sb;\n\text4_fsblk_t\t\tblock;\n\tint\t\t\tinodes_per_block, inode_offset;\n\n\tiloc->bh = NULL;\n\tif (inode->i_ino < EXT4_ROOT_INO ||\n\t    inode->i_ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn -EFSCORRUPTED;\n\n\tiloc->block_group = (inode->i_ino - 1) / EXT4_INODES_PER_GROUP(sb);\n\tgdp = ext4_get_group_desc(sb, iloc->block_group, NULL);\n\tif (!gdp)\n\t\treturn -EIO;\n\n\t/*\n\t * Figure out the offset within the block group inode table\n\t */\n\tinodes_per_block = EXT4_SB(sb)->s_inodes_per_block;\n\tinode_offset = ((inode->i_ino - 1) %\n\t\t\tEXT4_INODES_PER_GROUP(sb));\n\tblock = ext4_inode_table(sb, gdp) + (inode_offset / inodes_per_block);\n\tiloc->offset = (inode_offset % inodes_per_block) * EXT4_INODE_SIZE(sb);\n\n\tbh = sb_getblk(sb, block);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\tif (!buffer_uptodate(bh)) {\n\t\tlock_buffer(bh);\n\n\t\t/*\n\t\t * If the buffer has the write error flag, we have failed\n\t\t * to write out another inode in the same block.  In this\n\t\t * case, we don't have to read the block because we may\n\t\t * read the old inode data successfully.\n\t\t */\n\t\tif (buffer_write_io_error(bh) && !buffer_uptodate(bh))\n\t\t\tset_buffer_uptodate(bh);\n\n\t\tif (buffer_uptodate(bh)) {\n\t\t\t/* someone brought it uptodate while we waited */\n\t\t\tunlock_buffer(bh);\n\t\t\tgoto has_buffer;\n\t\t}\n\n\t\t/*\n\t\t * If we have all information of the inode in memory and this\n\t\t * is the only valid inode in the block, we need not read the\n\t\t * block.\n\t\t */\n\t\tif (in_mem) {\n\t\t\tstruct buffer_head *bitmap_bh;\n\t\t\tint i, start;\n\n\t\t\tstart = inode_offset & ~(inodes_per_block - 1);\n\n\t\t\t/* Is the inode bitmap in cache? */\n\t\t\tbitmap_bh = sb_getblk(sb, ext4_inode_bitmap(sb, gdp));\n\t\t\tif (unlikely(!bitmap_bh))\n\t\t\t\tgoto make_io;\n\n\t\t\t/*\n\t\t\t * If the inode bitmap isn't in cache then the\n\t\t\t * optimisation may end up performing two reads instead\n\t\t\t * of one, so skip it.\n\t\t\t */\n\t\t\tif (!buffer_uptodate(bitmap_bh)) {\n\t\t\t\tbrelse(bitmap_bh);\n\t\t\t\tgoto make_io;\n\t\t\t}\n\t\t\tfor (i = start; i < start + inodes_per_block; i++) {\n\t\t\t\tif (i == inode_offset)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (ext4_test_bit(i, bitmap_bh->b_data))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbrelse(bitmap_bh);\n\t\t\tif (i == start + inodes_per_block) {\n\t\t\t\t/* all other inodes are free, so skip I/O */\n\t\t\t\tmemset(bh->b_data, 0, bh->b_size);\n\t\t\t\tset_buffer_uptodate(bh);\n\t\t\t\tunlock_buffer(bh);\n\t\t\t\tgoto has_buffer;\n\t\t\t}\n\t\t}\n\nmake_io:\n\t\t/*\n\t\t * If we need to do any I/O, try to pre-readahead extra\n\t\t * blocks from the inode table.\n\t\t */\n\t\tif (EXT4_SB(sb)->s_inode_readahead_blks) {\n\t\t\text4_fsblk_t b, end, table;\n\t\t\tunsigned num;\n\t\t\t__u32 ra_blks = EXT4_SB(sb)->s_inode_readahead_blks;\n\n\t\t\ttable = ext4_inode_table(sb, gdp);\n\t\t\t/* s_inode_readahead_blks is always a power of 2 */\n\t\t\tb = block & ~((ext4_fsblk_t) ra_blks - 1);\n\t\t\tif (table > b)\n\t\t\t\tb = table;\n\t\t\tend = b + ra_blks;\n\t\t\tnum = EXT4_INODES_PER_GROUP(sb);\n\t\t\tif (ext4_has_group_desc_csum(sb))\n\t\t\t\tnum -= ext4_itable_unused_count(sb, gdp);\n\t\t\ttable += num / inodes_per_block;\n\t\t\tif (end > table)\n\t\t\t\tend = table;\n\t\t\twhile (b <= end)\n\t\t\t\tsb_breadahead(sb, b++);\n\t\t}\n\n\t\t/*\n\t\t * There are other valid inodes in the buffer, this inode\n\t\t * has in-inode xattrs, or we don't have this inode in memory.\n\t\t * Read the block from disk.\n\t\t */\n\t\ttrace_ext4_load_inode(inode);\n\t\tget_bh(bh);\n\t\tbh->b_end_io = end_buffer_read_sync;\n\t\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\t\twait_on_buffer(bh);\n\t\tif (!buffer_uptodate(bh)) {\n\t\t\tEXT4_ERROR_INODE_BLOCK(inode, block,\n\t\t\t\t\t       \"unable to read itable block\");\n\t\t\tbrelse(bh);\n\t\t\treturn -EIO;\n\t\t}\n\t}\nhas_buffer:\n\tiloc->bh = bh;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,8 @@\n \tint\t\t\tinodes_per_block, inode_offset;\n \n \tiloc->bh = NULL;\n-\tif (!ext4_valid_inum(sb, inode->i_ino))\n+\tif (inode->i_ino < EXT4_ROOT_INO ||\n+\t    inode->i_ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n \t\treturn -EFSCORRUPTED;\n \n \tiloc->block_group = (inode->i_ino - 1) / EXT4_INODES_PER_GROUP(sb);",
        "function_modified_lines": {
            "added": [
                "\tif (inode->i_ino < EXT4_ROOT_INO ||",
                "\t    inode->i_ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))"
            ],
            "deleted": [
                "\tif (!ext4_valid_inum(sb, inode->i_ino))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bound write in in fs/jbd2/transaction.c code, a denial of service, and a system crash by unmounting a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-10882",
        "code_before_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct dax_device *dax_dev = fs_dax_get_by_bdev(sb->s_bdev);\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_daxdev = dax_dev;\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\tsbi->s_chksum_driver = NULL;\n\t\tgoto failed_mount;\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb) || ext4_has_feature_ea_inode(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (ext4_has_feature_encrypt(sb)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"encrypted files will use data=ordered \"\n\t\t\t\t \"instead of data journaling mode\");\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? SB_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\t/*\n\t\t * ea_inode feature uses l_i_version field which is not\n\t\t * available in HURD_COMPAT mode.\n\t\t */\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"ea_inode feature is not supported for Hurd\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext[34] filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext4 filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb_rdonly(sb))))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\tif (ext4_has_feature_inline_data(sb)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot use DAX on a filesystem\"\n\t\t\t\t\t\" that may contain inline data\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"DAX unsupported by block device. Turning off DAX.\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) > db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\t/* Pre-read the descriptors into the buffer cache */\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsb_breadahead(sb, block);\n\t}\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\n\ttimer_setup(&sbi->s_err_report, print_daily_error_info, 0);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tsb->s_cop = &ext4_cryptops;\n#endif\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(&sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !sb_rdonly(sb))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\terr = ext4_load_journal(sb, es, journal_devnum);\n\t\tif (err)\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !sb_rdonly(sb) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\t\tsbi->s_def_mount_opt |= EXT4_MOUNT_ORDERED_DATA;\n\t\t} else {\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\t\tsbi->s_def_mount_opt |= EXT4_MOUNT_JOURNAL_DATA;\n\t\t}\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\"journal_async_commit in data=ordered mode\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tif (!test_opt(sb, NO_MBCACHE)) {\n\t\tsbi->s_ea_block_cache = ext4_xattr_create_cache();\n\t\tif (!sbi->s_ea_block_cache) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Failed to create ea_block_cache\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\tsbi->s_ea_inode_cache = ext4_xattr_create_cache();\n\t\t\tif (!sbi->s_ea_inode_cache) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Failed to create ea_inode_cache\");\n\t\t\t\tgoto failed_mount_wq;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !sb_rdonly(sb) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tret = ext4_setup_super(sb, es, sb_rdonly(sb));\n\tif (ret == -EROFS) {\n\t\tsb->s_flags |= SB_RDONLY;\n\t\tret = 0;\n\t} else if (ret)\n\t\tgoto failed_mount4a;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    sbi->s_want_extra_isize == 0) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !sb_rdonly(sb)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_ea_inode_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_inode_cache);\n\t\tsbi->s_ea_inode_cache = NULL;\n\t}\n\tif (sbi->s_ea_block_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_block_cache);\n\t\tsbi->s_ea_block_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\tfs_put_dax(dax_dev);\n\treturn err ? err : ret;\n}",
        "code_after_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct dax_device *dax_dev = fs_dax_get_by_bdev(sb->s_bdev);\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_daxdev = dax_dev;\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\tsbi->s_chksum_driver = NULL;\n\t\tgoto failed_mount;\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb) || ext4_has_feature_ea_inode(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (ext4_has_feature_encrypt(sb)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"encrypted files will use data=ordered \"\n\t\t\t\t \"instead of data journaling mode\");\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? SB_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\t/*\n\t\t * ea_inode feature uses l_i_version field which is not\n\t\t * available in HURD_COMPAT mode.\n\t\t */\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"ea_inode feature is not supported for Hurd\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext[34] filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext4 filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb_rdonly(sb))))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\tif (ext4_has_feature_inline_data(sb)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot use DAX on a filesystem\"\n\t\t\t\t\t\" that may contain inline data\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"DAX unsupported by block device. Turning off DAX.\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif (sbi->s_first_ino < EXT4_GOOD_OLD_FIRST_INO) {\n\t\t\text4_msg(sb, KERN_ERR, \"invalid first ino: %u\",\n\t\t\t\t sbi->s_first_ino);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) > db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\t/* Pre-read the descriptors into the buffer cache */\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsb_breadahead(sb, block);\n\t}\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\n\ttimer_setup(&sbi->s_err_report, print_daily_error_info, 0);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tsb->s_cop = &ext4_cryptops;\n#endif\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(&sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !sb_rdonly(sb))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\terr = ext4_load_journal(sb, es, journal_devnum);\n\t\tif (err)\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !sb_rdonly(sb) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\t\tsbi->s_def_mount_opt |= EXT4_MOUNT_ORDERED_DATA;\n\t\t} else {\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\t\tsbi->s_def_mount_opt |= EXT4_MOUNT_JOURNAL_DATA;\n\t\t}\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\"journal_async_commit in data=ordered mode\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tif (!test_opt(sb, NO_MBCACHE)) {\n\t\tsbi->s_ea_block_cache = ext4_xattr_create_cache();\n\t\tif (!sbi->s_ea_block_cache) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Failed to create ea_block_cache\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\tsbi->s_ea_inode_cache = ext4_xattr_create_cache();\n\t\t\tif (!sbi->s_ea_inode_cache) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Failed to create ea_inode_cache\");\n\t\t\t\tgoto failed_mount_wq;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !sb_rdonly(sb) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tret = ext4_setup_super(sb, es, sb_rdonly(sb));\n\tif (ret == -EROFS) {\n\t\tsb->s_flags |= SB_RDONLY;\n\t\tret = 0;\n\t} else if (ret)\n\t\tgoto failed_mount4a;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    sbi->s_want_extra_isize == 0) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !sb_rdonly(sb)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_ea_inode_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_inode_cache);\n\t\tsbi->s_ea_inode_cache = NULL;\n\t}\n\tif (sbi->s_ea_block_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_block_cache);\n\t\tsbi->s_ea_block_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\tfs_put_dax(dax_dev);\n\treturn err ? err : ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -376,6 +376,11 @@\n \t} else {\n \t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n \t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n+\t\tif (sbi->s_first_ino < EXT4_GOOD_OLD_FIRST_INO) {\n+\t\t\text4_msg(sb, KERN_ERR, \"invalid first ino: %u\",\n+\t\t\t\t sbi->s_first_ino);\n+\t\t\tgoto failed_mount;\n+\t\t}\n \t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n \t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n \t\t    (sbi->s_inode_size > blocksize)) {",
        "function_modified_lines": {
            "added": [
                "\t\tif (sbi->s_first_ino < EXT4_GOOD_OLD_FIRST_INO) {",
                "\t\t\text4_msg(sb, KERN_ERR, \"invalid first ino: %u\",",
                "\t\t\t\t sbi->s_first_ino);",
                "\t\t\tgoto failed_mount;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bound write in in fs/jbd2/transaction.c code, a denial of service, and a system crash by unmounting a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-10883",
        "code_before_change": "int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)\n{\n\ttransaction_t *transaction = handle->h_transaction;\n\tjournal_t *journal;\n\tstruct journal_head *jh;\n\tint ret = 0;\n\n\tif (is_handle_aborted(handle))\n\t\treturn -EROFS;\n\tif (!buffer_jbd(bh)) {\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\t/*\n\t * We don't grab jh reference here since the buffer must be part\n\t * of the running transaction.\n\t */\n\tjh = bh2jh(bh);\n\t/*\n\t * This and the following assertions are unreliable since we may see jh\n\t * in inconsistent state unless we grab bh_state lock. But this is\n\t * crucial to catch bugs so let's do a reliable check until the\n\t * lockless handling is fully proven.\n\t */\n\tif (jh->b_transaction != transaction &&\n\t    jh->b_next_transaction != transaction) {\n\t\tjbd_lock_bh_state(bh);\n\t\tJ_ASSERT_JH(jh, jh->b_transaction == transaction ||\n\t\t\t\tjh->b_next_transaction == transaction);\n\t\tjbd_unlock_bh_state(bh);\n\t}\n\tif (jh->b_modified == 1) {\n\t\t/* If it's in our transaction it must be in BJ_Metadata list. */\n\t\tif (jh->b_transaction == transaction &&\n\t\t    jh->b_jlist != BJ_Metadata) {\n\t\t\tjbd_lock_bh_state(bh);\n\t\t\tJ_ASSERT_JH(jh, jh->b_transaction != transaction ||\n\t\t\t\t\tjh->b_jlist == BJ_Metadata);\n\t\t\tjbd_unlock_bh_state(bh);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tjournal = transaction->t_journal;\n\tjbd_debug(5, \"journal_head %p\\n\", jh);\n\tJBUFFER_TRACE(jh, \"entry\");\n\n\tjbd_lock_bh_state(bh);\n\n\tif (jh->b_modified == 0) {\n\t\t/*\n\t\t * This buffer's got modified and becoming part\n\t\t * of the transaction. This needs to be done\n\t\t * once a transaction -bzzz\n\t\t */\n\t\tjh->b_modified = 1;\n\t\tif (handle->h_buffer_credits <= 0) {\n\t\t\tret = -ENOSPC;\n\t\t\tgoto out_unlock_bh;\n\t\t}\n\t\thandle->h_buffer_credits--;\n\t}\n\n\t/*\n\t * fastpath, to avoid expensive locking.  If this buffer is already\n\t * on the running transaction's metadata list there is nothing to do.\n\t * Nobody can take it off again because there is a handle open.\n\t * I _think_ we're OK here with SMP barriers - a mistaken decision will\n\t * result in this test being false, so we go in and take the locks.\n\t */\n\tif (jh->b_transaction == transaction && jh->b_jlist == BJ_Metadata) {\n\t\tJBUFFER_TRACE(jh, \"fastpath\");\n\t\tif (unlikely(jh->b_transaction !=\n\t\t\t     journal->j_running_transaction)) {\n\t\t\tprintk(KERN_ERR \"JBD2: %s: \"\n\t\t\t       \"jh->b_transaction (%llu, %p, %u) != \"\n\t\t\t       \"journal->j_running_transaction (%p, %u)\\n\",\n\t\t\t       journal->j_devname,\n\t\t\t       (unsigned long long) bh->b_blocknr,\n\t\t\t       jh->b_transaction,\n\t\t\t       jh->b_transaction ? jh->b_transaction->t_tid : 0,\n\t\t\t       journal->j_running_transaction,\n\t\t\t       journal->j_running_transaction ?\n\t\t\t       journal->j_running_transaction->t_tid : 0);\n\t\t\tret = -EINVAL;\n\t\t}\n\t\tgoto out_unlock_bh;\n\t}\n\n\tset_buffer_jbddirty(bh);\n\n\t/*\n\t * Metadata already on the current transaction list doesn't\n\t * need to be filed.  Metadata on another transaction's list must\n\t * be committing, and will be refiled once the commit completes:\n\t * leave it alone for now.\n\t */\n\tif (jh->b_transaction != transaction) {\n\t\tJBUFFER_TRACE(jh, \"already on other transaction\");\n\t\tif (unlikely(((jh->b_transaction !=\n\t\t\t       journal->j_committing_transaction)) ||\n\t\t\t     (jh->b_next_transaction != transaction))) {\n\t\t\tprintk(KERN_ERR \"jbd2_journal_dirty_metadata: %s: \"\n\t\t\t       \"bad jh for block %llu: \"\n\t\t\t       \"transaction (%p, %u), \"\n\t\t\t       \"jh->b_transaction (%p, %u), \"\n\t\t\t       \"jh->b_next_transaction (%p, %u), jlist %u\\n\",\n\t\t\t       journal->j_devname,\n\t\t\t       (unsigned long long) bh->b_blocknr,\n\t\t\t       transaction, transaction->t_tid,\n\t\t\t       jh->b_transaction,\n\t\t\t       jh->b_transaction ?\n\t\t\t       jh->b_transaction->t_tid : 0,\n\t\t\t       jh->b_next_transaction,\n\t\t\t       jh->b_next_transaction ?\n\t\t\t       jh->b_next_transaction->t_tid : 0,\n\t\t\t       jh->b_jlist);\n\t\t\tWARN_ON(1);\n\t\t\tret = -EINVAL;\n\t\t}\n\t\t/* And this case is illegal: we can't reuse another\n\t\t * transaction's data buffer, ever. */\n\t\tgoto out_unlock_bh;\n\t}\n\n\t/* That test should have eliminated the following case: */\n\tJ_ASSERT_JH(jh, jh->b_frozen_data == NULL);\n\n\tJBUFFER_TRACE(jh, \"file as BJ_Metadata\");\n\tspin_lock(&journal->j_list_lock);\n\t__jbd2_journal_file_buffer(jh, transaction, BJ_Metadata);\n\tspin_unlock(&journal->j_list_lock);\nout_unlock_bh:\n\tjbd_unlock_bh_state(bh);\nout:\n\tJBUFFER_TRACE(jh, \"exit\");\n\treturn ret;\n}",
        "code_after_change": "int jbd2_journal_dirty_metadata(handle_t *handle, struct buffer_head *bh)\n{\n\ttransaction_t *transaction = handle->h_transaction;\n\tjournal_t *journal;\n\tstruct journal_head *jh;\n\tint ret = 0;\n\n\tif (is_handle_aborted(handle))\n\t\treturn -EROFS;\n\tif (!buffer_jbd(bh)) {\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\t/*\n\t * We don't grab jh reference here since the buffer must be part\n\t * of the running transaction.\n\t */\n\tjh = bh2jh(bh);\n\t/*\n\t * This and the following assertions are unreliable since we may see jh\n\t * in inconsistent state unless we grab bh_state lock. But this is\n\t * crucial to catch bugs so let's do a reliable check until the\n\t * lockless handling is fully proven.\n\t */\n\tif (jh->b_transaction != transaction &&\n\t    jh->b_next_transaction != transaction) {\n\t\tjbd_lock_bh_state(bh);\n\t\tJ_ASSERT_JH(jh, jh->b_transaction == transaction ||\n\t\t\t\tjh->b_next_transaction == transaction);\n\t\tjbd_unlock_bh_state(bh);\n\t}\n\tif (jh->b_modified == 1) {\n\t\t/* If it's in our transaction it must be in BJ_Metadata list. */\n\t\tif (jh->b_transaction == transaction &&\n\t\t    jh->b_jlist != BJ_Metadata) {\n\t\t\tjbd_lock_bh_state(bh);\n\t\t\tif (jh->b_transaction == transaction &&\n\t\t\t    jh->b_jlist != BJ_Metadata)\n\t\t\t\tpr_err(\"JBD2: assertion failure: h_type=%u \"\n\t\t\t\t       \"h_line_no=%u block_no=%llu jlist=%u\\n\",\n\t\t\t\t       handle->h_type, handle->h_line_no,\n\t\t\t\t       (unsigned long long) bh->b_blocknr,\n\t\t\t\t       jh->b_jlist);\n\t\t\tJ_ASSERT_JH(jh, jh->b_transaction != transaction ||\n\t\t\t\t\tjh->b_jlist == BJ_Metadata);\n\t\t\tjbd_unlock_bh_state(bh);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tjournal = transaction->t_journal;\n\tjbd_debug(5, \"journal_head %p\\n\", jh);\n\tJBUFFER_TRACE(jh, \"entry\");\n\n\tjbd_lock_bh_state(bh);\n\n\tif (jh->b_modified == 0) {\n\t\t/*\n\t\t * This buffer's got modified and becoming part\n\t\t * of the transaction. This needs to be done\n\t\t * once a transaction -bzzz\n\t\t */\n\t\tif (handle->h_buffer_credits <= 0) {\n\t\t\tret = -ENOSPC;\n\t\t\tgoto out_unlock_bh;\n\t\t}\n\t\tjh->b_modified = 1;\n\t\thandle->h_buffer_credits--;\n\t}\n\n\t/*\n\t * fastpath, to avoid expensive locking.  If this buffer is already\n\t * on the running transaction's metadata list there is nothing to do.\n\t * Nobody can take it off again because there is a handle open.\n\t * I _think_ we're OK here with SMP barriers - a mistaken decision will\n\t * result in this test being false, so we go in and take the locks.\n\t */\n\tif (jh->b_transaction == transaction && jh->b_jlist == BJ_Metadata) {\n\t\tJBUFFER_TRACE(jh, \"fastpath\");\n\t\tif (unlikely(jh->b_transaction !=\n\t\t\t     journal->j_running_transaction)) {\n\t\t\tprintk(KERN_ERR \"JBD2: %s: \"\n\t\t\t       \"jh->b_transaction (%llu, %p, %u) != \"\n\t\t\t       \"journal->j_running_transaction (%p, %u)\\n\",\n\t\t\t       journal->j_devname,\n\t\t\t       (unsigned long long) bh->b_blocknr,\n\t\t\t       jh->b_transaction,\n\t\t\t       jh->b_transaction ? jh->b_transaction->t_tid : 0,\n\t\t\t       journal->j_running_transaction,\n\t\t\t       journal->j_running_transaction ?\n\t\t\t       journal->j_running_transaction->t_tid : 0);\n\t\t\tret = -EINVAL;\n\t\t}\n\t\tgoto out_unlock_bh;\n\t}\n\n\tset_buffer_jbddirty(bh);\n\n\t/*\n\t * Metadata already on the current transaction list doesn't\n\t * need to be filed.  Metadata on another transaction's list must\n\t * be committing, and will be refiled once the commit completes:\n\t * leave it alone for now.\n\t */\n\tif (jh->b_transaction != transaction) {\n\t\tJBUFFER_TRACE(jh, \"already on other transaction\");\n\t\tif (unlikely(((jh->b_transaction !=\n\t\t\t       journal->j_committing_transaction)) ||\n\t\t\t     (jh->b_next_transaction != transaction))) {\n\t\t\tprintk(KERN_ERR \"jbd2_journal_dirty_metadata: %s: \"\n\t\t\t       \"bad jh for block %llu: \"\n\t\t\t       \"transaction (%p, %u), \"\n\t\t\t       \"jh->b_transaction (%p, %u), \"\n\t\t\t       \"jh->b_next_transaction (%p, %u), jlist %u\\n\",\n\t\t\t       journal->j_devname,\n\t\t\t       (unsigned long long) bh->b_blocknr,\n\t\t\t       transaction, transaction->t_tid,\n\t\t\t       jh->b_transaction,\n\t\t\t       jh->b_transaction ?\n\t\t\t       jh->b_transaction->t_tid : 0,\n\t\t\t       jh->b_next_transaction,\n\t\t\t       jh->b_next_transaction ?\n\t\t\t       jh->b_next_transaction->t_tid : 0,\n\t\t\t       jh->b_jlist);\n\t\t\tWARN_ON(1);\n\t\t\tret = -EINVAL;\n\t\t}\n\t\t/* And this case is illegal: we can't reuse another\n\t\t * transaction's data buffer, ever. */\n\t\tgoto out_unlock_bh;\n\t}\n\n\t/* That test should have eliminated the following case: */\n\tJ_ASSERT_JH(jh, jh->b_frozen_data == NULL);\n\n\tJBUFFER_TRACE(jh, \"file as BJ_Metadata\");\n\tspin_lock(&journal->j_list_lock);\n\t__jbd2_journal_file_buffer(jh, transaction, BJ_Metadata);\n\tspin_unlock(&journal->j_list_lock);\nout_unlock_bh:\n\tjbd_unlock_bh_state(bh);\nout:\n\tJBUFFER_TRACE(jh, \"exit\");\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -34,6 +34,13 @@\n \t\tif (jh->b_transaction == transaction &&\n \t\t    jh->b_jlist != BJ_Metadata) {\n \t\t\tjbd_lock_bh_state(bh);\n+\t\t\tif (jh->b_transaction == transaction &&\n+\t\t\t    jh->b_jlist != BJ_Metadata)\n+\t\t\t\tpr_err(\"JBD2: assertion failure: h_type=%u \"\n+\t\t\t\t       \"h_line_no=%u block_no=%llu jlist=%u\\n\",\n+\t\t\t\t       handle->h_type, handle->h_line_no,\n+\t\t\t\t       (unsigned long long) bh->b_blocknr,\n+\t\t\t\t       jh->b_jlist);\n \t\t\tJ_ASSERT_JH(jh, jh->b_transaction != transaction ||\n \t\t\t\t\tjh->b_jlist == BJ_Metadata);\n \t\t\tjbd_unlock_bh_state(bh);\n@@ -53,11 +60,11 @@\n \t\t * of the transaction. This needs to be done\n \t\t * once a transaction -bzzz\n \t\t */\n-\t\tjh->b_modified = 1;\n \t\tif (handle->h_buffer_credits <= 0) {\n \t\t\tret = -ENOSPC;\n \t\t\tgoto out_unlock_bh;\n \t\t}\n+\t\tjh->b_modified = 1;\n \t\thandle->h_buffer_credits--;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (jh->b_transaction == transaction &&",
                "\t\t\t    jh->b_jlist != BJ_Metadata)",
                "\t\t\t\tpr_err(\"JBD2: assertion failure: h_type=%u \"",
                "\t\t\t\t       \"h_line_no=%u block_no=%llu jlist=%u\\n\",",
                "\t\t\t\t       handle->h_type, handle->h_line_no,",
                "\t\t\t\t       (unsigned long long) bh->b_blocknr,",
                "\t\t\t\t       jh->b_jlist);",
                "\t\tjh->b_modified = 1;"
            ],
            "deleted": [
                "\t\tjh->b_modified = 1;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ext4 filesystem. A local user can cause an out-of-bounds write in jbd2_journal_dirty_metadata(), a denial of service, and a system crash by mounting and operating on a crafted ext4 filesystem image."
    },
    {
        "cve_id": "CVE-2018-11506",
        "code_before_change": "int sr_do_ioctl(Scsi_CD *cd, struct packet_command *cgc)\n{\n\tstruct scsi_device *SDev;\n\tstruct scsi_sense_hdr sshdr;\n\tint result, err = 0, retries = 0;\n\n\tSDev = cd->device;\n\n      retry:\n\tif (!scsi_block_when_processing_errors(SDev)) {\n\t\terr = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tresult = scsi_execute(SDev, cgc->cmd, cgc->data_direction,\n\t\t\t      cgc->buffer, cgc->buflen,\n\t\t\t      (unsigned char *)cgc->sense, &sshdr,\n\t\t\t      cgc->timeout, IOCTL_RETRIES, 0, 0, NULL);\n\n\t/* Minimal error checking.  Ignore cases we know about, and report the rest. */\n\tif (driver_byte(result) != 0) {\n\t\tswitch (sshdr.sense_key) {\n\t\tcase UNIT_ATTENTION:\n\t\t\tSDev->changed = 1;\n\t\t\tif (!cgc->quiet)\n\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t  \"disc change detected.\\n\");\n\t\t\tif (retries++ < 10)\n\t\t\t\tgoto retry;\n\t\t\terr = -ENOMEDIUM;\n\t\t\tbreak;\n\t\tcase NOT_READY:\t/* This happens if there is no disc in drive */\n\t\t\tif (sshdr.asc == 0x04 &&\n\t\t\t    sshdr.ascq == 0x01) {\n\t\t\t\t/* sense: Logical unit is in process of becoming ready */\n\t\t\t\tif (!cgc->quiet)\n\t\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t\t  \"CDROM not ready yet.\\n\");\n\t\t\t\tif (retries++ < 10) {\n\t\t\t\t\t/* sleep 2 sec and try again */\n\t\t\t\t\tssleep(2);\n\t\t\t\t\tgoto retry;\n\t\t\t\t} else {\n\t\t\t\t\t/* 20 secs are enough? */\n\t\t\t\t\terr = -ENOMEDIUM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!cgc->quiet)\n\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t  \"CDROM not ready.  Make sure there \"\n\t\t\t\t\t  \"is a disc in the drive.\\n\");\n\t\t\terr = -ENOMEDIUM;\n\t\t\tbreak;\n\t\tcase ILLEGAL_REQUEST:\n\t\t\terr = -EIO;\n\t\t\tif (sshdr.asc == 0x20 &&\n\t\t\t    sshdr.ascq == 0x00)\n\t\t\t\t/* sense: Invalid command operation code */\n\t\t\t\terr = -EDRIVE_CANT_DO_THIS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr = -EIO;\n\t\t}\n\t}\n\n\t/* Wake up a process waiting for device */\n      out:\n\tcgc->stat = err;\n\treturn err;\n}",
        "code_after_change": "int sr_do_ioctl(Scsi_CD *cd, struct packet_command *cgc)\n{\n\tstruct scsi_device *SDev;\n\tstruct scsi_sense_hdr sshdr;\n\tint result, err = 0, retries = 0;\n\tunsigned char sense_buffer[SCSI_SENSE_BUFFERSIZE], *senseptr = NULL;\n\n\tSDev = cd->device;\n\n\tif (cgc->sense)\n\t\tsenseptr = sense_buffer;\n\n      retry:\n\tif (!scsi_block_when_processing_errors(SDev)) {\n\t\terr = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tresult = scsi_execute(SDev, cgc->cmd, cgc->data_direction,\n\t\t\t      cgc->buffer, cgc->buflen, senseptr, &sshdr,\n\t\t\t      cgc->timeout, IOCTL_RETRIES, 0, 0, NULL);\n\n\tif (cgc->sense)\n\t\tmemcpy(cgc->sense, sense_buffer, sizeof(*cgc->sense));\n\n\t/* Minimal error checking.  Ignore cases we know about, and report the rest. */\n\tif (driver_byte(result) != 0) {\n\t\tswitch (sshdr.sense_key) {\n\t\tcase UNIT_ATTENTION:\n\t\t\tSDev->changed = 1;\n\t\t\tif (!cgc->quiet)\n\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t  \"disc change detected.\\n\");\n\t\t\tif (retries++ < 10)\n\t\t\t\tgoto retry;\n\t\t\terr = -ENOMEDIUM;\n\t\t\tbreak;\n\t\tcase NOT_READY:\t/* This happens if there is no disc in drive */\n\t\t\tif (sshdr.asc == 0x04 &&\n\t\t\t    sshdr.ascq == 0x01) {\n\t\t\t\t/* sense: Logical unit is in process of becoming ready */\n\t\t\t\tif (!cgc->quiet)\n\t\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t\t  \"CDROM not ready yet.\\n\");\n\t\t\t\tif (retries++ < 10) {\n\t\t\t\t\t/* sleep 2 sec and try again */\n\t\t\t\t\tssleep(2);\n\t\t\t\t\tgoto retry;\n\t\t\t\t} else {\n\t\t\t\t\t/* 20 secs are enough? */\n\t\t\t\t\terr = -ENOMEDIUM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!cgc->quiet)\n\t\t\t\tsr_printk(KERN_INFO, cd,\n\t\t\t\t\t  \"CDROM not ready.  Make sure there \"\n\t\t\t\t\t  \"is a disc in the drive.\\n\");\n\t\t\terr = -ENOMEDIUM;\n\t\t\tbreak;\n\t\tcase ILLEGAL_REQUEST:\n\t\t\terr = -EIO;\n\t\t\tif (sshdr.asc == 0x20 &&\n\t\t\t    sshdr.ascq == 0x00)\n\t\t\t\t/* sense: Invalid command operation code */\n\t\t\t\terr = -EDRIVE_CANT_DO_THIS;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr = -EIO;\n\t\t}\n\t}\n\n\t/* Wake up a process waiting for device */\n      out:\n\tcgc->stat = err;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,8 +3,12 @@\n \tstruct scsi_device *SDev;\n \tstruct scsi_sense_hdr sshdr;\n \tint result, err = 0, retries = 0;\n+\tunsigned char sense_buffer[SCSI_SENSE_BUFFERSIZE], *senseptr = NULL;\n \n \tSDev = cd->device;\n+\n+\tif (cgc->sense)\n+\t\tsenseptr = sense_buffer;\n \n       retry:\n \tif (!scsi_block_when_processing_errors(SDev)) {\n@@ -13,9 +17,11 @@\n \t}\n \n \tresult = scsi_execute(SDev, cgc->cmd, cgc->data_direction,\n-\t\t\t      cgc->buffer, cgc->buflen,\n-\t\t\t      (unsigned char *)cgc->sense, &sshdr,\n+\t\t\t      cgc->buffer, cgc->buflen, senseptr, &sshdr,\n \t\t\t      cgc->timeout, IOCTL_RETRIES, 0, 0, NULL);\n+\n+\tif (cgc->sense)\n+\t\tmemcpy(cgc->sense, sense_buffer, sizeof(*cgc->sense));\n \n \t/* Minimal error checking.  Ignore cases we know about, and report the rest. */\n \tif (driver_byte(result) != 0) {",
        "function_modified_lines": {
            "added": [
                "\tunsigned char sense_buffer[SCSI_SENSE_BUFFERSIZE], *senseptr = NULL;",
                "",
                "\tif (cgc->sense)",
                "\t\tsenseptr = sense_buffer;",
                "\t\t\t      cgc->buffer, cgc->buflen, senseptr, &sshdr,",
                "",
                "\tif (cgc->sense)",
                "\t\tmemcpy(cgc->sense, sense_buffer, sizeof(*cgc->sense));"
            ],
            "deleted": [
                "\t\t\t      cgc->buffer, cgc->buflen,",
                "\t\t\t      (unsigned char *)cgc->sense, &sshdr,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The sr_do_ioctl function in drivers/scsi/sr_ioctl.c in the Linux kernel through 4.16.12 allows local users to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact because sense buffers have different sizes at the CDROM layer and the SCSI layer, as demonstrated by a CDROMREADMODE2 ioctl call."
    },
    {
        "cve_id": "CVE-2018-12714",
        "code_before_change": "static struct prog_entry *\npredicate_parse(const char *str, int nr_parens, int nr_preds,\n\t\tparse_pred_fn parse_pred, void *data,\n\t\tstruct filter_parse_error *pe)\n{\n\tstruct prog_entry *prog_stack;\n\tstruct prog_entry *prog;\n\tconst char *ptr = str;\n\tchar *inverts = NULL;\n\tint *op_stack;\n\tint *top;\n\tint invert = 0;\n\tint ret = -ENOMEM;\n\tint len;\n\tint N = 0;\n\tint i;\n\n\tnr_preds += 2; /* For TRUE and FALSE */\n\n\top_stack = kmalloc_array(nr_parens, sizeof(*op_stack), GFP_KERNEL);\n\tif (!op_stack)\n\t\treturn ERR_PTR(-ENOMEM);\n\tprog_stack = kmalloc_array(nr_preds, sizeof(*prog_stack), GFP_KERNEL);\n\tif (!prog_stack) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\tinverts = kmalloc_array(nr_preds, sizeof(*inverts), GFP_KERNEL);\n\tif (!inverts) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\n\ttop = op_stack;\n\tprog = prog_stack;\n\t*top = 0;\n\n\t/* First pass */\n\twhile (*ptr) {\t\t\t\t\t\t/* #1 */\n\t\tconst char *next = ptr++;\n\n\t\tif (isspace(*next))\n\t\t\tcontinue;\n\n\t\tswitch (*next) {\n\t\tcase '(':\t\t\t\t\t/* #2 */\n\t\t\tif (top - op_stack > nr_parens)\n\t\t\t\treturn ERR_PTR(-EINVAL);\n\t\t\t*(++top) = invert;\n\t\t\tcontinue;\n\t\tcase '!':\t\t\t\t\t/* #3 */\n\t\t\tif (!is_not(next))\n\t\t\t\tbreak;\n\t\t\tinvert = !invert;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (N >= nr_preds) {\n\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS, next - str);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tinverts[N] = invert;\t\t\t\t/* #4 */\n\t\tprog[N].target = N-1;\n\n\t\tlen = parse_pred(next, data, ptr - str, pe, &prog[N].pred);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto out_free;\n\t\t}\n\t\tptr = next + len;\n\n\t\tN++;\n\n\t\tret = -1;\n\t\twhile (1) {\t\t\t\t\t/* #5 */\n\t\t\tnext = ptr++;\n\t\t\tif (isspace(*next))\n\t\t\t\tcontinue;\n\n\t\t\tswitch (*next) {\n\t\t\tcase ')':\n\t\t\tcase '\\0':\n\t\t\t\tbreak;\n\t\t\tcase '&':\n\t\t\tcase '|':\n\t\t\t\tif (next[1] == next[0]) {\n\t\t\t\t\tptr++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS,\n\t\t\t\t\t    next - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tinvert = *top & INVERT;\n\n\t\t\tif (*top & PROCESS_AND) {\t\t/* #7 */\n\t\t\t\tupdate_preds(prog, N - 1, invert);\n\t\t\t\t*top &= ~PROCESS_AND;\n\t\t\t}\n\t\t\tif (*next == '&') {\t\t\t/* #8 */\n\t\t\t\t*top |= PROCESS_AND;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (*top & PROCESS_OR) {\t\t/* #9 */\n\t\t\t\tupdate_preds(prog, N - 1, !invert);\n\t\t\t\t*top &= ~PROCESS_OR;\n\t\t\t}\n\t\t\tif (*next == '|') {\t\t\t/* #10 */\n\t\t\t\t*top |= PROCESS_OR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!*next)\t\t\t\t/* #11 */\n\t\t\t\tgoto out;\n\n\t\t\tif (top == op_stack) {\n\t\t\t\tret = -1;\n\t\t\t\t/* Too few '(' */\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_CLOSE, ptr - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\ttop--;\t\t\t\t\t/* #12 */\n\t\t}\n\t}\n out:\n\tif (top != op_stack) {\n\t\t/* Too many '(' */\n\t\tparse_error(pe, FILT_ERR_TOO_MANY_OPEN, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tprog[N].pred = NULL;\t\t\t\t\t/* #13 */\n\tprog[N].target = 1;\t\t/* TRUE */\n\tprog[N+1].pred = NULL;\n\tprog[N+1].target = 0;\t\t/* FALSE */\n\tprog[N-1].target = N;\n\tprog[N-1].when_to_branch = false;\n\n\t/* Second Pass */\n\tfor (i = N-1 ; i--; ) {\n\t\tint target = prog[i].target;\n\t\tif (prog[i].when_to_branch == prog[target].when_to_branch)\n\t\t\tprog[i].target = prog[target].target;\n\t}\n\n\t/* Third Pass */\n\tfor (i = 0; i < N; i++) {\n\t\tinvert = inverts[i] ^ prog[i].when_to_branch;\n\t\tprog[i].when_to_branch = invert;\n\t\t/* Make sure the program always moves forward */\n\t\tif (WARN_ON(prog[i].target <= i)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\treturn prog;\nout_free:\n\tkfree(op_stack);\n\tkfree(prog_stack);\n\tkfree(inverts);\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "static struct prog_entry *\npredicate_parse(const char *str, int nr_parens, int nr_preds,\n\t\tparse_pred_fn parse_pred, void *data,\n\t\tstruct filter_parse_error *pe)\n{\n\tstruct prog_entry *prog_stack;\n\tstruct prog_entry *prog;\n\tconst char *ptr = str;\n\tchar *inverts = NULL;\n\tint *op_stack;\n\tint *top;\n\tint invert = 0;\n\tint ret = -ENOMEM;\n\tint len;\n\tint N = 0;\n\tint i;\n\n\tnr_preds += 2; /* For TRUE and FALSE */\n\n\top_stack = kmalloc_array(nr_parens, sizeof(*op_stack), GFP_KERNEL);\n\tif (!op_stack)\n\t\treturn ERR_PTR(-ENOMEM);\n\tprog_stack = kmalloc_array(nr_preds, sizeof(*prog_stack), GFP_KERNEL);\n\tif (!prog_stack) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\tinverts = kmalloc_array(nr_preds, sizeof(*inverts), GFP_KERNEL);\n\tif (!inverts) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\n\ttop = op_stack;\n\tprog = prog_stack;\n\t*top = 0;\n\n\t/* First pass */\n\twhile (*ptr) {\t\t\t\t\t\t/* #1 */\n\t\tconst char *next = ptr++;\n\n\t\tif (isspace(*next))\n\t\t\tcontinue;\n\n\t\tswitch (*next) {\n\t\tcase '(':\t\t\t\t\t/* #2 */\n\t\t\tif (top - op_stack > nr_parens)\n\t\t\t\treturn ERR_PTR(-EINVAL);\n\t\t\t*(++top) = invert;\n\t\t\tcontinue;\n\t\tcase '!':\t\t\t\t\t/* #3 */\n\t\t\tif (!is_not(next))\n\t\t\t\tbreak;\n\t\t\tinvert = !invert;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (N >= nr_preds) {\n\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS, next - str);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tinverts[N] = invert;\t\t\t\t/* #4 */\n\t\tprog[N].target = N-1;\n\n\t\tlen = parse_pred(next, data, ptr - str, pe, &prog[N].pred);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto out_free;\n\t\t}\n\t\tptr = next + len;\n\n\t\tN++;\n\n\t\tret = -1;\n\t\twhile (1) {\t\t\t\t\t/* #5 */\n\t\t\tnext = ptr++;\n\t\t\tif (isspace(*next))\n\t\t\t\tcontinue;\n\n\t\t\tswitch (*next) {\n\t\t\tcase ')':\n\t\t\tcase '\\0':\n\t\t\t\tbreak;\n\t\t\tcase '&':\n\t\t\tcase '|':\n\t\t\t\tif (next[1] == next[0]) {\n\t\t\t\t\tptr++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS,\n\t\t\t\t\t    next - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tinvert = *top & INVERT;\n\n\t\t\tif (*top & PROCESS_AND) {\t\t/* #7 */\n\t\t\t\tupdate_preds(prog, N - 1, invert);\n\t\t\t\t*top &= ~PROCESS_AND;\n\t\t\t}\n\t\t\tif (*next == '&') {\t\t\t/* #8 */\n\t\t\t\t*top |= PROCESS_AND;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (*top & PROCESS_OR) {\t\t/* #9 */\n\t\t\t\tupdate_preds(prog, N - 1, !invert);\n\t\t\t\t*top &= ~PROCESS_OR;\n\t\t\t}\n\t\t\tif (*next == '|') {\t\t\t/* #10 */\n\t\t\t\t*top |= PROCESS_OR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!*next)\t\t\t\t/* #11 */\n\t\t\t\tgoto out;\n\n\t\t\tif (top == op_stack) {\n\t\t\t\tret = -1;\n\t\t\t\t/* Too few '(' */\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_CLOSE, ptr - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\ttop--;\t\t\t\t\t/* #12 */\n\t\t}\n\t}\n out:\n\tif (top != op_stack) {\n\t\t/* Too many '(' */\n\t\tparse_error(pe, FILT_ERR_TOO_MANY_OPEN, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tif (!N) {\n\t\t/* No program? */\n\t\tret = -EINVAL;\n\t\tparse_error(pe, FILT_ERR_NO_FILTER, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tprog[N].pred = NULL;\t\t\t\t\t/* #13 */\n\tprog[N].target = 1;\t\t/* TRUE */\n\tprog[N+1].pred = NULL;\n\tprog[N+1].target = 0;\t\t/* FALSE */\n\tprog[N-1].target = N;\n\tprog[N-1].when_to_branch = false;\n\n\t/* Second Pass */\n\tfor (i = N-1 ; i--; ) {\n\t\tint target = prog[i].target;\n\t\tif (prog[i].when_to_branch == prog[target].when_to_branch)\n\t\t\tprog[i].target = prog[target].target;\n\t}\n\n\t/* Third Pass */\n\tfor (i = 0; i < N; i++) {\n\t\tinvert = inverts[i] ^ prog[i].when_to_branch;\n\t\tprog[i].when_to_branch = invert;\n\t\t/* Make sure the program always moves forward */\n\t\tif (WARN_ON(prog[i].target <= i)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\treturn prog;\nout_free:\n\tkfree(op_stack);\n\tkfree(prog_stack);\n\tkfree(inverts);\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -131,6 +131,13 @@\n \t\tgoto out_free;\n \t}\n \n+\tif (!N) {\n+\t\t/* No program? */\n+\t\tret = -EINVAL;\n+\t\tparse_error(pe, FILT_ERR_NO_FILTER, ptr - str);\n+\t\tgoto out_free;\n+\t}\n+\n \tprog[N].pred = NULL;\t\t\t\t\t/* #13 */\n \tprog[N].target = 1;\t\t/* TRUE */\n \tprog[N+1].pred = NULL;",
        "function_modified_lines": {
            "added": [
                "\tif (!N) {",
                "\t\t/* No program? */",
                "\t\tret = -EINVAL;",
                "\t\tparse_error(pe, FILT_ERR_NO_FILTER, ptr - str);",
                "\t\tgoto out_free;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.2. The filter parsing in kernel/trace/trace_events_filter.c could be called with no filter, which is an N=0 case when it expected at least one line to have been read, thus making the N-1 index invalid. This allows attackers to cause a denial of service (slab out-of-bounds write) or possibly have unspecified other impact via crafted perf_event_open and mmap system calls."
    },
    {
        "cve_id": "CVE-2018-13095",
        "code_before_change": "xfs_failaddr_t\nxfs_dinode_verify(\n\tstruct xfs_mount\t*mp,\n\txfs_ino_t\t\tino,\n\tstruct xfs_dinode\t*dip)\n{\n\txfs_failaddr_t\t\tfa;\n\tuint16_t\t\tmode;\n\tuint16_t\t\tflags;\n\tuint64_t\t\tflags2;\n\tuint64_t\t\tdi_size;\n\n\tif (dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))\n\t\treturn __this_address;\n\n\t/* Verify v3 integrity information first */\n\tif (dip->di_version >= 3) {\n\t\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\t\treturn __this_address;\n\t\tif (!xfs_verify_cksum((char *)dip, mp->m_sb.sb_inodesize,\n\t\t\t\t      XFS_DINODE_CRC_OFF))\n\t\t\treturn __this_address;\n\t\tif (be64_to_cpu(dip->di_ino) != ino)\n\t\t\treturn __this_address;\n\t\tif (!uuid_equal(&dip->di_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t}\n\n\t/* don't allow invalid i_size */\n\tdi_size = be64_to_cpu(dip->di_size);\n\tif (di_size & (1ULL << 63))\n\t\treturn __this_address;\n\n\tmode = be16_to_cpu(dip->di_mode);\n\tif (mode && xfs_mode_to_ftype(mode) == XFS_DIR3_FT_UNKNOWN)\n\t\treturn __this_address;\n\n\t/* No zero-length symlinks/dirs. */\n\tif ((S_ISLNK(mode) || S_ISDIR(mode)) && di_size == 0)\n\t\treturn __this_address;\n\n\t/* Fork checks carried over from xfs_iformat_fork */\n\tif (mode &&\n\t    be32_to_cpu(dip->di_nextents) + be16_to_cpu(dip->di_anextents) >\n\t\t\tbe64_to_cpu(dip->di_nblocks))\n\t\treturn __this_address;\n\n\tif (mode && XFS_DFORK_BOFF(dip) > mp->m_sb.sb_inodesize)\n\t\treturn __this_address;\n\n\tflags = be16_to_cpu(dip->di_flags);\n\n\tif (mode && (flags & XFS_DIFLAG_REALTIME) && !mp->m_rtdev_targp)\n\t\treturn __this_address;\n\n\t/* Do we have appropriate data fork formats for the mode? */\n\tswitch (mode & S_IFMT) {\n\tcase S_IFIFO:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFSOCK:\n\t\tif (dip->di_format != XFS_DINODE_FMT_DEV)\n\t\t\treturn __this_address;\n\t\tbreak;\n\tcase S_IFREG:\n\tcase S_IFLNK:\n\tcase S_IFDIR:\n\t\tswitch (dip->di_format) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\t\t/*\n\t\t\t * no local regular files yet\n\t\t\t */\n\t\t\tif (S_ISREG(mode))\n\t\t\t\treturn __this_address;\n\t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))\n\t\t\t\treturn __this_address;\n\t\t\tif (dip->di_nextents)\n\t\t\t\treturn __this_address;\n\t\t\t/* fall through */\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tbreak;\n\tcase 0:\n\t\t/* Uninitialized inode ok. */\n\t\tbreak;\n\tdefault:\n\t\treturn __this_address;\n\t}\n\n\tif (XFS_DFORK_Q(dip)) {\n\t\tswitch (dip->di_aformat) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\t\tif (dip->di_anextents)\n\t\t\t\treturn __this_address;\n\t\t/* fall through */\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * If there is no fork offset, this may be a freshly-made inode\n\t\t * in a new disk cluster, in which case di_aformat is zeroed.\n\t\t * Otherwise, such an inode must be in EXTENTS format; this goes\n\t\t * for freed inodes as well.\n\t\t */\n\t\tswitch (dip->di_aformat) {\n\t\tcase 0:\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tif (dip->di_anextents)\n\t\t\treturn __this_address;\n\t}\n\n\t/* extent size hint validation */\n\tfa = xfs_inode_validate_extsize(mp, be32_to_cpu(dip->di_extsize),\n\t\t\tmode, flags);\n\tif (fa)\n\t\treturn fa;\n\n\t/* only version 3 or greater inodes are extensively verified here */\n\tif (dip->di_version < 3)\n\t\treturn NULL;\n\n\tflags2 = be64_to_cpu(dip->di_flags2);\n\n\t/* don't allow reflink/cowextsize if we don't have reflink */\n\tif ((flags2 & (XFS_DIFLAG2_REFLINK | XFS_DIFLAG2_COWEXTSIZE)) &&\n\t     !xfs_sb_version_hasreflink(&mp->m_sb))\n\t\treturn __this_address;\n\n\t/* only regular files get reflink */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (mode & S_IFMT) != S_IFREG)\n\t\treturn __this_address;\n\n\t/* don't let reflink and realtime mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags & XFS_DIFLAG_REALTIME))\n\t\treturn __this_address;\n\n\t/* don't let reflink and dax mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags2 & XFS_DIFLAG2_DAX))\n\t\treturn __this_address;\n\n\t/* COW extent size hint validation */\n\tfa = xfs_inode_validate_cowextsize(mp, be32_to_cpu(dip->di_cowextsize),\n\t\t\tmode, flags, flags2);\n\tif (fa)\n\t\treturn fa;\n\n\treturn NULL;\n}",
        "code_after_change": "xfs_failaddr_t\nxfs_dinode_verify(\n\tstruct xfs_mount\t*mp,\n\txfs_ino_t\t\tino,\n\tstruct xfs_dinode\t*dip)\n{\n\txfs_failaddr_t\t\tfa;\n\tuint16_t\t\tmode;\n\tuint16_t\t\tflags;\n\tuint64_t\t\tflags2;\n\tuint64_t\t\tdi_size;\n\n\tif (dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))\n\t\treturn __this_address;\n\n\t/* Verify v3 integrity information first */\n\tif (dip->di_version >= 3) {\n\t\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\t\treturn __this_address;\n\t\tif (!xfs_verify_cksum((char *)dip, mp->m_sb.sb_inodesize,\n\t\t\t\t      XFS_DINODE_CRC_OFF))\n\t\t\treturn __this_address;\n\t\tif (be64_to_cpu(dip->di_ino) != ino)\n\t\t\treturn __this_address;\n\t\tif (!uuid_equal(&dip->di_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t}\n\n\t/* don't allow invalid i_size */\n\tdi_size = be64_to_cpu(dip->di_size);\n\tif (di_size & (1ULL << 63))\n\t\treturn __this_address;\n\n\tmode = be16_to_cpu(dip->di_mode);\n\tif (mode && xfs_mode_to_ftype(mode) == XFS_DIR3_FT_UNKNOWN)\n\t\treturn __this_address;\n\n\t/* No zero-length symlinks/dirs. */\n\tif ((S_ISLNK(mode) || S_ISDIR(mode)) && di_size == 0)\n\t\treturn __this_address;\n\n\t/* Fork checks carried over from xfs_iformat_fork */\n\tif (mode &&\n\t    be32_to_cpu(dip->di_nextents) + be16_to_cpu(dip->di_anextents) >\n\t\t\tbe64_to_cpu(dip->di_nblocks))\n\t\treturn __this_address;\n\n\tif (mode && XFS_DFORK_BOFF(dip) > mp->m_sb.sb_inodesize)\n\t\treturn __this_address;\n\n\tflags = be16_to_cpu(dip->di_flags);\n\n\tif (mode && (flags & XFS_DIFLAG_REALTIME) && !mp->m_rtdev_targp)\n\t\treturn __this_address;\n\n\t/* Do we have appropriate data fork formats for the mode? */\n\tswitch (mode & S_IFMT) {\n\tcase S_IFIFO:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFSOCK:\n\t\tif (dip->di_format != XFS_DINODE_FMT_DEV)\n\t\t\treturn __this_address;\n\t\tbreak;\n\tcase S_IFREG:\n\tcase S_IFLNK:\n\tcase S_IFDIR:\n\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_DATA_FORK);\n\t\tif (fa)\n\t\t\treturn fa;\n\t\tbreak;\n\tcase 0:\n\t\t/* Uninitialized inode ok. */\n\t\tbreak;\n\tdefault:\n\t\treturn __this_address;\n\t}\n\n\tif (XFS_DFORK_Q(dip)) {\n\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_ATTR_FORK);\n\t\tif (fa)\n\t\t\treturn fa;\n\t} else {\n\t\t/*\n\t\t * If there is no fork offset, this may be a freshly-made inode\n\t\t * in a new disk cluster, in which case di_aformat is zeroed.\n\t\t * Otherwise, such an inode must be in EXTENTS format; this goes\n\t\t * for freed inodes as well.\n\t\t */\n\t\tswitch (dip->di_aformat) {\n\t\tcase 0:\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tif (dip->di_anextents)\n\t\t\treturn __this_address;\n\t}\n\n\t/* extent size hint validation */\n\tfa = xfs_inode_validate_extsize(mp, be32_to_cpu(dip->di_extsize),\n\t\t\tmode, flags);\n\tif (fa)\n\t\treturn fa;\n\n\t/* only version 3 or greater inodes are extensively verified here */\n\tif (dip->di_version < 3)\n\t\treturn NULL;\n\n\tflags2 = be64_to_cpu(dip->di_flags2);\n\n\t/* don't allow reflink/cowextsize if we don't have reflink */\n\tif ((flags2 & (XFS_DIFLAG2_REFLINK | XFS_DIFLAG2_COWEXTSIZE)) &&\n\t     !xfs_sb_version_hasreflink(&mp->m_sb))\n\t\treturn __this_address;\n\n\t/* only regular files get reflink */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (mode & S_IFMT) != S_IFREG)\n\t\treturn __this_address;\n\n\t/* don't let reflink and realtime mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags & XFS_DIFLAG_REALTIME))\n\t\treturn __this_address;\n\n\t/* don't let reflink and dax mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags2 & XFS_DIFLAG2_DAX))\n\t\treturn __this_address;\n\n\t/* COW extent size hint validation */\n\tfa = xfs_inode_validate_cowextsize(mp, be32_to_cpu(dip->di_cowextsize),\n\t\t\tmode, flags, flags2);\n\tif (fa)\n\t\treturn fa;\n\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -65,24 +65,9 @@\n \tcase S_IFREG:\n \tcase S_IFLNK:\n \tcase S_IFDIR:\n-\t\tswitch (dip->di_format) {\n-\t\tcase XFS_DINODE_FMT_LOCAL:\n-\t\t\t/*\n-\t\t\t * no local regular files yet\n-\t\t\t */\n-\t\t\tif (S_ISREG(mode))\n-\t\t\t\treturn __this_address;\n-\t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))\n-\t\t\t\treturn __this_address;\n-\t\t\tif (dip->di_nextents)\n-\t\t\t\treturn __this_address;\n-\t\t\t/* fall through */\n-\t\tcase XFS_DINODE_FMT_EXTENTS:\n-\t\tcase XFS_DINODE_FMT_BTREE:\n-\t\t\tbreak;\n-\t\tdefault:\n-\t\t\treturn __this_address;\n-\t\t}\n+\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_DATA_FORK);\n+\t\tif (fa)\n+\t\t\treturn fa;\n \t\tbreak;\n \tcase 0:\n \t\t/* Uninitialized inode ok. */\n@@ -92,17 +77,9 @@\n \t}\n \n \tif (XFS_DFORK_Q(dip)) {\n-\t\tswitch (dip->di_aformat) {\n-\t\tcase XFS_DINODE_FMT_LOCAL:\n-\t\t\tif (dip->di_anextents)\n-\t\t\t\treturn __this_address;\n-\t\t/* fall through */\n-\t\tcase XFS_DINODE_FMT_EXTENTS:\n-\t\tcase XFS_DINODE_FMT_BTREE:\n-\t\t\tbreak;\n-\t\tdefault:\n-\t\t\treturn __this_address;\n-\t\t}\n+\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_ATTR_FORK);\n+\t\tif (fa)\n+\t\t\treturn fa;\n \t} else {\n \t\t/*\n \t\t * If there is no fork offset, this may be a freshly-made inode",
        "function_modified_lines": {
            "added": [
                "\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_DATA_FORK);",
                "\t\tif (fa)",
                "\t\t\treturn fa;",
                "\t\tfa = xfs_dinode_verify_fork(dip, mp, XFS_ATTR_FORK);",
                "\t\tif (fa)",
                "\t\t\treturn fa;"
            ],
            "deleted": [
                "\t\tswitch (dip->di_format) {",
                "\t\tcase XFS_DINODE_FMT_LOCAL:",
                "\t\t\t/*",
                "\t\t\t * no local regular files yet",
                "\t\t\t */",
                "\t\t\tif (S_ISREG(mode))",
                "\t\t\t\treturn __this_address;",
                "\t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))",
                "\t\t\t\treturn __this_address;",
                "\t\t\tif (dip->di_nextents)",
                "\t\t\t\treturn __this_address;",
                "\t\t\t/* fall through */",
                "\t\tcase XFS_DINODE_FMT_EXTENTS:",
                "\t\tcase XFS_DINODE_FMT_BTREE:",
                "\t\t\tbreak;",
                "\t\tdefault:",
                "\t\t\treturn __this_address;",
                "\t\t}",
                "\t\tswitch (dip->di_aformat) {",
                "\t\tcase XFS_DINODE_FMT_LOCAL:",
                "\t\t\tif (dip->di_anextents)",
                "\t\t\t\treturn __this_address;",
                "\t\t/* fall through */",
                "\t\tcase XFS_DINODE_FMT_EXTENTS:",
                "\t\tcase XFS_DINODE_FMT_BTREE:",
                "\t\t\tbreak;",
                "\t\tdefault:",
                "\t\t\treturn __this_address;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in fs/xfs/libxfs/xfs_inode_buf.c in the Linux kernel through 4.17.3. A denial of service (memory corruption and BUG) can occur for a corrupted xfs image upon encountering an inode that is in extent format, but has more extents than fit in the inode fork."
    },
    {
        "cve_id": "CVE-2018-14610",
        "code_before_change": "static int find_first_block_group(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_path *path,\n\t\t\t\t  struct btrfs_key *key)\n{\n\tstruct btrfs_root *root = fs_info->extent_root;\n\tint ret = 0;\n\tstruct btrfs_key found_key;\n\tstruct extent_buffer *leaf;\n\tint slot;\n\n\tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret == 0)\n\t\t\t\tcontinue;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.objectid >= key->objectid &&\n\t\t    found_key.type == BTRFS_BLOCK_GROUP_ITEM_KEY) {\n\t\t\tstruct extent_map_tree *em_tree;\n\t\t\tstruct extent_map *em;\n\n\t\t\tem_tree = &root->fs_info->mapping_tree.map_tree;\n\t\t\tread_lock(&em_tree->lock);\n\t\t\tem = lookup_extent_mapping(em_tree, found_key.objectid,\n\t\t\t\t\t\t   found_key.offset);\n\t\t\tread_unlock(&em_tree->lock);\n\t\t\tif (!em) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\"logical %llu len %llu found bg but no related chunk\",\n\t\t\t\t\t  found_key.objectid, found_key.offset);\n\t\t\t\tret = -ENOENT;\n\t\t\t} else {\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t\tfree_extent_map(em);\n\t\t\tgoto out;\n\t\t}\n\t\tpath->slots[0]++;\n\t}\nout:\n\treturn ret;\n}",
        "code_after_change": "static int find_first_block_group(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_path *path,\n\t\t\t\t  struct btrfs_key *key)\n{\n\tstruct btrfs_root *root = fs_info->extent_root;\n\tint ret = 0;\n\tstruct btrfs_key found_key;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_block_group_item bg;\n\tu64 flags;\n\tint slot;\n\n\tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret == 0)\n\t\t\t\tcontinue;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.objectid >= key->objectid &&\n\t\t    found_key.type == BTRFS_BLOCK_GROUP_ITEM_KEY) {\n\t\t\tstruct extent_map_tree *em_tree;\n\t\t\tstruct extent_map *em;\n\n\t\t\tem_tree = &root->fs_info->mapping_tree.map_tree;\n\t\t\tread_lock(&em_tree->lock);\n\t\t\tem = lookup_extent_mapping(em_tree, found_key.objectid,\n\t\t\t\t\t\t   found_key.offset);\n\t\t\tread_unlock(&em_tree->lock);\n\t\t\tif (!em) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\"logical %llu len %llu found bg but no related chunk\",\n\t\t\t\t\t  found_key.objectid, found_key.offset);\n\t\t\t\tret = -ENOENT;\n\t\t\t} else if (em->start != found_key.objectid ||\n\t\t\t\t   em->len != found_key.offset) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",\n\t\t\t\t\t  found_key.objectid, found_key.offset,\n\t\t\t\t\t  em->start, em->len);\n\t\t\t\tret = -EUCLEAN;\n\t\t\t} else {\n\t\t\t\tread_extent_buffer(leaf, &bg,\n\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),\n\t\t\t\t\tsizeof(bg));\n\t\t\t\tflags = btrfs_block_group_flags(&bg) &\n\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;\n\n\t\t\t\tif (flags != (em->map_lookup->type &\n\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {\n\t\t\t\t\tbtrfs_err(fs_info,\n\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",\n\t\t\t\t\t\tfound_key.objectid,\n\t\t\t\t\t\tfound_key.offset, flags,\n\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &\n\t\t\t\t\t\t em->map_lookup->type));\n\t\t\t\t\tret = -EUCLEAN;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfree_extent_map(em);\n\t\t\tgoto out;\n\t\t}\n\t\tpath->slots[0]++;\n\t}\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,8 @@\n \tint ret = 0;\n \tstruct btrfs_key found_key;\n \tstruct extent_buffer *leaf;\n+\tstruct btrfs_block_group_item bg;\n+\tu64 flags;\n \tint slot;\n \n \tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n@@ -40,8 +42,32 @@\n \t\t\t\"logical %llu len %llu found bg but no related chunk\",\n \t\t\t\t\t  found_key.objectid, found_key.offset);\n \t\t\t\tret = -ENOENT;\n+\t\t\t} else if (em->start != found_key.objectid ||\n+\t\t\t\t   em->len != found_key.offset) {\n+\t\t\t\tbtrfs_err(fs_info,\n+\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",\n+\t\t\t\t\t  found_key.objectid, found_key.offset,\n+\t\t\t\t\t  em->start, em->len);\n+\t\t\t\tret = -EUCLEAN;\n \t\t\t} else {\n-\t\t\t\tret = 0;\n+\t\t\t\tread_extent_buffer(leaf, &bg,\n+\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),\n+\t\t\t\t\tsizeof(bg));\n+\t\t\t\tflags = btrfs_block_group_flags(&bg) &\n+\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;\n+\n+\t\t\t\tif (flags != (em->map_lookup->type &\n+\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {\n+\t\t\t\t\tbtrfs_err(fs_info,\n+\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",\n+\t\t\t\t\t\tfound_key.objectid,\n+\t\t\t\t\t\tfound_key.offset, flags,\n+\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &\n+\t\t\t\t\t\t em->map_lookup->type));\n+\t\t\t\t\tret = -EUCLEAN;\n+\t\t\t\t} else {\n+\t\t\t\t\tret = 0;\n+\t\t\t\t}\n \t\t\t}\n \t\t\tfree_extent_map(em);\n \t\t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "\tstruct btrfs_block_group_item bg;",
                "\tu64 flags;",
                "\t\t\t} else if (em->start != found_key.objectid ||",
                "\t\t\t\t   em->len != found_key.offset) {",
                "\t\t\t\tbtrfs_err(fs_info,",
                "\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",",
                "\t\t\t\t\t  found_key.objectid, found_key.offset,",
                "\t\t\t\t\t  em->start, em->len);",
                "\t\t\t\tret = -EUCLEAN;",
                "\t\t\t\tread_extent_buffer(leaf, &bg,",
                "\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),",
                "\t\t\t\t\tsizeof(bg));",
                "\t\t\t\tflags = btrfs_block_group_flags(&bg) &",
                "\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;",
                "",
                "\t\t\t\tif (flags != (em->map_lookup->type &",
                "\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {",
                "\t\t\t\t\tbtrfs_err(fs_info,",
                "\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",",
                "\t\t\t\t\t\tfound_key.objectid,",
                "\t\t\t\t\t\tfound_key.offset, flags,",
                "\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &",
                "\t\t\t\t\t\t em->map_lookup->type));",
                "\t\t\t\t\tret = -EUCLEAN;",
                "\t\t\t\t} else {",
                "\t\t\t\t\tret = 0;",
                "\t\t\t\t}"
            ],
            "deleted": [
                "\t\t\t\tret = 0;"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is out-of-bounds access in write_extent_buffer() when mounting and operating a crafted btrfs image, because of a lack of verification that each block group has a corresponding chunk at mount time, within btrfs_read_block_groups in fs/btrfs/extent-tree.c."
    },
    {
        "cve_id": "CVE-2018-16276",
        "code_before_change": "static ssize_t yurex_read(struct file *file, char __user *buffer, size_t count,\n\t\t\t  loff_t *ppos)\n{\n\tstruct usb_yurex *dev;\n\tint retval = 0;\n\tint bytes_read = 0;\n\tchar in_buffer[20];\n\tunsigned long flags;\n\n\tdev = file->private_data;\n\n\tmutex_lock(&dev->io_mutex);\n\tif (!dev->interface) {\t\t/* already disconnected */\n\t\tretval = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\tbytes_read = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\tif (*ppos < bytes_read) {\n\t\tif (copy_to_user(buffer, in_buffer + *ppos, bytes_read - *ppos))\n\t\t\tretval = -EFAULT;\n\t\telse {\n\t\t\tretval = bytes_read - *ppos;\n\t\t\t*ppos += bytes_read;\n\t\t}\n\t}\n\nexit:\n\tmutex_unlock(&dev->io_mutex);\n\treturn retval;\n}",
        "code_after_change": "static ssize_t yurex_read(struct file *file, char __user *buffer, size_t count,\n\t\t\t  loff_t *ppos)\n{\n\tstruct usb_yurex *dev;\n\tint len = 0;\n\tchar in_buffer[20];\n\tunsigned long flags;\n\n\tdev = file->private_data;\n\n\tmutex_lock(&dev->io_mutex);\n\tif (!dev->interface) {\t\t/* already disconnected */\n\t\tmutex_unlock(&dev->io_mutex);\n\t\treturn -ENODEV;\n\t}\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\tlen = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\tmutex_unlock(&dev->io_mutex);\n\n\treturn simple_read_from_buffer(buffer, count, ppos, in_buffer, len);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,8 +2,7 @@\n \t\t\t  loff_t *ppos)\n {\n \tstruct usb_yurex *dev;\n-\tint retval = 0;\n-\tint bytes_read = 0;\n+\tint len = 0;\n \tchar in_buffer[20];\n \tunsigned long flags;\n \n@@ -11,24 +10,14 @@\n \n \tmutex_lock(&dev->io_mutex);\n \tif (!dev->interface) {\t\t/* already disconnected */\n-\t\tretval = -ENODEV;\n-\t\tgoto exit;\n+\t\tmutex_unlock(&dev->io_mutex);\n+\t\treturn -ENODEV;\n \t}\n \n \tspin_lock_irqsave(&dev->lock, flags);\n-\tbytes_read = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);\n+\tlen = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);\n \tspin_unlock_irqrestore(&dev->lock, flags);\n+\tmutex_unlock(&dev->io_mutex);\n \n-\tif (*ppos < bytes_read) {\n-\t\tif (copy_to_user(buffer, in_buffer + *ppos, bytes_read - *ppos))\n-\t\t\tretval = -EFAULT;\n-\t\telse {\n-\t\t\tretval = bytes_read - *ppos;\n-\t\t\t*ppos += bytes_read;\n-\t\t}\n-\t}\n-\n-exit:\n-\tmutex_unlock(&dev->io_mutex);\n-\treturn retval;\n+\treturn simple_read_from_buffer(buffer, count, ppos, in_buffer, len);\n }",
        "function_modified_lines": {
            "added": [
                "\tint len = 0;",
                "\t\tmutex_unlock(&dev->io_mutex);",
                "\t\treturn -ENODEV;",
                "\tlen = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);",
                "\tmutex_unlock(&dev->io_mutex);",
                "\treturn simple_read_from_buffer(buffer, count, ppos, in_buffer, len);"
            ],
            "deleted": [
                "\tint retval = 0;",
                "\tint bytes_read = 0;",
                "\t\tretval = -ENODEV;",
                "\t\tgoto exit;",
                "\tbytes_read = snprintf(in_buffer, 20, \"%lld\\n\", dev->bbu);",
                "\tif (*ppos < bytes_read) {",
                "\t\tif (copy_to_user(buffer, in_buffer + *ppos, bytes_read - *ppos))",
                "\t\t\tretval = -EFAULT;",
                "\t\telse {",
                "\t\t\tretval = bytes_read - *ppos;",
                "\t\t\t*ppos += bytes_read;",
                "\t\t}",
                "\t}",
                "",
                "exit:",
                "\tmutex_unlock(&dev->io_mutex);",
                "\treturn retval;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in yurex_read in drivers/usb/misc/yurex.c in the Linux kernel before 4.17.7. Local attackers could use user access read/writes with incorrect bounds checking in the yurex USB driver to crash the kernel or potentially escalate privileges."
    },
    {
        "cve_id": "CVE-2018-16880",
        "code_before_change": "static int vhost_net_open(struct inode *inode, struct file *f)\n{\n\tstruct vhost_net *n;\n\tstruct vhost_dev *dev;\n\tstruct vhost_virtqueue **vqs;\n\tvoid **queue;\n\tstruct xdp_buff *xdp;\n\tint i;\n\n\tn = kvmalloc(sizeof *n, GFP_KERNEL | __GFP_RETRY_MAYFAIL);\n\tif (!n)\n\t\treturn -ENOMEM;\n\tvqs = kmalloc_array(VHOST_NET_VQ_MAX, sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs) {\n\t\tkvfree(n);\n\t\treturn -ENOMEM;\n\t}\n\n\tqueue = kmalloc_array(VHOST_NET_BATCH, sizeof(void *),\n\t\t\t      GFP_KERNEL);\n\tif (!queue) {\n\t\tkfree(vqs);\n\t\tkvfree(n);\n\t\treturn -ENOMEM;\n\t}\n\tn->vqs[VHOST_NET_VQ_RX].rxq.queue = queue;\n\n\txdp = kmalloc_array(VHOST_NET_BATCH, sizeof(*xdp), GFP_KERNEL);\n\tif (!xdp) {\n\t\tkfree(vqs);\n\t\tkvfree(n);\n\t\tkfree(queue);\n\t\treturn -ENOMEM;\n\t}\n\tn->vqs[VHOST_NET_VQ_TX].xdp = xdp;\n\n\tdev = &n->dev;\n\tvqs[VHOST_NET_VQ_TX] = &n->vqs[VHOST_NET_VQ_TX].vq;\n\tvqs[VHOST_NET_VQ_RX] = &n->vqs[VHOST_NET_VQ_RX].vq;\n\tn->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;\n\tn->vqs[VHOST_NET_VQ_RX].vq.handle_kick = handle_rx_kick;\n\tfor (i = 0; i < VHOST_NET_VQ_MAX; i++) {\n\t\tn->vqs[i].ubufs = NULL;\n\t\tn->vqs[i].ubuf_info = NULL;\n\t\tn->vqs[i].upend_idx = 0;\n\t\tn->vqs[i].done_idx = 0;\n\t\tn->vqs[i].batched_xdp = 0;\n\t\tn->vqs[i].vhost_hlen = 0;\n\t\tn->vqs[i].sock_hlen = 0;\n\t\tn->vqs[i].rx_ring = NULL;\n\t\tvhost_net_buf_init(&n->vqs[i].rxq);\n\t}\n\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);\n\n\tvhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);\n\tvhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);\n\n\tf->private_data = n;\n\tn->page_frag.page = NULL;\n\tn->refcnt_bias = 0;\n\n\treturn 0;\n}",
        "code_after_change": "static int vhost_net_open(struct inode *inode, struct file *f)\n{\n\tstruct vhost_net *n;\n\tstruct vhost_dev *dev;\n\tstruct vhost_virtqueue **vqs;\n\tvoid **queue;\n\tstruct xdp_buff *xdp;\n\tint i;\n\n\tn = kvmalloc(sizeof *n, GFP_KERNEL | __GFP_RETRY_MAYFAIL);\n\tif (!n)\n\t\treturn -ENOMEM;\n\tvqs = kmalloc_array(VHOST_NET_VQ_MAX, sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs) {\n\t\tkvfree(n);\n\t\treturn -ENOMEM;\n\t}\n\n\tqueue = kmalloc_array(VHOST_NET_BATCH, sizeof(void *),\n\t\t\t      GFP_KERNEL);\n\tif (!queue) {\n\t\tkfree(vqs);\n\t\tkvfree(n);\n\t\treturn -ENOMEM;\n\t}\n\tn->vqs[VHOST_NET_VQ_RX].rxq.queue = queue;\n\n\txdp = kmalloc_array(VHOST_NET_BATCH, sizeof(*xdp), GFP_KERNEL);\n\tif (!xdp) {\n\t\tkfree(vqs);\n\t\tkvfree(n);\n\t\tkfree(queue);\n\t\treturn -ENOMEM;\n\t}\n\tn->vqs[VHOST_NET_VQ_TX].xdp = xdp;\n\n\tdev = &n->dev;\n\tvqs[VHOST_NET_VQ_TX] = &n->vqs[VHOST_NET_VQ_TX].vq;\n\tvqs[VHOST_NET_VQ_RX] = &n->vqs[VHOST_NET_VQ_RX].vq;\n\tn->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;\n\tn->vqs[VHOST_NET_VQ_RX].vq.handle_kick = handle_rx_kick;\n\tfor (i = 0; i < VHOST_NET_VQ_MAX; i++) {\n\t\tn->vqs[i].ubufs = NULL;\n\t\tn->vqs[i].ubuf_info = NULL;\n\t\tn->vqs[i].upend_idx = 0;\n\t\tn->vqs[i].done_idx = 0;\n\t\tn->vqs[i].batched_xdp = 0;\n\t\tn->vqs[i].vhost_hlen = 0;\n\t\tn->vqs[i].sock_hlen = 0;\n\t\tn->vqs[i].rx_ring = NULL;\n\t\tvhost_net_buf_init(&n->vqs[i].rxq);\n\t}\n\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,\n\t\t       UIO_MAXIOV + VHOST_NET_BATCH);\n\n\tvhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);\n\tvhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);\n\n\tf->private_data = n;\n\tn->page_frag.page = NULL;\n\tn->refcnt_bias = 0;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -50,7 +50,8 @@\n \t\tn->vqs[i].rx_ring = NULL;\n \t\tvhost_net_buf_init(&n->vqs[i].rxq);\n \t}\n-\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);\n+\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,\n+\t\t       UIO_MAXIOV + VHOST_NET_BATCH);\n \n \tvhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);\n \tvhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);",
        "function_modified_lines": {
            "added": [
                "\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,",
                "\t\t       UIO_MAXIOV + VHOST_NET_BATCH);"
            ],
            "deleted": [
                "\tvhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's handle_rx() function in the [vhost_net] driver. A malicious virtual guest, under specific conditions, can trigger an out-of-bounds write in a kmalloc-8 slab on a virtual host which may lead to a kernel memory corruption and a system panic. Due to the nature of the flaw, privilege escalation cannot be fully ruled out. Versions from v4.16 and newer are vulnerable."
    },
    {
        "cve_id": "CVE-2018-16880",
        "code_before_change": "static int vhost_scsi_open(struct inode *inode, struct file *f)\n{\n\tstruct vhost_scsi *vs;\n\tstruct vhost_virtqueue **vqs;\n\tint r = -ENOMEM, i;\n\n\tvs = kzalloc(sizeof(*vs), GFP_KERNEL | __GFP_NOWARN | __GFP_RETRY_MAYFAIL);\n\tif (!vs) {\n\t\tvs = vzalloc(sizeof(*vs));\n\t\tif (!vs)\n\t\t\tgoto err_vs;\n\t}\n\n\tvqs = kmalloc_array(VHOST_SCSI_MAX_VQ, sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs)\n\t\tgoto err_vqs;\n\n\tvhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);\n\tvhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);\n\n\tvs->vs_events_nr = 0;\n\tvs->vs_events_missed = false;\n\n\tvqs[VHOST_SCSI_VQ_CTL] = &vs->vqs[VHOST_SCSI_VQ_CTL].vq;\n\tvqs[VHOST_SCSI_VQ_EVT] = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;\n\tvs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;\n\tvs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;\n\tfor (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {\n\t\tvqs[i] = &vs->vqs[i].vq;\n\t\tvs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;\n\t}\n\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);\n\n\tvhost_scsi_init_inflight(vs, NULL);\n\n\tf->private_data = vs;\n\treturn 0;\n\nerr_vqs:\n\tkvfree(vs);\nerr_vs:\n\treturn r;\n}",
        "code_after_change": "static int vhost_scsi_open(struct inode *inode, struct file *f)\n{\n\tstruct vhost_scsi *vs;\n\tstruct vhost_virtqueue **vqs;\n\tint r = -ENOMEM, i;\n\n\tvs = kzalloc(sizeof(*vs), GFP_KERNEL | __GFP_NOWARN | __GFP_RETRY_MAYFAIL);\n\tif (!vs) {\n\t\tvs = vzalloc(sizeof(*vs));\n\t\tif (!vs)\n\t\t\tgoto err_vs;\n\t}\n\n\tvqs = kmalloc_array(VHOST_SCSI_MAX_VQ, sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs)\n\t\tgoto err_vqs;\n\n\tvhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);\n\tvhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);\n\n\tvs->vs_events_nr = 0;\n\tvs->vs_events_missed = false;\n\n\tvqs[VHOST_SCSI_VQ_CTL] = &vs->vqs[VHOST_SCSI_VQ_CTL].vq;\n\tvqs[VHOST_SCSI_VQ_EVT] = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;\n\tvs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;\n\tvs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;\n\tfor (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {\n\t\tvqs[i] = &vs->vqs[i].vq;\n\t\tvs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;\n\t}\n\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ, UIO_MAXIOV);\n\n\tvhost_scsi_init_inflight(vs, NULL);\n\n\tf->private_data = vs;\n\treturn 0;\n\nerr_vqs:\n\tkvfree(vs);\nerr_vs:\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,7 +29,7 @@\n \t\tvqs[i] = &vs->vqs[i].vq;\n \t\tvs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;\n \t}\n-\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);\n+\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ, UIO_MAXIOV);\n \n \tvhost_scsi_init_inflight(vs, NULL);\n ",
        "function_modified_lines": {
            "added": [
                "\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ, UIO_MAXIOV);"
            ],
            "deleted": [
                "\tvhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's handle_rx() function in the [vhost_net] driver. A malicious virtual guest, under specific conditions, can trigger an out-of-bounds write in a kmalloc-8 slab on a virtual host which may lead to a kernel memory corruption and a system panic. Due to the nature of the flaw, privilege escalation cannot be fully ruled out. Versions from v4.16 and newer are vulnerable."
    },
    {
        "cve_id": "CVE-2018-16880",
        "code_before_change": "static long vhost_dev_alloc_iovecs(struct vhost_dev *dev)\n{\n\tstruct vhost_virtqueue *vq;\n\tint i;\n\n\tfor (i = 0; i < dev->nvqs; ++i) {\n\t\tvq = dev->vqs[i];\n\t\tvq->indirect = kmalloc_array(UIO_MAXIOV,\n\t\t\t\t\t     sizeof(*vq->indirect),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tvq->log = kmalloc_array(UIO_MAXIOV, sizeof(*vq->log),\n\t\t\t\t\tGFP_KERNEL);\n\t\tvq->heads = kmalloc_array(UIO_MAXIOV, sizeof(*vq->heads),\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!vq->indirect || !vq->log || !vq->heads)\n\t\t\tgoto err_nomem;\n\t}\n\treturn 0;\n\nerr_nomem:\n\tfor (; i >= 0; --i)\n\t\tvhost_vq_free_iovecs(dev->vqs[i]);\n\treturn -ENOMEM;\n}",
        "code_after_change": "static long vhost_dev_alloc_iovecs(struct vhost_dev *dev)\n{\n\tstruct vhost_virtqueue *vq;\n\tint i;\n\n\tfor (i = 0; i < dev->nvqs; ++i) {\n\t\tvq = dev->vqs[i];\n\t\tvq->indirect = kmalloc_array(UIO_MAXIOV,\n\t\t\t\t\t     sizeof(*vq->indirect),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tvq->log = kmalloc_array(dev->iov_limit, sizeof(*vq->log),\n\t\t\t\t\tGFP_KERNEL);\n\t\tvq->heads = kmalloc_array(dev->iov_limit, sizeof(*vq->heads),\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!vq->indirect || !vq->log || !vq->heads)\n\t\t\tgoto err_nomem;\n\t}\n\treturn 0;\n\nerr_nomem:\n\tfor (; i >= 0; --i)\n\t\tvhost_vq_free_iovecs(dev->vqs[i]);\n\treturn -ENOMEM;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,9 +8,9 @@\n \t\tvq->indirect = kmalloc_array(UIO_MAXIOV,\n \t\t\t\t\t     sizeof(*vq->indirect),\n \t\t\t\t\t     GFP_KERNEL);\n-\t\tvq->log = kmalloc_array(UIO_MAXIOV, sizeof(*vq->log),\n+\t\tvq->log = kmalloc_array(dev->iov_limit, sizeof(*vq->log),\n \t\t\t\t\tGFP_KERNEL);\n-\t\tvq->heads = kmalloc_array(UIO_MAXIOV, sizeof(*vq->heads),\n+\t\tvq->heads = kmalloc_array(dev->iov_limit, sizeof(*vq->heads),\n \t\t\t\t\t  GFP_KERNEL);\n \t\tif (!vq->indirect || !vq->log || !vq->heads)\n \t\t\tgoto err_nomem;",
        "function_modified_lines": {
            "added": [
                "\t\tvq->log = kmalloc_array(dev->iov_limit, sizeof(*vq->log),",
                "\t\tvq->heads = kmalloc_array(dev->iov_limit, sizeof(*vq->heads),"
            ],
            "deleted": [
                "\t\tvq->log = kmalloc_array(UIO_MAXIOV, sizeof(*vq->log),",
                "\t\tvq->heads = kmalloc_array(UIO_MAXIOV, sizeof(*vq->heads),"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's handle_rx() function in the [vhost_net] driver. A malicious virtual guest, under specific conditions, can trigger an out-of-bounds write in a kmalloc-8 slab on a virtual host which may lead to a kernel memory corruption and a system panic. Due to the nature of the flaw, privilege escalation cannot be fully ruled out. Versions from v4.16 and newer are vulnerable."
    },
    {
        "cve_id": "CVE-2018-16880",
        "code_before_change": "static int vhost_vsock_dev_open(struct inode *inode, struct file *file)\n{\n\tstruct vhost_virtqueue **vqs;\n\tstruct vhost_vsock *vsock;\n\tint ret;\n\n\t/* This struct is large and allocation could fail, fall back to vmalloc\n\t * if there is no other way.\n\t */\n\tvsock = kvmalloc(sizeof(*vsock), GFP_KERNEL | __GFP_RETRY_MAYFAIL);\n\tif (!vsock)\n\t\treturn -ENOMEM;\n\n\tvqs = kmalloc_array(ARRAY_SIZE(vsock->vqs), sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tvsock->guest_cid = 0; /* no CID assigned yet */\n\n\tatomic_set(&vsock->queued_replies, 0);\n\n\tvqs[VSOCK_VQ_TX] = &vsock->vqs[VSOCK_VQ_TX];\n\tvqs[VSOCK_VQ_RX] = &vsock->vqs[VSOCK_VQ_RX];\n\tvsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;\n\tvsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;\n\n\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs));\n\n\tfile->private_data = vsock;\n\tspin_lock_init(&vsock->send_pkt_list_lock);\n\tINIT_LIST_HEAD(&vsock->send_pkt_list);\n\tvhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);\n\treturn 0;\n\nout:\n\tvhost_vsock_free(vsock);\n\treturn ret;\n}",
        "code_after_change": "static int vhost_vsock_dev_open(struct inode *inode, struct file *file)\n{\n\tstruct vhost_virtqueue **vqs;\n\tstruct vhost_vsock *vsock;\n\tint ret;\n\n\t/* This struct is large and allocation could fail, fall back to vmalloc\n\t * if there is no other way.\n\t */\n\tvsock = kvmalloc(sizeof(*vsock), GFP_KERNEL | __GFP_RETRY_MAYFAIL);\n\tif (!vsock)\n\t\treturn -ENOMEM;\n\n\tvqs = kmalloc_array(ARRAY_SIZE(vsock->vqs), sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tvsock->guest_cid = 0; /* no CID assigned yet */\n\n\tatomic_set(&vsock->queued_replies, 0);\n\n\tvqs[VSOCK_VQ_TX] = &vsock->vqs[VSOCK_VQ_TX];\n\tvqs[VSOCK_VQ_RX] = &vsock->vqs[VSOCK_VQ_RX];\n\tvsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;\n\tvsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;\n\n\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs), UIO_MAXIOV);\n\n\tfile->private_data = vsock;\n\tspin_lock_init(&vsock->send_pkt_list_lock);\n\tINIT_LIST_HEAD(&vsock->send_pkt_list);\n\tvhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);\n\treturn 0;\n\nout:\n\tvhost_vsock_free(vsock);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -26,7 +26,7 @@\n \tvsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;\n \tvsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;\n \n-\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs));\n+\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs), UIO_MAXIOV);\n \n \tfile->private_data = vsock;\n \tspin_lock_init(&vsock->send_pkt_list_lock);",
        "function_modified_lines": {
            "added": [
                "\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs), UIO_MAXIOV);"
            ],
            "deleted": [
                "\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs));"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel's handle_rx() function in the [vhost_net] driver. A malicious virtual guest, under specific conditions, can trigger an out-of-bounds write in a kmalloc-8 slab on a virtual host which may lead to a kernel memory corruption and a system panic. Due to the nature of the flaw, privilege escalation cannot be fully ruled out. Versions from v4.16 and newer are vulnerable."
    },
    {
        "cve_id": "CVE-2018-5332",
        "code_before_change": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}",
        "code_after_change": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\tif (args->nr_local == 0)\n\t\treturn -EINVAL;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,9 @@\n \tunsigned int i;\n \n \tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n+\n+\tif (args->nr_local == 0)\n+\t\treturn -EINVAL;\n \n \t/* figure out the number of pages in the vector */\n \tfor (i = 0; i < args->nr_local; i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (args->nr_local == 0)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel through 3.2, the rds_message_alloc_sgs() function does not validate a value that is used during DMA page allocation, leading to a heap-based out-of-bounds write (related to the rds_rdma_extra_size function in net/rds/rdma.c)."
    },
    {
        "cve_id": "CVE-2018-5703",
        "code_before_change": "static int tls_init(struct sock *sk)\n{\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tls_context *ctx;\n\tint rc = 0;\n\n\t/* The TLS ulp is currently supported only for TCP sockets\n\t * in ESTABLISHED state.\n\t * Supporting sockets in LISTEN state will require us\n\t * to modify the accept implementation to clone rather then\n\t * share the ulp context.\n\t */\n\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\treturn -ENOTSUPP;\n\n\t/* allocate tls context */\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\ticsk->icsk_ulp_data = ctx;\n\tctx->setsockopt = sk->sk_prot->setsockopt;\n\tctx->getsockopt = sk->sk_prot->getsockopt;\n\tctx->sk_proto_close = sk->sk_prot->close;\n\n\tctx->tx_conf = TLS_BASE_TX;\n\tupdate_sk_prot(sk, ctx);\nout:\n\treturn rc;\n}",
        "code_after_change": "static int tls_init(struct sock *sk)\n{\n\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tls_context *ctx;\n\tint rc = 0;\n\n\t/* The TLS ulp is currently supported only for TCP sockets\n\t * in ESTABLISHED state.\n\t * Supporting sockets in LISTEN state will require us\n\t * to modify the accept implementation to clone rather then\n\t * share the ulp context.\n\t */\n\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\treturn -ENOTSUPP;\n\n\t/* allocate tls context */\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\ticsk->icsk_ulp_data = ctx;\n\tctx->setsockopt = sk->sk_prot->setsockopt;\n\tctx->getsockopt = sk->sk_prot->getsockopt;\n\tctx->sk_proto_close = sk->sk_prot->close;\n\n\t/* Build IPv6 TLS whenever the address of tcpv6_prot changes */\n\tif (ip_ver == TLSV6 &&\n\t    unlikely(sk->sk_prot != smp_load_acquire(&saved_tcpv6_prot))) {\n\t\tmutex_lock(&tcpv6_prot_mutex);\n\t\tif (likely(sk->sk_prot != saved_tcpv6_prot)) {\n\t\t\tbuild_protos(tls_prots[TLSV6], sk->sk_prot);\n\t\t\tsmp_store_release(&saved_tcpv6_prot, sk->sk_prot);\n\t\t}\n\t\tmutex_unlock(&tcpv6_prot_mutex);\n\t}\n\n\tctx->tx_conf = TLS_BASE_TX;\n\tupdate_sk_prot(sk, ctx);\nout:\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,6 @@\n static int tls_init(struct sock *sk)\n {\n+\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;\n \tstruct inet_connection_sock *icsk = inet_csk(sk);\n \tstruct tls_context *ctx;\n \tint rc = 0;\n@@ -24,6 +25,17 @@\n \tctx->getsockopt = sk->sk_prot->getsockopt;\n \tctx->sk_proto_close = sk->sk_prot->close;\n \n+\t/* Build IPv6 TLS whenever the address of tcpv6_prot changes */\n+\tif (ip_ver == TLSV6 &&\n+\t    unlikely(sk->sk_prot != smp_load_acquire(&saved_tcpv6_prot))) {\n+\t\tmutex_lock(&tcpv6_prot_mutex);\n+\t\tif (likely(sk->sk_prot != saved_tcpv6_prot)) {\n+\t\t\tbuild_protos(tls_prots[TLSV6], sk->sk_prot);\n+\t\t\tsmp_store_release(&saved_tcpv6_prot, sk->sk_prot);\n+\t\t}\n+\t\tmutex_unlock(&tcpv6_prot_mutex);\n+\t}\n+\n \tctx->tx_conf = TLS_BASE_TX;\n \tupdate_sk_prot(sk, ctx);\n out:",
        "function_modified_lines": {
            "added": [
                "\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;",
                "\t/* Build IPv6 TLS whenever the address of tcpv6_prot changes */",
                "\tif (ip_ver == TLSV6 &&",
                "\t    unlikely(sk->sk_prot != smp_load_acquire(&saved_tcpv6_prot))) {",
                "\t\tmutex_lock(&tcpv6_prot_mutex);",
                "\t\tif (likely(sk->sk_prot != saved_tcpv6_prot)) {",
                "\t\t\tbuild_protos(tls_prots[TLSV6], sk->sk_prot);",
                "\t\t\tsmp_store_release(&saved_tcpv6_prot, sk->sk_prot);",
                "\t\t}",
                "\t\tmutex_unlock(&tcpv6_prot_mutex);",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The tcp_v6_syn_recv_sock function in net/ipv6/tcp_ipv6.c in the Linux kernel through 4.14.11 allows attackers to cause a denial of service (slab out-of-bounds write) or possibly have unspecified other impact via vectors involving TLS."
    },
    {
        "cve_id": "CVE-2018-5703",
        "code_before_change": "static int __init tls_register(void)\n{\n\tbuild_protos(tls_prots, &tcp_prot);\n\n\ttcp_register_ulp(&tcp_tls_ulp_ops);\n\n\treturn 0;\n}",
        "code_after_change": "static int __init tls_register(void)\n{\n\tbuild_protos(tls_prots[TLSV4], &tcp_prot);\n\n\ttcp_register_ulp(&tcp_tls_ulp_ops);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static int __init tls_register(void)\n {\n-\tbuild_protos(tls_prots, &tcp_prot);\n+\tbuild_protos(tls_prots[TLSV4], &tcp_prot);\n \n \ttcp_register_ulp(&tcp_tls_ulp_ops);\n ",
        "function_modified_lines": {
            "added": [
                "\tbuild_protos(tls_prots[TLSV4], &tcp_prot);"
            ],
            "deleted": [
                "\tbuild_protos(tls_prots, &tcp_prot);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The tcp_v6_syn_recv_sock function in net/ipv6/tcp_ipv6.c in the Linux kernel through 4.14.11 allows attackers to cause a denial of service (slab out-of-bounds write) or possibly have unspecified other impact via vectors involving TLS."
    },
    {
        "cve_id": "CVE-2018-5703",
        "code_before_change": "static inline void update_sk_prot(struct sock *sk, struct tls_context *ctx)\n{\n\tsk->sk_prot = &tls_prots[ctx->tx_conf];\n}",
        "code_after_change": "static inline void update_sk_prot(struct sock *sk, struct tls_context *ctx)\n{\n\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;\n\n\tsk->sk_prot = &tls_prots[ip_ver][ctx->tx_conf];\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,6 @@\n static inline void update_sk_prot(struct sock *sk, struct tls_context *ctx)\n {\n-\tsk->sk_prot = &tls_prots[ctx->tx_conf];\n+\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;\n+\n+\tsk->sk_prot = &tls_prots[ip_ver][ctx->tx_conf];\n }",
        "function_modified_lines": {
            "added": [
                "\tint ip_ver = sk->sk_family == AF_INET6 ? TLSV6 : TLSV4;",
                "",
                "\tsk->sk_prot = &tls_prots[ip_ver][ctx->tx_conf];"
            ],
            "deleted": [
                "\tsk->sk_prot = &tls_prots[ctx->tx_conf];"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The tcp_v6_syn_recv_sock function in net/ipv6/tcp_ipv6.c in the Linux kernel through 4.14.11 allows attackers to cause a denial of service (slab out-of-bounds write) or possibly have unspecified other impact via vectors involving TLS."
    },
    {
        "cve_id": "CVE-2018-9385",
        "code_before_change": "static ssize_t driver_override_store(struct device *_dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct amba_device *dev = to_amba_device(_dev);\n\tchar *driver_override, *old, *cp;\n\n\tif (count > PATH_MAX)\n\t\treturn -EINVAL;\n\n\tdriver_override = kstrndup(buf, count, GFP_KERNEL);\n\tif (!driver_override)\n\t\treturn -ENOMEM;\n\n\tcp = strchr(driver_override, '\\n');\n\tif (cp)\n\t\t*cp = '\\0';\n\n\tdevice_lock(_dev);\n\told = dev->driver_override;\n\tif (strlen(driver_override)) {\n\t\tdev->driver_override = driver_override;\n\t} else {\n\t       kfree(driver_override);\n\t       dev->driver_override = NULL;\n\t}\n\tdevice_unlock(_dev);\n\n\tkfree(old);\n\n\treturn count;\n}",
        "code_after_change": "static ssize_t driver_override_store(struct device *_dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct amba_device *dev = to_amba_device(_dev);\n\tchar *driver_override, *old, *cp;\n\n\t/* We need to keep extra room for a newline */\n\tif (count >= (PAGE_SIZE - 1))\n\t\treturn -EINVAL;\n\n\tdriver_override = kstrndup(buf, count, GFP_KERNEL);\n\tif (!driver_override)\n\t\treturn -ENOMEM;\n\n\tcp = strchr(driver_override, '\\n');\n\tif (cp)\n\t\t*cp = '\\0';\n\n\tdevice_lock(_dev);\n\told = dev->driver_override;\n\tif (strlen(driver_override)) {\n\t\tdev->driver_override = driver_override;\n\t} else {\n\t       kfree(driver_override);\n\t       dev->driver_override = NULL;\n\t}\n\tdevice_unlock(_dev);\n\n\tkfree(old);\n\n\treturn count;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,8 @@\n \tstruct amba_device *dev = to_amba_device(_dev);\n \tchar *driver_override, *old, *cp;\n \n-\tif (count > PATH_MAX)\n+\t/* We need to keep extra room for a newline */\n+\tif (count >= (PAGE_SIZE - 1))\n \t\treturn -EINVAL;\n \n \tdriver_override = kstrndup(buf, count, GFP_KERNEL);",
        "function_modified_lines": {
            "added": [
                "\t/* We need to keep extra room for a newline */",
                "\tif (count >= (PAGE_SIZE - 1))"
            ],
            "deleted": [
                "\tif (count > PATH_MAX)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In driver_override_store of bus.c, there is a possible out of bounds write due to an incorrect bounds check. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation. Product: Android Versions: Android kernel Android ID: A-74128061 References: Upstream kernel."
    },
    {
        "cve_id": "CVE-2018-9518",
        "code_before_change": "struct nfc_llcp_sdp_tlv *nfc_llcp_build_sdreq_tlv(u8 tid, char *uri,\n\t\t\t\t\t\t  size_t uri_len)\n{\n\tstruct nfc_llcp_sdp_tlv *sdreq;\n\n\tpr_debug(\"uri: %s, len: %zu\\n\", uri, uri_len);\n\n\tsdreq = kzalloc(sizeof(struct nfc_llcp_sdp_tlv), GFP_KERNEL);\n\tif (sdreq == NULL)\n\t\treturn NULL;\n\n\tsdreq->tlv_len = uri_len + 3;\n\n\tif (uri[uri_len - 1] == 0)\n\t\tsdreq->tlv_len--;\n\n\tsdreq->tlv = kzalloc(sdreq->tlv_len + 1, GFP_KERNEL);\n\tif (sdreq->tlv == NULL) {\n\t\tkfree(sdreq);\n\t\treturn NULL;\n\t}\n\n\tsdreq->tlv[0] = LLCP_TLV_SDREQ;\n\tsdreq->tlv[1] = sdreq->tlv_len - 2;\n\tsdreq->tlv[2] = tid;\n\n\tsdreq->tid = tid;\n\tsdreq->uri = sdreq->tlv + 3;\n\tmemcpy(sdreq->uri, uri, uri_len);\n\n\tsdreq->time = jiffies;\n\n\tINIT_HLIST_NODE(&sdreq->node);\n\n\treturn sdreq;\n}",
        "code_after_change": "struct nfc_llcp_sdp_tlv *nfc_llcp_build_sdreq_tlv(u8 tid, char *uri,\n\t\t\t\t\t\t  size_t uri_len)\n{\n\tstruct nfc_llcp_sdp_tlv *sdreq;\n\n\tpr_debug(\"uri: %s, len: %zu\\n\", uri, uri_len);\n\n\t/* sdreq->tlv_len is u8, takes uri_len, + 3 for header, + 1 for NULL */\n\tif (WARN_ON_ONCE(uri_len > U8_MAX - 4))\n\t\treturn NULL;\n\n\tsdreq = kzalloc(sizeof(struct nfc_llcp_sdp_tlv), GFP_KERNEL);\n\tif (sdreq == NULL)\n\t\treturn NULL;\n\n\tsdreq->tlv_len = uri_len + 3;\n\n\tif (uri[uri_len - 1] == 0)\n\t\tsdreq->tlv_len--;\n\n\tsdreq->tlv = kzalloc(sdreq->tlv_len + 1, GFP_KERNEL);\n\tif (sdreq->tlv == NULL) {\n\t\tkfree(sdreq);\n\t\treturn NULL;\n\t}\n\n\tsdreq->tlv[0] = LLCP_TLV_SDREQ;\n\tsdreq->tlv[1] = sdreq->tlv_len - 2;\n\tsdreq->tlv[2] = tid;\n\n\tsdreq->tid = tid;\n\tsdreq->uri = sdreq->tlv + 3;\n\tmemcpy(sdreq->uri, uri, uri_len);\n\n\tsdreq->time = jiffies;\n\n\tINIT_HLIST_NODE(&sdreq->node);\n\n\treturn sdreq;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,10 @@\n \tstruct nfc_llcp_sdp_tlv *sdreq;\n \n \tpr_debug(\"uri: %s, len: %zu\\n\", uri, uri_len);\n+\n+\t/* sdreq->tlv_len is u8, takes uri_len, + 3 for header, + 1 for NULL */\n+\tif (WARN_ON_ONCE(uri_len > U8_MAX - 4))\n+\t\treturn NULL;\n \n \tsdreq = kzalloc(sizeof(struct nfc_llcp_sdp_tlv), GFP_KERNEL);\n \tif (sdreq == NULL)",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* sdreq->tlv_len is u8, takes uri_len, + 3 for header, + 1 for NULL */",
                "\tif (WARN_ON_ONCE(uri_len > U8_MAX - 4))",
                "\t\treturn NULL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In nfc_llcp_build_sdreq_tlv of llcp_commands.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation. Product: Android. Versions: Android kernel. Android ID: A-73083945."
    },
    {
        "cve_id": "CVE-2019-11683",
        "code_before_change": "static struct sk_buff *udp_gro_receive_segment(struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct udphdr *uh = udp_hdr(skb);\n\tstruct sk_buff *pp = NULL;\n\tstruct udphdr *uh2;\n\tstruct sk_buff *p;\n\n\t/* requires non zero csum, for symmetry with GSO */\n\tif (!uh->check) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\n\t/* pull encapsulating udp header */\n\tskb_gro_pull(skb, sizeof(struct udphdr));\n\tskb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));\n\n\tlist_for_each_entry(p, head, list) {\n\t\tif (!NAPI_GRO_CB(p)->same_flow)\n\t\t\tcontinue;\n\n\t\tuh2 = udp_hdr(p);\n\n\t\t/* Match ports only, as csum is always non zero */\n\t\tif ((*(u32 *)&uh->source != *(u32 *)&uh2->source)) {\n\t\t\tNAPI_GRO_CB(p)->same_flow = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Terminate the flow on len mismatch or if it grow \"too much\".\n\t\t * Under small packet flood GRO count could elsewhere grow a lot\n\t\t * leading to execessive truesize values.\n\t\t * On len mismatch merge the first packet shorter than gso_size,\n\t\t * otherwise complete the GRO packet.\n\t\t */\n\t\tif (uh->len > uh2->len || skb_gro_receive(p, skb) ||\n\t\t    uh->len != uh2->len ||\n\t\t    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)\n\t\t\tpp = p;\n\n\t\treturn pp;\n\t}\n\n\t/* mismatch, but we never need to flush */\n\treturn NULL;\n}",
        "code_after_change": "static struct sk_buff *udp_gro_receive_segment(struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct udphdr *uh = udp_hdr(skb);\n\tstruct sk_buff *pp = NULL;\n\tstruct udphdr *uh2;\n\tstruct sk_buff *p;\n\tunsigned int ulen;\n\n\t/* requires non zero csum, for symmetry with GSO */\n\tif (!uh->check) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\n\t/* Do not deal with padded or malicious packets, sorry ! */\n\tulen = ntohs(uh->len);\n\tif (ulen <= sizeof(*uh) || ulen != skb_gro_len(skb)) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\t/* pull encapsulating udp header */\n\tskb_gro_pull(skb, sizeof(struct udphdr));\n\tskb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));\n\n\tlist_for_each_entry(p, head, list) {\n\t\tif (!NAPI_GRO_CB(p)->same_flow)\n\t\t\tcontinue;\n\n\t\tuh2 = udp_hdr(p);\n\n\t\t/* Match ports only, as csum is always non zero */\n\t\tif ((*(u32 *)&uh->source != *(u32 *)&uh2->source)) {\n\t\t\tNAPI_GRO_CB(p)->same_flow = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Terminate the flow on len mismatch or if it grow \"too much\".\n\t\t * Under small packet flood GRO count could elsewhere grow a lot\n\t\t * leading to excessive truesize values.\n\t\t * On len mismatch merge the first packet shorter than gso_size,\n\t\t * otherwise complete the GRO packet.\n\t\t */\n\t\tif (ulen > ntohs(uh2->len) || skb_gro_receive(p, skb) ||\n\t\t    ulen != ntohs(uh2->len) ||\n\t\t    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)\n\t\t\tpp = p;\n\n\t\treturn pp;\n\t}\n\n\t/* mismatch, but we never need to flush */\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tstruct sk_buff *pp = NULL;\n \tstruct udphdr *uh2;\n \tstruct sk_buff *p;\n+\tunsigned int ulen;\n \n \t/* requires non zero csum, for symmetry with GSO */\n \tif (!uh->check) {\n@@ -12,6 +13,12 @@\n \t\treturn NULL;\n \t}\n \n+\t/* Do not deal with padded or malicious packets, sorry ! */\n+\tulen = ntohs(uh->len);\n+\tif (ulen <= sizeof(*uh) || ulen != skb_gro_len(skb)) {\n+\t\tNAPI_GRO_CB(skb)->flush = 1;\n+\t\treturn NULL;\n+\t}\n \t/* pull encapsulating udp header */\n \tskb_gro_pull(skb, sizeof(struct udphdr));\n \tskb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));\n@@ -30,12 +37,12 @@\n \n \t\t/* Terminate the flow on len mismatch or if it grow \"too much\".\n \t\t * Under small packet flood GRO count could elsewhere grow a lot\n-\t\t * leading to execessive truesize values.\n+\t\t * leading to excessive truesize values.\n \t\t * On len mismatch merge the first packet shorter than gso_size,\n \t\t * otherwise complete the GRO packet.\n \t\t */\n-\t\tif (uh->len > uh2->len || skb_gro_receive(p, skb) ||\n-\t\t    uh->len != uh2->len ||\n+\t\tif (ulen > ntohs(uh2->len) || skb_gro_receive(p, skb) ||\n+\t\t    ulen != ntohs(uh2->len) ||\n \t\t    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)\n \t\t\tpp = p;\n ",
        "function_modified_lines": {
            "added": [
                "\tunsigned int ulen;",
                "\t/* Do not deal with padded or malicious packets, sorry ! */",
                "\tulen = ntohs(uh->len);",
                "\tif (ulen <= sizeof(*uh) || ulen != skb_gro_len(skb)) {",
                "\t\tNAPI_GRO_CB(skb)->flush = 1;",
                "\t\treturn NULL;",
                "\t}",
                "\t\t * leading to excessive truesize values.",
                "\t\tif (ulen > ntohs(uh2->len) || skb_gro_receive(p, skb) ||",
                "\t\t    ulen != ntohs(uh2->len) ||"
            ],
            "deleted": [
                "\t\t * leading to execessive truesize values.",
                "\t\tif (uh->len > uh2->len || skb_gro_receive(p, skb) ||",
                "\t\t    uh->len != uh2->len ||"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "udp_gro_receive_segment in net/ipv4/udp_offload.c in the Linux kernel 5.x before 5.0.13 allows remote attackers to cause a denial of service (slab-out-of-bounds memory corruption) or possibly have unspecified other impact via UDP packets with a 0 payload, because of mishandling of padded packets, aka the \"GRO packet of death\" issue."
    },
    {
        "cve_id": "CVE-2019-12817",
        "code_before_change": "static int hash__init_new_context(struct mm_struct *mm)\n{\n\tint index;\n\n\tindex = hash__alloc_context_id();\n\tif (index < 0)\n\t\treturn index;\n\n\t/*\n\t * The old code would re-promote on fork, we don't do that when using\n\t * slices as it could cause problem promoting slices that have been\n\t * forced down to 4K.\n\t *\n\t * For book3s we have MMU_NO_CONTEXT set to be ~0. Hence check\n\t * explicitly against context.id == 0. This ensures that we properly\n\t * initialize context slice details for newly allocated mm's (which will\n\t * have id == 0) and don't alter context slice inherited via fork (which\n\t * will have id != 0).\n\t *\n\t * We should not be calling init_new_context() on init_mm. Hence a\n\t * check against 0 is OK.\n\t */\n\tif (mm->context.id == 0)\n\t\tslice_init_new_context_exec(mm);\n\n\tsubpage_prot_init_new_context(mm);\n\n\tpkey_mm_init(mm);\n\treturn index;\n}",
        "code_after_change": "static int hash__init_new_context(struct mm_struct *mm)\n{\n\tint index;\n\n\t/*\n\t * The old code would re-promote on fork, we don't do that when using\n\t * slices as it could cause problem promoting slices that have been\n\t * forced down to 4K.\n\t *\n\t * For book3s we have MMU_NO_CONTEXT set to be ~0. Hence check\n\t * explicitly against context.id == 0. This ensures that we properly\n\t * initialize context slice details for newly allocated mm's (which will\n\t * have id == 0) and don't alter context slice inherited via fork (which\n\t * will have id != 0).\n\t *\n\t * We should not be calling init_new_context() on init_mm. Hence a\n\t * check against 0 is OK.\n\t */\n\tif (mm->context.id == 0)\n\t\tslice_init_new_context_exec(mm);\n\n\tindex = realloc_context_ids(&mm->context);\n\tif (index < 0)\n\t\treturn index;\n\n\tsubpage_prot_init_new_context(mm);\n\n\tpkey_mm_init(mm);\n\treturn index;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,6 @@\n static int hash__init_new_context(struct mm_struct *mm)\n {\n \tint index;\n-\n-\tindex = hash__alloc_context_id();\n-\tif (index < 0)\n-\t\treturn index;\n \n \t/*\n \t * The old code would re-promote on fork, we don't do that when using\n@@ -23,6 +19,10 @@\n \tif (mm->context.id == 0)\n \t\tslice_init_new_context_exec(mm);\n \n+\tindex = realloc_context_ids(&mm->context);\n+\tif (index < 0)\n+\t\treturn index;\n+\n \tsubpage_prot_init_new_context(mm);\n \n \tpkey_mm_init(mm);",
        "function_modified_lines": {
            "added": [
                "\tindex = realloc_context_ids(&mm->context);",
                "\tif (index < 0)",
                "\t\treturn index;",
                ""
            ],
            "deleted": [
                "",
                "\tindex = hash__alloc_context_id();",
                "\tif (index < 0)",
                "\t\treturn index;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "arch/powerpc/mm/mmu_context_book3s64.c in the Linux kernel before 5.1.15 for powerpc has a bug where unrelated processes may be able to read/write to one another's virtual memory under certain conditions via an mmap above 512 TB. Only a subset of powerpc systems are affected."
    },
    {
        "cve_id": "CVE-2019-13631",
        "code_before_change": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[10] = \"\";\n\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i++];\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = (1U << PREF_SIZE(prefix)) >> 1;\n\t\tif (i + size > length) {\n\t\t\tdev_err(ddev,\n\t\t\t\t\"Not enough data (need %d, have %d)\\n\",\n\t\t\t\ti + size, length);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\t\t\t\tmaintype = 'E';\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}",
        "code_after_change": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[MAX_COLLECTION_LEVELS + 1] = { 0 };\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i++];\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = (1U << PREF_SIZE(prefix)) >> 1;\n\t\tif (i + size > length) {\n\t\t\tdev_err(ddev,\n\t\t\t\t\"Not enough data (need %d, have %d)\\n\",\n\t\t\t\ti + size, length);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (indent == MAX_COLLECTION_LEVELS) {\n\t\t\t\t\tdev_err(ddev, \"Collection level %d would exceed limit of %d\\n\",\n\t\t\t\t\t\tindent + 1,\n\t\t\t\t\t\tMAX_COLLECTION_LEVELS);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tmaintype = 'E';\n\n\t\t\t\tif (indent == 0) {\n\t\t\t\t\tdev_err(ddev, \"Collection level already at zero\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,7 @@\n \tchar  maintype = 'x';\n \tchar  globtype[12];\n \tint   indent = 0;\n-\tchar  indentstr[10] = \"\";\n-\n+\tchar  indentstr[MAX_COLLECTION_LEVELS + 1] = { 0 };\n \n \tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n \n@@ -152,6 +151,13 @@\n \t\t\tcase TAG_MAIN_COL_START:\n \t\t\t\tmaintype = 'S';\n \n+\t\t\t\tif (indent == MAX_COLLECTION_LEVELS) {\n+\t\t\t\t\tdev_err(ddev, \"Collection level %d would exceed limit of %d\\n\",\n+\t\t\t\t\t\tindent + 1,\n+\t\t\t\t\t\tMAX_COLLECTION_LEVELS);\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\n \t\t\t\tif (data == 0) {\n \t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n \t\t\t\t\tstrcpy(globtype, \"Physical\");\n@@ -171,8 +177,15 @@\n \t\t\t\tbreak;\n \n \t\t\tcase TAG_MAIN_COL_END:\n+\t\t\t\tmaintype = 'E';\n+\n+\t\t\t\tif (indent == 0) {\n+\t\t\t\t\tdev_err(ddev, \"Collection level already at zero\\n\");\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\n \t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n-\t\t\t\tmaintype = 'E';\n+\n \t\t\t\tindent--;\n \t\t\t\tfor (x = 0; x < indent; x++)\n \t\t\t\t\tindentstr[x] = '-';",
        "function_modified_lines": {
            "added": [
                "\tchar  indentstr[MAX_COLLECTION_LEVELS + 1] = { 0 };",
                "\t\t\t\tif (indent == MAX_COLLECTION_LEVELS) {",
                "\t\t\t\t\tdev_err(ddev, \"Collection level %d would exceed limit of %d\\n\",",
                "\t\t\t\t\t\tindent + 1,",
                "\t\t\t\t\t\tMAX_COLLECTION_LEVELS);",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}",
                "",
                "\t\t\t\tmaintype = 'E';",
                "",
                "\t\t\t\tif (indent == 0) {",
                "\t\t\t\t\tdev_err(ddev, \"Collection level already at zero\\n\");",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}",
                "",
                ""
            ],
            "deleted": [
                "\tchar  indentstr[10] = \"\";",
                "",
                "\t\t\t\tmaintype = 'E';"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In parse_hid_report_descriptor in drivers/input/tablet/gtco.c in the Linux kernel through 5.2.1, a malicious USB device can send an HID report that triggers an out-of-bounds write during generation of debugging messages."
    },
    {
        "cve_id": "CVE-2019-14821",
        "code_before_change": "static int coalesced_mmio_write(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_io_device *this, gpa_t addr,\n\t\t\t\tint len, const void *val)\n{\n\tstruct kvm_coalesced_mmio_dev *dev = to_mmio(this);\n\tstruct kvm_coalesced_mmio_ring *ring = dev->kvm->coalesced_mmio_ring;\n\n\tif (!coalesced_mmio_in_range(dev, addr, len))\n\t\treturn -EOPNOTSUPP;\n\n\tspin_lock(&dev->kvm->ring_lock);\n\n\tif (!coalesced_mmio_has_room(dev)) {\n\t\tspin_unlock(&dev->kvm->ring_lock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t/* copy data in first free entry of the ring */\n\n\tring->coalesced_mmio[ring->last].phys_addr = addr;\n\tring->coalesced_mmio[ring->last].len = len;\n\tmemcpy(ring->coalesced_mmio[ring->last].data, val, len);\n\tring->coalesced_mmio[ring->last].pio = dev->zone.pio;\n\tsmp_wmb();\n\tring->last = (ring->last + 1) % KVM_COALESCED_MMIO_MAX;\n\tspin_unlock(&dev->kvm->ring_lock);\n\treturn 0;\n}",
        "code_after_change": "static int coalesced_mmio_write(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct kvm_io_device *this, gpa_t addr,\n\t\t\t\tint len, const void *val)\n{\n\tstruct kvm_coalesced_mmio_dev *dev = to_mmio(this);\n\tstruct kvm_coalesced_mmio_ring *ring = dev->kvm->coalesced_mmio_ring;\n\t__u32 insert;\n\n\tif (!coalesced_mmio_in_range(dev, addr, len))\n\t\treturn -EOPNOTSUPP;\n\n\tspin_lock(&dev->kvm->ring_lock);\n\n\tinsert = READ_ONCE(ring->last);\n\tif (!coalesced_mmio_has_room(dev, insert) ||\n\t    insert >= KVM_COALESCED_MMIO_MAX) {\n\t\tspin_unlock(&dev->kvm->ring_lock);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t/* copy data in first free entry of the ring */\n\n\tring->coalesced_mmio[insert].phys_addr = addr;\n\tring->coalesced_mmio[insert].len = len;\n\tmemcpy(ring->coalesced_mmio[insert].data, val, len);\n\tring->coalesced_mmio[insert].pio = dev->zone.pio;\n\tsmp_wmb();\n\tring->last = (insert + 1) % KVM_COALESCED_MMIO_MAX;\n\tspin_unlock(&dev->kvm->ring_lock);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,25 +4,28 @@\n {\n \tstruct kvm_coalesced_mmio_dev *dev = to_mmio(this);\n \tstruct kvm_coalesced_mmio_ring *ring = dev->kvm->coalesced_mmio_ring;\n+\t__u32 insert;\n \n \tif (!coalesced_mmio_in_range(dev, addr, len))\n \t\treturn -EOPNOTSUPP;\n \n \tspin_lock(&dev->kvm->ring_lock);\n \n-\tif (!coalesced_mmio_has_room(dev)) {\n+\tinsert = READ_ONCE(ring->last);\n+\tif (!coalesced_mmio_has_room(dev, insert) ||\n+\t    insert >= KVM_COALESCED_MMIO_MAX) {\n \t\tspin_unlock(&dev->kvm->ring_lock);\n \t\treturn -EOPNOTSUPP;\n \t}\n \n \t/* copy data in first free entry of the ring */\n \n-\tring->coalesced_mmio[ring->last].phys_addr = addr;\n-\tring->coalesced_mmio[ring->last].len = len;\n-\tmemcpy(ring->coalesced_mmio[ring->last].data, val, len);\n-\tring->coalesced_mmio[ring->last].pio = dev->zone.pio;\n+\tring->coalesced_mmio[insert].phys_addr = addr;\n+\tring->coalesced_mmio[insert].len = len;\n+\tmemcpy(ring->coalesced_mmio[insert].data, val, len);\n+\tring->coalesced_mmio[insert].pio = dev->zone.pio;\n \tsmp_wmb();\n-\tring->last = (ring->last + 1) % KVM_COALESCED_MMIO_MAX;\n+\tring->last = (insert + 1) % KVM_COALESCED_MMIO_MAX;\n \tspin_unlock(&dev->kvm->ring_lock);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\t__u32 insert;",
                "\tinsert = READ_ONCE(ring->last);",
                "\tif (!coalesced_mmio_has_room(dev, insert) ||",
                "\t    insert >= KVM_COALESCED_MMIO_MAX) {",
                "\tring->coalesced_mmio[insert].phys_addr = addr;",
                "\tring->coalesced_mmio[insert].len = len;",
                "\tmemcpy(ring->coalesced_mmio[insert].data, val, len);",
                "\tring->coalesced_mmio[insert].pio = dev->zone.pio;",
                "\tring->last = (insert + 1) % KVM_COALESCED_MMIO_MAX;"
            ],
            "deleted": [
                "\tif (!coalesced_mmio_has_room(dev)) {",
                "\tring->coalesced_mmio[ring->last].phys_addr = addr;",
                "\tring->coalesced_mmio[ring->last].len = len;",
                "\tmemcpy(ring->coalesced_mmio[ring->last].data, val, len);",
                "\tring->coalesced_mmio[ring->last].pio = dev->zone.pio;",
                "\tring->last = (ring->last + 1) % KVM_COALESCED_MMIO_MAX;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds access issue was found in the Linux kernel, all versions through 5.3, in the way Linux kernel's KVM hypervisor implements the Coalesced MMIO write operation. It operates on an MMIO ring buffer 'struct kvm_coalesced_mmio' object, wherein write indices 'ring->first' and 'ring->last' value could be supplied by a host user-space process. An unprivileged host user or process with access to '/dev/kvm' device could use this flaw to crash the host kernel, resulting in a denial of service or potentially escalating privileges on the system."
    },
    {
        "cve_id": "CVE-2019-19319",
        "code_before_change": "int ext4_setup_system_zone(struct super_block *sb)\n{\n\text4_group_t ngroups = ext4_get_groups_count(sb);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp;\n\text4_group_t i;\n\tint flex_size = ext4_flex_bg_size(sbi);\n\tint ret;\n\n\tif (!test_opt(sb, BLOCK_VALIDITY)) {\n\t\tif (sbi->system_blks.rb_node)\n\t\t\text4_release_system_zone(sb);\n\t\treturn 0;\n\t}\n\tif (sbi->system_blks.rb_node)\n\t\treturn 0;\n\n\tfor (i=0; i < ngroups; i++) {\n\t\tif (ext4_bg_has_super(sb, i) &&\n\t\t    ((i < 5) || ((i % flex_size) == 0)))\n\t\t\tadd_system_zone(sbi, ext4_group_first_block_no(sb, i),\n\t\t\t\t\text4_bg_num_gdb(sb, i) + 1);\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\t\tret = add_system_zone(sbi, ext4_block_bitmap(sb, gdp), 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = add_system_zone(sbi, ext4_inode_bitmap(sb, gdp), 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = add_system_zone(sbi, ext4_inode_table(sb, gdp),\n\t\t\t\tsbi->s_itb_per_group);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (test_opt(sb, DEBUG))\n\t\tdebug_print_tree(sbi);\n\treturn 0;\n}",
        "code_after_change": "int ext4_setup_system_zone(struct super_block *sb)\n{\n\text4_group_t ngroups = ext4_get_groups_count(sb);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp;\n\text4_group_t i;\n\tint flex_size = ext4_flex_bg_size(sbi);\n\tint ret;\n\n\tif (!test_opt(sb, BLOCK_VALIDITY)) {\n\t\tif (sbi->system_blks.rb_node)\n\t\t\text4_release_system_zone(sb);\n\t\treturn 0;\n\t}\n\tif (sbi->system_blks.rb_node)\n\t\treturn 0;\n\n\tfor (i=0; i < ngroups; i++) {\n\t\tif (ext4_bg_has_super(sb, i) &&\n\t\t    ((i < 5) || ((i % flex_size) == 0)))\n\t\t\tadd_system_zone(sbi, ext4_group_first_block_no(sb, i),\n\t\t\t\t\text4_bg_num_gdb(sb, i) + 1);\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\t\tret = add_system_zone(sbi, ext4_block_bitmap(sb, gdp), 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = add_system_zone(sbi, ext4_inode_bitmap(sb, gdp), 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = add_system_zone(sbi, ext4_inode_table(sb, gdp),\n\t\t\t\tsbi->s_itb_per_group);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tif (ext4_has_feature_journal(sb) && sbi->s_es->s_journal_inum) {\n\t\tret = ext4_protect_reserved_inode(sb,\n\t\t\t\tle32_to_cpu(sbi->s_es->s_journal_inum));\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (test_opt(sb, DEBUG))\n\t\tdebug_print_tree(sbi);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,6 +32,12 @@\n \t\tif (ret)\n \t\t\treturn ret;\n \t}\n+\tif (ext4_has_feature_journal(sb) && sbi->s_es->s_journal_inum) {\n+\t\tret = ext4_protect_reserved_inode(sb,\n+\t\t\t\tle32_to_cpu(sbi->s_es->s_journal_inum));\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n \n \tif (test_opt(sb, DEBUG))\n \t\tdebug_print_tree(sbi);",
        "function_modified_lines": {
            "added": [
                "\tif (ext4_has_feature_journal(sb) && sbi->s_es->s_journal_inum) {",
                "\t\tret = ext4_protect_reserved_inode(sb,",
                "\t\t\t\tle32_to_cpu(sbi->s_es->s_journal_inum));",
                "\t\tif (ret)",
                "\t\t\treturn ret;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In the Linux kernel before 5.2, a setxattr operation, after a mount of a crafted ext4 image, can cause a slab-out-of-bounds write access because of an ext4_xattr_set_entry use-after-free in fs/ext4/xattr.c when a large old_size value is used in a memset call, aka CID-345c0dbf3a30."
    },
    {
        "cve_id": "CVE-2019-19319",
        "code_before_change": "static int __check_block_validity(struct inode *inode, const char *func,\n\t\t\t\tunsigned int line,\n\t\t\t\tstruct ext4_map_blocks *map)\n{\n\tif (!ext4_data_block_valid(EXT4_SB(inode->i_sb), map->m_pblk,\n\t\t\t\t   map->m_len)) {\n\t\text4_error_inode(inode, func, line, map->m_pblk,\n\t\t\t\t \"lblock %lu mapped to illegal pblock %llu \"\n\t\t\t\t \"(length %d)\", (unsigned long) map->m_lblk,\n\t\t\t\t map->m_pblk, map->m_len);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int __check_block_validity(struct inode *inode, const char *func,\n\t\t\t\tunsigned int line,\n\t\t\t\tstruct ext4_map_blocks *map)\n{\n\tif (ext4_has_feature_journal(inode->i_sb) &&\n\t    (inode->i_ino ==\n\t     le32_to_cpu(EXT4_SB(inode->i_sb)->s_es->s_journal_inum)))\n\t\treturn 0;\n\tif (!ext4_data_block_valid(EXT4_SB(inode->i_sb), map->m_pblk,\n\t\t\t\t   map->m_len)) {\n\t\text4_error_inode(inode, func, line, map->m_pblk,\n\t\t\t\t \"lblock %lu mapped to illegal pblock %llu \"\n\t\t\t\t \"(length %d)\", (unsigned long) map->m_lblk,\n\t\t\t\t map->m_pblk, map->m_len);\n\t\treturn -EFSCORRUPTED;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,10 @@\n \t\t\t\tunsigned int line,\n \t\t\t\tstruct ext4_map_blocks *map)\n {\n+\tif (ext4_has_feature_journal(inode->i_sb) &&\n+\t    (inode->i_ino ==\n+\t     le32_to_cpu(EXT4_SB(inode->i_sb)->s_es->s_journal_inum)))\n+\t\treturn 0;\n \tif (!ext4_data_block_valid(EXT4_SB(inode->i_sb), map->m_pblk,\n \t\t\t\t   map->m_len)) {\n \t\text4_error_inode(inode, func, line, map->m_pblk,",
        "function_modified_lines": {
            "added": [
                "\tif (ext4_has_feature_journal(inode->i_sb) &&",
                "\t    (inode->i_ino ==",
                "\t     le32_to_cpu(EXT4_SB(inode->i_sb)->s_es->s_journal_inum)))",
                "\t\treturn 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In the Linux kernel before 5.2, a setxattr operation, after a mount of a crafted ext4 image, can cause a slab-out-of-bounds write access because of an ext4_xattr_set_entry use-after-free in fs/ext4/xattr.c when a large old_size value is used in a memset call, aka CID-345c0dbf3a30."
    },
    {
        "cve_id": "CVE-2019-19332",
        "code_before_change": "static inline int __do_cpuid_func(struct kvm_cpuid_entry2 *entry, u32 function,\n\t\t\t\t  int *nent, int maxnent)\n{\n\tint r;\n\tunsigned f_nx = is_efer_nx() ? F(NX) : 0;\n#ifdef CONFIG_X86_64\n\tunsigned f_gbpages = (kvm_x86_ops->get_lpage_level() == PT_PDPE_LEVEL)\n\t\t\t\t? F(GBPAGES) : 0;\n\tunsigned f_lm = F(LM);\n#else\n\tunsigned f_gbpages = 0;\n\tunsigned f_lm = 0;\n#endif\n\tunsigned f_rdtscp = kvm_x86_ops->rdtscp_supported() ? F(RDTSCP) : 0;\n\tunsigned f_xsaves = kvm_x86_ops->xsaves_supported() ? F(XSAVES) : 0;\n\tunsigned f_intel_pt = kvm_x86_ops->pt_supported() ? F(INTEL_PT) : 0;\n\n\t/* cpuid 1.edx */\n\tconst u32 kvm_cpuid_1_edx_x86_features =\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SEP) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* PSN */ | F(CLFLUSH) |\n\t\t0 /* Reserved, DS, ACPI */ | F(MMX) |\n\t\tF(FXSR) | F(XMM) | F(XMM2) | F(SELFSNOOP) |\n\t\t0 /* HTT, TM, Reserved, PBE */;\n\t/* cpuid 0x80000001.edx */\n\tconst u32 kvm_cpuid_8000_0001_edx_x86_features =\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SYSCALL) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* Reserved */ |\n\t\tf_nx | 0 /* Reserved */ | F(MMXEXT) | F(MMX) |\n\t\tF(FXSR) | F(FXSR_OPT) | f_gbpages | f_rdtscp |\n\t\t0 /* Reserved */ | f_lm | F(3DNOWEXT) | F(3DNOW);\n\t/* cpuid 1.ecx */\n\tconst u32 kvm_cpuid_1_ecx_x86_features =\n\t\t/* NOTE: MONITOR (and MWAIT) are emulated as NOP,\n\t\t * but *not* advertised to guests via CPUID ! */\n\t\tF(XMM3) | F(PCLMULQDQ) | 0 /* DTES64, MONITOR */ |\n\t\t0 /* DS-CPL, VMX, SMX, EST */ |\n\t\t0 /* TM2 */ | F(SSSE3) | 0 /* CNXT-ID */ | 0 /* Reserved */ |\n\t\tF(FMA) | F(CX16) | 0 /* xTPR Update, PDCM */ |\n\t\tF(PCID) | 0 /* Reserved, DCA */ | F(XMM4_1) |\n\t\tF(XMM4_2) | F(X2APIC) | F(MOVBE) | F(POPCNT) |\n\t\t0 /* Reserved*/ | F(AES) | F(XSAVE) | 0 /* OSXSAVE */ | F(AVX) |\n\t\tF(F16C) | F(RDRAND);\n\t/* cpuid 0x80000001.ecx */\n\tconst u32 kvm_cpuid_8000_0001_ecx_x86_features =\n\t\tF(LAHF_LM) | F(CMP_LEGACY) | 0 /*SVM*/ | 0 /* ExtApicSpace */ |\n\t\tF(CR8_LEGACY) | F(ABM) | F(SSE4A) | F(MISALIGNSSE) |\n\t\tF(3DNOWPREFETCH) | F(OSVW) | 0 /* IBS */ | F(XOP) |\n\t\t0 /* SKINIT, WDT, LWP */ | F(FMA4) | F(TBM) |\n\t\tF(TOPOEXT) | F(PERFCTR_CORE);\n\n\t/* cpuid 0x80000008.ebx */\n\tconst u32 kvm_cpuid_8000_0008_ebx_x86_features =\n\t\tF(CLZERO) | F(XSAVEERPTR) |\n\t\tF(WBNOINVD) | F(AMD_IBPB) | F(AMD_IBRS) | F(AMD_SSBD) | F(VIRT_SSBD) |\n\t\tF(AMD_SSB_NO) | F(AMD_STIBP) | F(AMD_STIBP_ALWAYS_ON);\n\n\t/* cpuid 0xC0000001.edx */\n\tconst u32 kvm_cpuid_C000_0001_edx_x86_features =\n\t\tF(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |\n\t\tF(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |\n\t\tF(PMM) | F(PMM_EN);\n\n\t/* cpuid 0xD.1.eax */\n\tconst u32 kvm_cpuid_D_1_eax_x86_features =\n\t\tF(XSAVEOPT) | F(XSAVEC) | F(XGETBV1) | f_xsaves;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tif (*nent >= maxnent)\n\t\tgoto out;\n\n\tdo_host_cpuid(entry, function, 0);\n\t++*nent;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tentry->edx &= kvm_cpuid_1_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_1_EDX);\n\t\tentry->ecx &= kvm_cpuid_1_ecx_x86_features;\n\t\tcpuid_mask(&entry->ecx, CPUID_1_ECX);\n\t\t/* we support x2apic emulation even if host does not support\n\t\t * it since we emulate x2apic in software */\n\t\tentry->ecx |= F(X2APIC);\n\t\tbreak;\n\t/* function 2 entries are STATEFUL. That is, repeated cpuid commands\n\t * may return different values. This forces us to get_cpu() before\n\t * issuing the first command, and also to emulate this annoying behavior\n\t * in kvm_emulate_cpuid() using KVM_CPUID_FLAG_STATE_READ_NEXT */\n\tcase 2: {\n\t\tint t, times = entry->eax & 0xff;\n\n\t\tentry->flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;\n\t\tfor (t = 1; t < times; ++t) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[t], function, 0);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d: {\n\t\tint i, cache_type;\n\n\t\t/* read more entries until cache_type is zero */\n\t\tfor (i = 1; ; ++i) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tcache_type = entry[i - 1].eax & 0x1f;\n\t\t\tif (!cache_type)\n\t\t\t\tbreak;\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7: {\n\t\tint i;\n\n\t\tfor (i = 0; ; ) {\n\t\t\tdo_cpuid_7_mask(&entry[i], i);\n\t\t\tif (i == entry->eax)\n\t\t\t\tbreak;\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\t++i;\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb: {\n\t\tint i;\n\n\t\t/*\n\t\t * We filled in entry[0] for CPUID(EAX=<function>,\n\t\t * ECX=00H) above.  If its level type (ECX[15:8]) is\n\t\t * zero, then the leaf is unimplemented, and we're\n\t\t * done.  Otherwise, continue to populate entries\n\t\t * until the level type (ECX[15:8]) of the previously\n\t\t * added entry is zero.\n\t\t */\n\t\tfor (i = 1; entry[i - 1].ecx & 0xff00; ++i) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 0xd: {\n\t\tint idx, i;\n\t\tu64 supported = kvm_supported_xcr0();\n\n\t\tentry->eax &= supported;\n\t\tentry->ebx = xstate_required_size(supported, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported >> 32;\n\t\tif (!supported)\n\t\t\tbreak;\n\n\t\tfor (idx = 1, i = 1; idx < 64; ++idx) {\n\t\t\tu64 mask = ((u64)1 << idx);\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[i], function, idx);\n\t\t\tif (idx == 1) {\n\t\t\t\tentry[i].eax &= kvm_cpuid_D_1_eax_x86_features;\n\t\t\t\tcpuid_mask(&entry[i].eax, CPUID_D_1_EAX);\n\t\t\t\tentry[i].ebx = 0;\n\t\t\t\tif (entry[i].eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\t\t\tentry[i].ebx =\n\t\t\t\t\t\txstate_required_size(supported,\n\t\t\t\t\t\t\t\t     true);\n\t\t\t} else {\n\t\t\t\tif (entry[i].eax == 0 || !(supported & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tif (WARN_ON_ONCE(entry[i].ecx & 1))\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry[i].ecx = 0;\n\t\t\tentry[i].edx = 0;\n\t\t\t++*nent;\n\t\t\t++i;\n\t\t}\n\t\tbreak;\n\t}\n\t/* Intel PT */\n\tcase 0x14: {\n\t\tint t, times = entry->eax;\n\n\t\tif (!f_intel_pt)\n\t\t\tbreak;\n\n\t\tfor (t = 1; t <= times; ++t) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\t\t\tdo_host_cpuid(&entry[t], function, t);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tentry->edx &= kvm_cpuid_8000_0001_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_8000_0001_EDX);\n\t\tentry->ecx &= kvm_cpuid_8000_0001_ecx_x86_features;\n\t\tcpuid_mask(&entry->ecx, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tentry->ebx &= kvm_cpuid_8000_0008_ebx_x86_features;\n\t\tcpuid_mask(&entry->ebx, CPUID_8000_0008_EBX);\n\t\t/*\n\t\t * AMD has separate bits for each SPEC_CTRL bit.\n\t\t * arch/x86/kernel/cpu/bugs.c is kind enough to\n\t\t * record that in cpufeatures so use them.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_IBPB))\n\t\t\tentry->ebx |= F(AMD_IBPB);\n\t\tif (boot_cpu_has(X86_FEATURE_IBRS))\n\t\t\tentry->ebx |= F(AMD_IBRS);\n\t\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\t\tentry->ebx |= F(AMD_STIBP);\n\t\tif (boot_cpu_has(X86_FEATURE_SSBD))\n\t\t\tentry->ebx |= F(AMD_SSBD);\n\t\tif (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))\n\t\t\tentry->ebx |= F(AMD_SSB_NO);\n\t\t/*\n\t\t * The preference is to use SPEC CTRL MSR instead of the\n\t\t * VIRT_SPEC MSR.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&\n\t\t    !boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\t\tentry->ebx |= F(VIRT_SSBD);\n\t\tbreak;\n\t}\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tentry->edx &= kvm_cpuid_C000_0001_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tkvm_x86_ops->set_supported_cpuid(function, entry);\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}",
        "code_after_change": "static inline int __do_cpuid_func(struct kvm_cpuid_entry2 *entry, u32 function,\n\t\t\t\t  int *nent, int maxnent)\n{\n\tint r;\n\tunsigned f_nx = is_efer_nx() ? F(NX) : 0;\n#ifdef CONFIG_X86_64\n\tunsigned f_gbpages = (kvm_x86_ops->get_lpage_level() == PT_PDPE_LEVEL)\n\t\t\t\t? F(GBPAGES) : 0;\n\tunsigned f_lm = F(LM);\n#else\n\tunsigned f_gbpages = 0;\n\tunsigned f_lm = 0;\n#endif\n\tunsigned f_rdtscp = kvm_x86_ops->rdtscp_supported() ? F(RDTSCP) : 0;\n\tunsigned f_xsaves = kvm_x86_ops->xsaves_supported() ? F(XSAVES) : 0;\n\tunsigned f_intel_pt = kvm_x86_ops->pt_supported() ? F(INTEL_PT) : 0;\n\n\t/* cpuid 1.edx */\n\tconst u32 kvm_cpuid_1_edx_x86_features =\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SEP) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* PSN */ | F(CLFLUSH) |\n\t\t0 /* Reserved, DS, ACPI */ | F(MMX) |\n\t\tF(FXSR) | F(XMM) | F(XMM2) | F(SELFSNOOP) |\n\t\t0 /* HTT, TM, Reserved, PBE */;\n\t/* cpuid 0x80000001.edx */\n\tconst u32 kvm_cpuid_8000_0001_edx_x86_features =\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SYSCALL) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* Reserved */ |\n\t\tf_nx | 0 /* Reserved */ | F(MMXEXT) | F(MMX) |\n\t\tF(FXSR) | F(FXSR_OPT) | f_gbpages | f_rdtscp |\n\t\t0 /* Reserved */ | f_lm | F(3DNOWEXT) | F(3DNOW);\n\t/* cpuid 1.ecx */\n\tconst u32 kvm_cpuid_1_ecx_x86_features =\n\t\t/* NOTE: MONITOR (and MWAIT) are emulated as NOP,\n\t\t * but *not* advertised to guests via CPUID ! */\n\t\tF(XMM3) | F(PCLMULQDQ) | 0 /* DTES64, MONITOR */ |\n\t\t0 /* DS-CPL, VMX, SMX, EST */ |\n\t\t0 /* TM2 */ | F(SSSE3) | 0 /* CNXT-ID */ | 0 /* Reserved */ |\n\t\tF(FMA) | F(CX16) | 0 /* xTPR Update, PDCM */ |\n\t\tF(PCID) | 0 /* Reserved, DCA */ | F(XMM4_1) |\n\t\tF(XMM4_2) | F(X2APIC) | F(MOVBE) | F(POPCNT) |\n\t\t0 /* Reserved*/ | F(AES) | F(XSAVE) | 0 /* OSXSAVE */ | F(AVX) |\n\t\tF(F16C) | F(RDRAND);\n\t/* cpuid 0x80000001.ecx */\n\tconst u32 kvm_cpuid_8000_0001_ecx_x86_features =\n\t\tF(LAHF_LM) | F(CMP_LEGACY) | 0 /*SVM*/ | 0 /* ExtApicSpace */ |\n\t\tF(CR8_LEGACY) | F(ABM) | F(SSE4A) | F(MISALIGNSSE) |\n\t\tF(3DNOWPREFETCH) | F(OSVW) | 0 /* IBS */ | F(XOP) |\n\t\t0 /* SKINIT, WDT, LWP */ | F(FMA4) | F(TBM) |\n\t\tF(TOPOEXT) | F(PERFCTR_CORE);\n\n\t/* cpuid 0x80000008.ebx */\n\tconst u32 kvm_cpuid_8000_0008_ebx_x86_features =\n\t\tF(CLZERO) | F(XSAVEERPTR) |\n\t\tF(WBNOINVD) | F(AMD_IBPB) | F(AMD_IBRS) | F(AMD_SSBD) | F(VIRT_SSBD) |\n\t\tF(AMD_SSB_NO) | F(AMD_STIBP) | F(AMD_STIBP_ALWAYS_ON);\n\n\t/* cpuid 0xC0000001.edx */\n\tconst u32 kvm_cpuid_C000_0001_edx_x86_features =\n\t\tF(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |\n\t\tF(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |\n\t\tF(PMM) | F(PMM_EN);\n\n\t/* cpuid 0xD.1.eax */\n\tconst u32 kvm_cpuid_D_1_eax_x86_features =\n\t\tF(XSAVEOPT) | F(XSAVEC) | F(XGETBV1) | f_xsaves;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tif (WARN_ON(*nent >= maxnent))\n\t\tgoto out;\n\n\tdo_host_cpuid(entry, function, 0);\n\t++*nent;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tentry->edx &= kvm_cpuid_1_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_1_EDX);\n\t\tentry->ecx &= kvm_cpuid_1_ecx_x86_features;\n\t\tcpuid_mask(&entry->ecx, CPUID_1_ECX);\n\t\t/* we support x2apic emulation even if host does not support\n\t\t * it since we emulate x2apic in software */\n\t\tentry->ecx |= F(X2APIC);\n\t\tbreak;\n\t/* function 2 entries are STATEFUL. That is, repeated cpuid commands\n\t * may return different values. This forces us to get_cpu() before\n\t * issuing the first command, and also to emulate this annoying behavior\n\t * in kvm_emulate_cpuid() using KVM_CPUID_FLAG_STATE_READ_NEXT */\n\tcase 2: {\n\t\tint t, times = entry->eax & 0xff;\n\n\t\tentry->flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;\n\t\tfor (t = 1; t < times; ++t) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[t], function, 0);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d: {\n\t\tint i, cache_type;\n\n\t\t/* read more entries until cache_type is zero */\n\t\tfor (i = 1; ; ++i) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tcache_type = entry[i - 1].eax & 0x1f;\n\t\t\tif (!cache_type)\n\t\t\t\tbreak;\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7: {\n\t\tint i;\n\n\t\tfor (i = 0; ; ) {\n\t\t\tdo_cpuid_7_mask(&entry[i], i);\n\t\t\tif (i == entry->eax)\n\t\t\t\tbreak;\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\t++i;\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb: {\n\t\tint i;\n\n\t\t/*\n\t\t * We filled in entry[0] for CPUID(EAX=<function>,\n\t\t * ECX=00H) above.  If its level type (ECX[15:8]) is\n\t\t * zero, then the leaf is unimplemented, and we're\n\t\t * done.  Otherwise, continue to populate entries\n\t\t * until the level type (ECX[15:8]) of the previously\n\t\t * added entry is zero.\n\t\t */\n\t\tfor (i = 1; entry[i - 1].ecx & 0xff00; ++i) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[i], function, i);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 0xd: {\n\t\tint idx, i;\n\t\tu64 supported = kvm_supported_xcr0();\n\n\t\tentry->eax &= supported;\n\t\tentry->ebx = xstate_required_size(supported, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported >> 32;\n\t\tif (!supported)\n\t\t\tbreak;\n\n\t\tfor (idx = 1, i = 1; idx < 64; ++idx) {\n\t\t\tu64 mask = ((u64)1 << idx);\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\n\t\t\tdo_host_cpuid(&entry[i], function, idx);\n\t\t\tif (idx == 1) {\n\t\t\t\tentry[i].eax &= kvm_cpuid_D_1_eax_x86_features;\n\t\t\t\tcpuid_mask(&entry[i].eax, CPUID_D_1_EAX);\n\t\t\t\tentry[i].ebx = 0;\n\t\t\t\tif (entry[i].eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\t\t\tentry[i].ebx =\n\t\t\t\t\t\txstate_required_size(supported,\n\t\t\t\t\t\t\t\t     true);\n\t\t\t} else {\n\t\t\t\tif (entry[i].eax == 0 || !(supported & mask))\n\t\t\t\t\tcontinue;\n\t\t\t\tif (WARN_ON_ONCE(entry[i].ecx & 1))\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry[i].ecx = 0;\n\t\t\tentry[i].edx = 0;\n\t\t\t++*nent;\n\t\t\t++i;\n\t\t}\n\t\tbreak;\n\t}\n\t/* Intel PT */\n\tcase 0x14: {\n\t\tint t, times = entry->eax;\n\n\t\tif (!f_intel_pt)\n\t\t\tbreak;\n\n\t\tfor (t = 1; t <= times; ++t) {\n\t\t\tif (*nent >= maxnent)\n\t\t\t\tgoto out;\n\t\t\tdo_host_cpuid(&entry[t], function, t);\n\t\t\t++*nent;\n\t\t}\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tentry->edx &= kvm_cpuid_8000_0001_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_8000_0001_EDX);\n\t\tentry->ecx &= kvm_cpuid_8000_0001_ecx_x86_features;\n\t\tcpuid_mask(&entry->ecx, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tentry->ebx &= kvm_cpuid_8000_0008_ebx_x86_features;\n\t\tcpuid_mask(&entry->ebx, CPUID_8000_0008_EBX);\n\t\t/*\n\t\t * AMD has separate bits for each SPEC_CTRL bit.\n\t\t * arch/x86/kernel/cpu/bugs.c is kind enough to\n\t\t * record that in cpufeatures so use them.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_IBPB))\n\t\t\tentry->ebx |= F(AMD_IBPB);\n\t\tif (boot_cpu_has(X86_FEATURE_IBRS))\n\t\t\tentry->ebx |= F(AMD_IBRS);\n\t\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\t\tentry->ebx |= F(AMD_STIBP);\n\t\tif (boot_cpu_has(X86_FEATURE_SSBD))\n\t\t\tentry->ebx |= F(AMD_SSBD);\n\t\tif (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))\n\t\t\tentry->ebx |= F(AMD_SSB_NO);\n\t\t/*\n\t\t * The preference is to use SPEC CTRL MSR instead of the\n\t\t * VIRT_SPEC MSR.\n\t\t */\n\t\tif (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&\n\t\t    !boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\t\tentry->ebx |= F(VIRT_SSBD);\n\t\tbreak;\n\t}\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tentry->edx &= kvm_cpuid_C000_0001_edx_x86_features;\n\t\tcpuid_mask(&entry->edx, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tkvm_x86_ops->set_supported_cpuid(function, entry);\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -76,7 +76,7 @@\n \n \tr = -E2BIG;\n \n-\tif (*nent >= maxnent)\n+\tif (WARN_ON(*nent >= maxnent))\n \t\tgoto out;\n \n \tdo_host_cpuid(entry, function, 0);",
        "function_modified_lines": {
            "added": [
                "\tif (WARN_ON(*nent >= maxnent))"
            ],
            "deleted": [
                "\tif (*nent >= maxnent)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write issue was found in the Linux Kernel, version 3.13 through 5.4, in the way the Linux kernel's KVM hypervisor handled the 'KVM_GET_EMULATED_CPUID' ioctl(2) request to get CPUID features emulated by the KVM hypervisor. A user or process able to access the '/dev/kvm' device could use this flaw to crash the system, resulting in a denial of service."
    },
    {
        "cve_id": "CVE-2019-19332",
        "code_before_change": "static int do_cpuid_func(struct kvm_cpuid_entry2 *entry, u32 func,\n\t\t\t int *nent, int maxnent, unsigned int type)\n{\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(entry, func, nent, maxnent);\n\n\treturn __do_cpuid_func(entry, func, nent, maxnent);\n}",
        "code_after_change": "static int do_cpuid_func(struct kvm_cpuid_entry2 *entry, u32 func,\n\t\t\t int *nent, int maxnent, unsigned int type)\n{\n\tif (*nent >= maxnent)\n\t\treturn -E2BIG;\n\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(entry, func, nent, maxnent);\n\n\treturn __do_cpuid_func(entry, func, nent, maxnent);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,9 @@\n static int do_cpuid_func(struct kvm_cpuid_entry2 *entry, u32 func,\n \t\t\t int *nent, int maxnent, unsigned int type)\n {\n+\tif (*nent >= maxnent)\n+\t\treturn -E2BIG;\n+\n \tif (type == KVM_GET_EMULATED_CPUID)\n \t\treturn __do_cpuid_func_emulated(entry, func, nent, maxnent);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (*nent >= maxnent)",
                "\t\treturn -E2BIG;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write issue was found in the Linux Kernel, version 3.13 through 5.4, in the way the Linux kernel's KVM hypervisor handled the 'KVM_GET_EMULATED_CPUID' ioctl(2) request to get CPUID features emulated by the KVM hypervisor. A user or process able to access the '/dev/kvm' device could use this flaw to crash the system, resulting in a denial of service."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "static int emsff_init(struct hid_device *hid)\n{\n\tstruct emsff_device *emsff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_first_entry(&hid->inputs,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output reports found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport = list_first_entry(report_list, struct hid_report, list);\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"no fields in the report\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (report->field[0]->report_count < 7) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\temsff = kzalloc(sizeof(struct emsff_device), GFP_KERNEL);\n\tif (!emsff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, emsff, emsff_play);\n\tif (error) {\n\t\tkfree(emsff);\n\t\treturn error;\n\t}\n\n\temsff->report = report;\n\temsff->report->field[0]->value[0] = 0x01;\n\temsff->report->field[0]->value[1] = 0x00;\n\temsff->report->field[0]->value[2] = 0x00;\n\temsff->report->field[0]->value[3] = 0x00;\n\temsff->report->field[0]->value[4] = 0x00;\n\temsff->report->field[0]->value[5] = 0x00;\n\temsff->report->field[0]->value[6] = 0x00;\n\thid_hw_request(hid, emsff->report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"force feedback for EMS based devices by Ignaz Forster <ignaz.forster@gmx.de>\\n\");\n\n\treturn 0;\n}",
        "code_after_change": "static int emsff_init(struct hid_device *hid)\n{\n\tstruct emsff_device *emsff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput;\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev;\n\tint error;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_first_entry(&hid->inputs, struct hid_input, list);\n\tdev = hidinput->input;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output reports found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport = list_first_entry(report_list, struct hid_report, list);\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"no fields in the report\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (report->field[0]->report_count < 7) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\temsff = kzalloc(sizeof(struct emsff_device), GFP_KERNEL);\n\tif (!emsff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, emsff, emsff_play);\n\tif (error) {\n\t\tkfree(emsff);\n\t\treturn error;\n\t}\n\n\temsff->report = report;\n\temsff->report->field[0]->value[0] = 0x01;\n\temsff->report->field[0]->value[1] = 0x00;\n\temsff->report->field[0]->value[2] = 0x00;\n\temsff->report->field[0]->value[3] = 0x00;\n\temsff->report->field[0]->value[4] = 0x00;\n\temsff->report->field[0]->value[5] = 0x00;\n\temsff->report->field[0]->value[6] = 0x00;\n\thid_hw_request(hid, emsff->report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"force feedback for EMS based devices by Ignaz Forster <ignaz.forster@gmx.de>\\n\");\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,12 +2,18 @@\n {\n \tstruct emsff_device *emsff;\n \tstruct hid_report *report;\n-\tstruct hid_input *hidinput = list_first_entry(&hid->inputs,\n-\t\t\t\t\t\tstruct hid_input, list);\n+\tstruct hid_input *hidinput;\n \tstruct list_head *report_list =\n \t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct input_dev *dev;\n \tint error;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_first_entry(&hid->inputs, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \tif (list_empty(report_list)) {\n \t\thid_err(hid, \"no output reports found\\n\");",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_first_entry(&hid->inputs, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_first_entry(&hid->inputs,",
                "\t\t\t\t\t\tstruct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "static int gaff_init(struct hid_device *hid)\n{\n\tstruct gaff_device *gaff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct list_head *report_ptr = report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output reports found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport_ptr = report_ptr->next;\n\n\treport = list_entry(report_ptr, struct hid_report, list);\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"no fields in the report\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (report->field[0]->report_count < 6) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tgaff = kzalloc(sizeof(struct gaff_device), GFP_KERNEL);\n\tif (!gaff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, gaff, hid_gaff_play);\n\tif (error) {\n\t\tkfree(gaff);\n\t\treturn error;\n\t}\n\n\tgaff->report = report;\n\tgaff->report->field[0]->value[0] = 0x51;\n\tgaff->report->field[0]->value[1] = 0x00;\n\tgaff->report->field[0]->value[2] = 0x00;\n\tgaff->report->field[0]->value[3] = 0x00;\n\thid_hw_request(hid, gaff->report, HID_REQ_SET_REPORT);\n\n\tgaff->report->field[0]->value[0] = 0xfa;\n\tgaff->report->field[0]->value[1] = 0xfe;\n\n\thid_hw_request(hid, gaff->report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force Feedback for GreenAsia 0x12 devices by Lukasz Lubojanski <lukasz@lubojanski.info>\\n\");\n\n\treturn 0;\n}",
        "code_after_change": "static int gaff_init(struct hid_device *hid)\n{\n\tstruct gaff_device *gaff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput;\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct list_head *report_ptr = report_list;\n\tstruct input_dev *dev;\n\tint error;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output reports found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport_ptr = report_ptr->next;\n\n\treport = list_entry(report_ptr, struct hid_report, list);\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"no fields in the report\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (report->field[0]->report_count < 6) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tgaff = kzalloc(sizeof(struct gaff_device), GFP_KERNEL);\n\tif (!gaff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, gaff, hid_gaff_play);\n\tif (error) {\n\t\tkfree(gaff);\n\t\treturn error;\n\t}\n\n\tgaff->report = report;\n\tgaff->report->field[0]->value[0] = 0x51;\n\tgaff->report->field[0]->value[1] = 0x00;\n\tgaff->report->field[0]->value[2] = 0x00;\n\tgaff->report->field[0]->value[3] = 0x00;\n\thid_hw_request(hid, gaff->report, HID_REQ_SET_REPORT);\n\n\tgaff->report->field[0]->value[0] = 0xfa;\n\tgaff->report->field[0]->value[1] = 0xfe;\n\n\thid_hw_request(hid, gaff->report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force Feedback for GreenAsia 0x12 devices by Lukasz Lubojanski <lukasz@lubojanski.info>\\n\");\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,13 +2,19 @@\n {\n \tstruct gaff_device *gaff;\n \tstruct hid_report *report;\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n-\t\t\t\t\t\tstruct hid_input, list);\n+\tstruct hid_input *hidinput;\n \tstruct list_head *report_list =\n \t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n \tstruct list_head *report_ptr = report_list;\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct input_dev *dev;\n \tint error;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \tif (list_empty(report_list)) {\n \t\thid_err(hid, \"no output reports found\\n\");",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next,",
                "\t\t\t\t\t\tstruct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\t/* Check that the report looks ok */\n\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\n\tif (!report)\n\t\treturn -ENODEV;\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech variant 2 rumble devices by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
        "code_after_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput;\n\tstruct input_dev *dev;\n\tint error;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\t/* Check that the report looks ok */\n\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\n\tif (!report)\n\t\treturn -ENODEV;\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech variant 2 rumble devices by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,10 +2,16 @@\n {\n \tstruct lg2ff_device *lg2ff;\n \tstruct hid_report *report;\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n-\t\t\t\t\t\tstruct hid_input, list);\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *dev;\n \tint error;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \t/* Check that the report looks ok */\n \treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next,",
                "\t\t\t\t\t\tstruct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "int lg3ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tconst signed short *ff_bits = ff3_joystick_ac;\n\tint error;\n\tint i;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 35))\n\t\treturn -ENODEV;\n\n\t/* Assume single fixed device G940 */\n\tfor (i = 0; ff_bits[i] >= 0; i++)\n\t\tset_bit(ff_bits[i], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg3ff_play);\n\tif (error)\n\t\treturn error;\n\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit))\n\t\tdev->ff->set_autocenter = hid_lg3ff_set_autocenter;\n\n\thid_info(hid, \"Force feedback for Logitech Flight System G940 by Gary Stein <LordCnidarian@gmail.com>\\n\");\n\treturn 0;\n}",
        "code_after_change": "int lg3ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput;\n\tstruct input_dev *dev;\n\tconst signed short *ff_bits = ff3_joystick_ac;\n\tint error;\n\tint i;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 35))\n\t\treturn -ENODEV;\n\n\t/* Assume single fixed device G940 */\n\tfor (i = 0; ff_bits[i] >= 0; i++)\n\t\tset_bit(ff_bits[i], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg3ff_play);\n\tif (error)\n\t\treturn error;\n\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit))\n\t\tdev->ff->set_autocenter = hid_lg3ff_set_autocenter;\n\n\thid_info(hid, \"Force feedback for Logitech Flight System G940 by Gary Stein <LordCnidarian@gmail.com>\\n\");\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,17 @@\n int lg3ff_init(struct hid_device *hid)\n {\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *dev;\n \tconst signed short *ff_bits = ff3_joystick_ac;\n \tint error;\n \tint i;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \t/* Check that the report looks ok */\n \tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 35))",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct hid_report *report = list_entry(report_list->next, struct hid_report, list);\n\tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n\tconst u16 bcdDevice = le16_to_cpu(udesc->bcdDevice);\n\tconst struct lg4ff_multimode_wheel *mmode_wheel = NULL;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tint error, i, j;\n\tint mmode_ret, mmode_idx = -1;\n\tu16 real_product_id;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -1;\n\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&entry->report_lock);\n\tentry->report = report;\n\tdrv_data->device_props = entry;\n\n\t/* Check if a multimode wheel has been connected and\n\t * handle it appropriately */\n\tmmode_ret = lg4ff_handle_multimode_wheel(hid, &real_product_id, bcdDevice);\n\n\t/* Wheel has been told to switch to native mode. There is no point in going on\n\t * with the initialization as the wheel will do a USB reset when it switches mode\n\t */\n\tif (mmode_ret == LG4FF_MMODE_SWITCHED)\n\t\treturn 0;\n\telse if (mmode_ret < 0) {\n\t\thid_err(hid, \"Unable to switch device mode during initialization, errno %d\\n\", mmode_ret);\n\t\terror = mmode_ret;\n\t\tgoto err_init;\n\t}\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"This device is flagged to be handled by the lg4ff module but this module does not know how to handle it. \"\n\t\t\t     \"Please report this as a bug to LKML, Simon Wood <simon@mungewell.org> or \"\n\t\t\t     \"Michal Maly <madcatxster@devoid-pointer.net>\\n\");\n\t\terror = -1;\n\t\tgoto err_init;\n\t}\n\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\tfor (mmode_idx = 0; mmode_idx < ARRAY_SIZE(lg4ff_multimode_wheels); mmode_idx++) {\n\t\t\tif (real_product_id == lg4ff_multimode_wheels[mmode_idx].product_id)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (mmode_idx == ARRAY_SIZE(lg4ff_multimode_wheels)) {\n\t\t\thid_err(hid, \"Device product ID %X is not listed as a multimode wheel\", real_product_id);\n\t\t\terror = -1;\n\t\t\tgoto err_init;\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, lg4ff_play);\n\n\tif (error)\n\t\tgoto err_init;\n\n\t/* Initialize device properties */\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\tBUG_ON(mmode_idx == -1);\n\t\tmmode_wheel = &lg4ff_multimode_wheels[mmode_idx];\n\t}\n\tlg4ff_init_wheel_data(&entry->wdata, &lg4ff_devices[i], mmode_wheel, real_product_id);\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\t/* Formula Force EX expects different autocentering command */\n\t\tif ((bcdDevice >> 8) == LG4FF_FFEX_REV_MAJ &&\n\t\t    (bcdDevice & 0xff) == LG4FF_FFEX_REV_MIN)\n\t\t\tdev->ff->set_autocenter = lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_combine_pedals);\n\tif (error)\n\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"combine\\\", errno %d\\n\", error);\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"range\\\", errno %d\\n\", error);\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\terror = device_create_file(&hid->dev, &dev_attr_real_id);\n\t\tif (error)\n\t\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"real_id\\\", errno %d\\n\", error);\n\t\terror = device_create_file(&hid->dev, &dev_attr_alternate_modes);\n\t\tif (error)\n\t\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"alternate_modes\\\", errno %d\\n\", error);\n\t}\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->wdata.range = entry->wdata.max_range;\n\tif (entry->wdata.set_range)\n\t\tentry->wdata.set_range(hid, entry->wdata.range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27/G29 only */\n\tentry->wdata.led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->wdata.led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL ||\n\t\t\tlg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G29_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err_leds;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->wdata.led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr_leds:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->wdata.led[j];\n\t\t\t\t\tentry->wdata.led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n\nerr_init:\n\tdrv_data->device_props = NULL;\n\tkfree(entry);\n\treturn error;\n}",
        "code_after_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput;\n\tstruct input_dev *dev;\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct hid_report *report = list_entry(report_list->next, struct hid_report, list);\n\tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n\tconst u16 bcdDevice = le16_to_cpu(udesc->bcdDevice);\n\tconst struct lg4ff_multimode_wheel *mmode_wheel = NULL;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tint error, i, j;\n\tint mmode_ret, mmode_idx = -1;\n\tu16 real_product_id;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -1;\n\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\tentry = kzalloc(sizeof(*entry), GFP_KERNEL);\n\tif (!entry)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&entry->report_lock);\n\tentry->report = report;\n\tdrv_data->device_props = entry;\n\n\t/* Check if a multimode wheel has been connected and\n\t * handle it appropriately */\n\tmmode_ret = lg4ff_handle_multimode_wheel(hid, &real_product_id, bcdDevice);\n\n\t/* Wheel has been told to switch to native mode. There is no point in going on\n\t * with the initialization as the wheel will do a USB reset when it switches mode\n\t */\n\tif (mmode_ret == LG4FF_MMODE_SWITCHED)\n\t\treturn 0;\n\telse if (mmode_ret < 0) {\n\t\thid_err(hid, \"Unable to switch device mode during initialization, errno %d\\n\", mmode_ret);\n\t\terror = mmode_ret;\n\t\tgoto err_init;\n\t}\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"This device is flagged to be handled by the lg4ff module but this module does not know how to handle it. \"\n\t\t\t     \"Please report this as a bug to LKML, Simon Wood <simon@mungewell.org> or \"\n\t\t\t     \"Michal Maly <madcatxster@devoid-pointer.net>\\n\");\n\t\terror = -1;\n\t\tgoto err_init;\n\t}\n\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\tfor (mmode_idx = 0; mmode_idx < ARRAY_SIZE(lg4ff_multimode_wheels); mmode_idx++) {\n\t\t\tif (real_product_id == lg4ff_multimode_wheels[mmode_idx].product_id)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (mmode_idx == ARRAY_SIZE(lg4ff_multimode_wheels)) {\n\t\t\thid_err(hid, \"Device product ID %X is not listed as a multimode wheel\", real_product_id);\n\t\t\terror = -1;\n\t\t\tgoto err_init;\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, lg4ff_play);\n\n\tif (error)\n\t\tgoto err_init;\n\n\t/* Initialize device properties */\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\tBUG_ON(mmode_idx == -1);\n\t\tmmode_wheel = &lg4ff_multimode_wheels[mmode_idx];\n\t}\n\tlg4ff_init_wheel_data(&entry->wdata, &lg4ff_devices[i], mmode_wheel, real_product_id);\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\t/* Formula Force EX expects different autocentering command */\n\t\tif ((bcdDevice >> 8) == LG4FF_FFEX_REV_MAJ &&\n\t\t    (bcdDevice & 0xff) == LG4FF_FFEX_REV_MIN)\n\t\t\tdev->ff->set_autocenter = lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_combine_pedals);\n\tif (error)\n\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"combine\\\", errno %d\\n\", error);\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"range\\\", errno %d\\n\", error);\n\tif (mmode_ret == LG4FF_MMODE_IS_MULTIMODE) {\n\t\terror = device_create_file(&hid->dev, &dev_attr_real_id);\n\t\tif (error)\n\t\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"real_id\\\", errno %d\\n\", error);\n\t\terror = device_create_file(&hid->dev, &dev_attr_alternate_modes);\n\t\tif (error)\n\t\t\thid_warn(hid, \"Unable to create sysfs interface for \\\"alternate_modes\\\", errno %d\\n\", error);\n\t}\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->wdata.range = entry->wdata.max_range;\n\tif (entry->wdata.set_range)\n\t\tentry->wdata.set_range(hid, entry->wdata.range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27/G29 only */\n\tentry->wdata.led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->wdata.led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL ||\n\t\t\tlg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G29_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err_leds;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->wdata.led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr_leds:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->wdata.led[j];\n\t\t\t\t\tentry->wdata.led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n\nerr_init:\n\tdrv_data->device_props = NULL;\n\tkfree(entry);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n int lg4ff_init(struct hid_device *hid)\n {\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *dev;\n \tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n \tstruct hid_report *report = list_entry(report_list->next, struct hid_report, list);\n \tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n@@ -12,6 +12,13 @@\n \tint error, i, j;\n \tint mmode_ret, mmode_idx = -1;\n \tu16 real_product_id;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \t/* Check that the report looks ok */\n \tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "int lgff_init(struct hid_device* hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tconst signed short *ff_bits = ff_joystick;\n\tint error;\n\tint i;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -ENODEV;\n\n\tfor (i = 0; i < ARRAY_SIZE(devices); i++) {\n\t\tif (dev->id.vendor == devices[i].idVendor &&\n\t\t    dev->id.product == devices[i].idProduct) {\n\t\t\tff_bits = devices[i].ff;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (i = 0; ff_bits[i] >= 0; i++)\n\t\tset_bit(ff_bits[i], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lgff_play);\n\tif (error)\n\t\treturn error;\n\n\tif ( test_bit(FF_AUTOCENTER, dev->ffbit) )\n\t\tdev->ff->set_autocenter = hid_lgff_set_autocenter;\n\n\tpr_info(\"Force feedback for Logitech force feedback devices by Johann Deneux <johann.deneux@it.uu.se>\\n\");\n\n\treturn 0;\n}",
        "code_after_change": "int lgff_init(struct hid_device* hid)\n{\n\tstruct hid_input *hidinput;\n\tstruct input_dev *dev;\n\tconst signed short *ff_bits = ff_joystick;\n\tint error;\n\tint i;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -ENODEV;\n\n\tfor (i = 0; i < ARRAY_SIZE(devices); i++) {\n\t\tif (dev->id.vendor == devices[i].idVendor &&\n\t\t    dev->id.product == devices[i].idProduct) {\n\t\t\tff_bits = devices[i].ff;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (i = 0; ff_bits[i] >= 0; i++)\n\t\tset_bit(ff_bits[i], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lgff_play);\n\tif (error)\n\t\treturn error;\n\n\tif ( test_bit(FF_AUTOCENTER, dev->ffbit) )\n\t\tdev->ff->set_autocenter = hid_lgff_set_autocenter;\n\n\tpr_info(\"Force feedback for Logitech force feedback devices by Johann Deneux <johann.deneux@it.uu.se>\\n\");\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,17 @@\n int lgff_init(struct hid_device* hid)\n {\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *dev;\n \tconst signed short *ff_bits = ff_joystick;\n \tint error;\n \tint i;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \t/* Check that the report looks ok */\n \tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "static int hidpp_ff_init(struct hidpp_device *hidpp, u8 feature_index)\n{\n\tstruct hid_device *hid = hidpp->hid_dev;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n\tconst u16 bcdDevice = le16_to_cpu(udesc->bcdDevice);\n\tstruct ff_device *ff;\n\tstruct hidpp_report response;\n\tstruct hidpp_ff_private_data *data;\n\tint error, j, num_slots;\n\tu8 version;\n\n\tif (!dev) {\n\t\thid_err(hid, \"Struct input_dev not set!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Get firmware release */\n\tversion = bcdDevice & 255;\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; hidpp_ff_effects[j] >= 0; j++)\n\t\tset_bit(hidpp_ff_effects[j], dev->ffbit);\n\tif (version > 1)\n\t\tfor (j = 0; hidpp_ff_effects_v2[j] >= 0; j++)\n\t\t\tset_bit(hidpp_ff_effects_v2[j], dev->ffbit);\n\n\t/* Read number of slots available in device */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_INFO, NULL, 0, &response);\n\tif (error) {\n\t\tif (error < 0)\n\t\t\treturn error;\n\t\thid_err(hidpp->hid_dev, \"%s: received protocol error 0x%02x\\n\",\n\t\t\t__func__, error);\n\t\treturn -EPROTO;\n\t}\n\n\tnum_slots = response.fap.params[0] - HIDPP_FF_RESERVED_SLOTS;\n\n\terror = input_ff_create(dev, num_slots);\n\n\tif (error) {\n\t\thid_err(dev, \"Failed to create FF device!\\n\");\n\t\treturn error;\n\t}\n\n\tdata = kzalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\tdata->effect_ids = kcalloc(num_slots, sizeof(int), GFP_KERNEL);\n\tif (!data->effect_ids) {\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\tdata->wq = create_singlethread_workqueue(\"hidpp-ff-sendqueue\");\n\tif (!data->wq) {\n\t\tkfree(data->effect_ids);\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\n\tdata->hidpp = hidpp;\n\tdata->feature_index = feature_index;\n\tdata->version = version;\n\tdata->slot_autocenter = 0;\n\tdata->num_effects = num_slots;\n\tfor (j = 0; j < num_slots; j++)\n\t\tdata->effect_ids[j] = -1;\n\n\tff = dev->ff;\n\tff->private = data;\n\n\tff->upload = hidpp_ff_upload_effect;\n\tff->erase = hidpp_ff_erase_effect;\n\tff->playback = hidpp_ff_playback;\n\tff->set_gain = hidpp_ff_set_gain;\n\tff->set_autocenter = hidpp_ff_set_autocenter;\n\tff->destroy = hidpp_ff_destroy;\n\n\n\t/* reset all forces */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_RESET_ALL, NULL, 0, &response);\n\n\t/* Read current Range */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_APERTURE, NULL, 0, &response);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Failed to read range from device!\\n\");\n\tdata->range = error ? 900 : get_unaligned_be16(&response.fap.params[0]);\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&(hidpp->hid_dev->dev), &dev_attr_range);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Unable to create sysfs interface for \\\"range\\\", errno %d!\\n\", error);\n\n\t/* Read the current gain values */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_GLOBAL_GAINS, NULL, 0, &response);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Failed to read gain values from device!\\n\");\n\tdata->gain = error ? 0xffff : get_unaligned_be16(&response.fap.params[0]);\n\t/* ignore boost value at response.fap.params[2] */\n\n\t/* init the hardware command queue */\n\tatomic_set(&data->workqueue_size, 0);\n\n\t/* initialize with zero autocenter to get wheel in usable state */\n\thidpp_ff_set_autocenter(dev, 0);\n\n\thid_info(hid, \"Force feedback support loaded (firmware release %d).\\n\",\n\t\t version);\n\n\treturn 0;\n}",
        "code_after_change": "static int hidpp_ff_init(struct hidpp_device *hidpp, u8 feature_index)\n{\n\tstruct hid_device *hid = hidpp->hid_dev;\n\tstruct hid_input *hidinput;\n\tstruct input_dev *dev;\n\tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n\tconst u16 bcdDevice = le16_to_cpu(udesc->bcdDevice);\n\tstruct ff_device *ff;\n\tstruct hidpp_report response;\n\tstruct hidpp_ff_private_data *data;\n\tint error, j, num_slots;\n\tu8 version;\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tdev = hidinput->input;\n\n\tif (!dev) {\n\t\thid_err(hid, \"Struct input_dev not set!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Get firmware release */\n\tversion = bcdDevice & 255;\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; hidpp_ff_effects[j] >= 0; j++)\n\t\tset_bit(hidpp_ff_effects[j], dev->ffbit);\n\tif (version > 1)\n\t\tfor (j = 0; hidpp_ff_effects_v2[j] >= 0; j++)\n\t\t\tset_bit(hidpp_ff_effects_v2[j], dev->ffbit);\n\n\t/* Read number of slots available in device */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_INFO, NULL, 0, &response);\n\tif (error) {\n\t\tif (error < 0)\n\t\t\treturn error;\n\t\thid_err(hidpp->hid_dev, \"%s: received protocol error 0x%02x\\n\",\n\t\t\t__func__, error);\n\t\treturn -EPROTO;\n\t}\n\n\tnum_slots = response.fap.params[0] - HIDPP_FF_RESERVED_SLOTS;\n\n\terror = input_ff_create(dev, num_slots);\n\n\tif (error) {\n\t\thid_err(dev, \"Failed to create FF device!\\n\");\n\t\treturn error;\n\t}\n\n\tdata = kzalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\tdata->effect_ids = kcalloc(num_slots, sizeof(int), GFP_KERNEL);\n\tif (!data->effect_ids) {\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\tdata->wq = create_singlethread_workqueue(\"hidpp-ff-sendqueue\");\n\tif (!data->wq) {\n\t\tkfree(data->effect_ids);\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\n\tdata->hidpp = hidpp;\n\tdata->feature_index = feature_index;\n\tdata->version = version;\n\tdata->slot_autocenter = 0;\n\tdata->num_effects = num_slots;\n\tfor (j = 0; j < num_slots; j++)\n\t\tdata->effect_ids[j] = -1;\n\n\tff = dev->ff;\n\tff->private = data;\n\n\tff->upload = hidpp_ff_upload_effect;\n\tff->erase = hidpp_ff_erase_effect;\n\tff->playback = hidpp_ff_playback;\n\tff->set_gain = hidpp_ff_set_gain;\n\tff->set_autocenter = hidpp_ff_set_autocenter;\n\tff->destroy = hidpp_ff_destroy;\n\n\n\t/* reset all forces */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_RESET_ALL, NULL, 0, &response);\n\n\t/* Read current Range */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_APERTURE, NULL, 0, &response);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Failed to read range from device!\\n\");\n\tdata->range = error ? 900 : get_unaligned_be16(&response.fap.params[0]);\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&(hidpp->hid_dev->dev), &dev_attr_range);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Unable to create sysfs interface for \\\"range\\\", errno %d!\\n\", error);\n\n\t/* Read the current gain values */\n\terror = hidpp_send_fap_command_sync(hidpp, feature_index,\n\t\tHIDPP_FF_GET_GLOBAL_GAINS, NULL, 0, &response);\n\tif (error)\n\t\thid_warn(hidpp->hid_dev, \"Failed to read gain values from device!\\n\");\n\tdata->gain = error ? 0xffff : get_unaligned_be16(&response.fap.params[0]);\n\t/* ignore boost value at response.fap.params[2] */\n\n\t/* init the hardware command queue */\n\tatomic_set(&data->workqueue_size, 0);\n\n\t/* initialize with zero autocenter to get wheel in usable state */\n\thidpp_ff_set_autocenter(dev, 0);\n\n\thid_info(hid, \"Force feedback support loaded (firmware release %d).\\n\",\n\t\t version);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,8 @@\n static int hidpp_ff_init(struct hidpp_device *hidpp, u8 feature_index)\n {\n \tstruct hid_device *hid = hidpp->hid_dev;\n-\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n-\tstruct input_dev *dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *dev;\n \tconst struct usb_device_descriptor *udesc = &(hid_to_usb_dev(hid)->descriptor);\n \tconst u16 bcdDevice = le16_to_cpu(udesc->bcdDevice);\n \tstruct ff_device *ff;\n@@ -10,6 +10,13 @@\n \tstruct hidpp_ff_private_data *data;\n \tint error, j, num_slots;\n \tu8 version;\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hid->inputs.next, struct hid_input, list);\n+\tdev = hidinput->input;\n \n \tif (!dev) {\n \t\thid_err(hid, \"Struct input_dev not set!\\n\");",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *dev;",
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tdev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);",
                "\tstruct input_dev *dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19532",
        "code_before_change": "static int ms_init_ff(struct hid_device *hdev)\n{\n\tstruct hid_input *hidinput = list_entry(hdev->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct input_dev *input_dev = hidinput->input;\n\tstruct ms_data *ms = hid_get_drvdata(hdev);\n\n\tif (!(ms->quirks & MS_QUIRK_FF))\n\t\treturn 0;\n\n\tms->hdev = hdev;\n\tINIT_WORK(&ms->ff_worker, ms_ff_worker);\n\n\tms->output_report_dmabuf = devm_kzalloc(&hdev->dev,\n\t\t\t\t\t\tsizeof(struct xb1s_ff_report),\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (ms->output_report_dmabuf == NULL)\n\t\treturn -ENOMEM;\n\n\tinput_set_capability(input_dev, EV_FF, FF_RUMBLE);\n\treturn input_ff_create_memless(input_dev, NULL, ms_play_effect);\n}",
        "code_after_change": "static int ms_init_ff(struct hid_device *hdev)\n{\n\tstruct hid_input *hidinput;\n\tstruct input_dev *input_dev;\n\tstruct ms_data *ms = hid_get_drvdata(hdev);\n\n\tif (list_empty(&hdev->inputs)) {\n\t\thid_err(hdev, \"no inputs found\\n\");\n\t\treturn -ENODEV;\n\t}\n\thidinput = list_entry(hdev->inputs.next, struct hid_input, list);\n\tinput_dev = hidinput->input;\n\n\tif (!(ms->quirks & MS_QUIRK_FF))\n\t\treturn 0;\n\n\tms->hdev = hdev;\n\tINIT_WORK(&ms->ff_worker, ms_ff_worker);\n\n\tms->output_report_dmabuf = devm_kzalloc(&hdev->dev,\n\t\t\t\t\t\tsizeof(struct xb1s_ff_report),\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (ms->output_report_dmabuf == NULL)\n\t\treturn -ENOMEM;\n\n\tinput_set_capability(input_dev, EV_FF, FF_RUMBLE);\n\treturn input_ff_create_memless(input_dev, NULL, ms_play_effect);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,15 @@\n static int ms_init_ff(struct hid_device *hdev)\n {\n-\tstruct hid_input *hidinput = list_entry(hdev->inputs.next,\n-\t\t\t\t\t\tstruct hid_input, list);\n-\tstruct input_dev *input_dev = hidinput->input;\n+\tstruct hid_input *hidinput;\n+\tstruct input_dev *input_dev;\n \tstruct ms_data *ms = hid_get_drvdata(hdev);\n+\n+\tif (list_empty(&hdev->inputs)) {\n+\t\thid_err(hdev, \"no inputs found\\n\");\n+\t\treturn -ENODEV;\n+\t}\n+\thidinput = list_entry(hdev->inputs.next, struct hid_input, list);\n+\tinput_dev = hidinput->input;\n \n \tif (!(ms->quirks & MS_QUIRK_FF))\n \t\treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tstruct hid_input *hidinput;",
                "\tstruct input_dev *input_dev;",
                "",
                "\tif (list_empty(&hdev->inputs)) {",
                "\t\thid_err(hdev, \"no inputs found\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\thidinput = list_entry(hdev->inputs.next, struct hid_input, list);",
                "\tinput_dev = hidinput->input;"
            ],
            "deleted": [
                "\tstruct hid_input *hidinput = list_entry(hdev->inputs.next,",
                "\t\t\t\t\t\tstruct hid_input, list);",
                "\tstruct input_dev *input_dev = hidinput->input;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.3.9, there are multiple out-of-bounds write bugs that can be caused by a malicious USB device in the Linux kernel HID drivers, aka CID-d9d4b1e46d95. This affects drivers/hid/hid-axff.c, drivers/hid/hid-dr.c, drivers/hid/hid-emsff.c, drivers/hid/hid-gaff.c, drivers/hid/hid-holtekff.c, drivers/hid/hid-lg2ff.c, drivers/hid/hid-lg3ff.c, drivers/hid/hid-lg4ff.c, drivers/hid/hid-lgff.c, drivers/hid/hid-logitech-hidpp.c, drivers/hid/hid-microsoft.c, drivers/hid/hid-sony.c, drivers/hid/hid-tmff.c, and drivers/hid/hid-zpff.c."
    },
    {
        "cve_id": "CVE-2019-19816",
        "code_before_change": "struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct inode *inode;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_root *sub_root = root;\n\tstruct btrfs_key location;\n\tint index;\n\tint ret = 0;\n\n\tif (dentry->d_name.len > BTRFS_NAME_LEN)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tret = btrfs_inode_by_name(dir, dentry, &location);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tif (location.type == BTRFS_INODE_ITEM_KEY) {\n\t\tinode = btrfs_iget(dir->i_sb, &location, root, NULL);\n\t\treturn inode;\n\t}\n\n\tindex = srcu_read_lock(&fs_info->subvol_srcu);\n\tret = fixup_tree_root_location(fs_info, dir, dentry,\n\t\t\t\t       &location, &sub_root);\n\tif (ret < 0) {\n\t\tif (ret != -ENOENT)\n\t\t\tinode = ERR_PTR(ret);\n\t\telse\n\t\t\tinode = new_simple_dir(dir->i_sb, &location, sub_root);\n\t} else {\n\t\tinode = btrfs_iget(dir->i_sb, &location, sub_root, NULL);\n\t}\n\tsrcu_read_unlock(&fs_info->subvol_srcu, index);\n\n\tif (!IS_ERR(inode) && root != sub_root) {\n\t\tdown_read(&fs_info->cleanup_work_sem);\n\t\tif (!sb_rdonly(inode->i_sb))\n\t\t\tret = btrfs_orphan_cleanup(sub_root);\n\t\tup_read(&fs_info->cleanup_work_sem);\n\t\tif (ret) {\n\t\t\tiput(inode);\n\t\t\tinode = ERR_PTR(ret);\n\t\t}\n\t}\n\n\treturn inode;\n}",
        "code_after_change": "struct inode *btrfs_lookup_dentry(struct inode *dir, struct dentry *dentry)\n{\n\tstruct btrfs_fs_info *fs_info = btrfs_sb(dir->i_sb);\n\tstruct inode *inode;\n\tstruct btrfs_root *root = BTRFS_I(dir)->root;\n\tstruct btrfs_root *sub_root = root;\n\tstruct btrfs_key location;\n\tu8 di_type = 0;\n\tint index;\n\tint ret = 0;\n\n\tif (dentry->d_name.len > BTRFS_NAME_LEN)\n\t\treturn ERR_PTR(-ENAMETOOLONG);\n\n\tret = btrfs_inode_by_name(dir, dentry, &location, &di_type);\n\tif (ret < 0)\n\t\treturn ERR_PTR(ret);\n\n\tif (location.type == BTRFS_INODE_ITEM_KEY) {\n\t\tinode = btrfs_iget(dir->i_sb, &location, root, NULL);\n\t\tif (IS_ERR(inode))\n\t\t\treturn inode;\n\n\t\t/* Do extra check against inode mode with di_type */\n\t\tif (btrfs_inode_type(inode) != di_type) {\n\t\t\tbtrfs_crit(fs_info,\n\"inode mode mismatch with dir: inode mode=0%o btrfs type=%u dir type=%u\",\n\t\t\t\t  inode->i_mode, btrfs_inode_type(inode),\n\t\t\t\t  di_type);\n\t\t\tiput(inode);\n\t\t\treturn ERR_PTR(-EUCLEAN);\n\t\t}\n\t\treturn inode;\n\t}\n\n\tindex = srcu_read_lock(&fs_info->subvol_srcu);\n\tret = fixup_tree_root_location(fs_info, dir, dentry,\n\t\t\t\t       &location, &sub_root);\n\tif (ret < 0) {\n\t\tif (ret != -ENOENT)\n\t\t\tinode = ERR_PTR(ret);\n\t\telse\n\t\t\tinode = new_simple_dir(dir->i_sb, &location, sub_root);\n\t} else {\n\t\tinode = btrfs_iget(dir->i_sb, &location, sub_root, NULL);\n\t}\n\tsrcu_read_unlock(&fs_info->subvol_srcu, index);\n\n\tif (!IS_ERR(inode) && root != sub_root) {\n\t\tdown_read(&fs_info->cleanup_work_sem);\n\t\tif (!sb_rdonly(inode->i_sb))\n\t\t\tret = btrfs_orphan_cleanup(sub_root);\n\t\tup_read(&fs_info->cleanup_work_sem);\n\t\tif (ret) {\n\t\t\tiput(inode);\n\t\t\tinode = ERR_PTR(ret);\n\t\t}\n\t}\n\n\treturn inode;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,18 +5,31 @@\n \tstruct btrfs_root *root = BTRFS_I(dir)->root;\n \tstruct btrfs_root *sub_root = root;\n \tstruct btrfs_key location;\n+\tu8 di_type = 0;\n \tint index;\n \tint ret = 0;\n \n \tif (dentry->d_name.len > BTRFS_NAME_LEN)\n \t\treturn ERR_PTR(-ENAMETOOLONG);\n \n-\tret = btrfs_inode_by_name(dir, dentry, &location);\n+\tret = btrfs_inode_by_name(dir, dentry, &location, &di_type);\n \tif (ret < 0)\n \t\treturn ERR_PTR(ret);\n \n \tif (location.type == BTRFS_INODE_ITEM_KEY) {\n \t\tinode = btrfs_iget(dir->i_sb, &location, root, NULL);\n+\t\tif (IS_ERR(inode))\n+\t\t\treturn inode;\n+\n+\t\t/* Do extra check against inode mode with di_type */\n+\t\tif (btrfs_inode_type(inode) != di_type) {\n+\t\t\tbtrfs_crit(fs_info,\n+\"inode mode mismatch with dir: inode mode=0%o btrfs type=%u dir type=%u\",\n+\t\t\t\t  inode->i_mode, btrfs_inode_type(inode),\n+\t\t\t\t  di_type);\n+\t\t\tiput(inode);\n+\t\t\treturn ERR_PTR(-EUCLEAN);\n+\t\t}\n \t\treturn inode;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tu8 di_type = 0;",
                "\tret = btrfs_inode_by_name(dir, dentry, &location, &di_type);",
                "\t\tif (IS_ERR(inode))",
                "\t\t\treturn inode;",
                "",
                "\t\t/* Do extra check against inode mode with di_type */",
                "\t\tif (btrfs_inode_type(inode) != di_type) {",
                "\t\t\tbtrfs_crit(fs_info,",
                "\"inode mode mismatch with dir: inode mode=0%o btrfs type=%u dir type=%u\",",
                "\t\t\t\t  inode->i_mode, btrfs_inode_type(inode),",
                "\t\t\t\t  di_type);",
                "\t\t\tiput(inode);",
                "\t\t\treturn ERR_PTR(-EUCLEAN);",
                "\t\t}"
            ],
            "deleted": [
                "\tret = btrfs_inode_by_name(dir, dentry, &location);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted btrfs filesystem image and performing some operations can cause slab-out-of-bounds write access in __btrfs_map_block in fs/btrfs/volumes.c, because a value of 1 for the number of data stripes is mishandled."
    },
    {
        "cve_id": "CVE-2019-19816",
        "code_before_change": "struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,\n\t\t\t\t    struct page *page,\n\t\t\t\t    size_t pg_offset, u64 start, u64 len,\n\t\t\t\t    int create)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tint ret;\n\tint err = 0;\n\tu64 extent_start = 0;\n\tu64 extent_end = 0;\n\tu64 objectid = btrfs_ino(inode);\n\tu8 extent_type;\n\tstruct btrfs_path *path = NULL;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_file_extent_item *item;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key found_key;\n\tstruct extent_map *em = NULL;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tconst bool new_inline = !page || create;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, start, len);\n\tif (em)\n\t\tem->bdev = fs_info->fs_devices->latest_bdev;\n\tread_unlock(&em_tree->lock);\n\n\tif (em) {\n\t\tif (em->start > start || em->start + em->len <= start)\n\t\t\tfree_extent_map(em);\n\t\telse if (em->block_start == EXTENT_MAP_INLINE && page)\n\t\t\tfree_extent_map(em);\n\t\telse\n\t\t\tgoto out;\n\t}\n\tem = alloc_extent_map();\n\tif (!em) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tem->bdev = fs_info->fs_devices->latest_bdev;\n\tem->start = EXTENT_MAP_HOLE;\n\tem->orig_start = EXTENT_MAP_HOLE;\n\tem->len = (u64)-1;\n\tem->block_len = (u64)-1;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t/* Chances are we'll be called again, so go ahead and do readahead */\n\tpath->reada = READA_FORWARD;\n\n\t/*\n\t * Unless we're going to uncompress the inline extent, no sleep would\n\t * happen.\n\t */\n\tpath->leave_spinning = 1;\n\n\tret = btrfs_lookup_file_extent(NULL, root, path, objectid, start, 0);\n\tif (ret < 0) {\n\t\terr = ret;\n\t\tgoto out;\n\t} else if (ret > 0) {\n\t\tif (path->slots[0] == 0)\n\t\t\tgoto not_found;\n\t\tpath->slots[0]--;\n\t}\n\n\tleaf = path->nodes[0];\n\titem = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t      struct btrfs_file_extent_item);\n\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\tif (found_key.objectid != objectid ||\n\t    found_key.type != BTRFS_EXTENT_DATA_KEY) {\n\t\t/*\n\t\t * If we backup past the first extent we want to move forward\n\t\t * and see if there is an extent in front of us, otherwise we'll\n\t\t * say there is a hole for our whole search range which can\n\t\t * cause problems.\n\t\t */\n\t\textent_end = start;\n\t\tgoto next;\n\t}\n\n\textent_type = btrfs_file_extent_type(leaf, item);\n\textent_start = found_key.offset;\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\textent_end = extent_start +\n\t\t       btrfs_file_extent_num_bytes(leaf, item);\n\n\t\ttrace_btrfs_get_extent_show_fi_regular(inode, leaf, item,\n\t\t\t\t\t\t       extent_start);\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\tsize_t size;\n\n\t\tsize = btrfs_file_extent_ram_bytes(leaf, item);\n\t\textent_end = ALIGN(extent_start + size,\n\t\t\t\t   fs_info->sectorsize);\n\n\t\ttrace_btrfs_get_extent_show_fi_inline(inode, leaf, item,\n\t\t\t\t\t\t      path->slots[0],\n\t\t\t\t\t\t      extent_start);\n\t}\nnext:\n\tif (start >= extent_end) {\n\t\tpath->slots[0]++;\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret < 0) {\n\t\t\t\terr = ret;\n\t\t\t\tgoto out;\n\t\t\t} else if (ret > 0) {\n\t\t\t\tgoto not_found;\n\t\t\t}\n\t\t\tleaf = path->nodes[0];\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\t\tif (found_key.objectid != objectid ||\n\t\t    found_key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tgoto not_found;\n\t\tif (start + len <= found_key.offset)\n\t\t\tgoto not_found;\n\t\tif (start > found_key.offset)\n\t\t\tgoto next;\n\n\t\t/* New extent overlaps with existing one */\n\t\tem->start = start;\n\t\tem->orig_start = start;\n\t\tem->len = found_key.offset - start;\n\t\tem->block_start = EXTENT_MAP_HOLE;\n\t\tgoto insert;\n\t}\n\n\tbtrfs_extent_item_to_extent_map(inode, path, item,\n\t\t\tnew_inline, em);\n\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\tgoto insert;\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\tunsigned long ptr;\n\t\tchar *map;\n\t\tsize_t size;\n\t\tsize_t extent_offset;\n\t\tsize_t copy_size;\n\n\t\tif (new_inline)\n\t\t\tgoto out;\n\n\t\tsize = btrfs_file_extent_ram_bytes(leaf, item);\n\t\textent_offset = page_offset(page) + pg_offset - extent_start;\n\t\tcopy_size = min_t(u64, PAGE_SIZE - pg_offset,\n\t\t\t\t  size - extent_offset);\n\t\tem->start = extent_start + extent_offset;\n\t\tem->len = ALIGN(copy_size, fs_info->sectorsize);\n\t\tem->orig_block_len = em->len;\n\t\tem->orig_start = em->start;\n\t\tptr = btrfs_file_extent_inline_start(item) + extent_offset;\n\n\t\tbtrfs_set_path_blocking(path);\n\t\tif (!PageUptodate(page)) {\n\t\t\tif (btrfs_file_extent_compression(leaf, item) !=\n\t\t\t    BTRFS_COMPRESS_NONE) {\n\t\t\t\tret = uncompress_inline(path, page, pg_offset,\n\t\t\t\t\t\t\textent_offset, item);\n\t\t\t\tif (ret) {\n\t\t\t\t\terr = ret;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmap = kmap(page);\n\t\t\t\tread_extent_buffer(leaf, map + pg_offset, ptr,\n\t\t\t\t\t\t   copy_size);\n\t\t\t\tif (pg_offset + copy_size < PAGE_SIZE) {\n\t\t\t\t\tmemset(map + pg_offset + copy_size, 0,\n\t\t\t\t\t       PAGE_SIZE - pg_offset -\n\t\t\t\t\t       copy_size);\n\t\t\t\t}\n\t\t\t\tkunmap(page);\n\t\t\t}\n\t\t\tflush_dcache_page(page);\n\t\t}\n\t\tset_extent_uptodate(io_tree, em->start,\n\t\t\t\t    extent_map_end(em) - 1, NULL, GFP_NOFS);\n\t\tgoto insert;\n\t}\nnot_found:\n\tem->start = start;\n\tem->orig_start = start;\n\tem->len = len;\n\tem->block_start = EXTENT_MAP_HOLE;\ninsert:\n\tbtrfs_release_path(path);\n\tif (em->start > start || extent_map_end(em) <= start) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"bad extent! em: [%llu %llu] passed [%llu %llu]\",\n\t\t\t  em->start, em->len, start, len);\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\terr = 0;\n\twrite_lock(&em_tree->lock);\n\terr = btrfs_add_extent_mapping(fs_info, em_tree, &em, start, len);\n\twrite_unlock(&em_tree->lock);\nout:\n\tbtrfs_free_path(path);\n\n\ttrace_btrfs_get_extent(root, inode, em);\n\n\tif (err) {\n\t\tfree_extent_map(em);\n\t\treturn ERR_PTR(err);\n\t}\n\tBUG_ON(!em); /* Error is always set */\n\treturn em;\n}",
        "code_after_change": "struct extent_map *btrfs_get_extent(struct btrfs_inode *inode,\n\t\t\t\t    struct page *page,\n\t\t\t\t    size_t pg_offset, u64 start, u64 len,\n\t\t\t\t    int create)\n{\n\tstruct btrfs_fs_info *fs_info = inode->root->fs_info;\n\tint ret;\n\tint err = 0;\n\tu64 extent_start = 0;\n\tu64 extent_end = 0;\n\tu64 objectid = btrfs_ino(inode);\n\tu8 extent_type;\n\tstruct btrfs_path *path = NULL;\n\tstruct btrfs_root *root = inode->root;\n\tstruct btrfs_file_extent_item *item;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_key found_key;\n\tstruct extent_map *em = NULL;\n\tstruct extent_map_tree *em_tree = &inode->extent_tree;\n\tstruct extent_io_tree *io_tree = &inode->io_tree;\n\tconst bool new_inline = !page || create;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, start, len);\n\tif (em)\n\t\tem->bdev = fs_info->fs_devices->latest_bdev;\n\tread_unlock(&em_tree->lock);\n\n\tif (em) {\n\t\tif (em->start > start || em->start + em->len <= start)\n\t\t\tfree_extent_map(em);\n\t\telse if (em->block_start == EXTENT_MAP_INLINE && page)\n\t\t\tfree_extent_map(em);\n\t\telse\n\t\t\tgoto out;\n\t}\n\tem = alloc_extent_map();\n\tif (!em) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tem->bdev = fs_info->fs_devices->latest_bdev;\n\tem->start = EXTENT_MAP_HOLE;\n\tem->orig_start = EXTENT_MAP_HOLE;\n\tem->len = (u64)-1;\n\tem->block_len = (u64)-1;\n\n\tpath = btrfs_alloc_path();\n\tif (!path) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t/* Chances are we'll be called again, so go ahead and do readahead */\n\tpath->reada = READA_FORWARD;\n\n\t/*\n\t * Unless we're going to uncompress the inline extent, no sleep would\n\t * happen.\n\t */\n\tpath->leave_spinning = 1;\n\n\tret = btrfs_lookup_file_extent(NULL, root, path, objectid, start, 0);\n\tif (ret < 0) {\n\t\terr = ret;\n\t\tgoto out;\n\t} else if (ret > 0) {\n\t\tif (path->slots[0] == 0)\n\t\t\tgoto not_found;\n\t\tpath->slots[0]--;\n\t}\n\n\tleaf = path->nodes[0];\n\titem = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t      struct btrfs_file_extent_item);\n\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\tif (found_key.objectid != objectid ||\n\t    found_key.type != BTRFS_EXTENT_DATA_KEY) {\n\t\t/*\n\t\t * If we backup past the first extent we want to move forward\n\t\t * and see if there is an extent in front of us, otherwise we'll\n\t\t * say there is a hole for our whole search range which can\n\t\t * cause problems.\n\t\t */\n\t\textent_end = start;\n\t\tgoto next;\n\t}\n\n\textent_type = btrfs_file_extent_type(leaf, item);\n\textent_start = found_key.offset;\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\t/* Only regular file could have regular/prealloc extent */\n\t\tif (!S_ISREG(inode->vfs_inode.i_mode)) {\n\t\t\tret = -EUCLEAN;\n\t\t\tbtrfs_crit(fs_info,\n\t\t\"regular/prealloc extent found for non-regular inode %llu\",\n\t\t\t\t   btrfs_ino(inode));\n\t\t\tgoto out;\n\t\t}\n\t\textent_end = extent_start +\n\t\t       btrfs_file_extent_num_bytes(leaf, item);\n\n\t\ttrace_btrfs_get_extent_show_fi_regular(inode, leaf, item,\n\t\t\t\t\t\t       extent_start);\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\tsize_t size;\n\n\t\tsize = btrfs_file_extent_ram_bytes(leaf, item);\n\t\textent_end = ALIGN(extent_start + size,\n\t\t\t\t   fs_info->sectorsize);\n\n\t\ttrace_btrfs_get_extent_show_fi_inline(inode, leaf, item,\n\t\t\t\t\t\t      path->slots[0],\n\t\t\t\t\t\t      extent_start);\n\t}\nnext:\n\tif (start >= extent_end) {\n\t\tpath->slots[0]++;\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret < 0) {\n\t\t\t\terr = ret;\n\t\t\t\tgoto out;\n\t\t\t} else if (ret > 0) {\n\t\t\t\tgoto not_found;\n\t\t\t}\n\t\t\tleaf = path->nodes[0];\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, path->slots[0]);\n\t\tif (found_key.objectid != objectid ||\n\t\t    found_key.type != BTRFS_EXTENT_DATA_KEY)\n\t\t\tgoto not_found;\n\t\tif (start + len <= found_key.offset)\n\t\t\tgoto not_found;\n\t\tif (start > found_key.offset)\n\t\t\tgoto next;\n\n\t\t/* New extent overlaps with existing one */\n\t\tem->start = start;\n\t\tem->orig_start = start;\n\t\tem->len = found_key.offset - start;\n\t\tem->block_start = EXTENT_MAP_HOLE;\n\t\tgoto insert;\n\t}\n\n\tbtrfs_extent_item_to_extent_map(inode, path, item,\n\t\t\tnew_inline, em);\n\n\tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n\t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n\t\tgoto insert;\n\t} else if (extent_type == BTRFS_FILE_EXTENT_INLINE) {\n\t\tunsigned long ptr;\n\t\tchar *map;\n\t\tsize_t size;\n\t\tsize_t extent_offset;\n\t\tsize_t copy_size;\n\n\t\tif (new_inline)\n\t\t\tgoto out;\n\n\t\tsize = btrfs_file_extent_ram_bytes(leaf, item);\n\t\textent_offset = page_offset(page) + pg_offset - extent_start;\n\t\tcopy_size = min_t(u64, PAGE_SIZE - pg_offset,\n\t\t\t\t  size - extent_offset);\n\t\tem->start = extent_start + extent_offset;\n\t\tem->len = ALIGN(copy_size, fs_info->sectorsize);\n\t\tem->orig_block_len = em->len;\n\t\tem->orig_start = em->start;\n\t\tptr = btrfs_file_extent_inline_start(item) + extent_offset;\n\n\t\tbtrfs_set_path_blocking(path);\n\t\tif (!PageUptodate(page)) {\n\t\t\tif (btrfs_file_extent_compression(leaf, item) !=\n\t\t\t    BTRFS_COMPRESS_NONE) {\n\t\t\t\tret = uncompress_inline(path, page, pg_offset,\n\t\t\t\t\t\t\textent_offset, item);\n\t\t\t\tif (ret) {\n\t\t\t\t\terr = ret;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmap = kmap(page);\n\t\t\t\tread_extent_buffer(leaf, map + pg_offset, ptr,\n\t\t\t\t\t\t   copy_size);\n\t\t\t\tif (pg_offset + copy_size < PAGE_SIZE) {\n\t\t\t\t\tmemset(map + pg_offset + copy_size, 0,\n\t\t\t\t\t       PAGE_SIZE - pg_offset -\n\t\t\t\t\t       copy_size);\n\t\t\t\t}\n\t\t\t\tkunmap(page);\n\t\t\t}\n\t\t\tflush_dcache_page(page);\n\t\t}\n\t\tset_extent_uptodate(io_tree, em->start,\n\t\t\t\t    extent_map_end(em) - 1, NULL, GFP_NOFS);\n\t\tgoto insert;\n\t}\nnot_found:\n\tem->start = start;\n\tem->orig_start = start;\n\tem->len = len;\n\tem->block_start = EXTENT_MAP_HOLE;\ninsert:\n\tbtrfs_release_path(path);\n\tif (em->start > start || extent_map_end(em) <= start) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"bad extent! em: [%llu %llu] passed [%llu %llu]\",\n\t\t\t  em->start, em->len, start, len);\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\terr = 0;\n\twrite_lock(&em_tree->lock);\n\terr = btrfs_add_extent_mapping(fs_info, em_tree, &em, start, len);\n\twrite_unlock(&em_tree->lock);\nout:\n\tbtrfs_free_path(path);\n\n\ttrace_btrfs_get_extent(root, inode, em);\n\n\tif (err) {\n\t\tfree_extent_map(em);\n\t\treturn ERR_PTR(err);\n\t}\n\tBUG_ON(!em); /* Error is always set */\n\treturn em;\n}",
        "patch": "--- code before\n+++ code after\n@@ -90,6 +90,14 @@\n \textent_start = found_key.offset;\n \tif (extent_type == BTRFS_FILE_EXTENT_REG ||\n \t    extent_type == BTRFS_FILE_EXTENT_PREALLOC) {\n+\t\t/* Only regular file could have regular/prealloc extent */\n+\t\tif (!S_ISREG(inode->vfs_inode.i_mode)) {\n+\t\t\tret = -EUCLEAN;\n+\t\t\tbtrfs_crit(fs_info,\n+\t\t\"regular/prealloc extent found for non-regular inode %llu\",\n+\t\t\t\t   btrfs_ino(inode));\n+\t\t\tgoto out;\n+\t\t}\n \t\textent_end = extent_start +\n \t\t       btrfs_file_extent_num_bytes(leaf, item);\n ",
        "function_modified_lines": {
            "added": [
                "\t\t/* Only regular file could have regular/prealloc extent */",
                "\t\tif (!S_ISREG(inode->vfs_inode.i_mode)) {",
                "\t\t\tret = -EUCLEAN;",
                "\t\t\tbtrfs_crit(fs_info,",
                "\t\t\"regular/prealloc extent found for non-regular inode %llu\",",
                "\t\t\t\t   btrfs_ino(inode));",
                "\t\t\tgoto out;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted btrfs filesystem image and performing some operations can cause slab-out-of-bounds write access in __btrfs_map_block in fs/btrfs/volumes.c, because a value of 1 for the number of data stripes is mishandled."
    },
    {
        "cve_id": "CVE-2019-19816",
        "code_before_change": "static noinline int test_btrfs_get_extent(u32 sectorsize, u32 nodesize)\n{\n\tstruct btrfs_fs_info *fs_info = NULL;\n\tstruct inode *inode = NULL;\n\tstruct btrfs_root *root = NULL;\n\tstruct extent_map *em = NULL;\n\tu64 orig_start;\n\tu64 disk_bytenr;\n\tu64 offset;\n\tint ret = -ENOMEM;\n\n\ttest_msg(\"running btrfs_get_extent tests\");\n\n\tinode = btrfs_new_test_inode();\n\tif (!inode) {\n\t\ttest_std_err(TEST_ALLOC_INODE);\n\t\treturn ret;\n\t}\n\n\tBTRFS_I(inode)->location.type = BTRFS_INODE_ITEM_KEY;\n\tBTRFS_I(inode)->location.objectid = BTRFS_FIRST_FREE_OBJECTID;\n\tBTRFS_I(inode)->location.offset = 0;\n\n\tfs_info = btrfs_alloc_dummy_fs_info(nodesize, sectorsize);\n\tif (!fs_info) {\n\t\ttest_std_err(TEST_ALLOC_FS_INFO);\n\t\tgoto out;\n\t}\n\n\troot = btrfs_alloc_dummy_root(fs_info);\n\tif (IS_ERR(root)) {\n\t\ttest_std_err(TEST_ALLOC_ROOT);\n\t\tgoto out;\n\t}\n\n\troot->node = alloc_dummy_extent_buffer(fs_info, nodesize);\n\tif (!root->node) {\n\t\ttest_std_err(TEST_ALLOC_ROOT);\n\t\tgoto out;\n\t}\n\n\tbtrfs_set_header_nritems(root->node, 0);\n\tbtrfs_set_header_level(root->node, 0);\n\tret = -EINVAL;\n\n\t/* First with no extents */\n\tBTRFS_I(inode)->root = root;\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, 0, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\tem = NULL;\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tfree_extent_map(em);\n\tbtrfs_drop_extent_cache(BTRFS_I(inode), 0, (u64)-1, 0);\n\n\t/*\n\t * All of the magic numbers are based on the mapping setup in\n\t * setup_file_extents, so if you change anything there you need to\n\t * update the comment and update the expected values below.\n\t */\n\tsetup_file_extents(root, sectorsize);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, 0, (u64)-1, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != 0 || em->len != 5) {\n\t\ttest_err(\n\t\t\"unexpected extent wanted start 0 len 5, got start %llu len %llu\",\n\t\t\tem->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_INLINE) {\n\t\ttest_err(\"expected an inline, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\n\tif (em->start != offset || em->len != (sectorsize - 5)) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 1, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\t/*\n\t * We don't test anything else for inline since it doesn't get set\n\t * unless we have a page for it to write into.  Maybe we should change\n\t * this?\n\t */\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 4) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 4, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Regular extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize - 1) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 4095, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* The next 3 are split extents */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\t\"unexpected extent start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t orig_start, em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr += (em->start - orig_start);\n\tif (em->block_start != disk_bytenr) {\n\t\ttest_err(\"wrong block start, want %llu, have %llu\",\n\t\t\t disk_bytenr, em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Prealloc extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* The next 3 are a half written prealloc extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"unexpected orig offset, wanted %llu, have %llu\",\n\t\t\t orig_start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->block_start != (disk_bytenr + (em->start - em->orig_start))) {\n\t\ttest_err(\"unexpected block start, wanted %llu, have %llu\",\n\t\t\t disk_bytenr + (em->start - em->orig_start),\n\t\t\t em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", orig_start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->block_start != (disk_bytenr + (em->start - em->orig_start))) {\n\t\ttest_err(\"unexpected block start, wanted %llu, have %llu\",\n\t\t\t disk_bytenr + (em->start - em->orig_start),\n\t\t\t em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Now for the compressed extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Split compressed extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != disk_bytenr) {\n\t\ttest_err(\"block start does not match, want %llu got %llu\",\n\t\t\t disk_bytenr, em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* A hole between regular extents but no hole extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset + 6,\n\t\t\tsectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, SZ_4M, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\t/*\n\t * Currently we just return a length that we requested rather than the\n\t * length of the actual hole, if this changes we'll have to change this\n\t * test.\n\t */\n\tif (em->start != offset || em->len != 3 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 3 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != vacancy_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t vacancy_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tif (!IS_ERR(em))\n\t\tfree_extent_map(em);\n\tiput(inode);\n\tbtrfs_free_dummy_root(root);\n\tbtrfs_free_dummy_fs_info(fs_info);\n\treturn ret;\n}",
        "code_after_change": "static noinline int test_btrfs_get_extent(u32 sectorsize, u32 nodesize)\n{\n\tstruct btrfs_fs_info *fs_info = NULL;\n\tstruct inode *inode = NULL;\n\tstruct btrfs_root *root = NULL;\n\tstruct extent_map *em = NULL;\n\tu64 orig_start;\n\tu64 disk_bytenr;\n\tu64 offset;\n\tint ret = -ENOMEM;\n\n\ttest_msg(\"running btrfs_get_extent tests\");\n\n\tinode = btrfs_new_test_inode();\n\tif (!inode) {\n\t\ttest_std_err(TEST_ALLOC_INODE);\n\t\treturn ret;\n\t}\n\n\tinode->i_mode = S_IFREG;\n\tBTRFS_I(inode)->location.type = BTRFS_INODE_ITEM_KEY;\n\tBTRFS_I(inode)->location.objectid = BTRFS_FIRST_FREE_OBJECTID;\n\tBTRFS_I(inode)->location.offset = 0;\n\n\tfs_info = btrfs_alloc_dummy_fs_info(nodesize, sectorsize);\n\tif (!fs_info) {\n\t\ttest_std_err(TEST_ALLOC_FS_INFO);\n\t\tgoto out;\n\t}\n\n\troot = btrfs_alloc_dummy_root(fs_info);\n\tif (IS_ERR(root)) {\n\t\ttest_std_err(TEST_ALLOC_ROOT);\n\t\tgoto out;\n\t}\n\n\troot->node = alloc_dummy_extent_buffer(fs_info, nodesize);\n\tif (!root->node) {\n\t\ttest_std_err(TEST_ALLOC_ROOT);\n\t\tgoto out;\n\t}\n\n\tbtrfs_set_header_nritems(root->node, 0);\n\tbtrfs_set_header_level(root->node, 0);\n\tret = -EINVAL;\n\n\t/* First with no extents */\n\tBTRFS_I(inode)->root = root;\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, 0, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\tem = NULL;\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tfree_extent_map(em);\n\tbtrfs_drop_extent_cache(BTRFS_I(inode), 0, (u64)-1, 0);\n\n\t/*\n\t * All of the magic numbers are based on the mapping setup in\n\t * setup_file_extents, so if you change anything there you need to\n\t * update the comment and update the expected values below.\n\t */\n\tsetup_file_extents(root, sectorsize);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, 0, (u64)-1, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != 0 || em->len != 5) {\n\t\ttest_err(\n\t\t\"unexpected extent wanted start 0 len 5, got start %llu len %llu\",\n\t\t\tem->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_INLINE) {\n\t\ttest_err(\"expected an inline, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\n\tif (em->start != offset || em->len != (sectorsize - 5)) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 1, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\t/*\n\t * We don't test anything else for inline since it doesn't get set\n\t * unless we have a page for it to write into.  Maybe we should change\n\t * this?\n\t */\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 4) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 4, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Regular extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize - 1) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len 4095, got start %llu len %llu\",\n\t\t\toffset, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* The next 3 are split extents */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\t\"unexpected extent start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t orig_start, em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr += (em->start - orig_start);\n\tif (em->block_start != disk_bytenr) {\n\t\ttest_err(\"wrong block start, want %llu, have %llu\",\n\t\t\t disk_bytenr, em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Prealloc extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* The next 3 are a half written prealloc extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"unexpected orig offset, wanted %llu, have %llu\",\n\t\t\t orig_start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->block_start != (disk_bytenr + (em->start - em->orig_start))) {\n\t\ttest_err(\"unexpected block start, wanted %llu, have %llu\",\n\t\t\t disk_bytenr + (em->start - em->orig_start),\n\t\t\t em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != prealloc_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t prealloc_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", orig_start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->block_start != (disk_bytenr + (em->start - em->orig_start))) {\n\t\ttest_err(\"unexpected block start, wanted %llu, have %llu\",\n\t\t\t disk_bytenr + (em->start - em->orig_start),\n\t\t\t em->block_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Now for the compressed extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* Split compressed extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, em->orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\tdisk_bytenr = em->block_start;\n\torig_start = em->start;\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != disk_bytenr) {\n\t\ttest_err(\"block start does not match, want %llu got %llu\",\n\t\t\t disk_bytenr, em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != 2 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 2 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != compressed_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t compressed_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != orig_start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\",\n\t\t\t em->start, orig_start);\n\t\tgoto out;\n\t}\n\tif (em->compress_type != BTRFS_COMPRESS_ZLIB) {\n\t\ttest_err(\"unexpected compress type, wanted %d, got %d\",\n\t\t\t BTRFS_COMPRESS_ZLIB, em->compress_type);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\t/* A hole between regular extents but no hole extent */\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset + 6,\n\t\t\tsectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, SZ_4M, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start != EXTENT_MAP_HOLE) {\n\t\ttest_err(\"expected a hole extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\t/*\n\t * Currently we just return a length that we requested rather than the\n\t * length of the actual hole, if this changes we'll have to change this\n\t * test.\n\t */\n\tif (em->start != offset || em->len != 3 * sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, 3 * sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != vacancy_only) {\n\t\ttest_err(\"unexpected flags set, want %lu have %lu\",\n\t\t\t vacancy_only, em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\toffset = em->start + em->len;\n\tfree_extent_map(em);\n\n\tem = btrfs_get_extent(BTRFS_I(inode), NULL, 0, offset, sectorsize, 0);\n\tif (IS_ERR(em)) {\n\t\ttest_err(\"got an error when we shouldn't have\");\n\t\tgoto out;\n\t}\n\tif (em->block_start >= EXTENT_MAP_LAST_BYTE) {\n\t\ttest_err(\"expected a real extent, got %llu\", em->block_start);\n\t\tgoto out;\n\t}\n\tif (em->start != offset || em->len != sectorsize) {\n\t\ttest_err(\n\t\"unexpected extent wanted start %llu len %u, got start %llu len %llu\",\n\t\t\toffset, sectorsize, em->start, em->len);\n\t\tgoto out;\n\t}\n\tif (em->flags != 0) {\n\t\ttest_err(\"unexpected flags set, want 0 have %lu\", em->flags);\n\t\tgoto out;\n\t}\n\tif (em->orig_start != em->start) {\n\t\ttest_err(\"wrong orig offset, want %llu, have %llu\", em->start,\n\t\t\t em->orig_start);\n\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tif (!IS_ERR(em))\n\t\tfree_extent_map(em);\n\tiput(inode);\n\tbtrfs_free_dummy_root(root);\n\tbtrfs_free_dummy_fs_info(fs_info);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,7 @@\n \t\treturn ret;\n \t}\n \n+\tinode->i_mode = S_IFREG;\n \tBTRFS_I(inode)->location.type = BTRFS_INODE_ITEM_KEY;\n \tBTRFS_I(inode)->location.objectid = BTRFS_FIRST_FREE_OBJECTID;\n \tBTRFS_I(inode)->location.offset = 0;",
        "function_modified_lines": {
            "added": [
                "\tinode->i_mode = S_IFREG;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted btrfs filesystem image and performing some operations can cause slab-out-of-bounds write access in __btrfs_map_block in fs/btrfs/volumes.c, because a value of 1 for the number of data stripes is mishandled."
    },
    {
        "cve_id": "CVE-2019-20636",
        "code_before_change": "int input_set_keycode(struct input_dev *dev,\n\t\t      const struct input_keymap_entry *ke)\n{\n\tunsigned long flags;\n\tunsigned int old_keycode;\n\tint retval;\n\n\tif (ke->keycode > KEY_MAX)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&dev->event_lock, flags);\n\n\tretval = dev->setkeycode(dev, ke, &old_keycode);\n\tif (retval)\n\t\tgoto out;\n\n\t/* Make sure KEY_RESERVED did not get enabled. */\n\t__clear_bit(KEY_RESERVED, dev->keybit);\n\n\t/*\n\t * Simulate keyup event if keycode is not present\n\t * in the keymap anymore\n\t */\n\tif (test_bit(EV_KEY, dev->evbit) &&\n\t    !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&\n\t    __test_and_clear_bit(old_keycode, dev->key)) {\n\t\tstruct input_value vals[] =  {\n\t\t\t{ EV_KEY, old_keycode, 0 },\n\t\t\tinput_value_sync\n\t\t};\n\n\t\tinput_pass_values(dev, vals, ARRAY_SIZE(vals));\n\t}\n\n out:\n\tspin_unlock_irqrestore(&dev->event_lock, flags);\n\n\treturn retval;\n}",
        "code_after_change": "int input_set_keycode(struct input_dev *dev,\n\t\t      const struct input_keymap_entry *ke)\n{\n\tunsigned long flags;\n\tunsigned int old_keycode;\n\tint retval;\n\n\tif (ke->keycode > KEY_MAX)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&dev->event_lock, flags);\n\n\tretval = dev->setkeycode(dev, ke, &old_keycode);\n\tif (retval)\n\t\tgoto out;\n\n\t/* Make sure KEY_RESERVED did not get enabled. */\n\t__clear_bit(KEY_RESERVED, dev->keybit);\n\n\t/*\n\t * Simulate keyup event if keycode is not present\n\t * in the keymap anymore\n\t */\n\tif (old_keycode > KEY_MAX) {\n\t\tdev_warn(dev->dev.parent ?: &dev->dev,\n\t\t\t \"%s: got too big old keycode %#x\\n\",\n\t\t\t __func__, old_keycode);\n\t} else if (test_bit(EV_KEY, dev->evbit) &&\n\t\t   !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&\n\t\t   __test_and_clear_bit(old_keycode, dev->key)) {\n\t\tstruct input_value vals[] =  {\n\t\t\t{ EV_KEY, old_keycode, 0 },\n\t\t\tinput_value_sync\n\t\t};\n\n\t\tinput_pass_values(dev, vals, ARRAY_SIZE(vals));\n\t}\n\n out:\n\tspin_unlock_irqrestore(&dev->event_lock, flags);\n\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,9 +21,13 @@\n \t * Simulate keyup event if keycode is not present\n \t * in the keymap anymore\n \t */\n-\tif (test_bit(EV_KEY, dev->evbit) &&\n-\t    !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&\n-\t    __test_and_clear_bit(old_keycode, dev->key)) {\n+\tif (old_keycode > KEY_MAX) {\n+\t\tdev_warn(dev->dev.parent ?: &dev->dev,\n+\t\t\t \"%s: got too big old keycode %#x\\n\",\n+\t\t\t __func__, old_keycode);\n+\t} else if (test_bit(EV_KEY, dev->evbit) &&\n+\t\t   !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&\n+\t\t   __test_and_clear_bit(old_keycode, dev->key)) {\n \t\tstruct input_value vals[] =  {\n \t\t\t{ EV_KEY, old_keycode, 0 },\n \t\t\tinput_value_sync",
        "function_modified_lines": {
            "added": [
                "\tif (old_keycode > KEY_MAX) {",
                "\t\tdev_warn(dev->dev.parent ?: &dev->dev,",
                "\t\t\t \"%s: got too big old keycode %#x\\n\",",
                "\t\t\t __func__, old_keycode);",
                "\t} else if (test_bit(EV_KEY, dev->evbit) &&",
                "\t\t   !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&",
                "\t\t   __test_and_clear_bit(old_keycode, dev->key)) {"
            ],
            "deleted": [
                "\tif (test_bit(EV_KEY, dev->evbit) &&",
                "\t    !is_event_supported(old_keycode, dev->keybit, KEY_MAX) &&",
                "\t    __test_and_clear_bit(old_keycode, dev->key)) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.4.12, drivers/input/input.c has out-of-bounds writes via a crafted keycode table, as demonstrated by input_set_keycode, aka CID-cb222aed03d7."
    },
    {
        "cve_id": "CVE-2019-20636",
        "code_before_change": "static int input_default_setkeycode(struct input_dev *dev,\n\t\t\t\t    const struct input_keymap_entry *ke,\n\t\t\t\t    unsigned int *old_keycode)\n{\n\tunsigned int index;\n\tint error;\n\tint i;\n\n\tif (!dev->keycodesize)\n\t\treturn -EINVAL;\n\n\tif (ke->flags & INPUT_KEYMAP_BY_INDEX) {\n\t\tindex = ke->index;\n\t} else {\n\t\terror = input_scancode_to_scalar(ke, &index);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (index >= dev->keycodemax)\n\t\treturn -EINVAL;\n\n\tif (dev->keycodesize < sizeof(ke->keycode) &&\n\t\t\t(ke->keycode >> (dev->keycodesize * 8)))\n\t\treturn -EINVAL;\n\n\tswitch (dev->keycodesize) {\n\t\tcase 1: {\n\t\t\tu8 *k = (u8 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t\tcase 2: {\n\t\t\tu16 *k = (u16 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tu32 *k = (u32 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t__clear_bit(*old_keycode, dev->keybit);\n\t__set_bit(ke->keycode, dev->keybit);\n\n\tfor (i = 0; i < dev->keycodemax; i++) {\n\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {\n\t\t\t__set_bit(*old_keycode, dev->keybit);\n\t\t\tbreak; /* Setting the bit twice is useless, so break */\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int input_default_setkeycode(struct input_dev *dev,\n\t\t\t\t    const struct input_keymap_entry *ke,\n\t\t\t\t    unsigned int *old_keycode)\n{\n\tunsigned int index;\n\tint error;\n\tint i;\n\n\tif (!dev->keycodesize)\n\t\treturn -EINVAL;\n\n\tif (ke->flags & INPUT_KEYMAP_BY_INDEX) {\n\t\tindex = ke->index;\n\t} else {\n\t\terror = input_scancode_to_scalar(ke, &index);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (index >= dev->keycodemax)\n\t\treturn -EINVAL;\n\n\tif (dev->keycodesize < sizeof(ke->keycode) &&\n\t\t\t(ke->keycode >> (dev->keycodesize * 8)))\n\t\treturn -EINVAL;\n\n\tswitch (dev->keycodesize) {\n\t\tcase 1: {\n\t\t\tu8 *k = (u8 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t\tcase 2: {\n\t\t\tu16 *k = (u16 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tu32 *k = (u32 *)dev->keycode;\n\t\t\t*old_keycode = k[index];\n\t\t\tk[index] = ke->keycode;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (*old_keycode <= KEY_MAX) {\n\t\t__clear_bit(*old_keycode, dev->keybit);\n\t\tfor (i = 0; i < dev->keycodemax; i++) {\n\t\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {\n\t\t\t\t__set_bit(*old_keycode, dev->keybit);\n\t\t\t\t/* Setting the bit twice is useless, so break */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t__set_bit(ke->keycode, dev->keybit);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -45,15 +45,17 @@\n \t\t}\n \t}\n \n-\t__clear_bit(*old_keycode, dev->keybit);\n-\t__set_bit(ke->keycode, dev->keybit);\n-\n-\tfor (i = 0; i < dev->keycodemax; i++) {\n-\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {\n-\t\t\t__set_bit(*old_keycode, dev->keybit);\n-\t\t\tbreak; /* Setting the bit twice is useless, so break */\n+\tif (*old_keycode <= KEY_MAX) {\n+\t\t__clear_bit(*old_keycode, dev->keybit);\n+\t\tfor (i = 0; i < dev->keycodemax; i++) {\n+\t\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {\n+\t\t\t\t__set_bit(*old_keycode, dev->keybit);\n+\t\t\t\t/* Setting the bit twice is useless, so break */\n+\t\t\t\tbreak;\n+\t\t\t}\n \t\t}\n \t}\n \n+\t__set_bit(ke->keycode, dev->keybit);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (*old_keycode <= KEY_MAX) {",
                "\t\t__clear_bit(*old_keycode, dev->keybit);",
                "\t\tfor (i = 0; i < dev->keycodemax; i++) {",
                "\t\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {",
                "\t\t\t\t__set_bit(*old_keycode, dev->keybit);",
                "\t\t\t\t/* Setting the bit twice is useless, so break */",
                "\t\t\t\tbreak;",
                "\t\t\t}",
                "\t__set_bit(ke->keycode, dev->keybit);"
            ],
            "deleted": [
                "\t__clear_bit(*old_keycode, dev->keybit);",
                "\t__set_bit(ke->keycode, dev->keybit);",
                "",
                "\tfor (i = 0; i < dev->keycodemax; i++) {",
                "\t\tif (input_fetch_keycode(dev, i) == *old_keycode) {",
                "\t\t\t__set_bit(*old_keycode, dev->keybit);",
                "\t\t\tbreak; /* Setting the bit twice is useless, so break */"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.4.12, drivers/input/input.c has out-of-bounds writes via a crafted keycode table, as demonstrated by input_set_keycode, aka CID-cb222aed03d7."
    },
    {
        "cve_id": "CVE-2019-2181",
        "code_before_change": "static void binder_transaction(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction_data *tr, int reply,\n\t\t\t       binder_size_t extra_buffers_size)\n{\n\tint ret;\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tstruct binder_work *tcomplete;\n\tbinder_size_t buffer_offset = 0;\n\tbinder_size_t off_start_offset, off_end_offset;\n\tbinder_size_t off_min;\n\tbinder_size_t sg_buf_offset, sg_buf_end_offset;\n\tstruct binder_proc *target_proc = NULL;\n\tstruct binder_thread *target_thread = NULL;\n\tstruct binder_node *target_node = NULL;\n\tstruct binder_transaction *in_reply_to = NULL;\n\tstruct binder_transaction_log_entry *e;\n\tuint32_t return_error = 0;\n\tuint32_t return_error_param = 0;\n\tuint32_t return_error_line = 0;\n\tbinder_size_t last_fixup_obj_off = 0;\n\tbinder_size_t last_fixup_min_off = 0;\n\tstruct binder_context *context = proc->context;\n\tint t_debug_id = atomic_inc_return(&binder_last_id);\n\tchar *secctx = NULL;\n\tu32 secctx_sz = 0;\n\n\te = binder_transaction_log_add(&binder_transaction_log);\n\te->debug_id = t_debug_id;\n\te->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);\n\te->from_proc = proc->pid;\n\te->from_thread = thread->pid;\n\te->target_handle = tr->target.handle;\n\te->data_size = tr->data_size;\n\te->offsets_size = tr->offsets_size;\n\te->context_name = proc->context->name;\n\n\tif (reply) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tin_reply_to = thread->transaction_stack;\n\t\tif (in_reply_to == NULL) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with no transaction stack\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_empty_call_stack;\n\t\t}\n\t\tif (in_reply_to->to_thread != thread) {\n\t\t\tspin_lock(&in_reply_to->lock);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\tproc->pid, thread->pid, in_reply_to->debug_id,\n\t\t\t\tin_reply_to->to_proc ?\n\t\t\t\tin_reply_to->to_proc->pid : 0,\n\t\t\t\tin_reply_to->to_thread ?\n\t\t\t\tin_reply_to->to_thread->pid : 0);\n\t\t\tspin_unlock(&in_reply_to->lock);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\tgoto err_bad_call_stack;\n\t\t}\n\t\tthread->transaction_stack = in_reply_to->to_parent;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_set_nice(in_reply_to->saved_priority);\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(in_reply_to);\n\t\tif (target_thread == NULL) {\n\t\t\t/* annotation for sparse */\n\t\t\t__release(&target_thread->proc->inner_lock);\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\tif (target_thread->transaction_stack != in_reply_to) {\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad target transaction stack %d, expected %d\\n\",\n\t\t\t\tproc->pid, thread->pid,\n\t\t\t\ttarget_thread->transaction_stack ?\n\t\t\t\ttarget_thread->transaction_stack->debug_id : 0,\n\t\t\t\tin_reply_to->debug_id);\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\ttarget_thread = NULL;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\ttarget_proc = target_thread->proc;\n\t\ttarget_proc->tmp_ref++;\n\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t} else {\n\t\tif (tr->target.handle) {\n\t\t\tstruct binder_ref *ref;\n\n\t\t\t/*\n\t\t\t * There must already be a strong ref\n\t\t\t * on this node. If so, do a strong\n\t\t\t * increment on the node to ensure it\n\t\t\t * stays alive until the transaction is\n\t\t\t * done.\n\t\t\t */\n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, tr->target.handle,\n\t\t\t\t\t\t     true);\n\t\t\tif (ref) {\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\tref->node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\t} else {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to invalid handle\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t}\n\t\t\tbinder_proc_unlock(proc);\n\t\t} else {\n\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\ttarget_node = context->binder_context_mgr_node;\n\t\t\tif (target_node)\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\ttarget_node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\telse\n\t\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\tif (target_node && target_proc == proc) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to context manager from process owning it\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_invalid_target_handle;\n\t\t\t}\n\t\t}\n\t\tif (!target_node) {\n\t\t\t/*\n\t\t\t * return_error is set above\n\t\t\t */\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\te->to_node = target_node->debug_id;\n\t\tif (security_binder_transaction(proc->tsk,\n\t\t\t\t\t\ttarget_proc->tsk) < 0) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPERM;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\n\t\tw = list_first_entry_or_null(&thread->todo,\n\t\t\t\t\t     struct binder_work, entry);\n\t\tif (!(tr->flags & TF_ONE_WAY) && w &&\n\t\t    w->type == BINDER_WORK_TRANSACTION) {\n\t\t\t/*\n\t\t\t * Do not allow new outgoing transaction from a\n\t\t\t * thread that has a transaction at the head of\n\t\t\t * its todo list. Only need to check the head\n\t\t\t * because binder_select_thread_ilocked picks a\n\t\t\t * thread from proc->waiting_threads to enqueue\n\t\t\t * the transaction, and nothing is queued to the\n\t\t\t * todo list while the thread is on waiting_threads.\n\t\t\t */\n\t\t\tbinder_user_error(\"%d:%d new transaction not allowed when there is a transaction on thread todo\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_todo_list;\n\t\t}\n\n\t\tif (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {\n\t\t\tstruct binder_transaction *tmp;\n\n\t\t\ttmp = thread->transaction_stack;\n\t\t\tif (tmp->to_thread != thread) {\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tbinder_user_error(\"%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, tmp->debug_id,\n\t\t\t\t\ttmp->to_proc ? tmp->to_proc->pid : 0,\n\t\t\t\t\ttmp->to_thread ?\n\t\t\t\t\ttmp->to_thread->pid : 0);\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EPROTO;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_call_stack;\n\t\t\t}\n\t\t\twhile (tmp) {\n\t\t\t\tstruct binder_thread *from;\n\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tfrom = tmp->from;\n\t\t\t\tif (from && from->proc == target_proc) {\n\t\t\t\t\tatomic_inc(&from->tmp_ref);\n\t\t\t\t\ttarget_thread = from;\n\t\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\ttmp = tmp->from_parent;\n\t\t\t}\n\t\t}\n\t\tbinder_inner_proc_unlock(proc);\n\t}\n\tif (target_thread)\n\t\te->to_thread = target_thread->pid;\n\te->to_proc = target_proc->pid;\n\n\t/* TODO: reuse incoming transaction for reply */\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (t == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_t_failed;\n\t}\n\tINIT_LIST_HEAD(&t->fd_fixups);\n\tbinder_stats_created(BINDER_STAT_TRANSACTION);\n\tspin_lock_init(&t->lock);\n\n\ttcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);\n\tif (tcomplete == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_tcomplete_failed;\n\t}\n\tbinder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);\n\n\tt->debug_id = t_debug_id;\n\n\tif (reply)\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_thread->pid,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\telse\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_node->debug_id,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\n\tif (!reply && !(tr->flags & TF_ONE_WAY))\n\t\tt->from = thread;\n\telse\n\t\tt->from = NULL;\n\tt->sender_euid = task_euid(proc->tsk);\n\tt->to_proc = target_proc;\n\tt->to_thread = target_thread;\n\tt->code = tr->code;\n\tt->flags = tr->flags;\n\tt->priority = task_nice(current);\n\n\tif (target_node && target_node->txn_security_ctx) {\n\t\tu32 secid;\n\n\t\tsecurity_task_getsecid(proc->tsk, &secid);\n\t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n\t\tif (ret) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = ret;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_get_secctx_failed;\n\t\t}\n\t\textra_buffers_size += ALIGN(secctx_sz, sizeof(u64));\n\t}\n\n\ttrace_binder_transaction(reply, t, target_node);\n\n\tt->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,\n\t\ttr->offsets_size, extra_buffers_size,\n\t\t!reply && (t->flags & TF_ONE_WAY));\n\tif (IS_ERR(t->buffer)) {\n\t\t/*\n\t\t * -ESRCH indicates VMA cleared. The target is dying.\n\t\t */\n\t\treturn_error_param = PTR_ERR(t->buffer);\n\t\treturn_error = return_error_param == -ESRCH ?\n\t\t\tBR_DEAD_REPLY : BR_FAILED_REPLY;\n\t\treturn_error_line = __LINE__;\n\t\tt->buffer = NULL;\n\t\tgoto err_binder_alloc_buf_failed;\n\t}\n\tif (secctx) {\n\t\tsize_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(tr->offsets_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(extra_buffers_size, sizeof(void *)) -\n\t\t\t\t    ALIGN(secctx_sz, sizeof(u64));\n\n\t\tt->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;\n\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t    t->buffer, buf_offset,\n\t\t\t\t\t    secctx, secctx_sz);\n\t\tsecurity_release_secctx(secctx, secctx_sz);\n\t\tsecctx = NULL;\n\t}\n\tt->buffer->debug_id = t->debug_id;\n\tt->buffer->transaction = t;\n\tt->buffer->target_node = target_node;\n\ttrace_binder_transaction_alloc_buf(t->buffer);\n\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer, 0,\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.buffer,\n\t\t\t\ttr->data_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer,\n\t\t\t\tALIGN(tr->data_size, sizeof(void *)),\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.offsets,\n\t\t\t\ttr->offsets_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets size, %lld\\n\",\n\t\t\t\tproc->pid, thread->pid, (u64)tr->offsets_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\tif (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {\n\t\tbinder_user_error(\"%d:%d got transaction with unaligned buffers size, %lld\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  (u64)extra_buffers_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\toff_start_offset = ALIGN(tr->data_size, sizeof(void *));\n\tbuffer_offset = off_start_offset;\n\toff_end_offset = off_start_offset + tr->offsets_size;\n\tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size;\n\toff_min = 0;\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\n\t\tbinder_alloc_copy_from_buffer(&target_proc->alloc,\n\t\t\t\t\t      &object_offset,\n\t\t\t\t\t      t->buffer,\n\t\t\t\t\t      buffer_offset,\n\t\t\t\t\t      sizeof(object_offset));\n\t\tobject_size = binder_get_object(target_proc, t->buffer,\n\t\t\t\t\t\tobject_offset, &object);\n\t\tif (object_size == 0 || object_offset < off_min) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\\n\",\n\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t  (u64)object_offset,\n\t\t\t\t\t  (u64)off_min,\n\t\t\t\t\t  (u64)t->buffer->data_size);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\n\t\thdr = &object.hdr;\n\t\toff_min = object_offset + object_size;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_binder(fp, t, thread);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_handle(fp, t, thread);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\tstruct binder_fd_object *fp = to_binder_fd_object(hdr);\n\t\t\tbinder_size_t fd_offset = object_offset +\n\t\t\t\t(uintptr_t)&fp->fd - (uintptr_t)fp;\n\t\t\tint ret = binder_translate_fd(fp->fd, fd_offset, t,\n\t\t\t\t\t\t      thread, in_reply_to);\n\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tfp->pad_binder = 0;\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t parent_offset;\n\t\t\tstruct binder_fd_array_object *fda =\n\t\t\t\tto_binder_fd_array_object(hdr);\n\t\t\tsize_t num_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tstruct binder_buffer_object *parent =\n\t\t\t\tbinder_validate_ptr(target_proc, t->buffer,\n\t\t\t\t\t\t    &ptr_object, fda->parent,\n\t\t\t\t\t\t    off_start_offset,\n\t\t\t\t\t\t    &parent_offset,\n\t\t\t\t\t\t    num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tif (!binder_validate_fixup(target_proc, t->buffer,\n\t\t\t\t\t\t   off_start_offset,\n\t\t\t\t\t\t   parent_offset,\n\t\t\t\t\t\t   fda->parent_offset,\n\t\t\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t\t\t   last_fixup_min_off)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tret = binder_translate_fd_array(fda, parent, t, thread,\n\t\t\t\t\t\t\tin_reply_to);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = parent_offset;\n\t\t\tlast_fixup_min_off =\n\t\t\t\tfda->parent_offset + sizeof(u32) * fda->num_fds;\n\t\t} break;\n\t\tcase BINDER_TYPE_PTR: {\n\t\t\tstruct binder_buffer_object *bp =\n\t\t\t\tto_binder_buffer_object(hdr);\n\t\t\tsize_t buf_left = sg_buf_end_offset - sg_buf_offset;\n\t\t\tsize_t num_valid;\n\n\t\t\tif (bp->length > buf_left) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with too large buffer\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_offset;\n\t\t\t}\n\t\t\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t\t\t&target_proc->alloc,\n\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\tsg_buf_offset,\n\t\t\t\t\t\t(const void __user *)\n\t\t\t\t\t\t\t(uintptr_t)bp->buffer,\n\t\t\t\t\t\tbp->length)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error_param = -EFAULT;\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_copy_data_failed;\n\t\t\t}\n\t\t\t/* Fixup buffer pointer to target proc address space */\n\t\t\tbp->buffer = (uintptr_t)\n\t\t\t\tt->buffer->user_data + sg_buf_offset;\n\t\t\tsg_buf_offset += ALIGN(bp->length, sizeof(u64));\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tret = binder_fixup_parent(t, thread, bp,\n\t\t\t\t\t\t  off_start_offset,\n\t\t\t\t\t\t  num_valid,\n\t\t\t\t\t\t  last_fixup_obj_off,\n\t\t\t\t\t\t  last_fixup_min_off);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    bp, sizeof(*bp));\n\t\t\tlast_fixup_obj_off = object_offset;\n\t\t\tlast_fixup_min_off = 0;\n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid object type, %x\\n\",\n\t\t\t\tproc->pid, thread->pid, hdr->type);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_object_type;\n\t\t}\n\t}\n\ttcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;\n\tt->work.type = BINDER_WORK_TRANSACTION;\n\n\tif (reply) {\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (target_thread->is_dead) {\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_pop_transaction_ilocked(target_thread, in_reply_to);\n\t\tbinder_enqueue_thread_work_ilocked(target_thread, &t->work);\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\twake_up_interruptible_sync(&target_thread->wait);\n\t\tbinder_free_transaction(in_reply_to);\n\t} else if (!(t->flags & TF_ONE_WAY)) {\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_inner_proc_lock(proc);\n\t\t/*\n\t\t * Defer the TRANSACTION_COMPLETE, so we don't return to\n\t\t * userspace immediately; this allows the target process to\n\t\t * immediately start processing this transaction, reducing\n\t\t * latency. We will then return the TRANSACTION_COMPLETE when\n\t\t * the target replies (or there is an error).\n\t\t */\n\t\tbinder_enqueue_deferred_thread_work_ilocked(thread, tcomplete);\n\t\tt->need_reply = 1;\n\t\tt->from_parent = thread->transaction_stack;\n\t\tthread->transaction_stack = t;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (!binder_proc_transaction(t, target_proc, target_thread)) {\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tbinder_pop_transaction_ilocked(thread, t);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t} else {\n\t\tBUG_ON(target_node == NULL);\n\t\tBUG_ON(t->buffer->async_transaction != 1);\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tif (!binder_proc_transaction(t, target_proc, NULL))\n\t\t\tgoto err_dead_proc_or_thread;\n\t}\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\t/*\n\t * write barrier to synchronize with initialization\n\t * of log entry\n\t */\n\tsmp_wmb();\n\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\treturn;\n\nerr_dead_proc_or_thread:\n\treturn_error = BR_DEAD_REPLY;\n\treturn_error_line = __LINE__;\n\tbinder_dequeue_work(proc, tcomplete);\nerr_translate_failed:\nerr_bad_object_type:\nerr_bad_offset:\nerr_bad_parent:\nerr_copy_data_failed:\n\tbinder_free_txn_fixups(t);\n\ttrace_binder_transaction_failed_buffer_release(t->buffer);\n\tbinder_transaction_buffer_release(target_proc, t->buffer,\n\t\t\t\t\t  buffer_offset, true);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\ttarget_node = NULL;\n\tt->buffer->transaction = NULL;\n\tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\nerr_binder_alloc_buf_failed:\n\tif (secctx)\n\t\tsecurity_release_secctx(secctx, secctx_sz);\nerr_get_secctx_failed:\n\tkfree(tcomplete);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\nerr_alloc_tcomplete_failed:\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\nerr_alloc_t_failed:\nerr_bad_todo_list:\nerr_bad_call_stack:\nerr_empty_call_stack:\nerr_dead_binder:\nerr_invalid_target_handle:\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tif (target_proc)\n\t\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node) {\n\t\tbinder_dec_node(target_node, 1, 0);\n\t\tbinder_dec_node_tmpref(target_node);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t     \"%d:%d transaction failed %d/%d, size %lld-%lld line %d\\n\",\n\t\t     proc->pid, thread->pid, return_error, return_error_param,\n\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t     return_error_line);\n\n\t{\n\t\tstruct binder_transaction_log_entry *fe;\n\n\t\te->return_error = return_error;\n\t\te->return_error_param = return_error_param;\n\t\te->return_error_line = return_error_line;\n\t\tfe = binder_transaction_log_add(&binder_transaction_log_failed);\n\t\t*fe = *e;\n\t\t/*\n\t\t * write barrier to synchronize with initialization\n\t\t * of log entry\n\t\t */\n\t\tsmp_wmb();\n\t\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\t\tWRITE_ONCE(fe->debug_id_done, t_debug_id);\n\t}\n\n\tBUG_ON(thread->return_error.cmd != BR_OK);\n\tif (in_reply_to) {\n\t\tthread->return_error.cmd = BR_TRANSACTION_COMPLETE;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t\tbinder_send_failed_reply(in_reply_to, return_error);\n\t} else {\n\t\tthread->return_error.cmd = return_error;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t}\n}",
        "code_after_change": "static void binder_transaction(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction_data *tr, int reply,\n\t\t\t       binder_size_t extra_buffers_size)\n{\n\tint ret;\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tstruct binder_work *tcomplete;\n\tbinder_size_t buffer_offset = 0;\n\tbinder_size_t off_start_offset, off_end_offset;\n\tbinder_size_t off_min;\n\tbinder_size_t sg_buf_offset, sg_buf_end_offset;\n\tstruct binder_proc *target_proc = NULL;\n\tstruct binder_thread *target_thread = NULL;\n\tstruct binder_node *target_node = NULL;\n\tstruct binder_transaction *in_reply_to = NULL;\n\tstruct binder_transaction_log_entry *e;\n\tuint32_t return_error = 0;\n\tuint32_t return_error_param = 0;\n\tuint32_t return_error_line = 0;\n\tbinder_size_t last_fixup_obj_off = 0;\n\tbinder_size_t last_fixup_min_off = 0;\n\tstruct binder_context *context = proc->context;\n\tint t_debug_id = atomic_inc_return(&binder_last_id);\n\tchar *secctx = NULL;\n\tu32 secctx_sz = 0;\n\n\te = binder_transaction_log_add(&binder_transaction_log);\n\te->debug_id = t_debug_id;\n\te->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);\n\te->from_proc = proc->pid;\n\te->from_thread = thread->pid;\n\te->target_handle = tr->target.handle;\n\te->data_size = tr->data_size;\n\te->offsets_size = tr->offsets_size;\n\te->context_name = proc->context->name;\n\n\tif (reply) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tin_reply_to = thread->transaction_stack;\n\t\tif (in_reply_to == NULL) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with no transaction stack\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_empty_call_stack;\n\t\t}\n\t\tif (in_reply_to->to_thread != thread) {\n\t\t\tspin_lock(&in_reply_to->lock);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\tproc->pid, thread->pid, in_reply_to->debug_id,\n\t\t\t\tin_reply_to->to_proc ?\n\t\t\t\tin_reply_to->to_proc->pid : 0,\n\t\t\t\tin_reply_to->to_thread ?\n\t\t\t\tin_reply_to->to_thread->pid : 0);\n\t\t\tspin_unlock(&in_reply_to->lock);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\tgoto err_bad_call_stack;\n\t\t}\n\t\tthread->transaction_stack = in_reply_to->to_parent;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_set_nice(in_reply_to->saved_priority);\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(in_reply_to);\n\t\tif (target_thread == NULL) {\n\t\t\t/* annotation for sparse */\n\t\t\t__release(&target_thread->proc->inner_lock);\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\tif (target_thread->transaction_stack != in_reply_to) {\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad target transaction stack %d, expected %d\\n\",\n\t\t\t\tproc->pid, thread->pid,\n\t\t\t\ttarget_thread->transaction_stack ?\n\t\t\t\ttarget_thread->transaction_stack->debug_id : 0,\n\t\t\t\tin_reply_to->debug_id);\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\ttarget_thread = NULL;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\ttarget_proc = target_thread->proc;\n\t\ttarget_proc->tmp_ref++;\n\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t} else {\n\t\tif (tr->target.handle) {\n\t\t\tstruct binder_ref *ref;\n\n\t\t\t/*\n\t\t\t * There must already be a strong ref\n\t\t\t * on this node. If so, do a strong\n\t\t\t * increment on the node to ensure it\n\t\t\t * stays alive until the transaction is\n\t\t\t * done.\n\t\t\t */\n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, tr->target.handle,\n\t\t\t\t\t\t     true);\n\t\t\tif (ref) {\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\tref->node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\t} else {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to invalid handle\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t}\n\t\t\tbinder_proc_unlock(proc);\n\t\t} else {\n\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\ttarget_node = context->binder_context_mgr_node;\n\t\t\tif (target_node)\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\ttarget_node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\telse\n\t\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\tif (target_node && target_proc == proc) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to context manager from process owning it\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_invalid_target_handle;\n\t\t\t}\n\t\t}\n\t\tif (!target_node) {\n\t\t\t/*\n\t\t\t * return_error is set above\n\t\t\t */\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\te->to_node = target_node->debug_id;\n\t\tif (security_binder_transaction(proc->tsk,\n\t\t\t\t\t\ttarget_proc->tsk) < 0) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPERM;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\n\t\tw = list_first_entry_or_null(&thread->todo,\n\t\t\t\t\t     struct binder_work, entry);\n\t\tif (!(tr->flags & TF_ONE_WAY) && w &&\n\t\t    w->type == BINDER_WORK_TRANSACTION) {\n\t\t\t/*\n\t\t\t * Do not allow new outgoing transaction from a\n\t\t\t * thread that has a transaction at the head of\n\t\t\t * its todo list. Only need to check the head\n\t\t\t * because binder_select_thread_ilocked picks a\n\t\t\t * thread from proc->waiting_threads to enqueue\n\t\t\t * the transaction, and nothing is queued to the\n\t\t\t * todo list while the thread is on waiting_threads.\n\t\t\t */\n\t\t\tbinder_user_error(\"%d:%d new transaction not allowed when there is a transaction on thread todo\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_todo_list;\n\t\t}\n\n\t\tif (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {\n\t\t\tstruct binder_transaction *tmp;\n\n\t\t\ttmp = thread->transaction_stack;\n\t\t\tif (tmp->to_thread != thread) {\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tbinder_user_error(\"%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, tmp->debug_id,\n\t\t\t\t\ttmp->to_proc ? tmp->to_proc->pid : 0,\n\t\t\t\t\ttmp->to_thread ?\n\t\t\t\t\ttmp->to_thread->pid : 0);\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EPROTO;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_call_stack;\n\t\t\t}\n\t\t\twhile (tmp) {\n\t\t\t\tstruct binder_thread *from;\n\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tfrom = tmp->from;\n\t\t\t\tif (from && from->proc == target_proc) {\n\t\t\t\t\tatomic_inc(&from->tmp_ref);\n\t\t\t\t\ttarget_thread = from;\n\t\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\ttmp = tmp->from_parent;\n\t\t\t}\n\t\t}\n\t\tbinder_inner_proc_unlock(proc);\n\t}\n\tif (target_thread)\n\t\te->to_thread = target_thread->pid;\n\te->to_proc = target_proc->pid;\n\n\t/* TODO: reuse incoming transaction for reply */\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (t == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_t_failed;\n\t}\n\tINIT_LIST_HEAD(&t->fd_fixups);\n\tbinder_stats_created(BINDER_STAT_TRANSACTION);\n\tspin_lock_init(&t->lock);\n\n\ttcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);\n\tif (tcomplete == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_tcomplete_failed;\n\t}\n\tbinder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);\n\n\tt->debug_id = t_debug_id;\n\n\tif (reply)\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_thread->pid,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\telse\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_node->debug_id,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\n\tif (!reply && !(tr->flags & TF_ONE_WAY))\n\t\tt->from = thread;\n\telse\n\t\tt->from = NULL;\n\tt->sender_euid = task_euid(proc->tsk);\n\tt->to_proc = target_proc;\n\tt->to_thread = target_thread;\n\tt->code = tr->code;\n\tt->flags = tr->flags;\n\tt->priority = task_nice(current);\n\n\tif (target_node && target_node->txn_security_ctx) {\n\t\tu32 secid;\n\t\tsize_t added_size;\n\n\t\tsecurity_task_getsecid(proc->tsk, &secid);\n\t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n\t\tif (ret) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = ret;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_get_secctx_failed;\n\t\t}\n\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));\n\t\textra_buffers_size += added_size;\n\t\tif (extra_buffers_size < added_size) {\n\t\t\t/* integer overflow of extra_buffers_size */\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_extra_size;\n\t\t}\n\t}\n\n\ttrace_binder_transaction(reply, t, target_node);\n\n\tt->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,\n\t\ttr->offsets_size, extra_buffers_size,\n\t\t!reply && (t->flags & TF_ONE_WAY));\n\tif (IS_ERR(t->buffer)) {\n\t\t/*\n\t\t * -ESRCH indicates VMA cleared. The target is dying.\n\t\t */\n\t\treturn_error_param = PTR_ERR(t->buffer);\n\t\treturn_error = return_error_param == -ESRCH ?\n\t\t\tBR_DEAD_REPLY : BR_FAILED_REPLY;\n\t\treturn_error_line = __LINE__;\n\t\tt->buffer = NULL;\n\t\tgoto err_binder_alloc_buf_failed;\n\t}\n\tif (secctx) {\n\t\tsize_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(tr->offsets_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(extra_buffers_size, sizeof(void *)) -\n\t\t\t\t    ALIGN(secctx_sz, sizeof(u64));\n\n\t\tt->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;\n\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t    t->buffer, buf_offset,\n\t\t\t\t\t    secctx, secctx_sz);\n\t\tsecurity_release_secctx(secctx, secctx_sz);\n\t\tsecctx = NULL;\n\t}\n\tt->buffer->debug_id = t->debug_id;\n\tt->buffer->transaction = t;\n\tt->buffer->target_node = target_node;\n\ttrace_binder_transaction_alloc_buf(t->buffer);\n\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer, 0,\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.buffer,\n\t\t\t\ttr->data_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer,\n\t\t\t\tALIGN(tr->data_size, sizeof(void *)),\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.offsets,\n\t\t\t\ttr->offsets_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets size, %lld\\n\",\n\t\t\t\tproc->pid, thread->pid, (u64)tr->offsets_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\tif (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {\n\t\tbinder_user_error(\"%d:%d got transaction with unaligned buffers size, %lld\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  (u64)extra_buffers_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\toff_start_offset = ALIGN(tr->data_size, sizeof(void *));\n\tbuffer_offset = off_start_offset;\n\toff_end_offset = off_start_offset + tr->offsets_size;\n\tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size;\n\toff_min = 0;\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\n\t\tbinder_alloc_copy_from_buffer(&target_proc->alloc,\n\t\t\t\t\t      &object_offset,\n\t\t\t\t\t      t->buffer,\n\t\t\t\t\t      buffer_offset,\n\t\t\t\t\t      sizeof(object_offset));\n\t\tobject_size = binder_get_object(target_proc, t->buffer,\n\t\t\t\t\t\tobject_offset, &object);\n\t\tif (object_size == 0 || object_offset < off_min) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\\n\",\n\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t  (u64)object_offset,\n\t\t\t\t\t  (u64)off_min,\n\t\t\t\t\t  (u64)t->buffer->data_size);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\n\t\thdr = &object.hdr;\n\t\toff_min = object_offset + object_size;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_binder(fp, t, thread);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_handle(fp, t, thread);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\tstruct binder_fd_object *fp = to_binder_fd_object(hdr);\n\t\t\tbinder_size_t fd_offset = object_offset +\n\t\t\t\t(uintptr_t)&fp->fd - (uintptr_t)fp;\n\t\t\tint ret = binder_translate_fd(fp->fd, fd_offset, t,\n\t\t\t\t\t\t      thread, in_reply_to);\n\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tfp->pad_binder = 0;\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    fp, sizeof(*fp));\n\t\t} break;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t parent_offset;\n\t\t\tstruct binder_fd_array_object *fda =\n\t\t\t\tto_binder_fd_array_object(hdr);\n\t\t\tsize_t num_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tstruct binder_buffer_object *parent =\n\t\t\t\tbinder_validate_ptr(target_proc, t->buffer,\n\t\t\t\t\t\t    &ptr_object, fda->parent,\n\t\t\t\t\t\t    off_start_offset,\n\t\t\t\t\t\t    &parent_offset,\n\t\t\t\t\t\t    num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tif (!binder_validate_fixup(target_proc, t->buffer,\n\t\t\t\t\t\t   off_start_offset,\n\t\t\t\t\t\t   parent_offset,\n\t\t\t\t\t\t   fda->parent_offset,\n\t\t\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t\t\t   last_fixup_min_off)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tret = binder_translate_fd_array(fda, parent, t, thread,\n\t\t\t\t\t\t\tin_reply_to);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = parent_offset;\n\t\t\tlast_fixup_min_off =\n\t\t\t\tfda->parent_offset + sizeof(u32) * fda->num_fds;\n\t\t} break;\n\t\tcase BINDER_TYPE_PTR: {\n\t\t\tstruct binder_buffer_object *bp =\n\t\t\t\tto_binder_buffer_object(hdr);\n\t\t\tsize_t buf_left = sg_buf_end_offset - sg_buf_offset;\n\t\t\tsize_t num_valid;\n\n\t\t\tif (bp->length > buf_left) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with too large buffer\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_offset;\n\t\t\t}\n\t\t\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t\t\t&target_proc->alloc,\n\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\tsg_buf_offset,\n\t\t\t\t\t\t(const void __user *)\n\t\t\t\t\t\t\t(uintptr_t)bp->buffer,\n\t\t\t\t\t\tbp->length)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error_param = -EFAULT;\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_copy_data_failed;\n\t\t\t}\n\t\t\t/* Fixup buffer pointer to target proc address space */\n\t\t\tbp->buffer = (uintptr_t)\n\t\t\t\tt->buffer->user_data + sg_buf_offset;\n\t\t\tsg_buf_offset += ALIGN(bp->length, sizeof(u64));\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tret = binder_fixup_parent(t, thread, bp,\n\t\t\t\t\t\t  off_start_offset,\n\t\t\t\t\t\t  num_valid,\n\t\t\t\t\t\t  last_fixup_obj_off,\n\t\t\t\t\t\t  last_fixup_min_off);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tbinder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t    t->buffer, object_offset,\n\t\t\t\t\t\t    bp, sizeof(*bp));\n\t\t\tlast_fixup_obj_off = object_offset;\n\t\t\tlast_fixup_min_off = 0;\n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid object type, %x\\n\",\n\t\t\t\tproc->pid, thread->pid, hdr->type);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_object_type;\n\t\t}\n\t}\n\ttcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;\n\tt->work.type = BINDER_WORK_TRANSACTION;\n\n\tif (reply) {\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (target_thread->is_dead) {\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_pop_transaction_ilocked(target_thread, in_reply_to);\n\t\tbinder_enqueue_thread_work_ilocked(target_thread, &t->work);\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\twake_up_interruptible_sync(&target_thread->wait);\n\t\tbinder_free_transaction(in_reply_to);\n\t} else if (!(t->flags & TF_ONE_WAY)) {\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_inner_proc_lock(proc);\n\t\t/*\n\t\t * Defer the TRANSACTION_COMPLETE, so we don't return to\n\t\t * userspace immediately; this allows the target process to\n\t\t * immediately start processing this transaction, reducing\n\t\t * latency. We will then return the TRANSACTION_COMPLETE when\n\t\t * the target replies (or there is an error).\n\t\t */\n\t\tbinder_enqueue_deferred_thread_work_ilocked(thread, tcomplete);\n\t\tt->need_reply = 1;\n\t\tt->from_parent = thread->transaction_stack;\n\t\tthread->transaction_stack = t;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (!binder_proc_transaction(t, target_proc, target_thread)) {\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tbinder_pop_transaction_ilocked(thread, t);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t} else {\n\t\tBUG_ON(target_node == NULL);\n\t\tBUG_ON(t->buffer->async_transaction != 1);\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tif (!binder_proc_transaction(t, target_proc, NULL))\n\t\t\tgoto err_dead_proc_or_thread;\n\t}\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\t/*\n\t * write barrier to synchronize with initialization\n\t * of log entry\n\t */\n\tsmp_wmb();\n\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\treturn;\n\nerr_dead_proc_or_thread:\n\treturn_error = BR_DEAD_REPLY;\n\treturn_error_line = __LINE__;\n\tbinder_dequeue_work(proc, tcomplete);\nerr_translate_failed:\nerr_bad_object_type:\nerr_bad_offset:\nerr_bad_parent:\nerr_copy_data_failed:\n\tbinder_free_txn_fixups(t);\n\ttrace_binder_transaction_failed_buffer_release(t->buffer);\n\tbinder_transaction_buffer_release(target_proc, t->buffer,\n\t\t\t\t\t  buffer_offset, true);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\ttarget_node = NULL;\n\tt->buffer->transaction = NULL;\n\tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\nerr_binder_alloc_buf_failed:\nerr_bad_extra_size:\n\tif (secctx)\n\t\tsecurity_release_secctx(secctx, secctx_sz);\nerr_get_secctx_failed:\n\tkfree(tcomplete);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\nerr_alloc_tcomplete_failed:\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\nerr_alloc_t_failed:\nerr_bad_todo_list:\nerr_bad_call_stack:\nerr_empty_call_stack:\nerr_dead_binder:\nerr_invalid_target_handle:\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tif (target_proc)\n\t\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node) {\n\t\tbinder_dec_node(target_node, 1, 0);\n\t\tbinder_dec_node_tmpref(target_node);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t     \"%d:%d transaction failed %d/%d, size %lld-%lld line %d\\n\",\n\t\t     proc->pid, thread->pid, return_error, return_error_param,\n\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t     return_error_line);\n\n\t{\n\t\tstruct binder_transaction_log_entry *fe;\n\n\t\te->return_error = return_error;\n\t\te->return_error_param = return_error_param;\n\t\te->return_error_line = return_error_line;\n\t\tfe = binder_transaction_log_add(&binder_transaction_log_failed);\n\t\t*fe = *e;\n\t\t/*\n\t\t * write barrier to synchronize with initialization\n\t\t * of log entry\n\t\t */\n\t\tsmp_wmb();\n\t\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\t\tWRITE_ONCE(fe->debug_id_done, t_debug_id);\n\t}\n\n\tBUG_ON(thread->return_error.cmd != BR_OK);\n\tif (in_reply_to) {\n\t\tthread->return_error.cmd = BR_TRANSACTION_COMPLETE;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t\tbinder_send_failed_reply(in_reply_to, return_error);\n\t} else {\n\t\tthread->return_error.cmd = return_error;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -269,6 +269,7 @@\n \n \tif (target_node && target_node->txn_security_ctx) {\n \t\tu32 secid;\n+\t\tsize_t added_size;\n \n \t\tsecurity_task_getsecid(proc->tsk, &secid);\n \t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n@@ -278,7 +279,15 @@\n \t\t\treturn_error_line = __LINE__;\n \t\t\tgoto err_get_secctx_failed;\n \t\t}\n-\t\textra_buffers_size += ALIGN(secctx_sz, sizeof(u64));\n+\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));\n+\t\textra_buffers_size += added_size;\n+\t\tif (extra_buffers_size < added_size) {\n+\t\t\t/* integer overflow of extra_buffers_size */\n+\t\t\treturn_error = BR_FAILED_REPLY;\n+\t\t\treturn_error_param = EINVAL;\n+\t\t\treturn_error_line = __LINE__;\n+\t\t\tgoto err_bad_extra_size;\n+\t\t}\n \t}\n \n \ttrace_binder_transaction(reply, t, target_node);\n@@ -628,6 +637,7 @@\n \tt->buffer->transaction = NULL;\n \tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\n err_binder_alloc_buf_failed:\n+err_bad_extra_size:\n \tif (secctx)\n \t\tsecurity_release_secctx(secctx, secctx_sz);\n err_get_secctx_failed:",
        "function_modified_lines": {
            "added": [
                "\t\tsize_t added_size;",
                "\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));",
                "\t\textra_buffers_size += added_size;",
                "\t\tif (extra_buffers_size < added_size) {",
                "\t\t\t/* integer overflow of extra_buffers_size */",
                "\t\t\treturn_error = BR_FAILED_REPLY;",
                "\t\t\treturn_error_param = EINVAL;",
                "\t\t\treturn_error_line = __LINE__;",
                "\t\t\tgoto err_bad_extra_size;",
                "\t\t}",
                "err_bad_extra_size:"
            ],
            "deleted": [
                "\t\textra_buffers_size += ALIGN(secctx_sz, sizeof(u64));"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "In binder_transaction of binder.c in the Android kernel, there is a possible out of bounds write due to an integer overflow. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is needed for exploitation."
    },
    {
        "cve_id": "CVE-2019-2214",
        "code_before_change": "static void binder_transaction(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction_data *tr, int reply,\n\t\t\t       binder_size_t extra_buffers_size)\n{\n\tint ret;\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tstruct binder_work *tcomplete;\n\tbinder_size_t buffer_offset = 0;\n\tbinder_size_t off_start_offset, off_end_offset;\n\tbinder_size_t off_min;\n\tbinder_size_t sg_buf_offset, sg_buf_end_offset;\n\tstruct binder_proc *target_proc = NULL;\n\tstruct binder_thread *target_thread = NULL;\n\tstruct binder_node *target_node = NULL;\n\tstruct binder_transaction *in_reply_to = NULL;\n\tstruct binder_transaction_log_entry *e;\n\tuint32_t return_error = 0;\n\tuint32_t return_error_param = 0;\n\tuint32_t return_error_line = 0;\n\tbinder_size_t last_fixup_obj_off = 0;\n\tbinder_size_t last_fixup_min_off = 0;\n\tstruct binder_context *context = proc->context;\n\tint t_debug_id = atomic_inc_return(&binder_last_id);\n\tchar *secctx = NULL;\n\tu32 secctx_sz = 0;\n\n\te = binder_transaction_log_add(&binder_transaction_log);\n\te->debug_id = t_debug_id;\n\te->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);\n\te->from_proc = proc->pid;\n\te->from_thread = thread->pid;\n\te->target_handle = tr->target.handle;\n\te->data_size = tr->data_size;\n\te->offsets_size = tr->offsets_size;\n\te->context_name = proc->context->name;\n\n\tif (reply) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tin_reply_to = thread->transaction_stack;\n\t\tif (in_reply_to == NULL) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with no transaction stack\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_empty_call_stack;\n\t\t}\n\t\tif (in_reply_to->to_thread != thread) {\n\t\t\tspin_lock(&in_reply_to->lock);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\tproc->pid, thread->pid, in_reply_to->debug_id,\n\t\t\t\tin_reply_to->to_proc ?\n\t\t\t\tin_reply_to->to_proc->pid : 0,\n\t\t\t\tin_reply_to->to_thread ?\n\t\t\t\tin_reply_to->to_thread->pid : 0);\n\t\t\tspin_unlock(&in_reply_to->lock);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\tgoto err_bad_call_stack;\n\t\t}\n\t\tthread->transaction_stack = in_reply_to->to_parent;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_set_nice(in_reply_to->saved_priority);\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(in_reply_to);\n\t\tif (target_thread == NULL) {\n\t\t\t/* annotation for sparse */\n\t\t\t__release(&target_thread->proc->inner_lock);\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\tif (target_thread->transaction_stack != in_reply_to) {\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad target transaction stack %d, expected %d\\n\",\n\t\t\t\tproc->pid, thread->pid,\n\t\t\t\ttarget_thread->transaction_stack ?\n\t\t\t\ttarget_thread->transaction_stack->debug_id : 0,\n\t\t\t\tin_reply_to->debug_id);\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\ttarget_thread = NULL;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\ttarget_proc = target_thread->proc;\n\t\ttarget_proc->tmp_ref++;\n\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t} else {\n\t\tif (tr->target.handle) {\n\t\t\tstruct binder_ref *ref;\n\n\t\t\t/*\n\t\t\t * There must already be a strong ref\n\t\t\t * on this node. If so, do a strong\n\t\t\t * increment on the node to ensure it\n\t\t\t * stays alive until the transaction is\n\t\t\t * done.\n\t\t\t */\n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, tr->target.handle,\n\t\t\t\t\t\t     true);\n\t\t\tif (ref) {\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\tref->node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\t} else {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to invalid handle\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t}\n\t\t\tbinder_proc_unlock(proc);\n\t\t} else {\n\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\ttarget_node = context->binder_context_mgr_node;\n\t\t\tif (target_node)\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\ttarget_node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\telse\n\t\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\tif (target_node && target_proc == proc) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to context manager from process owning it\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_invalid_target_handle;\n\t\t\t}\n\t\t}\n\t\tif (!target_node) {\n\t\t\t/*\n\t\t\t * return_error is set above\n\t\t\t */\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\te->to_node = target_node->debug_id;\n\t\tif (security_binder_transaction(proc->tsk,\n\t\t\t\t\t\ttarget_proc->tsk) < 0) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPERM;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\n\t\tw = list_first_entry_or_null(&thread->todo,\n\t\t\t\t\t     struct binder_work, entry);\n\t\tif (!(tr->flags & TF_ONE_WAY) && w &&\n\t\t    w->type == BINDER_WORK_TRANSACTION) {\n\t\t\t/*\n\t\t\t * Do not allow new outgoing transaction from a\n\t\t\t * thread that has a transaction at the head of\n\t\t\t * its todo list. Only need to check the head\n\t\t\t * because binder_select_thread_ilocked picks a\n\t\t\t * thread from proc->waiting_threads to enqueue\n\t\t\t * the transaction, and nothing is queued to the\n\t\t\t * todo list while the thread is on waiting_threads.\n\t\t\t */\n\t\t\tbinder_user_error(\"%d:%d new transaction not allowed when there is a transaction on thread todo\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_todo_list;\n\t\t}\n\n\t\tif (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {\n\t\t\tstruct binder_transaction *tmp;\n\n\t\t\ttmp = thread->transaction_stack;\n\t\t\tif (tmp->to_thread != thread) {\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tbinder_user_error(\"%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, tmp->debug_id,\n\t\t\t\t\ttmp->to_proc ? tmp->to_proc->pid : 0,\n\t\t\t\t\ttmp->to_thread ?\n\t\t\t\t\ttmp->to_thread->pid : 0);\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EPROTO;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_call_stack;\n\t\t\t}\n\t\t\twhile (tmp) {\n\t\t\t\tstruct binder_thread *from;\n\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tfrom = tmp->from;\n\t\t\t\tif (from && from->proc == target_proc) {\n\t\t\t\t\tatomic_inc(&from->tmp_ref);\n\t\t\t\t\ttarget_thread = from;\n\t\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\ttmp = tmp->from_parent;\n\t\t\t}\n\t\t}\n\t\tbinder_inner_proc_unlock(proc);\n\t}\n\tif (target_thread)\n\t\te->to_thread = target_thread->pid;\n\te->to_proc = target_proc->pid;\n\n\t/* TODO: reuse incoming transaction for reply */\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (t == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_t_failed;\n\t}\n\tINIT_LIST_HEAD(&t->fd_fixups);\n\tbinder_stats_created(BINDER_STAT_TRANSACTION);\n\tspin_lock_init(&t->lock);\n\n\ttcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);\n\tif (tcomplete == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_tcomplete_failed;\n\t}\n\tbinder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);\n\n\tt->debug_id = t_debug_id;\n\n\tif (reply)\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_thread->pid,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\telse\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_node->debug_id,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\n\tif (!reply && !(tr->flags & TF_ONE_WAY))\n\t\tt->from = thread;\n\telse\n\t\tt->from = NULL;\n\tt->sender_euid = task_euid(proc->tsk);\n\tt->to_proc = target_proc;\n\tt->to_thread = target_thread;\n\tt->code = tr->code;\n\tt->flags = tr->flags;\n\tt->priority = task_nice(current);\n\n\tif (target_node && target_node->txn_security_ctx) {\n\t\tu32 secid;\n\t\tsize_t added_size;\n\n\t\tsecurity_task_getsecid(proc->tsk, &secid);\n\t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n\t\tif (ret) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = ret;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_get_secctx_failed;\n\t\t}\n\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));\n\t\textra_buffers_size += added_size;\n\t\tif (extra_buffers_size < added_size) {\n\t\t\t/* integer overflow of extra_buffers_size */\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_extra_size;\n\t\t}\n\t}\n\n\ttrace_binder_transaction(reply, t, target_node);\n\n\tt->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,\n\t\ttr->offsets_size, extra_buffers_size,\n\t\t!reply && (t->flags & TF_ONE_WAY));\n\tif (IS_ERR(t->buffer)) {\n\t\t/*\n\t\t * -ESRCH indicates VMA cleared. The target is dying.\n\t\t */\n\t\treturn_error_param = PTR_ERR(t->buffer);\n\t\treturn_error = return_error_param == -ESRCH ?\n\t\t\tBR_DEAD_REPLY : BR_FAILED_REPLY;\n\t\treturn_error_line = __LINE__;\n\t\tt->buffer = NULL;\n\t\tgoto err_binder_alloc_buf_failed;\n\t}\n\tif (secctx) {\n\t\tint err;\n\t\tsize_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(tr->offsets_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(extra_buffers_size, sizeof(void *)) -\n\t\t\t\t    ALIGN(secctx_sz, sizeof(u64));\n\n\t\tt->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;\n\t\terr = binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  t->buffer, buf_offset,\n\t\t\t\t\t\t  secctx, secctx_sz);\n\t\tif (err) {\n\t\t\tt->security_ctx = 0;\n\t\t\tWARN_ON(1);\n\t\t}\n\t\tsecurity_release_secctx(secctx, secctx_sz);\n\t\tsecctx = NULL;\n\t}\n\tt->buffer->debug_id = t->debug_id;\n\tt->buffer->transaction = t;\n\tt->buffer->target_node = target_node;\n\ttrace_binder_transaction_alloc_buf(t->buffer);\n\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer, 0,\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.buffer,\n\t\t\t\ttr->data_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer,\n\t\t\t\tALIGN(tr->data_size, sizeof(void *)),\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.offsets,\n\t\t\t\ttr->offsets_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets size, %lld\\n\",\n\t\t\t\tproc->pid, thread->pid, (u64)tr->offsets_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\tif (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {\n\t\tbinder_user_error(\"%d:%d got transaction with unaligned buffers size, %lld\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  (u64)extra_buffers_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\toff_start_offset = ALIGN(tr->data_size, sizeof(void *));\n\tbuffer_offset = off_start_offset;\n\toff_end_offset = off_start_offset + tr->offsets_size;\n\tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size;\n\toff_min = 0;\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\n\t\tif (binder_alloc_copy_from_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  &object_offset,\n\t\t\t\t\t\t  t->buffer,\n\t\t\t\t\t\t  buffer_offset,\n\t\t\t\t\t\t  sizeof(object_offset))) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\t\tobject_size = binder_get_object(target_proc, t->buffer,\n\t\t\t\t\t\tobject_offset, &object);\n\t\tif (object_size == 0 || object_offset < off_min) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\\n\",\n\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t  (u64)object_offset,\n\t\t\t\t\t  (u64)off_min,\n\t\t\t\t\t  (u64)t->buffer->data_size);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\n\t\thdr = &object.hdr;\n\t\toff_min = object_offset + object_size;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_binder(fp, t, thread);\n\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_handle(fp, t, thread);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\tstruct binder_fd_object *fp = to_binder_fd_object(hdr);\n\t\t\tbinder_size_t fd_offset = object_offset +\n\t\t\t\t(uintptr_t)&fp->fd - (uintptr_t)fp;\n\t\t\tint ret = binder_translate_fd(fp->fd, fd_offset, t,\n\t\t\t\t\t\t      thread, in_reply_to);\n\n\t\t\tfp->pad_binder = 0;\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t parent_offset;\n\t\t\tstruct binder_fd_array_object *fda =\n\t\t\t\tto_binder_fd_array_object(hdr);\n\t\t\tsize_t num_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tstruct binder_buffer_object *parent =\n\t\t\t\tbinder_validate_ptr(target_proc, t->buffer,\n\t\t\t\t\t\t    &ptr_object, fda->parent,\n\t\t\t\t\t\t    off_start_offset,\n\t\t\t\t\t\t    &parent_offset,\n\t\t\t\t\t\t    num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tif (!binder_validate_fixup(target_proc, t->buffer,\n\t\t\t\t\t\t   off_start_offset,\n\t\t\t\t\t\t   parent_offset,\n\t\t\t\t\t\t   fda->parent_offset,\n\t\t\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t\t\t   last_fixup_min_off)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tret = binder_translate_fd_array(fda, parent, t, thread,\n\t\t\t\t\t\t\tin_reply_to);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = parent_offset;\n\t\t\tlast_fixup_min_off =\n\t\t\t\tfda->parent_offset + sizeof(u32) * fda->num_fds;\n\t\t} break;\n\t\tcase BINDER_TYPE_PTR: {\n\t\t\tstruct binder_buffer_object *bp =\n\t\t\t\tto_binder_buffer_object(hdr);\n\t\t\tsize_t buf_left = sg_buf_end_offset - sg_buf_offset;\n\t\t\tsize_t num_valid;\n\n\t\t\tif (bp->length > buf_left) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with too large buffer\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_offset;\n\t\t\t}\n\t\t\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t\t\t&target_proc->alloc,\n\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\tsg_buf_offset,\n\t\t\t\t\t\t(const void __user *)\n\t\t\t\t\t\t\t(uintptr_t)bp->buffer,\n\t\t\t\t\t\tbp->length)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error_param = -EFAULT;\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_copy_data_failed;\n\t\t\t}\n\t\t\t/* Fixup buffer pointer to target proc address space */\n\t\t\tbp->buffer = (uintptr_t)\n\t\t\t\tt->buffer->user_data + sg_buf_offset;\n\t\t\tsg_buf_offset += ALIGN(bp->length, sizeof(u64));\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tret = binder_fixup_parent(t, thread, bp,\n\t\t\t\t\t\t  off_start_offset,\n\t\t\t\t\t\t  num_valid,\n\t\t\t\t\t\t  last_fixup_obj_off,\n\t\t\t\t\t\t  last_fixup_min_off);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tbp, sizeof(*bp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = object_offset;\n\t\t\tlast_fixup_min_off = 0;\n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid object type, %x\\n\",\n\t\t\t\tproc->pid, thread->pid, hdr->type);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_object_type;\n\t\t}\n\t}\n\ttcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;\n\tt->work.type = BINDER_WORK_TRANSACTION;\n\n\tif (reply) {\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (target_thread->is_dead) {\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_pop_transaction_ilocked(target_thread, in_reply_to);\n\t\tbinder_enqueue_thread_work_ilocked(target_thread, &t->work);\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\twake_up_interruptible_sync(&target_thread->wait);\n\t\tbinder_free_transaction(in_reply_to);\n\t} else if (!(t->flags & TF_ONE_WAY)) {\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_inner_proc_lock(proc);\n\t\t/*\n\t\t * Defer the TRANSACTION_COMPLETE, so we don't return to\n\t\t * userspace immediately; this allows the target process to\n\t\t * immediately start processing this transaction, reducing\n\t\t * latency. We will then return the TRANSACTION_COMPLETE when\n\t\t * the target replies (or there is an error).\n\t\t */\n\t\tbinder_enqueue_deferred_thread_work_ilocked(thread, tcomplete);\n\t\tt->need_reply = 1;\n\t\tt->from_parent = thread->transaction_stack;\n\t\tthread->transaction_stack = t;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (!binder_proc_transaction(t, target_proc, target_thread)) {\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tbinder_pop_transaction_ilocked(thread, t);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t} else {\n\t\tBUG_ON(target_node == NULL);\n\t\tBUG_ON(t->buffer->async_transaction != 1);\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tif (!binder_proc_transaction(t, target_proc, NULL))\n\t\t\tgoto err_dead_proc_or_thread;\n\t}\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\t/*\n\t * write barrier to synchronize with initialization\n\t * of log entry\n\t */\n\tsmp_wmb();\n\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\treturn;\n\nerr_dead_proc_or_thread:\n\treturn_error = BR_DEAD_REPLY;\n\treturn_error_line = __LINE__;\n\tbinder_dequeue_work(proc, tcomplete);\nerr_translate_failed:\nerr_bad_object_type:\nerr_bad_offset:\nerr_bad_parent:\nerr_copy_data_failed:\n\tbinder_free_txn_fixups(t);\n\ttrace_binder_transaction_failed_buffer_release(t->buffer);\n\tbinder_transaction_buffer_release(target_proc, t->buffer,\n\t\t\t\t\t  buffer_offset, true);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\ttarget_node = NULL;\n\tt->buffer->transaction = NULL;\n\tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\nerr_binder_alloc_buf_failed:\nerr_bad_extra_size:\n\tif (secctx)\n\t\tsecurity_release_secctx(secctx, secctx_sz);\nerr_get_secctx_failed:\n\tkfree(tcomplete);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\nerr_alloc_tcomplete_failed:\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\nerr_alloc_t_failed:\nerr_bad_todo_list:\nerr_bad_call_stack:\nerr_empty_call_stack:\nerr_dead_binder:\nerr_invalid_target_handle:\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tif (target_proc)\n\t\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node) {\n\t\tbinder_dec_node(target_node, 1, 0);\n\t\tbinder_dec_node_tmpref(target_node);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t     \"%d:%d transaction failed %d/%d, size %lld-%lld line %d\\n\",\n\t\t     proc->pid, thread->pid, return_error, return_error_param,\n\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t     return_error_line);\n\n\t{\n\t\tstruct binder_transaction_log_entry *fe;\n\n\t\te->return_error = return_error;\n\t\te->return_error_param = return_error_param;\n\t\te->return_error_line = return_error_line;\n\t\tfe = binder_transaction_log_add(&binder_transaction_log_failed);\n\t\t*fe = *e;\n\t\t/*\n\t\t * write barrier to synchronize with initialization\n\t\t * of log entry\n\t\t */\n\t\tsmp_wmb();\n\t\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\t\tWRITE_ONCE(fe->debug_id_done, t_debug_id);\n\t}\n\n\tBUG_ON(thread->return_error.cmd != BR_OK);\n\tif (in_reply_to) {\n\t\tthread->return_error.cmd = BR_TRANSACTION_COMPLETE;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t\tbinder_send_failed_reply(in_reply_to, return_error);\n\t} else {\n\t\tthread->return_error.cmd = return_error;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t}\n}",
        "code_after_change": "static void binder_transaction(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction_data *tr, int reply,\n\t\t\t       binder_size_t extra_buffers_size)\n{\n\tint ret;\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tstruct binder_work *tcomplete;\n\tbinder_size_t buffer_offset = 0;\n\tbinder_size_t off_start_offset, off_end_offset;\n\tbinder_size_t off_min;\n\tbinder_size_t sg_buf_offset, sg_buf_end_offset;\n\tstruct binder_proc *target_proc = NULL;\n\tstruct binder_thread *target_thread = NULL;\n\tstruct binder_node *target_node = NULL;\n\tstruct binder_transaction *in_reply_to = NULL;\n\tstruct binder_transaction_log_entry *e;\n\tuint32_t return_error = 0;\n\tuint32_t return_error_param = 0;\n\tuint32_t return_error_line = 0;\n\tbinder_size_t last_fixup_obj_off = 0;\n\tbinder_size_t last_fixup_min_off = 0;\n\tstruct binder_context *context = proc->context;\n\tint t_debug_id = atomic_inc_return(&binder_last_id);\n\tchar *secctx = NULL;\n\tu32 secctx_sz = 0;\n\n\te = binder_transaction_log_add(&binder_transaction_log);\n\te->debug_id = t_debug_id;\n\te->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);\n\te->from_proc = proc->pid;\n\te->from_thread = thread->pid;\n\te->target_handle = tr->target.handle;\n\te->data_size = tr->data_size;\n\te->offsets_size = tr->offsets_size;\n\te->context_name = proc->context->name;\n\n\tif (reply) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tin_reply_to = thread->transaction_stack;\n\t\tif (in_reply_to == NULL) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with no transaction stack\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_empty_call_stack;\n\t\t}\n\t\tif (in_reply_to->to_thread != thread) {\n\t\t\tspin_lock(&in_reply_to->lock);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\tproc->pid, thread->pid, in_reply_to->debug_id,\n\t\t\t\tin_reply_to->to_proc ?\n\t\t\t\tin_reply_to->to_proc->pid : 0,\n\t\t\t\tin_reply_to->to_thread ?\n\t\t\t\tin_reply_to->to_thread->pid : 0);\n\t\t\tspin_unlock(&in_reply_to->lock);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\tgoto err_bad_call_stack;\n\t\t}\n\t\tthread->transaction_stack = in_reply_to->to_parent;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_set_nice(in_reply_to->saved_priority);\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(in_reply_to);\n\t\tif (target_thread == NULL) {\n\t\t\t/* annotation for sparse */\n\t\t\t__release(&target_thread->proc->inner_lock);\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\tif (target_thread->transaction_stack != in_reply_to) {\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad target transaction stack %d, expected %d\\n\",\n\t\t\t\tproc->pid, thread->pid,\n\t\t\t\ttarget_thread->transaction_stack ?\n\t\t\t\ttarget_thread->transaction_stack->debug_id : 0,\n\t\t\t\tin_reply_to->debug_id);\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\ttarget_thread = NULL;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\ttarget_proc = target_thread->proc;\n\t\ttarget_proc->tmp_ref++;\n\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t} else {\n\t\tif (tr->target.handle) {\n\t\t\tstruct binder_ref *ref;\n\n\t\t\t/*\n\t\t\t * There must already be a strong ref\n\t\t\t * on this node. If so, do a strong\n\t\t\t * increment on the node to ensure it\n\t\t\t * stays alive until the transaction is\n\t\t\t * done.\n\t\t\t */\n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, tr->target.handle,\n\t\t\t\t\t\t     true);\n\t\t\tif (ref) {\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\tref->node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\t} else {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to invalid handle\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t}\n\t\t\tbinder_proc_unlock(proc);\n\t\t} else {\n\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\ttarget_node = context->binder_context_mgr_node;\n\t\t\tif (target_node)\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\ttarget_node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\telse\n\t\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\tif (target_node && target_proc == proc) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to context manager from process owning it\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_invalid_target_handle;\n\t\t\t}\n\t\t}\n\t\tif (!target_node) {\n\t\t\t/*\n\t\t\t * return_error is set above\n\t\t\t */\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\te->to_node = target_node->debug_id;\n\t\tif (security_binder_transaction(proc->tsk,\n\t\t\t\t\t\ttarget_proc->tsk) < 0) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPERM;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\n\t\tw = list_first_entry_or_null(&thread->todo,\n\t\t\t\t\t     struct binder_work, entry);\n\t\tif (!(tr->flags & TF_ONE_WAY) && w &&\n\t\t    w->type == BINDER_WORK_TRANSACTION) {\n\t\t\t/*\n\t\t\t * Do not allow new outgoing transaction from a\n\t\t\t * thread that has a transaction at the head of\n\t\t\t * its todo list. Only need to check the head\n\t\t\t * because binder_select_thread_ilocked picks a\n\t\t\t * thread from proc->waiting_threads to enqueue\n\t\t\t * the transaction, and nothing is queued to the\n\t\t\t * todo list while the thread is on waiting_threads.\n\t\t\t */\n\t\t\tbinder_user_error(\"%d:%d new transaction not allowed when there is a transaction on thread todo\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_todo_list;\n\t\t}\n\n\t\tif (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {\n\t\t\tstruct binder_transaction *tmp;\n\n\t\t\ttmp = thread->transaction_stack;\n\t\t\tif (tmp->to_thread != thread) {\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tbinder_user_error(\"%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, tmp->debug_id,\n\t\t\t\t\ttmp->to_proc ? tmp->to_proc->pid : 0,\n\t\t\t\t\ttmp->to_thread ?\n\t\t\t\t\ttmp->to_thread->pid : 0);\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EPROTO;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_call_stack;\n\t\t\t}\n\t\t\twhile (tmp) {\n\t\t\t\tstruct binder_thread *from;\n\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tfrom = tmp->from;\n\t\t\t\tif (from && from->proc == target_proc) {\n\t\t\t\t\tatomic_inc(&from->tmp_ref);\n\t\t\t\t\ttarget_thread = from;\n\t\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\ttmp = tmp->from_parent;\n\t\t\t}\n\t\t}\n\t\tbinder_inner_proc_unlock(proc);\n\t}\n\tif (target_thread)\n\t\te->to_thread = target_thread->pid;\n\te->to_proc = target_proc->pid;\n\n\t/* TODO: reuse incoming transaction for reply */\n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (t == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_t_failed;\n\t}\n\tINIT_LIST_HEAD(&t->fd_fixups);\n\tbinder_stats_created(BINDER_STAT_TRANSACTION);\n\tspin_lock_init(&t->lock);\n\n\ttcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);\n\tif (tcomplete == NULL) {\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_tcomplete_failed;\n\t}\n\tbinder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);\n\n\tt->debug_id = t_debug_id;\n\n\tif (reply)\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_thread->pid,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\telse\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_node->debug_id,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\n\tif (!reply && !(tr->flags & TF_ONE_WAY))\n\t\tt->from = thread;\n\telse\n\t\tt->from = NULL;\n\tt->sender_euid = task_euid(proc->tsk);\n\tt->to_proc = target_proc;\n\tt->to_thread = target_thread;\n\tt->code = tr->code;\n\tt->flags = tr->flags;\n\tt->priority = task_nice(current);\n\n\tif (target_node && target_node->txn_security_ctx) {\n\t\tu32 secid;\n\t\tsize_t added_size;\n\n\t\tsecurity_task_getsecid(proc->tsk, &secid);\n\t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n\t\tif (ret) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = ret;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_get_secctx_failed;\n\t\t}\n\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));\n\t\textra_buffers_size += added_size;\n\t\tif (extra_buffers_size < added_size) {\n\t\t\t/* integer overflow of extra_buffers_size */\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_extra_size;\n\t\t}\n\t}\n\n\ttrace_binder_transaction(reply, t, target_node);\n\n\tt->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,\n\t\ttr->offsets_size, extra_buffers_size,\n\t\t!reply && (t->flags & TF_ONE_WAY));\n\tif (IS_ERR(t->buffer)) {\n\t\t/*\n\t\t * -ESRCH indicates VMA cleared. The target is dying.\n\t\t */\n\t\treturn_error_param = PTR_ERR(t->buffer);\n\t\treturn_error = return_error_param == -ESRCH ?\n\t\t\tBR_DEAD_REPLY : BR_FAILED_REPLY;\n\t\treturn_error_line = __LINE__;\n\t\tt->buffer = NULL;\n\t\tgoto err_binder_alloc_buf_failed;\n\t}\n\tif (secctx) {\n\t\tint err;\n\t\tsize_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(tr->offsets_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(extra_buffers_size, sizeof(void *)) -\n\t\t\t\t    ALIGN(secctx_sz, sizeof(u64));\n\n\t\tt->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;\n\t\terr = binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  t->buffer, buf_offset,\n\t\t\t\t\t\t  secctx, secctx_sz);\n\t\tif (err) {\n\t\t\tt->security_ctx = 0;\n\t\t\tWARN_ON(1);\n\t\t}\n\t\tsecurity_release_secctx(secctx, secctx_sz);\n\t\tsecctx = NULL;\n\t}\n\tt->buffer->debug_id = t->debug_id;\n\tt->buffer->transaction = t;\n\tt->buffer->target_node = target_node;\n\ttrace_binder_transaction_alloc_buf(t->buffer);\n\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer, 0,\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.buffer,\n\t\t\t\ttr->data_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer,\n\t\t\t\tALIGN(tr->data_size, sizeof(void *)),\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.offsets,\n\t\t\t\ttr->offsets_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets size, %lld\\n\",\n\t\t\t\tproc->pid, thread->pid, (u64)tr->offsets_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\tif (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {\n\t\tbinder_user_error(\"%d:%d got transaction with unaligned buffers size, %lld\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  (u64)extra_buffers_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\toff_start_offset = ALIGN(tr->data_size, sizeof(void *));\n\tbuffer_offset = off_start_offset;\n\toff_end_offset = off_start_offset + tr->offsets_size;\n\tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size -\n\t\tALIGN(secctx_sz, sizeof(u64));\n\toff_min = 0;\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\n\t\tif (binder_alloc_copy_from_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  &object_offset,\n\t\t\t\t\t\t  t->buffer,\n\t\t\t\t\t\t  buffer_offset,\n\t\t\t\t\t\t  sizeof(object_offset))) {\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\t\tobject_size = binder_get_object(target_proc, t->buffer,\n\t\t\t\t\t\tobject_offset, &object);\n\t\tif (object_size == 0 || object_offset < off_min) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\\n\",\n\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t  (u64)object_offset,\n\t\t\t\t\t  (u64)off_min,\n\t\t\t\t\t  (u64)t->buffer->data_size);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\n\t\thdr = &object.hdr;\n\t\toff_min = object_offset + object_size;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_binder(fp, t, thread);\n\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_handle(fp, t, thread);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\tstruct binder_fd_object *fp = to_binder_fd_object(hdr);\n\t\t\tbinder_size_t fd_offset = object_offset +\n\t\t\t\t(uintptr_t)&fp->fd - (uintptr_t)fp;\n\t\t\tint ret = binder_translate_fd(fp->fd, fd_offset, t,\n\t\t\t\t\t\t      thread, in_reply_to);\n\n\t\t\tfp->pad_binder = 0;\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t parent_offset;\n\t\t\tstruct binder_fd_array_object *fda =\n\t\t\t\tto_binder_fd_array_object(hdr);\n\t\t\tsize_t num_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tstruct binder_buffer_object *parent =\n\t\t\t\tbinder_validate_ptr(target_proc, t->buffer,\n\t\t\t\t\t\t    &ptr_object, fda->parent,\n\t\t\t\t\t\t    off_start_offset,\n\t\t\t\t\t\t    &parent_offset,\n\t\t\t\t\t\t    num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tif (!binder_validate_fixup(target_proc, t->buffer,\n\t\t\t\t\t\t   off_start_offset,\n\t\t\t\t\t\t   parent_offset,\n\t\t\t\t\t\t   fda->parent_offset,\n\t\t\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t\t\t   last_fixup_min_off)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tret = binder_translate_fd_array(fda, parent, t, thread,\n\t\t\t\t\t\t\tin_reply_to);\n\t\t\tif (ret < 0) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = parent_offset;\n\t\t\tlast_fixup_min_off =\n\t\t\t\tfda->parent_offset + sizeof(u32) * fda->num_fds;\n\t\t} break;\n\t\tcase BINDER_TYPE_PTR: {\n\t\t\tstruct binder_buffer_object *bp =\n\t\t\t\tto_binder_buffer_object(hdr);\n\t\t\tsize_t buf_left = sg_buf_end_offset - sg_buf_offset;\n\t\t\tsize_t num_valid;\n\n\t\t\tif (bp->length > buf_left) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with too large buffer\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_offset;\n\t\t\t}\n\t\t\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t\t\t&target_proc->alloc,\n\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\tsg_buf_offset,\n\t\t\t\t\t\t(const void __user *)\n\t\t\t\t\t\t\t(uintptr_t)bp->buffer,\n\t\t\t\t\t\tbp->length)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error_param = -EFAULT;\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_copy_data_failed;\n\t\t\t}\n\t\t\t/* Fixup buffer pointer to target proc address space */\n\t\t\tbp->buffer = (uintptr_t)\n\t\t\t\tt->buffer->user_data + sg_buf_offset;\n\t\t\tsg_buf_offset += ALIGN(bp->length, sizeof(u64));\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) *\n\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tret = binder_fixup_parent(t, thread, bp,\n\t\t\t\t\t\t  off_start_offset,\n\t\t\t\t\t\t  num_valid,\n\t\t\t\t\t\t  last_fixup_obj_off,\n\t\t\t\t\t\t  last_fixup_min_off);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tbp, sizeof(*bp))) {\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = object_offset;\n\t\t\tlast_fixup_min_off = 0;\n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid object type, %x\\n\",\n\t\t\t\tproc->pid, thread->pid, hdr->type);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_object_type;\n\t\t}\n\t}\n\ttcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;\n\tt->work.type = BINDER_WORK_TRANSACTION;\n\n\tif (reply) {\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (target_thread->is_dead) {\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_pop_transaction_ilocked(target_thread, in_reply_to);\n\t\tbinder_enqueue_thread_work_ilocked(target_thread, &t->work);\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\twake_up_interruptible_sync(&target_thread->wait);\n\t\tbinder_free_transaction(in_reply_to);\n\t} else if (!(t->flags & TF_ONE_WAY)) {\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_inner_proc_lock(proc);\n\t\t/*\n\t\t * Defer the TRANSACTION_COMPLETE, so we don't return to\n\t\t * userspace immediately; this allows the target process to\n\t\t * immediately start processing this transaction, reducing\n\t\t * latency. We will then return the TRANSACTION_COMPLETE when\n\t\t * the target replies (or there is an error).\n\t\t */\n\t\tbinder_enqueue_deferred_thread_work_ilocked(thread, tcomplete);\n\t\tt->need_reply = 1;\n\t\tt->from_parent = thread->transaction_stack;\n\t\tthread->transaction_stack = t;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (!binder_proc_transaction(t, target_proc, target_thread)) {\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tbinder_pop_transaction_ilocked(thread, t);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t} else {\n\t\tBUG_ON(target_node == NULL);\n\t\tBUG_ON(t->buffer->async_transaction != 1);\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tif (!binder_proc_transaction(t, target_proc, NULL))\n\t\t\tgoto err_dead_proc_or_thread;\n\t}\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\t/*\n\t * write barrier to synchronize with initialization\n\t * of log entry\n\t */\n\tsmp_wmb();\n\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\treturn;\n\nerr_dead_proc_or_thread:\n\treturn_error = BR_DEAD_REPLY;\n\treturn_error_line = __LINE__;\n\tbinder_dequeue_work(proc, tcomplete);\nerr_translate_failed:\nerr_bad_object_type:\nerr_bad_offset:\nerr_bad_parent:\nerr_copy_data_failed:\n\tbinder_free_txn_fixups(t);\n\ttrace_binder_transaction_failed_buffer_release(t->buffer);\n\tbinder_transaction_buffer_release(target_proc, t->buffer,\n\t\t\t\t\t  buffer_offset, true);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\ttarget_node = NULL;\n\tt->buffer->transaction = NULL;\n\tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\nerr_binder_alloc_buf_failed:\nerr_bad_extra_size:\n\tif (secctx)\n\t\tsecurity_release_secctx(secctx, secctx_sz);\nerr_get_secctx_failed:\n\tkfree(tcomplete);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\nerr_alloc_tcomplete_failed:\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\nerr_alloc_t_failed:\nerr_bad_todo_list:\nerr_bad_call_stack:\nerr_empty_call_stack:\nerr_dead_binder:\nerr_invalid_target_handle:\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tif (target_proc)\n\t\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node) {\n\t\tbinder_dec_node(target_node, 1, 0);\n\t\tbinder_dec_node_tmpref(target_node);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t     \"%d:%d transaction failed %d/%d, size %lld-%lld line %d\\n\",\n\t\t     proc->pid, thread->pid, return_error, return_error_param,\n\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t     return_error_line);\n\n\t{\n\t\tstruct binder_transaction_log_entry *fe;\n\n\t\te->return_error = return_error;\n\t\te->return_error_param = return_error_param;\n\t\te->return_error_line = return_error_line;\n\t\tfe = binder_transaction_log_add(&binder_transaction_log_failed);\n\t\t*fe = *e;\n\t\t/*\n\t\t * write barrier to synchronize with initialization\n\t\t * of log entry\n\t\t */\n\t\tsmp_wmb();\n\t\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\t\tWRITE_ONCE(fe->debug_id_done, t_debug_id);\n\t}\n\n\tBUG_ON(thread->return_error.cmd != BR_OK);\n\tif (in_reply_to) {\n\t\tthread->return_error.cmd = BR_TRANSACTION_COMPLETE;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t\tbinder_send_failed_reply(in_reply_to, return_error);\n\t} else {\n\t\tthread->return_error.cmd = return_error;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -377,7 +377,8 @@\n \tbuffer_offset = off_start_offset;\n \toff_end_offset = off_start_offset + tr->offsets_size;\n \tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n-\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size;\n+\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size -\n+\t\tALIGN(secctx_sz, sizeof(u64));\n \toff_min = 0;\n \tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n \t     buffer_offset += sizeof(binder_size_t)) {",
        "function_modified_lines": {
            "added": [
                "\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size -",
                "\t\tALIGN(secctx_sz, sizeof(u64));"
            ],
            "deleted": [
                "\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In binder_transaction of binder.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-136210786References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2019-3701",
        "code_before_change": "static void can_can_gw_rcv(struct sk_buff *skb, void *data)\n{\n\tstruct cgw_job *gwj = (struct cgw_job *)data;\n\tstruct can_frame *cf;\n\tstruct sk_buff *nskb;\n\tint modidx = 0;\n\n\t/*\n\t * Do not handle CAN frames routed more than 'max_hops' times.\n\t * In general we should never catch this delimiter which is intended\n\t * to cover a misconfiguration protection (e.g. circular CAN routes).\n\t *\n\t * The Controller Area Network controllers only accept CAN frames with\n\t * correct CRCs - which are not visible in the controller registers.\n\t * According to skbuff.h documentation the csum_start element for IP\n\t * checksums is undefined/unused when ip_summed == CHECKSUM_UNNECESSARY.\n\t * Only CAN skbs can be processed here which already have this property.\n\t */\n\n#define cgw_hops(skb) ((skb)->csum_start)\n\n\tBUG_ON(skb->ip_summed != CHECKSUM_UNNECESSARY);\n\n\tif (cgw_hops(skb) >= max_hops) {\n\t\t/* indicate deleted frames due to misconfiguration */\n\t\tgwj->deleted_frames++;\n\t\treturn;\n\t}\n\n\tif (!(gwj->dst.dev->flags & IFF_UP)) {\n\t\tgwj->dropped_frames++;\n\t\treturn;\n\t}\n\n\t/* is sending the skb back to the incoming interface not allowed? */\n\tif (!(gwj->flags & CGW_FLAGS_CAN_IIF_TX_OK) &&\n\t    can_skb_prv(skb)->ifindex == gwj->dst.dev->ifindex)\n\t\treturn;\n\n\t/*\n\t * clone the given skb, which has not been done in can_rcv()\n\t *\n\t * When there is at least one modification function activated,\n\t * we need to copy the skb as we want to modify skb->data.\n\t */\n\tif (gwj->mod.modfunc[0])\n\t\tnskb = skb_copy(skb, GFP_ATOMIC);\n\telse\n\t\tnskb = skb_clone(skb, GFP_ATOMIC);\n\n\tif (!nskb) {\n\t\tgwj->dropped_frames++;\n\t\treturn;\n\t}\n\n\t/* put the incremented hop counter in the cloned skb */\n\tcgw_hops(nskb) = cgw_hops(skb) + 1;\n\n\t/* first processing of this CAN frame -> adjust to private hop limit */\n\tif (gwj->limit_hops && cgw_hops(nskb) == 1)\n\t\tcgw_hops(nskb) = max_hops - gwj->limit_hops + 1;\n\n\tnskb->dev = gwj->dst.dev;\n\n\t/* pointer to modifiable CAN frame */\n\tcf = (struct can_frame *)nskb->data;\n\n\t/* perform preprocessed modification functions if there are any */\n\twhile (modidx < MAX_MODFUNCTIONS && gwj->mod.modfunc[modidx])\n\t\t(*gwj->mod.modfunc[modidx++])(cf, &gwj->mod);\n\n\t/* check for checksum updates when the CAN frame has been modified */\n\tif (modidx) {\n\t\tif (gwj->mod.csumfunc.crc8)\n\t\t\t(*gwj->mod.csumfunc.crc8)(cf, &gwj->mod.csum.crc8);\n\n\t\tif (gwj->mod.csumfunc.xor)\n\t\t\t(*gwj->mod.csumfunc.xor)(cf, &gwj->mod.csum.xor);\n\t}\n\n\t/* clear the skb timestamp if not configured the other way */\n\tif (!(gwj->flags & CGW_FLAGS_CAN_SRC_TSTAMP))\n\t\tnskb->tstamp = 0;\n\n\t/* send to netdevice */\n\tif (can_send(nskb, gwj->flags & CGW_FLAGS_CAN_ECHO))\n\t\tgwj->dropped_frames++;\n\telse\n\t\tgwj->handled_frames++;\n}",
        "code_after_change": "static void can_can_gw_rcv(struct sk_buff *skb, void *data)\n{\n\tstruct cgw_job *gwj = (struct cgw_job *)data;\n\tstruct can_frame *cf;\n\tstruct sk_buff *nskb;\n\tint modidx = 0;\n\n\t/*\n\t * Do not handle CAN frames routed more than 'max_hops' times.\n\t * In general we should never catch this delimiter which is intended\n\t * to cover a misconfiguration protection (e.g. circular CAN routes).\n\t *\n\t * The Controller Area Network controllers only accept CAN frames with\n\t * correct CRCs - which are not visible in the controller registers.\n\t * According to skbuff.h documentation the csum_start element for IP\n\t * checksums is undefined/unused when ip_summed == CHECKSUM_UNNECESSARY.\n\t * Only CAN skbs can be processed here which already have this property.\n\t */\n\n#define cgw_hops(skb) ((skb)->csum_start)\n\n\tBUG_ON(skb->ip_summed != CHECKSUM_UNNECESSARY);\n\n\tif (cgw_hops(skb) >= max_hops) {\n\t\t/* indicate deleted frames due to misconfiguration */\n\t\tgwj->deleted_frames++;\n\t\treturn;\n\t}\n\n\tif (!(gwj->dst.dev->flags & IFF_UP)) {\n\t\tgwj->dropped_frames++;\n\t\treturn;\n\t}\n\n\t/* is sending the skb back to the incoming interface not allowed? */\n\tif (!(gwj->flags & CGW_FLAGS_CAN_IIF_TX_OK) &&\n\t    can_skb_prv(skb)->ifindex == gwj->dst.dev->ifindex)\n\t\treturn;\n\n\t/*\n\t * clone the given skb, which has not been done in can_rcv()\n\t *\n\t * When there is at least one modification function activated,\n\t * we need to copy the skb as we want to modify skb->data.\n\t */\n\tif (gwj->mod.modfunc[0])\n\t\tnskb = skb_copy(skb, GFP_ATOMIC);\n\telse\n\t\tnskb = skb_clone(skb, GFP_ATOMIC);\n\n\tif (!nskb) {\n\t\tgwj->dropped_frames++;\n\t\treturn;\n\t}\n\n\t/* put the incremented hop counter in the cloned skb */\n\tcgw_hops(nskb) = cgw_hops(skb) + 1;\n\n\t/* first processing of this CAN frame -> adjust to private hop limit */\n\tif (gwj->limit_hops && cgw_hops(nskb) == 1)\n\t\tcgw_hops(nskb) = max_hops - gwj->limit_hops + 1;\n\n\tnskb->dev = gwj->dst.dev;\n\n\t/* pointer to modifiable CAN frame */\n\tcf = (struct can_frame *)nskb->data;\n\n\t/* perform preprocessed modification functions if there are any */\n\twhile (modidx < MAX_MODFUNCTIONS && gwj->mod.modfunc[modidx])\n\t\t(*gwj->mod.modfunc[modidx++])(cf, &gwj->mod);\n\n\t/* Has the CAN frame been modified? */\n\tif (modidx) {\n\t\t/* get available space for the processed CAN frame type */\n\t\tint max_len = nskb->len - offsetof(struct can_frame, data);\n\n\t\t/* dlc may have changed, make sure it fits to the CAN frame */\n\t\tif (cf->can_dlc > max_len)\n\t\t\tgoto out_delete;\n\n\t\t/* check for checksum updates in classic CAN length only */\n\t\tif (gwj->mod.csumfunc.crc8) {\n\t\t\tif (cf->can_dlc > 8)\n\t\t\t\tgoto out_delete;\n\n\t\t\t(*gwj->mod.csumfunc.crc8)(cf, &gwj->mod.csum.crc8);\n\t\t}\n\n\t\tif (gwj->mod.csumfunc.xor) {\n\t\t\tif (cf->can_dlc > 8)\n\t\t\t\tgoto out_delete;\n\n\t\t\t(*gwj->mod.csumfunc.xor)(cf, &gwj->mod.csum.xor);\n\t\t}\n\t}\n\n\t/* clear the skb timestamp if not configured the other way */\n\tif (!(gwj->flags & CGW_FLAGS_CAN_SRC_TSTAMP))\n\t\tnskb->tstamp = 0;\n\n\t/* send to netdevice */\n\tif (can_send(nskb, gwj->flags & CGW_FLAGS_CAN_ECHO))\n\t\tgwj->dropped_frames++;\n\telse\n\t\tgwj->handled_frames++;\n\n\treturn;\n\n out_delete:\n\t/* delete frame due to misconfiguration */\n\tgwj->deleted_frames++;\n\tkfree_skb(nskb);\n\treturn;\n}",
        "patch": "--- code before\n+++ code after\n@@ -69,13 +69,29 @@\n \twhile (modidx < MAX_MODFUNCTIONS && gwj->mod.modfunc[modidx])\n \t\t(*gwj->mod.modfunc[modidx++])(cf, &gwj->mod);\n \n-\t/* check for checksum updates when the CAN frame has been modified */\n+\t/* Has the CAN frame been modified? */\n \tif (modidx) {\n-\t\tif (gwj->mod.csumfunc.crc8)\n+\t\t/* get available space for the processed CAN frame type */\n+\t\tint max_len = nskb->len - offsetof(struct can_frame, data);\n+\n+\t\t/* dlc may have changed, make sure it fits to the CAN frame */\n+\t\tif (cf->can_dlc > max_len)\n+\t\t\tgoto out_delete;\n+\n+\t\t/* check for checksum updates in classic CAN length only */\n+\t\tif (gwj->mod.csumfunc.crc8) {\n+\t\t\tif (cf->can_dlc > 8)\n+\t\t\t\tgoto out_delete;\n+\n \t\t\t(*gwj->mod.csumfunc.crc8)(cf, &gwj->mod.csum.crc8);\n+\t\t}\n \n-\t\tif (gwj->mod.csumfunc.xor)\n+\t\tif (gwj->mod.csumfunc.xor) {\n+\t\t\tif (cf->can_dlc > 8)\n+\t\t\t\tgoto out_delete;\n+\n \t\t\t(*gwj->mod.csumfunc.xor)(cf, &gwj->mod.csum.xor);\n+\t\t}\n \t}\n \n \t/* clear the skb timestamp if not configured the other way */\n@@ -87,4 +103,12 @@\n \t\tgwj->dropped_frames++;\n \telse\n \t\tgwj->handled_frames++;\n+\n+\treturn;\n+\n+ out_delete:\n+\t/* delete frame due to misconfiguration */\n+\tgwj->deleted_frames++;\n+\tkfree_skb(nskb);\n+\treturn;\n }",
        "function_modified_lines": {
            "added": [
                "\t/* Has the CAN frame been modified? */",
                "\t\t/* get available space for the processed CAN frame type */",
                "\t\tint max_len = nskb->len - offsetof(struct can_frame, data);",
                "",
                "\t\t/* dlc may have changed, make sure it fits to the CAN frame */",
                "\t\tif (cf->can_dlc > max_len)",
                "\t\t\tgoto out_delete;",
                "",
                "\t\t/* check for checksum updates in classic CAN length only */",
                "\t\tif (gwj->mod.csumfunc.crc8) {",
                "\t\t\tif (cf->can_dlc > 8)",
                "\t\t\t\tgoto out_delete;",
                "",
                "\t\t}",
                "\t\tif (gwj->mod.csumfunc.xor) {",
                "\t\t\tif (cf->can_dlc > 8)",
                "\t\t\t\tgoto out_delete;",
                "",
                "\t\t}",
                "",
                "\treturn;",
                "",
                " out_delete:",
                "\t/* delete frame due to misconfiguration */",
                "\tgwj->deleted_frames++;",
                "\tkfree_skb(nskb);",
                "\treturn;"
            ],
            "deleted": [
                "\t/* check for checksum updates when the CAN frame has been modified */",
                "\t\tif (gwj->mod.csumfunc.crc8)",
                "\t\tif (gwj->mod.csumfunc.xor)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in can_can_gw_rcv in net/can/gw.c in the Linux kernel through 4.19.13. The CAN frame modification rules allow bitwise logical operations that can be also applied to the can_dlc field. The privileged user \"root\" with CAP_NET_ADMIN can create a CAN frame modification rule that makes the data length code a higher value than the available CAN frame data size. In combination with a configured checksum calculation where the result is stored relatively to the end of the data (e.g. cgw_csum_xor_rel) the tail of the skb (e.g. frag_list pointer in skb_shared_info) can be rewritten which finally can cause a system crash. Because of a missing check, the CAN drivers may write arbitrary content beyond the data registers in the CAN controller's I/O memory when processing can-gw manipulated outgoing frames."
    },
    {
        "cve_id": "CVE-2019-8956",
        "code_before_change": "static int sctp_sendmsg(struct sock *sk, struct msghdr *msg, size_t msg_len)\n{\n\tstruct sctp_endpoint *ep = sctp_sk(sk)->ep;\n\tstruct sctp_transport *transport = NULL;\n\tstruct sctp_sndrcvinfo _sinfo, *sinfo;\n\tstruct sctp_association *asoc;\n\tstruct sctp_cmsgs cmsgs;\n\tunion sctp_addr *daddr;\n\tbool new = false;\n\t__u16 sflags;\n\tint err;\n\n\t/* Parse and get snd_info */\n\terr = sctp_sendmsg_parse(sk, &cmsgs, &_sinfo, msg, msg_len);\n\tif (err)\n\t\tgoto out;\n\n\tsinfo  = &_sinfo;\n\tsflags = sinfo->sinfo_flags;\n\n\t/* Get daddr from msg */\n\tdaddr = sctp_sendmsg_get_daddr(sk, msg, &cmsgs);\n\tif (IS_ERR(daddr)) {\n\t\terr = PTR_ERR(daddr);\n\t\tgoto out;\n\t}\n\n\tlock_sock(sk);\n\n\t/* SCTP_SENDALL process */\n\tif ((sflags & SCTP_SENDALL) && sctp_style(sk, UDP)) {\n\t\tlist_for_each_entry(asoc, &ep->asocs, asocs) {\n\t\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg,\n\t\t\t\t\t\t\tmsg_len);\n\t\t\tif (err == 0)\n\t\t\t\tcontinue;\n\t\t\tif (err < 0)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tsctp_sendmsg_update_sinfo(asoc, sinfo, &cmsgs);\n\n\t\t\terr = sctp_sendmsg_to_asoc(asoc, msg, msg_len,\n\t\t\t\t\t\t   NULL, sinfo);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tiov_iter_revert(&msg->msg_iter, err);\n\t\t}\n\n\t\tgoto out_unlock;\n\t}\n\n\t/* Get and check or create asoc */\n\tif (daddr) {\n\t\tasoc = sctp_endpoint_lookup_assoc(ep, daddr, &transport);\n\t\tif (asoc) {\n\t\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg,\n\t\t\t\t\t\t\tmsg_len);\n\t\t\tif (err <= 0)\n\t\t\t\tgoto out_unlock;\n\t\t} else {\n\t\t\terr = sctp_sendmsg_new_asoc(sk, sflags, &cmsgs, daddr,\n\t\t\t\t\t\t    &transport);\n\t\t\tif (err)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tasoc = transport->asoc;\n\t\t\tnew = true;\n\t\t}\n\n\t\tif (!sctp_style(sk, TCP) && !(sflags & SCTP_ADDR_OVER))\n\t\t\ttransport = NULL;\n\t} else {\n\t\tasoc = sctp_id2assoc(sk, sinfo->sinfo_assoc_id);\n\t\tif (!asoc) {\n\t\t\terr = -EPIPE;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg, msg_len);\n\t\tif (err <= 0)\n\t\t\tgoto out_unlock;\n\t}\n\n\t/* Update snd_info with the asoc */\n\tsctp_sendmsg_update_sinfo(asoc, sinfo, &cmsgs);\n\n\t/* Send msg to the asoc */\n\terr = sctp_sendmsg_to_asoc(asoc, msg, msg_len, transport, sinfo);\n\tif (err < 0 && err != -ESRCH && new)\n\t\tsctp_association_free(asoc);\n\nout_unlock:\n\trelease_sock(sk);\nout:\n\treturn sctp_error(sk, msg->msg_flags, err);\n}",
        "code_after_change": "static int sctp_sendmsg(struct sock *sk, struct msghdr *msg, size_t msg_len)\n{\n\tstruct sctp_endpoint *ep = sctp_sk(sk)->ep;\n\tstruct sctp_transport *transport = NULL;\n\tstruct sctp_sndrcvinfo _sinfo, *sinfo;\n\tstruct sctp_association *asoc, *tmp;\n\tstruct sctp_cmsgs cmsgs;\n\tunion sctp_addr *daddr;\n\tbool new = false;\n\t__u16 sflags;\n\tint err;\n\n\t/* Parse and get snd_info */\n\terr = sctp_sendmsg_parse(sk, &cmsgs, &_sinfo, msg, msg_len);\n\tif (err)\n\t\tgoto out;\n\n\tsinfo  = &_sinfo;\n\tsflags = sinfo->sinfo_flags;\n\n\t/* Get daddr from msg */\n\tdaddr = sctp_sendmsg_get_daddr(sk, msg, &cmsgs);\n\tif (IS_ERR(daddr)) {\n\t\terr = PTR_ERR(daddr);\n\t\tgoto out;\n\t}\n\n\tlock_sock(sk);\n\n\t/* SCTP_SENDALL process */\n\tif ((sflags & SCTP_SENDALL) && sctp_style(sk, UDP)) {\n\t\tlist_for_each_entry_safe(asoc, tmp, &ep->asocs, asocs) {\n\t\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg,\n\t\t\t\t\t\t\tmsg_len);\n\t\t\tif (err == 0)\n\t\t\t\tcontinue;\n\t\t\tif (err < 0)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tsctp_sendmsg_update_sinfo(asoc, sinfo, &cmsgs);\n\n\t\t\terr = sctp_sendmsg_to_asoc(asoc, msg, msg_len,\n\t\t\t\t\t\t   NULL, sinfo);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tiov_iter_revert(&msg->msg_iter, err);\n\t\t}\n\n\t\tgoto out_unlock;\n\t}\n\n\t/* Get and check or create asoc */\n\tif (daddr) {\n\t\tasoc = sctp_endpoint_lookup_assoc(ep, daddr, &transport);\n\t\tif (asoc) {\n\t\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg,\n\t\t\t\t\t\t\tmsg_len);\n\t\t\tif (err <= 0)\n\t\t\t\tgoto out_unlock;\n\t\t} else {\n\t\t\terr = sctp_sendmsg_new_asoc(sk, sflags, &cmsgs, daddr,\n\t\t\t\t\t\t    &transport);\n\t\t\tif (err)\n\t\t\t\tgoto out_unlock;\n\n\t\t\tasoc = transport->asoc;\n\t\t\tnew = true;\n\t\t}\n\n\t\tif (!sctp_style(sk, TCP) && !(sflags & SCTP_ADDR_OVER))\n\t\t\ttransport = NULL;\n\t} else {\n\t\tasoc = sctp_id2assoc(sk, sinfo->sinfo_assoc_id);\n\t\tif (!asoc) {\n\t\t\terr = -EPIPE;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg, msg_len);\n\t\tif (err <= 0)\n\t\t\tgoto out_unlock;\n\t}\n\n\t/* Update snd_info with the asoc */\n\tsctp_sendmsg_update_sinfo(asoc, sinfo, &cmsgs);\n\n\t/* Send msg to the asoc */\n\terr = sctp_sendmsg_to_asoc(asoc, msg, msg_len, transport, sinfo);\n\tif (err < 0 && err != -ESRCH && new)\n\t\tsctp_association_free(asoc);\n\nout_unlock:\n\trelease_sock(sk);\nout:\n\treturn sctp_error(sk, msg->msg_flags, err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct sctp_endpoint *ep = sctp_sk(sk)->ep;\n \tstruct sctp_transport *transport = NULL;\n \tstruct sctp_sndrcvinfo _sinfo, *sinfo;\n-\tstruct sctp_association *asoc;\n+\tstruct sctp_association *asoc, *tmp;\n \tstruct sctp_cmsgs cmsgs;\n \tunion sctp_addr *daddr;\n \tbool new = false;\n@@ -29,7 +29,7 @@\n \n \t/* SCTP_SENDALL process */\n \tif ((sflags & SCTP_SENDALL) && sctp_style(sk, UDP)) {\n-\t\tlist_for_each_entry(asoc, &ep->asocs, asocs) {\n+\t\tlist_for_each_entry_safe(asoc, tmp, &ep->asocs, asocs) {\n \t\t\terr = sctp_sendmsg_check_sflags(asoc, sflags, msg,\n \t\t\t\t\t\t\tmsg_len);\n \t\t\tif (err == 0)",
        "function_modified_lines": {
            "added": [
                "\tstruct sctp_association *asoc, *tmp;",
                "\t\tlist_for_each_entry_safe(asoc, tmp, &ep->asocs, asocs) {"
            ],
            "deleted": [
                "\tstruct sctp_association *asoc;",
                "\t\tlist_for_each_entry(asoc, &ep->asocs, asocs) {"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In the Linux Kernel before versions 4.20.8 and 4.19.21 a use-after-free error in the \"sctp_sendmsg()\" function (net/sctp/socket.c) when handling SCTP_SENDALL flag can be exploited to corrupt memory."
    },
    {
        "cve_id": "CVE-2019-9162",
        "code_before_change": "int snmp_version(void *context, size_t hdrlen, unsigned char tag,\n\t\t const void *data, size_t datalen)\n{\n\tif (*(unsigned char *)data > 1)\n\t\treturn -ENOTSUPP;\n\treturn 1;\n}",
        "code_after_change": "int snmp_version(void *context, size_t hdrlen, unsigned char tag,\n\t\t const void *data, size_t datalen)\n{\n\tif (datalen != 1)\n\t\treturn -EINVAL;\n\tif (*(unsigned char *)data > 1)\n\t\treturn -ENOTSUPP;\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,8 @@\n int snmp_version(void *context, size_t hdrlen, unsigned char tag,\n \t\t const void *data, size_t datalen)\n {\n+\tif (datalen != 1)\n+\t\treturn -EINVAL;\n \tif (*(unsigned char *)data > 1)\n \t\treturn -ENOTSUPP;\n \treturn 1;",
        "function_modified_lines": {
            "added": [
                "\tif (datalen != 1)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 4.20.12, net/ipv4/netfilter/nf_nat_snmp_basic_main.c in the SNMP NAT module has insufficient ASN.1 length checks (aka an array index error), making out-of-bounds read and write operations possible, leading to an OOPS or local privilege escalation. This affects snmp_version and snmp_helper."
    },
    {
        "cve_id": "CVE-2019-9162",
        "code_before_change": "int snmp_helper(void *context, size_t hdrlen, unsigned char tag,\n\t\tconst void *data, size_t datalen)\n{\n\tstruct snmp_ctx *ctx = (struct snmp_ctx *)context;\n\t__be32 *pdata = (__be32 *)data;\n\n\tif (*pdata == ctx->from) {\n\t\tpr_debug(\"%s: %pI4 to %pI4\\n\", __func__,\n\t\t\t (void *)&ctx->from, (void *)&ctx->to);\n\n\t\tif (*ctx->check)\n\t\t\tfast_csum(ctx, (unsigned char *)data - ctx->begin);\n\t\t*pdata = ctx->to;\n\t}\n\n\treturn 1;\n}",
        "code_after_change": "int snmp_helper(void *context, size_t hdrlen, unsigned char tag,\n\t\tconst void *data, size_t datalen)\n{\n\tstruct snmp_ctx *ctx = (struct snmp_ctx *)context;\n\t__be32 *pdata;\n\n\tif (datalen != 4)\n\t\treturn -EINVAL;\n\tpdata = (__be32 *)data;\n\tif (*pdata == ctx->from) {\n\t\tpr_debug(\"%s: %pI4 to %pI4\\n\", __func__,\n\t\t\t (void *)&ctx->from, (void *)&ctx->to);\n\n\t\tif (*ctx->check)\n\t\t\tfast_csum(ctx, (unsigned char *)data - ctx->begin);\n\t\t*pdata = ctx->to;\n\t}\n\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,8 +2,11 @@\n \t\tconst void *data, size_t datalen)\n {\n \tstruct snmp_ctx *ctx = (struct snmp_ctx *)context;\n-\t__be32 *pdata = (__be32 *)data;\n+\t__be32 *pdata;\n \n+\tif (datalen != 4)\n+\t\treturn -EINVAL;\n+\tpdata = (__be32 *)data;\n \tif (*pdata == ctx->from) {\n \t\tpr_debug(\"%s: %pI4 to %pI4\\n\", __func__,\n \t\t\t (void *)&ctx->from, (void *)&ctx->to);",
        "function_modified_lines": {
            "added": [
                "\t__be32 *pdata;",
                "\tif (datalen != 4)",
                "\t\treturn -EINVAL;",
                "\tpdata = (__be32 *)data;"
            ],
            "deleted": [
                "\t__be32 *pdata = (__be32 *)data;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 4.20.12, net/ipv4/netfilter/nf_nat_snmp_basic_main.c in the SNMP NAT module has insufficient ASN.1 length checks (aka an array index error), making out-of-bounds read and write operations possible, leading to an OOPS or local privilege escalation. This affects snmp_version and snmp_helper."
    },
    {
        "cve_id": "CVE-2019-9454",
        "code_before_change": "static s32 i2c_smbus_xfer_emulated(struct i2c_adapter *adapter, u16 addr,\n\t\t\t\t   unsigned short flags,\n\t\t\t\t   char read_write, u8 command, int size,\n\t\t\t\t   union i2c_smbus_data *data)\n{\n\t/* So we need to generate a series of msgs. In the case of writing, we\n\t  need to use only one message; when reading, we need two. We initialize\n\t  most things with sane defaults, to keep the code below somewhat\n\t  simpler. */\n\tunsigned char msgbuf0[I2C_SMBUS_BLOCK_MAX+3];\n\tunsigned char msgbuf1[I2C_SMBUS_BLOCK_MAX+2];\n\tint num = read_write == I2C_SMBUS_READ ? 2 : 1;\n\tint i;\n\tu8 partial_pec = 0;\n\tint status;\n\tstruct i2c_msg msg[2] = {\n\t\t{\n\t\t\t.addr = addr,\n\t\t\t.flags = flags,\n\t\t\t.len = 1,\n\t\t\t.buf = msgbuf0,\n\t\t}, {\n\t\t\t.addr = addr,\n\t\t\t.flags = flags | I2C_M_RD,\n\t\t\t.len = 0,\n\t\t\t.buf = msgbuf1,\n\t\t},\n\t};\n\n\tmsgbuf0[0] = command;\n\tswitch (size) {\n\tcase I2C_SMBUS_QUICK:\n\t\tmsg[0].len = 0;\n\t\t/* Special case: The read/write field is used as data */\n\t\tmsg[0].flags = flags | (read_write == I2C_SMBUS_READ ?\n\t\t\t\t\tI2C_M_RD : 0);\n\t\tnum = 1;\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\t/* Special case: only a read! */\n\t\t\tmsg[0].flags = I2C_M_RD | flags;\n\t\t\tnum = 1;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 1;\n\t\telse {\n\t\t\tmsg[0].len = 2;\n\t\t\tmsgbuf0[1] = data->byte;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_WORD_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 2;\n\t\telse {\n\t\t\tmsg[0].len = 3;\n\t\t\tmsgbuf0[1] = data->word & 0xff;\n\t\t\tmsgbuf0[2] = data->word >> 8;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_PROC_CALL:\n\t\tnum = 2; /* Special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tmsg[0].len = 3;\n\t\tmsg[1].len = 2;\n\t\tmsgbuf0[1] = data->word & 0xff;\n\t\tmsgbuf0[2] = data->word >> 8;\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t\t   the underlying bus driver */\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 2;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 2) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\tnum = 2; /* Another special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmsg[0].len = data->block[0] + 2;\n\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t   the underlying bus driver */\n\t\tbreak;\n\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].len = data->block[0];\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 1;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i <= data->block[0]; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i];\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&adapter->dev, \"Unsupported transaction %d\\n\", size);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\ti = ((flags & I2C_CLIENT_PEC) && size != I2C_SMBUS_QUICK\n\t\t\t\t      && size != I2C_SMBUS_I2C_BLOCK_DATA);\n\tif (i) {\n\t\t/* Compute PEC if first message is a write */\n\t\tif (!(msg[0].flags & I2C_M_RD)) {\n\t\t\tif (num == 1) /* Write only */\n\t\t\t\ti2c_smbus_add_pec(&msg[0]);\n\t\t\telse /* Write followed by read */\n\t\t\t\tpartial_pec = i2c_smbus_msg_pec(0, &msg[0]);\n\t\t}\n\t\t/* Ask for PEC if last message is a read */\n\t\tif (msg[num-1].flags & I2C_M_RD)\n\t\t\tmsg[num-1].len++;\n\t}\n\n\tstatus = i2c_transfer(adapter, msg, num);\n\tif (status < 0)\n\t\treturn status;\n\n\t/* Check PEC if last message is a read */\n\tif (i && (msg[num-1].flags & I2C_M_RD)) {\n\t\tstatus = i2c_smbus_check_pec(partial_pec, &msg[num-1]);\n\t\tif (status < 0)\n\t\t\treturn status;\n\t}\n\n\tif (read_write == I2C_SMBUS_READ)\n\t\tswitch (size) {\n\t\tcase I2C_SMBUS_BYTE:\n\t\t\tdata->byte = msgbuf0[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BYTE_DATA:\n\t\t\tdata->byte = msgbuf1[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_WORD_DATA:\n\t\tcase I2C_SMBUS_PROC_CALL:\n\t\t\tdata->word = msgbuf1[0] | (msgbuf1[1] << 8);\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\t\tfor (i = 0; i < data->block[0]; i++)\n\t\t\t\tdata->block[i+1] = msgbuf1[i];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\t\tfor (i = 0; i < msgbuf1[0] + 1; i++)\n\t\t\t\tdata->block[i] = msgbuf1[i];\n\t\t\tbreak;\n\t\t}\n\treturn 0;\n}",
        "code_after_change": "static s32 i2c_smbus_xfer_emulated(struct i2c_adapter *adapter, u16 addr,\n\t\t\t\t   unsigned short flags,\n\t\t\t\t   char read_write, u8 command, int size,\n\t\t\t\t   union i2c_smbus_data *data)\n{\n\t/* So we need to generate a series of msgs. In the case of writing, we\n\t  need to use only one message; when reading, we need two. We initialize\n\t  most things with sane defaults, to keep the code below somewhat\n\t  simpler. */\n\tunsigned char msgbuf0[I2C_SMBUS_BLOCK_MAX+3];\n\tunsigned char msgbuf1[I2C_SMBUS_BLOCK_MAX+2];\n\tint num = read_write == I2C_SMBUS_READ ? 2 : 1;\n\tint i;\n\tu8 partial_pec = 0;\n\tint status;\n\tstruct i2c_msg msg[2] = {\n\t\t{\n\t\t\t.addr = addr,\n\t\t\t.flags = flags,\n\t\t\t.len = 1,\n\t\t\t.buf = msgbuf0,\n\t\t}, {\n\t\t\t.addr = addr,\n\t\t\t.flags = flags | I2C_M_RD,\n\t\t\t.len = 0,\n\t\t\t.buf = msgbuf1,\n\t\t},\n\t};\n\n\tmsgbuf0[0] = command;\n\tswitch (size) {\n\tcase I2C_SMBUS_QUICK:\n\t\tmsg[0].len = 0;\n\t\t/* Special case: The read/write field is used as data */\n\t\tmsg[0].flags = flags | (read_write == I2C_SMBUS_READ ?\n\t\t\t\t\tI2C_M_RD : 0);\n\t\tnum = 1;\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\t/* Special case: only a read! */\n\t\t\tmsg[0].flags = I2C_M_RD | flags;\n\t\t\tnum = 1;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BYTE_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 1;\n\t\telse {\n\t\t\tmsg[0].len = 2;\n\t\t\tmsgbuf0[1] = data->byte;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_WORD_DATA:\n\t\tif (read_write == I2C_SMBUS_READ)\n\t\t\tmsg[1].len = 2;\n\t\telse {\n\t\t\tmsg[0].len = 3;\n\t\t\tmsgbuf0[1] = data->word & 0xff;\n\t\t\tmsgbuf0[2] = data->word >> 8;\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_PROC_CALL:\n\t\tnum = 2; /* Special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tmsg[0].len = 3;\n\t\tmsg[1].len = 2;\n\t\tmsgbuf0[1] = data->word & 0xff;\n\t\tmsgbuf0[2] = data->word >> 8;\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t\t   the underlying bus driver */\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 2;\n\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 2) {\n\t\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\t\tdata->block[0]);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\t}\n\t\tbreak;\n\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\tnum = 2; /* Another special case */\n\t\tread_write = I2C_SMBUS_READ;\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev,\n\t\t\t\t\"Invalid block write size %d\\n\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmsg[0].len = data->block[0] + 2;\n\t\tfor (i = 1; i < msg[0].len; i++)\n\t\t\tmsgbuf0[i] = data->block[i-1];\n\t\tmsg[1].flags |= I2C_M_RECV_LEN;\n\t\tmsg[1].len = 1; /* block length will be added by\n\t\t\t\t   the underlying bus driver */\n\t\tbreak;\n\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",\n\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",\n\t\t\t\tdata->block[0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (read_write == I2C_SMBUS_READ) {\n\t\t\tmsg[1].len = data->block[0];\n\t\t} else {\n\t\t\tmsg[0].len = data->block[0] + 1;\n\t\t\tfor (i = 1; i <= data->block[0]; i++)\n\t\t\t\tmsgbuf0[i] = data->block[i];\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&adapter->dev, \"Unsupported transaction %d\\n\", size);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\ti = ((flags & I2C_CLIENT_PEC) && size != I2C_SMBUS_QUICK\n\t\t\t\t      && size != I2C_SMBUS_I2C_BLOCK_DATA);\n\tif (i) {\n\t\t/* Compute PEC if first message is a write */\n\t\tif (!(msg[0].flags & I2C_M_RD)) {\n\t\t\tif (num == 1) /* Write only */\n\t\t\t\ti2c_smbus_add_pec(&msg[0]);\n\t\t\telse /* Write followed by read */\n\t\t\t\tpartial_pec = i2c_smbus_msg_pec(0, &msg[0]);\n\t\t}\n\t\t/* Ask for PEC if last message is a read */\n\t\tif (msg[num-1].flags & I2C_M_RD)\n\t\t\tmsg[num-1].len++;\n\t}\n\n\tstatus = i2c_transfer(adapter, msg, num);\n\tif (status < 0)\n\t\treturn status;\n\n\t/* Check PEC if last message is a read */\n\tif (i && (msg[num-1].flags & I2C_M_RD)) {\n\t\tstatus = i2c_smbus_check_pec(partial_pec, &msg[num-1]);\n\t\tif (status < 0)\n\t\t\treturn status;\n\t}\n\n\tif (read_write == I2C_SMBUS_READ)\n\t\tswitch (size) {\n\t\tcase I2C_SMBUS_BYTE:\n\t\t\tdata->byte = msgbuf0[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BYTE_DATA:\n\t\t\tdata->byte = msgbuf1[0];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_WORD_DATA:\n\t\tcase I2C_SMBUS_PROC_CALL:\n\t\t\tdata->word = msgbuf1[0] | (msgbuf1[1] << 8);\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_I2C_BLOCK_DATA:\n\t\t\tfor (i = 0; i < data->block[0]; i++)\n\t\t\t\tdata->block[i+1] = msgbuf1[i];\n\t\t\tbreak;\n\t\tcase I2C_SMBUS_BLOCK_DATA:\n\t\tcase I2C_SMBUS_BLOCK_PROC_CALL:\n\t\t\tfor (i = 0; i < msgbuf1[0] + 1; i++)\n\t\t\t\tdata->block[i] = msgbuf1[i];\n\t\t\tbreak;\n\t\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -102,16 +102,17 @@\n \t\t\t\t   the underlying bus driver */\n \t\tbreak;\n \tcase I2C_SMBUS_I2C_BLOCK_DATA:\n+\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {\n+\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",\n+\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",\n+\t\t\t\tdata->block[0]);\n+\t\t\treturn -EINVAL;\n+\t\t}\n+\n \t\tif (read_write == I2C_SMBUS_READ) {\n \t\t\tmsg[1].len = data->block[0];\n \t\t} else {\n \t\t\tmsg[0].len = data->block[0] + 1;\n-\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {\n-\t\t\t\tdev_err(&adapter->dev,\n-\t\t\t\t\t\"Invalid block write size %d\\n\",\n-\t\t\t\t\tdata->block[0]);\n-\t\t\t\treturn -EINVAL;\n-\t\t\t}\n \t\t\tfor (i = 1; i <= data->block[0]; i++)\n \t\t\t\tmsgbuf0[i] = data->block[i];\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (data->block[0] > I2C_SMBUS_BLOCK_MAX) {",
                "\t\t\tdev_err(&adapter->dev, \"Invalid block %s size %d\\n\",",
                "\t\t\t\tread_write == I2C_SMBUS_READ ? \"read\" : \"write\",",
                "\t\t\t\tdata->block[0]);",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                ""
            ],
            "deleted": [
                "\t\t\tif (msg[0].len > I2C_SMBUS_BLOCK_MAX + 1) {",
                "\t\t\t\tdev_err(&adapter->dev,",
                "\t\t\t\t\t\"Invalid block write size %d\\n\",",
                "\t\t\t\t\tdata->block[0]);",
                "\t\t\t\treturn -EINVAL;",
                "\t\t\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Android kernel in i2c driver there is a possible out of bounds write due to memory corruption. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation."
    },
    {
        "cve_id": "CVE-2019-9456",
        "code_before_change": "static ssize_t mon_text_read_u(struct file *file, char __user *buf,\n\t\t\t\tsize_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_text *rp = file->private_data;\n\tstruct mon_event_text *ep;\n\tstruct mon_text_ptr ptr;\n\n\tep = mon_text_read_wait(rp, file);\n\tif (IS_ERR(ep))\n\t\treturn PTR_ERR(ep);\n\tmutex_lock(&rp->printf_lock);\n\tptr.cnt = 0;\n\tptr.pbuf = rp->printf_buf;\n\tptr.limit = rp->printf_size;\n\n\tmon_text_read_head_u(rp, &ptr, ep);\n\tif (ep->type == 'E') {\n\t\tmon_text_read_statset(rp, &ptr, ep);\n\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {\n\t\tmon_text_read_isostat(rp, &ptr, ep);\n\t\tmon_text_read_isodesc(rp, &ptr, ep);\n\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {\n\t\tmon_text_read_intstat(rp, &ptr, ep);\n\t} else {\n\t\tmon_text_read_statset(rp, &ptr, ep);\n\t}\n\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n\t    \" %d\", ep->length);\n\tmon_text_read_data(rp, &ptr, ep);\n\n\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))\n\t\tptr.cnt = -EFAULT;\n\tmutex_unlock(&rp->printf_lock);\n\tkmem_cache_free(rp->e_slab, ep);\n\treturn ptr.cnt;\n}",
        "code_after_change": "static ssize_t mon_text_read_u(struct file *file, char __user *buf,\n    size_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_text *rp = file->private_data;\n\tstruct mon_event_text *ep;\n\tstruct mon_text_ptr ptr;\n\tssize_t ret;\n\n\tmutex_lock(&rp->printf_lock);\n\n\tif (rp->printf_togo == 0) {\n\n\t\tep = mon_text_read_wait(rp, file);\n\t\tif (IS_ERR(ep)) {\n\t\t\tmutex_unlock(&rp->printf_lock);\n\t\t\treturn PTR_ERR(ep);\n\t\t}\n\t\tptr.cnt = 0;\n\t\tptr.pbuf = rp->printf_buf;\n\t\tptr.limit = rp->printf_size;\n\n\t\tmon_text_read_head_u(rp, &ptr, ep);\n\t\tif (ep->type == 'E') {\n\t\t\tmon_text_read_statset(rp, &ptr, ep);\n\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {\n\t\t\tmon_text_read_isostat(rp, &ptr, ep);\n\t\t\tmon_text_read_isodesc(rp, &ptr, ep);\n\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {\n\t\t\tmon_text_read_intstat(rp, &ptr, ep);\n\t\t} else {\n\t\t\tmon_text_read_statset(rp, &ptr, ep);\n\t\t}\n\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n\t\t    \" %d\", ep->length);\n\t\tmon_text_read_data(rp, &ptr, ep);\n\n\t\trp->printf_togo = ptr.cnt;\n\t\trp->printf_offset = 0;\n\n\t\tkmem_cache_free(rp->e_slab, ep);\n\t}\n\n\tret = mon_text_copy_to_user(rp, buf, nbytes);\n\tmutex_unlock(&rp->printf_lock);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,36 +1,46 @@\n static ssize_t mon_text_read_u(struct file *file, char __user *buf,\n-\t\t\t\tsize_t nbytes, loff_t *ppos)\n+    size_t nbytes, loff_t *ppos)\n {\n \tstruct mon_reader_text *rp = file->private_data;\n \tstruct mon_event_text *ep;\n \tstruct mon_text_ptr ptr;\n+\tssize_t ret;\n \n-\tep = mon_text_read_wait(rp, file);\n-\tif (IS_ERR(ep))\n-\t\treturn PTR_ERR(ep);\n \tmutex_lock(&rp->printf_lock);\n-\tptr.cnt = 0;\n-\tptr.pbuf = rp->printf_buf;\n-\tptr.limit = rp->printf_size;\n \n-\tmon_text_read_head_u(rp, &ptr, ep);\n-\tif (ep->type == 'E') {\n-\t\tmon_text_read_statset(rp, &ptr, ep);\n-\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {\n-\t\tmon_text_read_isostat(rp, &ptr, ep);\n-\t\tmon_text_read_isodesc(rp, &ptr, ep);\n-\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {\n-\t\tmon_text_read_intstat(rp, &ptr, ep);\n-\t} else {\n-\t\tmon_text_read_statset(rp, &ptr, ep);\n+\tif (rp->printf_togo == 0) {\n+\n+\t\tep = mon_text_read_wait(rp, file);\n+\t\tif (IS_ERR(ep)) {\n+\t\t\tmutex_unlock(&rp->printf_lock);\n+\t\t\treturn PTR_ERR(ep);\n+\t\t}\n+\t\tptr.cnt = 0;\n+\t\tptr.pbuf = rp->printf_buf;\n+\t\tptr.limit = rp->printf_size;\n+\n+\t\tmon_text_read_head_u(rp, &ptr, ep);\n+\t\tif (ep->type == 'E') {\n+\t\t\tmon_text_read_statset(rp, &ptr, ep);\n+\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {\n+\t\t\tmon_text_read_isostat(rp, &ptr, ep);\n+\t\t\tmon_text_read_isodesc(rp, &ptr, ep);\n+\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {\n+\t\t\tmon_text_read_intstat(rp, &ptr, ep);\n+\t\t} else {\n+\t\t\tmon_text_read_statset(rp, &ptr, ep);\n+\t\t}\n+\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n+\t\t    \" %d\", ep->length);\n+\t\tmon_text_read_data(rp, &ptr, ep);\n+\n+\t\trp->printf_togo = ptr.cnt;\n+\t\trp->printf_offset = 0;\n+\n+\t\tkmem_cache_free(rp->e_slab, ep);\n \t}\n-\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n-\t    \" %d\", ep->length);\n-\tmon_text_read_data(rp, &ptr, ep);\n \n-\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))\n-\t\tptr.cnt = -EFAULT;\n+\tret = mon_text_copy_to_user(rp, buf, nbytes);\n \tmutex_unlock(&rp->printf_lock);\n-\tkmem_cache_free(rp->e_slab, ep);\n-\treturn ptr.cnt;\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "    size_t nbytes, loff_t *ppos)",
                "\tssize_t ret;",
                "\tif (rp->printf_togo == 0) {",
                "",
                "\t\tep = mon_text_read_wait(rp, file);",
                "\t\tif (IS_ERR(ep)) {",
                "\t\t\tmutex_unlock(&rp->printf_lock);",
                "\t\t\treturn PTR_ERR(ep);",
                "\t\t}",
                "\t\tptr.cnt = 0;",
                "\t\tptr.pbuf = rp->printf_buf;",
                "\t\tptr.limit = rp->printf_size;",
                "",
                "\t\tmon_text_read_head_u(rp, &ptr, ep);",
                "\t\tif (ep->type == 'E') {",
                "\t\t\tmon_text_read_statset(rp, &ptr, ep);",
                "\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {",
                "\t\t\tmon_text_read_isostat(rp, &ptr, ep);",
                "\t\t\tmon_text_read_isodesc(rp, &ptr, ep);",
                "\t\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {",
                "\t\t\tmon_text_read_intstat(rp, &ptr, ep);",
                "\t\t} else {",
                "\t\t\tmon_text_read_statset(rp, &ptr, ep);",
                "\t\t}",
                "\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,",
                "\t\t    \" %d\", ep->length);",
                "\t\tmon_text_read_data(rp, &ptr, ep);",
                "",
                "\t\trp->printf_togo = ptr.cnt;",
                "\t\trp->printf_offset = 0;",
                "",
                "\t\tkmem_cache_free(rp->e_slab, ep);",
                "\tret = mon_text_copy_to_user(rp, buf, nbytes);",
                "\treturn ret;"
            ],
            "deleted": [
                "\t\t\t\tsize_t nbytes, loff_t *ppos)",
                "\tep = mon_text_read_wait(rp, file);",
                "\tif (IS_ERR(ep))",
                "\t\treturn PTR_ERR(ep);",
                "\tptr.cnt = 0;",
                "\tptr.pbuf = rp->printf_buf;",
                "\tptr.limit = rp->printf_size;",
                "\tmon_text_read_head_u(rp, &ptr, ep);",
                "\tif (ep->type == 'E') {",
                "\t\tmon_text_read_statset(rp, &ptr, ep);",
                "\t} else if (ep->xfertype == USB_ENDPOINT_XFER_ISOC) {",
                "\t\tmon_text_read_isostat(rp, &ptr, ep);",
                "\t\tmon_text_read_isodesc(rp, &ptr, ep);",
                "\t} else if (ep->xfertype == USB_ENDPOINT_XFER_INT) {",
                "\t\tmon_text_read_intstat(rp, &ptr, ep);",
                "\t} else {",
                "\t\tmon_text_read_statset(rp, &ptr, ep);",
                "\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,",
                "\t    \" %d\", ep->length);",
                "\tmon_text_read_data(rp, &ptr, ep);",
                "\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))",
                "\t\tptr.cnt = -EFAULT;",
                "\tkmem_cache_free(rp->e_slab, ep);",
                "\treturn ptr.cnt;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Android kernel in Pixel C USB monitor driver there is a possible OOB write due to a missing bounds check. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation."
    },
    {
        "cve_id": "CVE-2019-9456",
        "code_before_change": "static ssize_t mon_text_read_t(struct file *file, char __user *buf,\n\t\t\t\tsize_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_text *rp = file->private_data;\n\tstruct mon_event_text *ep;\n\tstruct mon_text_ptr ptr;\n\n\tep = mon_text_read_wait(rp, file);\n\tif (IS_ERR(ep))\n\t\treturn PTR_ERR(ep);\n\tmutex_lock(&rp->printf_lock);\n\tptr.cnt = 0;\n\tptr.pbuf = rp->printf_buf;\n\tptr.limit = rp->printf_size;\n\n\tmon_text_read_head_t(rp, &ptr, ep);\n\tmon_text_read_statset(rp, &ptr, ep);\n\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n\t    \" %d\", ep->length);\n\tmon_text_read_data(rp, &ptr, ep);\n\n\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))\n\t\tptr.cnt = -EFAULT;\n\tmutex_unlock(&rp->printf_lock);\n\tkmem_cache_free(rp->e_slab, ep);\n\treturn ptr.cnt;\n}",
        "code_after_change": "static ssize_t mon_text_read_t(struct file *file, char __user *buf,\n    size_t nbytes, loff_t *ppos)\n{\n\tstruct mon_reader_text *rp = file->private_data;\n\tstruct mon_event_text *ep;\n\tstruct mon_text_ptr ptr;\n\tssize_t ret;\n\n\tmutex_lock(&rp->printf_lock);\n\n\tif (rp->printf_togo == 0) {\n\n\t\tep = mon_text_read_wait(rp, file);\n\t\tif (IS_ERR(ep)) {\n\t\t\tmutex_unlock(&rp->printf_lock);\n\t\t\treturn PTR_ERR(ep);\n\t\t}\n\t\tptr.cnt = 0;\n\t\tptr.pbuf = rp->printf_buf;\n\t\tptr.limit = rp->printf_size;\n\n\t\tmon_text_read_head_t(rp, &ptr, ep);\n\t\tmon_text_read_statset(rp, &ptr, ep);\n\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n\t\t    \" %d\", ep->length);\n\t\tmon_text_read_data(rp, &ptr, ep);\n\n\t\trp->printf_togo = ptr.cnt;\n\t\trp->printf_offset = 0;\n\n\t\tkmem_cache_free(rp->e_slab, ep);\n\t}\n\n\tret = mon_text_copy_to_user(rp, buf, nbytes);\n\tmutex_unlock(&rp->printf_lock);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,27 +1,37 @@\n static ssize_t mon_text_read_t(struct file *file, char __user *buf,\n-\t\t\t\tsize_t nbytes, loff_t *ppos)\n+    size_t nbytes, loff_t *ppos)\n {\n \tstruct mon_reader_text *rp = file->private_data;\n \tstruct mon_event_text *ep;\n \tstruct mon_text_ptr ptr;\n+\tssize_t ret;\n \n-\tep = mon_text_read_wait(rp, file);\n-\tif (IS_ERR(ep))\n-\t\treturn PTR_ERR(ep);\n \tmutex_lock(&rp->printf_lock);\n-\tptr.cnt = 0;\n-\tptr.pbuf = rp->printf_buf;\n-\tptr.limit = rp->printf_size;\n \n-\tmon_text_read_head_t(rp, &ptr, ep);\n-\tmon_text_read_statset(rp, &ptr, ep);\n-\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n-\t    \" %d\", ep->length);\n-\tmon_text_read_data(rp, &ptr, ep);\n+\tif (rp->printf_togo == 0) {\n \n-\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))\n-\t\tptr.cnt = -EFAULT;\n+\t\tep = mon_text_read_wait(rp, file);\n+\t\tif (IS_ERR(ep)) {\n+\t\t\tmutex_unlock(&rp->printf_lock);\n+\t\t\treturn PTR_ERR(ep);\n+\t\t}\n+\t\tptr.cnt = 0;\n+\t\tptr.pbuf = rp->printf_buf;\n+\t\tptr.limit = rp->printf_size;\n+\n+\t\tmon_text_read_head_t(rp, &ptr, ep);\n+\t\tmon_text_read_statset(rp, &ptr, ep);\n+\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,\n+\t\t    \" %d\", ep->length);\n+\t\tmon_text_read_data(rp, &ptr, ep);\n+\n+\t\trp->printf_togo = ptr.cnt;\n+\t\trp->printf_offset = 0;\n+\n+\t\tkmem_cache_free(rp->e_slab, ep);\n+\t}\n+\n+\tret = mon_text_copy_to_user(rp, buf, nbytes);\n \tmutex_unlock(&rp->printf_lock);\n-\tkmem_cache_free(rp->e_slab, ep);\n-\treturn ptr.cnt;\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "    size_t nbytes, loff_t *ppos)",
                "\tssize_t ret;",
                "\tif (rp->printf_togo == 0) {",
                "\t\tep = mon_text_read_wait(rp, file);",
                "\t\tif (IS_ERR(ep)) {",
                "\t\t\tmutex_unlock(&rp->printf_lock);",
                "\t\t\treturn PTR_ERR(ep);",
                "\t\t}",
                "\t\tptr.cnt = 0;",
                "\t\tptr.pbuf = rp->printf_buf;",
                "\t\tptr.limit = rp->printf_size;",
                "",
                "\t\tmon_text_read_head_t(rp, &ptr, ep);",
                "\t\tmon_text_read_statset(rp, &ptr, ep);",
                "\t\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,",
                "\t\t    \" %d\", ep->length);",
                "\t\tmon_text_read_data(rp, &ptr, ep);",
                "",
                "\t\trp->printf_togo = ptr.cnt;",
                "\t\trp->printf_offset = 0;",
                "",
                "\t\tkmem_cache_free(rp->e_slab, ep);",
                "\t}",
                "",
                "\tret = mon_text_copy_to_user(rp, buf, nbytes);",
                "\treturn ret;"
            ],
            "deleted": [
                "\t\t\t\tsize_t nbytes, loff_t *ppos)",
                "\tep = mon_text_read_wait(rp, file);",
                "\tif (IS_ERR(ep))",
                "\t\treturn PTR_ERR(ep);",
                "\tptr.cnt = 0;",
                "\tptr.pbuf = rp->printf_buf;",
                "\tptr.limit = rp->printf_size;",
                "\tmon_text_read_head_t(rp, &ptr, ep);",
                "\tmon_text_read_statset(rp, &ptr, ep);",
                "\tptr.cnt += snprintf(ptr.pbuf + ptr.cnt, ptr.limit - ptr.cnt,",
                "\t    \" %d\", ep->length);",
                "\tmon_text_read_data(rp, &ptr, ep);",
                "\tif (copy_to_user(buf, rp->printf_buf, ptr.cnt))",
                "\t\tptr.cnt = -EFAULT;",
                "\tkmem_cache_free(rp->e_slab, ep);",
                "\treturn ptr.cnt;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Android kernel in Pixel C USB monitor driver there is a possible OOB write due to a missing bounds check. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation."
    },
    {
        "cve_id": "CVE-2019-9500",
        "code_before_change": "static s32\nbrcmf_wowl_nd_results(struct brcmf_if *ifp, const struct brcmf_event_msg *e,\n\t\t      void *data)\n{\n\tstruct brcmf_cfg80211_info *cfg = ifp->drvr->config;\n\tstruct wiphy *wiphy = cfg_to_wiphy(cfg);\n\tstruct brcmf_pno_scanresults_le *pfn_result;\n\tstruct brcmf_pno_net_info_le *netinfo;\n\n\tbrcmf_dbg(SCAN, \"Enter\\n\");\n\n\tif (e->datalen < (sizeof(*pfn_result) + sizeof(*netinfo))) {\n\t\tbrcmf_dbg(SCAN, \"Event data to small. Ignore\\n\");\n\t\treturn 0;\n\t}\n\n\tpfn_result = (struct brcmf_pno_scanresults_le *)data;\n\n\tif (e->event_code == BRCMF_E_PFN_NET_LOST) {\n\t\tbrcmf_dbg(SCAN, \"PFN NET LOST event. Ignore\\n\");\n\t\treturn 0;\n\t}\n\n\tif (le32_to_cpu(pfn_result->count) < 1) {\n\t\tbphy_err(wiphy, \"Invalid result count, expected 1 (%d)\\n\",\n\t\t\t le32_to_cpu(pfn_result->count));\n\t\treturn -EINVAL;\n\t}\n\n\tnetinfo = brcmf_get_netinfo_array(pfn_result);\n\tmemcpy(cfg->wowl.nd->ssid.ssid, netinfo->SSID, netinfo->SSID_len);\n\tcfg->wowl.nd->ssid.ssid_len = netinfo->SSID_len;\n\tcfg->wowl.nd->n_channels = 1;\n\tcfg->wowl.nd->channels[0] =\n\t\tieee80211_channel_to_frequency(netinfo->channel,\n\t\t\tnetinfo->channel <= CH_MAX_2G_CHANNEL ?\n\t\t\t\t\tNL80211_BAND_2GHZ : NL80211_BAND_5GHZ);\n\tcfg->wowl.nd_info->n_matches = 1;\n\tcfg->wowl.nd_info->matches[0] = cfg->wowl.nd;\n\n\t/* Inform (the resume task) that the net detect information was recvd */\n\tcfg->wowl.nd_data_completed = true;\n\twake_up(&cfg->wowl.nd_data_wait);\n\n\treturn 0;\n}",
        "code_after_change": "static s32\nbrcmf_wowl_nd_results(struct brcmf_if *ifp, const struct brcmf_event_msg *e,\n\t\t      void *data)\n{\n\tstruct brcmf_cfg80211_info *cfg = ifp->drvr->config;\n\tstruct wiphy *wiphy = cfg_to_wiphy(cfg);\n\tstruct brcmf_pno_scanresults_le *pfn_result;\n\tstruct brcmf_pno_net_info_le *netinfo;\n\n\tbrcmf_dbg(SCAN, \"Enter\\n\");\n\n\tif (e->datalen < (sizeof(*pfn_result) + sizeof(*netinfo))) {\n\t\tbrcmf_dbg(SCAN, \"Event data to small. Ignore\\n\");\n\t\treturn 0;\n\t}\n\n\tpfn_result = (struct brcmf_pno_scanresults_le *)data;\n\n\tif (e->event_code == BRCMF_E_PFN_NET_LOST) {\n\t\tbrcmf_dbg(SCAN, \"PFN NET LOST event. Ignore\\n\");\n\t\treturn 0;\n\t}\n\n\tif (le32_to_cpu(pfn_result->count) < 1) {\n\t\tbphy_err(wiphy, \"Invalid result count, expected 1 (%d)\\n\",\n\t\t\t le32_to_cpu(pfn_result->count));\n\t\treturn -EINVAL;\n\t}\n\n\tnetinfo = brcmf_get_netinfo_array(pfn_result);\n\tif (netinfo->SSID_len > IEEE80211_MAX_SSID_LEN)\n\t\tnetinfo->SSID_len = IEEE80211_MAX_SSID_LEN;\n\tmemcpy(cfg->wowl.nd->ssid.ssid, netinfo->SSID, netinfo->SSID_len);\n\tcfg->wowl.nd->ssid.ssid_len = netinfo->SSID_len;\n\tcfg->wowl.nd->n_channels = 1;\n\tcfg->wowl.nd->channels[0] =\n\t\tieee80211_channel_to_frequency(netinfo->channel,\n\t\t\tnetinfo->channel <= CH_MAX_2G_CHANNEL ?\n\t\t\t\t\tNL80211_BAND_2GHZ : NL80211_BAND_5GHZ);\n\tcfg->wowl.nd_info->n_matches = 1;\n\tcfg->wowl.nd_info->matches[0] = cfg->wowl.nd;\n\n\t/* Inform (the resume task) that the net detect information was recvd */\n\tcfg->wowl.nd_data_completed = true;\n\twake_up(&cfg->wowl.nd_data_wait);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,6 +28,8 @@\n \t}\n \n \tnetinfo = brcmf_get_netinfo_array(pfn_result);\n+\tif (netinfo->SSID_len > IEEE80211_MAX_SSID_LEN)\n+\t\tnetinfo->SSID_len = IEEE80211_MAX_SSID_LEN;\n \tmemcpy(cfg->wowl.nd->ssid.ssid, netinfo->SSID, netinfo->SSID_len);\n \tcfg->wowl.nd->ssid.ssid_len = netinfo->SSID_len;\n \tcfg->wowl.nd->n_channels = 1;",
        "function_modified_lines": {
            "added": [
                "\tif (netinfo->SSID_len > IEEE80211_MAX_SSID_LEN)",
                "\t\tnetinfo->SSID_len = IEEE80211_MAX_SSID_LEN;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The Broadcom brcmfmac WiFi driver prior to commit 1b5e2423164b3670e8bc9174e4762d297990deff is vulnerable to a heap buffer overflow. If the Wake-up on Wireless LAN functionality is configured, a malicious event frame can be constructed to trigger an heap buffer overflow in the brcmf_wowl_nd_results function. This vulnerability can be exploited with compromised chipsets to compromise the host, or when used in combination with CVE-2019-9503, can be used remotely. In the worst case scenario, by sending specially-crafted WiFi packets, a remote, unauthenticated attacker may be able to execute arbitrary code on a vulnerable system. More typically, this vulnerability will result in denial-of-service conditions."
    },
    {
        "cve_id": "CVE-2020-0066",
        "code_before_change": "static int netlink_dump(struct sock *sk)\n{\n\tstruct netlink_sock *nlk = nlk_sk(sk);\n\tstruct netlink_callback *cb;\n\tstruct sk_buff *skb = NULL;\n\tstruct nlmsghdr *nlh;\n\tint len, err = -ENOBUFS;\n\tint alloc_size;\n\n\tmutex_lock(nlk->cb_mutex);\n\tif (!nlk->cb_running) {\n\t\terr = -EINVAL;\n\t\tgoto errout_skb;\n\t}\n\n\tcb = &nlk->cb;\n\talloc_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);\n\n\tif (!netlink_rx_is_mmaped(sk) &&\n\t    atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)\n\t\tgoto errout_skb;\n\n\t/* NLMSG_GOODSIZE is small to avoid high order allocations being\n\t * required, but it makes sense to _attempt_ a 16K bytes allocation\n\t * to reduce number of system calls on dump operations, if user\n\t * ever provided a big enough buffer.\n\t */\n\tif (alloc_size < nlk->max_recvmsg_len) {\n\t\tskb = netlink_alloc_skb(sk,\n\t\t\t\t\tnlk->max_recvmsg_len,\n\t\t\t\t\tnlk->portid,\n\t\t\t\t\tGFP_KERNEL |\n\t\t\t\t\t__GFP_NOWARN |\n\t\t\t\t\t__GFP_NORETRY);\n\t\t/* available room should be exact amount to avoid MSG_TRUNC */\n\t\tif (skb)\n\t\t\tskb_reserve(skb, skb_tailroom(skb) -\n\t\t\t\t\t nlk->max_recvmsg_len);\n\t}\n\tif (!skb)\n\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!skb)\n\t\tgoto errout_skb;\n\tnetlink_skb_set_owner_r(skb, sk);\n\n\tlen = cb->dump(skb, cb);\n\n\tif (len > 0) {\n\t\tmutex_unlock(nlk->cb_mutex);\n\n\t\tif (sk_filter(sk, skb))\n\t\t\tkfree_skb(skb);\n\t\telse\n\t\t\t__netlink_sendskb(sk, skb);\n\t\treturn 0;\n\t}\n\n\tnlh = nlmsg_put_answer(skb, cb, NLMSG_DONE, sizeof(len), NLM_F_MULTI);\n\tif (!nlh)\n\t\tgoto errout_skb;\n\n\tnl_dump_check_consistent(cb, nlh);\n\n\tmemcpy(nlmsg_data(nlh), &len, sizeof(len));\n\n\tif (sk_filter(sk, skb))\n\t\tkfree_skb(skb);\n\telse\n\t\t__netlink_sendskb(sk, skb);\n\n\tif (cb->done)\n\t\tcb->done(cb);\n\n\tnlk->cb_running = false;\n\tmutex_unlock(nlk->cb_mutex);\n\tmodule_put(cb->module);\n\tconsume_skb(cb->skb);\n\treturn 0;\n\nerrout_skb:\n\tmutex_unlock(nlk->cb_mutex);\n\tkfree_skb(skb);\n\treturn err;\n}",
        "code_after_change": "static int netlink_dump(struct sock *sk)\n{\n\tstruct netlink_sock *nlk = nlk_sk(sk);\n\tstruct netlink_callback *cb;\n\tstruct sk_buff *skb = NULL;\n\tstruct nlmsghdr *nlh;\n\tint len, err = -ENOBUFS;\n\tint alloc_min_size;\n\tint alloc_size;\n\n\tmutex_lock(nlk->cb_mutex);\n\tif (!nlk->cb_running) {\n\t\terr = -EINVAL;\n\t\tgoto errout_skb;\n\t}\n\n\tif (!netlink_rx_is_mmaped(sk) &&\n\t    atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)\n\t\tgoto errout_skb;\n\n\t/* NLMSG_GOODSIZE is small to avoid high order allocations being\n\t * required, but it makes sense to _attempt_ a 16K bytes allocation\n\t * to reduce number of system calls on dump operations, if user\n\t * ever provided a big enough buffer.\n\t */\n\tcb = &nlk->cb;\n\talloc_min_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);\n\n\tif (alloc_min_size < nlk->max_recvmsg_len) {\n\t\talloc_size = nlk->max_recvmsg_len;\n\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n\t\t\t\t\tGFP_KERNEL |\n\t\t\t\t\t__GFP_NOWARN |\n\t\t\t\t\t__GFP_NORETRY);\n\t}\n\tif (!skb) {\n\t\talloc_size = alloc_min_size;\n\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n\t\t\t\t\tGFP_KERNEL);\n\t}\n\tif (!skb)\n\t\tgoto errout_skb;\n\n\t/* Trim skb to allocated size. User is expected to provide buffer as\n\t * large as max(min_dump_alloc, 16KiB (mac_recvmsg_len capped at\n\t * netlink_recvmsg())). dump will pack as many smaller messages as\n\t * could fit within the allocated skb. skb is typically allocated\n\t * with larger space than required (could be as much as near 2x the\n\t * requested size with align to next power of 2 approach). Allowing\n\t * dump to use the excess space makes it difficult for a user to have a\n\t * reasonable static buffer based on the expected largest dump of a\n\t * single netdev. The outcome is MSG_TRUNC error.\n\t */\n\tskb_reserve(skb, skb_tailroom(skb) - alloc_size);\n\tnetlink_skb_set_owner_r(skb, sk);\n\n\tlen = cb->dump(skb, cb);\n\n\tif (len > 0) {\n\t\tmutex_unlock(nlk->cb_mutex);\n\n\t\tif (sk_filter(sk, skb))\n\t\t\tkfree_skb(skb);\n\t\telse\n\t\t\t__netlink_sendskb(sk, skb);\n\t\treturn 0;\n\t}\n\n\tnlh = nlmsg_put_answer(skb, cb, NLMSG_DONE, sizeof(len), NLM_F_MULTI);\n\tif (!nlh)\n\t\tgoto errout_skb;\n\n\tnl_dump_check_consistent(cb, nlh);\n\n\tmemcpy(nlmsg_data(nlh), &len, sizeof(len));\n\n\tif (sk_filter(sk, skb))\n\t\tkfree_skb(skb);\n\telse\n\t\t__netlink_sendskb(sk, skb);\n\n\tif (cb->done)\n\t\tcb->done(cb);\n\n\tnlk->cb_running = false;\n\tmutex_unlock(nlk->cb_mutex);\n\tmodule_put(cb->module);\n\tconsume_skb(cb->skb);\n\treturn 0;\n\nerrout_skb:\n\tmutex_unlock(nlk->cb_mutex);\n\tkfree_skb(skb);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tstruct sk_buff *skb = NULL;\n \tstruct nlmsghdr *nlh;\n \tint len, err = -ENOBUFS;\n+\tint alloc_min_size;\n \tint alloc_size;\n \n \tmutex_lock(nlk->cb_mutex);\n@@ -12,9 +13,6 @@\n \t\terr = -EINVAL;\n \t\tgoto errout_skb;\n \t}\n-\n-\tcb = &nlk->cb;\n-\talloc_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);\n \n \tif (!netlink_rx_is_mmaped(sk) &&\n \t    atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf)\n@@ -25,23 +23,35 @@\n \t * to reduce number of system calls on dump operations, if user\n \t * ever provided a big enough buffer.\n \t */\n-\tif (alloc_size < nlk->max_recvmsg_len) {\n-\t\tskb = netlink_alloc_skb(sk,\n-\t\t\t\t\tnlk->max_recvmsg_len,\n-\t\t\t\t\tnlk->portid,\n+\tcb = &nlk->cb;\n+\talloc_min_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);\n+\n+\tif (alloc_min_size < nlk->max_recvmsg_len) {\n+\t\talloc_size = nlk->max_recvmsg_len;\n+\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n \t\t\t\t\tGFP_KERNEL |\n \t\t\t\t\t__GFP_NOWARN |\n \t\t\t\t\t__GFP_NORETRY);\n-\t\t/* available room should be exact amount to avoid MSG_TRUNC */\n-\t\tif (skb)\n-\t\t\tskb_reserve(skb, skb_tailroom(skb) -\n-\t\t\t\t\t nlk->max_recvmsg_len);\n+\t}\n+\tif (!skb) {\n+\t\talloc_size = alloc_min_size;\n+\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n+\t\t\t\t\tGFP_KERNEL);\n \t}\n \tif (!skb)\n-\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,\n-\t\t\t\t\tGFP_KERNEL);\n-\tif (!skb)\n \t\tgoto errout_skb;\n+\n+\t/* Trim skb to allocated size. User is expected to provide buffer as\n+\t * large as max(min_dump_alloc, 16KiB (mac_recvmsg_len capped at\n+\t * netlink_recvmsg())). dump will pack as many smaller messages as\n+\t * could fit within the allocated skb. skb is typically allocated\n+\t * with larger space than required (could be as much as near 2x the\n+\t * requested size with align to next power of 2 approach). Allowing\n+\t * dump to use the excess space makes it difficult for a user to have a\n+\t * reasonable static buffer based on the expected largest dump of a\n+\t * single netdev. The outcome is MSG_TRUNC error.\n+\t */\n+\tskb_reserve(skb, skb_tailroom(skb) - alloc_size);\n \tnetlink_skb_set_owner_r(skb, sk);\n \n \tlen = cb->dump(skb, cb);",
        "function_modified_lines": {
            "added": [
                "\tint alloc_min_size;",
                "\tcb = &nlk->cb;",
                "\talloc_min_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);",
                "",
                "\tif (alloc_min_size < nlk->max_recvmsg_len) {",
                "\t\talloc_size = nlk->max_recvmsg_len;",
                "\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,",
                "\t}",
                "\tif (!skb) {",
                "\t\talloc_size = alloc_min_size;",
                "\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,",
                "\t\t\t\t\tGFP_KERNEL);",
                "",
                "\t/* Trim skb to allocated size. User is expected to provide buffer as",
                "\t * large as max(min_dump_alloc, 16KiB (mac_recvmsg_len capped at",
                "\t * netlink_recvmsg())). dump will pack as many smaller messages as",
                "\t * could fit within the allocated skb. skb is typically allocated",
                "\t * with larger space than required (could be as much as near 2x the",
                "\t * requested size with align to next power of 2 approach). Allowing",
                "\t * dump to use the excess space makes it difficult for a user to have a",
                "\t * reasonable static buffer based on the expected largest dump of a",
                "\t * single netdev. The outcome is MSG_TRUNC error.",
                "\t */",
                "\tskb_reserve(skb, skb_tailroom(skb) - alloc_size);"
            ],
            "deleted": [
                "",
                "\tcb = &nlk->cb;",
                "\talloc_size = max_t(int, cb->min_dump_alloc, NLMSG_GOODSIZE);",
                "\tif (alloc_size < nlk->max_recvmsg_len) {",
                "\t\tskb = netlink_alloc_skb(sk,",
                "\t\t\t\t\tnlk->max_recvmsg_len,",
                "\t\t\t\t\tnlk->portid,",
                "\t\t/* available room should be exact amount to avoid MSG_TRUNC */",
                "\t\tif (skb)",
                "\t\t\tskb_reserve(skb, skb_tailroom(skb) -",
                "\t\t\t\t\t nlk->max_recvmsg_len);",
                "\t\tskb = netlink_alloc_skb(sk, alloc_size, nlk->portid,",
                "\t\t\t\t\tGFP_KERNEL);",
                "\tif (!skb)"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-787"
        ],
        "cve_description": "In the netlink driver, there is a possible out of bounds write due to a race condition. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-65025077"
    },
    {
        "cve_id": "CVE-2020-0429",
        "code_before_change": "void l2tp_tunnel_closeall(struct l2tp_tunnel *tunnel)\n{\n\tint hash;\n\tstruct hlist_node *walk;\n\tstruct hlist_node *tmp;\n\tstruct l2tp_session *session;\n\n\tBUG_ON(tunnel == NULL);\n\n\tl2tp_info(tunnel, L2TP_MSG_CONTROL, \"%s: closing all sessions...\\n\",\n\t\t  tunnel->name);\n\n\twrite_lock_bh(&tunnel->hlist_lock);\n\ttunnel->acpt_newsess = false;\n\tfor (hash = 0; hash < L2TP_HASH_SIZE; hash++) {\nagain:\n\t\thlist_for_each_safe(walk, tmp, &tunnel->session_hlist[hash]) {\n\t\t\tsession = hlist_entry(walk, struct l2tp_session, hlist);\n\n\t\t\tl2tp_info(session, L2TP_MSG_CONTROL,\n\t\t\t\t  \"%s: closing session\\n\", session->name);\n\n\t\t\thlist_del_init(&session->hlist);\n\n\t\t\tif (session->ref != NULL)\n\t\t\t\t(*session->ref)(session);\n\n\t\t\twrite_unlock_bh(&tunnel->hlist_lock);\n\n\t\t\t__l2tp_session_unhash(session);\n\t\t\tl2tp_session_queue_purge(session);\n\n\t\t\tif (session->session_close != NULL)\n\t\t\t\t(*session->session_close)(session);\n\n\t\t\tif (session->deref != NULL)\n\t\t\t\t(*session->deref)(session);\n\n\t\t\tl2tp_session_dec_refcount(session);\n\n\t\t\twrite_lock_bh(&tunnel->hlist_lock);\n\n\t\t\t/* Now restart from the beginning of this hash\n\t\t\t * chain.  We always remove a session from the\n\t\t\t * list so we are guaranteed to make forward\n\t\t\t * progress.\n\t\t\t */\n\t\t\tgoto again;\n\t\t}\n\t}\n\twrite_unlock_bh(&tunnel->hlist_lock);\n}",
        "code_after_change": "void l2tp_tunnel_closeall(struct l2tp_tunnel *tunnel)\n{\n\tint hash;\n\tstruct hlist_node *walk;\n\tstruct hlist_node *tmp;\n\tstruct l2tp_session *session;\n\n\tBUG_ON(tunnel == NULL);\n\n\tl2tp_info(tunnel, L2TP_MSG_CONTROL, \"%s: closing all sessions...\\n\",\n\t\t  tunnel->name);\n\n\twrite_lock_bh(&tunnel->hlist_lock);\n\ttunnel->acpt_newsess = false;\n\tfor (hash = 0; hash < L2TP_HASH_SIZE; hash++) {\nagain:\n\t\thlist_for_each_safe(walk, tmp, &tunnel->session_hlist[hash]) {\n\t\t\tsession = hlist_entry(walk, struct l2tp_session, hlist);\n\n\t\t\tl2tp_info(session, L2TP_MSG_CONTROL,\n\t\t\t\t  \"%s: closing session\\n\", session->name);\n\n\t\t\thlist_del_init(&session->hlist);\n\n\t\t\tif (test_and_set_bit(0, &session->dead))\n\t\t\t\tgoto again;\n\n\t\t\tif (session->ref != NULL)\n\t\t\t\t(*session->ref)(session);\n\n\t\t\twrite_unlock_bh(&tunnel->hlist_lock);\n\n\t\t\t__l2tp_session_unhash(session);\n\t\t\tl2tp_session_queue_purge(session);\n\n\t\t\tif (session->session_close != NULL)\n\t\t\t\t(*session->session_close)(session);\n\n\t\t\tif (session->deref != NULL)\n\t\t\t\t(*session->deref)(session);\n\n\t\t\tl2tp_session_dec_refcount(session);\n\n\t\t\twrite_lock_bh(&tunnel->hlist_lock);\n\n\t\t\t/* Now restart from the beginning of this hash\n\t\t\t * chain.  We always remove a session from the\n\t\t\t * list so we are guaranteed to make forward\n\t\t\t * progress.\n\t\t\t */\n\t\t\tgoto again;\n\t\t}\n\t}\n\twrite_unlock_bh(&tunnel->hlist_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,9 @@\n \t\t\t\t  \"%s: closing session\\n\", session->name);\n \n \t\t\thlist_del_init(&session->hlist);\n+\n+\t\t\tif (test_and_set_bit(0, &session->dead))\n+\t\t\t\tgoto again;\n \n \t\t\tif (session->ref != NULL)\n \t\t\t\t(*session->ref)(session);",
        "function_modified_lines": {
            "added": [
                "",
                "\t\t\tif (test_and_set_bit(0, &session->dead))",
                "\t\t\t\tgoto again;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In l2tp_session_delete and related functions of l2tp_core.c, there is possible memory corruption due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-152735806"
    },
    {
        "cve_id": "CVE-2020-0429",
        "code_before_change": "int l2tp_session_delete(struct l2tp_session *session)\n{\n\tif (session->ref)\n\t\t(*session->ref)(session);\n\t__l2tp_session_unhash(session);\n\tl2tp_session_queue_purge(session);\n\tif (session->session_close != NULL)\n\t\t(*session->session_close)(session);\n\tif (session->deref)\n\t\t(*session->deref)(session);\n\tl2tp_session_dec_refcount(session);\n\treturn 0;\n}",
        "code_after_change": "int l2tp_session_delete(struct l2tp_session *session)\n{\n\tif (test_and_set_bit(0, &session->dead))\n\t\treturn 0;\n\n\tif (session->ref)\n\t\t(*session->ref)(session);\n\t__l2tp_session_unhash(session);\n\tl2tp_session_queue_purge(session);\n\tif (session->session_close != NULL)\n\t\t(*session->session_close)(session);\n\tif (session->deref)\n\t\t(*session->deref)(session);\n\tl2tp_session_dec_refcount(session);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,8 @@\n int l2tp_session_delete(struct l2tp_session *session)\n {\n+\tif (test_and_set_bit(0, &session->dead))\n+\t\treturn 0;\n+\n \tif (session->ref)\n \t\t(*session->ref)(session);\n \t__l2tp_session_unhash(session);",
        "function_modified_lines": {
            "added": [
                "\tif (test_and_set_bit(0, &session->dead))",
                "\t\treturn 0;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In l2tp_session_delete and related functions of l2tp_core.c, there is possible memory corruption due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-152735806"
    },
    {
        "cve_id": "CVE-2020-0432",
        "code_before_change": "static int skb_to_mep(const struct sk_buff *skb, struct mbo *mbo)\n{\n\tu8 *buff = mbo->virt_address;\n\tunsigned int mep_len = skb->len + MEP_HDR_LEN;\n\n\tif (mbo->buffer_length < mep_len) {\n\t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",\n\t\t       mbo->buffer_length, mep_len);\n\t\treturn -EINVAL;\n\t}\n\n\t*buff++ = HB(mep_len - 2);\n\t*buff++ = LB(mep_len - 2);\n\n\t*buff++ = PMHL;\n\t*buff++ = (PMS_FIFONO_MEP << PMS_FIFONO_SHIFT) | PMS_MSGTYPE_DATA;\n\t*buff++ = (MEP_DEF_RETRY << PMS_RETRY_SHIFT) | PMS_DEF_PRIO;\n\t*buff++ = 0;\n\t*buff++ = 0;\n\t*buff++ = 0;\n\n\tmemcpy(buff, skb->data, skb->len);\n\tmbo->buffer_length = mep_len;\n\treturn 0;\n}",
        "code_after_change": "static int skb_to_mep(const struct sk_buff *skb, struct mbo *mbo)\n{\n\tu8 *buff = mbo->virt_address;\n\tunsigned int mep_len = skb->len + MEP_HDR_LEN;\n\n\tif (mep_len < skb->len) {\n\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (mbo->buffer_length < mep_len) {\n\t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",\n\t\t       mbo->buffer_length, mep_len);\n\t\treturn -EINVAL;\n\t}\n\n\t*buff++ = HB(mep_len - 2);\n\t*buff++ = LB(mep_len - 2);\n\n\t*buff++ = PMHL;\n\t*buff++ = (PMS_FIFONO_MEP << PMS_FIFONO_SHIFT) | PMS_MSGTYPE_DATA;\n\t*buff++ = (MEP_DEF_RETRY << PMS_RETRY_SHIFT) | PMS_DEF_PRIO;\n\t*buff++ = 0;\n\t*buff++ = 0;\n\t*buff++ = 0;\n\n\tmemcpy(buff, skb->data, skb->len);\n\tmbo->buffer_length = mep_len;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,11 @@\n {\n \tu8 *buff = mbo->virt_address;\n \tunsigned int mep_len = skb->len + MEP_HDR_LEN;\n+\n+\tif (mep_len < skb->len) {\n+\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);\n+\t\treturn -EINVAL;\n+\t}\n \n \tif (mbo->buffer_length < mep_len) {\n \t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (mep_len < skb->len) {",
                "\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "In skb_to_mamac of networking.c, there is a possible out of bounds write due to an integer overflow. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-143560807"
    },
    {
        "cve_id": "CVE-2020-0432",
        "code_before_change": "static int skb_to_mamac(const struct sk_buff *skb, struct mbo *mbo)\n{\n\tu8 *buff = mbo->virt_address;\n\tstatic const u8 broadcast[] = { 0x03, 0xFF };\n\tconst u8 *dest_addr = skb->data + 4;\n\tconst u8 *eth_type = skb->data + 12;\n\tunsigned int payload_len = skb->len - ETH_HLEN;\n\tunsigned int mdp_len = payload_len + MDP_HDR_LEN;\n\n\tif (mbo->buffer_length < mdp_len) {\n\t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",\n\t\t       mbo->buffer_length, mdp_len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (skb->len < ETH_HLEN) {\n\t\tpr_err(\"drop: too small packet! (%d)\\n\", skb->len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (dest_addr[0] == 0xFF && dest_addr[1] == 0xFF)\n\t\tdest_addr = broadcast;\n\n\t*buff++ = HB(mdp_len - 2);\n\t*buff++ = LB(mdp_len - 2);\n\n\t*buff++ = PMHL;\n\t*buff++ = (PMS_FIFONO_MDP << PMS_FIFONO_SHIFT) | PMS_MSGTYPE_DATA;\n\t*buff++ = PMS_DEF_PRIO;\n\t*buff++ = dest_addr[0];\n\t*buff++ = dest_addr[1];\n\t*buff++ = 0x00;\n\n\t*buff++ = HB(payload_len + 6);\n\t*buff++ = LB(payload_len + 6);\n\n\t/* end of FPH here */\n\n\t*buff++ = eth_type[0];\n\t*buff++ = eth_type[1];\n\t*buff++ = 0;\n\t*buff++ = 0;\n\n\t*buff++ = PMS_TELID_UNSEGM_MAMAC << 4 | HB(payload_len);\n\t*buff++ = LB(payload_len);\n\n\tmemcpy(buff, skb->data + ETH_HLEN, payload_len);\n\tmbo->buffer_length = mdp_len;\n\treturn 0;\n}",
        "code_after_change": "static int skb_to_mamac(const struct sk_buff *skb, struct mbo *mbo)\n{\n\tu8 *buff = mbo->virt_address;\n\tstatic const u8 broadcast[] = { 0x03, 0xFF };\n\tconst u8 *dest_addr = skb->data + 4;\n\tconst u8 *eth_type = skb->data + 12;\n\tunsigned int payload_len = skb->len - ETH_HLEN;\n\tunsigned int mdp_len = payload_len + MDP_HDR_LEN;\n\n\tif (mdp_len < skb->len) {\n\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (mbo->buffer_length < mdp_len) {\n\t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",\n\t\t       mbo->buffer_length, mdp_len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (skb->len < ETH_HLEN) {\n\t\tpr_err(\"drop: too small packet! (%d)\\n\", skb->len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (dest_addr[0] == 0xFF && dest_addr[1] == 0xFF)\n\t\tdest_addr = broadcast;\n\n\t*buff++ = HB(mdp_len - 2);\n\t*buff++ = LB(mdp_len - 2);\n\n\t*buff++ = PMHL;\n\t*buff++ = (PMS_FIFONO_MDP << PMS_FIFONO_SHIFT) | PMS_MSGTYPE_DATA;\n\t*buff++ = PMS_DEF_PRIO;\n\t*buff++ = dest_addr[0];\n\t*buff++ = dest_addr[1];\n\t*buff++ = 0x00;\n\n\t*buff++ = HB(payload_len + 6);\n\t*buff++ = LB(payload_len + 6);\n\n\t/* end of FPH here */\n\n\t*buff++ = eth_type[0];\n\t*buff++ = eth_type[1];\n\t*buff++ = 0;\n\t*buff++ = 0;\n\n\t*buff++ = PMS_TELID_UNSEGM_MAMAC << 4 | HB(payload_len);\n\t*buff++ = LB(payload_len);\n\n\tmemcpy(buff, skb->data + ETH_HLEN, payload_len);\n\tmbo->buffer_length = mdp_len;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,11 @@\n \tconst u8 *eth_type = skb->data + 12;\n \tunsigned int payload_len = skb->len - ETH_HLEN;\n \tunsigned int mdp_len = payload_len + MDP_HDR_LEN;\n+\n+\tif (mdp_len < skb->len) {\n+\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);\n+\t\treturn -EINVAL;\n+\t}\n \n \tif (mbo->buffer_length < mdp_len) {\n \t\tpr_err(\"drop: too small buffer! (%d for %d)\\n\",",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (mdp_len < skb->len) {",
                "\t\tpr_err(\"drop: too large packet! (%u)\\n\", skb->len);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "In skb_to_mamac of networking.c, there is a possible out of bounds write due to an integer overflow. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-143560807"
    },
    {
        "cve_id": "CVE-2020-0465",
        "code_before_change": "static void hidinput_configure_usage(struct hid_input *hidinput, struct hid_field *field,\n\t\t\t\t     struct hid_usage *usage)\n{\n\tstruct input_dev *input = hidinput->input;\n\tstruct hid_device *device = input_get_drvdata(input);\n\tint max = 0, code;\n\tunsigned long *bit = NULL;\n\n\tfield->hidinput = hidinput;\n\n\tif (field->flags & HID_MAIN_ITEM_CONSTANT)\n\t\tgoto ignore;\n\n\t/* Ignore if report count is out of bounds. */\n\tif (field->report_count < 1)\n\t\tgoto ignore;\n\n\t/* only LED usages are supported in output fields */\n\tif (field->report_type == HID_OUTPUT_REPORT &&\n\t\t\t(usage->hid & HID_USAGE_PAGE) != HID_UP_LED) {\n\t\tgoto ignore;\n\t}\n\n\tif (device->driver->input_mapping) {\n\t\tint ret = device->driver->input_mapping(device, hidinput, field,\n\t\t\t\tusage, &bit, &max);\n\t\tif (ret > 0)\n\t\t\tgoto mapped;\n\t\tif (ret < 0)\n\t\t\tgoto ignore;\n\t}\n\n\tswitch (usage->hid & HID_USAGE_PAGE) {\n\tcase HID_UP_UNDEFINED:\n\t\tgoto ignore;\n\n\tcase HID_UP_KEYBOARD:\n\t\tset_bit(EV_REP, input->evbit);\n\n\t\tif ((usage->hid & HID_USAGE) < 256) {\n\t\t\tif (!hid_keyboard[usage->hid & HID_USAGE]) goto ignore;\n\t\t\tmap_key_clear(hid_keyboard[usage->hid & HID_USAGE]);\n\t\t} else\n\t\t\tmap_key(KEY_UNKNOWN);\n\n\t\tbreak;\n\n\tcase HID_UP_BUTTON:\n\t\tcode = ((usage->hid - 1) & HID_USAGE);\n\n\t\tswitch (field->application) {\n\t\tcase HID_GD_MOUSE:\n\t\tcase HID_GD_POINTER:  code += BTN_MOUSE; break;\n\t\tcase HID_GD_JOYSTICK:\n\t\t\t\tif (code <= 0xf)\n\t\t\t\t\tcode += BTN_JOYSTICK;\n\t\t\t\telse\n\t\t\t\t\tcode += BTN_TRIGGER_HAPPY - 0x10;\n\t\t\t\tbreak;\n\t\tcase HID_GD_GAMEPAD:\n\t\t\t\tif (code <= 0xf)\n\t\t\t\t\tcode += BTN_GAMEPAD;\n\t\t\t\telse\n\t\t\t\t\tcode += BTN_TRIGGER_HAPPY - 0x10;\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tswitch (field->physical) {\n\t\t\tcase HID_GD_MOUSE:\n\t\t\tcase HID_GD_POINTER:  code += BTN_MOUSE; break;\n\t\t\tcase HID_GD_JOYSTICK: code += BTN_JOYSTICK; break;\n\t\t\tcase HID_GD_GAMEPAD:  code += BTN_GAMEPAD; break;\n\t\t\tdefault:              code += BTN_MISC;\n\t\t\t}\n\t\t}\n\n\t\tmap_key(code);\n\t\tbreak;\n\n\tcase HID_UP_SIMULATION:\n\t\tswitch (usage->hid & 0xffff) {\n\t\tcase 0xba: map_abs(ABS_RUDDER);   break;\n\t\tcase 0xbb: map_abs(ABS_THROTTLE); break;\n\t\tcase 0xc4: map_abs(ABS_GAS);      break;\n\t\tcase 0xc5: map_abs(ABS_BRAKE);    break;\n\t\tcase 0xc8: map_abs(ABS_WHEEL);    break;\n\t\tdefault:   goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_GENDESK:\n\t\tif ((usage->hid & 0xf0) == 0x80) {\t/* SystemControl */\n\t\t\tswitch (usage->hid & 0xf) {\n\t\t\tcase 0x1: map_key_clear(KEY_POWER);  break;\n\t\t\tcase 0x2: map_key_clear(KEY_SLEEP);  break;\n\t\t\tcase 0x3: map_key_clear(KEY_WAKEUP); break;\n\t\t\tcase 0x4: map_key_clear(KEY_CONTEXT_MENU); break;\n\t\t\tcase 0x5: map_key_clear(KEY_MENU); break;\n\t\t\tcase 0x6: map_key_clear(KEY_PROG1); break;\n\t\t\tcase 0x7: map_key_clear(KEY_HELP); break;\n\t\t\tcase 0x8: map_key_clear(KEY_EXIT); break;\n\t\t\tcase 0x9: map_key_clear(KEY_SELECT); break;\n\t\t\tcase 0xa: map_key_clear(KEY_RIGHT); break;\n\t\t\tcase 0xb: map_key_clear(KEY_LEFT); break;\n\t\t\tcase 0xc: map_key_clear(KEY_UP); break;\n\t\t\tcase 0xd: map_key_clear(KEY_DOWN); break;\n\t\t\tcase 0xe: map_key_clear(KEY_POWER2); break;\n\t\t\tcase 0xf: map_key_clear(KEY_RESTART); break;\n\t\t\tdefault: goto unknown;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((usage->hid & 0xf0) == 0xb0) {\t/* SC - Display */\n\t\t\tswitch (usage->hid & 0xf) {\n\t\t\tcase 0x05: map_key_clear(KEY_SWITCHVIDEOMODE); break;\n\t\t\tdefault: goto ignore;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Some lazy vendors declare 255 usages for System Control,\n\t\t * leading to the creation of ABS_X|Y axis and too many others.\n\t\t * It wouldn't be a problem if joydev doesn't consider the\n\t\t * device as a joystick then.\n\t\t */\n\t\tif (field->application == HID_GD_SYSTEM_CONTROL)\n\t\t\tgoto ignore;\n\n\t\tif ((usage->hid & 0xf0) == 0x90) {\t/* D-pad */\n\t\t\tswitch (usage->hid) {\n\t\t\tcase HID_GD_UP:\t   usage->hat_dir = 1; break;\n\t\t\tcase HID_GD_DOWN:  usage->hat_dir = 5; break;\n\t\t\tcase HID_GD_RIGHT: usage->hat_dir = 3; break;\n\t\t\tcase HID_GD_LEFT:  usage->hat_dir = 7; break;\n\t\t\tdefault: goto unknown;\n\t\t\t}\n\t\t\tif (field->dpad) {\n\t\t\t\tmap_abs(field->dpad);\n\t\t\t\tgoto ignore;\n\t\t\t}\n\t\t\tmap_abs(ABS_HAT0X);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (usage->hid) {\n\t\t/* These usage IDs map directly to the usage codes. */\n\t\tcase HID_GD_X: case HID_GD_Y: case HID_GD_Z:\n\t\tcase HID_GD_RX: case HID_GD_RY: case HID_GD_RZ:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE)\n\t\t\t\tmap_rel(usage->hid & 0xf);\n\t\t\telse\n\t\t\t\tmap_abs_clear(usage->hid & 0xf);\n\t\t\tbreak;\n\n\t\tcase HID_GD_WHEEL:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE) {\n\t\t\t\tset_bit(REL_WHEEL, input->relbit);\n\t\t\t\tmap_rel(REL_WHEEL_HI_RES);\n\t\t\t} else {\n\t\t\t\tmap_abs(usage->hid & 0xf);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase HID_GD_SLIDER: case HID_GD_DIAL:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE)\n\t\t\t\tmap_rel(usage->hid & 0xf);\n\t\t\telse\n\t\t\t\tmap_abs(usage->hid & 0xf);\n\t\t\tbreak;\n\n\t\tcase HID_GD_HATSWITCH:\n\t\t\tusage->hat_min = field->logical_minimum;\n\t\t\tusage->hat_max = field->logical_maximum;\n\t\t\tmap_abs(ABS_HAT0X);\n\t\t\tbreak;\n\n\t\tcase HID_GD_START:\tmap_key_clear(BTN_START);\tbreak;\n\t\tcase HID_GD_SELECT:\tmap_key_clear(BTN_SELECT);\tbreak;\n\n\t\tcase HID_GD_RFKILL_BTN:\n\t\t\t/* MS wireless radio ctl extension, also check CA */\n\t\t\tif (field->application == HID_GD_WIRELESS_RADIO_CTLS) {\n\t\t\t\tmap_key_clear(KEY_RFKILL);\n\t\t\t\t/* We need to simulate the btn release */\n\t\t\t\tfield->flags |= HID_MAIN_ITEM_RELATIVE;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault: goto unknown;\n\t\t}\n\n\t\tbreak;\n\n\tcase HID_UP_LED:\n\t\tswitch (usage->hid & 0xffff) {\t\t      /* HID-Value:                   */\n\t\tcase 0x01:  map_led (LED_NUML);     break;    /*   \"Num Lock\"                 */\n\t\tcase 0x02:  map_led (LED_CAPSL);    break;    /*   \"Caps Lock\"                */\n\t\tcase 0x03:  map_led (LED_SCROLLL);  break;    /*   \"Scroll Lock\"              */\n\t\tcase 0x04:  map_led (LED_COMPOSE);  break;    /*   \"Compose\"                  */\n\t\tcase 0x05:  map_led (LED_KANA);     break;    /*   \"Kana\"                     */\n\t\tcase 0x27:  map_led (LED_SLEEP);    break;    /*   \"Stand-By\"                 */\n\t\tcase 0x4c:  map_led (LED_SUSPEND);  break;    /*   \"System Suspend\"           */\n\t\tcase 0x09:  map_led (LED_MUTE);     break;    /*   \"Mute\"                     */\n\t\tcase 0x4b:  map_led (LED_MISC);     break;    /*   \"Generic Indicator\"        */\n\t\tcase 0x19:  map_led (LED_MAIL);     break;    /*   \"Message Waiting\"          */\n\t\tcase 0x4d:  map_led (LED_CHARGING); break;    /*   \"External Power Connected\" */\n\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_DIGITIZER:\n\t\tif ((field->application & 0xff) == 0x01) /* Digitizer */\n\t\t\t__set_bit(INPUT_PROP_POINTER, input->propbit);\n\t\telse if ((field->application & 0xff) == 0x02) /* Pen */\n\t\t\t__set_bit(INPUT_PROP_DIRECT, input->propbit);\n\n\t\tswitch (usage->hid & 0xff) {\n\t\tcase 0x00: /* Undefined */\n\t\t\tgoto ignore;\n\n\t\tcase 0x30: /* TipPressure */\n\t\t\tif (!test_bit(BTN_TOUCH, input->keybit)) {\n\t\t\t\tdevice->quirks |= HID_QUIRK_NOTOUCH;\n\t\t\t\tset_bit(EV_KEY, input->evbit);\n\t\t\t\tset_bit(BTN_TOUCH, input->keybit);\n\t\t\t}\n\t\t\tmap_abs_clear(ABS_PRESSURE);\n\t\t\tbreak;\n\n\t\tcase 0x32: /* InRange */\n\t\t\tswitch (field->physical & 0xff) {\n\t\t\tcase 0x21: map_key(BTN_TOOL_MOUSE); break;\n\t\t\tcase 0x22: map_key(BTN_TOOL_FINGER); break;\n\t\t\tdefault: map_key(BTN_TOOL_PEN); break;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase 0x3b: /* Battery Strength */\n\t\t\thidinput_setup_battery(device, HID_INPUT_REPORT, field);\n\t\t\tusage->type = EV_PWR;\n\t\t\tgoto ignore;\n\n\t\tcase 0x3c: /* Invert */\n\t\t\tmap_key_clear(BTN_TOOL_RUBBER);\n\t\t\tbreak;\n\n\t\tcase 0x3d: /* X Tilt */\n\t\t\tmap_abs_clear(ABS_TILT_X);\n\t\t\tbreak;\n\n\t\tcase 0x3e: /* Y Tilt */\n\t\t\tmap_abs_clear(ABS_TILT_Y);\n\t\t\tbreak;\n\n\t\tcase 0x33: /* Touch */\n\t\tcase 0x42: /* TipSwitch */\n\t\tcase 0x43: /* TipSwitch2 */\n\t\t\tdevice->quirks &= ~HID_QUIRK_NOTOUCH;\n\t\t\tmap_key_clear(BTN_TOUCH);\n\t\t\tbreak;\n\n\t\tcase 0x44: /* BarrelSwitch */\n\t\t\tmap_key_clear(BTN_STYLUS);\n\t\t\tbreak;\n\n\t\tcase 0x45: /* ERASER */\n\t\t\t/*\n\t\t\t * This event is reported when eraser tip touches the surface.\n\t\t\t * Actual eraser (BTN_TOOL_RUBBER) is set by Invert usage when\n\t\t\t * tool gets in proximity.\n\t\t\t */\n\t\t\tmap_key_clear(BTN_TOUCH);\n\t\t\tbreak;\n\n\t\tcase 0x46: /* TabletPick */\n\t\tcase 0x5a: /* SecondaryBarrelSwitch */\n\t\t\tmap_key_clear(BTN_STYLUS2);\n\t\t\tbreak;\n\n\t\tcase 0x5b: /* TransducerSerialNumber */\n\t\t\tusage->type = EV_MSC;\n\t\t\tusage->code = MSC_SERIAL;\n\t\t\tbit = input->mscbit;\n\t\t\tmax = MSC_MAX;\n\t\t\tbreak;\n\n\t\tdefault:  goto unknown;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_TELEPHONY:\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x2f: map_key_clear(KEY_MICMUTE);\t\tbreak;\n\t\tcase 0xb0: map_key_clear(KEY_NUMERIC_0);\tbreak;\n\t\tcase 0xb1: map_key_clear(KEY_NUMERIC_1);\tbreak;\n\t\tcase 0xb2: map_key_clear(KEY_NUMERIC_2);\tbreak;\n\t\tcase 0xb3: map_key_clear(KEY_NUMERIC_3);\tbreak;\n\t\tcase 0xb4: map_key_clear(KEY_NUMERIC_4);\tbreak;\n\t\tcase 0xb5: map_key_clear(KEY_NUMERIC_5);\tbreak;\n\t\tcase 0xb6: map_key_clear(KEY_NUMERIC_6);\tbreak;\n\t\tcase 0xb7: map_key_clear(KEY_NUMERIC_7);\tbreak;\n\t\tcase 0xb8: map_key_clear(KEY_NUMERIC_8);\tbreak;\n\t\tcase 0xb9: map_key_clear(KEY_NUMERIC_9);\tbreak;\n\t\tcase 0xba: map_key_clear(KEY_NUMERIC_STAR);\tbreak;\n\t\tcase 0xbb: map_key_clear(KEY_NUMERIC_POUND);\tbreak;\n\t\tcase 0xbc: map_key_clear(KEY_NUMERIC_A);\tbreak;\n\t\tcase 0xbd: map_key_clear(KEY_NUMERIC_B);\tbreak;\n\t\tcase 0xbe: map_key_clear(KEY_NUMERIC_C);\tbreak;\n\t\tcase 0xbf: map_key_clear(KEY_NUMERIC_D);\tbreak;\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_CONSUMER:\t/* USB HUT v1.12, pages 75-84 */\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x000: goto ignore;\n\t\tcase 0x030: map_key_clear(KEY_POWER);\t\tbreak;\n\t\tcase 0x031: map_key_clear(KEY_RESTART);\t\tbreak;\n\t\tcase 0x032: map_key_clear(KEY_SLEEP);\t\tbreak;\n\t\tcase 0x034: map_key_clear(KEY_SLEEP);\t\tbreak;\n\t\tcase 0x035: map_key_clear(KEY_KBDILLUMTOGGLE);\tbreak;\n\t\tcase 0x036: map_key_clear(BTN_MISC);\t\tbreak;\n\n\t\tcase 0x040: map_key_clear(KEY_MENU);\t\tbreak; /* Menu */\n\t\tcase 0x041: map_key_clear(KEY_SELECT);\t\tbreak; /* Menu Pick */\n\t\tcase 0x042: map_key_clear(KEY_UP);\t\tbreak; /* Menu Up */\n\t\tcase 0x043: map_key_clear(KEY_DOWN);\t\tbreak; /* Menu Down */\n\t\tcase 0x044: map_key_clear(KEY_LEFT);\t\tbreak; /* Menu Left */\n\t\tcase 0x045: map_key_clear(KEY_RIGHT);\t\tbreak; /* Menu Right */\n\t\tcase 0x046: map_key_clear(KEY_ESC);\t\tbreak; /* Menu Escape */\n\t\tcase 0x047: map_key_clear(KEY_KPPLUS);\t\tbreak; /* Menu Value Increase */\n\t\tcase 0x048: map_key_clear(KEY_KPMINUS);\t\tbreak; /* Menu Value Decrease */\n\n\t\tcase 0x060: map_key_clear(KEY_INFO);\t\tbreak; /* Data On Screen */\n\t\tcase 0x061: map_key_clear(KEY_SUBTITLE);\tbreak; /* Closed Caption */\n\t\tcase 0x063: map_key_clear(KEY_VCR);\t\tbreak; /* VCR/TV */\n\t\tcase 0x065: map_key_clear(KEY_CAMERA);\t\tbreak; /* Snapshot */\n\t\tcase 0x069: map_key_clear(KEY_RED);\t\tbreak;\n\t\tcase 0x06a: map_key_clear(KEY_GREEN);\t\tbreak;\n\t\tcase 0x06b: map_key_clear(KEY_BLUE);\t\tbreak;\n\t\tcase 0x06c: map_key_clear(KEY_YELLOW);\t\tbreak;\n\t\tcase 0x06d: map_key_clear(KEY_ASPECT_RATIO);\tbreak;\n\n\t\tcase 0x06f: map_key_clear(KEY_BRIGHTNESSUP);\t\tbreak;\n\t\tcase 0x070: map_key_clear(KEY_BRIGHTNESSDOWN);\t\tbreak;\n\t\tcase 0x072: map_key_clear(KEY_BRIGHTNESS_TOGGLE);\tbreak;\n\t\tcase 0x073: map_key_clear(KEY_BRIGHTNESS_MIN);\t\tbreak;\n\t\tcase 0x074: map_key_clear(KEY_BRIGHTNESS_MAX);\t\tbreak;\n\t\tcase 0x075: map_key_clear(KEY_BRIGHTNESS_AUTO);\t\tbreak;\n\n\t\tcase 0x079: map_key_clear(KEY_KBDILLUMUP);\tbreak;\n\t\tcase 0x07a: map_key_clear(KEY_KBDILLUMDOWN);\tbreak;\n\t\tcase 0x07c: map_key_clear(KEY_KBDILLUMTOGGLE);\tbreak;\n\n\t\tcase 0x082: map_key_clear(KEY_VIDEO_NEXT);\tbreak;\n\t\tcase 0x083: map_key_clear(KEY_LAST);\t\tbreak;\n\t\tcase 0x084: map_key_clear(KEY_ENTER);\t\tbreak;\n\t\tcase 0x088: map_key_clear(KEY_PC);\t\tbreak;\n\t\tcase 0x089: map_key_clear(KEY_TV);\t\tbreak;\n\t\tcase 0x08a: map_key_clear(KEY_WWW);\t\tbreak;\n\t\tcase 0x08b: map_key_clear(KEY_DVD);\t\tbreak;\n\t\tcase 0x08c: map_key_clear(KEY_PHONE);\t\tbreak;\n\t\tcase 0x08d: map_key_clear(KEY_PROGRAM);\t\tbreak;\n\t\tcase 0x08e: map_key_clear(KEY_VIDEOPHONE);\tbreak;\n\t\tcase 0x08f: map_key_clear(KEY_GAMES);\t\tbreak;\n\t\tcase 0x090: map_key_clear(KEY_MEMO);\t\tbreak;\n\t\tcase 0x091: map_key_clear(KEY_CD);\t\tbreak;\n\t\tcase 0x092: map_key_clear(KEY_VCR);\t\tbreak;\n\t\tcase 0x093: map_key_clear(KEY_TUNER);\t\tbreak;\n\t\tcase 0x094: map_key_clear(KEY_EXIT);\t\tbreak;\n\t\tcase 0x095: map_key_clear(KEY_HELP);\t\tbreak;\n\t\tcase 0x096: map_key_clear(KEY_TAPE);\t\tbreak;\n\t\tcase 0x097: map_key_clear(KEY_TV2);\t\tbreak;\n\t\tcase 0x098: map_key_clear(KEY_SAT);\t\tbreak;\n\t\tcase 0x09a: map_key_clear(KEY_PVR);\t\tbreak;\n\n\t\tcase 0x09c: map_key_clear(KEY_CHANNELUP);\tbreak;\n\t\tcase 0x09d: map_key_clear(KEY_CHANNELDOWN);\tbreak;\n\t\tcase 0x0a0: map_key_clear(KEY_VCR2);\t\tbreak;\n\n\t\tcase 0x0b0: map_key_clear(KEY_PLAY);\t\tbreak;\n\t\tcase 0x0b1: map_key_clear(KEY_PAUSE);\t\tbreak;\n\t\tcase 0x0b2: map_key_clear(KEY_RECORD);\t\tbreak;\n\t\tcase 0x0b3: map_key_clear(KEY_FASTFORWARD);\tbreak;\n\t\tcase 0x0b4: map_key_clear(KEY_REWIND);\t\tbreak;\n\t\tcase 0x0b5: map_key_clear(KEY_NEXTSONG);\tbreak;\n\t\tcase 0x0b6: map_key_clear(KEY_PREVIOUSSONG);\tbreak;\n\t\tcase 0x0b7: map_key_clear(KEY_STOPCD);\t\tbreak;\n\t\tcase 0x0b8: map_key_clear(KEY_EJECTCD);\t\tbreak;\n\t\tcase 0x0bc: map_key_clear(KEY_MEDIA_REPEAT);\tbreak;\n\t\tcase 0x0b9: map_key_clear(KEY_SHUFFLE);\t\tbreak;\n\t\tcase 0x0bf: map_key_clear(KEY_SLOW);\t\tbreak;\n\n\t\tcase 0x0cd: map_key_clear(KEY_PLAYPAUSE);\tbreak;\n\t\tcase 0x0cf: map_key_clear(KEY_VOICECOMMAND);\tbreak;\n\t\tcase 0x0e0: map_abs_clear(ABS_VOLUME);\t\tbreak;\n\t\tcase 0x0e2: map_key_clear(KEY_MUTE);\t\tbreak;\n\t\tcase 0x0e5: map_key_clear(KEY_BASSBOOST);\tbreak;\n\t\tcase 0x0e9: map_key_clear(KEY_VOLUMEUP);\tbreak;\n\t\tcase 0x0ea: map_key_clear(KEY_VOLUMEDOWN);\tbreak;\n\t\tcase 0x0f5: map_key_clear(KEY_SLOW);\t\tbreak;\n\n\t\tcase 0x181: map_key_clear(KEY_BUTTONCONFIG);\tbreak;\n\t\tcase 0x182: map_key_clear(KEY_BOOKMARKS);\tbreak;\n\t\tcase 0x183: map_key_clear(KEY_CONFIG);\t\tbreak;\n\t\tcase 0x184: map_key_clear(KEY_WORDPROCESSOR);\tbreak;\n\t\tcase 0x185: map_key_clear(KEY_EDITOR);\t\tbreak;\n\t\tcase 0x186: map_key_clear(KEY_SPREADSHEET);\tbreak;\n\t\tcase 0x187: map_key_clear(KEY_GRAPHICSEDITOR);\tbreak;\n\t\tcase 0x188: map_key_clear(KEY_PRESENTATION);\tbreak;\n\t\tcase 0x189: map_key_clear(KEY_DATABASE);\tbreak;\n\t\tcase 0x18a: map_key_clear(KEY_MAIL);\t\tbreak;\n\t\tcase 0x18b: map_key_clear(KEY_NEWS);\t\tbreak;\n\t\tcase 0x18c: map_key_clear(KEY_VOICEMAIL);\tbreak;\n\t\tcase 0x18d: map_key_clear(KEY_ADDRESSBOOK);\tbreak;\n\t\tcase 0x18e: map_key_clear(KEY_CALENDAR);\tbreak;\n\t\tcase 0x18f: map_key_clear(KEY_TASKMANAGER);\tbreak;\n\t\tcase 0x190: map_key_clear(KEY_JOURNAL);\t\tbreak;\n\t\tcase 0x191: map_key_clear(KEY_FINANCE);\t\tbreak;\n\t\tcase 0x192: map_key_clear(KEY_CALC);\t\tbreak;\n\t\tcase 0x193: map_key_clear(KEY_PLAYER);\t\tbreak;\n\t\tcase 0x194: map_key_clear(KEY_FILE);\t\tbreak;\n\t\tcase 0x196: map_key_clear(KEY_WWW);\t\tbreak;\n\t\tcase 0x199: map_key_clear(KEY_CHAT);\t\tbreak;\n\t\tcase 0x19c: map_key_clear(KEY_LOGOFF);\t\tbreak;\n\t\tcase 0x19e: map_key_clear(KEY_COFFEE);\t\tbreak;\n\t\tcase 0x19f: map_key_clear(KEY_CONTROLPANEL);\t\tbreak;\n\t\tcase 0x1a2: map_key_clear(KEY_APPSELECT);\t\tbreak;\n\t\tcase 0x1a3: map_key_clear(KEY_NEXT);\t\tbreak;\n\t\tcase 0x1a4: map_key_clear(KEY_PREVIOUS);\tbreak;\n\t\tcase 0x1a6: map_key_clear(KEY_HELP);\t\tbreak;\n\t\tcase 0x1a7: map_key_clear(KEY_DOCUMENTS);\tbreak;\n\t\tcase 0x1ab: map_key_clear(KEY_SPELLCHECK);\tbreak;\n\t\tcase 0x1ae: map_key_clear(KEY_KEYBOARD);\tbreak;\n\t\tcase 0x1b1: map_key_clear(KEY_SCREENSAVER);\t\tbreak;\n\t\tcase 0x1b4: map_key_clear(KEY_FILE);\t\tbreak;\n\t\tcase 0x1b6: map_key_clear(KEY_IMAGES);\t\tbreak;\n\t\tcase 0x1b7: map_key_clear(KEY_AUDIO);\t\tbreak;\n\t\tcase 0x1b8: map_key_clear(KEY_VIDEO);\t\tbreak;\n\t\tcase 0x1bc: map_key_clear(KEY_MESSENGER);\tbreak;\n\t\tcase 0x1bd: map_key_clear(KEY_INFO);\t\tbreak;\n\t\tcase 0x1cb: map_key_clear(KEY_ASSISTANT);\tbreak;\n\t\tcase 0x201: map_key_clear(KEY_NEW);\t\tbreak;\n\t\tcase 0x202: map_key_clear(KEY_OPEN);\t\tbreak;\n\t\tcase 0x203: map_key_clear(KEY_CLOSE);\t\tbreak;\n\t\tcase 0x204: map_key_clear(KEY_EXIT);\t\tbreak;\n\t\tcase 0x207: map_key_clear(KEY_SAVE);\t\tbreak;\n\t\tcase 0x208: map_key_clear(KEY_PRINT);\t\tbreak;\n\t\tcase 0x209: map_key_clear(KEY_PROPS);\t\tbreak;\n\t\tcase 0x21a: map_key_clear(KEY_UNDO);\t\tbreak;\n\t\tcase 0x21b: map_key_clear(KEY_COPY);\t\tbreak;\n\t\tcase 0x21c: map_key_clear(KEY_CUT);\t\tbreak;\n\t\tcase 0x21d: map_key_clear(KEY_PASTE);\t\tbreak;\n\t\tcase 0x21f: map_key_clear(KEY_FIND);\t\tbreak;\n\t\tcase 0x221: map_key_clear(KEY_SEARCH);\t\tbreak;\n\t\tcase 0x222: map_key_clear(KEY_GOTO);\t\tbreak;\n\t\tcase 0x223: map_key_clear(KEY_HOMEPAGE);\tbreak;\n\t\tcase 0x224: map_key_clear(KEY_BACK);\t\tbreak;\n\t\tcase 0x225: map_key_clear(KEY_FORWARD);\t\tbreak;\n\t\tcase 0x226: map_key_clear(KEY_STOP);\t\tbreak;\n\t\tcase 0x227: map_key_clear(KEY_REFRESH);\t\tbreak;\n\t\tcase 0x22a: map_key_clear(KEY_BOOKMARKS);\tbreak;\n\t\tcase 0x22d: map_key_clear(KEY_ZOOMIN);\t\tbreak;\n\t\tcase 0x22e: map_key_clear(KEY_ZOOMOUT);\t\tbreak;\n\t\tcase 0x22f: map_key_clear(KEY_ZOOMRESET);\tbreak;\n\t\tcase 0x232: map_key_clear(KEY_FULL_SCREEN);\tbreak;\n\t\tcase 0x233: map_key_clear(KEY_SCROLLUP);\tbreak;\n\t\tcase 0x234: map_key_clear(KEY_SCROLLDOWN);\tbreak;\n\t\tcase 0x238: /* AC Pan */\n\t\t\tset_bit(REL_HWHEEL, input->relbit);\n\t\t\tmap_rel(REL_HWHEEL_HI_RES);\n\t\t\tbreak;\n\t\tcase 0x23d: map_key_clear(KEY_EDIT);\t\tbreak;\n\t\tcase 0x25f: map_key_clear(KEY_CANCEL);\t\tbreak;\n\t\tcase 0x269: map_key_clear(KEY_INSERT);\t\tbreak;\n\t\tcase 0x26a: map_key_clear(KEY_DELETE);\t\tbreak;\n\t\tcase 0x279: map_key_clear(KEY_REDO);\t\tbreak;\n\n\t\tcase 0x289: map_key_clear(KEY_REPLY);\t\tbreak;\n\t\tcase 0x28b: map_key_clear(KEY_FORWARDMAIL);\tbreak;\n\t\tcase 0x28c: map_key_clear(KEY_SEND);\t\tbreak;\n\n\t\tcase 0x29d: map_key_clear(KEY_KBD_LAYOUT_NEXT);\tbreak;\n\n\t\tcase 0x2c7: map_key_clear(KEY_KBDINPUTASSIST_PREV);\t\tbreak;\n\t\tcase 0x2c8: map_key_clear(KEY_KBDINPUTASSIST_NEXT);\t\tbreak;\n\t\tcase 0x2c9: map_key_clear(KEY_KBDINPUTASSIST_PREVGROUP);\t\tbreak;\n\t\tcase 0x2ca: map_key_clear(KEY_KBDINPUTASSIST_NEXTGROUP);\t\tbreak;\n\t\tcase 0x2cb: map_key_clear(KEY_KBDINPUTASSIST_ACCEPT);\tbreak;\n\t\tcase 0x2cc: map_key_clear(KEY_KBDINPUTASSIST_CANCEL);\tbreak;\n\n\t\tcase 0x29f: map_key_clear(KEY_SCALE);\t\tbreak;\n\n\t\tdefault: map_key_clear(KEY_UNKNOWN);\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_GENDEVCTRLS:\n\t\tswitch (usage->hid) {\n\t\tcase HID_DC_BATTERYSTRENGTH:\n\t\t\thidinput_setup_battery(device, HID_INPUT_REPORT, field);\n\t\t\tusage->type = EV_PWR;\n\t\t\tgoto ignore;\n\t\t}\n\t\tgoto unknown;\n\n\tcase HID_UP_HPVENDOR:\t/* Reported on a Dutch layout HP5308 */\n\t\tset_bit(EV_REP, input->evbit);\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x021: map_key_clear(KEY_PRINT);           break;\n\t\tcase 0x070: map_key_clear(KEY_HP);\t\tbreak;\n\t\tcase 0x071: map_key_clear(KEY_CAMERA);\t\tbreak;\n\t\tcase 0x072: map_key_clear(KEY_SOUND);\t\tbreak;\n\t\tcase 0x073: map_key_clear(KEY_QUESTION);\tbreak;\n\t\tcase 0x080: map_key_clear(KEY_EMAIL);\t\tbreak;\n\t\tcase 0x081: map_key_clear(KEY_CHAT);\t\tbreak;\n\t\tcase 0x082: map_key_clear(KEY_SEARCH);\t\tbreak;\n\t\tcase 0x083: map_key_clear(KEY_CONNECT);\t        break;\n\t\tcase 0x084: map_key_clear(KEY_FINANCE);\t\tbreak;\n\t\tcase 0x085: map_key_clear(KEY_SPORT);\t\tbreak;\n\t\tcase 0x086: map_key_clear(KEY_SHOP);\t        break;\n\t\tdefault:    goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_HPVENDOR2:\n\t\tset_bit(EV_REP, input->evbit);\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x001: map_key_clear(KEY_MICMUTE);\t\tbreak;\n\t\tcase 0x003: map_key_clear(KEY_BRIGHTNESSDOWN);\tbreak;\n\t\tcase 0x004: map_key_clear(KEY_BRIGHTNESSUP);\tbreak;\n\t\tdefault:    goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_MSVENDOR:\n\t\tgoto ignore;\n\n\tcase HID_UP_CUSTOM: /* Reported on Logitech and Apple USB keyboards */\n\t\tset_bit(EV_REP, input->evbit);\n\t\tgoto ignore;\n\n\tcase HID_UP_LOGIVENDOR:\n\t\t/* intentional fallback */\n\tcase HID_UP_LOGIVENDOR2:\n\t\t/* intentional fallback */\n\tcase HID_UP_LOGIVENDOR3:\n\t\tgoto ignore;\n\n\tcase HID_UP_PID:\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0xa4: map_key_clear(BTN_DEAD);\tbreak;\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\tunknown:\n\t\tif (field->report_size == 1) {\n\t\t\tif (field->report->type == HID_OUTPUT_REPORT) {\n\t\t\t\tmap_led(LED_MISC);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tmap_key(BTN_MISC);\n\t\t\tbreak;\n\t\t}\n\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE) {\n\t\t\tmap_rel(REL_MISC);\n\t\t\tbreak;\n\t\t}\n\t\tmap_abs(ABS_MISC);\n\t\tbreak;\n\t}\n\nmapped:\n\tif (device->driver->input_mapped &&\n\t    device->driver->input_mapped(device, hidinput, field, usage,\n\t\t\t\t\t &bit, &max) < 0) {\n\t\t/*\n\t\t * The driver indicated that no further generic handling\n\t\t * of the usage is desired.\n\t\t */\n\t\treturn;\n\t}\n\n\tset_bit(usage->type, input->evbit);\n\n\t/*\n\t * This part is *really* controversial:\n\t * - HID aims at being generic so we should do our best to export\n\t *   all incoming events\n\t * - HID describes what events are, so there is no reason for ABS_X\n\t *   to be mapped to ABS_Y\n\t * - HID is using *_MISC+N as a default value, but nothing prevents\n\t *   *_MISC+N to overwrite a legitimate even, which confuses userspace\n\t *   (for instance ABS_MISC + 7 is ABS_MT_SLOT, which has a different\n\t *   processing)\n\t *\n\t * If devices still want to use this (at their own risk), they will\n\t * have to use the quirk HID_QUIRK_INCREMENT_USAGE_ON_DUPLICATE, but\n\t * the default should be a reliable mapping.\n\t */\n\twhile (usage->code <= max && test_and_set_bit(usage->code, bit)) {\n\t\tif (device->quirks & HID_QUIRK_INCREMENT_USAGE_ON_DUPLICATE) {\n\t\t\tusage->code = find_next_zero_bit(bit,\n\t\t\t\t\t\t\t max + 1,\n\t\t\t\t\t\t\t usage->code);\n\t\t} else {\n\t\t\tdevice->status |= HID_STAT_DUP_DETECTED;\n\t\t\tgoto ignore;\n\t\t}\n\t}\n\n\tif (usage->code > max)\n\t\tgoto ignore;\n\n\tif (usage->type == EV_ABS) {\n\n\t\tint a = field->logical_minimum;\n\t\tint b = field->logical_maximum;\n\n\t\tif ((device->quirks & HID_QUIRK_BADPAD) && (usage->code == ABS_X || usage->code == ABS_Y)) {\n\t\t\ta = field->logical_minimum = 0;\n\t\t\tb = field->logical_maximum = 255;\n\t\t}\n\n\t\tif (field->application == HID_GD_GAMEPAD || field->application == HID_GD_JOYSTICK)\n\t\t\tinput_set_abs_params(input, usage->code, a, b, (b - a) >> 8, (b - a) >> 4);\n\t\telse\tinput_set_abs_params(input, usage->code, a, b, 0, 0);\n\n\t\tinput_abs_set_res(input, usage->code,\n\t\t\t\t  hidinput_calc_abs_res(field, usage->code));\n\n\t\t/* use a larger default input buffer for MT devices */\n\t\tif (usage->code == ABS_MT_POSITION_X && input->hint_events_per_packet == 0)\n\t\t\tinput_set_events_per_packet(input, 60);\n\t}\n\n\tif (usage->type == EV_ABS &&\n\t    (usage->hat_min < usage->hat_max || usage->hat_dir)) {\n\t\tint i;\n\t\tfor (i = usage->code; i < usage->code + 2 && i <= max; i++) {\n\t\t\tinput_set_abs_params(input, i, -1, 1, 0, 0);\n\t\t\tset_bit(i, input->absbit);\n\t\t}\n\t\tif (usage->hat_dir && !field->dpad)\n\t\t\tfield->dpad = usage->code;\n\t}\n\n\t/* for those devices which produce Consumer volume usage as relative,\n\t * we emulate pressing volumeup/volumedown appropriate number of times\n\t * in hidinput_hid_event()\n\t */\n\tif ((usage->type == EV_ABS) && (field->flags & HID_MAIN_ITEM_RELATIVE) &&\n\t\t\t(usage->code == ABS_VOLUME)) {\n\t\tset_bit(KEY_VOLUMEUP, input->keybit);\n\t\tset_bit(KEY_VOLUMEDOWN, input->keybit);\n\t}\n\n\tif (usage->type == EV_KEY) {\n\t\tset_bit(EV_MSC, input->evbit);\n\t\tset_bit(MSC_SCAN, input->mscbit);\n\t}\n\n\treturn;\n\nignore:\n\tusage->type = 0;\n\tusage->code = 0;\n}",
        "code_after_change": "static void hidinput_configure_usage(struct hid_input *hidinput, struct hid_field *field,\n\t\t\t\t     struct hid_usage *usage)\n{\n\tstruct input_dev *input = hidinput->input;\n\tstruct hid_device *device = input_get_drvdata(input);\n\tint max = 0, code;\n\tunsigned long *bit = NULL;\n\n\tfield->hidinput = hidinput;\n\n\tif (field->flags & HID_MAIN_ITEM_CONSTANT)\n\t\tgoto ignore;\n\n\t/* Ignore if report count is out of bounds. */\n\tif (field->report_count < 1)\n\t\tgoto ignore;\n\n\t/* only LED usages are supported in output fields */\n\tif (field->report_type == HID_OUTPUT_REPORT &&\n\t\t\t(usage->hid & HID_USAGE_PAGE) != HID_UP_LED) {\n\t\tgoto ignore;\n\t}\n\n\tif (device->driver->input_mapping) {\n\t\tint ret = device->driver->input_mapping(device, hidinput, field,\n\t\t\t\tusage, &bit, &max);\n\t\tif (ret > 0)\n\t\t\tgoto mapped;\n\t\tif (ret < 0)\n\t\t\tgoto ignore;\n\t}\n\n\tswitch (usage->hid & HID_USAGE_PAGE) {\n\tcase HID_UP_UNDEFINED:\n\t\tgoto ignore;\n\n\tcase HID_UP_KEYBOARD:\n\t\tset_bit(EV_REP, input->evbit);\n\n\t\tif ((usage->hid & HID_USAGE) < 256) {\n\t\t\tif (!hid_keyboard[usage->hid & HID_USAGE]) goto ignore;\n\t\t\tmap_key_clear(hid_keyboard[usage->hid & HID_USAGE]);\n\t\t} else\n\t\t\tmap_key(KEY_UNKNOWN);\n\n\t\tbreak;\n\n\tcase HID_UP_BUTTON:\n\t\tcode = ((usage->hid - 1) & HID_USAGE);\n\n\t\tswitch (field->application) {\n\t\tcase HID_GD_MOUSE:\n\t\tcase HID_GD_POINTER:  code += BTN_MOUSE; break;\n\t\tcase HID_GD_JOYSTICK:\n\t\t\t\tif (code <= 0xf)\n\t\t\t\t\tcode += BTN_JOYSTICK;\n\t\t\t\telse\n\t\t\t\t\tcode += BTN_TRIGGER_HAPPY - 0x10;\n\t\t\t\tbreak;\n\t\tcase HID_GD_GAMEPAD:\n\t\t\t\tif (code <= 0xf)\n\t\t\t\t\tcode += BTN_GAMEPAD;\n\t\t\t\telse\n\t\t\t\t\tcode += BTN_TRIGGER_HAPPY - 0x10;\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tswitch (field->physical) {\n\t\t\tcase HID_GD_MOUSE:\n\t\t\tcase HID_GD_POINTER:  code += BTN_MOUSE; break;\n\t\t\tcase HID_GD_JOYSTICK: code += BTN_JOYSTICK; break;\n\t\t\tcase HID_GD_GAMEPAD:  code += BTN_GAMEPAD; break;\n\t\t\tdefault:              code += BTN_MISC;\n\t\t\t}\n\t\t}\n\n\t\tmap_key(code);\n\t\tbreak;\n\n\tcase HID_UP_SIMULATION:\n\t\tswitch (usage->hid & 0xffff) {\n\t\tcase 0xba: map_abs(ABS_RUDDER);   break;\n\t\tcase 0xbb: map_abs(ABS_THROTTLE); break;\n\t\tcase 0xc4: map_abs(ABS_GAS);      break;\n\t\tcase 0xc5: map_abs(ABS_BRAKE);    break;\n\t\tcase 0xc8: map_abs(ABS_WHEEL);    break;\n\t\tdefault:   goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_GENDESK:\n\t\tif ((usage->hid & 0xf0) == 0x80) {\t/* SystemControl */\n\t\t\tswitch (usage->hid & 0xf) {\n\t\t\tcase 0x1: map_key_clear(KEY_POWER);  break;\n\t\t\tcase 0x2: map_key_clear(KEY_SLEEP);  break;\n\t\t\tcase 0x3: map_key_clear(KEY_WAKEUP); break;\n\t\t\tcase 0x4: map_key_clear(KEY_CONTEXT_MENU); break;\n\t\t\tcase 0x5: map_key_clear(KEY_MENU); break;\n\t\t\tcase 0x6: map_key_clear(KEY_PROG1); break;\n\t\t\tcase 0x7: map_key_clear(KEY_HELP); break;\n\t\t\tcase 0x8: map_key_clear(KEY_EXIT); break;\n\t\t\tcase 0x9: map_key_clear(KEY_SELECT); break;\n\t\t\tcase 0xa: map_key_clear(KEY_RIGHT); break;\n\t\t\tcase 0xb: map_key_clear(KEY_LEFT); break;\n\t\t\tcase 0xc: map_key_clear(KEY_UP); break;\n\t\t\tcase 0xd: map_key_clear(KEY_DOWN); break;\n\t\t\tcase 0xe: map_key_clear(KEY_POWER2); break;\n\t\t\tcase 0xf: map_key_clear(KEY_RESTART); break;\n\t\t\tdefault: goto unknown;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((usage->hid & 0xf0) == 0xb0) {\t/* SC - Display */\n\t\t\tswitch (usage->hid & 0xf) {\n\t\t\tcase 0x05: map_key_clear(KEY_SWITCHVIDEOMODE); break;\n\t\t\tdefault: goto ignore;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Some lazy vendors declare 255 usages for System Control,\n\t\t * leading to the creation of ABS_X|Y axis and too many others.\n\t\t * It wouldn't be a problem if joydev doesn't consider the\n\t\t * device as a joystick then.\n\t\t */\n\t\tif (field->application == HID_GD_SYSTEM_CONTROL)\n\t\t\tgoto ignore;\n\n\t\tif ((usage->hid & 0xf0) == 0x90) {\t/* D-pad */\n\t\t\tswitch (usage->hid) {\n\t\t\tcase HID_GD_UP:\t   usage->hat_dir = 1; break;\n\t\t\tcase HID_GD_DOWN:  usage->hat_dir = 5; break;\n\t\t\tcase HID_GD_RIGHT: usage->hat_dir = 3; break;\n\t\t\tcase HID_GD_LEFT:  usage->hat_dir = 7; break;\n\t\t\tdefault: goto unknown;\n\t\t\t}\n\t\t\tif (field->dpad) {\n\t\t\t\tmap_abs(field->dpad);\n\t\t\t\tgoto ignore;\n\t\t\t}\n\t\t\tmap_abs(ABS_HAT0X);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (usage->hid) {\n\t\t/* These usage IDs map directly to the usage codes. */\n\t\tcase HID_GD_X: case HID_GD_Y: case HID_GD_Z:\n\t\tcase HID_GD_RX: case HID_GD_RY: case HID_GD_RZ:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE)\n\t\t\t\tmap_rel(usage->hid & 0xf);\n\t\t\telse\n\t\t\t\tmap_abs_clear(usage->hid & 0xf);\n\t\t\tbreak;\n\n\t\tcase HID_GD_WHEEL:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE) {\n\t\t\t\tset_bit(REL_WHEEL, input->relbit);\n\t\t\t\tmap_rel(REL_WHEEL_HI_RES);\n\t\t\t} else {\n\t\t\t\tmap_abs(usage->hid & 0xf);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase HID_GD_SLIDER: case HID_GD_DIAL:\n\t\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE)\n\t\t\t\tmap_rel(usage->hid & 0xf);\n\t\t\telse\n\t\t\t\tmap_abs(usage->hid & 0xf);\n\t\t\tbreak;\n\n\t\tcase HID_GD_HATSWITCH:\n\t\t\tusage->hat_min = field->logical_minimum;\n\t\t\tusage->hat_max = field->logical_maximum;\n\t\t\tmap_abs(ABS_HAT0X);\n\t\t\tbreak;\n\n\t\tcase HID_GD_START:\tmap_key_clear(BTN_START);\tbreak;\n\t\tcase HID_GD_SELECT:\tmap_key_clear(BTN_SELECT);\tbreak;\n\n\t\tcase HID_GD_RFKILL_BTN:\n\t\t\t/* MS wireless radio ctl extension, also check CA */\n\t\t\tif (field->application == HID_GD_WIRELESS_RADIO_CTLS) {\n\t\t\t\tmap_key_clear(KEY_RFKILL);\n\t\t\t\t/* We need to simulate the btn release */\n\t\t\t\tfield->flags |= HID_MAIN_ITEM_RELATIVE;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault: goto unknown;\n\t\t}\n\n\t\tbreak;\n\n\tcase HID_UP_LED:\n\t\tswitch (usage->hid & 0xffff) {\t\t      /* HID-Value:                   */\n\t\tcase 0x01:  map_led (LED_NUML);     break;    /*   \"Num Lock\"                 */\n\t\tcase 0x02:  map_led (LED_CAPSL);    break;    /*   \"Caps Lock\"                */\n\t\tcase 0x03:  map_led (LED_SCROLLL);  break;    /*   \"Scroll Lock\"              */\n\t\tcase 0x04:  map_led (LED_COMPOSE);  break;    /*   \"Compose\"                  */\n\t\tcase 0x05:  map_led (LED_KANA);     break;    /*   \"Kana\"                     */\n\t\tcase 0x27:  map_led (LED_SLEEP);    break;    /*   \"Stand-By\"                 */\n\t\tcase 0x4c:  map_led (LED_SUSPEND);  break;    /*   \"System Suspend\"           */\n\t\tcase 0x09:  map_led (LED_MUTE);     break;    /*   \"Mute\"                     */\n\t\tcase 0x4b:  map_led (LED_MISC);     break;    /*   \"Generic Indicator\"        */\n\t\tcase 0x19:  map_led (LED_MAIL);     break;    /*   \"Message Waiting\"          */\n\t\tcase 0x4d:  map_led (LED_CHARGING); break;    /*   \"External Power Connected\" */\n\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_DIGITIZER:\n\t\tif ((field->application & 0xff) == 0x01) /* Digitizer */\n\t\t\t__set_bit(INPUT_PROP_POINTER, input->propbit);\n\t\telse if ((field->application & 0xff) == 0x02) /* Pen */\n\t\t\t__set_bit(INPUT_PROP_DIRECT, input->propbit);\n\n\t\tswitch (usage->hid & 0xff) {\n\t\tcase 0x00: /* Undefined */\n\t\t\tgoto ignore;\n\n\t\tcase 0x30: /* TipPressure */\n\t\t\tif (!test_bit(BTN_TOUCH, input->keybit)) {\n\t\t\t\tdevice->quirks |= HID_QUIRK_NOTOUCH;\n\t\t\t\tset_bit(EV_KEY, input->evbit);\n\t\t\t\tset_bit(BTN_TOUCH, input->keybit);\n\t\t\t}\n\t\t\tmap_abs_clear(ABS_PRESSURE);\n\t\t\tbreak;\n\n\t\tcase 0x32: /* InRange */\n\t\t\tswitch (field->physical & 0xff) {\n\t\t\tcase 0x21: map_key(BTN_TOOL_MOUSE); break;\n\t\t\tcase 0x22: map_key(BTN_TOOL_FINGER); break;\n\t\t\tdefault: map_key(BTN_TOOL_PEN); break;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase 0x3b: /* Battery Strength */\n\t\t\thidinput_setup_battery(device, HID_INPUT_REPORT, field);\n\t\t\tusage->type = EV_PWR;\n\t\t\tgoto ignore;\n\n\t\tcase 0x3c: /* Invert */\n\t\t\tmap_key_clear(BTN_TOOL_RUBBER);\n\t\t\tbreak;\n\n\t\tcase 0x3d: /* X Tilt */\n\t\t\tmap_abs_clear(ABS_TILT_X);\n\t\t\tbreak;\n\n\t\tcase 0x3e: /* Y Tilt */\n\t\t\tmap_abs_clear(ABS_TILT_Y);\n\t\t\tbreak;\n\n\t\tcase 0x33: /* Touch */\n\t\tcase 0x42: /* TipSwitch */\n\t\tcase 0x43: /* TipSwitch2 */\n\t\t\tdevice->quirks &= ~HID_QUIRK_NOTOUCH;\n\t\t\tmap_key_clear(BTN_TOUCH);\n\t\t\tbreak;\n\n\t\tcase 0x44: /* BarrelSwitch */\n\t\t\tmap_key_clear(BTN_STYLUS);\n\t\t\tbreak;\n\n\t\tcase 0x45: /* ERASER */\n\t\t\t/*\n\t\t\t * This event is reported when eraser tip touches the surface.\n\t\t\t * Actual eraser (BTN_TOOL_RUBBER) is set by Invert usage when\n\t\t\t * tool gets in proximity.\n\t\t\t */\n\t\t\tmap_key_clear(BTN_TOUCH);\n\t\t\tbreak;\n\n\t\tcase 0x46: /* TabletPick */\n\t\tcase 0x5a: /* SecondaryBarrelSwitch */\n\t\t\tmap_key_clear(BTN_STYLUS2);\n\t\t\tbreak;\n\n\t\tcase 0x5b: /* TransducerSerialNumber */\n\t\t\tusage->type = EV_MSC;\n\t\t\tusage->code = MSC_SERIAL;\n\t\t\tbit = input->mscbit;\n\t\t\tmax = MSC_MAX;\n\t\t\tbreak;\n\n\t\tdefault:  goto unknown;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_TELEPHONY:\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x2f: map_key_clear(KEY_MICMUTE);\t\tbreak;\n\t\tcase 0xb0: map_key_clear(KEY_NUMERIC_0);\tbreak;\n\t\tcase 0xb1: map_key_clear(KEY_NUMERIC_1);\tbreak;\n\t\tcase 0xb2: map_key_clear(KEY_NUMERIC_2);\tbreak;\n\t\tcase 0xb3: map_key_clear(KEY_NUMERIC_3);\tbreak;\n\t\tcase 0xb4: map_key_clear(KEY_NUMERIC_4);\tbreak;\n\t\tcase 0xb5: map_key_clear(KEY_NUMERIC_5);\tbreak;\n\t\tcase 0xb6: map_key_clear(KEY_NUMERIC_6);\tbreak;\n\t\tcase 0xb7: map_key_clear(KEY_NUMERIC_7);\tbreak;\n\t\tcase 0xb8: map_key_clear(KEY_NUMERIC_8);\tbreak;\n\t\tcase 0xb9: map_key_clear(KEY_NUMERIC_9);\tbreak;\n\t\tcase 0xba: map_key_clear(KEY_NUMERIC_STAR);\tbreak;\n\t\tcase 0xbb: map_key_clear(KEY_NUMERIC_POUND);\tbreak;\n\t\tcase 0xbc: map_key_clear(KEY_NUMERIC_A);\tbreak;\n\t\tcase 0xbd: map_key_clear(KEY_NUMERIC_B);\tbreak;\n\t\tcase 0xbe: map_key_clear(KEY_NUMERIC_C);\tbreak;\n\t\tcase 0xbf: map_key_clear(KEY_NUMERIC_D);\tbreak;\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_CONSUMER:\t/* USB HUT v1.12, pages 75-84 */\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x000: goto ignore;\n\t\tcase 0x030: map_key_clear(KEY_POWER);\t\tbreak;\n\t\tcase 0x031: map_key_clear(KEY_RESTART);\t\tbreak;\n\t\tcase 0x032: map_key_clear(KEY_SLEEP);\t\tbreak;\n\t\tcase 0x034: map_key_clear(KEY_SLEEP);\t\tbreak;\n\t\tcase 0x035: map_key_clear(KEY_KBDILLUMTOGGLE);\tbreak;\n\t\tcase 0x036: map_key_clear(BTN_MISC);\t\tbreak;\n\n\t\tcase 0x040: map_key_clear(KEY_MENU);\t\tbreak; /* Menu */\n\t\tcase 0x041: map_key_clear(KEY_SELECT);\t\tbreak; /* Menu Pick */\n\t\tcase 0x042: map_key_clear(KEY_UP);\t\tbreak; /* Menu Up */\n\t\tcase 0x043: map_key_clear(KEY_DOWN);\t\tbreak; /* Menu Down */\n\t\tcase 0x044: map_key_clear(KEY_LEFT);\t\tbreak; /* Menu Left */\n\t\tcase 0x045: map_key_clear(KEY_RIGHT);\t\tbreak; /* Menu Right */\n\t\tcase 0x046: map_key_clear(KEY_ESC);\t\tbreak; /* Menu Escape */\n\t\tcase 0x047: map_key_clear(KEY_KPPLUS);\t\tbreak; /* Menu Value Increase */\n\t\tcase 0x048: map_key_clear(KEY_KPMINUS);\t\tbreak; /* Menu Value Decrease */\n\n\t\tcase 0x060: map_key_clear(KEY_INFO);\t\tbreak; /* Data On Screen */\n\t\tcase 0x061: map_key_clear(KEY_SUBTITLE);\tbreak; /* Closed Caption */\n\t\tcase 0x063: map_key_clear(KEY_VCR);\t\tbreak; /* VCR/TV */\n\t\tcase 0x065: map_key_clear(KEY_CAMERA);\t\tbreak; /* Snapshot */\n\t\tcase 0x069: map_key_clear(KEY_RED);\t\tbreak;\n\t\tcase 0x06a: map_key_clear(KEY_GREEN);\t\tbreak;\n\t\tcase 0x06b: map_key_clear(KEY_BLUE);\t\tbreak;\n\t\tcase 0x06c: map_key_clear(KEY_YELLOW);\t\tbreak;\n\t\tcase 0x06d: map_key_clear(KEY_ASPECT_RATIO);\tbreak;\n\n\t\tcase 0x06f: map_key_clear(KEY_BRIGHTNESSUP);\t\tbreak;\n\t\tcase 0x070: map_key_clear(KEY_BRIGHTNESSDOWN);\t\tbreak;\n\t\tcase 0x072: map_key_clear(KEY_BRIGHTNESS_TOGGLE);\tbreak;\n\t\tcase 0x073: map_key_clear(KEY_BRIGHTNESS_MIN);\t\tbreak;\n\t\tcase 0x074: map_key_clear(KEY_BRIGHTNESS_MAX);\t\tbreak;\n\t\tcase 0x075: map_key_clear(KEY_BRIGHTNESS_AUTO);\t\tbreak;\n\n\t\tcase 0x079: map_key_clear(KEY_KBDILLUMUP);\tbreak;\n\t\tcase 0x07a: map_key_clear(KEY_KBDILLUMDOWN);\tbreak;\n\t\tcase 0x07c: map_key_clear(KEY_KBDILLUMTOGGLE);\tbreak;\n\n\t\tcase 0x082: map_key_clear(KEY_VIDEO_NEXT);\tbreak;\n\t\tcase 0x083: map_key_clear(KEY_LAST);\t\tbreak;\n\t\tcase 0x084: map_key_clear(KEY_ENTER);\t\tbreak;\n\t\tcase 0x088: map_key_clear(KEY_PC);\t\tbreak;\n\t\tcase 0x089: map_key_clear(KEY_TV);\t\tbreak;\n\t\tcase 0x08a: map_key_clear(KEY_WWW);\t\tbreak;\n\t\tcase 0x08b: map_key_clear(KEY_DVD);\t\tbreak;\n\t\tcase 0x08c: map_key_clear(KEY_PHONE);\t\tbreak;\n\t\tcase 0x08d: map_key_clear(KEY_PROGRAM);\t\tbreak;\n\t\tcase 0x08e: map_key_clear(KEY_VIDEOPHONE);\tbreak;\n\t\tcase 0x08f: map_key_clear(KEY_GAMES);\t\tbreak;\n\t\tcase 0x090: map_key_clear(KEY_MEMO);\t\tbreak;\n\t\tcase 0x091: map_key_clear(KEY_CD);\t\tbreak;\n\t\tcase 0x092: map_key_clear(KEY_VCR);\t\tbreak;\n\t\tcase 0x093: map_key_clear(KEY_TUNER);\t\tbreak;\n\t\tcase 0x094: map_key_clear(KEY_EXIT);\t\tbreak;\n\t\tcase 0x095: map_key_clear(KEY_HELP);\t\tbreak;\n\t\tcase 0x096: map_key_clear(KEY_TAPE);\t\tbreak;\n\t\tcase 0x097: map_key_clear(KEY_TV2);\t\tbreak;\n\t\tcase 0x098: map_key_clear(KEY_SAT);\t\tbreak;\n\t\tcase 0x09a: map_key_clear(KEY_PVR);\t\tbreak;\n\n\t\tcase 0x09c: map_key_clear(KEY_CHANNELUP);\tbreak;\n\t\tcase 0x09d: map_key_clear(KEY_CHANNELDOWN);\tbreak;\n\t\tcase 0x0a0: map_key_clear(KEY_VCR2);\t\tbreak;\n\n\t\tcase 0x0b0: map_key_clear(KEY_PLAY);\t\tbreak;\n\t\tcase 0x0b1: map_key_clear(KEY_PAUSE);\t\tbreak;\n\t\tcase 0x0b2: map_key_clear(KEY_RECORD);\t\tbreak;\n\t\tcase 0x0b3: map_key_clear(KEY_FASTFORWARD);\tbreak;\n\t\tcase 0x0b4: map_key_clear(KEY_REWIND);\t\tbreak;\n\t\tcase 0x0b5: map_key_clear(KEY_NEXTSONG);\tbreak;\n\t\tcase 0x0b6: map_key_clear(KEY_PREVIOUSSONG);\tbreak;\n\t\tcase 0x0b7: map_key_clear(KEY_STOPCD);\t\tbreak;\n\t\tcase 0x0b8: map_key_clear(KEY_EJECTCD);\t\tbreak;\n\t\tcase 0x0bc: map_key_clear(KEY_MEDIA_REPEAT);\tbreak;\n\t\tcase 0x0b9: map_key_clear(KEY_SHUFFLE);\t\tbreak;\n\t\tcase 0x0bf: map_key_clear(KEY_SLOW);\t\tbreak;\n\n\t\tcase 0x0cd: map_key_clear(KEY_PLAYPAUSE);\tbreak;\n\t\tcase 0x0cf: map_key_clear(KEY_VOICECOMMAND);\tbreak;\n\t\tcase 0x0e0: map_abs_clear(ABS_VOLUME);\t\tbreak;\n\t\tcase 0x0e2: map_key_clear(KEY_MUTE);\t\tbreak;\n\t\tcase 0x0e5: map_key_clear(KEY_BASSBOOST);\tbreak;\n\t\tcase 0x0e9: map_key_clear(KEY_VOLUMEUP);\tbreak;\n\t\tcase 0x0ea: map_key_clear(KEY_VOLUMEDOWN);\tbreak;\n\t\tcase 0x0f5: map_key_clear(KEY_SLOW);\t\tbreak;\n\n\t\tcase 0x181: map_key_clear(KEY_BUTTONCONFIG);\tbreak;\n\t\tcase 0x182: map_key_clear(KEY_BOOKMARKS);\tbreak;\n\t\tcase 0x183: map_key_clear(KEY_CONFIG);\t\tbreak;\n\t\tcase 0x184: map_key_clear(KEY_WORDPROCESSOR);\tbreak;\n\t\tcase 0x185: map_key_clear(KEY_EDITOR);\t\tbreak;\n\t\tcase 0x186: map_key_clear(KEY_SPREADSHEET);\tbreak;\n\t\tcase 0x187: map_key_clear(KEY_GRAPHICSEDITOR);\tbreak;\n\t\tcase 0x188: map_key_clear(KEY_PRESENTATION);\tbreak;\n\t\tcase 0x189: map_key_clear(KEY_DATABASE);\tbreak;\n\t\tcase 0x18a: map_key_clear(KEY_MAIL);\t\tbreak;\n\t\tcase 0x18b: map_key_clear(KEY_NEWS);\t\tbreak;\n\t\tcase 0x18c: map_key_clear(KEY_VOICEMAIL);\tbreak;\n\t\tcase 0x18d: map_key_clear(KEY_ADDRESSBOOK);\tbreak;\n\t\tcase 0x18e: map_key_clear(KEY_CALENDAR);\tbreak;\n\t\tcase 0x18f: map_key_clear(KEY_TASKMANAGER);\tbreak;\n\t\tcase 0x190: map_key_clear(KEY_JOURNAL);\t\tbreak;\n\t\tcase 0x191: map_key_clear(KEY_FINANCE);\t\tbreak;\n\t\tcase 0x192: map_key_clear(KEY_CALC);\t\tbreak;\n\t\tcase 0x193: map_key_clear(KEY_PLAYER);\t\tbreak;\n\t\tcase 0x194: map_key_clear(KEY_FILE);\t\tbreak;\n\t\tcase 0x196: map_key_clear(KEY_WWW);\t\tbreak;\n\t\tcase 0x199: map_key_clear(KEY_CHAT);\t\tbreak;\n\t\tcase 0x19c: map_key_clear(KEY_LOGOFF);\t\tbreak;\n\t\tcase 0x19e: map_key_clear(KEY_COFFEE);\t\tbreak;\n\t\tcase 0x19f: map_key_clear(KEY_CONTROLPANEL);\t\tbreak;\n\t\tcase 0x1a2: map_key_clear(KEY_APPSELECT);\t\tbreak;\n\t\tcase 0x1a3: map_key_clear(KEY_NEXT);\t\tbreak;\n\t\tcase 0x1a4: map_key_clear(KEY_PREVIOUS);\tbreak;\n\t\tcase 0x1a6: map_key_clear(KEY_HELP);\t\tbreak;\n\t\tcase 0x1a7: map_key_clear(KEY_DOCUMENTS);\tbreak;\n\t\tcase 0x1ab: map_key_clear(KEY_SPELLCHECK);\tbreak;\n\t\tcase 0x1ae: map_key_clear(KEY_KEYBOARD);\tbreak;\n\t\tcase 0x1b1: map_key_clear(KEY_SCREENSAVER);\t\tbreak;\n\t\tcase 0x1b4: map_key_clear(KEY_FILE);\t\tbreak;\n\t\tcase 0x1b6: map_key_clear(KEY_IMAGES);\t\tbreak;\n\t\tcase 0x1b7: map_key_clear(KEY_AUDIO);\t\tbreak;\n\t\tcase 0x1b8: map_key_clear(KEY_VIDEO);\t\tbreak;\n\t\tcase 0x1bc: map_key_clear(KEY_MESSENGER);\tbreak;\n\t\tcase 0x1bd: map_key_clear(KEY_INFO);\t\tbreak;\n\t\tcase 0x1cb: map_key_clear(KEY_ASSISTANT);\tbreak;\n\t\tcase 0x201: map_key_clear(KEY_NEW);\t\tbreak;\n\t\tcase 0x202: map_key_clear(KEY_OPEN);\t\tbreak;\n\t\tcase 0x203: map_key_clear(KEY_CLOSE);\t\tbreak;\n\t\tcase 0x204: map_key_clear(KEY_EXIT);\t\tbreak;\n\t\tcase 0x207: map_key_clear(KEY_SAVE);\t\tbreak;\n\t\tcase 0x208: map_key_clear(KEY_PRINT);\t\tbreak;\n\t\tcase 0x209: map_key_clear(KEY_PROPS);\t\tbreak;\n\t\tcase 0x21a: map_key_clear(KEY_UNDO);\t\tbreak;\n\t\tcase 0x21b: map_key_clear(KEY_COPY);\t\tbreak;\n\t\tcase 0x21c: map_key_clear(KEY_CUT);\t\tbreak;\n\t\tcase 0x21d: map_key_clear(KEY_PASTE);\t\tbreak;\n\t\tcase 0x21f: map_key_clear(KEY_FIND);\t\tbreak;\n\t\tcase 0x221: map_key_clear(KEY_SEARCH);\t\tbreak;\n\t\tcase 0x222: map_key_clear(KEY_GOTO);\t\tbreak;\n\t\tcase 0x223: map_key_clear(KEY_HOMEPAGE);\tbreak;\n\t\tcase 0x224: map_key_clear(KEY_BACK);\t\tbreak;\n\t\tcase 0x225: map_key_clear(KEY_FORWARD);\t\tbreak;\n\t\tcase 0x226: map_key_clear(KEY_STOP);\t\tbreak;\n\t\tcase 0x227: map_key_clear(KEY_REFRESH);\t\tbreak;\n\t\tcase 0x22a: map_key_clear(KEY_BOOKMARKS);\tbreak;\n\t\tcase 0x22d: map_key_clear(KEY_ZOOMIN);\t\tbreak;\n\t\tcase 0x22e: map_key_clear(KEY_ZOOMOUT);\t\tbreak;\n\t\tcase 0x22f: map_key_clear(KEY_ZOOMRESET);\tbreak;\n\t\tcase 0x232: map_key_clear(KEY_FULL_SCREEN);\tbreak;\n\t\tcase 0x233: map_key_clear(KEY_SCROLLUP);\tbreak;\n\t\tcase 0x234: map_key_clear(KEY_SCROLLDOWN);\tbreak;\n\t\tcase 0x238: /* AC Pan */\n\t\t\tset_bit(REL_HWHEEL, input->relbit);\n\t\t\tmap_rel(REL_HWHEEL_HI_RES);\n\t\t\tbreak;\n\t\tcase 0x23d: map_key_clear(KEY_EDIT);\t\tbreak;\n\t\tcase 0x25f: map_key_clear(KEY_CANCEL);\t\tbreak;\n\t\tcase 0x269: map_key_clear(KEY_INSERT);\t\tbreak;\n\t\tcase 0x26a: map_key_clear(KEY_DELETE);\t\tbreak;\n\t\tcase 0x279: map_key_clear(KEY_REDO);\t\tbreak;\n\n\t\tcase 0x289: map_key_clear(KEY_REPLY);\t\tbreak;\n\t\tcase 0x28b: map_key_clear(KEY_FORWARDMAIL);\tbreak;\n\t\tcase 0x28c: map_key_clear(KEY_SEND);\t\tbreak;\n\n\t\tcase 0x29d: map_key_clear(KEY_KBD_LAYOUT_NEXT);\tbreak;\n\n\t\tcase 0x2c7: map_key_clear(KEY_KBDINPUTASSIST_PREV);\t\tbreak;\n\t\tcase 0x2c8: map_key_clear(KEY_KBDINPUTASSIST_NEXT);\t\tbreak;\n\t\tcase 0x2c9: map_key_clear(KEY_KBDINPUTASSIST_PREVGROUP);\t\tbreak;\n\t\tcase 0x2ca: map_key_clear(KEY_KBDINPUTASSIST_NEXTGROUP);\t\tbreak;\n\t\tcase 0x2cb: map_key_clear(KEY_KBDINPUTASSIST_ACCEPT);\tbreak;\n\t\tcase 0x2cc: map_key_clear(KEY_KBDINPUTASSIST_CANCEL);\tbreak;\n\n\t\tcase 0x29f: map_key_clear(KEY_SCALE);\t\tbreak;\n\n\t\tdefault: map_key_clear(KEY_UNKNOWN);\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_GENDEVCTRLS:\n\t\tswitch (usage->hid) {\n\t\tcase HID_DC_BATTERYSTRENGTH:\n\t\t\thidinput_setup_battery(device, HID_INPUT_REPORT, field);\n\t\t\tusage->type = EV_PWR;\n\t\t\tgoto ignore;\n\t\t}\n\t\tgoto unknown;\n\n\tcase HID_UP_HPVENDOR:\t/* Reported on a Dutch layout HP5308 */\n\t\tset_bit(EV_REP, input->evbit);\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x021: map_key_clear(KEY_PRINT);           break;\n\t\tcase 0x070: map_key_clear(KEY_HP);\t\tbreak;\n\t\tcase 0x071: map_key_clear(KEY_CAMERA);\t\tbreak;\n\t\tcase 0x072: map_key_clear(KEY_SOUND);\t\tbreak;\n\t\tcase 0x073: map_key_clear(KEY_QUESTION);\tbreak;\n\t\tcase 0x080: map_key_clear(KEY_EMAIL);\t\tbreak;\n\t\tcase 0x081: map_key_clear(KEY_CHAT);\t\tbreak;\n\t\tcase 0x082: map_key_clear(KEY_SEARCH);\t\tbreak;\n\t\tcase 0x083: map_key_clear(KEY_CONNECT);\t        break;\n\t\tcase 0x084: map_key_clear(KEY_FINANCE);\t\tbreak;\n\t\tcase 0x085: map_key_clear(KEY_SPORT);\t\tbreak;\n\t\tcase 0x086: map_key_clear(KEY_SHOP);\t        break;\n\t\tdefault:    goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_HPVENDOR2:\n\t\tset_bit(EV_REP, input->evbit);\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0x001: map_key_clear(KEY_MICMUTE);\t\tbreak;\n\t\tcase 0x003: map_key_clear(KEY_BRIGHTNESSDOWN);\tbreak;\n\t\tcase 0x004: map_key_clear(KEY_BRIGHTNESSUP);\tbreak;\n\t\tdefault:    goto ignore;\n\t\t}\n\t\tbreak;\n\n\tcase HID_UP_MSVENDOR:\n\t\tgoto ignore;\n\n\tcase HID_UP_CUSTOM: /* Reported on Logitech and Apple USB keyboards */\n\t\tset_bit(EV_REP, input->evbit);\n\t\tgoto ignore;\n\n\tcase HID_UP_LOGIVENDOR:\n\t\t/* intentional fallback */\n\tcase HID_UP_LOGIVENDOR2:\n\t\t/* intentional fallback */\n\tcase HID_UP_LOGIVENDOR3:\n\t\tgoto ignore;\n\n\tcase HID_UP_PID:\n\t\tswitch (usage->hid & HID_USAGE) {\n\t\tcase 0xa4: map_key_clear(BTN_DEAD);\tbreak;\n\t\tdefault: goto ignore;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\tunknown:\n\t\tif (field->report_size == 1) {\n\t\t\tif (field->report->type == HID_OUTPUT_REPORT) {\n\t\t\t\tmap_led(LED_MISC);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tmap_key(BTN_MISC);\n\t\t\tbreak;\n\t\t}\n\t\tif (field->flags & HID_MAIN_ITEM_RELATIVE) {\n\t\t\tmap_rel(REL_MISC);\n\t\t\tbreak;\n\t\t}\n\t\tmap_abs(ABS_MISC);\n\t\tbreak;\n\t}\n\nmapped:\n\t/* Mapping failed, bail out */\n\tif (!bit)\n\t\treturn;\n\n\tif (device->driver->input_mapped &&\n\t    device->driver->input_mapped(device, hidinput, field, usage,\n\t\t\t\t\t &bit, &max) < 0) {\n\t\t/*\n\t\t * The driver indicated that no further generic handling\n\t\t * of the usage is desired.\n\t\t */\n\t\treturn;\n\t}\n\n\tset_bit(usage->type, input->evbit);\n\n\t/*\n\t * This part is *really* controversial:\n\t * - HID aims at being generic so we should do our best to export\n\t *   all incoming events\n\t * - HID describes what events are, so there is no reason for ABS_X\n\t *   to be mapped to ABS_Y\n\t * - HID is using *_MISC+N as a default value, but nothing prevents\n\t *   *_MISC+N to overwrite a legitimate even, which confuses userspace\n\t *   (for instance ABS_MISC + 7 is ABS_MT_SLOT, which has a different\n\t *   processing)\n\t *\n\t * If devices still want to use this (at their own risk), they will\n\t * have to use the quirk HID_QUIRK_INCREMENT_USAGE_ON_DUPLICATE, but\n\t * the default should be a reliable mapping.\n\t */\n\twhile (usage->code <= max && test_and_set_bit(usage->code, bit)) {\n\t\tif (device->quirks & HID_QUIRK_INCREMENT_USAGE_ON_DUPLICATE) {\n\t\t\tusage->code = find_next_zero_bit(bit,\n\t\t\t\t\t\t\t max + 1,\n\t\t\t\t\t\t\t usage->code);\n\t\t} else {\n\t\t\tdevice->status |= HID_STAT_DUP_DETECTED;\n\t\t\tgoto ignore;\n\t\t}\n\t}\n\n\tif (usage->code > max)\n\t\tgoto ignore;\n\n\tif (usage->type == EV_ABS) {\n\n\t\tint a = field->logical_minimum;\n\t\tint b = field->logical_maximum;\n\n\t\tif ((device->quirks & HID_QUIRK_BADPAD) && (usage->code == ABS_X || usage->code == ABS_Y)) {\n\t\t\ta = field->logical_minimum = 0;\n\t\t\tb = field->logical_maximum = 255;\n\t\t}\n\n\t\tif (field->application == HID_GD_GAMEPAD || field->application == HID_GD_JOYSTICK)\n\t\t\tinput_set_abs_params(input, usage->code, a, b, (b - a) >> 8, (b - a) >> 4);\n\t\telse\tinput_set_abs_params(input, usage->code, a, b, 0, 0);\n\n\t\tinput_abs_set_res(input, usage->code,\n\t\t\t\t  hidinput_calc_abs_res(field, usage->code));\n\n\t\t/* use a larger default input buffer for MT devices */\n\t\tif (usage->code == ABS_MT_POSITION_X && input->hint_events_per_packet == 0)\n\t\t\tinput_set_events_per_packet(input, 60);\n\t}\n\n\tif (usage->type == EV_ABS &&\n\t    (usage->hat_min < usage->hat_max || usage->hat_dir)) {\n\t\tint i;\n\t\tfor (i = usage->code; i < usage->code + 2 && i <= max; i++) {\n\t\t\tinput_set_abs_params(input, i, -1, 1, 0, 0);\n\t\t\tset_bit(i, input->absbit);\n\t\t}\n\t\tif (usage->hat_dir && !field->dpad)\n\t\t\tfield->dpad = usage->code;\n\t}\n\n\t/* for those devices which produce Consumer volume usage as relative,\n\t * we emulate pressing volumeup/volumedown appropriate number of times\n\t * in hidinput_hid_event()\n\t */\n\tif ((usage->type == EV_ABS) && (field->flags & HID_MAIN_ITEM_RELATIVE) &&\n\t\t\t(usage->code == ABS_VOLUME)) {\n\t\tset_bit(KEY_VOLUMEUP, input->keybit);\n\t\tset_bit(KEY_VOLUMEDOWN, input->keybit);\n\t}\n\n\tif (usage->type == EV_KEY) {\n\t\tset_bit(EV_MSC, input->evbit);\n\t\tset_bit(MSC_SCAN, input->mscbit);\n\t}\n\n\treturn;\n\nignore:\n\tusage->type = 0;\n\tusage->code = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -574,6 +574,10 @@\n \t}\n \n mapped:\n+\t/* Mapping failed, bail out */\n+\tif (!bit)\n+\t\treturn;\n+\n \tif (device->driver->input_mapped &&\n \t    device->driver->input_mapped(device, hidinput, field, usage,\n \t\t\t\t\t &bit, &max) < 0) {",
        "function_modified_lines": {
            "added": [
                "\t/* Mapping failed, bail out */",
                "\tif (!bit)",
                "\t\treturn;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various methods of hid-multitouch.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-162844689References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2020-0465",
        "code_before_change": "static int mt_touch_input_mapping(struct hid_device *hdev, struct hid_input *hi,\n\t\tstruct hid_field *field, struct hid_usage *usage,\n\t\tunsigned long **bit, int *max, struct mt_application *app)\n{\n\tstruct mt_device *td = hid_get_drvdata(hdev);\n\tstruct mt_class *cls = &td->mtclass;\n\tint code;\n\tstruct hid_usage *prev_usage = NULL;\n\n\t/*\n\t * Model touchscreens providing buttons as touchpads.\n\t */\n\tif (field->application == HID_DG_TOUCHSCREEN &&\n\t    (usage->hid & HID_USAGE_PAGE) == HID_UP_BUTTON) {\n\t\tapp->mt_flags |= INPUT_MT_POINTER;\n\t\ttd->inputmode_value = MT_INPUTMODE_TOUCHPAD;\n\t}\n\n\t/* count the buttons on touchpads */\n\tif ((usage->hid & HID_USAGE_PAGE) == HID_UP_BUTTON)\n\t\tapp->buttons_count++;\n\n\tif (usage->usage_index)\n\t\tprev_usage = &field->usage[usage->usage_index - 1];\n\n\tswitch (usage->hid & HID_USAGE_PAGE) {\n\n\tcase HID_UP_GENDESK:\n\t\tswitch (usage->hid) {\n\t\tcase HID_GD_X:\n\t\t\tif (prev_usage && (prev_usage->hid == usage->hid)) {\n\t\t\t\tcode = ABS_MT_TOOL_X;\n\t\t\t\tMT_STORE_FIELD(cx);\n\t\t\t} else {\n\t\t\t\tcode = ABS_MT_POSITION_X;\n\t\t\t\tMT_STORE_FIELD(x);\n\t\t\t}\n\n\t\t\tset_abs(hi->input, code, field, cls->sn_move);\n\n\t\t\t/*\n\t\t\t * A system multi-axis that exports X and Y has a high\n\t\t\t * chance of being used directly on a surface\n\t\t\t */\n\t\t\tif (field->application == HID_GD_SYSTEM_MULTIAXIS) {\n\t\t\t\t__set_bit(INPUT_PROP_DIRECT,\n\t\t\t\t\t  hi->input->propbit);\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\t     ABS_MT_TOOL_TYPE,\n\t\t\t\t\t\t     MT_TOOL_DIAL,\n\t\t\t\t\t\t     MT_TOOL_DIAL, 0, 0);\n\t\t\t}\n\n\t\t\treturn 1;\n\t\tcase HID_GD_Y:\n\t\t\tif (prev_usage && (prev_usage->hid == usage->hid)) {\n\t\t\t\tcode = ABS_MT_TOOL_Y;\n\t\t\t\tMT_STORE_FIELD(cy);\n\t\t\t} else {\n\t\t\t\tcode = ABS_MT_POSITION_Y;\n\t\t\t\tMT_STORE_FIELD(y);\n\t\t\t}\n\n\t\t\tset_abs(hi->input, code, field, cls->sn_move);\n\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\n\tcase HID_UP_DIGITIZER:\n\t\tswitch (usage->hid) {\n\t\tcase HID_DG_INRANGE:\n\t\t\tif (app->quirks & MT_QUIRK_HOVERING) {\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\tABS_MT_DISTANCE, 0, 1, 0, 0);\n\t\t\t}\n\t\t\tMT_STORE_FIELD(inrange_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONFIDENCE:\n\t\t\tif (cls->name == MT_CLS_WIN_8 &&\n\t\t\t\t(field->application == HID_DG_TOUCHPAD ||\n\t\t\t\t field->application == HID_DG_TOUCHSCREEN))\n\t\t\t\tapp->quirks |= MT_QUIRK_CONFIDENCE;\n\n\t\t\tif (app->quirks & MT_QUIRK_CONFIDENCE)\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\t     ABS_MT_TOOL_TYPE,\n\t\t\t\t\t\t     MT_TOOL_FINGER,\n\t\t\t\t\t\t     MT_TOOL_PALM, 0, 0);\n\n\t\t\tMT_STORE_FIELD(confidence_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_TIPSWITCH:\n\t\t\tif (field->application != HID_GD_SYSTEM_MULTIAXIS)\n\t\t\t\tinput_set_capability(hi->input,\n\t\t\t\t\t\t     EV_KEY, BTN_TOUCH);\n\t\t\tMT_STORE_FIELD(tip_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTID:\n\t\t\tMT_STORE_FIELD(contactid);\n\t\t\tapp->touches_by_report++;\n\t\t\treturn 1;\n\t\tcase HID_DG_WIDTH:\n\t\t\tif (!(app->quirks & MT_QUIRK_NO_AREA))\n\t\t\t\tset_abs(hi->input, ABS_MT_TOUCH_MAJOR, field,\n\t\t\t\t\tcls->sn_width);\n\t\t\tMT_STORE_FIELD(w);\n\t\t\treturn 1;\n\t\tcase HID_DG_HEIGHT:\n\t\t\tif (!(app->quirks & MT_QUIRK_NO_AREA)) {\n\t\t\t\tset_abs(hi->input, ABS_MT_TOUCH_MINOR, field,\n\t\t\t\t\tcls->sn_height);\n\n\t\t\t\t/*\n\t\t\t\t * Only set ABS_MT_ORIENTATION if it is not\n\t\t\t\t * already set by the HID_DG_AZIMUTH usage.\n\t\t\t\t */\n\t\t\t\tif (!test_bit(ABS_MT_ORIENTATION,\n\t\t\t\t\t\thi->input->absbit))\n\t\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\tABS_MT_ORIENTATION, 0, 1, 0, 0);\n\t\t\t}\n\t\t\tMT_STORE_FIELD(h);\n\t\t\treturn 1;\n\t\tcase HID_DG_TIPPRESSURE:\n\t\t\tset_abs(hi->input, ABS_MT_PRESSURE, field,\n\t\t\t\tcls->sn_pressure);\n\t\t\tMT_STORE_FIELD(p);\n\t\t\treturn 1;\n\t\tcase HID_DG_SCANTIME:\n\t\t\tinput_set_capability(hi->input, EV_MSC, MSC_TIMESTAMP);\n\t\t\tapp->scantime = &field->value[usage->usage_index];\n\t\t\tapp->scantime_logical_max = field->logical_maximum;\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTCOUNT:\n\t\t\tapp->have_contact_count = true;\n\t\t\tapp->raw_cc = &field->value[usage->usage_index];\n\t\t\treturn 1;\n\t\tcase HID_DG_AZIMUTH:\n\t\t\t/*\n\t\t\t * Azimuth has the range of [0, MAX) representing a full\n\t\t\t * revolution. Set ABS_MT_ORIENTATION to a quarter of\n\t\t\t * MAX according the definition of ABS_MT_ORIENTATION\n\t\t\t */\n\t\t\tinput_set_abs_params(hi->input, ABS_MT_ORIENTATION,\n\t\t\t\t-field->logical_maximum / 4,\n\t\t\t\tfield->logical_maximum / 4,\n\t\t\t\tcls->sn_move ?\n\t\t\t\tfield->logical_maximum / cls->sn_move : 0, 0);\n\t\t\tMT_STORE_FIELD(a);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTMAX:\n\t\t\t/* contact max are global to the report */\n\t\t\treturn -1;\n\t\tcase HID_DG_TOUCH:\n\t\t\t/* Legacy devices use TIPSWITCH and not TOUCH.\n\t\t\t * Let's just ignore this field. */\n\t\t\treturn -1;\n\t\t}\n\t\t/* let hid-input decide for the others */\n\t\treturn 0;\n\n\tcase HID_UP_BUTTON:\n\t\tcode = BTN_MOUSE + ((usage->hid - 1) & HID_USAGE);\n\t\t/*\n\t\t * MS PTP spec says that external buttons left and right have\n\t\t * usages 2 and 3.\n\t\t */\n\t\tif ((app->quirks & MT_QUIRK_WIN8_PTP_BUTTONS) &&\n\t\t    field->application == HID_DG_TOUCHPAD &&\n\t\t    (usage->hid & HID_USAGE) > 1)\n\t\t\tcode--;\n\n\t\tif (field->application == HID_GD_SYSTEM_MULTIAXIS)\n\t\t\tcode = BTN_0  + ((usage->hid - 1) & HID_USAGE);\n\n\t\thid_map_usage(hi, usage, bit, max, EV_KEY, code);\n\t\tinput_set_capability(hi->input, EV_KEY, code);\n\t\treturn 1;\n\n\tcase 0xff000000:\n\t\t/* we do not want to map these: no input-oriented meaning */\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int mt_touch_input_mapping(struct hid_device *hdev, struct hid_input *hi,\n\t\tstruct hid_field *field, struct hid_usage *usage,\n\t\tunsigned long **bit, int *max, struct mt_application *app)\n{\n\tstruct mt_device *td = hid_get_drvdata(hdev);\n\tstruct mt_class *cls = &td->mtclass;\n\tint code;\n\tstruct hid_usage *prev_usage = NULL;\n\n\t/*\n\t * Model touchscreens providing buttons as touchpads.\n\t */\n\tif (field->application == HID_DG_TOUCHSCREEN &&\n\t    (usage->hid & HID_USAGE_PAGE) == HID_UP_BUTTON) {\n\t\tapp->mt_flags |= INPUT_MT_POINTER;\n\t\ttd->inputmode_value = MT_INPUTMODE_TOUCHPAD;\n\t}\n\n\t/* count the buttons on touchpads */\n\tif ((usage->hid & HID_USAGE_PAGE) == HID_UP_BUTTON)\n\t\tapp->buttons_count++;\n\n\tif (usage->usage_index)\n\t\tprev_usage = &field->usage[usage->usage_index - 1];\n\n\tswitch (usage->hid & HID_USAGE_PAGE) {\n\n\tcase HID_UP_GENDESK:\n\t\tswitch (usage->hid) {\n\t\tcase HID_GD_X:\n\t\t\tif (prev_usage && (prev_usage->hid == usage->hid)) {\n\t\t\t\tcode = ABS_MT_TOOL_X;\n\t\t\t\tMT_STORE_FIELD(cx);\n\t\t\t} else {\n\t\t\t\tcode = ABS_MT_POSITION_X;\n\t\t\t\tMT_STORE_FIELD(x);\n\t\t\t}\n\n\t\t\tset_abs(hi->input, code, field, cls->sn_move);\n\n\t\t\t/*\n\t\t\t * A system multi-axis that exports X and Y has a high\n\t\t\t * chance of being used directly on a surface\n\t\t\t */\n\t\t\tif (field->application == HID_GD_SYSTEM_MULTIAXIS) {\n\t\t\t\t__set_bit(INPUT_PROP_DIRECT,\n\t\t\t\t\t  hi->input->propbit);\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\t     ABS_MT_TOOL_TYPE,\n\t\t\t\t\t\t     MT_TOOL_DIAL,\n\t\t\t\t\t\t     MT_TOOL_DIAL, 0, 0);\n\t\t\t}\n\n\t\t\treturn 1;\n\t\tcase HID_GD_Y:\n\t\t\tif (prev_usage && (prev_usage->hid == usage->hid)) {\n\t\t\t\tcode = ABS_MT_TOOL_Y;\n\t\t\t\tMT_STORE_FIELD(cy);\n\t\t\t} else {\n\t\t\t\tcode = ABS_MT_POSITION_Y;\n\t\t\t\tMT_STORE_FIELD(y);\n\t\t\t}\n\n\t\t\tset_abs(hi->input, code, field, cls->sn_move);\n\n\t\t\treturn 1;\n\t\t}\n\t\treturn 0;\n\n\tcase HID_UP_DIGITIZER:\n\t\tswitch (usage->hid) {\n\t\tcase HID_DG_INRANGE:\n\t\t\tif (app->quirks & MT_QUIRK_HOVERING) {\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\tABS_MT_DISTANCE, 0, 1, 0, 0);\n\t\t\t}\n\t\t\tMT_STORE_FIELD(inrange_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONFIDENCE:\n\t\t\tif (cls->name == MT_CLS_WIN_8 &&\n\t\t\t\t(field->application == HID_DG_TOUCHPAD ||\n\t\t\t\t field->application == HID_DG_TOUCHSCREEN))\n\t\t\t\tapp->quirks |= MT_QUIRK_CONFIDENCE;\n\n\t\t\tif (app->quirks & MT_QUIRK_CONFIDENCE)\n\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\t     ABS_MT_TOOL_TYPE,\n\t\t\t\t\t\t     MT_TOOL_FINGER,\n\t\t\t\t\t\t     MT_TOOL_PALM, 0, 0);\n\n\t\t\tMT_STORE_FIELD(confidence_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_TIPSWITCH:\n\t\t\tif (field->application != HID_GD_SYSTEM_MULTIAXIS)\n\t\t\t\tinput_set_capability(hi->input,\n\t\t\t\t\t\t     EV_KEY, BTN_TOUCH);\n\t\t\tMT_STORE_FIELD(tip_state);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTID:\n\t\t\tMT_STORE_FIELD(contactid);\n\t\t\tapp->touches_by_report++;\n\t\t\treturn 1;\n\t\tcase HID_DG_WIDTH:\n\t\t\tif (!(app->quirks & MT_QUIRK_NO_AREA))\n\t\t\t\tset_abs(hi->input, ABS_MT_TOUCH_MAJOR, field,\n\t\t\t\t\tcls->sn_width);\n\t\t\tMT_STORE_FIELD(w);\n\t\t\treturn 1;\n\t\tcase HID_DG_HEIGHT:\n\t\t\tif (!(app->quirks & MT_QUIRK_NO_AREA)) {\n\t\t\t\tset_abs(hi->input, ABS_MT_TOUCH_MINOR, field,\n\t\t\t\t\tcls->sn_height);\n\n\t\t\t\t/*\n\t\t\t\t * Only set ABS_MT_ORIENTATION if it is not\n\t\t\t\t * already set by the HID_DG_AZIMUTH usage.\n\t\t\t\t */\n\t\t\t\tif (!test_bit(ABS_MT_ORIENTATION,\n\t\t\t\t\t\thi->input->absbit))\n\t\t\t\t\tinput_set_abs_params(hi->input,\n\t\t\t\t\t\tABS_MT_ORIENTATION, 0, 1, 0, 0);\n\t\t\t}\n\t\t\tMT_STORE_FIELD(h);\n\t\t\treturn 1;\n\t\tcase HID_DG_TIPPRESSURE:\n\t\t\tset_abs(hi->input, ABS_MT_PRESSURE, field,\n\t\t\t\tcls->sn_pressure);\n\t\t\tMT_STORE_FIELD(p);\n\t\t\treturn 1;\n\t\tcase HID_DG_SCANTIME:\n\t\t\tinput_set_capability(hi->input, EV_MSC, MSC_TIMESTAMP);\n\t\t\tapp->scantime = &field->value[usage->usage_index];\n\t\t\tapp->scantime_logical_max = field->logical_maximum;\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTCOUNT:\n\t\t\tapp->have_contact_count = true;\n\t\t\tapp->raw_cc = &field->value[usage->usage_index];\n\t\t\treturn 1;\n\t\tcase HID_DG_AZIMUTH:\n\t\t\t/*\n\t\t\t * Azimuth has the range of [0, MAX) representing a full\n\t\t\t * revolution. Set ABS_MT_ORIENTATION to a quarter of\n\t\t\t * MAX according the definition of ABS_MT_ORIENTATION\n\t\t\t */\n\t\t\tinput_set_abs_params(hi->input, ABS_MT_ORIENTATION,\n\t\t\t\t-field->logical_maximum / 4,\n\t\t\t\tfield->logical_maximum / 4,\n\t\t\t\tcls->sn_move ?\n\t\t\t\tfield->logical_maximum / cls->sn_move : 0, 0);\n\t\t\tMT_STORE_FIELD(a);\n\t\t\treturn 1;\n\t\tcase HID_DG_CONTACTMAX:\n\t\t\t/* contact max are global to the report */\n\t\t\treturn -1;\n\t\tcase HID_DG_TOUCH:\n\t\t\t/* Legacy devices use TIPSWITCH and not TOUCH.\n\t\t\t * Let's just ignore this field. */\n\t\t\treturn -1;\n\t\t}\n\t\t/* let hid-input decide for the others */\n\t\treturn 0;\n\n\tcase HID_UP_BUTTON:\n\t\tcode = BTN_MOUSE + ((usage->hid - 1) & HID_USAGE);\n\t\t/*\n\t\t * MS PTP spec says that external buttons left and right have\n\t\t * usages 2 and 3.\n\t\t */\n\t\tif ((app->quirks & MT_QUIRK_WIN8_PTP_BUTTONS) &&\n\t\t    field->application == HID_DG_TOUCHPAD &&\n\t\t    (usage->hid & HID_USAGE) > 1)\n\t\t\tcode--;\n\n\t\tif (field->application == HID_GD_SYSTEM_MULTIAXIS)\n\t\t\tcode = BTN_0  + ((usage->hid - 1) & HID_USAGE);\n\n\t\thid_map_usage(hi, usage, bit, max, EV_KEY, code);\n\t\tif (!*bit)\n\t\t\treturn -1;\n\t\tinput_set_capability(hi->input, EV_KEY, code);\n\t\treturn 1;\n\n\tcase 0xff000000:\n\t\t/* we do not want to map these: no input-oriented meaning */\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -175,6 +175,8 @@\n \t\t\tcode = BTN_0  + ((usage->hid - 1) & HID_USAGE);\n \n \t\thid_map_usage(hi, usage, bit, max, EV_KEY, code);\n+\t\tif (!*bit)\n+\t\t\treturn -1;\n \t\tinput_set_capability(hi->input, EV_KEY, code);\n \t\treturn 1;\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (!*bit)",
                "\t\t\treturn -1;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various methods of hid-multitouch.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-162844689References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2020-0465",
        "code_before_change": "static inline void hid_map_usage_clear(struct hid_input *hidinput,\n\t\tstruct hid_usage *usage, unsigned long **bit, int *max,\n\t\t__u8 type, __u16 c)\n{\n\thid_map_usage(hidinput, usage, bit, max, type, c);\n\tclear_bit(c, *bit);\n}",
        "code_after_change": "static inline void hid_map_usage_clear(struct hid_input *hidinput,\n\t\tstruct hid_usage *usage, unsigned long **bit, int *max,\n\t\t__u8 type, __u16 c)\n{\n\thid_map_usage(hidinput, usage, bit, max, type, c);\n\tif (*bit)\n\t\tclear_bit(usage->code, *bit);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,5 +3,6 @@\n \t\t__u8 type, __u16 c)\n {\n \thid_map_usage(hidinput, usage, bit, max, type, c);\n-\tclear_bit(c, *bit);\n+\tif (*bit)\n+\t\tclear_bit(usage->code, *bit);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (*bit)",
                "\t\tclear_bit(usage->code, *bit);"
            ],
            "deleted": [
                "\tclear_bit(c, *bit);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various methods of hid-multitouch.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-162844689References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2020-10742",
        "code_before_change": "static void ll_free_user_pages(struct page **pages, int npages, int do_dirty)\n{\n\tint i;\n\n\tfor (i = 0; i < npages; i++) {\n\t\tif (pages[i] == NULL)\n\t\t\tbreak;\n\t\tif (do_dirty)\n\t\t\tset_page_dirty_lock(pages[i]);\n\t\tpage_cache_release(pages[i]);\n\t}\n\n\tOBD_FREE_LARGE(pages, npages * sizeof(*pages));\n}",
        "code_after_change": "static void ll_free_user_pages(struct page **pages, int npages, int do_dirty)\n{\n\tint i;\n\n\tfor (i = 0; i < npages; i++) {\n\t\tif (do_dirty)\n\t\t\tset_page_dirty_lock(pages[i]);\n\t\tpage_cache_release(pages[i]);\n\t}\n\tkvfree(pages);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,12 +3,9 @@\n \tint i;\n \n \tfor (i = 0; i < npages; i++) {\n-\t\tif (pages[i] == NULL)\n-\t\t\tbreak;\n \t\tif (do_dirty)\n \t\t\tset_page_dirty_lock(pages[i]);\n \t\tpage_cache_release(pages[i]);\n \t}\n-\n-\tOBD_FREE_LARGE(pages, npages * sizeof(*pages));\n+\tkvfree(pages);\n }",
        "function_modified_lines": {
            "added": [
                "\tkvfree(pages);"
            ],
            "deleted": [
                "\t\tif (pages[i] == NULL)",
                "\t\t\tbreak;",
                "",
                "\tOBD_FREE_LARGE(pages, npages * sizeof(*pages));"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel. An index buffer overflow during Direct IO write leading to the NFS client to crash. In some cases, a reach out of the index after one memory allocation by kmalloc will cause a kernel panic. The highest threat from this vulnerability is to data confidentiality and system availability."
    },
    {
        "cve_id": "CVE-2020-10742",
        "code_before_change": "static ssize_t ll_direct_IO_26(int rw, struct kiocb *iocb,\n\t\t\t       struct iov_iter *iter, loff_t file_offset)\n{\n\tstruct lu_env *env;\n\tstruct cl_io *io;\n\tstruct file *file = iocb->ki_filp;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct ccc_object *obj = cl_inode2ccc(inode);\n\tlong count = iov_iter_count(iter);\n\tlong tot_bytes = 0, result = 0;\n\tstruct ll_inode_info *lli = ll_i2info(inode);\n\tunsigned long seg = 0;\n\tlong size = MAX_DIO_SIZE;\n\tint refcheck;\n\n\tif (!lli->lli_has_smd)\n\t\treturn -EBADF;\n\n\t/* FIXME: io smaller than PAGE_SIZE is broken on ia64 ??? */\n\tif ((file_offset & ~CFS_PAGE_MASK) || (count & ~CFS_PAGE_MASK))\n\t\treturn -EINVAL;\n\n\tCDEBUG(D_VFSTRACE, \"VFS Op:inode=%lu/%u(%p), size=%lu (max %lu), \"\n\t       \"offset=%lld=%llx, pages %lu (max %lu)\\n\",\n\t       inode->i_ino, inode->i_generation, inode, count, MAX_DIO_SIZE,\n\t       file_offset, file_offset, count >> PAGE_CACHE_SHIFT,\n\t       MAX_DIO_SIZE >> PAGE_CACHE_SHIFT);\n\n\t/* Check that all user buffers are aligned as well */\n\tif (iov_iter_alignment(iter) & ~CFS_PAGE_MASK)\n\t\treturn -EINVAL;\n\n\tenv = cl_env_get(&refcheck);\n\tLASSERT(!IS_ERR(env));\n\tio = ccc_env_io(env)->cui_cl.cis_io;\n\tLASSERT(io != NULL);\n\n\t/* 0. Need locking between buffered and direct access. and race with\n\t *    size changing by concurrent truncates and writes.\n\t * 1. Need inode mutex to operate transient pages.\n\t */\n\tif (rw == READ)\n\t\tmutex_lock(&inode->i_mutex);\n\n\tLASSERT(obj->cob_transient_pages == 0);\n\tfor (seg = 0; seg < iter->nr_segs; seg++) {\n\t\tlong iov_left = iter->iov[seg].iov_len;\n\t\tunsigned long user_addr = (unsigned long)iter->iov[seg].iov_base;\n\n\t\tif (rw == READ) {\n\t\t\tif (file_offset >= i_size_read(inode))\n\t\t\t\tbreak;\n\t\t\tif (file_offset + iov_left > i_size_read(inode))\n\t\t\t\tiov_left = i_size_read(inode) - file_offset;\n\t\t}\n\n\t\twhile (iov_left > 0) {\n\t\t\tstruct page **pages;\n\t\t\tint page_count, max_pages = 0;\n\t\t\tlong bytes;\n\n\t\t\tbytes = min(size, iov_left);\n\t\t\tpage_count = ll_get_user_pages(rw, user_addr, bytes,\n\t\t\t\t\t\t       &pages, &max_pages);\n\t\t\tif (likely(page_count > 0)) {\n\t\t\t\tif (unlikely(page_count <  max_pages))\n\t\t\t\t\tbytes = page_count << PAGE_CACHE_SHIFT;\n\t\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,\n\t\t\t\t\t\t\t     file->f_mapping,\n\t\t\t\t\t\t\t     bytes, file_offset,\n\t\t\t\t\t\t\t     pages, page_count);\n\t\t\t\tll_free_user_pages(pages, max_pages, rw==READ);\n\t\t\t} else if (page_count == 0) {\n\t\t\t\tGOTO(out, result = -EFAULT);\n\t\t\t} else {\n\t\t\t\tresult = page_count;\n\t\t\t}\n\t\t\tif (unlikely(result <= 0)) {\n\t\t\t\t/* If we can't allocate a large enough buffer\n\t\t\t\t * for the request, shrink it to a smaller\n\t\t\t\t * PAGE_SIZE multiple and try again.\n\t\t\t\t * We should always be able to kmalloc for a\n\t\t\t\t * page worth of page pointers = 4MB on i386. */\n\t\t\t\tif (result == -ENOMEM &&\n\t\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *\n\t\t\t\t\t   PAGE_CACHE_SIZE) {\n\t\t\t\t\tsize = ((((size / 2) - 1) |\n\t\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &\n\t\t\t\t\t\tCFS_PAGE_MASK;\n\t\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",\n\t\t\t\t\t       size);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tGOTO(out, result);\n\t\t\t}\n\n\t\t\ttot_bytes += result;\n\t\t\tfile_offset += result;\n\t\t\tiov_left -= result;\n\t\t\tuser_addr += result;\n\t\t}\n\t}\nout:\n\tLASSERT(obj->cob_transient_pages == 0);\n\tif (rw == READ)\n\t\tmutex_unlock(&inode->i_mutex);\n\n\tif (tot_bytes > 0) {\n\t\tif (rw == WRITE) {\n\t\t\tstruct lov_stripe_md *lsm;\n\n\t\t\tlsm = ccc_inode_lsm_get(inode);\n\t\t\tLASSERT(lsm != NULL);\n\t\t\tlov_stripe_lock(lsm);\n\t\t\tobd_adjust_kms(ll_i2dtexp(inode), lsm, file_offset, 0);\n\t\t\tlov_stripe_unlock(lsm);\n\t\t\tccc_inode_lsm_put(inode, lsm);\n\t\t}\n\t}\n\n\tcl_env_put(env, &refcheck);\n\treturn tot_bytes ? : result;\n}",
        "code_after_change": "static ssize_t ll_direct_IO_26(int rw, struct kiocb *iocb,\n\t\t\t       struct iov_iter *iter, loff_t file_offset)\n{\n\tstruct lu_env *env;\n\tstruct cl_io *io;\n\tstruct file *file = iocb->ki_filp;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct ccc_object *obj = cl_inode2ccc(inode);\n\tssize_t count = iov_iter_count(iter);\n\tssize_t tot_bytes = 0, result = 0;\n\tstruct ll_inode_info *lli = ll_i2info(inode);\n\tlong size = MAX_DIO_SIZE;\n\tint refcheck;\n\n\tif (!lli->lli_has_smd)\n\t\treturn -EBADF;\n\n\t/* FIXME: io smaller than PAGE_SIZE is broken on ia64 ??? */\n\tif ((file_offset & ~CFS_PAGE_MASK) || (count & ~CFS_PAGE_MASK))\n\t\treturn -EINVAL;\n\n\tCDEBUG(D_VFSTRACE, \"VFS Op:inode=%lu/%u(%p), size=%lu (max %lu), \"\n\t       \"offset=%lld=%llx, pages %lu (max %lu)\\n\",\n\t       inode->i_ino, inode->i_generation, inode, count, MAX_DIO_SIZE,\n\t       file_offset, file_offset, count >> PAGE_CACHE_SHIFT,\n\t       MAX_DIO_SIZE >> PAGE_CACHE_SHIFT);\n\n\t/* Check that all user buffers are aligned as well */\n\tif (iov_iter_alignment(iter) & ~CFS_PAGE_MASK)\n\t\treturn -EINVAL;\n\n\tenv = cl_env_get(&refcheck);\n\tLASSERT(!IS_ERR(env));\n\tio = ccc_env_io(env)->cui_cl.cis_io;\n\tLASSERT(io != NULL);\n\n\t/* 0. Need locking between buffered and direct access. and race with\n\t *    size changing by concurrent truncates and writes.\n\t * 1. Need inode mutex to operate transient pages.\n\t */\n\tif (rw == READ)\n\t\tmutex_lock(&inode->i_mutex);\n\n\tLASSERT(obj->cob_transient_pages == 0);\n\twhile (iov_iter_count(iter)) {\n\t\tstruct page **pages;\n\t\tsize_t offs;\n\n\t\tcount = min_t(size_t, iov_iter_count(iter), size);\n\t\tif (rw == READ) {\n\t\t\tif (file_offset >= i_size_read(inode))\n\t\t\t\tbreak;\n\t\t\tif (file_offset + count > i_size_read(inode))\n\t\t\t\tcount = i_size_read(inode) - file_offset;\n\t\t}\n\n\t\tresult = iov_iter_get_pages_alloc(iter, &pages, count, &offs);\n\t\tif (likely(result > 0)) {\n\t\t\tint n = (result + offs + PAGE_SIZE - 1) / PAGE_SIZE;\n\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,\n\t\t\t\t\t\t     file->f_mapping,\n\t\t\t\t\t\t     result, file_offset,\n\t\t\t\t\t\t     pages, n);\n\t\t\tll_free_user_pages(pages, n, rw==READ);\n\t\t}\n\t\tif (unlikely(result <= 0)) {\n\t\t\t/* If we can't allocate a large enough buffer\n\t\t\t * for the request, shrink it to a smaller\n\t\t\t * PAGE_SIZE multiple and try again.\n\t\t\t * We should always be able to kmalloc for a\n\t\t\t * page worth of page pointers = 4MB on i386. */\n\t\t\tif (result == -ENOMEM &&\n\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *\n\t\t\t\t   PAGE_CACHE_SIZE) {\n\t\t\t\tsize = ((((size / 2) - 1) |\n\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &\n\t\t\t\t\tCFS_PAGE_MASK;\n\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",\n\t\t\t\t       size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tGOTO(out, result);\n\t\t}\n\t\tiov_iter_advance(iter, result);\n\t\ttot_bytes += result;\n\t\tfile_offset += result;\n\t}\nout:\n\tLASSERT(obj->cob_transient_pages == 0);\n\tif (rw == READ)\n\t\tmutex_unlock(&inode->i_mutex);\n\n\tif (tot_bytes > 0) {\n\t\tif (rw == WRITE) {\n\t\t\tstruct lov_stripe_md *lsm;\n\n\t\t\tlsm = ccc_inode_lsm_get(inode);\n\t\t\tLASSERT(lsm != NULL);\n\t\t\tlov_stripe_lock(lsm);\n\t\t\tobd_adjust_kms(ll_i2dtexp(inode), lsm, file_offset, 0);\n\t\t\tlov_stripe_unlock(lsm);\n\t\t\tccc_inode_lsm_put(inode, lsm);\n\t\t}\n\t}\n\n\tcl_env_put(env, &refcheck);\n\treturn tot_bytes ? : result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,10 +6,9 @@\n \tstruct file *file = iocb->ki_filp;\n \tstruct inode *inode = file->f_mapping->host;\n \tstruct ccc_object *obj = cl_inode2ccc(inode);\n-\tlong count = iov_iter_count(iter);\n-\tlong tot_bytes = 0, result = 0;\n+\tssize_t count = iov_iter_count(iter);\n+\tssize_t tot_bytes = 0, result = 0;\n \tstruct ll_inode_info *lli = ll_i2info(inode);\n-\tunsigned long seg = 0;\n \tlong size = MAX_DIO_SIZE;\n \tint refcheck;\n \n@@ -43,63 +42,49 @@\n \t\tmutex_lock(&inode->i_mutex);\n \n \tLASSERT(obj->cob_transient_pages == 0);\n-\tfor (seg = 0; seg < iter->nr_segs; seg++) {\n-\t\tlong iov_left = iter->iov[seg].iov_len;\n-\t\tunsigned long user_addr = (unsigned long)iter->iov[seg].iov_base;\n+\twhile (iov_iter_count(iter)) {\n+\t\tstruct page **pages;\n+\t\tsize_t offs;\n \n+\t\tcount = min_t(size_t, iov_iter_count(iter), size);\n \t\tif (rw == READ) {\n \t\t\tif (file_offset >= i_size_read(inode))\n \t\t\t\tbreak;\n-\t\t\tif (file_offset + iov_left > i_size_read(inode))\n-\t\t\t\tiov_left = i_size_read(inode) - file_offset;\n+\t\t\tif (file_offset + count > i_size_read(inode))\n+\t\t\t\tcount = i_size_read(inode) - file_offset;\n \t\t}\n \n-\t\twhile (iov_left > 0) {\n-\t\t\tstruct page **pages;\n-\t\t\tint page_count, max_pages = 0;\n-\t\t\tlong bytes;\n-\n-\t\t\tbytes = min(size, iov_left);\n-\t\t\tpage_count = ll_get_user_pages(rw, user_addr, bytes,\n-\t\t\t\t\t\t       &pages, &max_pages);\n-\t\t\tif (likely(page_count > 0)) {\n-\t\t\t\tif (unlikely(page_count <  max_pages))\n-\t\t\t\t\tbytes = page_count << PAGE_CACHE_SHIFT;\n-\t\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,\n-\t\t\t\t\t\t\t     file->f_mapping,\n-\t\t\t\t\t\t\t     bytes, file_offset,\n-\t\t\t\t\t\t\t     pages, page_count);\n-\t\t\t\tll_free_user_pages(pages, max_pages, rw==READ);\n-\t\t\t} else if (page_count == 0) {\n-\t\t\t\tGOTO(out, result = -EFAULT);\n-\t\t\t} else {\n-\t\t\t\tresult = page_count;\n-\t\t\t}\n-\t\t\tif (unlikely(result <= 0)) {\n-\t\t\t\t/* If we can't allocate a large enough buffer\n-\t\t\t\t * for the request, shrink it to a smaller\n-\t\t\t\t * PAGE_SIZE multiple and try again.\n-\t\t\t\t * We should always be able to kmalloc for a\n-\t\t\t\t * page worth of page pointers = 4MB on i386. */\n-\t\t\t\tif (result == -ENOMEM &&\n-\t\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *\n-\t\t\t\t\t   PAGE_CACHE_SIZE) {\n-\t\t\t\t\tsize = ((((size / 2) - 1) |\n-\t\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &\n-\t\t\t\t\t\tCFS_PAGE_MASK;\n-\t\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",\n-\t\t\t\t\t       size);\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\n-\t\t\t\tGOTO(out, result);\n+\t\tresult = iov_iter_get_pages_alloc(iter, &pages, count, &offs);\n+\t\tif (likely(result > 0)) {\n+\t\t\tint n = (result + offs + PAGE_SIZE - 1) / PAGE_SIZE;\n+\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,\n+\t\t\t\t\t\t     file->f_mapping,\n+\t\t\t\t\t\t     result, file_offset,\n+\t\t\t\t\t\t     pages, n);\n+\t\t\tll_free_user_pages(pages, n, rw==READ);\n+\t\t}\n+\t\tif (unlikely(result <= 0)) {\n+\t\t\t/* If we can't allocate a large enough buffer\n+\t\t\t * for the request, shrink it to a smaller\n+\t\t\t * PAGE_SIZE multiple and try again.\n+\t\t\t * We should always be able to kmalloc for a\n+\t\t\t * page worth of page pointers = 4MB on i386. */\n+\t\t\tif (result == -ENOMEM &&\n+\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *\n+\t\t\t\t   PAGE_CACHE_SIZE) {\n+\t\t\t\tsize = ((((size / 2) - 1) |\n+\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &\n+\t\t\t\t\tCFS_PAGE_MASK;\n+\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",\n+\t\t\t\t       size);\n+\t\t\t\tcontinue;\n \t\t\t}\n \n-\t\t\ttot_bytes += result;\n-\t\t\tfile_offset += result;\n-\t\t\tiov_left -= result;\n-\t\t\tuser_addr += result;\n+\t\t\tGOTO(out, result);\n \t\t}\n+\t\tiov_iter_advance(iter, result);\n+\t\ttot_bytes += result;\n+\t\tfile_offset += result;\n \t}\n out:\n \tLASSERT(obj->cob_transient_pages == 0);",
        "function_modified_lines": {
            "added": [
                "\tssize_t count = iov_iter_count(iter);",
                "\tssize_t tot_bytes = 0, result = 0;",
                "\twhile (iov_iter_count(iter)) {",
                "\t\tstruct page **pages;",
                "\t\tsize_t offs;",
                "\t\tcount = min_t(size_t, iov_iter_count(iter), size);",
                "\t\t\tif (file_offset + count > i_size_read(inode))",
                "\t\t\t\tcount = i_size_read(inode) - file_offset;",
                "\t\tresult = iov_iter_get_pages_alloc(iter, &pages, count, &offs);",
                "\t\tif (likely(result > 0)) {",
                "\t\t\tint n = (result + offs + PAGE_SIZE - 1) / PAGE_SIZE;",
                "\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,",
                "\t\t\t\t\t\t     file->f_mapping,",
                "\t\t\t\t\t\t     result, file_offset,",
                "\t\t\t\t\t\t     pages, n);",
                "\t\t\tll_free_user_pages(pages, n, rw==READ);",
                "\t\t}",
                "\t\tif (unlikely(result <= 0)) {",
                "\t\t\t/* If we can't allocate a large enough buffer",
                "\t\t\t * for the request, shrink it to a smaller",
                "\t\t\t * PAGE_SIZE multiple and try again.",
                "\t\t\t * We should always be able to kmalloc for a",
                "\t\t\t * page worth of page pointers = 4MB on i386. */",
                "\t\t\tif (result == -ENOMEM &&",
                "\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *",
                "\t\t\t\t   PAGE_CACHE_SIZE) {",
                "\t\t\t\tsize = ((((size / 2) - 1) |",
                "\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &",
                "\t\t\t\t\tCFS_PAGE_MASK;",
                "\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",",
                "\t\t\t\t       size);",
                "\t\t\t\tcontinue;",
                "\t\t\tGOTO(out, result);",
                "\t\tiov_iter_advance(iter, result);",
                "\t\ttot_bytes += result;",
                "\t\tfile_offset += result;"
            ],
            "deleted": [
                "\tlong count = iov_iter_count(iter);",
                "\tlong tot_bytes = 0, result = 0;",
                "\tunsigned long seg = 0;",
                "\tfor (seg = 0; seg < iter->nr_segs; seg++) {",
                "\t\tlong iov_left = iter->iov[seg].iov_len;",
                "\t\tunsigned long user_addr = (unsigned long)iter->iov[seg].iov_base;",
                "\t\t\tif (file_offset + iov_left > i_size_read(inode))",
                "\t\t\t\tiov_left = i_size_read(inode) - file_offset;",
                "\t\twhile (iov_left > 0) {",
                "\t\t\tstruct page **pages;",
                "\t\t\tint page_count, max_pages = 0;",
                "\t\t\tlong bytes;",
                "",
                "\t\t\tbytes = min(size, iov_left);",
                "\t\t\tpage_count = ll_get_user_pages(rw, user_addr, bytes,",
                "\t\t\t\t\t\t       &pages, &max_pages);",
                "\t\t\tif (likely(page_count > 0)) {",
                "\t\t\t\tif (unlikely(page_count <  max_pages))",
                "\t\t\t\t\tbytes = page_count << PAGE_CACHE_SHIFT;",
                "\t\t\t\tresult = ll_direct_IO_26_seg(env, io, rw, inode,",
                "\t\t\t\t\t\t\t     file->f_mapping,",
                "\t\t\t\t\t\t\t     bytes, file_offset,",
                "\t\t\t\t\t\t\t     pages, page_count);",
                "\t\t\t\tll_free_user_pages(pages, max_pages, rw==READ);",
                "\t\t\t} else if (page_count == 0) {",
                "\t\t\t\tGOTO(out, result = -EFAULT);",
                "\t\t\t} else {",
                "\t\t\t\tresult = page_count;",
                "\t\t\t}",
                "\t\t\tif (unlikely(result <= 0)) {",
                "\t\t\t\t/* If we can't allocate a large enough buffer",
                "\t\t\t\t * for the request, shrink it to a smaller",
                "\t\t\t\t * PAGE_SIZE multiple and try again.",
                "\t\t\t\t * We should always be able to kmalloc for a",
                "\t\t\t\t * page worth of page pointers = 4MB on i386. */",
                "\t\t\t\tif (result == -ENOMEM &&",
                "\t\t\t\t    size > (PAGE_CACHE_SIZE / sizeof(*pages)) *",
                "\t\t\t\t\t   PAGE_CACHE_SIZE) {",
                "\t\t\t\t\tsize = ((((size / 2) - 1) |",
                "\t\t\t\t\t\t ~CFS_PAGE_MASK) + 1) &",
                "\t\t\t\t\t\tCFS_PAGE_MASK;",
                "\t\t\t\t\tCDEBUG(D_VFSTRACE,\"DIO size now %lu\\n\",",
                "\t\t\t\t\t       size);",
                "\t\t\t\t\tcontinue;",
                "\t\t\t\t}",
                "",
                "\t\t\t\tGOTO(out, result);",
                "\t\t\ttot_bytes += result;",
                "\t\t\tfile_offset += result;",
                "\t\t\tiov_left -= result;",
                "\t\t\tuser_addr += result;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel. An index buffer overflow during Direct IO write leading to the NFS client to crash. In some cases, a reach out of the index after one memory allocation by kmalloc will cause a kernel panic. The highest threat from this vulnerability is to data confidentiality and system availability."
    },
    {
        "cve_id": "CVE-2020-10742",
        "code_before_change": "ssize_t nfs_file_direct_read(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t\tloff_t pos, bool uio)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tssize_t result = -EINVAL;\n\tsize_t count = iov_iter_count(iter);\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTREADBYTES, count);\n\n\tdfprintk(FILE, \"NFS: direct read(%pD2, %zd@%Ld)\\n\",\n\t\tfile, count, (long long) pos);\n\n\tresult = 0;\n\tif (!count)\n\t\tgoto out;\n\n\tmutex_lock(&inode->i_mutex);\n\tresult = nfs_sync_mapping(mapping);\n\tif (result)\n\t\tgoto out_unlock;\n\n\ttask_io_account_read(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (dreq == NULL)\n\t\tgoto out_unlock;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = count;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\n\tNFS_I(inode)->read_io += count;\n\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos, uio);\n\n\tmutex_unlock(&inode->i_mutex);\n\n\tif (!result) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0)\n\t\t\tiocb->ki_pos = pos + result;\n\t}\n\n\tnfs_direct_req_release(dreq);\n\treturn result;\n\nout_release:\n\tnfs_direct_req_release(dreq);\nout_unlock:\n\tmutex_unlock(&inode->i_mutex);\nout:\n\treturn result;\n}",
        "code_after_change": "ssize_t nfs_file_direct_read(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t\tloff_t pos, bool uio)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tssize_t result = -EINVAL;\n\tsize_t count = iov_iter_count(iter);\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTREADBYTES, count);\n\n\tdfprintk(FILE, \"NFS: direct read(%pD2, %zd@%Ld)\\n\",\n\t\tfile, count, (long long) pos);\n\n\tresult = 0;\n\tif (!count)\n\t\tgoto out;\n\n\tmutex_lock(&inode->i_mutex);\n\tresult = nfs_sync_mapping(mapping);\n\tif (result)\n\t\tgoto out_unlock;\n\n\ttask_io_account_read(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (dreq == NULL)\n\t\tgoto out_unlock;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = count;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\n\tNFS_I(inode)->read_io += count;\n\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos);\n\n\tmutex_unlock(&inode->i_mutex);\n\n\tif (!result) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0)\n\t\t\tiocb->ki_pos = pos + result;\n\t}\n\n\tnfs_direct_req_release(dreq);\n\treturn result;\n\nout_release:\n\tnfs_direct_req_release(dreq);\nout_unlock:\n\tmutex_unlock(&inode->i_mutex);\nout:\n\treturn result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,7 +42,7 @@\n \t\tdreq->iocb = iocb;\n \n \tNFS_I(inode)->read_io += count;\n-\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos, uio);\n+\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos);\n \n \tmutex_unlock(&inode->i_mutex);\n ",
        "function_modified_lines": {
            "added": [
                "\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos);"
            ],
            "deleted": [
                "\tresult = nfs_direct_read_schedule_iovec(dreq, iter, pos, uio);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel. An index buffer overflow during Direct IO write leading to the NFS client to crash. In some cases, a reach out of the index after one memory allocation by kmalloc will cause a kernel panic. The highest threat from this vulnerability is to data confidentiality and system availability."
    },
    {
        "cve_id": "CVE-2020-10742",
        "code_before_change": "ssize_t nfs_file_direct_write(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t\tloff_t pos, bool uio)\n{\n\tssize_t result = -EINVAL;\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tloff_t end;\n\tsize_t count = iov_iter_count(iter);\n\tend = (pos + count - 1) >> PAGE_CACHE_SHIFT;\n\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTWRITTENBYTES, count);\n\n\tdfprintk(FILE, \"NFS: direct write(%pD2, %zd@%Ld)\\n\",\n\t\tfile, count, (long long) pos);\n\n\tresult = generic_write_checks(file, &pos, &count, 0);\n\tif (result)\n\t\tgoto out;\n\n\tresult = -EINVAL;\n\tif ((ssize_t) count < 0)\n\t\tgoto out;\n\tresult = 0;\n\tif (!count)\n\t\tgoto out;\n\n\tmutex_lock(&inode->i_mutex);\n\n\tresult = nfs_sync_mapping(mapping);\n\tif (result)\n\t\tgoto out_unlock;\n\n\tif (mapping->nrpages) {\n\t\tresult = invalidate_inode_pages2_range(mapping,\n\t\t\t\t\tpos >> PAGE_CACHE_SHIFT, end);\n\t\tif (result)\n\t\t\tgoto out_unlock;\n\t}\n\n\ttask_io_account_write(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (!dreq)\n\t\tgoto out_unlock;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = count;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\n\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos, uio);\n\n\tif (mapping->nrpages) {\n\t\tinvalidate_inode_pages2_range(mapping,\n\t\t\t\t\t      pos >> PAGE_CACHE_SHIFT, end);\n\t}\n\n\tmutex_unlock(&inode->i_mutex);\n\n\tif (!result) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0) {\n\t\t\tstruct inode *inode = mapping->host;\n\n\t\t\tiocb->ki_pos = pos + result;\n\t\t\tspin_lock(&inode->i_lock);\n\t\t\tif (i_size_read(inode) < iocb->ki_pos)\n\t\t\t\ti_size_write(inode, iocb->ki_pos);\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t}\n\t}\n\tnfs_direct_req_release(dreq);\n\treturn result;\n\nout_release:\n\tnfs_direct_req_release(dreq);\nout_unlock:\n\tmutex_unlock(&inode->i_mutex);\nout:\n\treturn result;\n}",
        "code_after_change": "ssize_t nfs_file_direct_write(struct kiocb *iocb, struct iov_iter *iter,\n\t\t\t\tloff_t pos, bool uio)\n{\n\tssize_t result = -EINVAL;\n\tstruct file *file = iocb->ki_filp;\n\tstruct address_space *mapping = file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tstruct nfs_direct_req *dreq;\n\tstruct nfs_lock_context *l_ctx;\n\tloff_t end;\n\tsize_t count = iov_iter_count(iter);\n\tend = (pos + count - 1) >> PAGE_CACHE_SHIFT;\n\n\tnfs_add_stats(mapping->host, NFSIOS_DIRECTWRITTENBYTES, count);\n\n\tdfprintk(FILE, \"NFS: direct write(%pD2, %zd@%Ld)\\n\",\n\t\tfile, count, (long long) pos);\n\n\tresult = generic_write_checks(file, &pos, &count, 0);\n\tif (result)\n\t\tgoto out;\n\n\tresult = -EINVAL;\n\tif ((ssize_t) count < 0)\n\t\tgoto out;\n\tresult = 0;\n\tif (!count)\n\t\tgoto out;\n\n\tmutex_lock(&inode->i_mutex);\n\n\tresult = nfs_sync_mapping(mapping);\n\tif (result)\n\t\tgoto out_unlock;\n\n\tif (mapping->nrpages) {\n\t\tresult = invalidate_inode_pages2_range(mapping,\n\t\t\t\t\tpos >> PAGE_CACHE_SHIFT, end);\n\t\tif (result)\n\t\t\tgoto out_unlock;\n\t}\n\n\ttask_io_account_write(count);\n\n\tresult = -ENOMEM;\n\tdreq = nfs_direct_req_alloc();\n\tif (!dreq)\n\t\tgoto out_unlock;\n\n\tdreq->inode = inode;\n\tdreq->bytes_left = count;\n\tdreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));\n\tl_ctx = nfs_get_lock_context(dreq->ctx);\n\tif (IS_ERR(l_ctx)) {\n\t\tresult = PTR_ERR(l_ctx);\n\t\tgoto out_release;\n\t}\n\tdreq->l_ctx = l_ctx;\n\tif (!is_sync_kiocb(iocb))\n\t\tdreq->iocb = iocb;\n\n\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos);\n\n\tif (mapping->nrpages) {\n\t\tinvalidate_inode_pages2_range(mapping,\n\t\t\t\t\t      pos >> PAGE_CACHE_SHIFT, end);\n\t}\n\n\tmutex_unlock(&inode->i_mutex);\n\n\tif (!result) {\n\t\tresult = nfs_direct_wait(dreq);\n\t\tif (result > 0) {\n\t\t\tstruct inode *inode = mapping->host;\n\n\t\t\tiocb->ki_pos = pos + result;\n\t\t\tspin_lock(&inode->i_lock);\n\t\t\tif (i_size_read(inode) < iocb->ki_pos)\n\t\t\t\ti_size_write(inode, iocb->ki_pos);\n\t\t\tspin_unlock(&inode->i_lock);\n\t\t}\n\t}\n\tnfs_direct_req_release(dreq);\n\treturn result;\n\nout_release:\n\tnfs_direct_req_release(dreq);\nout_unlock:\n\tmutex_unlock(&inode->i_mutex);\nout:\n\treturn result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -59,7 +59,7 @@\n \tif (!is_sync_kiocb(iocb))\n \t\tdreq->iocb = iocb;\n \n-\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos, uio);\n+\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos);\n \n \tif (mapping->nrpages) {\n \t\tinvalidate_inode_pages2_range(mapping,",
        "function_modified_lines": {
            "added": [
                "\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos);"
            ],
            "deleted": [
                "\tresult = nfs_direct_write_schedule_iovec(dreq, iter, pos, uio);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel. An index buffer overflow during Direct IO write leading to the NFS client to crash. In some cases, a reach out of the index after one memory allocation by kmalloc will cause a kernel panic. The highest threat from this vulnerability is to data confidentiality and system availability."
    },
    {
        "cve_id": "CVE-2020-10942",
        "code_before_change": "static struct socket *get_raw_socket(int fd)\n{\n\tstruct {\n\t\tstruct sockaddr_ll sa;\n\t\tchar  buf[MAX_ADDR_LEN];\n\t} uaddr;\n\tint r;\n\tstruct socket *sock = sockfd_lookup(fd, &r);\n\n\tif (!sock)\n\t\treturn ERR_PTR(-ENOTSOCK);\n\n\t/* Parameter checking */\n\tif (sock->sk->sk_type != SOCK_RAW) {\n\t\tr = -ESOCKTNOSUPPORT;\n\t\tgoto err;\n\t}\n\n\tr = sock->ops->getname(sock, (struct sockaddr *)&uaddr.sa, 0);\n\tif (r < 0)\n\t\tgoto err;\n\n\tif (uaddr.sa.sll_family != AF_PACKET) {\n\t\tr = -EPFNOSUPPORT;\n\t\tgoto err;\n\t}\n\treturn sock;\nerr:\n\tsockfd_put(sock);\n\treturn ERR_PTR(r);\n}",
        "code_after_change": "static struct socket *get_raw_socket(int fd)\n{\n\tint r;\n\tstruct socket *sock = sockfd_lookup(fd, &r);\n\n\tif (!sock)\n\t\treturn ERR_PTR(-ENOTSOCK);\n\n\t/* Parameter checking */\n\tif (sock->sk->sk_type != SOCK_RAW) {\n\t\tr = -ESOCKTNOSUPPORT;\n\t\tgoto err;\n\t}\n\n\tif (sock->sk->sk_family != AF_PACKET) {\n\t\tr = -EPFNOSUPPORT;\n\t\tgoto err;\n\t}\n\treturn sock;\nerr:\n\tsockfd_put(sock);\n\treturn ERR_PTR(r);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,5 @@\n static struct socket *get_raw_socket(int fd)\n {\n-\tstruct {\n-\t\tstruct sockaddr_ll sa;\n-\t\tchar  buf[MAX_ADDR_LEN];\n-\t} uaddr;\n \tint r;\n \tstruct socket *sock = sockfd_lookup(fd, &r);\n \n@@ -16,11 +12,7 @@\n \t\tgoto err;\n \t}\n \n-\tr = sock->ops->getname(sock, (struct sockaddr *)&uaddr.sa, 0);\n-\tif (r < 0)\n-\t\tgoto err;\n-\n-\tif (uaddr.sa.sll_family != AF_PACKET) {\n+\tif (sock->sk->sk_family != AF_PACKET) {\n \t\tr = -EPFNOSUPPORT;\n \t\tgoto err;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (sock->sk->sk_family != AF_PACKET) {"
            ],
            "deleted": [
                "\tstruct {",
                "\t\tstruct sockaddr_ll sa;",
                "\t\tchar  buf[MAX_ADDR_LEN];",
                "\t} uaddr;",
                "\tr = sock->ops->getname(sock, (struct sockaddr *)&uaddr.sa, 0);",
                "\tif (r < 0)",
                "\t\tgoto err;",
                "",
                "\tif (uaddr.sa.sll_family != AF_PACKET) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 5.5.8, get_raw_socket in drivers/vhost/net.c lacks validation of an sk_family field, which might allow attackers to trigger kernel stack corruption via crafted system calls."
    },
    {
        "cve_id": "CVE-2020-11565",
        "code_before_change": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}",
        "code_after_change": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only, although later\n\t\t * we use first_node(nodes) to grab a single node, so here\n\t\t * nodelist (or nodes) cannot be empty.\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t\tif (nodes_empty(nodes))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,13 +27,17 @@\n \tswitch (mode) {\n \tcase MPOL_PREFERRED:\n \t\t/*\n-\t\t * Insist on a nodelist of one node only\n+\t\t * Insist on a nodelist of one node only, although later\n+\t\t * we use first_node(nodes) to grab a single node, so here\n+\t\t * nodelist (or nodes) cannot be empty.\n \t\t */\n \t\tif (nodelist) {\n \t\t\tchar *rest = nodelist;\n \t\t\twhile (isdigit(*rest))\n \t\t\t\trest++;\n \t\t\tif (*rest)\n+\t\t\t\tgoto out;\n+\t\t\tif (nodes_empty(nodes))\n \t\t\t\tgoto out;\n \t\t}\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\t\t * Insist on a nodelist of one node only, although later",
                "\t\t * we use first_node(nodes) to grab a single node, so here",
                "\t\t * nodelist (or nodes) cannot be empty.",
                "\t\t\t\tgoto out;",
                "\t\t\tif (nodes_empty(nodes))"
            ],
            "deleted": [
                "\t\t * Insist on a nodelist of one node only"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.6.2. mpol_parse_str in mm/mempolicy.c has a stack-based out-of-bounds write because an empty nodelist is mishandled during mount option parsing, aka CID-aa9f7d5172fa. NOTE: Someone in the security community disagrees that this is a vulnerability because the issue \u201cis a bug in parsing mount options which can only be specified by a privileged user, so triggering the bug does not grant any powers not already held.\u201d"
    },
    {
        "cve_id": "CVE-2020-12653",
        "code_before_change": "int\nmwifiex_cmd_append_vsie_tlv(struct mwifiex_private *priv,\n\t\t\t    u16 vsie_mask, u8 **buffer)\n{\n\tint id, ret_len = 0;\n\tstruct mwifiex_ie_types_vendor_param_set *vs_param_set;\n\n\tif (!buffer)\n\t\treturn 0;\n\tif (!(*buffer))\n\t\treturn 0;\n\n\t/*\n\t * Traverse through the saved vendor specific IE array and append\n\t * the selected(scan/assoc/adhoc) IE as TLV to the command\n\t */\n\tfor (id = 0; id < MWIFIEX_MAX_VSIE_NUM; id++) {\n\t\tif (priv->vs_ie[id].mask & vsie_mask) {\n\t\t\tvs_param_set =\n\t\t\t\t(struct mwifiex_ie_types_vendor_param_set *)\n\t\t\t\t*buffer;\n\t\t\tvs_param_set->header.type =\n\t\t\t\tcpu_to_le16(TLV_TYPE_PASSTHROUGH);\n\t\t\tvs_param_set->header.len =\n\t\t\t\tcpu_to_le16((((u16) priv->vs_ie[id].ie[1])\n\t\t\t\t& 0x00FF) + 2);\n\t\t\tmemcpy(vs_param_set->ie, priv->vs_ie[id].ie,\n\t\t\t       le16_to_cpu(vs_param_set->header.len));\n\t\t\t*buffer += le16_to_cpu(vs_param_set->header.len) +\n\t\t\t\t   sizeof(struct mwifiex_ie_types_header);\n\t\t\tret_len += le16_to_cpu(vs_param_set->header.len) +\n\t\t\t\t   sizeof(struct mwifiex_ie_types_header);\n\t\t}\n\t}\n\treturn ret_len;\n}",
        "code_after_change": "int\nmwifiex_cmd_append_vsie_tlv(struct mwifiex_private *priv,\n\t\t\t    u16 vsie_mask, u8 **buffer)\n{\n\tint id, ret_len = 0;\n\tstruct mwifiex_ie_types_vendor_param_set *vs_param_set;\n\n\tif (!buffer)\n\t\treturn 0;\n\tif (!(*buffer))\n\t\treturn 0;\n\n\t/*\n\t * Traverse through the saved vendor specific IE array and append\n\t * the selected(scan/assoc/adhoc) IE as TLV to the command\n\t */\n\tfor (id = 0; id < MWIFIEX_MAX_VSIE_NUM; id++) {\n\t\tif (priv->vs_ie[id].mask & vsie_mask) {\n\t\t\tvs_param_set =\n\t\t\t\t(struct mwifiex_ie_types_vendor_param_set *)\n\t\t\t\t*buffer;\n\t\t\tvs_param_set->header.type =\n\t\t\t\tcpu_to_le16(TLV_TYPE_PASSTHROUGH);\n\t\t\tvs_param_set->header.len =\n\t\t\t\tcpu_to_le16((((u16) priv->vs_ie[id].ie[1])\n\t\t\t\t& 0x00FF) + 2);\n\t\t\tif (le16_to_cpu(vs_param_set->header.len) >\n\t\t\t\tMWIFIEX_MAX_VSIE_LEN) {\n\t\t\t\tmwifiex_dbg(priv->adapter, ERROR,\n\t\t\t\t\t    \"Invalid param length!\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tmemcpy(vs_param_set->ie, priv->vs_ie[id].ie,\n\t\t\t       le16_to_cpu(vs_param_set->header.len));\n\t\t\t*buffer += le16_to_cpu(vs_param_set->header.len) +\n\t\t\t\t   sizeof(struct mwifiex_ie_types_header);\n\t\t\tret_len += le16_to_cpu(vs_param_set->header.len) +\n\t\t\t\t   sizeof(struct mwifiex_ie_types_header);\n\t\t}\n\t}\n\treturn ret_len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,6 +24,13 @@\n \t\t\tvs_param_set->header.len =\n \t\t\t\tcpu_to_le16((((u16) priv->vs_ie[id].ie[1])\n \t\t\t\t& 0x00FF) + 2);\n+\t\t\tif (le16_to_cpu(vs_param_set->header.len) >\n+\t\t\t\tMWIFIEX_MAX_VSIE_LEN) {\n+\t\t\t\tmwifiex_dbg(priv->adapter, ERROR,\n+\t\t\t\t\t    \"Invalid param length!\\n\");\n+\t\t\t\tbreak;\n+\t\t\t}\n+\n \t\t\tmemcpy(vs_param_set->ie, priv->vs_ie[id].ie,\n \t\t\t       le16_to_cpu(vs_param_set->header.len));\n \t\t\t*buffer += le16_to_cpu(vs_param_set->header.len) +",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (le16_to_cpu(vs_param_set->header.len) >",
                "\t\t\t\tMWIFIEX_MAX_VSIE_LEN) {",
                "\t\t\t\tmwifiex_dbg(priv->adapter, ERROR,",
                "\t\t\t\t\t    \"Invalid param length!\\n\");",
                "\t\t\t\tbreak;",
                "\t\t\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was found in Linux kernel before 5.5.4. The mwifiex_cmd_append_vsie_tlv() function in drivers/net/wireless/marvell/mwifiex/scan.c allows local users to gain privileges or cause a denial of service because of an incorrect memcpy and buffer overflow, aka CID-b70261a288ea."
    },
    {
        "cve_id": "CVE-2020-12654",
        "code_before_change": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}",
        "code_after_change": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >\n\t\t\t\tsizeof(struct ieee_types_wmm_parameter))\n\t\t\t\tbreak;\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -60,6 +60,10 @@\n \t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n \t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n \n+\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >\n+\t\t\t\tsizeof(struct ieee_types_wmm_parameter))\n+\t\t\t\tbreak;\n+\n \t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n \t\t\t       wmm_ie, wmm_param_ie,\n \t\t\t       wmm_param_ie->vend_hdr.len + 2);",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >",
                "\t\t\t\tsizeof(struct ieee_types_wmm_parameter))",
                "\t\t\t\tbreak;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was found in Linux kernel before 5.5.4. mwifiex_ret_wmm_get_status() in drivers/net/wireless/marvell/mwifiex/wmm.c allows a remote AP to trigger a heap-based buffer overflow because of an incorrect memcpy, aka CID-3a9b153c5591."
    },
    {
        "cve_id": "CVE-2020-12659",
        "code_before_change": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint size_chk, err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;\n\tif (size_chk < 0)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}",
        "code_after_change": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n \tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n \tunsigned int chunks, chunks_per_page;\n \tu64 addr = mr->addr, size = mr->len;\n-\tint size_chk, err;\n+\tint err;\n \n \tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n \t\t/* Strictly speaking we could support this, if:\n@@ -43,8 +43,7 @@\n \t\t\treturn -EINVAL;\n \t}\n \n-\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;\n-\tif (size_chk < 0)\n+\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)\n \t\treturn -EINVAL;\n \n \tumem->address = (unsigned long)addr;",
        "function_modified_lines": {
            "added": [
                "\tint err;",
                "\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)"
            ],
            "deleted": [
                "\tint size_chk, err;",
                "\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;",
                "\tif (size_chk < 0)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.6.7. xdp_umem_reg in net/xdp/xdp_umem.c has an out-of-bounds write (by a user with the CAP_NET_ADMIN capability) because of a lack of headroom validation."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "static int __init nf_conntrack_ftp_init(void)\n{\n\tint i, ret = 0;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_ftp_master));\n\n\tftp_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!ftp_buffer)\n\t\treturn -ENOMEM;\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = FTP_PORT;\n\n\t/* FIXME should be configurable whether IPv4 and IPv6 FTP connections\n\t\t are tracked or not - YK */\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&ftp[2 * i], AF_INET, IPPROTO_TCP, \"ftp\",\n\t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,\n\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);\n\t\tnf_ct_helper_init(&ftp[2 * i + 1], AF_INET6, IPPROTO_TCP, \"ftp\",\n\t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,\n\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(ftp, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(ftp_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int __init nf_conntrack_ftp_init(void)\n{\n\tint i, ret = 0;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_ftp_master));\n\n\tftp_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!ftp_buffer)\n\t\treturn -ENOMEM;\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = FTP_PORT;\n\n\t/* FIXME should be configurable whether IPv4 and IPv6 FTP connections\n\t\t are tracked or not - YK */\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&ftp[2 * i], AF_INET, IPPROTO_TCP, \"ftp\",\n\t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);\n\t\tnf_ct_helper_init(&ftp[2 * i + 1], AF_INET6, IPPROTO_TCP, \"ftp\",\n\t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(ftp, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(ftp_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,12 +16,10 @@\n \tfor (i = 0; i < ports_c; i++) {\n \t\tnf_ct_helper_init(&ftp[2 * i], AF_INET, IPPROTO_TCP, \"ftp\",\n \t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n-\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,\n-\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);\n+\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);\n \t\tnf_ct_helper_init(&ftp[2 * i + 1], AF_INET6, IPPROTO_TCP, \"ftp\",\n \t\t\t\t  FTP_PORT, ports[i], ports[i], &ftp_exp_policy,\n-\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,\n-\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);\n+\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);\n \t}\n \n \tret = nf_conntrack_helpers_register(ftp, ports_c * 2);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);",
                "\t\t\t\t  0, help, nf_ct_ftp_from_nlattr, THIS_MODULE);"
            ],
            "deleted": [
                "\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,",
                "\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);",
                "\t\t\t\t  0, sizeof(struct nf_ct_ftp_master), help,",
                "\t\t\t\t  nf_ct_ftp_from_nlattr, THIS_MODULE);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "struct nf_conn_help *\nnf_ct_helper_ext_add(struct nf_conn *ct,\n\t\t     struct nf_conntrack_helper *helper, gfp_t gfp)\n{\n\tstruct nf_conn_help *help;\n\n\thelp = nf_ct_ext_add_length(ct, NF_CT_EXT_HELPER,\n\t\t\t\t    helper->data_len, gfp);\n\tif (help)\n\t\tINIT_HLIST_HEAD(&help->expectations);\n\telse\n\t\tpr_debug(\"failed to add helper extension area\");\n\treturn help;\n}",
        "code_after_change": "struct nf_conn_help *\nnf_ct_helper_ext_add(struct nf_conn *ct,\n\t\t     struct nf_conntrack_helper *helper, gfp_t gfp)\n{\n\tstruct nf_conn_help *help;\n\n\thelp = nf_ct_ext_add(ct, NF_CT_EXT_HELPER, gfp);\n\tif (help)\n\t\tINIT_HLIST_HEAD(&help->expectations);\n\telse\n\t\tpr_debug(\"failed to add helper extension area\");\n\treturn help;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,8 +4,7 @@\n {\n \tstruct nf_conn_help *help;\n \n-\thelp = nf_ct_ext_add_length(ct, NF_CT_EXT_HELPER,\n-\t\t\t\t    helper->data_len, gfp);\n+\thelp = nf_ct_ext_add(ct, NF_CT_EXT_HELPER, gfp);\n \tif (help)\n \t\tINIT_HLIST_HEAD(&help->expectations);\n \telse",
        "function_modified_lines": {
            "added": [
                "\thelp = nf_ct_ext_add(ct, NF_CT_EXT_HELPER, gfp);"
            ],
            "deleted": [
                "\thelp = nf_ct_ext_add_length(ct, NF_CT_EXT_HELPER,",
                "\t\t\t\t    helper->data_len, gfp);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "static int __init nf_conntrack_irc_init(void)\n{\n\tint i, ret;\n\n\tif (max_dcc_channels < 1) {\n\t\tpr_err(\"max_dcc_channels must not be zero\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (max_dcc_channels > NF_CT_EXPECT_MAX_CNT) {\n\t\tpr_err(\"max_dcc_channels must not be more than %u\\n\",\n\t\t       NF_CT_EXPECT_MAX_CNT);\n\t\treturn -EINVAL;\n\t}\n\n\tirc_exp_policy.max_expected = max_dcc_channels;\n\tirc_exp_policy.timeout = dcc_timeout;\n\n\tirc_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!irc_buffer)\n\t\treturn -ENOMEM;\n\n\t/* If no port given, default to standard irc port */\n\tif (ports_c == 0)\n\t\tports[ports_c++] = IRC_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&irc[i], AF_INET, IPPROTO_TCP, \"irc\",\n\t\t\t\t  IRC_PORT, ports[i], i, &irc_exp_policy,\n\t\t\t\t  0, 0, help, NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(&irc[0], ports_c);\n\tif (ret) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(irc_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int __init nf_conntrack_irc_init(void)\n{\n\tint i, ret;\n\n\tif (max_dcc_channels < 1) {\n\t\tpr_err(\"max_dcc_channels must not be zero\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (max_dcc_channels > NF_CT_EXPECT_MAX_CNT) {\n\t\tpr_err(\"max_dcc_channels must not be more than %u\\n\",\n\t\t       NF_CT_EXPECT_MAX_CNT);\n\t\treturn -EINVAL;\n\t}\n\n\tirc_exp_policy.max_expected = max_dcc_channels;\n\tirc_exp_policy.timeout = dcc_timeout;\n\n\tirc_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!irc_buffer)\n\t\treturn -ENOMEM;\n\n\t/* If no port given, default to standard irc port */\n\tif (ports_c == 0)\n\t\tports[ports_c++] = IRC_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&irc[i], AF_INET, IPPROTO_TCP, \"irc\",\n\t\t\t\t  IRC_PORT, ports[i], i, &irc_exp_policy,\n\t\t\t\t  0, help, NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(&irc[0], ports_c);\n\tif (ret) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(irc_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,7 +27,7 @@\n \tfor (i = 0; i < ports_c; i++) {\n \t\tnf_ct_helper_init(&irc[i], AF_INET, IPPROTO_TCP, \"irc\",\n \t\t\t\t  IRC_PORT, ports[i], i, &irc_exp_policy,\n-\t\t\t\t  0, 0, help, NULL, THIS_MODULE);\n+\t\t\t\t  0, help, NULL, THIS_MODULE);\n \t}\n \n \tret = nf_conntrack_helpers_register(&irc[0], ports_c);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t  0, help, NULL, THIS_MODULE);"
            ],
            "deleted": [
                "\t\t\t\t  0, 0, help, NULL, THIS_MODULE);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "static int __init nf_conntrack_sane_init(void)\n{\n\tint i, ret = 0;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_sane_master));\n\n\tsane_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!sane_buffer)\n\t\treturn -ENOMEM;\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = SANE_PORT;\n\n\t/* FIXME should be configurable whether IPv4 and IPv6 connections\n\t\t are tracked or not - YK */\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&sane[2 * i], AF_INET, IPPROTO_TCP, \"sane\",\n\t\t\t\t  SANE_PORT, ports[i], ports[i],\n\t\t\t\t  &sane_exp_policy, 0,\n\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,\n\t\t\t\t  THIS_MODULE);\n\t\tnf_ct_helper_init(&sane[2 * i + 1], AF_INET6, IPPROTO_TCP, \"sane\",\n\t\t\t\t  SANE_PORT, ports[i], ports[i],\n\t\t\t\t  &sane_exp_policy, 0,\n\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,\n\t\t\t\t  THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(sane, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(sane_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int __init nf_conntrack_sane_init(void)\n{\n\tint i, ret = 0;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_sane_master));\n\n\tsane_buffer = kmalloc(65536, GFP_KERNEL);\n\tif (!sane_buffer)\n\t\treturn -ENOMEM;\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = SANE_PORT;\n\n\t/* FIXME should be configurable whether IPv4 and IPv6 connections\n\t\t are tracked or not - YK */\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&sane[2 * i], AF_INET, IPPROTO_TCP, \"sane\",\n\t\t\t\t  SANE_PORT, ports[i], ports[i],\n\t\t\t\t  &sane_exp_policy, 0, help, NULL,\n\t\t\t\t  THIS_MODULE);\n\t\tnf_ct_helper_init(&sane[2 * i + 1], AF_INET6, IPPROTO_TCP, \"sane\",\n\t\t\t\t  SANE_PORT, ports[i], ports[i],\n\t\t\t\t  &sane_exp_policy, 0, help, NULL,\n\t\t\t\t  THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(sane, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\tkfree(sane_buffer);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,13 +16,11 @@\n \tfor (i = 0; i < ports_c; i++) {\n \t\tnf_ct_helper_init(&sane[2 * i], AF_INET, IPPROTO_TCP, \"sane\",\n \t\t\t\t  SANE_PORT, ports[i], ports[i],\n-\t\t\t\t  &sane_exp_policy, 0,\n-\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,\n+\t\t\t\t  &sane_exp_policy, 0, help, NULL,\n \t\t\t\t  THIS_MODULE);\n \t\tnf_ct_helper_init(&sane[2 * i + 1], AF_INET6, IPPROTO_TCP, \"sane\",\n \t\t\t\t  SANE_PORT, ports[i], ports[i],\n-\t\t\t\t  &sane_exp_policy, 0,\n-\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,\n+\t\t\t\t  &sane_exp_policy, 0, help, NULL,\n \t\t\t\t  THIS_MODULE);\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t  &sane_exp_policy, 0, help, NULL,",
                "\t\t\t\t  &sane_exp_policy, 0, help, NULL,"
            ],
            "deleted": [
                "\t\t\t\t  &sane_exp_policy, 0,",
                "\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,",
                "\t\t\t\t  &sane_exp_policy, 0,",
                "\t\t\t\t  sizeof(struct nf_ct_sane_master), help, NULL,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "static int __init nf_conntrack_sip_init(void)\n{\n\tint i, ret;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_sip_master));\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = SIP_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&sip[4 * i], AF_INET, IPPROTO_UDP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX,\n\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 1], AF_INET, IPPROTO_TCP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX,\n\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 2], AF_INET6, IPPROTO_UDP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX,\n\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 3], AF_INET6, IPPROTO_TCP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX,\n\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(sip, ports_c * 4);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int __init nf_conntrack_sip_init(void)\n{\n\tint i, ret;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(sizeof(struct nf_ct_sip_master));\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = SIP_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&sip[4 * i], AF_INET, IPPROTO_UDP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 1], AF_INET, IPPROTO_TCP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 2], AF_INET6, IPPROTO_UDP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&sip[4 * i + 3], AF_INET6, IPPROTO_TCP, \"sip\",\n\t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,\n\t\t\t\t  NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(sip, ports_c * 4);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,23 +10,19 @@\n \tfor (i = 0; i < ports_c; i++) {\n \t\tnf_ct_helper_init(&sip[4 * i], AF_INET, IPPROTO_UDP, \"sip\",\n \t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n-\t\t\t\t  SIP_EXPECT_MAX,\n-\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,\n+\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,\n \t\t\t\t  NULL, THIS_MODULE);\n \t\tnf_ct_helper_init(&sip[4 * i + 1], AF_INET, IPPROTO_TCP, \"sip\",\n \t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n-\t\t\t\t  SIP_EXPECT_MAX,\n-\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,\n+\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,\n \t\t\t\t  NULL, THIS_MODULE);\n \t\tnf_ct_helper_init(&sip[4 * i + 2], AF_INET6, IPPROTO_UDP, \"sip\",\n \t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n-\t\t\t\t  SIP_EXPECT_MAX,\n-\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,\n+\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,\n \t\t\t\t  NULL, THIS_MODULE);\n \t\tnf_ct_helper_init(&sip[4 * i + 3], AF_INET6, IPPROTO_TCP, \"sip\",\n \t\t\t\t  SIP_PORT, ports[i], i, sip_exp_policy,\n-\t\t\t\t  SIP_EXPECT_MAX,\n-\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,\n+\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,\n \t\t\t\t  NULL, THIS_MODULE);\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,",
                "\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,",
                "\t\t\t\t  SIP_EXPECT_MAX, sip_help_udp,",
                "\t\t\t\t  SIP_EXPECT_MAX, sip_help_tcp,"
            ],
            "deleted": [
                "\t\t\t\t  SIP_EXPECT_MAX,",
                "\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,",
                "\t\t\t\t  SIP_EXPECT_MAX,",
                "\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,",
                "\t\t\t\t  SIP_EXPECT_MAX,",
                "\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_udp,",
                "\t\t\t\t  SIP_EXPECT_MAX,",
                "\t\t\t\t  sizeof(struct nf_ct_sip_master), sip_help_tcp,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14305",
        "code_before_change": "static int __init nf_conntrack_tftp_init(void)\n{\n\tint i, ret;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(0);\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = TFTP_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&tftp[2 * i], AF_INET, IPPROTO_UDP, \"tftp\",\n\t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&tftp[2 * i + 1], AF_INET6, IPPROTO_UDP, \"tftp\",\n\t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(tftp, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int __init nf_conntrack_tftp_init(void)\n{\n\tint i, ret;\n\n\tNF_CT_HELPER_BUILD_BUG_ON(0);\n\n\tif (ports_c == 0)\n\t\tports[ports_c++] = TFTP_PORT;\n\n\tfor (i = 0; i < ports_c; i++) {\n\t\tnf_ct_helper_init(&tftp[2 * i], AF_INET, IPPROTO_UDP, \"tftp\",\n\t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);\n\t\tnf_ct_helper_init(&tftp[2 * i + 1], AF_INET6, IPPROTO_UDP, \"tftp\",\n\t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);\n\t}\n\n\tret = nf_conntrack_helpers_register(tftp, ports_c * 2);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to register helpers\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,10 +10,10 @@\n \tfor (i = 0; i < ports_c; i++) {\n \t\tnf_ct_helper_init(&tftp[2 * i], AF_INET, IPPROTO_UDP, \"tftp\",\n \t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n-\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);\n+\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);\n \t\tnf_ct_helper_init(&tftp[2 * i + 1], AF_INET6, IPPROTO_UDP, \"tftp\",\n \t\t\t\t  TFTP_PORT, ports[i], i, &tftp_exp_policy,\n-\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);\n+\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);\n \t}\n \n \tret = nf_conntrack_helpers_register(tftp, ports_c * 2);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);",
                "\t\t\t\t  0, tftp_help, NULL, THIS_MODULE);"
            ],
            "deleted": [
                "\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);",
                "\t\t\t\t  0, 0, tftp_help, NULL, THIS_MODULE);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in how the Linux kernel\u2019s Voice Over IP H.323 connection tracking functionality handled connections on ipv6 port 1720. This flaw allows an unauthenticated remote user to crash the system, causing a denial of service. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14331",
        "code_before_change": "static void vgacon_scrollback_update(struct vc_data *c, int t, int count)\n{\n\tvoid *p;\n\n\tif (!vgacon_scrollback_cur->data || !vgacon_scrollback_cur->size ||\n\t    c->vc_num != fg_console)\n\t\treturn;\n\n\tp = (void *) (c->vc_origin + t * c->vc_size_row);\n\n\twhile (count--) {\n\t\tscr_memcpyw(vgacon_scrollback_cur->data +\n\t\t\t    vgacon_scrollback_cur->tail,\n\t\t\t    p, c->vc_size_row);\n\n\t\tvgacon_scrollback_cur->cnt++;\n\t\tp += c->vc_size_row;\n\t\tvgacon_scrollback_cur->tail += c->vc_size_row;\n\n\t\tif (vgacon_scrollback_cur->tail >= vgacon_scrollback_cur->size)\n\t\t\tvgacon_scrollback_cur->tail = 0;\n\n\t\tif (vgacon_scrollback_cur->cnt > vgacon_scrollback_cur->rows)\n\t\t\tvgacon_scrollback_cur->cnt = vgacon_scrollback_cur->rows;\n\n\t\tvgacon_scrollback_cur->cur = vgacon_scrollback_cur->cnt;\n\t}\n}",
        "code_after_change": "static void vgacon_scrollback_update(struct vc_data *c, int t, int count)\n{\n\tvoid *p;\n\n\tif (!vgacon_scrollback_cur->data || !vgacon_scrollback_cur->size ||\n\t    c->vc_num != fg_console)\n\t\treturn;\n\n\tp = (void *) (c->vc_origin + t * c->vc_size_row);\n\n\twhile (count--) {\n\t\tif ((vgacon_scrollback_cur->tail + c->vc_size_row) >\n\t\t    vgacon_scrollback_cur->size)\n\t\t\tvgacon_scrollback_cur->tail = 0;\n\n\t\tscr_memcpyw(vgacon_scrollback_cur->data +\n\t\t\t    vgacon_scrollback_cur->tail,\n\t\t\t    p, c->vc_size_row);\n\n\t\tvgacon_scrollback_cur->cnt++;\n\t\tp += c->vc_size_row;\n\t\tvgacon_scrollback_cur->tail += c->vc_size_row;\n\n\t\tif (vgacon_scrollback_cur->tail >= vgacon_scrollback_cur->size)\n\t\t\tvgacon_scrollback_cur->tail = 0;\n\n\t\tif (vgacon_scrollback_cur->cnt > vgacon_scrollback_cur->rows)\n\t\t\tvgacon_scrollback_cur->cnt = vgacon_scrollback_cur->rows;\n\n\t\tvgacon_scrollback_cur->cur = vgacon_scrollback_cur->cnt;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,10 @@\n \tp = (void *) (c->vc_origin + t * c->vc_size_row);\n \n \twhile (count--) {\n+\t\tif ((vgacon_scrollback_cur->tail + c->vc_size_row) >\n+\t\t    vgacon_scrollback_cur->size)\n+\t\t\tvgacon_scrollback_cur->tail = 0;\n+\n \t\tscr_memcpyw(vgacon_scrollback_cur->data +\n \t\t\t    vgacon_scrollback_cur->tail,\n \t\t\t    p, c->vc_size_row);",
        "function_modified_lines": {
            "added": [
                "\t\tif ((vgacon_scrollback_cur->tail + c->vc_size_row) >",
                "\t\t    vgacon_scrollback_cur->size)",
                "\t\t\tvgacon_scrollback_cur->tail = 0;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel\u2019s implementation of the invert video code on VGA consoles when a local attacker attempts to resize the console, calling an ioctl VT_RESIZE, which causes an out-of-bounds write to occur. This flaw allows a local user with access to the VGA console to crash the system, potentially escalating their privileges on the system. The highest threat from this vulnerability is to data confidentiality and integrity as well as system availability."
    },
    {
        "cve_id": "CVE-2020-14386",
        "code_before_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, netoff, hdrlen;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec64 ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\tunsigned int slot_id = 0;\n\tbool do_vnet = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\t/* If we are flooded, just give up */\n\tif (__packet_rcv_has_room(po, skb) == ROOM_NONE) {\n\t\tatomic_inc(&po->tp_drops);\n\t\tgoto drop_n_restore;\n\t}\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr) {\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\t\tdo_vnet = true;\n\t\t}\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0) {\n\t\t\t\tsnaplen = 0;\n\t\t\t\tdo_vnet = false;\n\t\t\t}\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t\tdo_vnet = false;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tslot_id = po->rx_ring.head;\n\t\tif (test_bit(slot_id, po->rx_ring.rx_owner_map))\n\t\t\tgoto drop_n_account;\n\t\t__set_bit(slot_id, po->rx_ring.rx_owner_map);\n\t}\n\n\tif (do_vnet &&\n\t    virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t    vio_le(), true, 0)) {\n\t\tif (po->tp_version == TPACKET_V3)\n\t\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t\tgoto drop_n_account;\n\t}\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (atomic_read(&po->tp_drops))\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tktime_get_real_ts64(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t__packet_set_status(po, h.raw, status);\n\t\t__clear_bit(slot_id, po->rx_ring.rx_owner_map);\n\t\tspin_unlock(&sk->sk_receive_queue.lock);\n\t\tsk->sk_data_ready(sk);\n\t} else if (po->tp_version == TPACKET_V3) {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\tatomic_inc(&po->tp_drops);\n\tis_drop_n_account = true;\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
        "code_after_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, hdrlen;\n\tunsigned int netoff;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec64 ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\tunsigned int slot_id = 0;\n\tbool do_vnet = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\t/* If we are flooded, just give up */\n\tif (__packet_rcv_has_room(po, skb) == ROOM_NONE) {\n\t\tatomic_inc(&po->tp_drops);\n\t\tgoto drop_n_restore;\n\t}\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr) {\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\t\tdo_vnet = true;\n\t\t}\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (netoff > USHRT_MAX) {\n\t\tatomic_inc(&po->tp_drops);\n\t\tgoto drop_n_restore;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0) {\n\t\t\t\tsnaplen = 0;\n\t\t\t\tdo_vnet = false;\n\t\t\t}\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t\tdo_vnet = false;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tslot_id = po->rx_ring.head;\n\t\tif (test_bit(slot_id, po->rx_ring.rx_owner_map))\n\t\t\tgoto drop_n_account;\n\t\t__set_bit(slot_id, po->rx_ring.rx_owner_map);\n\t}\n\n\tif (do_vnet &&\n\t    virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t    vio_le(), true, 0)) {\n\t\tif (po->tp_version == TPACKET_V3)\n\t\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t\tgoto drop_n_account;\n\t}\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (atomic_read(&po->tp_drops))\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tktime_get_real_ts64(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t__packet_set_status(po, h.raw, status);\n\t\t__clear_bit(slot_id, po->rx_ring.rx_owner_map);\n\t\tspin_unlock(&sk->sk_receive_queue.lock);\n\t\tsk->sk_data_ready(sk);\n\t} else if (po->tp_version == TPACKET_V3) {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\tatomic_inc(&po->tp_drops);\n\tis_drop_n_account = true;\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,8 @@\n \tint skb_len = skb->len;\n \tunsigned int snaplen, res;\n \tunsigned long status = TP_STATUS_USER;\n-\tunsigned short macoff, netoff, hdrlen;\n+\tunsigned short macoff, hdrlen;\n+\tunsigned int netoff;\n \tstruct sk_buff *copy_skb = NULL;\n \tstruct timespec64 ts;\n \t__u32 ts_status;\n@@ -77,6 +78,10 @@\n \t\t\tdo_vnet = true;\n \t\t}\n \t\tmacoff = netoff - maclen;\n+\t}\n+\tif (netoff > USHRT_MAX) {\n+\t\tatomic_inc(&po->tp_drops);\n+\t\tgoto drop_n_restore;\n \t}\n \tif (po->tp_version <= TPACKET_V2) {\n \t\tif (macoff + snaplen > po->rx_ring.frame_size) {",
        "function_modified_lines": {
            "added": [
                "\tunsigned short macoff, hdrlen;",
                "\tunsigned int netoff;",
                "\t}",
                "\tif (netoff > USHRT_MAX) {",
                "\t\tatomic_inc(&po->tp_drops);",
                "\t\tgoto drop_n_restore;"
            ],
            "deleted": [
                "\tunsigned short macoff, netoff, hdrlen;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel before 5.9-rc4. Memory corruption can be exploited to gain root privileges from unprivileged processes. The highest threat from this vulnerability is to data confidentiality and integrity."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static u16 *fbcon_screen_pos(struct vc_data *vc, int offset)\n{\n\tunsigned long p;\n\tint line;\n\n\tif (vc->vc_num != fg_console || !softback_lines)\n\t\treturn (u16 *) (vc->vc_origin + offset);\n\tline = offset / vc->vc_size_row;\n\tif (line >= softback_lines)\n\t\treturn (u16 *) (vc->vc_origin + offset -\n\t\t\t\tsoftback_lines * vc->vc_size_row);\n\tp = softback_curr + offset;\n\tif (p >= softback_end)\n\t\tp += softback_buf - softback_end;\n\treturn (u16 *) p;\n}",
        "code_after_change": "static u16 *fbcon_screen_pos(struct vc_data *vc, int offset)\n{\n\treturn (u16 *) (vc->vc_origin + offset);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,16 +1,4 @@\n static u16 *fbcon_screen_pos(struct vc_data *vc, int offset)\n {\n-\tunsigned long p;\n-\tint line;\n-\n-\tif (vc->vc_num != fg_console || !softback_lines)\n-\t\treturn (u16 *) (vc->vc_origin + offset);\n-\tline = offset / vc->vc_size_row;\n-\tif (line >= softback_lines)\n-\t\treturn (u16 *) (vc->vc_origin + offset -\n-\t\t\t\tsoftback_lines * vc->vc_size_row);\n-\tp = softback_curr + offset;\n-\tif (p >= softback_end)\n-\t\tp += softback_buf - softback_end;\n-\treturn (u16 *) p;\n+\treturn (u16 *) (vc->vc_origin + offset);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn (u16 *) (vc->vc_origin + offset);"
            ],
            "deleted": [
                "\tunsigned long p;",
                "\tint line;",
                "",
                "\tif (vc->vc_num != fg_console || !softback_lines)",
                "\t\treturn (u16 *) (vc->vc_origin + offset);",
                "\tline = offset / vc->vc_size_row;",
                "\tif (line >= softback_lines)",
                "\t\treturn (u16 *) (vc->vc_origin + offset -",
                "\t\t\t\tsoftback_lines * vc->vc_size_row);",
                "\tp = softback_curr + offset;",
                "\tif (p >= softback_end)",
                "\t\tp += softback_buf - softback_end;",
                "\treturn (u16 *) p;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static unsigned long fbcon_getxy(struct vc_data *vc, unsigned long pos,\n\t\t\t\t int *px, int *py)\n{\n\tunsigned long ret;\n\tint x, y;\n\n\tif (pos >= vc->vc_origin && pos < vc->vc_scr_end) {\n\t\tunsigned long offset = (pos - vc->vc_origin) / 2;\n\n\t\tx = offset % vc->vc_cols;\n\t\ty = offset / vc->vc_cols;\n\t\tif (vc->vc_num == fg_console)\n\t\t\ty += softback_lines;\n\t\tret = pos + (vc->vc_cols - x) * 2;\n\t} else if (vc->vc_num == fg_console && softback_lines) {\n\t\tunsigned long offset = pos - softback_curr;\n\n\t\tif (pos < softback_curr)\n\t\t\toffset += softback_end - softback_buf;\n\t\toffset /= 2;\n\t\tx = offset % vc->vc_cols;\n\t\ty = offset / vc->vc_cols;\n\t\tret = pos + (vc->vc_cols - x) * 2;\n\t\tif (ret == softback_end)\n\t\t\tret = softback_buf;\n\t\tif (ret == softback_in)\n\t\t\tret = vc->vc_origin;\n\t} else {\n\t\t/* Should not happen */\n\t\tx = y = 0;\n\t\tret = vc->vc_origin;\n\t}\n\tif (px)\n\t\t*px = x;\n\tif (py)\n\t\t*py = y;\n\treturn ret;\n}",
        "code_after_change": "static unsigned long fbcon_getxy(struct vc_data *vc, unsigned long pos,\n\t\t\t\t int *px, int *py)\n{\n\tunsigned long ret;\n\tint x, y;\n\n\tif (pos >= vc->vc_origin && pos < vc->vc_scr_end) {\n\t\tunsigned long offset = (pos - vc->vc_origin) / 2;\n\n\t\tx = offset % vc->vc_cols;\n\t\ty = offset / vc->vc_cols;\n\t\tret = pos + (vc->vc_cols - x) * 2;\n\t} else {\n\t\t/* Should not happen */\n\t\tx = y = 0;\n\t\tret = vc->vc_origin;\n\t}\n\tif (px)\n\t\t*px = x;\n\tif (py)\n\t\t*py = y;\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,22 +9,7 @@\n \n \t\tx = offset % vc->vc_cols;\n \t\ty = offset / vc->vc_cols;\n-\t\tif (vc->vc_num == fg_console)\n-\t\t\ty += softback_lines;\n \t\tret = pos + (vc->vc_cols - x) * 2;\n-\t} else if (vc->vc_num == fg_console && softback_lines) {\n-\t\tunsigned long offset = pos - softback_curr;\n-\n-\t\tif (pos < softback_curr)\n-\t\t\toffset += softback_end - softback_buf;\n-\t\toffset /= 2;\n-\t\tx = offset % vc->vc_cols;\n-\t\ty = offset / vc->vc_cols;\n-\t\tret = pos + (vc->vc_cols - x) * 2;\n-\t\tif (ret == softback_end)\n-\t\t\tret = softback_buf;\n-\t\tif (ret == softback_in)\n-\t\t\tret = vc->vc_origin;\n \t} else {\n \t\t/* Should not happen */\n \t\tx = y = 0;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tif (vc->vc_num == fg_console)",
                "\t\t\ty += softback_lines;",
                "\t} else if (vc->vc_num == fg_console && softback_lines) {",
                "\t\tunsigned long offset = pos - softback_curr;",
                "",
                "\t\tif (pos < softback_curr)",
                "\t\t\toffset += softback_end - softback_buf;",
                "\t\toffset /= 2;",
                "\t\tx = offset % vc->vc_cols;",
                "\t\ty = offset / vc->vc_cols;",
                "\t\tret = pos + (vc->vc_cols - x) * 2;",
                "\t\tif (ret == softback_end)",
                "\t\t\tret = softback_buf;",
                "\t\tif (ret == softback_in)",
                "\t\t\tret = vc->vc_origin;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_invert_region(struct vc_data *vc, u16 * p, int cnt)\n{\n\twhile (cnt--) {\n\t\tu16 a = scr_readw(p);\n\t\tif (!vc->vc_can_do_color)\n\t\t\ta ^= 0x0800;\n\t\telse if (vc->vc_hi_font_mask == 0x100)\n\t\t\ta = ((a) & 0x11ff) | (((a) & 0xe000) >> 4) |\n\t\t\t    (((a) & 0x0e00) << 4);\n\t\telse\n\t\t\ta = ((a) & 0x88ff) | (((a) & 0x7000) >> 4) |\n\t\t\t    (((a) & 0x0700) << 4);\n\t\tscr_writew(a, p++);\n\t\tif (p == (u16 *) softback_end)\n\t\t\tp = (u16 *) softback_buf;\n\t\tif (p == (u16 *) softback_in)\n\t\t\tp = (u16 *) vc->vc_origin;\n\t}\n}",
        "code_after_change": "static void fbcon_invert_region(struct vc_data *vc, u16 * p, int cnt)\n{\n\twhile (cnt--) {\n\t\tu16 a = scr_readw(p);\n\t\tif (!vc->vc_can_do_color)\n\t\t\ta ^= 0x0800;\n\t\telse if (vc->vc_hi_font_mask == 0x100)\n\t\t\ta = ((a) & 0x11ff) | (((a) & 0xe000) >> 4) |\n\t\t\t    (((a) & 0x0e00) << 4);\n\t\telse\n\t\t\ta = ((a) & 0x88ff) | (((a) & 0x7000) >> 4) |\n\t\t\t    (((a) & 0x0700) << 4);\n\t\tscr_writew(a, p++);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,9 +11,5 @@\n \t\t\ta = ((a) & 0x88ff) | (((a) & 0x7000) >> 4) |\n \t\t\t    (((a) & 0x0700) << 4);\n \t\tscr_writew(a, p++);\n-\t\tif (p == (u16 *) softback_end)\n-\t\t\tp = (u16 *) softback_buf;\n-\t\tif (p == (u16 *) softback_in)\n-\t\t\tp = (u16 *) vc->vc_origin;\n \t}\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tif (p == (u16 *) softback_end)",
                "\t\t\tp = (u16 *) softback_buf;",
                "\t\tif (p == (u16 *) softback_in)",
                "\t\t\tp = (u16 *) vc->vc_origin;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static const char *fbcon_startup(void)\n{\n\tconst char *display_desc = \"frame buffer device\";\n\tstruct fbcon_display *p = &fb_display[fg_console];\n\tstruct vc_data *vc = vc_cons[fg_console].d;\n\tconst struct font_desc *font = NULL;\n\tstruct module *owner;\n\tstruct fb_info *info = NULL;\n\tstruct fbcon_ops *ops;\n\tint rows, cols;\n\n\t/*\n\t *  If num_registered_fb is zero, this is a call for the dummy part.\n\t *  The frame buffer devices weren't initialized yet.\n\t */\n\tif (!num_registered_fb || info_idx == -1)\n\t\treturn display_desc;\n\t/*\n\t * Instead of blindly using registered_fb[0], we use info_idx, set by\n\t * fb_console_init();\n\t */\n\tinfo = registered_fb[info_idx];\n\tif (!info)\n\t\treturn NULL;\n\t\n\towner = info->fbops->owner;\n\tif (!try_module_get(owner))\n\t\treturn NULL;\n\tif (info->fbops->fb_open && info->fbops->fb_open(info, 0)) {\n\t\tmodule_put(owner);\n\t\treturn NULL;\n\t}\n\n\tops = kzalloc(sizeof(struct fbcon_ops), GFP_KERNEL);\n\tif (!ops) {\n\t\tmodule_put(owner);\n\t\treturn NULL;\n\t}\n\n\tops->currcon = -1;\n\tops->graphics = 1;\n\tops->cur_rotate = -1;\n\tops->cur_blink_jiffies = HZ / 5;\n\tops->info = info;\n\tinfo->fbcon_par = ops;\n\n\tp->con_rotate = initial_rotation;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = info->fbcon_rotate_hint;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = FB_ROTATE_UR;\n\n\tset_blitting_type(vc, info);\n\n\tif (info->fix.type != FB_TYPE_TEXT) {\n\t\tif (fbcon_softback_size) {\n\t\t\tif (!softback_buf) {\n\t\t\t\tsoftback_buf =\n\t\t\t\t    (unsigned long)\n\t\t\t\t    kvmalloc(fbcon_softback_size,\n\t\t\t\t\t    GFP_KERNEL);\n\t\t\t\tif (!softback_buf) {\n\t\t\t\t\tfbcon_softback_size = 0;\n\t\t\t\t\tsoftback_top = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (softback_buf) {\n\t\t\t\tkvfree((void *) softback_buf);\n\t\t\t\tsoftback_buf = 0;\n\t\t\t\tsoftback_top = 0;\n\t\t\t}\n\t\t}\n\t\tif (softback_buf)\n\t\t\tsoftback_in = softback_top = softback_curr =\n\t\t\t    softback_buf;\n\t\tsoftback_lines = 0;\n\t}\n\n\t/* Setup default font */\n\tif (!p->fontdata && !vc->vc_font.data) {\n\t\tif (!fontname[0] || !(font = find_font(fontname)))\n\t\t\tfont = get_default_font(info->var.xres,\n\t\t\t\t\t\tinfo->var.yres,\n\t\t\t\t\t\tinfo->pixmap.blit_x,\n\t\t\t\t\t\tinfo->pixmap.blit_y);\n\t\tvc->vc_font.width = font->width;\n\t\tvc->vc_font.height = font->height;\n\t\tvc->vc_font.data = (void *)(p->fontdata = font->data);\n\t\tvc->vc_font.charcount = 256; /* FIXME  Need to support more fonts */\n\t} else {\n\t\tp->fontdata = vc->vc_font.data;\n\t}\n\n\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tcols /= vc->vc_font.width;\n\trows /= vc->vc_font.height;\n\tvc_resize(vc, cols, rows);\n\n\tDPRINTK(\"mode:   %s\\n\", info->fix.id);\n\tDPRINTK(\"visual: %d\\n\", info->fix.visual);\n\tDPRINTK(\"res:    %dx%d-%d\\n\", info->var.xres,\n\t\tinfo->var.yres,\n\t\tinfo->var.bits_per_pixel);\n\n\tfbcon_add_cursor_timer(info);\n\treturn display_desc;\n}",
        "code_after_change": "static const char *fbcon_startup(void)\n{\n\tconst char *display_desc = \"frame buffer device\";\n\tstruct fbcon_display *p = &fb_display[fg_console];\n\tstruct vc_data *vc = vc_cons[fg_console].d;\n\tconst struct font_desc *font = NULL;\n\tstruct module *owner;\n\tstruct fb_info *info = NULL;\n\tstruct fbcon_ops *ops;\n\tint rows, cols;\n\n\t/*\n\t *  If num_registered_fb is zero, this is a call for the dummy part.\n\t *  The frame buffer devices weren't initialized yet.\n\t */\n\tif (!num_registered_fb || info_idx == -1)\n\t\treturn display_desc;\n\t/*\n\t * Instead of blindly using registered_fb[0], we use info_idx, set by\n\t * fb_console_init();\n\t */\n\tinfo = registered_fb[info_idx];\n\tif (!info)\n\t\treturn NULL;\n\t\n\towner = info->fbops->owner;\n\tif (!try_module_get(owner))\n\t\treturn NULL;\n\tif (info->fbops->fb_open && info->fbops->fb_open(info, 0)) {\n\t\tmodule_put(owner);\n\t\treturn NULL;\n\t}\n\n\tops = kzalloc(sizeof(struct fbcon_ops), GFP_KERNEL);\n\tif (!ops) {\n\t\tmodule_put(owner);\n\t\treturn NULL;\n\t}\n\n\tops->currcon = -1;\n\tops->graphics = 1;\n\tops->cur_rotate = -1;\n\tops->cur_blink_jiffies = HZ / 5;\n\tops->info = info;\n\tinfo->fbcon_par = ops;\n\n\tp->con_rotate = initial_rotation;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = info->fbcon_rotate_hint;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = FB_ROTATE_UR;\n\n\tset_blitting_type(vc, info);\n\n\t/* Setup default font */\n\tif (!p->fontdata && !vc->vc_font.data) {\n\t\tif (!fontname[0] || !(font = find_font(fontname)))\n\t\t\tfont = get_default_font(info->var.xres,\n\t\t\t\t\t\tinfo->var.yres,\n\t\t\t\t\t\tinfo->pixmap.blit_x,\n\t\t\t\t\t\tinfo->pixmap.blit_y);\n\t\tvc->vc_font.width = font->width;\n\t\tvc->vc_font.height = font->height;\n\t\tvc->vc_font.data = (void *)(p->fontdata = font->data);\n\t\tvc->vc_font.charcount = 256; /* FIXME  Need to support more fonts */\n\t} else {\n\t\tp->fontdata = vc->vc_font.data;\n\t}\n\n\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tcols /= vc->vc_font.width;\n\trows /= vc->vc_font.height;\n\tvc_resize(vc, cols, rows);\n\n\tDPRINTK(\"mode:   %s\\n\", info->fix.id);\n\tDPRINTK(\"visual: %d\\n\", info->fix.visual);\n\tDPRINTK(\"res:    %dx%d-%d\\n\", info->var.xres,\n\t\tinfo->var.yres,\n\t\tinfo->var.bits_per_pixel);\n\n\tfbcon_add_cursor_timer(info);\n\treturn display_desc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -52,31 +52,6 @@\n \n \tset_blitting_type(vc, info);\n \n-\tif (info->fix.type != FB_TYPE_TEXT) {\n-\t\tif (fbcon_softback_size) {\n-\t\t\tif (!softback_buf) {\n-\t\t\t\tsoftback_buf =\n-\t\t\t\t    (unsigned long)\n-\t\t\t\t    kvmalloc(fbcon_softback_size,\n-\t\t\t\t\t    GFP_KERNEL);\n-\t\t\t\tif (!softback_buf) {\n-\t\t\t\t\tfbcon_softback_size = 0;\n-\t\t\t\t\tsoftback_top = 0;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t} else {\n-\t\t\tif (softback_buf) {\n-\t\t\t\tkvfree((void *) softback_buf);\n-\t\t\t\tsoftback_buf = 0;\n-\t\t\t\tsoftback_top = 0;\n-\t\t\t}\n-\t\t}\n-\t\tif (softback_buf)\n-\t\t\tsoftback_in = softback_top = softback_curr =\n-\t\t\t    softback_buf;\n-\t\tsoftback_lines = 0;\n-\t}\n-\n \t/* Setup default font */\n \tif (!p->fontdata && !vc->vc_font.data) {\n \t\tif (!fontname[0] || !(font = find_font(fontname)))",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (info->fix.type != FB_TYPE_TEXT) {",
                "\t\tif (fbcon_softback_size) {",
                "\t\t\tif (!softback_buf) {",
                "\t\t\t\tsoftback_buf =",
                "\t\t\t\t    (unsigned long)",
                "\t\t\t\t    kvmalloc(fbcon_softback_size,",
                "\t\t\t\t\t    GFP_KERNEL);",
                "\t\t\t\tif (!softback_buf) {",
                "\t\t\t\t\tfbcon_softback_size = 0;",
                "\t\t\t\t\tsoftback_top = 0;",
                "\t\t\t\t}",
                "\t\t\t}",
                "\t\t} else {",
                "\t\t\tif (softback_buf) {",
                "\t\t\t\tkvfree((void *) softback_buf);",
                "\t\t\t\tsoftback_buf = 0;",
                "\t\t\t\tsoftback_top = 0;",
                "\t\t\t}",
                "\t\t}",
                "\t\tif (softback_buf)",
                "\t\t\tsoftback_in = softback_top = softback_curr =",
                "\t\t\t    softback_buf;",
                "\t\tsoftback_lines = 0;",
                "\t}",
                ""
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static int fbcon_switch(struct vc_data *vc)\n{\n\tstruct fb_info *info, *old_info = NULL;\n\tstruct fbcon_ops *ops;\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tstruct fb_var_screeninfo var;\n\tint i, ret, prev_console, charcnt = 256;\n\n\tinfo = registered_fb[con2fb_map[vc->vc_num]];\n\tops = info->fbcon_par;\n\n\tif (softback_top) {\n\t\tif (softback_lines)\n\t\t\tfbcon_set_origin(vc);\n\t\tsoftback_top = softback_curr = softback_in = softback_buf;\n\t\tsoftback_lines = 0;\n\t\tfbcon_update_softback(vc);\n\t}\n\n\tif (logo_shown >= 0) {\n\t\tstruct vc_data *conp2 = vc_cons[logo_shown].d;\n\n\t\tif (conp2->vc_top == logo_lines\n\t\t    && conp2->vc_bottom == conp2->vc_rows)\n\t\t\tconp2->vc_top = 0;\n\t\tlogo_shown = FBCON_LOGO_CANSHOW;\n\t}\n\n\tprev_console = ops->currcon;\n\tif (prev_console != -1)\n\t\told_info = registered_fb[con2fb_map[prev_console]];\n\t/*\n\t * FIXME: If we have multiple fbdev's loaded, we need to\n\t * update all info->currcon.  Perhaps, we can place this\n\t * in a centralized structure, but this might break some\n\t * drivers.\n\t *\n\t * info->currcon = vc->vc_num;\n\t */\n\tfor_each_registered_fb(i) {\n\t\tif (registered_fb[i]->fbcon_par) {\n\t\t\tstruct fbcon_ops *o = registered_fb[i]->fbcon_par;\n\n\t\t\to->currcon = vc->vc_num;\n\t\t}\n\t}\n\tmemset(&var, 0, sizeof(struct fb_var_screeninfo));\n\tdisplay_to_var(&var, p);\n\tvar.activate = FB_ACTIVATE_NOW;\n\n\t/*\n\t * make sure we don't unnecessarily trip the memcmp()\n\t * in fb_set_var()\n\t */\n\tinfo->var.activate = var.activate;\n\tvar.vmode |= info->var.vmode & ~FB_VMODE_MASK;\n\tfb_set_var(info, &var);\n\tops->var = info->var;\n\n\tif (old_info != NULL && (old_info != info ||\n\t\t\t\t info->flags & FBINFO_MISC_ALWAYS_SETPAR)) {\n\t\tif (info->fbops->fb_set_par) {\n\t\t\tret = info->fbops->fb_set_par(info);\n\n\t\t\tif (ret)\n\t\t\t\tprintk(KERN_ERR \"fbcon_switch: detected \"\n\t\t\t\t\t\"unhandled fb_set_par error, \"\n\t\t\t\t\t\"error code %d\\n\", ret);\n\t\t}\n\n\t\tif (old_info != info)\n\t\t\tfbcon_del_cursor_timer(old_info);\n\t}\n\n\tif (fbcon_is_inactive(vc, info) ||\n\t    ops->blank_state != FB_BLANK_UNBLANK)\n\t\tfbcon_del_cursor_timer(info);\n\telse\n\t\tfbcon_add_cursor_timer(info);\n\n\tset_blitting_type(vc, info);\n\tops->cursor_reset = 1;\n\n\tif (ops->rotate_font && ops->rotate_font(info, vc)) {\n\t\tops->rotate = FB_ROTATE_UR;\n\t\tset_blitting_type(vc, info);\n\t}\n\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(vc->vc_font.data);\n\n\tif (charcnt > 256)\n\t\tvc->vc_complement_mask <<= 1;\n\n\tupdatescrollmode(p, info, vc);\n\n\tswitch (p->scrollmode) {\n\tcase SCROLL_WRAP_MOVE:\n\t\tscrollback_phys_max = p->vrows - vc->vc_rows;\n\t\tbreak;\n\tcase SCROLL_PAN_MOVE:\n\tcase SCROLL_PAN_REDRAW:\n\t\tscrollback_phys_max = p->vrows - 2 * vc->vc_rows;\n\t\tif (scrollback_phys_max < 0)\n\t\t\tscrollback_phys_max = 0;\n\t\tbreak;\n\tdefault:\n\t\tscrollback_phys_max = 0;\n\t\tbreak;\n\t}\n\n\tscrollback_max = 0;\n\tscrollback_current = 0;\n\n\tif (!fbcon_is_inactive(vc, info)) {\n\t    ops->var.xoffset = ops->var.yoffset = p->yscroll = 0;\n\t    ops->update_start(info);\n\t}\n\n\tfbcon_set_palette(vc, color_table); \t\n\tfbcon_clear_margins(vc, 0);\n\n\tif (logo_shown == FBCON_LOGO_DRAW) {\n\n\t\tlogo_shown = fg_console;\n\t\t/* This is protected above by initmem_freed */\n\t\tfb_show_logo(info, ops->rotate);\n\t\tupdate_region(vc,\n\t\t\t      vc->vc_origin + vc->vc_size_row * vc->vc_top,\n\t\t\t      vc->vc_size_row * (vc->vc_bottom -\n\t\t\t\t\t\t vc->vc_top) / 2);\n\t\treturn 0;\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int fbcon_switch(struct vc_data *vc)\n{\n\tstruct fb_info *info, *old_info = NULL;\n\tstruct fbcon_ops *ops;\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tstruct fb_var_screeninfo var;\n\tint i, ret, prev_console, charcnt = 256;\n\n\tinfo = registered_fb[con2fb_map[vc->vc_num]];\n\tops = info->fbcon_par;\n\n\tif (logo_shown >= 0) {\n\t\tstruct vc_data *conp2 = vc_cons[logo_shown].d;\n\n\t\tif (conp2->vc_top == logo_lines\n\t\t    && conp2->vc_bottom == conp2->vc_rows)\n\t\t\tconp2->vc_top = 0;\n\t\tlogo_shown = FBCON_LOGO_CANSHOW;\n\t}\n\n\tprev_console = ops->currcon;\n\tif (prev_console != -1)\n\t\told_info = registered_fb[con2fb_map[prev_console]];\n\t/*\n\t * FIXME: If we have multiple fbdev's loaded, we need to\n\t * update all info->currcon.  Perhaps, we can place this\n\t * in a centralized structure, but this might break some\n\t * drivers.\n\t *\n\t * info->currcon = vc->vc_num;\n\t */\n\tfor_each_registered_fb(i) {\n\t\tif (registered_fb[i]->fbcon_par) {\n\t\t\tstruct fbcon_ops *o = registered_fb[i]->fbcon_par;\n\n\t\t\to->currcon = vc->vc_num;\n\t\t}\n\t}\n\tmemset(&var, 0, sizeof(struct fb_var_screeninfo));\n\tdisplay_to_var(&var, p);\n\tvar.activate = FB_ACTIVATE_NOW;\n\n\t/*\n\t * make sure we don't unnecessarily trip the memcmp()\n\t * in fb_set_var()\n\t */\n\tinfo->var.activate = var.activate;\n\tvar.vmode |= info->var.vmode & ~FB_VMODE_MASK;\n\tfb_set_var(info, &var);\n\tops->var = info->var;\n\n\tif (old_info != NULL && (old_info != info ||\n\t\t\t\t info->flags & FBINFO_MISC_ALWAYS_SETPAR)) {\n\t\tif (info->fbops->fb_set_par) {\n\t\t\tret = info->fbops->fb_set_par(info);\n\n\t\t\tif (ret)\n\t\t\t\tprintk(KERN_ERR \"fbcon_switch: detected \"\n\t\t\t\t\t\"unhandled fb_set_par error, \"\n\t\t\t\t\t\"error code %d\\n\", ret);\n\t\t}\n\n\t\tif (old_info != info)\n\t\t\tfbcon_del_cursor_timer(old_info);\n\t}\n\n\tif (fbcon_is_inactive(vc, info) ||\n\t    ops->blank_state != FB_BLANK_UNBLANK)\n\t\tfbcon_del_cursor_timer(info);\n\telse\n\t\tfbcon_add_cursor_timer(info);\n\n\tset_blitting_type(vc, info);\n\tops->cursor_reset = 1;\n\n\tif (ops->rotate_font && ops->rotate_font(info, vc)) {\n\t\tops->rotate = FB_ROTATE_UR;\n\t\tset_blitting_type(vc, info);\n\t}\n\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(vc->vc_font.data);\n\n\tif (charcnt > 256)\n\t\tvc->vc_complement_mask <<= 1;\n\n\tupdatescrollmode(p, info, vc);\n\n\tswitch (p->scrollmode) {\n\tcase SCROLL_WRAP_MOVE:\n\t\tscrollback_phys_max = p->vrows - vc->vc_rows;\n\t\tbreak;\n\tcase SCROLL_PAN_MOVE:\n\tcase SCROLL_PAN_REDRAW:\n\t\tscrollback_phys_max = p->vrows - 2 * vc->vc_rows;\n\t\tif (scrollback_phys_max < 0)\n\t\t\tscrollback_phys_max = 0;\n\t\tbreak;\n\tdefault:\n\t\tscrollback_phys_max = 0;\n\t\tbreak;\n\t}\n\n\tscrollback_max = 0;\n\tscrollback_current = 0;\n\n\tif (!fbcon_is_inactive(vc, info)) {\n\t    ops->var.xoffset = ops->var.yoffset = p->yscroll = 0;\n\t    ops->update_start(info);\n\t}\n\n\tfbcon_set_palette(vc, color_table); \t\n\tfbcon_clear_margins(vc, 0);\n\n\tif (logo_shown == FBCON_LOGO_DRAW) {\n\n\t\tlogo_shown = fg_console;\n\t\t/* This is protected above by initmem_freed */\n\t\tfb_show_logo(info, ops->rotate);\n\t\tupdate_region(vc,\n\t\t\t      vc->vc_origin + vc->vc_size_row * vc->vc_top,\n\t\t\t      vc->vc_size_row * (vc->vc_bottom -\n\t\t\t\t\t\t vc->vc_top) / 2);\n\t\treturn 0;\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,14 +8,6 @@\n \n \tinfo = registered_fb[con2fb_map[vc->vc_num]];\n \tops = info->fbcon_par;\n-\n-\tif (softback_top) {\n-\t\tif (softback_lines)\n-\t\t\tfbcon_set_origin(vc);\n-\t\tsoftback_top = softback_curr = softback_in = softback_buf;\n-\t\tsoftback_lines = 0;\n-\t\tfbcon_update_softback(vc);\n-\t}\n \n \tif (logo_shown >= 0) {\n \t\tstruct vc_data *conp2 = vc_cons[logo_shown].d;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tif (softback_top) {",
                "\t\tif (softback_lines)",
                "\t\t\tfbcon_set_origin(vc);",
                "\t\tsoftback_top = softback_curr = softback_in = softback_buf;",
                "\t\tsoftback_lines = 0;",
                "\t\tfbcon_update_softback(vc);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_set_disp(struct fb_info *info, struct fb_var_screeninfo *var,\n\t\t\t   int unit)\n{\n\tstruct fbcon_display *p, *t;\n\tstruct vc_data **default_mode, *vc;\n\tstruct vc_data *svc;\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tint rows, cols, charcnt = 256;\n\n\tp = &fb_display[unit];\n\n\tif (var_to_display(p, var, info))\n\t\treturn;\n\n\tvc = vc_cons[unit].d;\n\n\tif (!vc)\n\t\treturn;\n\n\tdefault_mode = vc->vc_display_fg;\n\tsvc = *default_mode;\n\tt = &fb_display[svc->vc_num];\n\n\tif (!vc->vc_font.data) {\n\t\tvc->vc_font.data = (void *)(p->fontdata = t->fontdata);\n\t\tvc->vc_font.width = (*default_mode)->vc_font.width;\n\t\tvc->vc_font.height = (*default_mode)->vc_font.height;\n\t\tp->userfont = t->userfont;\n\t\tif (p->userfont)\n\t\t\tREFCOUNT(p->fontdata)++;\n\t}\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(p->fontdata);\n\n\tvar->activate = FB_ACTIVATE_NOW;\n\tinfo->var.activate = var->activate;\n\tvar->yoffset = info->var.yoffset;\n\tvar->xoffset = info->var.xoffset;\n\tfb_set_var(info, var);\n\tops->var = info->var;\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\tif (charcnt == 256) {\n\t\tvc->vc_hi_font_mask = 0;\n\t} else {\n\t\tvc->vc_hi_font_mask = 0x100;\n\t\tif (vc->vc_can_do_color)\n\t\t\tvc->vc_complement_mask <<= 1;\n\t}\n\n\tif (!*svc->vc_uni_pagedir_loc)\n\t\tcon_set_default_unimap(svc);\n\tif (!*vc->vc_uni_pagedir_loc)\n\t\tcon_copy_unimap(vc, svc);\n\n\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tcols /= vc->vc_font.width;\n\trows /= vc->vc_font.height;\n\tvc_resize(vc, cols, rows);\n\n\tif (con_is_visible(vc)) {\n\t\tupdate_screen(vc);\n\t\tif (softback_buf)\n\t\t\tfbcon_update_softback(vc);\n\t}\n}",
        "code_after_change": "static void fbcon_set_disp(struct fb_info *info, struct fb_var_screeninfo *var,\n\t\t\t   int unit)\n{\n\tstruct fbcon_display *p, *t;\n\tstruct vc_data **default_mode, *vc;\n\tstruct vc_data *svc;\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tint rows, cols, charcnt = 256;\n\n\tp = &fb_display[unit];\n\n\tif (var_to_display(p, var, info))\n\t\treturn;\n\n\tvc = vc_cons[unit].d;\n\n\tif (!vc)\n\t\treturn;\n\n\tdefault_mode = vc->vc_display_fg;\n\tsvc = *default_mode;\n\tt = &fb_display[svc->vc_num];\n\n\tif (!vc->vc_font.data) {\n\t\tvc->vc_font.data = (void *)(p->fontdata = t->fontdata);\n\t\tvc->vc_font.width = (*default_mode)->vc_font.width;\n\t\tvc->vc_font.height = (*default_mode)->vc_font.height;\n\t\tp->userfont = t->userfont;\n\t\tif (p->userfont)\n\t\t\tREFCOUNT(p->fontdata)++;\n\t}\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(p->fontdata);\n\n\tvar->activate = FB_ACTIVATE_NOW;\n\tinfo->var.activate = var->activate;\n\tvar->yoffset = info->var.yoffset;\n\tvar->xoffset = info->var.xoffset;\n\tfb_set_var(info, var);\n\tops->var = info->var;\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\tif (charcnt == 256) {\n\t\tvc->vc_hi_font_mask = 0;\n\t} else {\n\t\tvc->vc_hi_font_mask = 0x100;\n\t\tif (vc->vc_can_do_color)\n\t\t\tvc->vc_complement_mask <<= 1;\n\t}\n\n\tif (!*svc->vc_uni_pagedir_loc)\n\t\tcon_set_default_unimap(svc);\n\tif (!*vc->vc_uni_pagedir_loc)\n\t\tcon_copy_unimap(vc, svc);\n\n\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tcols /= vc->vc_font.width;\n\trows /= vc->vc_font.height;\n\tvc_resize(vc, cols, rows);\n\n\tif (con_is_visible(vc)) {\n\t\tupdate_screen(vc);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,7 +61,5 @@\n \n \tif (con_is_visible(vc)) {\n \t\tupdate_screen(vc);\n-\t\tif (softback_buf)\n-\t\t\tfbcon_update_softback(vc);\n \t}\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tif (softback_buf)",
                "\t\t\tfbcon_update_softback(vc);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static int fbcon_set_origin(struct vc_data *vc)\n{\n\tif (softback_lines)\n\t\tfbcon_scrolldelta(vc, softback_lines);\n\treturn 0;\n}",
        "code_after_change": "static int fbcon_set_origin(struct vc_data *vc)\n{\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,4 @@\n static int fbcon_set_origin(struct vc_data *vc)\n {\n-\tif (softback_lines)\n-\t\tfbcon_scrolldelta(vc, softback_lines);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (softback_lines)",
                "\t\tfbcon_scrolldelta(vc, softback_lines);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_cursor(struct vc_data *vc, int mode)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tint y;\n \tint c = scr_readw((u16 *) vc->vc_pos);\n\n\tops->cur_blink_jiffies = msecs_to_jiffies(vc->vc_cur_blink_ms);\n\n\tif (fbcon_is_inactive(vc, info) || vc->vc_deccm != 1)\n\t\treturn;\n\n\tif (vc->vc_cursor_type & CUR_SW)\n\t\tfbcon_del_cursor_timer(info);\n\telse\n\t\tfbcon_add_cursor_timer(info);\n\n\tops->cursor_flash = (mode == CM_ERASE) ? 0 : 1;\n\tif (mode & CM_SOFTBACK) {\n\t\tmode &= ~CM_SOFTBACK;\n\t\ty = softback_lines;\n\t} else {\n\t\tif (softback_lines)\n\t\t\tfbcon_set_origin(vc);\n\t\ty = 0;\n\t}\n\n\tops->cursor(vc, info, mode, y, get_color(vc, info, c, 1),\n\t\t    get_color(vc, info, c, 0));\n}",
        "code_after_change": "static void fbcon_cursor(struct vc_data *vc, int mode)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_ops *ops = info->fbcon_par;\n \tint c = scr_readw((u16 *) vc->vc_pos);\n\n\tops->cur_blink_jiffies = msecs_to_jiffies(vc->vc_cur_blink_ms);\n\n\tif (fbcon_is_inactive(vc, info) || vc->vc_deccm != 1)\n\t\treturn;\n\n\tif (vc->vc_cursor_type & CUR_SW)\n\t\tfbcon_del_cursor_timer(info);\n\telse\n\t\tfbcon_add_cursor_timer(info);\n\n\tops->cursor_flash = (mode == CM_ERASE) ? 0 : 1;\n\n\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),\n\t\t    get_color(vc, info, c, 0));\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,6 @@\n {\n \tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n \tstruct fbcon_ops *ops = info->fbcon_par;\n-\tint y;\n  \tint c = scr_readw((u16 *) vc->vc_pos);\n \n \tops->cur_blink_jiffies = msecs_to_jiffies(vc->vc_cur_blink_ms);\n@@ -16,15 +15,7 @@\n \t\tfbcon_add_cursor_timer(info);\n \n \tops->cursor_flash = (mode == CM_ERASE) ? 0 : 1;\n-\tif (mode & CM_SOFTBACK) {\n-\t\tmode &= ~CM_SOFTBACK;\n-\t\ty = softback_lines;\n-\t} else {\n-\t\tif (softback_lines)\n-\t\t\tfbcon_set_origin(vc);\n-\t\ty = 0;\n-\t}\n \n-\tops->cursor(vc, info, mode, y, get_color(vc, info, c, 1),\n+\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),\n \t\t    get_color(vc, info, c, 0));\n }",
        "function_modified_lines": {
            "added": [
                "\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),"
            ],
            "deleted": [
                "\tint y;",
                "\tif (mode & CM_SOFTBACK) {",
                "\t\tmode &= ~CM_SOFTBACK;",
                "\t\ty = softback_lines;",
                "\t} else {",
                "\t\tif (softback_lines)",
                "\t\t\tfbcon_set_origin(vc);",
                "\t\ty = 0;",
                "\t}",
                "\tops->cursor(vc, info, mode, y, get_color(vc, info, c, 1),"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static int fbcon_do_set_font(struct vc_data *vc, int w, int h,\n\t\t\t     const u8 * data, int userfont)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tint resize;\n\tint cnt;\n\tchar *old_data = NULL;\n\n\tif (con_is_visible(vc) && softback_lines)\n\t\tfbcon_set_origin(vc);\n\n\tresize = (w != vc->vc_font.width) || (h != vc->vc_font.height);\n\tif (p->userfont)\n\t\told_data = vc->vc_font.data;\n\tif (userfont)\n\t\tcnt = FNTCHARCNT(data);\n\telse\n\t\tcnt = 256;\n\tvc->vc_font.data = (void *)(p->fontdata = data);\n\tif ((p->userfont = userfont))\n\t\tREFCOUNT(data)++;\n\tvc->vc_font.width = w;\n\tvc->vc_font.height = h;\n\tif (vc->vc_hi_font_mask && cnt == 256)\n\t\tset_vc_hi_font(vc, false);\n\telse if (!vc->vc_hi_font_mask && cnt == 512)\n\t\tset_vc_hi_font(vc, true);\n\n\tif (resize) {\n\t\tint cols, rows;\n\n\t\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\t\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\t\tcols /= w;\n\t\trows /= h;\n\t\tvc_resize(vc, cols, rows);\n\t\tif (con_is_visible(vc) && softback_buf)\n\t\t\tfbcon_update_softback(vc);\n\t} else if (con_is_visible(vc)\n\t\t   && vc->vc_mode == KD_TEXT) {\n\t\tfbcon_clear_margins(vc, 0);\n\t\tupdate_screen(vc);\n\t}\n\n\tif (old_data && (--REFCOUNT(old_data) == 0))\n\t\tkfree(old_data - FONT_EXTRA_WORDS * sizeof(int));\n\treturn 0;\n}",
        "code_after_change": "static int fbcon_do_set_font(struct vc_data *vc, int w, int h,\n\t\t\t     const u8 * data, int userfont)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tint resize;\n\tint cnt;\n\tchar *old_data = NULL;\n\n\tresize = (w != vc->vc_font.width) || (h != vc->vc_font.height);\n\tif (p->userfont)\n\t\told_data = vc->vc_font.data;\n\tif (userfont)\n\t\tcnt = FNTCHARCNT(data);\n\telse\n\t\tcnt = 256;\n\tvc->vc_font.data = (void *)(p->fontdata = data);\n\tif ((p->userfont = userfont))\n\t\tREFCOUNT(data)++;\n\tvc->vc_font.width = w;\n\tvc->vc_font.height = h;\n\tif (vc->vc_hi_font_mask && cnt == 256)\n\t\tset_vc_hi_font(vc, false);\n\telse if (!vc->vc_hi_font_mask && cnt == 512)\n\t\tset_vc_hi_font(vc, true);\n\n\tif (resize) {\n\t\tint cols, rows;\n\n\t\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\t\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\t\tcols /= w;\n\t\trows /= h;\n\t\tvc_resize(vc, cols, rows);\n\t} else if (con_is_visible(vc)\n\t\t   && vc->vc_mode == KD_TEXT) {\n\t\tfbcon_clear_margins(vc, 0);\n\t\tupdate_screen(vc);\n\t}\n\n\tif (old_data && (--REFCOUNT(old_data) == 0))\n\t\tkfree(old_data - FONT_EXTRA_WORDS * sizeof(int));\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,9 +7,6 @@\n \tint resize;\n \tint cnt;\n \tchar *old_data = NULL;\n-\n-\tif (con_is_visible(vc) && softback_lines)\n-\t\tfbcon_set_origin(vc);\n \n \tresize = (w != vc->vc_font.width) || (h != vc->vc_font.height);\n \tif (p->userfont)\n@@ -36,8 +33,6 @@\n \t\tcols /= w;\n \t\trows /= h;\n \t\tvc_resize(vc, cols, rows);\n-\t\tif (con_is_visible(vc) && softback_buf)\n-\t\t\tfbcon_update_softback(vc);\n \t} else if (con_is_visible(vc)\n \t\t   && vc->vc_mode == KD_TEXT) {\n \t\tfbcon_clear_margins(vc, 0);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tif (con_is_visible(vc) && softback_lines)",
                "\t\tfbcon_set_origin(vc);",
                "\t\tif (con_is_visible(vc) && softback_buf)",
                "\t\t\tfbcon_update_softback(vc);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fb_flashcursor(struct work_struct *work)\n{\n\tstruct fb_info *info = container_of(work, struct fb_info, queue);\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct vc_data *vc = NULL;\n\tint c;\n\tint mode;\n\tint ret;\n\n\t/* FIXME: we should sort out the unbind locking instead */\n\t/* instead we just fail to flash the cursor if we can't get\n\t * the lock instead of blocking fbcon deinit */\n\tret = console_trylock();\n\tif (ret == 0)\n\t\treturn;\n\n\tif (ops && ops->currcon != -1)\n\t\tvc = vc_cons[ops->currcon].d;\n\n\tif (!vc || !con_is_visible(vc) ||\n \t    registered_fb[con2fb_map[vc->vc_num]] != info ||\n\t    vc->vc_deccm != 1) {\n\t\tconsole_unlock();\n\t\treturn;\n\t}\n\n\tc = scr_readw((u16 *) vc->vc_pos);\n\tmode = (!ops->cursor_flash || ops->cursor_state.enable) ?\n\t\tCM_ERASE : CM_DRAW;\n\tops->cursor(vc, info, mode, softback_lines, get_color(vc, info, c, 1),\n\t\t    get_color(vc, info, c, 0));\n\tconsole_unlock();\n}",
        "code_after_change": "static void fb_flashcursor(struct work_struct *work)\n{\n\tstruct fb_info *info = container_of(work, struct fb_info, queue);\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct vc_data *vc = NULL;\n\tint c;\n\tint mode;\n\tint ret;\n\n\t/* FIXME: we should sort out the unbind locking instead */\n\t/* instead we just fail to flash the cursor if we can't get\n\t * the lock instead of blocking fbcon deinit */\n\tret = console_trylock();\n\tif (ret == 0)\n\t\treturn;\n\n\tif (ops && ops->currcon != -1)\n\t\tvc = vc_cons[ops->currcon].d;\n\n\tif (!vc || !con_is_visible(vc) ||\n \t    registered_fb[con2fb_map[vc->vc_num]] != info ||\n\t    vc->vc_deccm != 1) {\n\t\tconsole_unlock();\n\t\treturn;\n\t}\n\n\tc = scr_readw((u16 *) vc->vc_pos);\n\tmode = (!ops->cursor_flash || ops->cursor_state.enable) ?\n\t\tCM_ERASE : CM_DRAW;\n\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),\n\t\t    get_color(vc, info, c, 0));\n\tconsole_unlock();\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,7 +27,7 @@\n \tc = scr_readw((u16 *) vc->vc_pos);\n \tmode = (!ops->cursor_flash || ops->cursor_state.enable) ?\n \t\tCM_ERASE : CM_DRAW;\n-\tops->cursor(vc, info, mode, softback_lines, get_color(vc, info, c, 1),\n+\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),\n \t\t    get_color(vc, info, c, 0));\n \tconsole_unlock();\n }",
        "function_modified_lines": {
            "added": [
                "\tops->cursor(vc, info, mode, 0, get_color(vc, info, c, 1),"
            ],
            "deleted": [
                "\tops->cursor(vc, info, mode, softback_lines, get_color(vc, info, c, 1),"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_modechanged(struct fb_info *info)\n{\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct vc_data *vc;\n\tstruct fbcon_display *p;\n\tint rows, cols;\n\n\tif (!ops || ops->currcon < 0)\n\t\treturn;\n\tvc = vc_cons[ops->currcon].d;\n\tif (vc->vc_mode != KD_TEXT ||\n\t    registered_fb[con2fb_map[ops->currcon]] != info)\n\t\treturn;\n\n\tp = &fb_display[vc->vc_num];\n\tset_blitting_type(vc, info);\n\n\tif (con_is_visible(vc)) {\n\t\tvar_to_display(p, &info->var, info);\n\t\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\t\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\t\tcols /= vc->vc_font.width;\n\t\trows /= vc->vc_font.height;\n\t\tvc_resize(vc, cols, rows);\n\t\tupdatescrollmode(p, info, vc);\n\t\tscrollback_max = 0;\n\t\tscrollback_current = 0;\n\n\t\tif (!fbcon_is_inactive(vc, info)) {\n\t\t    ops->var.xoffset = ops->var.yoffset = p->yscroll = 0;\n\t\t    ops->update_start(info);\n\t\t}\n\n\t\tfbcon_set_palette(vc, color_table);\n\t\tupdate_screen(vc);\n\t\tif (softback_buf)\n\t\t\tfbcon_update_softback(vc);\n\t}\n}",
        "code_after_change": "static void fbcon_modechanged(struct fb_info *info)\n{\n\tstruct fbcon_ops *ops = info->fbcon_par;\n\tstruct vc_data *vc;\n\tstruct fbcon_display *p;\n\tint rows, cols;\n\n\tif (!ops || ops->currcon < 0)\n\t\treturn;\n\tvc = vc_cons[ops->currcon].d;\n\tif (vc->vc_mode != KD_TEXT ||\n\t    registered_fb[con2fb_map[ops->currcon]] != info)\n\t\treturn;\n\n\tp = &fb_display[vc->vc_num];\n\tset_blitting_type(vc, info);\n\n\tif (con_is_visible(vc)) {\n\t\tvar_to_display(p, &info->var, info);\n\t\tcols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\t\trows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\t\tcols /= vc->vc_font.width;\n\t\trows /= vc->vc_font.height;\n\t\tvc_resize(vc, cols, rows);\n\t\tupdatescrollmode(p, info, vc);\n\t\tscrollback_max = 0;\n\t\tscrollback_current = 0;\n\n\t\tif (!fbcon_is_inactive(vc, info)) {\n\t\t    ops->var.xoffset = ops->var.yoffset = p->yscroll = 0;\n\t\t    ops->update_start(info);\n\t\t}\n\n\t\tfbcon_set_palette(vc, color_table);\n\t\tupdate_screen(vc);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -33,7 +33,5 @@\n \n \t\tfbcon_set_palette(vc, color_table);\n \t\tupdate_screen(vc);\n-\t\tif (softback_buf)\n-\t\t\tfbcon_update_softback(vc);\n \t}\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tif (softback_buf)",
                "\t\t\tfbcon_update_softback(vc);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static int __init fb_console_setup(char *this_opt)\n{\n\tchar *options;\n\tint i, j;\n\n\tif (!this_opt || !*this_opt)\n\t\treturn 1;\n\n\twhile ((options = strsep(&this_opt, \",\")) != NULL) {\n\t\tif (!strncmp(options, \"font:\", 5)) {\n\t\t\tstrlcpy(fontname, options + 5, sizeof(fontname));\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tif (!strncmp(options, \"scrollback:\", 11)) {\n\t\t\toptions += 11;\n\t\t\tif (*options) {\n\t\t\t\tfbcon_softback_size = simple_strtoul(options, &options, 0);\n\t\t\t\tif (*options == 'k' || *options == 'K') {\n\t\t\t\t\tfbcon_softback_size *= 1024;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tif (!strncmp(options, \"map:\", 4)) {\n\t\t\toptions += 4;\n\t\t\tif (*options) {\n\t\t\t\tfor (i = 0, j = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\t\t\tif (!options[j])\n\t\t\t\t\t\tj = 0;\n\t\t\t\t\tcon2fb_map_boot[i] =\n\t\t\t\t\t\t(options[j++]-'0') % FB_MAX;\n\t\t\t\t}\n\n\t\t\t\tfbcon_map_override();\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"vc:\", 3)) {\n\t\t\toptions += 3;\n\t\t\tif (*options)\n\t\t\t\tfirst_fb_vc = simple_strtoul(options, &options, 10) - 1;\n\t\t\tif (first_fb_vc < 0)\n\t\t\t\tfirst_fb_vc = 0;\n\t\t\tif (*options++ == '-')\n\t\t\t\tlast_fb_vc = simple_strtoul(options, &options, 10) - 1;\n\t\t\tfbcon_is_default = 0; \n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"rotate:\", 7)) {\n\t\t\toptions += 7;\n\t\t\tif (*options)\n\t\t\t\tinitial_rotation = simple_strtoul(options, &options, 0);\n\t\t\tif (initial_rotation > 3)\n\t\t\t\tinitial_rotation = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"margin:\", 7)) {\n\t\t\toptions += 7;\n\t\t\tif (*options)\n\t\t\t\tmargin_color = simple_strtoul(options, &options, 0);\n\t\t\tcontinue;\n\t\t}\n#ifdef CONFIG_FRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER\n\t\tif (!strcmp(options, \"nodefer\")) {\n\t\t\tdeferred_takeover = false;\n\t\t\tcontinue;\n\t\t}\n#endif\n\n\t\tif (!strncmp(options, \"logo-pos:\", 9)) {\n\t\t\toptions += 9;\n\t\t\tif (!strcmp(options, \"center\"))\n\t\t\t\tfb_center_logo = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"logo-count:\", 11)) {\n\t\t\toptions += 11;\n\t\t\tif (*options)\n\t\t\t\tfb_logo_count = simple_strtol(options, &options, 0);\n\t\t\tcontinue;\n\t\t}\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int __init fb_console_setup(char *this_opt)\n{\n\tchar *options;\n\tint i, j;\n\n\tif (!this_opt || !*this_opt)\n\t\treturn 1;\n\n\twhile ((options = strsep(&this_opt, \",\")) != NULL) {\n\t\tif (!strncmp(options, \"font:\", 5)) {\n\t\t\tstrlcpy(fontname, options + 5, sizeof(fontname));\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tif (!strncmp(options, \"scrollback:\", 11)) {\n\t\t\tpr_warn(\"Ignoring scrollback size option\\n\");\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tif (!strncmp(options, \"map:\", 4)) {\n\t\t\toptions += 4;\n\t\t\tif (*options) {\n\t\t\t\tfor (i = 0, j = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\t\t\tif (!options[j])\n\t\t\t\t\t\tj = 0;\n\t\t\t\t\tcon2fb_map_boot[i] =\n\t\t\t\t\t\t(options[j++]-'0') % FB_MAX;\n\t\t\t\t}\n\n\t\t\t\tfbcon_map_override();\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"vc:\", 3)) {\n\t\t\toptions += 3;\n\t\t\tif (*options)\n\t\t\t\tfirst_fb_vc = simple_strtoul(options, &options, 10) - 1;\n\t\t\tif (first_fb_vc < 0)\n\t\t\t\tfirst_fb_vc = 0;\n\t\t\tif (*options++ == '-')\n\t\t\t\tlast_fb_vc = simple_strtoul(options, &options, 10) - 1;\n\t\t\tfbcon_is_default = 0; \n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"rotate:\", 7)) {\n\t\t\toptions += 7;\n\t\t\tif (*options)\n\t\t\t\tinitial_rotation = simple_strtoul(options, &options, 0);\n\t\t\tif (initial_rotation > 3)\n\t\t\t\tinitial_rotation = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"margin:\", 7)) {\n\t\t\toptions += 7;\n\t\t\tif (*options)\n\t\t\t\tmargin_color = simple_strtoul(options, &options, 0);\n\t\t\tcontinue;\n\t\t}\n#ifdef CONFIG_FRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER\n\t\tif (!strcmp(options, \"nodefer\")) {\n\t\t\tdeferred_takeover = false;\n\t\t\tcontinue;\n\t\t}\n#endif\n\n\t\tif (!strncmp(options, \"logo-pos:\", 9)) {\n\t\t\toptions += 9;\n\t\t\tif (!strcmp(options, \"center\"))\n\t\t\t\tfb_center_logo = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strncmp(options, \"logo-count:\", 11)) {\n\t\t\toptions += 11;\n\t\t\tif (*options)\n\t\t\t\tfb_logo_count = simple_strtol(options, &options, 0);\n\t\t\tcontinue;\n\t\t}\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,13 +13,7 @@\n \t\t}\n \t\t\n \t\tif (!strncmp(options, \"scrollback:\", 11)) {\n-\t\t\toptions += 11;\n-\t\t\tif (*options) {\n-\t\t\t\tfbcon_softback_size = simple_strtoul(options, &options, 0);\n-\t\t\t\tif (*options == 'k' || *options == 'K') {\n-\t\t\t\t\tfbcon_softback_size *= 1024;\n-\t\t\t\t}\n-\t\t\t}\n+\t\t\tpr_warn(\"Ignoring scrollback size option\\n\");\n \t\t\tcontinue;\n \t\t}\n \t\t",
        "function_modified_lines": {
            "added": [
                "\t\t\tpr_warn(\"Ignoring scrollback size option\\n\");"
            ],
            "deleted": [
                "\t\t\toptions += 11;",
                "\t\t\tif (*options) {",
                "\t\t\t\tfbcon_softback_size = simple_strtoul(options, &options, 0);",
                "\t\t\t\tif (*options == 'k' || *options == 'K') {",
                "\t\t\t\t\tfbcon_softback_size *= 1024;",
                "\t\t\t\t}",
                "\t\t\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_init(struct vc_data *vc, int init)\n{\n\tstruct fb_info *info;\n\tstruct fbcon_ops *ops;\n\tstruct vc_data **default_mode = vc->vc_display_fg;\n\tstruct vc_data *svc = *default_mode;\n\tstruct fbcon_display *t, *p = &fb_display[vc->vc_num];\n\tint logo = 1, new_rows, new_cols, rows, cols, charcnt = 256;\n\tint cap, ret;\n\n\tif (WARN_ON(info_idx == -1))\n\t    return;\n\n\tif (con2fb_map[vc->vc_num] == -1)\n\t\tcon2fb_map[vc->vc_num] = info_idx;\n\n\tinfo = registered_fb[con2fb_map[vc->vc_num]];\n\tcap = info->flags;\n\n\tif (logo_shown < 0 && console_loglevel <= CONSOLE_LOGLEVEL_QUIET)\n\t\tlogo_shown = FBCON_LOGO_DONTSHOW;\n\n\tif (vc != svc || logo_shown == FBCON_LOGO_DONTSHOW ||\n\t    (info->fix.type == FB_TYPE_TEXT))\n\t\tlogo = 0;\n\n\tif (var_to_display(p, &info->var, info))\n\t\treturn;\n\n\tif (!info->fbcon_par)\n\t\tcon2fb_acquire_newinfo(vc, info, vc->vc_num, -1);\n\n\t/* If we are not the first console on this\n\t   fb, copy the font from that console */\n\tt = &fb_display[fg_console];\n\tif (!p->fontdata) {\n\t\tif (t->fontdata) {\n\t\t\tstruct vc_data *fvc = vc_cons[fg_console].d;\n\n\t\t\tvc->vc_font.data = (void *)(p->fontdata =\n\t\t\t\t\t\t    fvc->vc_font.data);\n\t\t\tvc->vc_font.width = fvc->vc_font.width;\n\t\t\tvc->vc_font.height = fvc->vc_font.height;\n\t\t\tp->userfont = t->userfont;\n\n\t\t\tif (p->userfont)\n\t\t\t\tREFCOUNT(p->fontdata)++;\n\t\t} else {\n\t\t\tconst struct font_desc *font = NULL;\n\n\t\t\tif (!fontname[0] || !(font = find_font(fontname)))\n\t\t\t\tfont = get_default_font(info->var.xres,\n\t\t\t\t\t\t\tinfo->var.yres,\n\t\t\t\t\t\t\tinfo->pixmap.blit_x,\n\t\t\t\t\t\t\tinfo->pixmap.blit_y);\n\t\t\tvc->vc_font.width = font->width;\n\t\t\tvc->vc_font.height = font->height;\n\t\t\tvc->vc_font.data = (void *)(p->fontdata = font->data);\n\t\t\tvc->vc_font.charcount = 256; /* FIXME  Need to\n\t\t\t\t\t\t\tsupport more fonts */\n\t\t}\n\t}\n\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(p->fontdata);\n\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\tif (charcnt == 256) {\n\t\tvc->vc_hi_font_mask = 0;\n\t} else {\n\t\tvc->vc_hi_font_mask = 0x100;\n\t\tif (vc->vc_can_do_color)\n\t\t\tvc->vc_complement_mask <<= 1;\n\t}\n\n\tif (!*svc->vc_uni_pagedir_loc)\n\t\tcon_set_default_unimap(svc);\n\tif (!*vc->vc_uni_pagedir_loc)\n\t\tcon_copy_unimap(vc, svc);\n\n\tops = info->fbcon_par;\n\tops->cur_blink_jiffies = msecs_to_jiffies(vc->vc_cur_blink_ms);\n\n\tp->con_rotate = initial_rotation;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = info->fbcon_rotate_hint;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = FB_ROTATE_UR;\n\n\tset_blitting_type(vc, info);\n\n\tcols = vc->vc_cols;\n\trows = vc->vc_rows;\n\tnew_cols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\tnew_rows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tnew_cols /= vc->vc_font.width;\n\tnew_rows /= vc->vc_font.height;\n\n\t/*\n\t * We must always set the mode. The mode of the previous console\n\t * driver could be in the same resolution but we are using different\n\t * hardware so we have to initialize the hardware.\n\t *\n\t * We need to do it in fbcon_init() to prevent screen corruption.\n\t */\n\tif (con_is_visible(vc) && vc->vc_mode == KD_TEXT) {\n\t\tif (info->fbops->fb_set_par &&\n\t\t    !(ops->flags & FBCON_FLAGS_INIT)) {\n\t\t\tret = info->fbops->fb_set_par(info);\n\n\t\t\tif (ret)\n\t\t\t\tprintk(KERN_ERR \"fbcon_init: detected \"\n\t\t\t\t\t\"unhandled fb_set_par error, \"\n\t\t\t\t\t\"error code %d\\n\", ret);\n\t\t}\n\n\t\tops->flags |= FBCON_FLAGS_INIT;\n\t}\n\n\tops->graphics = 0;\n\n\tif ((cap & FBINFO_HWACCEL_COPYAREA) &&\n\t    !(cap & FBINFO_HWACCEL_DISABLED))\n\t\tp->scrollmode = SCROLL_MOVE;\n\telse /* default to something safe */\n\t\tp->scrollmode = SCROLL_REDRAW;\n\n\t/*\n\t *  ++guenther: console.c:vc_allocate() relies on initializing\n\t *  vc_{cols,rows}, but we must not set those if we are only\n\t *  resizing the console.\n\t */\n\tif (init) {\n\t\tvc->vc_cols = new_cols;\n\t\tvc->vc_rows = new_rows;\n\t} else\n\t\tvc_resize(vc, new_cols, new_rows);\n\n\tif (logo)\n\t\tfbcon_prepare_logo(vc, info, cols, rows, new_cols, new_rows);\n\n\tif (vc == svc && softback_buf)\n\t\tfbcon_update_softback(vc);\n\n\tif (ops->rotate_font && ops->rotate_font(info, vc)) {\n\t\tops->rotate = FB_ROTATE_UR;\n\t\tset_blitting_type(vc, info);\n\t}\n\n\tops->p = &fb_display[fg_console];\n}",
        "code_after_change": "static void fbcon_init(struct vc_data *vc, int init)\n{\n\tstruct fb_info *info;\n\tstruct fbcon_ops *ops;\n\tstruct vc_data **default_mode = vc->vc_display_fg;\n\tstruct vc_data *svc = *default_mode;\n\tstruct fbcon_display *t, *p = &fb_display[vc->vc_num];\n\tint logo = 1, new_rows, new_cols, rows, cols, charcnt = 256;\n\tint cap, ret;\n\n\tif (WARN_ON(info_idx == -1))\n\t    return;\n\n\tif (con2fb_map[vc->vc_num] == -1)\n\t\tcon2fb_map[vc->vc_num] = info_idx;\n\n\tinfo = registered_fb[con2fb_map[vc->vc_num]];\n\tcap = info->flags;\n\n\tif (logo_shown < 0 && console_loglevel <= CONSOLE_LOGLEVEL_QUIET)\n\t\tlogo_shown = FBCON_LOGO_DONTSHOW;\n\n\tif (vc != svc || logo_shown == FBCON_LOGO_DONTSHOW ||\n\t    (info->fix.type == FB_TYPE_TEXT))\n\t\tlogo = 0;\n\n\tif (var_to_display(p, &info->var, info))\n\t\treturn;\n\n\tif (!info->fbcon_par)\n\t\tcon2fb_acquire_newinfo(vc, info, vc->vc_num, -1);\n\n\t/* If we are not the first console on this\n\t   fb, copy the font from that console */\n\tt = &fb_display[fg_console];\n\tif (!p->fontdata) {\n\t\tif (t->fontdata) {\n\t\t\tstruct vc_data *fvc = vc_cons[fg_console].d;\n\n\t\t\tvc->vc_font.data = (void *)(p->fontdata =\n\t\t\t\t\t\t    fvc->vc_font.data);\n\t\t\tvc->vc_font.width = fvc->vc_font.width;\n\t\t\tvc->vc_font.height = fvc->vc_font.height;\n\t\t\tp->userfont = t->userfont;\n\n\t\t\tif (p->userfont)\n\t\t\t\tREFCOUNT(p->fontdata)++;\n\t\t} else {\n\t\t\tconst struct font_desc *font = NULL;\n\n\t\t\tif (!fontname[0] || !(font = find_font(fontname)))\n\t\t\t\tfont = get_default_font(info->var.xres,\n\t\t\t\t\t\t\tinfo->var.yres,\n\t\t\t\t\t\t\tinfo->pixmap.blit_x,\n\t\t\t\t\t\t\tinfo->pixmap.blit_y);\n\t\t\tvc->vc_font.width = font->width;\n\t\t\tvc->vc_font.height = font->height;\n\t\t\tvc->vc_font.data = (void *)(p->fontdata = font->data);\n\t\t\tvc->vc_font.charcount = 256; /* FIXME  Need to\n\t\t\t\t\t\t\tsupport more fonts */\n\t\t}\n\t}\n\n\tif (p->userfont)\n\t\tcharcnt = FNTCHARCNT(p->fontdata);\n\n\tvc->vc_can_do_color = (fb_get_color_depth(&info->var, &info->fix)!=1);\n\tvc->vc_complement_mask = vc->vc_can_do_color ? 0x7700 : 0x0800;\n\tif (charcnt == 256) {\n\t\tvc->vc_hi_font_mask = 0;\n\t} else {\n\t\tvc->vc_hi_font_mask = 0x100;\n\t\tif (vc->vc_can_do_color)\n\t\t\tvc->vc_complement_mask <<= 1;\n\t}\n\n\tif (!*svc->vc_uni_pagedir_loc)\n\t\tcon_set_default_unimap(svc);\n\tif (!*vc->vc_uni_pagedir_loc)\n\t\tcon_copy_unimap(vc, svc);\n\n\tops = info->fbcon_par;\n\tops->cur_blink_jiffies = msecs_to_jiffies(vc->vc_cur_blink_ms);\n\n\tp->con_rotate = initial_rotation;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = info->fbcon_rotate_hint;\n\tif (p->con_rotate == -1)\n\t\tp->con_rotate = FB_ROTATE_UR;\n\n\tset_blitting_type(vc, info);\n\n\tcols = vc->vc_cols;\n\trows = vc->vc_rows;\n\tnew_cols = FBCON_SWAP(ops->rotate, info->var.xres, info->var.yres);\n\tnew_rows = FBCON_SWAP(ops->rotate, info->var.yres, info->var.xres);\n\tnew_cols /= vc->vc_font.width;\n\tnew_rows /= vc->vc_font.height;\n\n\t/*\n\t * We must always set the mode. The mode of the previous console\n\t * driver could be in the same resolution but we are using different\n\t * hardware so we have to initialize the hardware.\n\t *\n\t * We need to do it in fbcon_init() to prevent screen corruption.\n\t */\n\tif (con_is_visible(vc) && vc->vc_mode == KD_TEXT) {\n\t\tif (info->fbops->fb_set_par &&\n\t\t    !(ops->flags & FBCON_FLAGS_INIT)) {\n\t\t\tret = info->fbops->fb_set_par(info);\n\n\t\t\tif (ret)\n\t\t\t\tprintk(KERN_ERR \"fbcon_init: detected \"\n\t\t\t\t\t\"unhandled fb_set_par error, \"\n\t\t\t\t\t\"error code %d\\n\", ret);\n\t\t}\n\n\t\tops->flags |= FBCON_FLAGS_INIT;\n\t}\n\n\tops->graphics = 0;\n\n\tif ((cap & FBINFO_HWACCEL_COPYAREA) &&\n\t    !(cap & FBINFO_HWACCEL_DISABLED))\n\t\tp->scrollmode = SCROLL_MOVE;\n\telse /* default to something safe */\n\t\tp->scrollmode = SCROLL_REDRAW;\n\n\t/*\n\t *  ++guenther: console.c:vc_allocate() relies on initializing\n\t *  vc_{cols,rows}, but we must not set those if we are only\n\t *  resizing the console.\n\t */\n\tif (init) {\n\t\tvc->vc_cols = new_cols;\n\t\tvc->vc_rows = new_rows;\n\t} else\n\t\tvc_resize(vc, new_cols, new_rows);\n\n\tif (logo)\n\t\tfbcon_prepare_logo(vc, info, cols, rows, new_cols, new_rows);\n\n\tif (ops->rotate_font && ops->rotate_font(info, vc)) {\n\t\tops->rotate = FB_ROTATE_UR;\n\t\tset_blitting_type(vc, info);\n\t}\n\n\tops->p = &fb_display[fg_console];\n}",
        "patch": "--- code before\n+++ code after\n@@ -140,9 +140,6 @@\n \tif (logo)\n \t\tfbcon_prepare_logo(vc, info, cols, rows, new_cols, new_rows);\n \n-\tif (vc == svc && softback_buf)\n-\t\tfbcon_update_softback(vc);\n-\n \tif (ops->rotate_font && ops->rotate_font(info, vc)) {\n \t\tops->rotate = FB_ROTATE_UR;\n \t\tset_blitting_type(vc, info);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (vc == svc && softback_buf)",
                "\t\tfbcon_update_softback(vc);",
                ""
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static void fbcon_exit(void)\n{\n\tstruct fb_info *info;\n\tint i, j, mapped;\n\n#ifdef CONFIG_FRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER\n\tif (deferred_takeover) {\n\t\tdummycon_unregister_output_notifier(&fbcon_output_nb);\n\t\tdeferred_takeover = false;\n\t}\n#endif\n\n\tkvfree((void *)softback_buf);\n\tsoftback_buf = 0UL;\n\n\tfor_each_registered_fb(i) {\n\t\tint pending = 0;\n\n\t\tmapped = 0;\n\t\tinfo = registered_fb[i];\n\n\t\tif (info->queue.func)\n\t\t\tpending = cancel_work_sync(&info->queue);\n\t\tDPRINTK(\"fbcon: %s pending work\\n\", (pending ? \"canceled\" :\n\t\t\t\"no\"));\n\n\t\tfor (j = first_fb_vc; j <= last_fb_vc; j++) {\n\t\t\tif (con2fb_map[j] == i) {\n\t\t\t\tmapped = 1;\n\t\t\t\tcon2fb_map[j] = -1;\n\t\t\t}\n\t\t}\n\n\t\tif (mapped) {\n\t\t\tif (info->fbops->fb_release)\n\t\t\t\tinfo->fbops->fb_release(info, 0);\n\t\t\tmodule_put(info->fbops->owner);\n\n\t\t\tif (info->fbcon_par) {\n\t\t\t\tstruct fbcon_ops *ops = info->fbcon_par;\n\n\t\t\t\tfbcon_del_cursor_timer(info);\n\t\t\t\tkfree(ops->cursor_src);\n\t\t\t\tkfree(ops->cursor_state.mask);\n\t\t\t\tkfree(info->fbcon_par);\n\t\t\t\tinfo->fbcon_par = NULL;\n\t\t\t}\n\n\t\t\tif (info->queue.func == fb_flashcursor)\n\t\t\t\tinfo->queue.func = NULL;\n\t\t}\n\t}\n}",
        "code_after_change": "static void fbcon_exit(void)\n{\n\tstruct fb_info *info;\n\tint i, j, mapped;\n\n#ifdef CONFIG_FRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER\n\tif (deferred_takeover) {\n\t\tdummycon_unregister_output_notifier(&fbcon_output_nb);\n\t\tdeferred_takeover = false;\n\t}\n#endif\n\n\tfor_each_registered_fb(i) {\n\t\tint pending = 0;\n\n\t\tmapped = 0;\n\t\tinfo = registered_fb[i];\n\n\t\tif (info->queue.func)\n\t\t\tpending = cancel_work_sync(&info->queue);\n\t\tDPRINTK(\"fbcon: %s pending work\\n\", (pending ? \"canceled\" :\n\t\t\t\"no\"));\n\n\t\tfor (j = first_fb_vc; j <= last_fb_vc; j++) {\n\t\t\tif (con2fb_map[j] == i) {\n\t\t\t\tmapped = 1;\n\t\t\t\tcon2fb_map[j] = -1;\n\t\t\t}\n\t\t}\n\n\t\tif (mapped) {\n\t\t\tif (info->fbops->fb_release)\n\t\t\t\tinfo->fbops->fb_release(info, 0);\n\t\t\tmodule_put(info->fbops->owner);\n\n\t\t\tif (info->fbcon_par) {\n\t\t\t\tstruct fbcon_ops *ops = info->fbcon_par;\n\n\t\t\t\tfbcon_del_cursor_timer(info);\n\t\t\t\tkfree(ops->cursor_src);\n\t\t\t\tkfree(ops->cursor_state.mask);\n\t\t\t\tkfree(info->fbcon_par);\n\t\t\t\tinfo->fbcon_par = NULL;\n\t\t\t}\n\n\t\t\tif (info->queue.func == fb_flashcursor)\n\t\t\t\tinfo->queue.func = NULL;\n\t\t}\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,9 +9,6 @@\n \t\tdeferred_takeover = false;\n \t}\n #endif\n-\n-\tkvfree((void *)softback_buf);\n-\tsoftback_buf = 0UL;\n \n \tfor_each_registered_fb(i) {\n \t\tint pending = 0;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tkvfree((void *)softback_buf);",
                "\tsoftback_buf = 0UL;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-14390",
        "code_before_change": "static bool fbcon_scroll(struct vc_data *vc, unsigned int t, unsigned int b,\n\t\tenum con_scroll dir, unsigned int count)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tint scroll_partial = info->flags & FBINFO_PARTIAL_PAN_OK;\n\n\tif (fbcon_is_inactive(vc, info))\n\t\treturn true;\n\n\tfbcon_cursor(vc, CM_ERASE);\n\n\t/*\n\t * ++Geert: Only use ywrap/ypan if the console is in text mode\n\t * ++Andrew: Only use ypan on hardware text mode when scrolling the\n\t *           whole screen (prevents flicker).\n\t */\n\n\tswitch (dir) {\n\tcase SM_UP:\n\t\tif (count > vc->vc_rows)\t/* Maximum realistic size */\n\t\t\tcount = vc->vc_rows;\n\t\tif (softback_top)\n\t\t\tfbcon_softback_note(vc, t, count);\n\t\tif (logo_shown >= 0)\n\t\t\tgoto redraw_up;\n\t\tswitch (p->scrollmode) {\n\t\tcase SCROLL_MOVE:\n\t\t\tfbcon_redraw_blit(vc, info, p, t, b - t - count,\n\t\t\t\t     count);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\t(b - count)),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t\tbreak;\n\n\t\tcase SCROLL_WRAP_MOVE:\n\t\t\tif (b - t - count > 3 * vc->vc_rows >> 2) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, 0, 0, count, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\tywrap_up(vc, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b - count, 0, b, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t + count, 0, t, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_up;\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_REDRAW:\n\t\t\tif ((p->yscroll + count <=\n\t\t\t     2 * (p->vrows - vc->vc_rows))\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, 0, t, count);\n\t\t\t\typan_up_redraw(vc, t, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, b,\n\t\t\t\t\t\t\t  vc->vc_rows - b, b);\n\t\t\t} else\n\t\t\t\tfbcon_redraw_move(vc, p, t + count, b - t - count, t);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_MOVE:\n\t\t\tif ((p->yscroll + count <=\n\t\t\t     2 * (p->vrows - vc->vc_rows))\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, 0, 0, count, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\typan_up(vc, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b - count, 0, b, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t + count, 0, t, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_up;\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_REDRAW:\n\t\t      redraw_up:\n\t\t\tfbcon_redraw(vc, p, t, b - t - count,\n\t\t\t\t     count * vc->vc_cols);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\t(b - count)),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t}\n\t\tbreak;\n\n\tcase SM_DOWN:\n\t\tif (count > vc->vc_rows)\t/* Maximum realistic size */\n\t\t\tcount = vc->vc_rows;\n\t\tif (logo_shown >= 0)\n\t\t\tgoto redraw_down;\n\t\tswitch (p->scrollmode) {\n\t\tcase SCROLL_MOVE:\n\t\t\tfbcon_redraw_blit(vc, info, p, b - 1, b - t - count,\n\t\t\t\t     -count);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\tt),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t\tbreak;\n\n\t\tcase SCROLL_WRAP_MOVE:\n\t\t\tif (b - t - count > 3 * vc->vc_rows >> 2) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b, 0, b - count, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\tywrap_down(vc, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, count, 0, 0, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t, 0, t + count, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_down;\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_MOVE:\n\t\t\tif ((count - p->yscroll <= p->vrows - vc->vc_rows)\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b, 0, b - count, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\typan_down(vc, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, count, 0, 0, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t, 0, t + count, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_down;\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_REDRAW:\n\t\t\tif ((count - p->yscroll <= p->vrows - vc->vc_rows)\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, b, vc->vc_rows - b,\n\t\t\t\t\t\t\t  b - count);\n\t\t\t\typan_down_redraw(vc, t, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, count, t, 0);\n\t\t\t} else\n\t\t\t\tfbcon_redraw_move(vc, p, t, b - t - count, t + count);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_REDRAW:\n\t\t      redraw_down:\n\t\t\tfbcon_redraw(vc, p, b - 1, b - t - count,\n\t\t\t\t     -count * vc->vc_cols);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\tt),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}",
        "code_after_change": "static bool fbcon_scroll(struct vc_data *vc, unsigned int t, unsigned int b,\n\t\tenum con_scroll dir, unsigned int count)\n{\n\tstruct fb_info *info = registered_fb[con2fb_map[vc->vc_num]];\n\tstruct fbcon_display *p = &fb_display[vc->vc_num];\n\tint scroll_partial = info->flags & FBINFO_PARTIAL_PAN_OK;\n\n\tif (fbcon_is_inactive(vc, info))\n\t\treturn true;\n\n\tfbcon_cursor(vc, CM_ERASE);\n\n\t/*\n\t * ++Geert: Only use ywrap/ypan if the console is in text mode\n\t * ++Andrew: Only use ypan on hardware text mode when scrolling the\n\t *           whole screen (prevents flicker).\n\t */\n\n\tswitch (dir) {\n\tcase SM_UP:\n\t\tif (count > vc->vc_rows)\t/* Maximum realistic size */\n\t\t\tcount = vc->vc_rows;\n\t\tif (logo_shown >= 0)\n\t\t\tgoto redraw_up;\n\t\tswitch (p->scrollmode) {\n\t\tcase SCROLL_MOVE:\n\t\t\tfbcon_redraw_blit(vc, info, p, t, b - t - count,\n\t\t\t\t     count);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\t(b - count)),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t\tbreak;\n\n\t\tcase SCROLL_WRAP_MOVE:\n\t\t\tif (b - t - count > 3 * vc->vc_rows >> 2) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, 0, 0, count, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\tywrap_up(vc, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b - count, 0, b, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t + count, 0, t, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_up;\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_REDRAW:\n\t\t\tif ((p->yscroll + count <=\n\t\t\t     2 * (p->vrows - vc->vc_rows))\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, 0, t, count);\n\t\t\t\typan_up_redraw(vc, t, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, b,\n\t\t\t\t\t\t\t  vc->vc_rows - b, b);\n\t\t\t} else\n\t\t\t\tfbcon_redraw_move(vc, p, t + count, b - t - count, t);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_MOVE:\n\t\t\tif ((p->yscroll + count <=\n\t\t\t     2 * (p->vrows - vc->vc_rows))\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, 0, 0, count, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\typan_up(vc, count);\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b - count, 0, b, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t + count, 0, t, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_up;\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_REDRAW:\n\t\t      redraw_up:\n\t\t\tfbcon_redraw(vc, p, t, b - t - count,\n\t\t\t\t     count * vc->vc_cols);\n\t\t\tfbcon_clear(vc, b - count, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\t(b - count)),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t}\n\t\tbreak;\n\n\tcase SM_DOWN:\n\t\tif (count > vc->vc_rows)\t/* Maximum realistic size */\n\t\t\tcount = vc->vc_rows;\n\t\tif (logo_shown >= 0)\n\t\t\tgoto redraw_down;\n\t\tswitch (p->scrollmode) {\n\t\tcase SCROLL_MOVE:\n\t\t\tfbcon_redraw_blit(vc, info, p, b - 1, b - t - count,\n\t\t\t\t     -count);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\tt),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t\tbreak;\n\n\t\tcase SCROLL_WRAP_MOVE:\n\t\t\tif (b - t - count > 3 * vc->vc_rows >> 2) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b, 0, b - count, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\tywrap_down(vc, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, count, 0, 0, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t, 0, t + count, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_down;\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_MOVE:\n\t\t\tif ((count - p->yscroll <= p->vrows - vc->vc_rows)\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_bmove(vc, b, 0, b - count, 0,\n\t\t\t\t\t\t    vc->vc_rows - b,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t\typan_down(vc, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_bmove(vc, count, 0, 0, 0, t,\n\t\t\t\t\t\t    vc->vc_cols);\n\t\t\t} else if (info->flags & FBINFO_READS_FAST)\n\t\t\t\tfbcon_bmove(vc, t, 0, t + count, 0,\n\t\t\t\t\t    b - t - count, vc->vc_cols);\n\t\t\telse\n\t\t\t\tgoto redraw_down;\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_PAN_REDRAW:\n\t\t\tif ((count - p->yscroll <= p->vrows - vc->vc_rows)\n\t\t\t    && ((!scroll_partial && (b - t == vc->vc_rows))\n\t\t\t\t|| (scroll_partial\n\t\t\t\t    && (b - t - count >\n\t\t\t\t\t3 * vc->vc_rows >> 2)))) {\n\t\t\t\tif (vc->vc_rows - b > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, b, vc->vc_rows - b,\n\t\t\t\t\t\t\t  b - count);\n\t\t\t\typan_down_redraw(vc, t, count);\n\t\t\t\tif (t > 0)\n\t\t\t\t\tfbcon_redraw_move(vc, p, count, t, 0);\n\t\t\t} else\n\t\t\t\tfbcon_redraw_move(vc, p, t, b - t - count, t + count);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tbreak;\n\n\t\tcase SCROLL_REDRAW:\n\t\t      redraw_down:\n\t\t\tfbcon_redraw(vc, p, b - 1, b - t - count,\n\t\t\t\t     -count * vc->vc_cols);\n\t\t\tfbcon_clear(vc, t, 0, count, vc->vc_cols);\n\t\t\tscr_memsetw((unsigned short *) (vc->vc_origin +\n\t\t\t\t\t\t\tvc->vc_size_row *\n\t\t\t\t\t\t\tt),\n\t\t\t\t    vc->vc_video_erase_char,\n\t\t\t\t    vc->vc_size_row * count);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,8 +20,6 @@\n \tcase SM_UP:\n \t\tif (count > vc->vc_rows)\t/* Maximum realistic size */\n \t\t\tcount = vc->vc_rows;\n-\t\tif (softback_top)\n-\t\t\tfbcon_softback_note(vc, t, count);\n \t\tif (logo_shown >= 0)\n \t\t\tgoto redraw_up;\n \t\tswitch (p->scrollmode) {",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tif (softback_top)",
                "\t\t\tfbcon_softback_note(vc, t, count);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.9-rc6. When changing screen size, an out-of-bounds memory write can occur leading to memory corruption or a denial of service. Due to the nature of the flaw, privilege escalation cannot be fully ruled out."
    },
    {
        "cve_id": "CVE-2020-25212",
        "code_before_change": "static int _nfs4_get_security_label(struct inode *inode, void *buf,\n\t\t\t\t\tsize_t buflen)\n{\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tstruct nfs_fattr fattr;\n\tstruct nfs4_label label = {0, 0, buflen, buf};\n\n\tu32 bitmask[3] = { 0, 0, FATTR4_WORD2_SECURITY_LABEL };\n\tstruct nfs4_getattr_arg arg = {\n\t\t.fh\t\t= NFS_FH(inode),\n\t\t.bitmask\t= bitmask,\n\t};\n\tstruct nfs4_getattr_res res = {\n\t\t.fattr\t\t= &fattr,\n\t\t.label\t\t= &label,\n\t\t.server\t\t= server,\n\t};\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs4_procedures[NFSPROC4_CLNT_GETATTR],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint ret;\n\n\tnfs_fattr_init(&fattr);\n\n\tret = nfs4_call_sync(server->client, server, &msg, &arg.seq_args, &res.seq_res, 0);\n\tif (ret)\n\t\treturn ret;\n\tif (!(fattr.valid & NFS_ATTR_FATTR_V4_SECURITY_LABEL))\n\t\treturn -ENOENT;\n\tif (buflen < label.len)\n\t\treturn -ERANGE;\n\treturn 0;\n}",
        "code_after_change": "static int _nfs4_get_security_label(struct inode *inode, void *buf,\n\t\t\t\t\tsize_t buflen)\n{\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tstruct nfs_fattr fattr;\n\tstruct nfs4_label label = {0, 0, buflen, buf};\n\n\tu32 bitmask[3] = { 0, 0, FATTR4_WORD2_SECURITY_LABEL };\n\tstruct nfs4_getattr_arg arg = {\n\t\t.fh\t\t= NFS_FH(inode),\n\t\t.bitmask\t= bitmask,\n\t};\n\tstruct nfs4_getattr_res res = {\n\t\t.fattr\t\t= &fattr,\n\t\t.label\t\t= &label,\n\t\t.server\t\t= server,\n\t};\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs4_procedures[NFSPROC4_CLNT_GETATTR],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint ret;\n\n\tnfs_fattr_init(&fattr);\n\n\tret = nfs4_call_sync(server->client, server, &msg, &arg.seq_args, &res.seq_res, 0);\n\tif (ret)\n\t\treturn ret;\n\tif (!(fattr.valid & NFS_ATTR_FATTR_V4_SECURITY_LABEL))\n\t\treturn -ENOENT;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,7 +29,5 @@\n \t\treturn ret;\n \tif (!(fattr.valid & NFS_ATTR_FATTR_V4_SECURITY_LABEL))\n \t\treturn -ENOENT;\n-\tif (buflen < label.len)\n-\t\treturn -ERANGE;\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (buflen < label.len)",
                "\t\treturn -ERANGE;"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-367"
        ],
        "cve_description": "A TOCTOU mismatch in the NFS client code in the Linux kernel before 5.8.3 could be used by local attackers to corrupt memory or possibly have unspecified other impact because a size check is in fs/nfs/nfs4proc.c instead of fs/nfs/nfs4xdr.c, aka CID-b4487b935452."
    },
    {
        "cve_id": "CVE-2020-25212",
        "code_before_change": "static int decode_attr_security_label(struct xdr_stream *xdr, uint32_t *bitmap,\n\t\t\t\t\tstruct nfs4_label *label)\n{\n\tuint32_t pi = 0;\n\tuint32_t lfs = 0;\n\t__u32 len;\n\t__be32 *p;\n\tint status = 0;\n\n\tif (unlikely(bitmap[2] & (FATTR4_WORD2_SECURITY_LABEL - 1U)))\n\t\treturn -EIO;\n\tif (likely(bitmap[2] & FATTR4_WORD2_SECURITY_LABEL)) {\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tlfs = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tpi = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tlen = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, len);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tif (len < NFS4_MAXLABELLEN) {\n\t\t\tif (label) {\n\t\t\t\tmemcpy(label->label, p, len);\n\t\t\t\tlabel->len = len;\n\t\t\t\tlabel->pi = pi;\n\t\t\t\tlabel->lfs = lfs;\n\t\t\t\tstatus = NFS_ATTR_FATTR_V4_SECURITY_LABEL;\n\t\t\t}\n\t\t\tbitmap[2] &= ~FATTR4_WORD2_SECURITY_LABEL;\n\t\t} else\n\t\t\tprintk(KERN_WARNING \"%s: label too long (%u)!\\n\",\n\t\t\t\t\t__func__, len);\n\t}\n\tif (label && label->label)\n\t\tdprintk(\"%s: label=%s, len=%d, PI=%d, LFS=%d\\n\", __func__,\n\t\t\t(char *)label->label, label->len, label->pi, label->lfs);\n\treturn status;\n}",
        "code_after_change": "static int decode_attr_security_label(struct xdr_stream *xdr, uint32_t *bitmap,\n\t\t\t\t\tstruct nfs4_label *label)\n{\n\tuint32_t pi = 0;\n\tuint32_t lfs = 0;\n\t__u32 len;\n\t__be32 *p;\n\tint status = 0;\n\n\tif (unlikely(bitmap[2] & (FATTR4_WORD2_SECURITY_LABEL - 1U)))\n\t\treturn -EIO;\n\tif (likely(bitmap[2] & FATTR4_WORD2_SECURITY_LABEL)) {\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tlfs = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tpi = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, 4);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tlen = be32_to_cpup(p++);\n\t\tp = xdr_inline_decode(xdr, len);\n\t\tif (unlikely(!p))\n\t\t\treturn -EIO;\n\t\tif (len < NFS4_MAXLABELLEN) {\n\t\t\tif (label) {\n\t\t\t\tif (label->len) {\n\t\t\t\t\tif (label->len < len)\n\t\t\t\t\t\treturn -ERANGE;\n\t\t\t\t\tmemcpy(label->label, p, len);\n\t\t\t\t}\n\t\t\t\tlabel->len = len;\n\t\t\t\tlabel->pi = pi;\n\t\t\t\tlabel->lfs = lfs;\n\t\t\t\tstatus = NFS_ATTR_FATTR_V4_SECURITY_LABEL;\n\t\t\t}\n\t\t\tbitmap[2] &= ~FATTR4_WORD2_SECURITY_LABEL;\n\t\t} else\n\t\t\tprintk(KERN_WARNING \"%s: label too long (%u)!\\n\",\n\t\t\t\t\t__func__, len);\n\t}\n\tif (label && label->label)\n\t\tdprintk(\"%s: label=%s, len=%d, PI=%d, LFS=%d\\n\", __func__,\n\t\t\t(char *)label->label, label->len, label->pi, label->lfs);\n\treturn status;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,7 +27,11 @@\n \t\t\treturn -EIO;\n \t\tif (len < NFS4_MAXLABELLEN) {\n \t\t\tif (label) {\n-\t\t\t\tmemcpy(label->label, p, len);\n+\t\t\t\tif (label->len) {\n+\t\t\t\t\tif (label->len < len)\n+\t\t\t\t\t\treturn -ERANGE;\n+\t\t\t\t\tmemcpy(label->label, p, len);\n+\t\t\t\t}\n \t\t\t\tlabel->len = len;\n \t\t\t\tlabel->pi = pi;\n \t\t\t\tlabel->lfs = lfs;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tif (label->len) {",
                "\t\t\t\t\tif (label->len < len)",
                "\t\t\t\t\t\treturn -ERANGE;",
                "\t\t\t\t\tmemcpy(label->label, p, len);",
                "\t\t\t\t}"
            ],
            "deleted": [
                "\t\t\t\tmemcpy(label->label, p, len);"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-367"
        ],
        "cve_description": "A TOCTOU mismatch in the NFS client code in the Linux kernel before 5.8.3 could be used by local attackers to corrupt memory or possibly have unspecified other impact because a size check is in fs/nfs/nfs4proc.c instead of fs/nfs/nfs4xdr.c, aka CID-b4487b935452."
    },
    {
        "cve_id": "CVE-2020-25285",
        "code_before_change": "int hugetlb_overcommit_handler(struct ctl_table *table, int write,\n\t\tvoid *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttmp = h->nr_overcommit_huge_pages;\n\n\tif (write && hstate_is_gigantic(h))\n\t\treturn -EINVAL;\n\n\ttable->data = &tmp;\n\ttable->maxlen = sizeof(unsigned long);\n\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write) {\n\t\tspin_lock(&hugetlb_lock);\n\t\th->nr_overcommit_huge_pages = tmp;\n\t\tspin_unlock(&hugetlb_lock);\n\t}\nout:\n\treturn ret;\n}",
        "code_after_change": "int hugetlb_overcommit_handler(struct ctl_table *table, int write,\n\t\tvoid *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttmp = h->nr_overcommit_huge_pages;\n\n\tif (write && hstate_is_gigantic(h))\n\t\treturn -EINVAL;\n\n\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n\t\t\t\t\t     &tmp);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write) {\n\t\tspin_lock(&hugetlb_lock);\n\t\th->nr_overcommit_huge_pages = tmp;\n\t\tspin_unlock(&hugetlb_lock);\n\t}\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,9 +13,8 @@\n \tif (write && hstate_is_gigantic(h))\n \t\treturn -EINVAL;\n \n-\ttable->data = &tmp;\n-\ttable->maxlen = sizeof(unsigned long);\n-\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n+\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n+\t\t\t\t\t     &tmp);\n \tif (ret)\n \t\tgoto out;\n ",
        "function_modified_lines": {
            "added": [
                "\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,",
                "\t\t\t\t\t     &tmp);"
            ],
            "deleted": [
                "\ttable->data = &tmp;",
                "\ttable->maxlen = sizeof(unsigned long);",
                "\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-787",
            "CWE-476"
        ],
        "cve_description": "A race condition between hugetlb sysctl handlers in mm/hugetlb.c in the Linux kernel before 5.8.8 could be used by local attackers to corrupt memory, cause a NULL pointer dereference, or possibly have unspecified other impact, aka CID-17743798d812."
    },
    {
        "cve_id": "CVE-2020-25285",
        "code_before_change": "static int hugetlb_sysctl_handler_common(bool obey_mempolicy,\n\t\t\t struct ctl_table *table, int write,\n\t\t\t void *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp = h->max_huge_pages;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttable->data = &tmp;\n\ttable->maxlen = sizeof(unsigned long);\n\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write)\n\t\tret = __nr_hugepages_store_common(obey_mempolicy, h,\n\t\t\t\t\t\t  NUMA_NO_NODE, tmp, *length);\nout:\n\treturn ret;\n}",
        "code_after_change": "static int hugetlb_sysctl_handler_common(bool obey_mempolicy,\n\t\t\t struct ctl_table *table, int write,\n\t\t\t void *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp = h->max_huge_pages;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n\t\t\t\t\t     &tmp);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write)\n\t\tret = __nr_hugepages_store_common(obey_mempolicy, h,\n\t\t\t\t\t\t  NUMA_NO_NODE, tmp, *length);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,9 +9,8 @@\n \tif (!hugepages_supported())\n \t\treturn -EOPNOTSUPP;\n \n-\ttable->data = &tmp;\n-\ttable->maxlen = sizeof(unsigned long);\n-\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n+\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n+\t\t\t\t\t     &tmp);\n \tif (ret)\n \t\tgoto out;\n ",
        "function_modified_lines": {
            "added": [
                "\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,",
                "\t\t\t\t\t     &tmp);"
            ],
            "deleted": [
                "\ttable->data = &tmp;",
                "\ttable->maxlen = sizeof(unsigned long);",
                "\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-787",
            "CWE-476"
        ],
        "cve_description": "A race condition between hugetlb sysctl handlers in mm/hugetlb.c in the Linux kernel before 5.8.8 could be used by local attackers to corrupt memory, cause a NULL pointer dereference, or possibly have unspecified other impact, aka CID-17743798d812."
    },
    {
        "cve_id": "CVE-2020-8835",
        "code_before_change": "static void reg_set_min_max_inv(struct bpf_reg_state *true_reg,\n\t\t\t\tstruct bpf_reg_state *false_reg, u64 val,\n\t\t\t\tu8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JGT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JGT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSGT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSGT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JLT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JLT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSLT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSLT ? sval + 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\tif (is_jmp32) {\n\t\t__reg_bound_offset32(false_reg);\n\t\t__reg_bound_offset32(true_reg);\n\t}\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "code_after_change": "static void reg_set_min_max_inv(struct bpf_reg_state *true_reg,\n\t\t\t\tstruct bpf_reg_state *false_reg, u64 val,\n\t\t\t\tu8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JGT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JGT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSGT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSGT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JLT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JLT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSLT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSLT ? sval + 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "patch": "--- code before\n+++ code after\n@@ -96,10 +96,6 @@\n \t/* We might have learned some bits from the bounds. */\n \t__reg_bound_offset(false_reg);\n \t__reg_bound_offset(true_reg);\n-\tif (is_jmp32) {\n-\t\t__reg_bound_offset32(false_reg);\n-\t\t__reg_bound_offset32(true_reg);\n-\t}\n \t/* Intersecting with the old var_off might have improved our bounds\n \t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n \t * then new var_off is (0; 0x7f...fc) which improves our umax.",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (is_jmp32) {",
                "\t\t__reg_bound_offset32(false_reg);",
                "\t\t__reg_bound_offset32(true_reg);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.5.0 and newer, the bpf verifier (kernel/bpf/verifier.c) did not properly restrict the register bounds for 32-bit operations, leading to out-of-bounds reads and writes in kernel memory. The vulnerability also affects the Linux 5.4 stable series, starting with v5.4.7, as the introducing commit was backported to that branch. This vulnerability was fixed in 5.6.1, 5.5.14, and 5.4.29. (issue is aka ZDI-CAN-10780)"
    },
    {
        "cve_id": "CVE-2020-8835",
        "code_before_change": "static void reg_set_min_max(struct bpf_reg_state *true_reg,\n\t\t\t    struct bpf_reg_state *false_reg, u64 val,\n\t\t\t    u8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\t/* If the dst_reg is a pointer, we can't learn anything about its\n\t * variable offset from the compare (unless src_reg were a pointer into\n\t * the same object, but we don't bother with that.\n\t * Since false_reg and true_reg have the same type by construction, we\n\t * only need to check one of them for pointerness.\n\t */\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\t/* For BPF_JEQ, if this is false we know nothing Jon Snow, but\n\t\t * if it is true we know the value for sure. Likewise for\n\t\t * BPF_JNE.\n\t\t */\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JGT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JGT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSGT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSGT ? sval + 1 : sval;\n\n\t\t/* If the full s64 was not sign-extended from s32 then don't\n\t\t * deduct further info.\n\t\t */\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JLT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JLT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSLT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSLT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\tif (is_jmp32) {\n\t\t__reg_bound_offset32(false_reg);\n\t\t__reg_bound_offset32(true_reg);\n\t}\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "code_after_change": "static void reg_set_min_max(struct bpf_reg_state *true_reg,\n\t\t\t    struct bpf_reg_state *false_reg, u64 val,\n\t\t\t    u8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\t/* If the dst_reg is a pointer, we can't learn anything about its\n\t * variable offset from the compare (unless src_reg were a pointer into\n\t * the same object, but we don't bother with that.\n\t * Since false_reg and true_reg have the same type by construction, we\n\t * only need to check one of them for pointerness.\n\t */\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\t/* For BPF_JEQ, if this is false we know nothing Jon Snow, but\n\t\t * if it is true we know the value for sure. Likewise for\n\t\t * BPF_JNE.\n\t\t */\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JGT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JGT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSGT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSGT ? sval + 1 : sval;\n\n\t\t/* If the full s64 was not sign-extended from s32 then don't\n\t\t * deduct further info.\n\t\t */\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JLT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JLT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSLT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSLT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "patch": "--- code before\n+++ code after\n@@ -109,10 +109,6 @@\n \t/* We might have learned some bits from the bounds. */\n \t__reg_bound_offset(false_reg);\n \t__reg_bound_offset(true_reg);\n-\tif (is_jmp32) {\n-\t\t__reg_bound_offset32(false_reg);\n-\t\t__reg_bound_offset32(true_reg);\n-\t}\n \t/* Intersecting with the old var_off might have improved our bounds\n \t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n \t * then new var_off is (0; 0x7f...fc) which improves our umax.",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (is_jmp32) {",
                "\t\t__reg_bound_offset32(false_reg);",
                "\t\t__reg_bound_offset32(true_reg);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.5.0 and newer, the bpf verifier (kernel/bpf/verifier.c) did not properly restrict the register bounds for 32-bit operations, leading to out-of-bounds reads and writes in kernel memory. The vulnerability also affects the Linux 5.4 stable series, starting with v5.4.7, as the introducing commit was backported to that branch. This vulnerability was fixed in 5.6.1, 5.5.14, and 5.4.29. (issue is aka ZDI-CAN-10780)"
    },
    {
        "cve_id": "CVE-2020-9391",
        "code_before_change": "unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len,\n\t\t\t      unsigned long prot, unsigned long flags,\n\t\t\t      unsigned long fd, unsigned long pgoff)\n{\n\tstruct file *file = NULL;\n\tunsigned long retval;\n\n\taddr = untagged_addr(addr);\n\n\tif (!(flags & MAP_ANONYMOUS)) {\n\t\taudit_mmap_fd(fd, flags);\n\t\tfile = fget(fd);\n\t\tif (!file)\n\t\t\treturn -EBADF;\n\t\tif (is_file_hugepages(file))\n\t\t\tlen = ALIGN(len, huge_page_size(hstate_file(file)));\n\t\tretval = -EINVAL;\n\t\tif (unlikely(flags & MAP_HUGETLB && !is_file_hugepages(file)))\n\t\t\tgoto out_fput;\n\t} else if (flags & MAP_HUGETLB) {\n\t\tstruct user_struct *user = NULL;\n\t\tstruct hstate *hs;\n\n\t\ths = hstate_sizelog((flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);\n\t\tif (!hs)\n\t\t\treturn -EINVAL;\n\n\t\tlen = ALIGN(len, huge_page_size(hs));\n\t\t/*\n\t\t * VM_NORESERVE is used because the reservations will be\n\t\t * taken when vm_ops->mmap() is called\n\t\t * A dummy user value is used because we are not locking\n\t\t * memory so no accounting is necessary\n\t\t */\n\t\tfile = hugetlb_file_setup(HUGETLB_ANON_FILE, len,\n\t\t\t\tVM_NORESERVE,\n\t\t\t\t&user, HUGETLB_ANONHUGE_INODE,\n\t\t\t\t(flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);\n\t\tif (IS_ERR(file))\n\t\t\treturn PTR_ERR(file);\n\t}\n\n\tflags &= ~(MAP_EXECUTABLE | MAP_DENYWRITE);\n\n\tretval = vm_mmap_pgoff(file, addr, len, prot, flags, pgoff);\nout_fput:\n\tif (file)\n\t\tfput(file);\n\treturn retval;\n}",
        "code_after_change": "unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len,\n\t\t\t      unsigned long prot, unsigned long flags,\n\t\t\t      unsigned long fd, unsigned long pgoff)\n{\n\tstruct file *file = NULL;\n\tunsigned long retval;\n\n\tif (!(flags & MAP_ANONYMOUS)) {\n\t\taudit_mmap_fd(fd, flags);\n\t\tfile = fget(fd);\n\t\tif (!file)\n\t\t\treturn -EBADF;\n\t\tif (is_file_hugepages(file))\n\t\t\tlen = ALIGN(len, huge_page_size(hstate_file(file)));\n\t\tretval = -EINVAL;\n\t\tif (unlikely(flags & MAP_HUGETLB && !is_file_hugepages(file)))\n\t\t\tgoto out_fput;\n\t} else if (flags & MAP_HUGETLB) {\n\t\tstruct user_struct *user = NULL;\n\t\tstruct hstate *hs;\n\n\t\ths = hstate_sizelog((flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);\n\t\tif (!hs)\n\t\t\treturn -EINVAL;\n\n\t\tlen = ALIGN(len, huge_page_size(hs));\n\t\t/*\n\t\t * VM_NORESERVE is used because the reservations will be\n\t\t * taken when vm_ops->mmap() is called\n\t\t * A dummy user value is used because we are not locking\n\t\t * memory so no accounting is necessary\n\t\t */\n\t\tfile = hugetlb_file_setup(HUGETLB_ANON_FILE, len,\n\t\t\t\tVM_NORESERVE,\n\t\t\t\t&user, HUGETLB_ANONHUGE_INODE,\n\t\t\t\t(flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);\n\t\tif (IS_ERR(file))\n\t\t\treturn PTR_ERR(file);\n\t}\n\n\tflags &= ~(MAP_EXECUTABLE | MAP_DENYWRITE);\n\n\tretval = vm_mmap_pgoff(file, addr, len, prot, flags, pgoff);\nout_fput:\n\tif (file)\n\t\tfput(file);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,8 +4,6 @@\n {\n \tstruct file *file = NULL;\n \tunsigned long retval;\n-\n-\taddr = untagged_addr(addr);\n \n \tif (!(flags & MAP_ANONYMOUS)) {\n \t\taudit_mmap_fd(fd, flags);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\taddr = untagged_addr(addr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel 5.4 and 5.5 through 5.5.6 on the AArch64 architecture. It ignores the top byte in the address passed to the brk system call, potentially moving the memory break downwards when the application expects it to move upwards, aka CID-dcde237319e6. This has been observed to cause heap corruption with the GNU C Library malloc implementation."
    },
    {
        "cve_id": "CVE-2020-9391",
        "code_before_change": "\t\tstruct list_head *uf);\nSYSCALL_DEFINE1(brk, unsigned long, brk)\n{\n\tunsigned long retval;\n\tunsigned long newbrk, oldbrk, origbrk;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *next;\n\tunsigned long min_brk;\n\tbool populate;\n\tbool downgraded = false;\n\tLIST_HEAD(uf);\n\n\tbrk = untagged_addr(brk);\n\n\tif (down_write_killable(&mm->mmap_sem))\n\t\treturn -EINTR;\n\n\torigbrk = mm->brk;\n\n#ifdef CONFIG_COMPAT_BRK\n\t/*\n\t * CONFIG_COMPAT_BRK can still be overridden by setting\n\t * randomize_va_space to 2, which will still cause mm->start_brk\n\t * to be arbitrarily shifted\n\t */\n\tif (current->brk_randomized)\n\t\tmin_brk = mm->start_brk;\n\telse\n\t\tmin_brk = mm->end_data;\n#else\n\tmin_brk = mm->start_brk;\n#endif\n\tif (brk < min_brk)\n\t\tgoto out;\n\n\t/*\n\t * Check against rlimit here. If this check is done later after the test\n\t * of oldbrk with newbrk then it can escape the test and let the data\n\t * segment grow beyond its set limit the in case where the limit is\n\t * not page aligned -Ram Gupta\n\t */\n\tif (check_data_rlimit(rlimit(RLIMIT_DATA), brk, mm->start_brk,\n\t\t\t      mm->end_data, mm->start_data))\n\t\tgoto out;\n\n\tnewbrk = PAGE_ALIGN(brk);\n\toldbrk = PAGE_ALIGN(mm->brk);\n\tif (oldbrk == newbrk) {\n\t\tmm->brk = brk;\n\t\tgoto success;\n\t}\n\n\t/*\n\t * Always allow shrinking brk.\n\t * __do_munmap() may downgrade mmap_sem to read.\n\t */\n\tif (brk <= mm->brk) {\n\t\tint ret;\n\n\t\t/*\n\t\t * mm->brk must to be protected by write mmap_sem so update it\n\t\t * before downgrading mmap_sem. When __do_munmap() fails,\n\t\t * mm->brk will be restored from origbrk.\n\t\t */\n\t\tmm->brk = brk;\n\t\tret = __do_munmap(mm, newbrk, oldbrk-newbrk, &uf, true);\n\t\tif (ret < 0) {\n\t\t\tmm->brk = origbrk;\n\t\t\tgoto out;\n\t\t} else if (ret == 1) {\n\t\t\tdowngraded = true;\n\t\t}\n\t\tgoto success;\n\t}\n\n\t/* Check against existing mmap mappings. */\n\tnext = find_vma(mm, oldbrk);\n\tif (next && newbrk + PAGE_SIZE > vm_start_gap(next))\n\t\tgoto out;\n\n\t/* Ok, looks good - let it rip. */\n\tif (do_brk_flags(oldbrk, newbrk-oldbrk, 0, &uf) < 0)\n\t\tgoto out;\n\tmm->brk = brk;\n\nsuccess:\n\tpopulate = newbrk > oldbrk && (mm->def_flags & VM_LOCKED) != 0;\n\tif (downgraded)\n\t\tup_read(&mm->mmap_sem);\n\telse\n\t\tup_write(&mm->mmap_sem);\n\tuserfaultfd_unmap_complete(mm, &uf);\n\tif (populate)\n\t\tmm_populate(oldbrk, newbrk - oldbrk);\n\treturn brk;\n\nout:\n\tretval = origbrk;\n\tup_write(&mm->mmap_sem);\n\treturn retval;\n}",
        "code_after_change": "\t\tstruct list_head *uf);\nSYSCALL_DEFINE1(brk, unsigned long, brk)\n{\n\tunsigned long retval;\n\tunsigned long newbrk, oldbrk, origbrk;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *next;\n\tunsigned long min_brk;\n\tbool populate;\n\tbool downgraded = false;\n\tLIST_HEAD(uf);\n\n\tif (down_write_killable(&mm->mmap_sem))\n\t\treturn -EINTR;\n\n\torigbrk = mm->brk;\n\n#ifdef CONFIG_COMPAT_BRK\n\t/*\n\t * CONFIG_COMPAT_BRK can still be overridden by setting\n\t * randomize_va_space to 2, which will still cause mm->start_brk\n\t * to be arbitrarily shifted\n\t */\n\tif (current->brk_randomized)\n\t\tmin_brk = mm->start_brk;\n\telse\n\t\tmin_brk = mm->end_data;\n#else\n\tmin_brk = mm->start_brk;\n#endif\n\tif (brk < min_brk)\n\t\tgoto out;\n\n\t/*\n\t * Check against rlimit here. If this check is done later after the test\n\t * of oldbrk with newbrk then it can escape the test and let the data\n\t * segment grow beyond its set limit the in case where the limit is\n\t * not page aligned -Ram Gupta\n\t */\n\tif (check_data_rlimit(rlimit(RLIMIT_DATA), brk, mm->start_brk,\n\t\t\t      mm->end_data, mm->start_data))\n\t\tgoto out;\n\n\tnewbrk = PAGE_ALIGN(brk);\n\toldbrk = PAGE_ALIGN(mm->brk);\n\tif (oldbrk == newbrk) {\n\t\tmm->brk = brk;\n\t\tgoto success;\n\t}\n\n\t/*\n\t * Always allow shrinking brk.\n\t * __do_munmap() may downgrade mmap_sem to read.\n\t */\n\tif (brk <= mm->brk) {\n\t\tint ret;\n\n\t\t/*\n\t\t * mm->brk must to be protected by write mmap_sem so update it\n\t\t * before downgrading mmap_sem. When __do_munmap() fails,\n\t\t * mm->brk will be restored from origbrk.\n\t\t */\n\t\tmm->brk = brk;\n\t\tret = __do_munmap(mm, newbrk, oldbrk-newbrk, &uf, true);\n\t\tif (ret < 0) {\n\t\t\tmm->brk = origbrk;\n\t\t\tgoto out;\n\t\t} else if (ret == 1) {\n\t\t\tdowngraded = true;\n\t\t}\n\t\tgoto success;\n\t}\n\n\t/* Check against existing mmap mappings. */\n\tnext = find_vma(mm, oldbrk);\n\tif (next && newbrk + PAGE_SIZE > vm_start_gap(next))\n\t\tgoto out;\n\n\t/* Ok, looks good - let it rip. */\n\tif (do_brk_flags(oldbrk, newbrk-oldbrk, 0, &uf) < 0)\n\t\tgoto out;\n\tmm->brk = brk;\n\nsuccess:\n\tpopulate = newbrk > oldbrk && (mm->def_flags & VM_LOCKED) != 0;\n\tif (downgraded)\n\t\tup_read(&mm->mmap_sem);\n\telse\n\t\tup_write(&mm->mmap_sem);\n\tuserfaultfd_unmap_complete(mm, &uf);\n\tif (populate)\n\t\tmm_populate(oldbrk, newbrk - oldbrk);\n\treturn brk;\n\nout:\n\tretval = origbrk;\n\tup_write(&mm->mmap_sem);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,8 +9,6 @@\n \tbool populate;\n \tbool downgraded = false;\n \tLIST_HEAD(uf);\n-\n-\tbrk = untagged_addr(brk);\n \n \tif (down_write_killable(&mm->mmap_sem))\n \t\treturn -EINTR;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tbrk = untagged_addr(brk);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel 5.4 and 5.5 through 5.5.6 on the AArch64 architecture. It ignores the top byte in the address passed to the brk system call, potentially moving the memory break downwards when the application expects it to move upwards, aka CID-dcde237319e6. This has been observed to cause heap corruption with the GNU C Library malloc implementation."
    },
    {
        "cve_id": "CVE-2020-9391",
        "code_before_change": " */\nSYSCALL_DEFINE5(mremap, unsigned long, addr, unsigned long, old_len,\n\t\tunsigned long, new_len, unsigned long, flags,\n\t\tunsigned long, new_addr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long ret = -EINVAL;\n\tunsigned long charged = 0;\n\tbool locked = false;\n\tbool downgraded = false;\n\tstruct vm_userfaultfd_ctx uf = NULL_VM_UFFD_CTX;\n\tLIST_HEAD(uf_unmap_early);\n\tLIST_HEAD(uf_unmap);\n\n\taddr = untagged_addr(addr);\n\tnew_addr = untagged_addr(new_addr);\n\n\tif (flags & ~(MREMAP_FIXED | MREMAP_MAYMOVE))\n\t\treturn ret;\n\n\tif (flags & MREMAP_FIXED && !(flags & MREMAP_MAYMOVE))\n\t\treturn ret;\n\n\tif (offset_in_page(addr))\n\t\treturn ret;\n\n\told_len = PAGE_ALIGN(old_len);\n\tnew_len = PAGE_ALIGN(new_len);\n\n\t/*\n\t * We allow a zero old-len as a special case\n\t * for DOS-emu \"duplicate shm area\" thing. But\n\t * a zero new-len is nonsensical.\n\t */\n\tif (!new_len)\n\t\treturn ret;\n\n\tif (down_write_killable(&current->mm->mmap_sem))\n\t\treturn -EINTR;\n\n\tif (flags & MREMAP_FIXED) {\n\t\tret = mremap_to(addr, old_len, new_addr, new_len,\n\t\t\t\t&locked, &uf, &uf_unmap_early, &uf_unmap);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Always allow a shrinking remap: that just unmaps\n\t * the unnecessary pages..\n\t * __do_munmap does all the needed commit accounting, and\n\t * downgrades mmap_sem to read if so directed.\n\t */\n\tif (old_len >= new_len) {\n\t\tint retval;\n\n\t\tretval = __do_munmap(mm, addr+new_len, old_len - new_len,\n\t\t\t\t  &uf_unmap, true);\n\t\tif (retval < 0 && old_len != new_len) {\n\t\t\tret = retval;\n\t\t\tgoto out;\n\t\t/* Returning 1 indicates mmap_sem is downgraded to read. */\n\t\t} else if (retval == 1)\n\t\t\tdowngraded = true;\n\t\tret = addr;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Ok, we need to grow..\n\t */\n\tvma = vma_to_resize(addr, old_len, new_len, &charged);\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto out;\n\t}\n\n\t/* old_len exactly to the end of the area..\n\t */\n\tif (old_len == vma->vm_end - addr) {\n\t\t/* can we just expand the current mapping? */\n\t\tif (vma_expandable(vma, new_len - old_len)) {\n\t\t\tint pages = (new_len - old_len) >> PAGE_SHIFT;\n\n\t\t\tif (vma_adjust(vma, vma->vm_start, addr + new_len,\n\t\t\t\t       vma->vm_pgoff, NULL)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tvm_stat_account(mm, vma->vm_flags, pages);\n\t\t\tif (vma->vm_flags & VM_LOCKED) {\n\t\t\t\tmm->locked_vm += pages;\n\t\t\t\tlocked = true;\n\t\t\t\tnew_addr = addr;\n\t\t\t}\n\t\t\tret = addr;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * We weren't able to just expand or shrink the area,\n\t * we need to create a new one and move it..\n\t */\n\tret = -ENOMEM;\n\tif (flags & MREMAP_MAYMOVE) {\n\t\tunsigned long map_flags = 0;\n\t\tif (vma->vm_flags & VM_MAYSHARE)\n\t\t\tmap_flags |= MAP_SHARED;\n\n\t\tnew_addr = get_unmapped_area(vma->vm_file, 0, new_len,\n\t\t\t\t\tvma->vm_pgoff +\n\t\t\t\t\t((addr - vma->vm_start) >> PAGE_SHIFT),\n\t\t\t\t\tmap_flags);\n\t\tif (IS_ERR_VALUE(new_addr)) {\n\t\t\tret = new_addr;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = move_vma(vma, addr, old_len, new_len, new_addr,\n\t\t\t       &locked, &uf, &uf_unmap);\n\t}\nout:\n\tif (offset_in_page(ret)) {\n\t\tvm_unacct_memory(charged);\n\t\tlocked = 0;\n\t}\n\tif (downgraded)\n\t\tup_read(&current->mm->mmap_sem);\n\telse\n\t\tup_write(&current->mm->mmap_sem);\n\tif (locked && new_len > old_len)\n\t\tmm_populate(new_addr + old_len, new_len - old_len);\n\tuserfaultfd_unmap_complete(mm, &uf_unmap_early);\n\tmremap_userfaultfd_complete(&uf, addr, new_addr, old_len);\n\tuserfaultfd_unmap_complete(mm, &uf_unmap);\n\treturn ret;\n}",
        "code_after_change": " */\nSYSCALL_DEFINE5(mremap, unsigned long, addr, unsigned long, old_len,\n\t\tunsigned long, new_len, unsigned long, flags,\n\t\tunsigned long, new_addr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long ret = -EINVAL;\n\tunsigned long charged = 0;\n\tbool locked = false;\n\tbool downgraded = false;\n\tstruct vm_userfaultfd_ctx uf = NULL_VM_UFFD_CTX;\n\tLIST_HEAD(uf_unmap_early);\n\tLIST_HEAD(uf_unmap);\n\n\taddr = untagged_addr(addr);\n\n\tif (flags & ~(MREMAP_FIXED | MREMAP_MAYMOVE))\n\t\treturn ret;\n\n\tif (flags & MREMAP_FIXED && !(flags & MREMAP_MAYMOVE))\n\t\treturn ret;\n\n\tif (offset_in_page(addr))\n\t\treturn ret;\n\n\told_len = PAGE_ALIGN(old_len);\n\tnew_len = PAGE_ALIGN(new_len);\n\n\t/*\n\t * We allow a zero old-len as a special case\n\t * for DOS-emu \"duplicate shm area\" thing. But\n\t * a zero new-len is nonsensical.\n\t */\n\tif (!new_len)\n\t\treturn ret;\n\n\tif (down_write_killable(&current->mm->mmap_sem))\n\t\treturn -EINTR;\n\n\tif (flags & MREMAP_FIXED) {\n\t\tret = mremap_to(addr, old_len, new_addr, new_len,\n\t\t\t\t&locked, &uf, &uf_unmap_early, &uf_unmap);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Always allow a shrinking remap: that just unmaps\n\t * the unnecessary pages..\n\t * __do_munmap does all the needed commit accounting, and\n\t * downgrades mmap_sem to read if so directed.\n\t */\n\tif (old_len >= new_len) {\n\t\tint retval;\n\n\t\tretval = __do_munmap(mm, addr+new_len, old_len - new_len,\n\t\t\t\t  &uf_unmap, true);\n\t\tif (retval < 0 && old_len != new_len) {\n\t\t\tret = retval;\n\t\t\tgoto out;\n\t\t/* Returning 1 indicates mmap_sem is downgraded to read. */\n\t\t} else if (retval == 1)\n\t\t\tdowngraded = true;\n\t\tret = addr;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Ok, we need to grow..\n\t */\n\tvma = vma_to_resize(addr, old_len, new_len, &charged);\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto out;\n\t}\n\n\t/* old_len exactly to the end of the area..\n\t */\n\tif (old_len == vma->vm_end - addr) {\n\t\t/* can we just expand the current mapping? */\n\t\tif (vma_expandable(vma, new_len - old_len)) {\n\t\t\tint pages = (new_len - old_len) >> PAGE_SHIFT;\n\n\t\t\tif (vma_adjust(vma, vma->vm_start, addr + new_len,\n\t\t\t\t       vma->vm_pgoff, NULL)) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tvm_stat_account(mm, vma->vm_flags, pages);\n\t\t\tif (vma->vm_flags & VM_LOCKED) {\n\t\t\t\tmm->locked_vm += pages;\n\t\t\t\tlocked = true;\n\t\t\t\tnew_addr = addr;\n\t\t\t}\n\t\t\tret = addr;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * We weren't able to just expand or shrink the area,\n\t * we need to create a new one and move it..\n\t */\n\tret = -ENOMEM;\n\tif (flags & MREMAP_MAYMOVE) {\n\t\tunsigned long map_flags = 0;\n\t\tif (vma->vm_flags & VM_MAYSHARE)\n\t\t\tmap_flags |= MAP_SHARED;\n\n\t\tnew_addr = get_unmapped_area(vma->vm_file, 0, new_len,\n\t\t\t\t\tvma->vm_pgoff +\n\t\t\t\t\t((addr - vma->vm_start) >> PAGE_SHIFT),\n\t\t\t\t\tmap_flags);\n\t\tif (IS_ERR_VALUE(new_addr)) {\n\t\t\tret = new_addr;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = move_vma(vma, addr, old_len, new_len, new_addr,\n\t\t\t       &locked, &uf, &uf_unmap);\n\t}\nout:\n\tif (offset_in_page(ret)) {\n\t\tvm_unacct_memory(charged);\n\t\tlocked = 0;\n\t}\n\tif (downgraded)\n\t\tup_read(&current->mm->mmap_sem);\n\telse\n\t\tup_write(&current->mm->mmap_sem);\n\tif (locked && new_len > old_len)\n\t\tmm_populate(new_addr + old_len, new_len - old_len);\n\tuserfaultfd_unmap_complete(mm, &uf_unmap_early);\n\tmremap_userfaultfd_complete(&uf, addr, new_addr, old_len);\n\tuserfaultfd_unmap_complete(mm, &uf_unmap);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,6 @@\n \tLIST_HEAD(uf_unmap);\n \n \taddr = untagged_addr(addr);\n-\tnew_addr = untagged_addr(new_addr);\n \n \tif (flags & ~(MREMAP_FIXED | MREMAP_MAYMOVE))\n \t\treturn ret;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tnew_addr = untagged_addr(new_addr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel 5.4 and 5.5 through 5.5.6 on the AArch64 architecture. It ignores the top byte in the address passed to the brk system call, potentially moving the memory break downwards when the application expects it to move upwards, aka CID-dcde237319e6. This has been observed to cause heap corruption with the GNU C Library malloc implementation."
    },
    {
        "cve_id": "CVE-2021-0512",
        "code_before_change": "static int hid_add_field(struct hid_parser *parser, unsigned report_type, unsigned flags)\n{\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tunsigned int usages;\n\tunsigned int offset;\n\tunsigned int i;\n\tunsigned int application;\n\n\tapplication = hid_lookup_collection(parser, HID_COLLECTION_APPLICATION);\n\n\treport = hid_register_report(parser->device, report_type,\n\t\t\t\t     parser->global.report_id, application);\n\tif (!report) {\n\t\thid_err(parser->device, \"hid_register_report failed\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Handle both signed and unsigned cases properly */\n\tif ((parser->global.logical_minimum < 0 &&\n\t\tparser->global.logical_maximum <\n\t\tparser->global.logical_minimum) ||\n\t\t(parser->global.logical_minimum >= 0 &&\n\t\t(__u32)parser->global.logical_maximum <\n\t\t(__u32)parser->global.logical_minimum)) {\n\t\tdbg_hid(\"logical range invalid 0x%x 0x%x\\n\",\n\t\t\tparser->global.logical_minimum,\n\t\t\tparser->global.logical_maximum);\n\t\treturn -1;\n\t}\n\n\toffset = report->size;\n\treport->size += parser->global.report_size * parser->global.report_count;\n\n\t/* Total size check: Allow for possible report index byte */\n\tif (report->size > (HID_MAX_BUFFER_SIZE - 1) << 3) {\n\t\thid_err(parser->device, \"report is too long\\n\");\n\t\treturn -1;\n\t}\n\n\tif (!parser->local.usage_index) /* Ignore padding fields */\n\t\treturn 0;\n\n\tusages = max_t(unsigned, parser->local.usage_index,\n\t\t\t\t parser->global.report_count);\n\n\tfield = hid_register_field(report, usages, parser->global.report_count);\n\tif (!field)\n\t\treturn 0;\n\n\tfield->physical = hid_lookup_collection(parser, HID_COLLECTION_PHYSICAL);\n\tfield->logical = hid_lookup_collection(parser, HID_COLLECTION_LOGICAL);\n\tfield->application = application;\n\n\tfor (i = 0; i < usages; i++) {\n\t\tunsigned j = i;\n\t\t/* Duplicate the last usage we parsed if we have excess values */\n\t\tif (i >= parser->local.usage_index)\n\t\t\tj = parser->local.usage_index - 1;\n\t\tfield->usage[i].hid = parser->local.usage[j];\n\t\tfield->usage[i].collection_index =\n\t\t\tparser->local.collection_index[j];\n\t\tfield->usage[i].usage_index = i;\n\t\tfield->usage[i].resolution_multiplier = 1;\n\t}\n\n\tfield->maxusage = usages;\n\tfield->flags = flags;\n\tfield->report_offset = offset;\n\tfield->report_type = report_type;\n\tfield->report_size = parser->global.report_size;\n\tfield->report_count = parser->global.report_count;\n\tfield->logical_minimum = parser->global.logical_minimum;\n\tfield->logical_maximum = parser->global.logical_maximum;\n\tfield->physical_minimum = parser->global.physical_minimum;\n\tfield->physical_maximum = parser->global.physical_maximum;\n\tfield->unit_exponent = parser->global.unit_exponent;\n\tfield->unit = parser->global.unit;\n\n\treturn 0;\n}",
        "code_after_change": "static int hid_add_field(struct hid_parser *parser, unsigned report_type, unsigned flags)\n{\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tunsigned int usages;\n\tunsigned int offset;\n\tunsigned int i;\n\tunsigned int application;\n\n\tapplication = hid_lookup_collection(parser, HID_COLLECTION_APPLICATION);\n\n\treport = hid_register_report(parser->device, report_type,\n\t\t\t\t     parser->global.report_id, application);\n\tif (!report) {\n\t\thid_err(parser->device, \"hid_register_report failed\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Handle both signed and unsigned cases properly */\n\tif ((parser->global.logical_minimum < 0 &&\n\t\tparser->global.logical_maximum <\n\t\tparser->global.logical_minimum) ||\n\t\t(parser->global.logical_minimum >= 0 &&\n\t\t(__u32)parser->global.logical_maximum <\n\t\t(__u32)parser->global.logical_minimum)) {\n\t\tdbg_hid(\"logical range invalid 0x%x 0x%x\\n\",\n\t\t\tparser->global.logical_minimum,\n\t\t\tparser->global.logical_maximum);\n\t\treturn -1;\n\t}\n\n\toffset = report->size;\n\treport->size += parser->global.report_size * parser->global.report_count;\n\n\t/* Total size check: Allow for possible report index byte */\n\tif (report->size > (HID_MAX_BUFFER_SIZE - 1) << 3) {\n\t\thid_err(parser->device, \"report is too long\\n\");\n\t\treturn -1;\n\t}\n\n\tif (!parser->local.usage_index) /* Ignore padding fields */\n\t\treturn 0;\n\n\tusages = max_t(unsigned, parser->local.usage_index,\n\t\t\t\t parser->global.report_count);\n\n\tfield = hid_register_field(report, usages);\n\tif (!field)\n\t\treturn 0;\n\n\tfield->physical = hid_lookup_collection(parser, HID_COLLECTION_PHYSICAL);\n\tfield->logical = hid_lookup_collection(parser, HID_COLLECTION_LOGICAL);\n\tfield->application = application;\n\n\tfor (i = 0; i < usages; i++) {\n\t\tunsigned j = i;\n\t\t/* Duplicate the last usage we parsed if we have excess values */\n\t\tif (i >= parser->local.usage_index)\n\t\t\tj = parser->local.usage_index - 1;\n\t\tfield->usage[i].hid = parser->local.usage[j];\n\t\tfield->usage[i].collection_index =\n\t\t\tparser->local.collection_index[j];\n\t\tfield->usage[i].usage_index = i;\n\t\tfield->usage[i].resolution_multiplier = 1;\n\t}\n\n\tfield->maxusage = usages;\n\tfield->flags = flags;\n\tfield->report_offset = offset;\n\tfield->report_type = report_type;\n\tfield->report_size = parser->global.report_size;\n\tfield->report_count = parser->global.report_count;\n\tfield->logical_minimum = parser->global.logical_minimum;\n\tfield->logical_maximum = parser->global.logical_maximum;\n\tfield->physical_minimum = parser->global.physical_minimum;\n\tfield->physical_maximum = parser->global.physical_maximum;\n\tfield->unit_exponent = parser->global.unit_exponent;\n\tfield->unit = parser->global.unit;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -44,7 +44,7 @@\n \tusages = max_t(unsigned, parser->local.usage_index,\n \t\t\t\t parser->global.report_count);\n \n-\tfield = hid_register_field(report, usages, parser->global.report_count);\n+\tfield = hid_register_field(report, usages);\n \tif (!field)\n \t\treturn 0;\n ",
        "function_modified_lines": {
            "added": [
                "\tfield = hid_register_field(report, usages);"
            ],
            "deleted": [
                "\tfield = hid_register_field(report, usages, parser->global.report_count);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In __hidinput_change_resolution_multipliers of hid-input.c, there is a possible out of bounds write due to a heap buffer overflow. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-173843328References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2021-0935",
        "code_before_change": "int __ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr,\n\t\t\t   int addr_len)\n{\n\tstruct sockaddr_in6\t*usin = (struct sockaddr_in6 *) uaddr;\n\tstruct inet_sock\t*inet = inet_sk(sk);\n\tstruct ipv6_pinfo\t*np = inet6_sk(sk);\n\tstruct in6_addr\t\t*daddr;\n\tint\t\t\taddr_type;\n\tint\t\t\terr;\n\t__be32\t\t\tfl6_flowlabel = 0;\n\n\tif (usin->sin6_family == AF_INET) {\n\t\tif (__ipv6_only_sock(sk))\n\t\t\treturn -EAFNOSUPPORT;\n\t\terr = __ip4_datagram_connect(sk, uaddr, addr_len);\n\t\tgoto ipv4_connected;\n\t}\n\n\tif (addr_len < SIN6_LEN_RFC2133)\n\t\treturn -EINVAL;\n\n\tif (usin->sin6_family != AF_INET6)\n\t\treturn -EAFNOSUPPORT;\n\n\tif (np->sndflow)\n\t\tfl6_flowlabel = usin->sin6_flowinfo & IPV6_FLOWINFO_MASK;\n\n\tif (ipv6_addr_any(&usin->sin6_addr)) {\n\t\t/*\n\t\t *\tconnect to self\n\t\t */\n\t\tif (ipv6_addr_v4mapped(&sk->sk_v6_rcv_saddr))\n\t\t\tipv6_addr_set_v4mapped(htonl(INADDR_LOOPBACK),\n\t\t\t\t\t       &usin->sin6_addr);\n\t\telse\n\t\t\tusin->sin6_addr = in6addr_loopback;\n\t}\n\n\taddr_type = ipv6_addr_type(&usin->sin6_addr);\n\n\tdaddr = &usin->sin6_addr;\n\n\tif (addr_type & IPV6_ADDR_MAPPED) {\n\t\tstruct sockaddr_in sin;\n\n\t\tif (__ipv6_only_sock(sk)) {\n\t\t\terr = -ENETUNREACH;\n\t\t\tgoto out;\n\t\t}\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_addr.s_addr = daddr->s6_addr32[3];\n\t\tsin.sin_port = usin->sin6_port;\n\n\t\terr = __ip4_datagram_connect(sk,\n\t\t\t\t\t     (struct sockaddr *) &sin,\n\t\t\t\t\t     sizeof(sin));\n\nipv4_connected:\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tipv6_addr_set_v4mapped(inet->inet_daddr, &sk->sk_v6_daddr);\n\n\t\tif (ipv6_addr_any(&np->saddr) ||\n\t\t    ipv6_mapped_addr_any(&np->saddr))\n\t\t\tipv6_addr_set_v4mapped(inet->inet_saddr, &np->saddr);\n\n\t\tif (ipv6_addr_any(&sk->sk_v6_rcv_saddr) ||\n\t\t    ipv6_mapped_addr_any(&sk->sk_v6_rcv_saddr)) {\n\t\t\tipv6_addr_set_v4mapped(inet->inet_rcv_saddr,\n\t\t\t\t\t       &sk->sk_v6_rcv_saddr);\n\t\t\tif (sk->sk_prot->rehash)\n\t\t\t\tsk->sk_prot->rehash(sk);\n\t\t}\n\n\t\tgoto out;\n\t}\n\n\tif (__ipv6_addr_needs_scope_id(addr_type)) {\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    usin->sin6_scope_id) {\n\t\t\tif (!sk_dev_equal_l3scope(sk, usin->sin6_scope_id)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsk->sk_bound_dev_if = usin->sin6_scope_id;\n\t\t}\n\n\t\tif (!sk->sk_bound_dev_if && (addr_type & IPV6_ADDR_MULTICAST))\n\t\t\tsk->sk_bound_dev_if = np->mcast_oif;\n\n\t\t/* Connect to link-local address requires an interface */\n\t\tif (!sk->sk_bound_dev_if) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tsk->sk_v6_daddr = *daddr;\n\tnp->flow_label = fl6_flowlabel;\n\n\tinet->inet_dport = usin->sin6_port;\n\n\t/*\n\t *\tCheck for a route to destination an obtain the\n\t *\tdestination cache for it.\n\t */\n\n\terr = ip6_datagram_dst_update(sk, true);\n\tif (err) {\n\t\t/* Reset daddr and dport so that udp_v6_early_demux()\n\t\t * fails to find this socket\n\t\t */\n\t\tmemset(&sk->sk_v6_daddr, 0, sizeof(sk->sk_v6_daddr));\n\t\tinet->inet_dport = 0;\n\t\tgoto out;\n\t}\n\n\tsk->sk_state = TCP_ESTABLISHED;\n\tsk_set_txhash(sk);\nout:\n\treturn err;\n}",
        "code_after_change": "int __ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr,\n\t\t\t   int addr_len)\n{\n\tstruct sockaddr_in6\t*usin = (struct sockaddr_in6 *) uaddr;\n\tstruct inet_sock\t*inet = inet_sk(sk);\n\tstruct ipv6_pinfo\t*np = inet6_sk(sk);\n\tstruct in6_addr\t\t*daddr, old_daddr;\n\t__be32\t\t\tfl6_flowlabel = 0;\n\t__be32\t\t\told_fl6_flowlabel;\n\t__be32\t\t\told_dport;\n\tint\t\t\taddr_type;\n\tint\t\t\terr;\n\n\tif (usin->sin6_family == AF_INET) {\n\t\tif (__ipv6_only_sock(sk))\n\t\t\treturn -EAFNOSUPPORT;\n\t\terr = __ip4_datagram_connect(sk, uaddr, addr_len);\n\t\tgoto ipv4_connected;\n\t}\n\n\tif (addr_len < SIN6_LEN_RFC2133)\n\t\treturn -EINVAL;\n\n\tif (usin->sin6_family != AF_INET6)\n\t\treturn -EAFNOSUPPORT;\n\n\tif (np->sndflow)\n\t\tfl6_flowlabel = usin->sin6_flowinfo & IPV6_FLOWINFO_MASK;\n\n\tif (ipv6_addr_any(&usin->sin6_addr)) {\n\t\t/*\n\t\t *\tconnect to self\n\t\t */\n\t\tif (ipv6_addr_v4mapped(&sk->sk_v6_rcv_saddr))\n\t\t\tipv6_addr_set_v4mapped(htonl(INADDR_LOOPBACK),\n\t\t\t\t\t       &usin->sin6_addr);\n\t\telse\n\t\t\tusin->sin6_addr = in6addr_loopback;\n\t}\n\n\taddr_type = ipv6_addr_type(&usin->sin6_addr);\n\n\tdaddr = &usin->sin6_addr;\n\n\tif (addr_type & IPV6_ADDR_MAPPED) {\n\t\tstruct sockaddr_in sin;\n\n\t\tif (__ipv6_only_sock(sk)) {\n\t\t\terr = -ENETUNREACH;\n\t\t\tgoto out;\n\t\t}\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_addr.s_addr = daddr->s6_addr32[3];\n\t\tsin.sin_port = usin->sin6_port;\n\n\t\terr = __ip4_datagram_connect(sk,\n\t\t\t\t\t     (struct sockaddr *) &sin,\n\t\t\t\t\t     sizeof(sin));\n\nipv4_connected:\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tipv6_addr_set_v4mapped(inet->inet_daddr, &sk->sk_v6_daddr);\n\n\t\tif (ipv6_addr_any(&np->saddr) ||\n\t\t    ipv6_mapped_addr_any(&np->saddr))\n\t\t\tipv6_addr_set_v4mapped(inet->inet_saddr, &np->saddr);\n\n\t\tif (ipv6_addr_any(&sk->sk_v6_rcv_saddr) ||\n\t\t    ipv6_mapped_addr_any(&sk->sk_v6_rcv_saddr)) {\n\t\t\tipv6_addr_set_v4mapped(inet->inet_rcv_saddr,\n\t\t\t\t\t       &sk->sk_v6_rcv_saddr);\n\t\t\tif (sk->sk_prot->rehash)\n\t\t\t\tsk->sk_prot->rehash(sk);\n\t\t}\n\n\t\tgoto out;\n\t}\n\n\tif (__ipv6_addr_needs_scope_id(addr_type)) {\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    usin->sin6_scope_id) {\n\t\t\tif (!sk_dev_equal_l3scope(sk, usin->sin6_scope_id)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsk->sk_bound_dev_if = usin->sin6_scope_id;\n\t\t}\n\n\t\tif (!sk->sk_bound_dev_if && (addr_type & IPV6_ADDR_MULTICAST))\n\t\t\tsk->sk_bound_dev_if = np->mcast_oif;\n\n\t\t/* Connect to link-local address requires an interface */\n\t\tif (!sk->sk_bound_dev_if) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* save the current peer information before updating it */\n\told_daddr = sk->sk_v6_daddr;\n\told_fl6_flowlabel = np->flow_label;\n\told_dport = inet->inet_dport;\n\n\tsk->sk_v6_daddr = *daddr;\n\tnp->flow_label = fl6_flowlabel;\n\tinet->inet_dport = usin->sin6_port;\n\n\t/*\n\t *\tCheck for a route to destination an obtain the\n\t *\tdestination cache for it.\n\t */\n\n\terr = ip6_datagram_dst_update(sk, true);\n\tif (err) {\n\t\t/* Restore the socket peer info, to keep it consistent with\n\t\t * the old socket state\n\t\t */\n\t\tsk->sk_v6_daddr = old_daddr;\n\t\tnp->flow_label = old_fl6_flowlabel;\n\t\tinet->inet_dport = old_dport;\n\t\tgoto out;\n\t}\n\n\tsk->sk_state = TCP_ESTABLISHED;\n\tsk_set_txhash(sk);\nout:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,12 @@\n \tstruct sockaddr_in6\t*usin = (struct sockaddr_in6 *) uaddr;\n \tstruct inet_sock\t*inet = inet_sk(sk);\n \tstruct ipv6_pinfo\t*np = inet6_sk(sk);\n-\tstruct in6_addr\t\t*daddr;\n+\tstruct in6_addr\t\t*daddr, old_daddr;\n+\t__be32\t\t\tfl6_flowlabel = 0;\n+\t__be32\t\t\told_fl6_flowlabel;\n+\t__be32\t\t\told_dport;\n \tint\t\t\taddr_type;\n \tint\t\t\terr;\n-\t__be32\t\t\tfl6_flowlabel = 0;\n \n \tif (usin->sin6_family == AF_INET) {\n \t\tif (__ipv6_only_sock(sk))\n@@ -96,9 +98,13 @@\n \t\t}\n \t}\n \n+\t/* save the current peer information before updating it */\n+\told_daddr = sk->sk_v6_daddr;\n+\told_fl6_flowlabel = np->flow_label;\n+\told_dport = inet->inet_dport;\n+\n \tsk->sk_v6_daddr = *daddr;\n \tnp->flow_label = fl6_flowlabel;\n-\n \tinet->inet_dport = usin->sin6_port;\n \n \t/*\n@@ -108,11 +114,12 @@\n \n \terr = ip6_datagram_dst_update(sk, true);\n \tif (err) {\n-\t\t/* Reset daddr and dport so that udp_v6_early_demux()\n-\t\t * fails to find this socket\n+\t\t/* Restore the socket peer info, to keep it consistent with\n+\t\t * the old socket state\n \t\t */\n-\t\tmemset(&sk->sk_v6_daddr, 0, sizeof(sk->sk_v6_daddr));\n-\t\tinet->inet_dport = 0;\n+\t\tsk->sk_v6_daddr = old_daddr;\n+\t\tnp->flow_label = old_fl6_flowlabel;\n+\t\tinet->inet_dport = old_dport;\n \t\tgoto out;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct in6_addr\t\t*daddr, old_daddr;",
                "\t__be32\t\t\tfl6_flowlabel = 0;",
                "\t__be32\t\t\told_fl6_flowlabel;",
                "\t__be32\t\t\told_dport;",
                "\t/* save the current peer information before updating it */",
                "\told_daddr = sk->sk_v6_daddr;",
                "\told_fl6_flowlabel = np->flow_label;",
                "\told_dport = inet->inet_dport;",
                "",
                "\t\t/* Restore the socket peer info, to keep it consistent with",
                "\t\t * the old socket state",
                "\t\tsk->sk_v6_daddr = old_daddr;",
                "\t\tnp->flow_label = old_fl6_flowlabel;",
                "\t\tinet->inet_dport = old_dport;"
            ],
            "deleted": [
                "\tstruct in6_addr\t\t*daddr;",
                "\t__be32\t\t\tfl6_flowlabel = 0;",
                "",
                "\t\t/* Reset daddr and dport so that udp_v6_early_demux()",
                "\t\t * fails to find this socket",
                "\t\tmemset(&sk->sk_v6_daddr, 0, sizeof(sk->sk_v6_daddr));",
                "\t\tinet->inet_dport = 0;"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In ip6_xmit of ip6_output.c, there is a possible out of bounds write due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-168607263References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2021-22555",
        "code_before_change": "static int translate_compat_table(struct net *net,\n\t\t\t\t  struct xt_table_info **pinfo,\n\t\t\t\t  void **pentry0,\n\t\t\t\t  const struct compat_arpt_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_arpt_entry *iter0;\n\tstruct arpt_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(NFPROTO_ARP);\n\tret = xt_compat_init_offsets(NFPROTO_ARP, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone */\n\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "code_after_change": "static int translate_compat_table(struct net *net,\n\t\t\t\t  struct xt_table_info **pinfo,\n\t\t\t\t  void **pentry0,\n\t\t\t\t  const struct compat_arpt_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_arpt_entry *iter0;\n\tstruct arpt_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(NFPROTO_ARP);\n\tret = xt_compat_init_offsets(NFPROTO_ARP, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tmemset(newinfo->entries, 0, size);\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone */\n\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,6 +39,8 @@\n \tnewinfo = xt_alloc_table_info(size);\n \tif (!newinfo)\n \t\tgoto out_unlock;\n+\n+\tmemset(newinfo->entries, 0, size);\n \n \tnewinfo->number = compatr->num_entries;\n \tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tmemset(newinfo->entries, 0, size);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write affecting Linux since v2.6.19-rc1 was discovered in net/netfilter/x_tables.c. This allows an attacker to gain privileges or cause a DoS (via heap memory corruption) through user name space"
    },
    {
        "cve_id": "CVE-2021-22555",
        "code_before_change": "static int\ntranslate_compat_table(struct net *net,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       const struct compat_ipt_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ipt_entry *iter0;\n\tstruct ipt_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(AF_INET);\n\tret = xt_compat_init_offsets(AF_INET, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone.\n\t * entry1/newinfo contains a 64bit ruleset that looks exactly as\n\t * generated by 64bit userspace.\n\t *\n\t * Call standard translate_table() to validate all hook_entrys,\n\t * underflows, check for loops, etc.\n\t */\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "code_after_change": "static int\ntranslate_compat_table(struct net *net,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       const struct compat_ipt_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ipt_entry *iter0;\n\tstruct ipt_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(AF_INET);\n\tret = xt_compat_init_offsets(AF_INET, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tmemset(newinfo->entries, 0, size);\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone.\n\t * entry1/newinfo contains a 64bit ruleset that looks exactly as\n\t * generated by 64bit userspace.\n\t *\n\t * Call standard translate_table() to validate all hook_entrys,\n\t * underflows, check for loops, etc.\n\t */\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -40,6 +40,8 @@\n \tnewinfo = xt_alloc_table_info(size);\n \tif (!newinfo)\n \t\tgoto out_unlock;\n+\n+\tmemset(newinfo->entries, 0, size);\n \n \tnewinfo->number = compatr->num_entries;\n \tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tmemset(newinfo->entries, 0, size);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write affecting Linux since v2.6.19-rc1 was discovered in net/netfilter/x_tables.c. This allows an attacker to gain privileges or cause a DoS (via heap memory corruption) through user name space"
    },
    {
        "cve_id": "CVE-2021-22555",
        "code_before_change": "static int\ntranslate_compat_table(struct net *net,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       const struct compat_ip6t_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ip6t_entry *iter0;\n\tstruct ip6t_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(AF_INET6);\n\tret = xt_compat_init_offsets(AF_INET6, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone. */\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "code_after_change": "static int\ntranslate_compat_table(struct net *net,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       const struct compat_ip6t_replace *compatr)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ip6t_entry *iter0;\n\tstruct ip6t_replace repl;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = compatr->size;\n\tinfo->number = compatr->num_entries;\n\n\tj = 0;\n\txt_compat_lock(AF_INET6);\n\tret = xt_compat_init_offsets(AF_INET6, compatr->num_entries);\n\tif (ret)\n\t\tgoto out_unlock;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + compatr->size);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != compatr->num_entries)\n\t\tgoto out_unlock;\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tmemset(newinfo->entries, 0, size);\n\n\tnewinfo->number = compatr->num_entries;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = compatr->hook_entry[i];\n\t\tnewinfo->underflow[i] = compatr->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = compatr->size;\n\txt_entry_foreach(iter0, entry0, compatr->size)\n\t\tcompat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t    newinfo, entry1);\n\n\t/* all module references in entry0 are now gone. */\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\n\tmemcpy(&repl, compatr, sizeof(*compatr));\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\trepl.hook_entry[i] = newinfo->hook_entry[i];\n\t\trepl.underflow[i] = newinfo->underflow[i];\n\t}\n\n\trepl.num_counters = 0;\n\trepl.counters = NULL;\n\trepl.size = newinfo->size;\n\tret = translate_table(net, newinfo, entry1, &repl);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\txt_entry_foreach(iter0, entry0, compatr->size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -40,6 +40,8 @@\n \tnewinfo = xt_alloc_table_info(size);\n \tif (!newinfo)\n \t\tgoto out_unlock;\n+\n+\tmemset(newinfo->entries, 0, size);\n \n \tnewinfo->number = compatr->num_entries;\n \tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tmemset(newinfo->entries, 0, size);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write affecting Linux since v2.6.19-rc1 was discovered in net/netfilter/x_tables.c. This allows an attacker to gain privileges or cause a DoS (via heap memory corruption) through user name space"
    },
    {
        "cve_id": "CVE-2021-22555",
        "code_before_change": "void xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t       unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n\tint pad, off = xt_compat_match_offset(match);\n\tu_int16_t msize = cm->u.user.match_size;\n\tchar name[sizeof(m->u.user.name)];\n\n\tm = *dstptr;\n\tmemcpy(m, cm, sizeof(*cm));\n\tif (match->compat_from_user)\n\t\tmatch->compat_from_user(m->data, cm->data);\n\telse\n\t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n\tpad = XT_ALIGN(match->matchsize) - match->matchsize;\n\tif (pad > 0)\n\t\tmemset(m->data + match->matchsize, 0, pad);\n\n\tmsize += off;\n\tm->u.user.match_size = msize;\n\tstrlcpy(name, match->name, sizeof(name));\n\tmodule_put(match->me);\n\tstrncpy(m->u.user.name, name, sizeof(m->u.user.name));\n\n\t*size += off;\n\t*dstptr += msize;\n}",
        "code_after_change": "void xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t       unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n\tint off = xt_compat_match_offset(match);\n\tu_int16_t msize = cm->u.user.match_size;\n\tchar name[sizeof(m->u.user.name)];\n\n\tm = *dstptr;\n\tmemcpy(m, cm, sizeof(*cm));\n\tif (match->compat_from_user)\n\t\tmatch->compat_from_user(m->data, cm->data);\n\telse\n\t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n\n\tmsize += off;\n\tm->u.user.match_size = msize;\n\tstrlcpy(name, match->name, sizeof(name));\n\tmodule_put(match->me);\n\tstrncpy(m->u.user.name, name, sizeof(m->u.user.name));\n\n\t*size += off;\n\t*dstptr += msize;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n {\n \tconst struct xt_match *match = m->u.kernel.match;\n \tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n-\tint pad, off = xt_compat_match_offset(match);\n+\tint off = xt_compat_match_offset(match);\n \tu_int16_t msize = cm->u.user.match_size;\n \tchar name[sizeof(m->u.user.name)];\n \n@@ -13,9 +13,6 @@\n \t\tmatch->compat_from_user(m->data, cm->data);\n \telse\n \t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n-\tpad = XT_ALIGN(match->matchsize) - match->matchsize;\n-\tif (pad > 0)\n-\t\tmemset(m->data + match->matchsize, 0, pad);\n \n \tmsize += off;\n \tm->u.user.match_size = msize;",
        "function_modified_lines": {
            "added": [
                "\tint off = xt_compat_match_offset(match);"
            ],
            "deleted": [
                "\tint pad, off = xt_compat_match_offset(match);",
                "\tpad = XT_ALIGN(match->matchsize) - match->matchsize;",
                "\tif (pad > 0)",
                "\t\tmemset(m->data + match->matchsize, 0, pad);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write affecting Linux since v2.6.19-rc1 was discovered in net/netfilter/x_tables.c. This allows an attacker to gain privileges or cause a DoS (via heap memory corruption) through user name space"
    },
    {
        "cve_id": "CVE-2021-22555",
        "code_before_change": "void xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n\tint pad, off = xt_compat_target_offset(target);\n\tu_int16_t tsize = ct->u.user.target_size;\n\tchar name[sizeof(t->u.user.name)];\n\n\tt = *dstptr;\n\tmemcpy(t, ct, sizeof(*ct));\n\tif (target->compat_from_user)\n\t\ttarget->compat_from_user(t->data, ct->data);\n\telse\n\t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n\tpad = XT_ALIGN(target->targetsize) - target->targetsize;\n\tif (pad > 0)\n\t\tmemset(t->data + target->targetsize, 0, pad);\n\n\ttsize += off;\n\tt->u.user.target_size = tsize;\n\tstrlcpy(name, target->name, sizeof(name));\n\tmodule_put(target->me);\n\tstrncpy(t->u.user.name, name, sizeof(t->u.user.name));\n\n\t*size += off;\n\t*dstptr += tsize;\n}",
        "code_after_change": "void xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n\tint off = xt_compat_target_offset(target);\n\tu_int16_t tsize = ct->u.user.target_size;\n\tchar name[sizeof(t->u.user.name)];\n\n\tt = *dstptr;\n\tmemcpy(t, ct, sizeof(*ct));\n\tif (target->compat_from_user)\n\t\ttarget->compat_from_user(t->data, ct->data);\n\telse\n\t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n\n\ttsize += off;\n\tt->u.user.target_size = tsize;\n\tstrlcpy(name, target->name, sizeof(name));\n\tmodule_put(target->me);\n\tstrncpy(t->u.user.name, name, sizeof(t->u.user.name));\n\n\t*size += off;\n\t*dstptr += tsize;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n {\n \tconst struct xt_target *target = t->u.kernel.target;\n \tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n-\tint pad, off = xt_compat_target_offset(target);\n+\tint off = xt_compat_target_offset(target);\n \tu_int16_t tsize = ct->u.user.target_size;\n \tchar name[sizeof(t->u.user.name)];\n \n@@ -13,9 +13,6 @@\n \t\ttarget->compat_from_user(t->data, ct->data);\n \telse\n \t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n-\tpad = XT_ALIGN(target->targetsize) - target->targetsize;\n-\tif (pad > 0)\n-\t\tmemset(t->data + target->targetsize, 0, pad);\n \n \ttsize += off;\n \tt->u.user.target_size = tsize;",
        "function_modified_lines": {
            "added": [
                "\tint off = xt_compat_target_offset(target);"
            ],
            "deleted": [
                "\tint pad, off = xt_compat_target_offset(target);",
                "\tpad = XT_ALIGN(target->targetsize) - target->targetsize;",
                "\tif (pad > 0)",
                "\t\tmemset(t->data + target->targetsize, 0, pad);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write affecting Linux since v2.6.19-rc1 was discovered in net/netfilter/x_tables.c. This allows an attacker to gain privileges or cause a DoS (via heap memory corruption) through user name space"
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "int iscsi_conn_get_addr_param(struct sockaddr_storage *addr,\n\t\t\t      enum iscsi_param param, char *buf)\n{\n\tstruct sockaddr_in6 *sin6 = NULL;\n\tstruct sockaddr_in *sin = NULL;\n\tint len;\n\n\tswitch (addr->ss_family) {\n\tcase AF_INET:\n\t\tsin = (struct sockaddr_in *)addr;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tsin6 = (struct sockaddr_in6 *)addr;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (param) {\n\tcase ISCSI_PARAM_CONN_ADDRESS:\n\tcase ISCSI_HOST_PARAM_IPADDRESS:\n\t\tif (sin)\n\t\t\tlen = sprintf(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);\n\t\telse\n\t\t\tlen = sprintf(buf, \"%pI6\\n\", &sin6->sin6_addr);\n\t\tbreak;\n\tcase ISCSI_PARAM_CONN_PORT:\n\tcase ISCSI_PARAM_LOCAL_PORT:\n\t\tif (sin)\n\t\t\tlen = sprintf(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));\n\t\telse\n\t\t\tlen = sprintf(buf, \"%hu\\n\",\n\t\t\t\t      be16_to_cpu(sin6->sin6_port));\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn len;\n}",
        "code_after_change": "int iscsi_conn_get_addr_param(struct sockaddr_storage *addr,\n\t\t\t      enum iscsi_param param, char *buf)\n{\n\tstruct sockaddr_in6 *sin6 = NULL;\n\tstruct sockaddr_in *sin = NULL;\n\tint len;\n\n\tswitch (addr->ss_family) {\n\tcase AF_INET:\n\t\tsin = (struct sockaddr_in *)addr;\n\t\tbreak;\n\tcase AF_INET6:\n\t\tsin6 = (struct sockaddr_in6 *)addr;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (param) {\n\tcase ISCSI_PARAM_CONN_ADDRESS:\n\tcase ISCSI_HOST_PARAM_IPADDRESS:\n\t\tif (sin)\n\t\t\tlen = sysfs_emit(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);\n\t\telse\n\t\t\tlen = sysfs_emit(buf, \"%pI6\\n\", &sin6->sin6_addr);\n\t\tbreak;\n\tcase ISCSI_PARAM_CONN_PORT:\n\tcase ISCSI_PARAM_LOCAL_PORT:\n\t\tif (sin)\n\t\t\tlen = sysfs_emit(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));\n\t\telse\n\t\t\tlen = sysfs_emit(buf, \"%hu\\n\",\n\t\t\t\t      be16_to_cpu(sin6->sin6_port));\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,16 +20,16 @@\n \tcase ISCSI_PARAM_CONN_ADDRESS:\n \tcase ISCSI_HOST_PARAM_IPADDRESS:\n \t\tif (sin)\n-\t\t\tlen = sprintf(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);\n+\t\t\tlen = sysfs_emit(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);\n \t\telse\n-\t\t\tlen = sprintf(buf, \"%pI6\\n\", &sin6->sin6_addr);\n+\t\t\tlen = sysfs_emit(buf, \"%pI6\\n\", &sin6->sin6_addr);\n \t\tbreak;\n \tcase ISCSI_PARAM_CONN_PORT:\n \tcase ISCSI_PARAM_LOCAL_PORT:\n \t\tif (sin)\n-\t\t\tlen = sprintf(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));\n+\t\t\tlen = sysfs_emit(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));\n \t\telse\n-\t\t\tlen = sprintf(buf, \"%hu\\n\",\n+\t\t\tlen = sysfs_emit(buf, \"%hu\\n\",\n \t\t\t\t      be16_to_cpu(sin6->sin6_port));\n \t\tbreak;\n \tdefault:",
        "function_modified_lines": {
            "added": [
                "\t\t\tlen = sysfs_emit(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);",
                "\t\t\tlen = sysfs_emit(buf, \"%pI6\\n\", &sin6->sin6_addr);",
                "\t\t\tlen = sysfs_emit(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));",
                "\t\t\tlen = sysfs_emit(buf, \"%hu\\n\","
            ],
            "deleted": [
                "\t\t\tlen = sprintf(buf, \"%pI4\\n\", &sin->sin_addr.s_addr);",
                "\t\t\tlen = sprintf(buf, \"%pI6\\n\", &sin6->sin6_addr);",
                "\t\t\tlen = sprintf(buf, \"%hu\\n\", be16_to_cpu(sin->sin_port));",
                "\t\t\tlen = sprintf(buf, \"%hu\\n\","
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "int iscsi_conn_get_param(struct iscsi_cls_conn *cls_conn,\n\t\t\t enum iscsi_param param, char *buf)\n{\n\tstruct iscsi_conn *conn = cls_conn->dd_data;\n\tint len;\n\n\tswitch(param) {\n\tcase ISCSI_PARAM_PING_TMO:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->ping_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_RECV_TMO:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->recv_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_RECV_DLENGTH:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->max_recv_dlength);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_XMIT_DLENGTH:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->max_xmit_dlength);\n\t\tbreak;\n\tcase ISCSI_PARAM_HDRDGST_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", conn->hdrdgst_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DATADGST_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", conn->datadgst_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_IFMARKER_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", conn->ifmarker_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_OFMARKER_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", conn->ofmarker_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_EXP_STATSN:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->exp_statsn);\n\t\tbreak;\n\tcase ISCSI_PARAM_PERSISTENT_PORT:\n\t\tlen = sprintf(buf, \"%d\\n\", conn->persistent_port);\n\t\tbreak;\n\tcase ISCSI_PARAM_PERSISTENT_ADDRESS:\n\t\tlen = sprintf(buf, \"%s\\n\", conn->persistent_address);\n\t\tbreak;\n\tcase ISCSI_PARAM_STATSN:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->statsn);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_SEGMENT_SIZE:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->max_segment_size);\n\t\tbreak;\n\tcase ISCSI_PARAM_KEEPALIVE_TMO:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->keepalive_tmo);\n\t\tbreak;\n\tcase ISCSI_PARAM_LOCAL_PORT:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->local_port);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMESTAMP_STAT:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_stat);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_NAGLE_DISABLE:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_nagle_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_WSF_DISABLE:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_wsf_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMER_SCALE:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timer_scale);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMESTAMP_EN:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_IP_FRAGMENT_DISABLE:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->fragment_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV4_TOS:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv4_tos);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV6_TC:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_traffic_class);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV6_FLOW_LABEL:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_flow_label);\n\t\tbreak;\n\tcase ISCSI_PARAM_IS_FW_ASSIGNED_IPV6:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_XMIT_WSF:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_xmit_wsf);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_RECV_WSF:\n\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_recv_wsf);\n\t\tbreak;\n\tcase ISCSI_PARAM_LOCAL_IPADDR:\n\t\tlen = sprintf(buf, \"%s\\n\", conn->local_ipaddr);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "code_after_change": "int iscsi_conn_get_param(struct iscsi_cls_conn *cls_conn,\n\t\t\t enum iscsi_param param, char *buf)\n{\n\tstruct iscsi_conn *conn = cls_conn->dd_data;\n\tint len;\n\n\tswitch(param) {\n\tcase ISCSI_PARAM_PING_TMO:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ping_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_RECV_TMO:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->recv_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_RECV_DLENGTH:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_recv_dlength);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_XMIT_DLENGTH:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_xmit_dlength);\n\t\tbreak;\n\tcase ISCSI_PARAM_HDRDGST_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->hdrdgst_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DATADGST_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->datadgst_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_IFMARKER_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ifmarker_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_OFMARKER_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ofmarker_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_EXP_STATSN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->exp_statsn);\n\t\tbreak;\n\tcase ISCSI_PARAM_PERSISTENT_PORT:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->persistent_port);\n\t\tbreak;\n\tcase ISCSI_PARAM_PERSISTENT_ADDRESS:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->persistent_address);\n\t\tbreak;\n\tcase ISCSI_PARAM_STATSN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->statsn);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_SEGMENT_SIZE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_segment_size);\n\t\tbreak;\n\tcase ISCSI_PARAM_KEEPALIVE_TMO:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->keepalive_tmo);\n\t\tbreak;\n\tcase ISCSI_PARAM_LOCAL_PORT:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->local_port);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMESTAMP_STAT:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_stat);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_NAGLE_DISABLE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_nagle_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_WSF_DISABLE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_wsf_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMER_SCALE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timer_scale);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_TIMESTAMP_EN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_IP_FRAGMENT_DISABLE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->fragment_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV4_TOS:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv4_tos);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV6_TC:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_traffic_class);\n\t\tbreak;\n\tcase ISCSI_PARAM_IPV6_FLOW_LABEL:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_flow_label);\n\t\tbreak;\n\tcase ISCSI_PARAM_IS_FW_ASSIGNED_IPV6:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_XMIT_WSF:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_xmit_wsf);\n\t\tbreak;\n\tcase ISCSI_PARAM_TCP_RECV_WSF:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_recv_wsf);\n\t\tbreak;\n\tcase ISCSI_PARAM_LOCAL_IPADDR:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->local_ipaddr);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,88 +6,88 @@\n \n \tswitch(param) {\n \tcase ISCSI_PARAM_PING_TMO:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->ping_timeout);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ping_timeout);\n \t\tbreak;\n \tcase ISCSI_PARAM_RECV_TMO:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->recv_timeout);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->recv_timeout);\n \t\tbreak;\n \tcase ISCSI_PARAM_MAX_RECV_DLENGTH:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->max_recv_dlength);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_recv_dlength);\n \t\tbreak;\n \tcase ISCSI_PARAM_MAX_XMIT_DLENGTH:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->max_xmit_dlength);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_xmit_dlength);\n \t\tbreak;\n \tcase ISCSI_PARAM_HDRDGST_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", conn->hdrdgst_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->hdrdgst_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_DATADGST_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", conn->datadgst_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->datadgst_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_IFMARKER_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", conn->ifmarker_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ifmarker_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_OFMARKER_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", conn->ofmarker_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ofmarker_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_EXP_STATSN:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->exp_statsn);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->exp_statsn);\n \t\tbreak;\n \tcase ISCSI_PARAM_PERSISTENT_PORT:\n-\t\tlen = sprintf(buf, \"%d\\n\", conn->persistent_port);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->persistent_port);\n \t\tbreak;\n \tcase ISCSI_PARAM_PERSISTENT_ADDRESS:\n-\t\tlen = sprintf(buf, \"%s\\n\", conn->persistent_address);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->persistent_address);\n \t\tbreak;\n \tcase ISCSI_PARAM_STATSN:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->statsn);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->statsn);\n \t\tbreak;\n \tcase ISCSI_PARAM_MAX_SEGMENT_SIZE:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->max_segment_size);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_segment_size);\n \t\tbreak;\n \tcase ISCSI_PARAM_KEEPALIVE_TMO:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->keepalive_tmo);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->keepalive_tmo);\n \t\tbreak;\n \tcase ISCSI_PARAM_LOCAL_PORT:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->local_port);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->local_port);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_TIMESTAMP_STAT:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_stat);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_stat);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_NAGLE_DISABLE:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_nagle_disable);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_nagle_disable);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_WSF_DISABLE:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_wsf_disable);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_wsf_disable);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_TIMER_SCALE:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timer_scale);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timer_scale);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_TIMESTAMP_EN:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_en);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_IP_FRAGMENT_DISABLE:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->fragment_disable);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->fragment_disable);\n \t\tbreak;\n \tcase ISCSI_PARAM_IPV4_TOS:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv4_tos);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv4_tos);\n \t\tbreak;\n \tcase ISCSI_PARAM_IPV6_TC:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_traffic_class);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_traffic_class);\n \t\tbreak;\n \tcase ISCSI_PARAM_IPV6_FLOW_LABEL:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_flow_label);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_flow_label);\n \t\tbreak;\n \tcase ISCSI_PARAM_IS_FW_ASSIGNED_IPV6:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_XMIT_WSF:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_xmit_wsf);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_xmit_wsf);\n \t\tbreak;\n \tcase ISCSI_PARAM_TCP_RECV_WSF:\n-\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_recv_wsf);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_recv_wsf);\n \t\tbreak;\n \tcase ISCSI_PARAM_LOCAL_IPADDR:\n-\t\tlen = sprintf(buf, \"%s\\n\", conn->local_ipaddr);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->local_ipaddr);\n \t\tbreak;\n \tdefault:\n \t\treturn -ENOSYS;",
        "function_modified_lines": {
            "added": [
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ping_timeout);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->recv_timeout);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_recv_dlength);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_xmit_dlength);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->hdrdgst_en);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->datadgst_en);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ifmarker_en);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->ofmarker_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->exp_statsn);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", conn->persistent_port);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->persistent_address);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->statsn);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->max_segment_size);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->keepalive_tmo);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->local_port);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_stat);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_nagle_disable);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_wsf_disable);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timer_scale);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_timestamp_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->fragment_disable);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv4_tos);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_traffic_class);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->ipv6_flow_label);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_xmit_wsf);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", conn->tcp_recv_wsf);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", conn->local_ipaddr);"
            ],
            "deleted": [
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->ping_timeout);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->recv_timeout);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->max_recv_dlength);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->max_xmit_dlength);",
                "\t\tlen = sprintf(buf, \"%d\\n\", conn->hdrdgst_en);",
                "\t\tlen = sprintf(buf, \"%d\\n\", conn->datadgst_en);",
                "\t\tlen = sprintf(buf, \"%d\\n\", conn->ifmarker_en);",
                "\t\tlen = sprintf(buf, \"%d\\n\", conn->ofmarker_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->exp_statsn);",
                "\t\tlen = sprintf(buf, \"%d\\n\", conn->persistent_port);",
                "\t\tlen = sprintf(buf, \"%s\\n\", conn->persistent_address);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->statsn);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->max_segment_size);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->keepalive_tmo);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->local_port);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_stat);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_nagle_disable);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_wsf_disable);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timer_scale);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_timestamp_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->fragment_disable);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv4_tos);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_traffic_class);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->ipv6_flow_label);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->is_fw_assigned_ipv6);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_xmit_wsf);",
                "\t\tlen = sprintf(buf, \"%u\\n\", conn->tcp_recv_wsf);",
                "\t\tlen = sprintf(buf, \"%s\\n\", conn->local_ipaddr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "int iscsi_session_get_param(struct iscsi_cls_session *cls_session,\n\t\t\t    enum iscsi_param param, char *buf)\n{\n\tstruct iscsi_session *session = cls_session->dd_data;\n\tint len;\n\n\tswitch(param) {\n\tcase ISCSI_PARAM_FAST_ABORT:\n\t\tlen = sprintf(buf, \"%d\\n\", session->fast_abort);\n\t\tbreak;\n\tcase ISCSI_PARAM_ABORT_TMO:\n\t\tlen = sprintf(buf, \"%d\\n\", session->abort_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_LU_RESET_TMO:\n\t\tlen = sprintf(buf, \"%d\\n\", session->lu_reset_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_TGT_RESET_TMO:\n\t\tlen = sprintf(buf, \"%d\\n\", session->tgt_reset_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_INITIAL_R2T_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", session->initial_r2t_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_R2T:\n\t\tlen = sprintf(buf, \"%hu\\n\", session->max_r2t);\n\t\tbreak;\n\tcase ISCSI_PARAM_IMM_DATA_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", session->imm_data_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_FIRST_BURST:\n\t\tlen = sprintf(buf, \"%u\\n\", session->first_burst);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_BURST:\n\t\tlen = sprintf(buf, \"%u\\n\", session->max_burst);\n\t\tbreak;\n\tcase ISCSI_PARAM_PDU_INORDER_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", session->pdu_inorder_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DATASEQ_INORDER_EN:\n\t\tlen = sprintf(buf, \"%d\\n\", session->dataseq_inorder_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TASKMGMT_TMO:\n\t\tlen = sprintf(buf, \"%d\\n\", session->def_taskmgmt_tmo);\n\t\tbreak;\n\tcase ISCSI_PARAM_ERL:\n\t\tlen = sprintf(buf, \"%d\\n\", session->erl);\n\t\tbreak;\n\tcase ISCSI_PARAM_TARGET_NAME:\n\t\tlen = sprintf(buf, \"%s\\n\", session->targetname);\n\t\tbreak;\n\tcase ISCSI_PARAM_TARGET_ALIAS:\n\t\tlen = sprintf(buf, \"%s\\n\", session->targetalias);\n\t\tbreak;\n\tcase ISCSI_PARAM_TPGT:\n\t\tlen = sprintf(buf, \"%d\\n\", session->tpgt);\n\t\tbreak;\n\tcase ISCSI_PARAM_USERNAME:\n\t\tlen = sprintf(buf, \"%s\\n\", session->username);\n\t\tbreak;\n\tcase ISCSI_PARAM_USERNAME_IN:\n\t\tlen = sprintf(buf, \"%s\\n\", session->username_in);\n\t\tbreak;\n\tcase ISCSI_PARAM_PASSWORD:\n\t\tlen = sprintf(buf, \"%s\\n\", session->password);\n\t\tbreak;\n\tcase ISCSI_PARAM_PASSWORD_IN:\n\t\tlen = sprintf(buf, \"%s\\n\", session->password_in);\n\t\tbreak;\n\tcase ISCSI_PARAM_IFACE_NAME:\n\t\tlen = sprintf(buf, \"%s\\n\", session->ifacename);\n\t\tbreak;\n\tcase ISCSI_PARAM_INITIATOR_NAME:\n\t\tlen = sprintf(buf, \"%s\\n\", session->initiatorname);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_ROOT:\n\t\tlen = sprintf(buf, \"%s\\n\", session->boot_root);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_NIC:\n\t\tlen = sprintf(buf, \"%s\\n\", session->boot_nic);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_TARGET:\n\t\tlen = sprintf(buf, \"%s\\n\", session->boot_target);\n\t\tbreak;\n\tcase ISCSI_PARAM_AUTO_SND_TGT_DISABLE:\n\t\tlen = sprintf(buf, \"%u\\n\", session->auto_snd_tgt_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_SESS:\n\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_sess);\n\t\tbreak;\n\tcase ISCSI_PARAM_PORTAL_TYPE:\n\t\tlen = sprintf(buf, \"%s\\n\", session->portal_type);\n\t\tbreak;\n\tcase ISCSI_PARAM_CHAP_AUTH_EN:\n\t\tlen = sprintf(buf, \"%u\\n\", session->chap_auth_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_LOGOUT_EN:\n\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_logout_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_BIDI_CHAP_EN:\n\t\tlen = sprintf(buf, \"%u\\n\", session->bidi_chap_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_AUTH_OPTIONAL:\n\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_auth_optional);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TIME2WAIT:\n\t\tlen = sprintf(buf, \"%d\\n\", session->time2wait);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TIME2RETAIN:\n\t\tlen = sprintf(buf, \"%d\\n\", session->time2retain);\n\t\tbreak;\n\tcase ISCSI_PARAM_TSID:\n\t\tlen = sprintf(buf, \"%u\\n\", session->tsid);\n\t\tbreak;\n\tcase ISCSI_PARAM_ISID:\n\t\tlen = sprintf(buf, \"%02x%02x%02x%02x%02x%02x\\n\",\n\t\t\t      session->isid[0], session->isid[1],\n\t\t\t      session->isid[2], session->isid[3],\n\t\t\t      session->isid[4], session->isid[5]);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_PARENT_IDX:\n\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_parent_idx);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_PARENT_TYPE:\n\t\tif (session->discovery_parent_type)\n\t\t\tlen = sprintf(buf, \"%s\\n\",\n\t\t\t\t      session->discovery_parent_type);\n\t\telse\n\t\t\tlen = sprintf(buf, \"\\n\");\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "code_after_change": "int iscsi_session_get_param(struct iscsi_cls_session *cls_session,\n\t\t\t    enum iscsi_param param, char *buf)\n{\n\tstruct iscsi_session *session = cls_session->dd_data;\n\tint len;\n\n\tswitch(param) {\n\tcase ISCSI_PARAM_FAST_ABORT:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->fast_abort);\n\t\tbreak;\n\tcase ISCSI_PARAM_ABORT_TMO:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->abort_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_LU_RESET_TMO:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->lu_reset_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_TGT_RESET_TMO:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tgt_reset_timeout);\n\t\tbreak;\n\tcase ISCSI_PARAM_INITIAL_R2T_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->initial_r2t_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_R2T:\n\t\tlen = sysfs_emit(buf, \"%hu\\n\", session->max_r2t);\n\t\tbreak;\n\tcase ISCSI_PARAM_IMM_DATA_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->imm_data_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_FIRST_BURST:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->first_burst);\n\t\tbreak;\n\tcase ISCSI_PARAM_MAX_BURST:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->max_burst);\n\t\tbreak;\n\tcase ISCSI_PARAM_PDU_INORDER_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->pdu_inorder_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DATASEQ_INORDER_EN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->dataseq_inorder_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TASKMGMT_TMO:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->def_taskmgmt_tmo);\n\t\tbreak;\n\tcase ISCSI_PARAM_ERL:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->erl);\n\t\tbreak;\n\tcase ISCSI_PARAM_TARGET_NAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetname);\n\t\tbreak;\n\tcase ISCSI_PARAM_TARGET_ALIAS:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetalias);\n\t\tbreak;\n\tcase ISCSI_PARAM_TPGT:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tpgt);\n\t\tbreak;\n\tcase ISCSI_PARAM_USERNAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username);\n\t\tbreak;\n\tcase ISCSI_PARAM_USERNAME_IN:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username_in);\n\t\tbreak;\n\tcase ISCSI_PARAM_PASSWORD:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password);\n\t\tbreak;\n\tcase ISCSI_PARAM_PASSWORD_IN:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password_in);\n\t\tbreak;\n\tcase ISCSI_PARAM_IFACE_NAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->ifacename);\n\t\tbreak;\n\tcase ISCSI_PARAM_INITIATOR_NAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->initiatorname);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_ROOT:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_root);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_NIC:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_nic);\n\t\tbreak;\n\tcase ISCSI_PARAM_BOOT_TARGET:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_target);\n\t\tbreak;\n\tcase ISCSI_PARAM_AUTO_SND_TGT_DISABLE:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->auto_snd_tgt_disable);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_SESS:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_sess);\n\t\tbreak;\n\tcase ISCSI_PARAM_PORTAL_TYPE:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", session->portal_type);\n\t\tbreak;\n\tcase ISCSI_PARAM_CHAP_AUTH_EN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->chap_auth_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_LOGOUT_EN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_logout_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_BIDI_CHAP_EN:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->bidi_chap_en);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_AUTH_OPTIONAL:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_auth_optional);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TIME2WAIT:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2wait);\n\t\tbreak;\n\tcase ISCSI_PARAM_DEF_TIME2RETAIN:\n\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2retain);\n\t\tbreak;\n\tcase ISCSI_PARAM_TSID:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->tsid);\n\t\tbreak;\n\tcase ISCSI_PARAM_ISID:\n\t\tlen = sysfs_emit(buf, \"%02x%02x%02x%02x%02x%02x\\n\",\n\t\t\t      session->isid[0], session->isid[1],\n\t\t\t      session->isid[2], session->isid[3],\n\t\t\t      session->isid[4], session->isid[5]);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_PARENT_IDX:\n\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_parent_idx);\n\t\tbreak;\n\tcase ISCSI_PARAM_DISCOVERY_PARENT_TYPE:\n\t\tif (session->discovery_parent_type)\n\t\t\tlen = sysfs_emit(buf, \"%s\\n\",\n\t\t\t\t      session->discovery_parent_type);\n\t\telse\n\t\t\tlen = sysfs_emit(buf, \"\\n\");\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,125 +6,125 @@\n \n \tswitch(param) {\n \tcase ISCSI_PARAM_FAST_ABORT:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->fast_abort);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->fast_abort);\n \t\tbreak;\n \tcase ISCSI_PARAM_ABORT_TMO:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->abort_timeout);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->abort_timeout);\n \t\tbreak;\n \tcase ISCSI_PARAM_LU_RESET_TMO:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->lu_reset_timeout);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->lu_reset_timeout);\n \t\tbreak;\n \tcase ISCSI_PARAM_TGT_RESET_TMO:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->tgt_reset_timeout);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tgt_reset_timeout);\n \t\tbreak;\n \tcase ISCSI_PARAM_INITIAL_R2T_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->initial_r2t_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->initial_r2t_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_MAX_R2T:\n-\t\tlen = sprintf(buf, \"%hu\\n\", session->max_r2t);\n+\t\tlen = sysfs_emit(buf, \"%hu\\n\", session->max_r2t);\n \t\tbreak;\n \tcase ISCSI_PARAM_IMM_DATA_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->imm_data_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->imm_data_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_FIRST_BURST:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->first_burst);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->first_burst);\n \t\tbreak;\n \tcase ISCSI_PARAM_MAX_BURST:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->max_burst);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->max_burst);\n \t\tbreak;\n \tcase ISCSI_PARAM_PDU_INORDER_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->pdu_inorder_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->pdu_inorder_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_DATASEQ_INORDER_EN:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->dataseq_inorder_en);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->dataseq_inorder_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_DEF_TASKMGMT_TMO:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->def_taskmgmt_tmo);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->def_taskmgmt_tmo);\n \t\tbreak;\n \tcase ISCSI_PARAM_ERL:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->erl);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->erl);\n \t\tbreak;\n \tcase ISCSI_PARAM_TARGET_NAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->targetname);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetname);\n \t\tbreak;\n \tcase ISCSI_PARAM_TARGET_ALIAS:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->targetalias);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetalias);\n \t\tbreak;\n \tcase ISCSI_PARAM_TPGT:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->tpgt);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tpgt);\n \t\tbreak;\n \tcase ISCSI_PARAM_USERNAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->username);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username);\n \t\tbreak;\n \tcase ISCSI_PARAM_USERNAME_IN:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->username_in);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username_in);\n \t\tbreak;\n \tcase ISCSI_PARAM_PASSWORD:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->password);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password);\n \t\tbreak;\n \tcase ISCSI_PARAM_PASSWORD_IN:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->password_in);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password_in);\n \t\tbreak;\n \tcase ISCSI_PARAM_IFACE_NAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->ifacename);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->ifacename);\n \t\tbreak;\n \tcase ISCSI_PARAM_INITIATOR_NAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->initiatorname);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->initiatorname);\n \t\tbreak;\n \tcase ISCSI_PARAM_BOOT_ROOT:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->boot_root);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_root);\n \t\tbreak;\n \tcase ISCSI_PARAM_BOOT_NIC:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->boot_nic);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_nic);\n \t\tbreak;\n \tcase ISCSI_PARAM_BOOT_TARGET:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->boot_target);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_target);\n \t\tbreak;\n \tcase ISCSI_PARAM_AUTO_SND_TGT_DISABLE:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->auto_snd_tgt_disable);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->auto_snd_tgt_disable);\n \t\tbreak;\n \tcase ISCSI_PARAM_DISCOVERY_SESS:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_sess);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_sess);\n \t\tbreak;\n \tcase ISCSI_PARAM_PORTAL_TYPE:\n-\t\tlen = sprintf(buf, \"%s\\n\", session->portal_type);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", session->portal_type);\n \t\tbreak;\n \tcase ISCSI_PARAM_CHAP_AUTH_EN:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->chap_auth_en);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->chap_auth_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_DISCOVERY_LOGOUT_EN:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_logout_en);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_logout_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_BIDI_CHAP_EN:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->bidi_chap_en);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->bidi_chap_en);\n \t\tbreak;\n \tcase ISCSI_PARAM_DISCOVERY_AUTH_OPTIONAL:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_auth_optional);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_auth_optional);\n \t\tbreak;\n \tcase ISCSI_PARAM_DEF_TIME2WAIT:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->time2wait);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2wait);\n \t\tbreak;\n \tcase ISCSI_PARAM_DEF_TIME2RETAIN:\n-\t\tlen = sprintf(buf, \"%d\\n\", session->time2retain);\n+\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2retain);\n \t\tbreak;\n \tcase ISCSI_PARAM_TSID:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->tsid);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->tsid);\n \t\tbreak;\n \tcase ISCSI_PARAM_ISID:\n-\t\tlen = sprintf(buf, \"%02x%02x%02x%02x%02x%02x\\n\",\n+\t\tlen = sysfs_emit(buf, \"%02x%02x%02x%02x%02x%02x\\n\",\n \t\t\t      session->isid[0], session->isid[1],\n \t\t\t      session->isid[2], session->isid[3],\n \t\t\t      session->isid[4], session->isid[5]);\n \t\tbreak;\n \tcase ISCSI_PARAM_DISCOVERY_PARENT_IDX:\n-\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_parent_idx);\n+\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_parent_idx);\n \t\tbreak;\n \tcase ISCSI_PARAM_DISCOVERY_PARENT_TYPE:\n \t\tif (session->discovery_parent_type)\n-\t\t\tlen = sprintf(buf, \"%s\\n\",\n+\t\t\tlen = sysfs_emit(buf, \"%s\\n\",\n \t\t\t\t      session->discovery_parent_type);\n \t\telse\n-\t\t\tlen = sprintf(buf, \"\\n\");\n+\t\t\tlen = sysfs_emit(buf, \"\\n\");\n \t\tbreak;\n \tdefault:\n \t\treturn -ENOSYS;",
        "function_modified_lines": {
            "added": [
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->fast_abort);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->abort_timeout);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->lu_reset_timeout);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tgt_reset_timeout);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->initial_r2t_en);",
                "\t\tlen = sysfs_emit(buf, \"%hu\\n\", session->max_r2t);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->imm_data_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->first_burst);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->max_burst);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->pdu_inorder_en);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->dataseq_inorder_en);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->def_taskmgmt_tmo);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->erl);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetname);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->targetalias);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->tpgt);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->username_in);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->password_in);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->ifacename);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->initiatorname);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_root);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_nic);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->boot_target);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->auto_snd_tgt_disable);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_sess);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", session->portal_type);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->chap_auth_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_logout_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->bidi_chap_en);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_auth_optional);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2wait);",
                "\t\tlen = sysfs_emit(buf, \"%d\\n\", session->time2retain);",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->tsid);",
                "\t\tlen = sysfs_emit(buf, \"%02x%02x%02x%02x%02x%02x\\n\",",
                "\t\tlen = sysfs_emit(buf, \"%u\\n\", session->discovery_parent_idx);",
                "\t\t\tlen = sysfs_emit(buf, \"%s\\n\",",
                "\t\t\tlen = sysfs_emit(buf, \"\\n\");"
            ],
            "deleted": [
                "\t\tlen = sprintf(buf, \"%d\\n\", session->fast_abort);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->abort_timeout);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->lu_reset_timeout);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->tgt_reset_timeout);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->initial_r2t_en);",
                "\t\tlen = sprintf(buf, \"%hu\\n\", session->max_r2t);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->imm_data_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->first_burst);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->max_burst);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->pdu_inorder_en);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->dataseq_inorder_en);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->def_taskmgmt_tmo);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->erl);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->targetname);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->targetalias);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->tpgt);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->username);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->username_in);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->password);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->password_in);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->ifacename);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->initiatorname);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->boot_root);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->boot_nic);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->boot_target);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->auto_snd_tgt_disable);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_sess);",
                "\t\tlen = sprintf(buf, \"%s\\n\", session->portal_type);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->chap_auth_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_logout_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->bidi_chap_en);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_auth_optional);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->time2wait);",
                "\t\tlen = sprintf(buf, \"%d\\n\", session->time2retain);",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->tsid);",
                "\t\tlen = sprintf(buf, \"%02x%02x%02x%02x%02x%02x\\n\",",
                "\t\tlen = sprintf(buf, \"%u\\n\", session->discovery_parent_idx);",
                "\t\t\tlen = sprintf(buf, \"%s\\n\",",
                "\t\t\tlen = sprintf(buf, \"\\n\");"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "int iscsi_host_get_param(struct Scsi_Host *shost, enum iscsi_host_param param,\n\t\t\t char *buf)\n{\n\tstruct iscsi_host *ihost = shost_priv(shost);\n\tint len;\n\n\tswitch (param) {\n\tcase ISCSI_HOST_PARAM_NETDEV_NAME:\n\t\tlen = sprintf(buf, \"%s\\n\", ihost->netdev);\n\t\tbreak;\n\tcase ISCSI_HOST_PARAM_HWADDRESS:\n\t\tlen = sprintf(buf, \"%s\\n\", ihost->hwaddress);\n\t\tbreak;\n\tcase ISCSI_HOST_PARAM_INITIATOR_NAME:\n\t\tlen = sprintf(buf, \"%s\\n\", ihost->initiatorname);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "code_after_change": "int iscsi_host_get_param(struct Scsi_Host *shost, enum iscsi_host_param param,\n\t\t\t char *buf)\n{\n\tstruct iscsi_host *ihost = shost_priv(shost);\n\tint len;\n\n\tswitch (param) {\n\tcase ISCSI_HOST_PARAM_NETDEV_NAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->netdev);\n\t\tbreak;\n\tcase ISCSI_HOST_PARAM_HWADDRESS:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->hwaddress);\n\t\tbreak;\n\tcase ISCSI_HOST_PARAM_INITIATOR_NAME:\n\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->initiatorname);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n\n\treturn len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,13 +6,13 @@\n \n \tswitch (param) {\n \tcase ISCSI_HOST_PARAM_NETDEV_NAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", ihost->netdev);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->netdev);\n \t\tbreak;\n \tcase ISCSI_HOST_PARAM_HWADDRESS:\n-\t\tlen = sprintf(buf, \"%s\\n\", ihost->hwaddress);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->hwaddress);\n \t\tbreak;\n \tcase ISCSI_HOST_PARAM_INITIATOR_NAME:\n-\t\tlen = sprintf(buf, \"%s\\n\", ihost->initiatorname);\n+\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->initiatorname);\n \t\tbreak;\n \tdefault:\n \t\treturn -ENOSYS;",
        "function_modified_lines": {
            "added": [
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->netdev);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->hwaddress);",
                "\t\tlen = sysfs_emit(buf, \"%s\\n\", ihost->initiatorname);"
            ],
            "deleted": [
                "\t\tlen = sprintf(buf, \"%s\\n\", ihost->netdev);",
                "\t\tlen = sprintf(buf, \"%s\\n\", ihost->hwaddress);",
                "\t\tlen = sprintf(buf, \"%s\\n\", ihost->initiatorname);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "static int\niscsi_set_param(struct iscsi_transport *transport, struct iscsi_uevent *ev)\n{\n\tchar *data = (char*)ev + sizeof(*ev);\n\tstruct iscsi_cls_conn *conn;\n\tstruct iscsi_cls_session *session;\n\tint err = 0, value = 0;\n\n\tsession = iscsi_session_lookup(ev->u.set_param.sid);\n\tconn = iscsi_conn_lookup(ev->u.set_param.sid, ev->u.set_param.cid);\n\tif (!conn || !session)\n\t\treturn -EINVAL;\n\n\tswitch (ev->u.set_param.param) {\n\tcase ISCSI_PARAM_SESS_RECOVERY_TMO:\n\t\tsscanf(data, \"%d\", &value);\n\t\tif (!session->recovery_tmo_sysfs_override)\n\t\t\tsession->recovery_tmo = value;\n\t\tbreak;\n\tdefault:\n\t\terr = transport->set_param(conn, ev->u.set_param.param,\n\t\t\t\t\t   data, ev->u.set_param.len);\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int\niscsi_set_param(struct iscsi_transport *transport, struct iscsi_uevent *ev)\n{\n\tchar *data = (char*)ev + sizeof(*ev);\n\tstruct iscsi_cls_conn *conn;\n\tstruct iscsi_cls_session *session;\n\tint err = 0, value = 0;\n\n\tif (ev->u.set_param.len > PAGE_SIZE)\n\t\treturn -EINVAL;\n\n\tsession = iscsi_session_lookup(ev->u.set_param.sid);\n\tconn = iscsi_conn_lookup(ev->u.set_param.sid, ev->u.set_param.cid);\n\tif (!conn || !session)\n\t\treturn -EINVAL;\n\n\tswitch (ev->u.set_param.param) {\n\tcase ISCSI_PARAM_SESS_RECOVERY_TMO:\n\t\tsscanf(data, \"%d\", &value);\n\t\tif (!session->recovery_tmo_sysfs_override)\n\t\t\tsession->recovery_tmo = value;\n\t\tbreak;\n\tdefault:\n\t\terr = transport->set_param(conn, ev->u.set_param.param,\n\t\t\t\t\t   data, ev->u.set_param.len);\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tstruct iscsi_cls_conn *conn;\n \tstruct iscsi_cls_session *session;\n \tint err = 0, value = 0;\n+\n+\tif (ev->u.set_param.len > PAGE_SIZE)\n+\t\treturn -EINVAL;\n \n \tsession = iscsi_session_lookup(ev->u.set_param.sid);\n \tconn = iscsi_conn_lookup(ev->u.set_param.sid, ev->u.set_param.cid);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (ev->u.set_param.len > PAGE_SIZE)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "static int\niscsi_set_host_param(struct iscsi_transport *transport,\n\t\t     struct iscsi_uevent *ev)\n{\n\tchar *data = (char*)ev + sizeof(*ev);\n\tstruct Scsi_Host *shost;\n\tint err;\n\n\tif (!transport->set_host_param)\n\t\treturn -ENOSYS;\n\n\tshost = scsi_host_lookup(ev->u.set_host_param.host_no);\n\tif (!shost) {\n\t\tprintk(KERN_ERR \"set_host_param could not find host no %u\\n\",\n\t\t       ev->u.set_host_param.host_no);\n\t\treturn -ENODEV;\n\t}\n\n\terr = transport->set_host_param(shost, ev->u.set_host_param.param,\n\t\t\t\t\tdata, ev->u.set_host_param.len);\n\tscsi_host_put(shost);\n\treturn err;\n}",
        "code_after_change": "static int\niscsi_set_host_param(struct iscsi_transport *transport,\n\t\t     struct iscsi_uevent *ev)\n{\n\tchar *data = (char*)ev + sizeof(*ev);\n\tstruct Scsi_Host *shost;\n\tint err;\n\n\tif (!transport->set_host_param)\n\t\treturn -ENOSYS;\n\n\tif (ev->u.set_host_param.len > PAGE_SIZE)\n\t\treturn -EINVAL;\n\n\tshost = scsi_host_lookup(ev->u.set_host_param.host_no);\n\tif (!shost) {\n\t\tprintk(KERN_ERR \"set_host_param could not find host no %u\\n\",\n\t\t       ev->u.set_host_param.host_no);\n\t\treturn -ENODEV;\n\t}\n\n\terr = transport->set_host_param(shost, ev->u.set_host_param.param,\n\t\t\t\t\tdata, ev->u.set_host_param.len);\n\tscsi_host_put(shost);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,9 @@\n \n \tif (!transport->set_host_param)\n \t\treturn -ENOSYS;\n+\n+\tif (ev->u.set_host_param.len > PAGE_SIZE)\n+\t\treturn -EINVAL;\n \n \tshost = scsi_host_lookup(ev->u.set_host_param.host_no);\n \tif (!shost) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (ev->u.set_host_param.len > PAGE_SIZE)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "static ssize_t\nshow_transport_handle(struct device *dev, struct device_attribute *attr,\n\t\t      char *buf)\n{\n\tstruct iscsi_internal *priv = dev_to_iscsi_internal(dev);\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\treturn sprintf(buf, \"%llu\\n\", (unsigned long long)iscsi_handle(priv->iscsi_transport));\n}",
        "code_after_change": "static ssize_t\nshow_transport_handle(struct device *dev, struct device_attribute *attr,\n\t\t      char *buf)\n{\n\tstruct iscsi_internal *priv = dev_to_iscsi_internal(dev);\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\treturn sysfs_emit(buf, \"%llu\\n\",\n\t\t  (unsigned long long)iscsi_handle(priv->iscsi_transport));\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,5 +6,6 @@\n \n \tif (!capable(CAP_SYS_ADMIN))\n \t\treturn -EACCES;\n-\treturn sprintf(buf, \"%llu\\n\", (unsigned long long)iscsi_handle(priv->iscsi_transport));\n+\treturn sysfs_emit(buf, \"%llu\\n\",\n+\t\t  (unsigned long long)iscsi_handle(priv->iscsi_transport));\n }",
        "function_modified_lines": {
            "added": [
                "\treturn sysfs_emit(buf, \"%llu\\n\",",
                "\t\t  (unsigned long long)iscsi_handle(priv->iscsi_transport));"
            ],
            "deleted": [
                "\treturn sprintf(buf, \"%llu\\n\", (unsigned long long)iscsi_handle(priv->iscsi_transport));"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-27365",
        "code_before_change": "static ssize_t\nshow_ep_handle(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct iscsi_endpoint *ep = iscsi_dev_to_endpoint(dev);\n\treturn sprintf(buf, \"%llu\\n\", (unsigned long long) ep->id);\n}",
        "code_after_change": "static ssize_t\nshow_ep_handle(struct device *dev, struct device_attribute *attr, char *buf)\n{\n\tstruct iscsi_endpoint *ep = iscsi_dev_to_endpoint(dev);\n\treturn sysfs_emit(buf, \"%llu\\n\", (unsigned long long) ep->id);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,5 +2,5 @@\n show_ep_handle(struct device *dev, struct device_attribute *attr, char *buf)\n {\n \tstruct iscsi_endpoint *ep = iscsi_dev_to_endpoint(dev);\n-\treturn sprintf(buf, \"%llu\\n\", (unsigned long long) ep->id);\n+\treturn sysfs_emit(buf, \"%llu\\n\", (unsigned long long) ep->id);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn sysfs_emit(buf, \"%llu\\n\", (unsigned long long) ep->id);"
            ],
            "deleted": [
                "\treturn sprintf(buf, \"%llu\\n\", (unsigned long long) ep->id);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. Certain iSCSI data structures do not have appropriate length constraints or checks, and can exceed the PAGE_SIZE value. An unprivileged user can send a Netlink message that is associated with iSCSI, and has a length up to the maximum length of a Netlink message."
    },
    {
        "cve_id": "CVE-2021-28660",
        "code_before_change": "static int rtw_wx_set_scan(struct net_device *dev, struct iw_request_info *a,\n\t\t\t   union iwreq_data *wrqu, char *extra)\n{\n\tu8 _status = false;\n\tint ret = 0;\n\tstruct adapter *padapter = rtw_netdev_priv(dev);\n\tstruct mlme_priv *pmlmepriv = &padapter->mlmepriv;\n\tstruct ndis_802_11_ssid ssid[RTW_SSID_SCAN_AMOUNT];\n\n\tRT_TRACE(_module_rtl871x_mlme_c_, _drv_info_, (\"%s\\n\", __func__));\n\n\tif (!rtw_pwr_wakeup(padapter)) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (padapter->bDriverStopped) {\n\t\tDBG_88E(\"bDriverStopped =%d\\n\", padapter->bDriverStopped);\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (!padapter->bup) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (!padapter->hw_init_completed) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\t/*  When Busy Traffic, driver do not site survey. So driver return success. */\n\t/*  wpa_supplicant will not issue SIOCSIWSCAN cmd again after scan timeout. */\n\t/*  modify by thomas 2011-02-22. */\n\tif (pmlmepriv->LinkDetectInfo.bBusyTraffic) {\n\t\tindicate_wx_scan_complete_event(padapter);\n\t\tgoto exit;\n\t}\n\n\tif (check_fwstate(pmlmepriv, _FW_UNDER_SURVEY | _FW_UNDER_LINKING)) {\n\t\tindicate_wx_scan_complete_event(padapter);\n\t\tgoto exit;\n\t}\n\n/*\tFor the DMP WiFi Display project, the driver won't to scan because */\n/*\tthe pmlmepriv->scan_interval is always equal to 3. */\n/*\tSo, the wpa_supplicant won't find out the WPS SoftAP. */\n\n\tmemset(ssid, 0, sizeof(struct ndis_802_11_ssid) * RTW_SSID_SCAN_AMOUNT);\n\n\tif (wrqu->data.length == sizeof(struct iw_scan_req)) {\n\t\tstruct iw_scan_req *req = (struct iw_scan_req *)extra;\n\n\t\tif (wrqu->data.flags & IW_SCAN_THIS_ESSID) {\n\t\t\tint len = min_t(int, req->essid_len,\n\t\t\t\t\tIW_ESSID_MAX_SIZE);\n\n\t\t\tmemcpy(ssid[0].ssid, req->essid, len);\n\t\t\tssid[0].ssid_length = len;\n\n\t\t\tDBG_88E(\"IW_SCAN_THIS_ESSID, ssid =%s, len =%d\\n\", req->essid, req->essid_len);\n\n\t\t\tspin_lock_bh(&pmlmepriv->lock);\n\n\t\t\t_status = rtw_sitesurvey_cmd(padapter, ssid, 1, NULL, 0);\n\n\t\t\tspin_unlock_bh(&pmlmepriv->lock);\n\t\t} else if (req->scan_type == IW_SCAN_TYPE_PASSIVE) {\n\t\t\tDBG_88E(\"%s, req->scan_type == IW_SCAN_TYPE_PASSIVE\\n\", __func__);\n\t\t}\n\t} else {\n\t\tif (wrqu->data.length >= WEXT_CSCAN_HEADER_SIZE &&\n\t\t    !memcmp(extra, WEXT_CSCAN_HEADER, WEXT_CSCAN_HEADER_SIZE)) {\n\t\t\tint len = wrqu->data.length - WEXT_CSCAN_HEADER_SIZE;\n\t\t\tchar *pos = extra + WEXT_CSCAN_HEADER_SIZE;\n\t\t\tchar section;\n\t\t\tchar sec_len;\n\t\t\tint ssid_index = 0;\n\n\t\t\twhile (len >= 1) {\n\t\t\t\tsection = *(pos++);\n\t\t\t\tlen -= 1;\n\n\t\t\t\tswitch (section) {\n\t\t\t\tcase WEXT_CSCAN_SSID_SECTION:\n\t\t\t\t\tif (len < 1) {\n\t\t\t\t\t\tlen = 0;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tsec_len = *(pos++); len -= 1;\n\t\t\t\t\tif (sec_len > 0 && sec_len <= len) {\n\t\t\t\t\t\tssid[ssid_index].ssid_length = sec_len;\n\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, ssid[ssid_index].ssid_length);\n\t\t\t\t\t\tssid_index++;\n\t\t\t\t\t}\n\t\t\t\t\tpos += sec_len;\n\t\t\t\t\tlen -= sec_len;\n\t\t\t\t\tbreak;\n\t\t\t\tcase WEXT_CSCAN_TYPE_SECTION:\n\t\t\t\tcase WEXT_CSCAN_CHANNEL_SECTION:\n\t\t\t\t\tpos += 1;\n\t\t\t\t\tlen -= 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase WEXT_CSCAN_PASV_DWELL_SECTION:\n\t\t\t\tcase WEXT_CSCAN_HOME_DWELL_SECTION:\n\t\t\t\tcase WEXT_CSCAN_ACTV_DWELL_SECTION:\n\t\t\t\t\tpos += 2;\n\t\t\t\t\tlen -= 2;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tlen = 0; /*  stop parsing */\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* it has still some scan parameter to parse, we only do this now... */\n\t\t\t_status = rtw_set_802_11_bssid_list_scan(padapter, ssid, RTW_SSID_SCAN_AMOUNT);\n\t\t} else {\n\t\t\t_status = rtw_set_802_11_bssid_list_scan(padapter, NULL, 0);\n\t\t}\n\t}\n\n\tif (!_status)\n\t\tret = -1;\n\nexit:\n\n\treturn ret;\n}",
        "code_after_change": "static int rtw_wx_set_scan(struct net_device *dev, struct iw_request_info *a,\n\t\t\t   union iwreq_data *wrqu, char *extra)\n{\n\tu8 _status = false;\n\tint ret = 0;\n\tstruct adapter *padapter = rtw_netdev_priv(dev);\n\tstruct mlme_priv *pmlmepriv = &padapter->mlmepriv;\n\tstruct ndis_802_11_ssid ssid[RTW_SSID_SCAN_AMOUNT];\n\n\tRT_TRACE(_module_rtl871x_mlme_c_, _drv_info_, (\"%s\\n\", __func__));\n\n\tif (!rtw_pwr_wakeup(padapter)) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (padapter->bDriverStopped) {\n\t\tDBG_88E(\"bDriverStopped =%d\\n\", padapter->bDriverStopped);\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (!padapter->bup) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\tif (!padapter->hw_init_completed) {\n\t\tret = -1;\n\t\tgoto exit;\n\t}\n\n\t/*  When Busy Traffic, driver do not site survey. So driver return success. */\n\t/*  wpa_supplicant will not issue SIOCSIWSCAN cmd again after scan timeout. */\n\t/*  modify by thomas 2011-02-22. */\n\tif (pmlmepriv->LinkDetectInfo.bBusyTraffic) {\n\t\tindicate_wx_scan_complete_event(padapter);\n\t\tgoto exit;\n\t}\n\n\tif (check_fwstate(pmlmepriv, _FW_UNDER_SURVEY | _FW_UNDER_LINKING)) {\n\t\tindicate_wx_scan_complete_event(padapter);\n\t\tgoto exit;\n\t}\n\n/*\tFor the DMP WiFi Display project, the driver won't to scan because */\n/*\tthe pmlmepriv->scan_interval is always equal to 3. */\n/*\tSo, the wpa_supplicant won't find out the WPS SoftAP. */\n\n\tmemset(ssid, 0, sizeof(struct ndis_802_11_ssid) * RTW_SSID_SCAN_AMOUNT);\n\n\tif (wrqu->data.length == sizeof(struct iw_scan_req)) {\n\t\tstruct iw_scan_req *req = (struct iw_scan_req *)extra;\n\n\t\tif (wrqu->data.flags & IW_SCAN_THIS_ESSID) {\n\t\t\tint len = min_t(int, req->essid_len,\n\t\t\t\t\tIW_ESSID_MAX_SIZE);\n\n\t\t\tmemcpy(ssid[0].ssid, req->essid, len);\n\t\t\tssid[0].ssid_length = len;\n\n\t\t\tDBG_88E(\"IW_SCAN_THIS_ESSID, ssid =%s, len =%d\\n\", req->essid, req->essid_len);\n\n\t\t\tspin_lock_bh(&pmlmepriv->lock);\n\n\t\t\t_status = rtw_sitesurvey_cmd(padapter, ssid, 1, NULL, 0);\n\n\t\t\tspin_unlock_bh(&pmlmepriv->lock);\n\t\t} else if (req->scan_type == IW_SCAN_TYPE_PASSIVE) {\n\t\t\tDBG_88E(\"%s, req->scan_type == IW_SCAN_TYPE_PASSIVE\\n\", __func__);\n\t\t}\n\t} else {\n\t\tif (wrqu->data.length >= WEXT_CSCAN_HEADER_SIZE &&\n\t\t    !memcmp(extra, WEXT_CSCAN_HEADER, WEXT_CSCAN_HEADER_SIZE)) {\n\t\t\tint len = wrqu->data.length - WEXT_CSCAN_HEADER_SIZE;\n\t\t\tchar *pos = extra + WEXT_CSCAN_HEADER_SIZE;\n\t\t\tchar section;\n\t\t\tchar sec_len;\n\t\t\tint ssid_index = 0;\n\n\t\t\twhile (len >= 1) {\n\t\t\t\tsection = *(pos++);\n\t\t\t\tlen -= 1;\n\n\t\t\t\tswitch (section) {\n\t\t\t\tcase WEXT_CSCAN_SSID_SECTION:\n\t\t\t\t\tif (len < 1) {\n\t\t\t\t\t\tlen = 0;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tsec_len = *(pos++); len -= 1;\n\t\t\t\t\tif (sec_len > 0 &&\n\t\t\t\t\t    sec_len <= len &&\n\t\t\t\t\t    sec_len <= 32) {\n\t\t\t\t\t\tssid[ssid_index].ssid_length = sec_len;\n\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, sec_len);\n\t\t\t\t\t\tssid_index++;\n\t\t\t\t\t}\n\t\t\t\t\tpos += sec_len;\n\t\t\t\t\tlen -= sec_len;\n\t\t\t\t\tbreak;\n\t\t\t\tcase WEXT_CSCAN_TYPE_SECTION:\n\t\t\t\tcase WEXT_CSCAN_CHANNEL_SECTION:\n\t\t\t\t\tpos += 1;\n\t\t\t\t\tlen -= 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase WEXT_CSCAN_PASV_DWELL_SECTION:\n\t\t\t\tcase WEXT_CSCAN_HOME_DWELL_SECTION:\n\t\t\t\tcase WEXT_CSCAN_ACTV_DWELL_SECTION:\n\t\t\t\t\tpos += 2;\n\t\t\t\t\tlen -= 2;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tlen = 0; /*  stop parsing */\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* it has still some scan parameter to parse, we only do this now... */\n\t\t\t_status = rtw_set_802_11_bssid_list_scan(padapter, ssid, RTW_SSID_SCAN_AMOUNT);\n\t\t} else {\n\t\t\t_status = rtw_set_802_11_bssid_list_scan(padapter, NULL, 0);\n\t\t}\n\t}\n\n\tif (!_status)\n\t\tret = -1;\n\nexit:\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -89,9 +89,11 @@\n \t\t\t\t\t\tbreak;\n \t\t\t\t\t}\n \t\t\t\t\tsec_len = *(pos++); len -= 1;\n-\t\t\t\t\tif (sec_len > 0 && sec_len <= len) {\n+\t\t\t\t\tif (sec_len > 0 &&\n+\t\t\t\t\t    sec_len <= len &&\n+\t\t\t\t\t    sec_len <= 32) {\n \t\t\t\t\t\tssid[ssid_index].ssid_length = sec_len;\n-\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, ssid[ssid_index].ssid_length);\n+\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, sec_len);\n \t\t\t\t\t\tssid_index++;\n \t\t\t\t\t}\n \t\t\t\t\tpos += sec_len;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\tif (sec_len > 0 &&",
                "\t\t\t\t\t    sec_len <= len &&",
                "\t\t\t\t\t    sec_len <= 32) {",
                "\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, sec_len);"
            ],
            "deleted": [
                "\t\t\t\t\tif (sec_len > 0 && sec_len <= len) {",
                "\t\t\t\t\t\tmemcpy(ssid[ssid_index].ssid, pos, ssid[ssid_index].ssid_length);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "rtw_wx_set_scan in drivers/staging/rtl8188eu/os_dep/ioctl_linux.c in the Linux kernel through 5.11.6 allows writing beyond the end of the ->ssid[] array. NOTE: from the perspective of kernel.org releases, CVE IDs are not normally used for drivers/staging/* (unfinished work); however, system integrators may have situations in which a drivers/staging issue is relevant to their own customer base."
    },
    {
        "cve_id": "CVE-2021-31916",
        "code_before_change": "static int list_devices(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i;\n\tstruct hash_cell *hc;\n\tsize_t len, needed = 0;\n\tstruct gendisk *disk;\n\tstruct dm_name_list *orig_nl, *nl, *old_nl = NULL;\n\tuint32_t *event_nr;\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tneeded += align_val(offsetof(struct dm_name_list, name) + strlen(hc->name) + 1);\n\t\t\tneeded += align_val(sizeof(uint32_t));\n\t\t}\n\t}\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tnl = orig_nl = get_result_buffer(param, param_size, &len);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\tnl->dev = 0;\t/* Flags no data */\n\n\t/*\n\t * Now loop through filling out the names.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tif (old_nl)\n\t\t\t\told_nl->next = (uint32_t) ((void *) nl -\n\t\t\t\t\t\t\t   (void *) old_nl);\n\t\t\tdisk = dm_disk(hc->md);\n\t\t\tnl->dev = huge_encode_dev(disk_devt(disk));\n\t\t\tnl->next = 0;\n\t\t\tstrcpy(nl->name, hc->name);\n\n\t\t\told_nl = nl;\n\t\t\tevent_nr = align_ptr(nl->name + strlen(hc->name) + 1);\n\t\t\t*event_nr = dm_get_event_nr(hc->md);\n\t\t\tnl = align_ptr(event_nr + 1);\n\t\t}\n\t}\n\t/*\n\t * If mismatch happens, security may be compromised due to buffer\n\t * overflow, so it's better to crash.\n\t */\n\tBUG_ON((char *)nl - (char *)orig_nl != needed);\n\n out:\n\tup_write(&_hash_lock);\n\treturn 0;\n}",
        "code_after_change": "static int list_devices(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i;\n\tstruct hash_cell *hc;\n\tsize_t len, needed = 0;\n\tstruct gendisk *disk;\n\tstruct dm_name_list *orig_nl, *nl, *old_nl = NULL;\n\tuint32_t *event_nr;\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tneeded += align_val(offsetof(struct dm_name_list, name) + strlen(hc->name) + 1);\n\t\t\tneeded += align_val(sizeof(uint32_t));\n\t\t}\n\t}\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tnl = orig_nl = get_result_buffer(param, param_size, &len);\n\tif (len < needed || len < sizeof(nl->dev)) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\tnl->dev = 0;\t/* Flags no data */\n\n\t/*\n\t * Now loop through filling out the names.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tif (old_nl)\n\t\t\t\told_nl->next = (uint32_t) ((void *) nl -\n\t\t\t\t\t\t\t   (void *) old_nl);\n\t\t\tdisk = dm_disk(hc->md);\n\t\t\tnl->dev = huge_encode_dev(disk_devt(disk));\n\t\t\tnl->next = 0;\n\t\t\tstrcpy(nl->name, hc->name);\n\n\t\t\told_nl = nl;\n\t\t\tevent_nr = align_ptr(nl->name + strlen(hc->name) + 1);\n\t\t\t*event_nr = dm_get_event_nr(hc->md);\n\t\t\tnl = align_ptr(event_nr + 1);\n\t\t}\n\t}\n\t/*\n\t * If mismatch happens, security may be compromised due to buffer\n\t * overflow, so it's better to crash.\n\t */\n\tBUG_ON((char *)nl - (char *)orig_nl != needed);\n\n out:\n\tup_write(&_hash_lock);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,7 +24,7 @@\n \t * Grab our output buffer.\n \t */\n \tnl = orig_nl = get_result_buffer(param, param_size, &len);\n-\tif (len < needed) {\n+\tif (len < needed || len < sizeof(nl->dev)) {\n \t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n \t\tgoto out;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (len < needed || len < sizeof(nl->dev)) {"
            ],
            "deleted": [
                "\tif (len < needed) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds (OOB) memory write flaw was found in list_devices in drivers/md/dm-ioctl.c in the Multi-device driver module in the Linux kernel before 5.12. A bound check failure allows an attacker with special user (CAP_SYS_ADMIN) privilege to gain access to out-of-bounds memory leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability."
    },
    {
        "cve_id": "CVE-2021-33655",
        "code_before_change": "static int fbcon_set_font(struct vc_data *vc, struct console_font *font,\n\t\t\t  unsigned int flags)\n{\n\tstruct fb_info *info = fbcon_info_from_console(vc->vc_num);\n\tunsigned charcount = font->charcount;\n\tint w = font->width;\n\tint h = font->height;\n\tint size;\n\tint i, csum;\n\tu8 *new_data, *data = font->data;\n\tint pitch = PITCH(font->width);\n\n\t/* Is there a reason why fbconsole couldn't handle any charcount >256?\n\t * If not this check should be changed to charcount < 256 */\n\tif (charcount != 256 && charcount != 512)\n\t\treturn -EINVAL;\n\n\t/* Make sure drawing engine can handle the font */\n\tif (!(info->pixmap.blit_x & (1 << (font->width - 1))) ||\n\t    !(info->pixmap.blit_y & (1 << (font->height - 1))))\n\t\treturn -EINVAL;\n\n\t/* Make sure driver can handle the font length */\n\tif (fbcon_invalid_charcount(info, charcount))\n\t\treturn -EINVAL;\n\n\tsize = CALC_FONTSZ(h, pitch, charcount);\n\n\tnew_data = kmalloc(FONT_EXTRA_WORDS * sizeof(int) + size, GFP_USER);\n\n\tif (!new_data)\n\t\treturn -ENOMEM;\n\n\tmemset(new_data, 0, FONT_EXTRA_WORDS * sizeof(int));\n\n\tnew_data += FONT_EXTRA_WORDS * sizeof(int);\n\tFNTSIZE(new_data) = size;\n\tREFCOUNT(new_data) = 0;\t/* usage counter */\n\tfor (i=0; i< charcount; i++) {\n\t\tmemcpy(new_data + i*h*pitch, data +  i*32*pitch, h*pitch);\n\t}\n\n\t/* Since linux has a nice crc32 function use it for counting font\n\t * checksums. */\n\tcsum = crc32(0, new_data, size);\n\n\tFNTSUM(new_data) = csum;\n\t/* Check if the same font is on some other console already */\n\tfor (i = first_fb_vc; i <= last_fb_vc; i++) {\n\t\tstruct vc_data *tmp = vc_cons[i].d;\n\t\t\n\t\tif (fb_display[i].userfont &&\n\t\t    fb_display[i].fontdata &&\n\t\t    FNTSUM(fb_display[i].fontdata) == csum &&\n\t\t    FNTSIZE(fb_display[i].fontdata) == size &&\n\t\t    tmp->vc_font.width == w &&\n\t\t    !memcmp(fb_display[i].fontdata, new_data, size)) {\n\t\t\tkfree(new_data - FONT_EXTRA_WORDS * sizeof(int));\n\t\t\tnew_data = (u8 *)fb_display[i].fontdata;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn fbcon_do_set_font(vc, font->width, font->height, charcount, new_data, 1);\n}",
        "code_after_change": "static int fbcon_set_font(struct vc_data *vc, struct console_font *font,\n\t\t\t  unsigned int flags)\n{\n\tstruct fb_info *info = fbcon_info_from_console(vc->vc_num);\n\tunsigned charcount = font->charcount;\n\tint w = font->width;\n\tint h = font->height;\n\tint size;\n\tint i, csum;\n\tu8 *new_data, *data = font->data;\n\tint pitch = PITCH(font->width);\n\n\t/* Is there a reason why fbconsole couldn't handle any charcount >256?\n\t * If not this check should be changed to charcount < 256 */\n\tif (charcount != 256 && charcount != 512)\n\t\treturn -EINVAL;\n\n\t/* font bigger than screen resolution ? */\n\tif (w > FBCON_SWAP(info->var.rotate, info->var.xres, info->var.yres) ||\n\t    h > FBCON_SWAP(info->var.rotate, info->var.yres, info->var.xres))\n\t\treturn -EINVAL;\n\n\t/* Make sure drawing engine can handle the font */\n\tif (!(info->pixmap.blit_x & (1 << (font->width - 1))) ||\n\t    !(info->pixmap.blit_y & (1 << (font->height - 1))))\n\t\treturn -EINVAL;\n\n\t/* Make sure driver can handle the font length */\n\tif (fbcon_invalid_charcount(info, charcount))\n\t\treturn -EINVAL;\n\n\tsize = CALC_FONTSZ(h, pitch, charcount);\n\n\tnew_data = kmalloc(FONT_EXTRA_WORDS * sizeof(int) + size, GFP_USER);\n\n\tif (!new_data)\n\t\treturn -ENOMEM;\n\n\tmemset(new_data, 0, FONT_EXTRA_WORDS * sizeof(int));\n\n\tnew_data += FONT_EXTRA_WORDS * sizeof(int);\n\tFNTSIZE(new_data) = size;\n\tREFCOUNT(new_data) = 0;\t/* usage counter */\n\tfor (i=0; i< charcount; i++) {\n\t\tmemcpy(new_data + i*h*pitch, data +  i*32*pitch, h*pitch);\n\t}\n\n\t/* Since linux has a nice crc32 function use it for counting font\n\t * checksums. */\n\tcsum = crc32(0, new_data, size);\n\n\tFNTSUM(new_data) = csum;\n\t/* Check if the same font is on some other console already */\n\tfor (i = first_fb_vc; i <= last_fb_vc; i++) {\n\t\tstruct vc_data *tmp = vc_cons[i].d;\n\t\t\n\t\tif (fb_display[i].userfont &&\n\t\t    fb_display[i].fontdata &&\n\t\t    FNTSUM(fb_display[i].fontdata) == csum &&\n\t\t    FNTSIZE(fb_display[i].fontdata) == size &&\n\t\t    tmp->vc_font.width == w &&\n\t\t    !memcmp(fb_display[i].fontdata, new_data, size)) {\n\t\t\tkfree(new_data - FONT_EXTRA_WORDS * sizeof(int));\n\t\t\tnew_data = (u8 *)fb_display[i].fontdata;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn fbcon_do_set_font(vc, font->width, font->height, charcount, new_data, 1);\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,6 +13,11 @@\n \t/* Is there a reason why fbconsole couldn't handle any charcount >256?\n \t * If not this check should be changed to charcount < 256 */\n \tif (charcount != 256 && charcount != 512)\n+\t\treturn -EINVAL;\n+\n+\t/* font bigger than screen resolution ? */\n+\tif (w > FBCON_SWAP(info->var.rotate, info->var.xres, info->var.yres) ||\n+\t    h > FBCON_SWAP(info->var.rotate, info->var.yres, info->var.xres))\n \t\treturn -EINVAL;\n \n \t/* Make sure drawing engine can handle the font */",
        "function_modified_lines": {
            "added": [
                "\t\treturn -EINVAL;",
                "",
                "\t/* font bigger than screen resolution ? */",
                "\tif (w > FBCON_SWAP(info->var.rotate, info->var.xres, info->var.yres) ||",
                "\t    h > FBCON_SWAP(info->var.rotate, info->var.yres, info->var.xres))"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "When sending malicous data to kernel by ioctl cmd FBIOPUT_VSCREENINFO,kernel will write memory out of bounds."
    },
    {
        "cve_id": "CVE-2021-33656",
        "code_before_change": "static int con_font_get(struct vc_data *vc, struct console_font_op *op)\n{\n\tstruct console_font font;\n\tint rc = -EINVAL;\n\tint c;\n\n\tif (op->data) {\n\t\tfont.data = kmalloc(max_font_size, GFP_KERNEL);\n\t\tif (!font.data)\n\t\t\treturn -ENOMEM;\n\t} else\n\t\tfont.data = NULL;\n\n\tconsole_lock();\n\tif (vc->vc_mode != KD_TEXT)\n\t\trc = -EINVAL;\n\telse if (vc->vc_sw->con_font_get)\n\t\trc = vc->vc_sw->con_font_get(vc, &font);\n\telse\n\t\trc = -ENOSYS;\n\tconsole_unlock();\n\n\tif (rc)\n\t\tgoto out;\n\n\tc = (font.width+7)/8 * 32 * font.charcount;\n\n\tif (op->data && font.charcount > op->charcount)\n\t\trc = -ENOSPC;\n\tif (!(op->flags & KD_FONT_FLAG_OLD)) {\n\t\tif (font.width > op->width || font.height > op->height)\n\t\t\trc = -ENOSPC;\n\t} else {\n\t\tif (font.width != 8)\n\t\t\trc = -EIO;\n\t\telse if ((op->height && font.height > op->height) ||\n\t\t\t font.height > 32)\n\t\t\trc = -ENOSPC;\n\t}\n\tif (rc)\n\t\tgoto out;\n\n\top->height = font.height;\n\top->width = font.width;\n\top->charcount = font.charcount;\n\n\tif (op->data && copy_to_user(op->data, font.data, c))\n\t\trc = -EFAULT;\n\nout:\n\tkfree(font.data);\n\treturn rc;\n}",
        "code_after_change": "static int con_font_get(struct vc_data *vc, struct console_font_op *op)\n{\n\tstruct console_font font;\n\tint rc = -EINVAL;\n\tint c;\n\n\tif (op->data) {\n\t\tfont.data = kmalloc(max_font_size, GFP_KERNEL);\n\t\tif (!font.data)\n\t\t\treturn -ENOMEM;\n\t} else\n\t\tfont.data = NULL;\n\n\tconsole_lock();\n\tif (vc->vc_mode != KD_TEXT)\n\t\trc = -EINVAL;\n\telse if (vc->vc_sw->con_font_get)\n\t\trc = vc->vc_sw->con_font_get(vc, &font);\n\telse\n\t\trc = -ENOSYS;\n\tconsole_unlock();\n\n\tif (rc)\n\t\tgoto out;\n\n\tc = (font.width+7)/8 * 32 * font.charcount;\n\n\tif (op->data && font.charcount > op->charcount)\n\t\trc = -ENOSPC;\n\tif (font.width > op->width || font.height > op->height)\n\t\trc = -ENOSPC;\n\tif (rc)\n\t\tgoto out;\n\n\top->height = font.height;\n\top->width = font.width;\n\top->charcount = font.charcount;\n\n\tif (op->data && copy_to_user(op->data, font.data, c))\n\t\trc = -EFAULT;\n\nout:\n\tkfree(font.data);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,16 +27,8 @@\n \n \tif (op->data && font.charcount > op->charcount)\n \t\trc = -ENOSPC;\n-\tif (!(op->flags & KD_FONT_FLAG_OLD)) {\n-\t\tif (font.width > op->width || font.height > op->height)\n-\t\t\trc = -ENOSPC;\n-\t} else {\n-\t\tif (font.width != 8)\n-\t\t\trc = -EIO;\n-\t\telse if ((op->height && font.height > op->height) ||\n-\t\t\t font.height > 32)\n-\t\t\trc = -ENOSPC;\n-\t}\n+\tif (font.width > op->width || font.height > op->height)\n+\t\trc = -ENOSPC;\n \tif (rc)\n \t\tgoto out;\n ",
        "function_modified_lines": {
            "added": [
                "\tif (font.width > op->width || font.height > op->height)",
                "\t\trc = -ENOSPC;"
            ],
            "deleted": [
                "\tif (!(op->flags & KD_FONT_FLAG_OLD)) {",
                "\t\tif (font.width > op->width || font.height > op->height)",
                "\t\t\trc = -ENOSPC;",
                "\t} else {",
                "\t\tif (font.width != 8)",
                "\t\t\trc = -EIO;",
                "\t\telse if ((op->height && font.height > op->height) ||",
                "\t\t\t font.height > 32)",
                "\t\t\trc = -ENOSPC;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "When setting font with malicous data by ioctl cmd PIO_FONT,kernel will write memory out of bounds."
    },
    {
        "cve_id": "CVE-2021-33656",
        "code_before_change": "static int con_font_set(struct vc_data *vc, struct console_font_op *op)\n{\n\tstruct console_font font;\n\tint rc = -EINVAL;\n\tint size;\n\n\tif (vc->vc_mode != KD_TEXT)\n\t\treturn -EINVAL;\n\tif (!op->data)\n\t\treturn -EINVAL;\n\tif (op->charcount > 512)\n\t\treturn -EINVAL;\n\tif (op->width <= 0 || op->width > 32 || op->height > 32)\n\t\treturn -EINVAL;\n\tsize = (op->width+7)/8 * 32 * op->charcount;\n\tif (size > max_font_size)\n\t\treturn -ENOSPC;\n\n\tfont.data = memdup_user(op->data, size);\n\tif (IS_ERR(font.data))\n\t\treturn PTR_ERR(font.data);\n\n\tif (!op->height) {\t\t/* Need to guess font height [compat] */\n\t\tint h, i;\n\t\tu8 *charmap = font.data;\n\n\t\t/*\n\t\t * If from KDFONTOP ioctl, don't allow things which can be done\n\t\t * in userland,so that we can get rid of this soon\n\t\t */\n\t\tif (!(op->flags & KD_FONT_FLAG_OLD)) {\n\t\t\tkfree(font.data);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfor (h = 32; h > 0; h--)\n\t\t\tfor (i = 0; i < op->charcount; i++)\n\t\t\t\tif (charmap[32*i+h-1])\n\t\t\t\t\tgoto nonzero;\n\n\t\tkfree(font.data);\n\t\treturn -EINVAL;\n\n\tnonzero:\n\t\top->height = h;\n\t}\n\n\tfont.charcount = op->charcount;\n\tfont.width = op->width;\n\tfont.height = op->height;\n\n\tconsole_lock();\n\tif (vc->vc_mode != KD_TEXT)\n\t\trc = -EINVAL;\n\telse if (vc->vc_sw->con_font_set)\n\t\trc = vc->vc_sw->con_font_set(vc, &font, op->flags);\n\telse\n\t\trc = -ENOSYS;\n\tconsole_unlock();\n\tkfree(font.data);\n\treturn rc;\n}",
        "code_after_change": "static int con_font_set(struct vc_data *vc, struct console_font_op *op)\n{\n\tstruct console_font font;\n\tint rc = -EINVAL;\n\tint size;\n\n\tif (vc->vc_mode != KD_TEXT)\n\t\treturn -EINVAL;\n\tif (!op->data)\n\t\treturn -EINVAL;\n\tif (op->charcount > 512)\n\t\treturn -EINVAL;\n\tif (op->width <= 0 || op->width > 32 || !op->height || op->height > 32)\n\t\treturn -EINVAL;\n\tsize = (op->width+7)/8 * 32 * op->charcount;\n\tif (size > max_font_size)\n\t\treturn -ENOSPC;\n\n\tfont.data = memdup_user(op->data, size);\n\tif (IS_ERR(font.data))\n\t\treturn PTR_ERR(font.data);\n\n\tfont.charcount = op->charcount;\n\tfont.width = op->width;\n\tfont.height = op->height;\n\n\tconsole_lock();\n\tif (vc->vc_mode != KD_TEXT)\n\t\trc = -EINVAL;\n\telse if (vc->vc_sw->con_font_set)\n\t\trc = vc->vc_sw->con_font_set(vc, &font, op->flags);\n\telse\n\t\trc = -ENOSYS;\n\tconsole_unlock();\n\tkfree(font.data);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t\treturn -EINVAL;\n \tif (op->charcount > 512)\n \t\treturn -EINVAL;\n-\tif (op->width <= 0 || op->width > 32 || op->height > 32)\n+\tif (op->width <= 0 || op->width > 32 || !op->height || op->height > 32)\n \t\treturn -EINVAL;\n \tsize = (op->width+7)/8 * 32 * op->charcount;\n \tif (size > max_font_size)\n@@ -19,31 +19,6 @@\n \tfont.data = memdup_user(op->data, size);\n \tif (IS_ERR(font.data))\n \t\treturn PTR_ERR(font.data);\n-\n-\tif (!op->height) {\t\t/* Need to guess font height [compat] */\n-\t\tint h, i;\n-\t\tu8 *charmap = font.data;\n-\n-\t\t/*\n-\t\t * If from KDFONTOP ioctl, don't allow things which can be done\n-\t\t * in userland,so that we can get rid of this soon\n-\t\t */\n-\t\tif (!(op->flags & KD_FONT_FLAG_OLD)) {\n-\t\t\tkfree(font.data);\n-\t\t\treturn -EINVAL;\n-\t\t}\n-\n-\t\tfor (h = 32; h > 0; h--)\n-\t\t\tfor (i = 0; i < op->charcount; i++)\n-\t\t\t\tif (charmap[32*i+h-1])\n-\t\t\t\t\tgoto nonzero;\n-\n-\t\tkfree(font.data);\n-\t\treturn -EINVAL;\n-\n-\tnonzero:\n-\t\top->height = h;\n-\t}\n \n \tfont.charcount = op->charcount;\n \tfont.width = op->width;",
        "function_modified_lines": {
            "added": [
                "\tif (op->width <= 0 || op->width > 32 || !op->height || op->height > 32)"
            ],
            "deleted": [
                "\tif (op->width <= 0 || op->width > 32 || op->height > 32)",
                "",
                "\tif (!op->height) {\t\t/* Need to guess font height [compat] */",
                "\t\tint h, i;",
                "\t\tu8 *charmap = font.data;",
                "",
                "\t\t/*",
                "\t\t * If from KDFONTOP ioctl, don't allow things which can be done",
                "\t\t * in userland,so that we can get rid of this soon",
                "\t\t */",
                "\t\tif (!(op->flags & KD_FONT_FLAG_OLD)) {",
                "\t\t\tkfree(font.data);",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                "",
                "\t\tfor (h = 32; h > 0; h--)",
                "\t\t\tfor (i = 0; i < op->charcount; i++)",
                "\t\t\t\tif (charmap[32*i+h-1])",
                "\t\t\t\t\tgoto nonzero;",
                "",
                "\t\tkfree(font.data);",
                "\t\treturn -EINVAL;",
                "",
                "\tnonzero:",
                "\t\top->height = h;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "When setting font with malicous data by ioctl cmd PIO_FONT,kernel will write memory out of bounds."
    },
    {
        "cve_id": "CVE-2021-33656",
        "code_before_change": "static int vt_io_ioctl(struct vc_data *vc, unsigned int cmd, void __user *up,\n\t\tbool perm)\n{\n\tstruct console_font_op op;\t/* used in multiple places here */\n\n\tswitch (cmd) {\n\tcase PIO_FONT:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top.op = KD_FONT_OP_SET;\n\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n\t\top.width = 8;\n\t\top.height = 0;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc, &op);\n\n\tcase GIO_FONT:\n\t\top.op = KD_FONT_OP_GET;\n\t\top.flags = KD_FONT_FLAG_OLD;\n\t\top.width = 8;\n\t\top.height = 32;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc, &op);\n\n\tcase PIO_CMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_cmap(up);\n\n\tcase GIO_CMAP:\n\t\treturn con_get_cmap(up);\n\n\tcase PIO_FONTX:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tfallthrough;\n\tcase GIO_FONTX:\n\t\treturn do_fontx_ioctl(vc, cmd, up, &op);\n\n\tcase PIO_FONTRESET:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\treturn vt_io_fontreset(vc, &op);\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_old(up);\n\n\tcase GIO_SCRNMAP:\n\t\treturn con_get_trans_old(up);\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_new(up);\n\n\tcase GIO_UNISCRNMAP:\n\t\treturn con_get_trans_new(up);\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn do_unimap_ioctl(cmd, up, perm, vc);\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int vt_io_ioctl(struct vc_data *vc, unsigned int cmd, void __user *up,\n\t\tbool perm)\n{\n\tswitch (cmd) {\n\tcase PIO_CMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_cmap(up);\n\n\tcase GIO_CMAP:\n\t\treturn con_get_cmap(up);\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_old(up);\n\n\tcase GIO_SCRNMAP:\n\t\treturn con_get_trans_old(up);\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_new(up);\n\n\tcase GIO_UNISCRNMAP:\n\t\treturn con_get_trans_new(up);\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn do_unimap_ioctl(cmd, up, perm, vc);\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,29 +1,7 @@\n static int vt_io_ioctl(struct vc_data *vc, unsigned int cmd, void __user *up,\n \t\tbool perm)\n {\n-\tstruct console_font_op op;\t/* used in multiple places here */\n-\n \tswitch (cmd) {\n-\tcase PIO_FONT:\n-\t\tif (!perm)\n-\t\t\treturn -EPERM;\n-\t\top.op = KD_FONT_OP_SET;\n-\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n-\t\top.width = 8;\n-\t\top.height = 0;\n-\t\top.charcount = 256;\n-\t\top.data = up;\n-\t\treturn con_font_op(vc, &op);\n-\n-\tcase GIO_FONT:\n-\t\top.op = KD_FONT_OP_GET;\n-\t\top.flags = KD_FONT_FLAG_OLD;\n-\t\top.width = 8;\n-\t\top.height = 32;\n-\t\top.charcount = 256;\n-\t\top.data = up;\n-\t\treturn con_font_op(vc, &op);\n-\n \tcase PIO_CMAP:\n \t\tif (!perm)\n \t\t\treturn -EPERM;\n@@ -31,20 +9,6 @@\n \n \tcase GIO_CMAP:\n \t\treturn con_get_cmap(up);\n-\n-\tcase PIO_FONTX:\n-\t\tif (!perm)\n-\t\t\treturn -EPERM;\n-\n-\t\tfallthrough;\n-\tcase GIO_FONTX:\n-\t\treturn do_fontx_ioctl(vc, cmd, up, &op);\n-\n-\tcase PIO_FONTRESET:\n-\t\tif (!perm)\n-\t\t\treturn -EPERM;\n-\n-\t\treturn vt_io_fontreset(vc, &op);\n \n \tcase PIO_SCRNMAP:\n \t\tif (!perm)",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tstruct console_font_op op;\t/* used in multiple places here */",
                "",
                "\tcase PIO_FONT:",
                "\t\tif (!perm)",
                "\t\t\treturn -EPERM;",
                "\t\top.op = KD_FONT_OP_SET;",
                "\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */",
                "\t\top.width = 8;",
                "\t\top.height = 0;",
                "\t\top.charcount = 256;",
                "\t\top.data = up;",
                "\t\treturn con_font_op(vc, &op);",
                "",
                "\tcase GIO_FONT:",
                "\t\top.op = KD_FONT_OP_GET;",
                "\t\top.flags = KD_FONT_FLAG_OLD;",
                "\t\top.width = 8;",
                "\t\top.height = 32;",
                "\t\top.charcount = 256;",
                "\t\top.data = up;",
                "\t\treturn con_font_op(vc, &op);",
                "",
                "",
                "\tcase PIO_FONTX:",
                "\t\tif (!perm)",
                "\t\t\treturn -EPERM;",
                "",
                "\t\tfallthrough;",
                "\tcase GIO_FONTX:",
                "\t\treturn do_fontx_ioctl(vc, cmd, up, &op);",
                "",
                "\tcase PIO_FONTRESET:",
                "\t\tif (!perm)",
                "\t\t\treturn -EPERM;",
                "",
                "\t\treturn vt_io_fontreset(vc, &op);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "When setting font with malicous data by ioctl cmd PIO_FONT,kernel will write memory out of bounds."
    },
    {
        "cve_id": "CVE-2021-33656",
        "code_before_change": "long vt_compat_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tvoid __user *up = compat_ptr(arg);\n\tint perm;\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n\n\tswitch (cmd) {\n\t/*\n\t * these need special handlers for incompatible data structures\n\t */\n\tcase PIO_FONTX:\n\tcase GIO_FONTX:\n\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);\n\n\tcase KDFONTOP:\n\t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn compat_unimap_ioctl(cmd, up, perm, vc);\n\n\t/*\n\t * all these treat 'arg' as an integer\n\t */\n\tcase KIOCSOUND:\n\tcase KDMKTONE:\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n#endif\n\tcase KDSETMODE:\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\tcase KDSKBMODE:\n\tcase KDSKBMETA:\n\tcase KDSKBLED:\n\tcase KDSETLED:\n\tcase KDSIGACCEPT:\n\tcase VT_ACTIVATE:\n\tcase VT_WAITACTIVE:\n\tcase VT_RELDISP:\n\tcase VT_DISALLOCATE:\n\tcase VT_RESIZE:\n\tcase VT_RESIZEX:\n\t\treturn vt_ioctl(tty, cmd, arg);\n\n\t/*\n\t * the rest has a compatible data structure behind arg,\n\t * but we have to convert it to a proper 64 bit pointer.\n\t */\n\tdefault:\n\t\treturn vt_ioctl(tty, cmd, (unsigned long)up);\n\t}\n}",
        "code_after_change": "long vt_compat_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tvoid __user *up = compat_ptr(arg);\n\tint perm;\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n\n\tswitch (cmd) {\n\t/*\n\t * these need special handlers for incompatible data structures\n\t */\n\n\tcase KDFONTOP:\n\t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn compat_unimap_ioctl(cmd, up, perm, vc);\n\n\t/*\n\t * all these treat 'arg' as an integer\n\t */\n\tcase KIOCSOUND:\n\tcase KDMKTONE:\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n#endif\n\tcase KDSETMODE:\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\tcase KDSKBMODE:\n\tcase KDSKBMETA:\n\tcase KDSKBLED:\n\tcase KDSETLED:\n\tcase KDSIGACCEPT:\n\tcase VT_ACTIVATE:\n\tcase VT_WAITACTIVE:\n\tcase VT_RELDISP:\n\tcase VT_DISALLOCATE:\n\tcase VT_RESIZE:\n\tcase VT_RESIZEX:\n\t\treturn vt_ioctl(tty, cmd, arg);\n\n\t/*\n\t * the rest has a compatible data structure behind arg,\n\t * but we have to convert it to a proper 64 bit pointer.\n\t */\n\tdefault:\n\t\treturn vt_ioctl(tty, cmd, (unsigned long)up);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,9 +18,6 @@\n \t/*\n \t * these need special handlers for incompatible data structures\n \t */\n-\tcase PIO_FONTX:\n-\tcase GIO_FONTX:\n-\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);\n \n \tcase KDFONTOP:\n \t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tcase PIO_FONTX:",
                "\tcase GIO_FONTX:",
                "\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "When setting font with malicous data by ioctl cmd PIO_FONT,kernel will write memory out of bounds."
    },
    {
        "cve_id": "CVE-2021-33909",
        "code_before_change": "static void *seq_buf_alloc(unsigned long size)\n{\n\treturn kvmalloc(size, GFP_KERNEL_ACCOUNT);\n}",
        "code_after_change": "static void *seq_buf_alloc(unsigned long size)\n{\n\tif (unlikely(size > MAX_RW_COUNT))\n\t\treturn NULL;\n\n\treturn kvmalloc(size, GFP_KERNEL_ACCOUNT);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,7 @@\n static void *seq_buf_alloc(unsigned long size)\n {\n+\tif (unlikely(size > MAX_RW_COUNT))\n+\t\treturn NULL;\n+\n \treturn kvmalloc(size, GFP_KERNEL_ACCOUNT);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(size > MAX_RW_COUNT))",
                "\t\treturn NULL;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "fs/seq_file.c in the Linux kernel 3.16 through 5.13.x before 5.13.4 does not properly restrict seq buffer allocations, leading to an integer overflow, an Out-of-bounds Write, and escalation to root by an unprivileged user, aka CID-8cae8cd89f05."
    },
    {
        "cve_id": "CVE-2021-3489",
        "code_before_change": "static void *__bpf_ringbuf_reserve(struct bpf_ringbuf *rb, u64 size)\n{\n\tunsigned long cons_pos, prod_pos, new_prod_pos, flags;\n\tu32 len, pg_off;\n\tstruct bpf_ringbuf_hdr *hdr;\n\n\tif (unlikely(size > RINGBUF_MAX_RECORD_SZ))\n\t\treturn NULL;\n\n\tlen = round_up(size + BPF_RINGBUF_HDR_SZ, 8);\n\tcons_pos = smp_load_acquire(&rb->consumer_pos);\n\n\tif (in_nmi()) {\n\t\tif (!spin_trylock_irqsave(&rb->spinlock, flags))\n\t\t\treturn NULL;\n\t} else {\n\t\tspin_lock_irqsave(&rb->spinlock, flags);\n\t}\n\n\tprod_pos = rb->producer_pos;\n\tnew_prod_pos = prod_pos + len;\n\n\t/* check for out of ringbuf space by ensuring producer position\n\t * doesn't advance more than (ringbuf_size - 1) ahead\n\t */\n\tif (new_prod_pos - cons_pos > rb->mask) {\n\t\tspin_unlock_irqrestore(&rb->spinlock, flags);\n\t\treturn NULL;\n\t}\n\n\thdr = (void *)rb->data + (prod_pos & rb->mask);\n\tpg_off = bpf_ringbuf_rec_pg_off(rb, hdr);\n\thdr->len = size | BPF_RINGBUF_BUSY_BIT;\n\thdr->pg_off = pg_off;\n\n\t/* pairs with consumer's smp_load_acquire() */\n\tsmp_store_release(&rb->producer_pos, new_prod_pos);\n\n\tspin_unlock_irqrestore(&rb->spinlock, flags);\n\n\treturn (void *)hdr + BPF_RINGBUF_HDR_SZ;\n}",
        "code_after_change": "static void *__bpf_ringbuf_reserve(struct bpf_ringbuf *rb, u64 size)\n{\n\tunsigned long cons_pos, prod_pos, new_prod_pos, flags;\n\tu32 len, pg_off;\n\tstruct bpf_ringbuf_hdr *hdr;\n\n\tif (unlikely(size > RINGBUF_MAX_RECORD_SZ))\n\t\treturn NULL;\n\n\tlen = round_up(size + BPF_RINGBUF_HDR_SZ, 8);\n\tif (len > rb->mask + 1)\n\t\treturn NULL;\n\n\tcons_pos = smp_load_acquire(&rb->consumer_pos);\n\n\tif (in_nmi()) {\n\t\tif (!spin_trylock_irqsave(&rb->spinlock, flags))\n\t\t\treturn NULL;\n\t} else {\n\t\tspin_lock_irqsave(&rb->spinlock, flags);\n\t}\n\n\tprod_pos = rb->producer_pos;\n\tnew_prod_pos = prod_pos + len;\n\n\t/* check for out of ringbuf space by ensuring producer position\n\t * doesn't advance more than (ringbuf_size - 1) ahead\n\t */\n\tif (new_prod_pos - cons_pos > rb->mask) {\n\t\tspin_unlock_irqrestore(&rb->spinlock, flags);\n\t\treturn NULL;\n\t}\n\n\thdr = (void *)rb->data + (prod_pos & rb->mask);\n\tpg_off = bpf_ringbuf_rec_pg_off(rb, hdr);\n\thdr->len = size | BPF_RINGBUF_BUSY_BIT;\n\thdr->pg_off = pg_off;\n\n\t/* pairs with consumer's smp_load_acquire() */\n\tsmp_store_release(&rb->producer_pos, new_prod_pos);\n\n\tspin_unlock_irqrestore(&rb->spinlock, flags);\n\n\treturn (void *)hdr + BPF_RINGBUF_HDR_SZ;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,9 @@\n \t\treturn NULL;\n \n \tlen = round_up(size + BPF_RINGBUF_HDR_SZ, 8);\n+\tif (len > rb->mask + 1)\n+\t\treturn NULL;\n+\n \tcons_pos = smp_load_acquire(&rb->consumer_pos);\n \n \tif (in_nmi()) {",
        "function_modified_lines": {
            "added": [
                "\tif (len > rb->mask + 1)",
                "\t\treturn NULL;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The eBPF RINGBUF bpf_ringbuf_reserve() function in the Linux kernel did not check that the allocated size was smaller than the ringbuf size, allowing an attacker to perform out-of-bounds writes within the kernel and therefore, arbitrary code execution. This issue was fixed via commit 4b81ccebaeee (\"bpf, ringbuf: Deny reserve of buffers larger than ringbuf\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. It was introduced via 457f44363a88 (\"bpf: Implement BPF ring buffer and verifier support for it\") (v5.8-rc1)."
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\t/* Assuming scalar64_min_max_xor will be called so it is safe\n\t * to skip updating register for known case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "code_after_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,11 +6,10 @@\n \tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n \ts32 smin_val = src_reg->s32_min_value;\n \n-\t/* Assuming scalar64_min_max_xor will be called so it is safe\n-\t * to skip updating register for known case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get both minimum and maximum from the var32_off. */\n \tdst_reg->u32_min_value = var32_off.value;",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_xor will be called so it is safe",
                "\t * to skip updating register for known case.",
                "\t */",
                "\tif (src_known && dst_known)"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1)."
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_and(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umax_val = src_reg->u32_max_value;\n\n\t/* Assuming scalar64_min_max_and will be called so its safe\n\t * to skip updating register for known 32-bit case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get our minimum from the var_off, since that's inherently\n\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = min(dst_reg->u32_max_value, umax_val);\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ANDing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n\n}",
        "code_after_change": "static void scalar32_min_max_and(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umax_val = src_reg->u32_max_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get our minimum from the var_off, since that's inherently\n\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = min(dst_reg->u32_max_value, umax_val);\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ANDing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,11 +7,10 @@\n \ts32 smin_val = src_reg->s32_min_value;\n \tu32 umax_val = src_reg->u32_max_value;\n \n-\t/* Assuming scalar64_min_max_and will be called so its safe\n-\t * to skip updating register for known 32-bit case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get our minimum from the var_off, since that's inherently\n \t * bitwise.  Our maximum is the minimum of the operands' maxima.\n@@ -31,5 +30,4 @@\n \t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n \t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n \t}\n-\n }",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_and will be called so its safe",
                "\t * to skip updating register for known 32-bit case.",
                "\t */",
                "\tif (src_known && dst_known)",
                ""
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1)."
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_or(struct bpf_reg_state *dst_reg,\n\t\t\t\tstruct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umin_val = src_reg->u32_min_value;\n\n\t/* Assuming scalar64_min_max_or will be called so it is safe\n\t * to skip updating register for known case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get our maximum from the var_off, and our minimum is the\n\t * maximum of the operands' minima\n\t */\n\tdst_reg->u32_min_value = max(dst_reg->u32_min_value, umin_val);\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ORing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "code_after_change": "static void scalar32_min_max_or(struct bpf_reg_state *dst_reg,\n\t\t\t\tstruct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umin_val = src_reg->u32_min_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get our maximum from the var_off, and our minimum is the\n\t * maximum of the operands' minima\n\t */\n\tdst_reg->u32_min_value = max(dst_reg->u32_min_value, umin_val);\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ORing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,11 +7,10 @@\n \ts32 smin_val = src_reg->s32_min_value;\n \tu32 umin_val = src_reg->u32_min_value;\n \n-\t/* Assuming scalar64_min_max_or will be called so it is safe\n-\t * to skip updating register for known case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get our maximum from the var_off, and our minimum is the\n \t * maximum of the operands' minima",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_or will be called so it is safe",
                "\t * to skip updating register for known case.",
                "\t */",
                "\tif (src_known && dst_known)"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1)."
    },
    {
        "cve_id": "CVE-2021-3491",
        "code_before_change": "static int io_add_buffers(struct io_provide_buf *pbuf, struct io_buffer **head)\n{\n\tstruct io_buffer *buf;\n\tu64 addr = pbuf->addr;\n\tint i, bid = pbuf->bid;\n\n\tfor (i = 0; i < pbuf->nbufs; i++) {\n\t\tbuf = kmalloc(sizeof(*buf), GFP_KERNEL);\n\t\tif (!buf)\n\t\t\tbreak;\n\n\t\tbuf->addr = addr;\n\t\tbuf->len = pbuf->len;\n\t\tbuf->bid = bid;\n\t\taddr += pbuf->len;\n\t\tbid++;\n\t\tif (!*head) {\n\t\t\tINIT_LIST_HEAD(&buf->list);\n\t\t\t*head = buf;\n\t\t} else {\n\t\t\tlist_add_tail(&buf->list, &(*head)->list);\n\t\t}\n\t}\n\n\treturn i ? i : -ENOMEM;\n}",
        "code_after_change": "static int io_add_buffers(struct io_provide_buf *pbuf, struct io_buffer **head)\n{\n\tstruct io_buffer *buf;\n\tu64 addr = pbuf->addr;\n\tint i, bid = pbuf->bid;\n\n\tfor (i = 0; i < pbuf->nbufs; i++) {\n\t\tbuf = kmalloc(sizeof(*buf), GFP_KERNEL);\n\t\tif (!buf)\n\t\t\tbreak;\n\n\t\tbuf->addr = addr;\n\t\tbuf->len = min_t(__u32, pbuf->len, MAX_RW_COUNT);\n\t\tbuf->bid = bid;\n\t\taddr += pbuf->len;\n\t\tbid++;\n\t\tif (!*head) {\n\t\t\tINIT_LIST_HEAD(&buf->list);\n\t\t\t*head = buf;\n\t\t} else {\n\t\t\tlist_add_tail(&buf->list, &(*head)->list);\n\t\t}\n\t}\n\n\treturn i ? i : -ENOMEM;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t\t\tbreak;\n \n \t\tbuf->addr = addr;\n-\t\tbuf->len = pbuf->len;\n+\t\tbuf->len = min_t(__u32, pbuf->len, MAX_RW_COUNT);\n \t\tbuf->bid = bid;\n \t\taddr += pbuf->len;\n \t\tbid++;",
        "function_modified_lines": {
            "added": [
                "\t\tbuf->len = min_t(__u32, pbuf->len, MAX_RW_COUNT);"
            ],
            "deleted": [
                "\t\tbuf->len = pbuf->len;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The io_uring subsystem in the Linux kernel allowed the MAX_RW_COUNT limit to be bypassed in the PROVIDE_BUFFERS operation, which led to negative values being usedin mem_rw when reading /proc/<PID>/mem. This could be used to create a heap overflow leading to arbitrary code execution in the kernel. It was addressed via commit d1f82808877b (\"io_uring: truncate lengths larger than MAX_RW_COUNT on provide buffers\") (v5.13-rc1) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. It was introduced in ddf0322db79c (\"io_uring: add IORING_OP_PROVIDE_BUFFERS\") (v5.7-rc1)."
    },
    {
        "cve_id": "CVE-2021-3501",
        "code_before_change": "static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunion vmx_exit_reason exit_reason = vmx->exit_reason;\n\tu32 vectoring_info = vmx->idt_vectoring_info;\n\tu16 exit_handler_index;\n\n\t/*\n\t * Flush logged GPAs PML buffer, this will make dirty_bitmap more\n\t * updated. Another good is, in kvm_vm_ioctl_get_dirty_log, before\n\t * querying dirty_bitmap, we only need to kick all vcpus out of guest\n\t * mode as if vcpus is in root mode, the PML buffer must has been\n\t * flushed already.  Note, PML is never enabled in hardware while\n\t * running L2.\n\t */\n\tif (enable_pml && !is_guest_mode(vcpu))\n\t\tvmx_flush_pml_buffer(vcpu);\n\n\t/*\n\t * We should never reach this point with a pending nested VM-Enter, and\n\t * more specifically emulation of L2 due to invalid guest state (see\n\t * below) should never happen as that means we incorrectly allowed a\n\t * nested VM-Enter with an invalid vmcs12.\n\t */\n\tWARN_ON_ONCE(vmx->nested.nested_run_pending);\n\n\t/* If guest state is invalid, start emulating */\n\tif (vmx->emulation_required)\n\t\treturn handle_invalid_guest_state(vcpu);\n\n\tif (is_guest_mode(vcpu)) {\n\t\t/*\n\t\t * PML is never enabled when running L2, bail immediately if a\n\t\t * PML full exit occurs as something is horribly wrong.\n\t\t */\n\t\tif (exit_reason.basic == EXIT_REASON_PML_FULL)\n\t\t\tgoto unexpected_vmexit;\n\n\t\t/*\n\t\t * The host physical addresses of some pages of guest memory\n\t\t * are loaded into the vmcs02 (e.g. vmcs12's Virtual APIC\n\t\t * Page). The CPU may write to these pages via their host\n\t\t * physical address while L2 is running, bypassing any\n\t\t * address-translation-based dirty tracking (e.g. EPT write\n\t\t * protection).\n\t\t *\n\t\t * Mark them dirty on every exit from L2 to prevent them from\n\t\t * getting out of sync with dirty tracking.\n\t\t */\n\t\tnested_mark_vmcs12_pages_dirty(vcpu);\n\n\t\tif (nested_vmx_reflect_vmexit(vcpu))\n\t\t\treturn 1;\n\t}\n\n\tif (exit_reason.failed_vmentry) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= exit_reason.full;\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(vmx->fail)) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= vmcs_read32(VM_INSTRUCTION_ERROR);\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Note:\n\t * Do not try to fix EXIT_REASON_EPT_MISCONFIG if it caused by\n\t * delivery event since it indicates guest is accessing MMIO.\n\t * The vm-exit can be triggered again after return to guest that\n\t * will cause infinite loop.\n\t */\n\tif ((vectoring_info & VECTORING_INFO_VALID_MASK) &&\n\t    (exit_reason.basic != EXIT_REASON_EXCEPTION_NMI &&\n\t     exit_reason.basic != EXIT_REASON_EPT_VIOLATION &&\n\t     exit_reason.basic != EXIT_REASON_PML_FULL &&\n\t     exit_reason.basic != EXIT_REASON_APIC_ACCESS &&\n\t     exit_reason.basic != EXIT_REASON_TASK_SWITCH)) {\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_DELIVERY_EV;\n\t\tvcpu->run->internal.ndata = 3;\n\t\tvcpu->run->internal.data[0] = vectoring_info;\n\t\tvcpu->run->internal.data[1] = exit_reason.full;\n\t\tvcpu->run->internal.data[2] = vcpu->arch.exit_qualification;\n\t\tif (exit_reason.basic == EXIT_REASON_EPT_MISCONFIG) {\n\t\t\tvcpu->run->internal.ndata++;\n\t\t\tvcpu->run->internal.data[3] =\n\t\t\t\tvmcs_read64(GUEST_PHYSICAL_ADDRESS);\n\t\t}\n\t\tvcpu->run->internal.data[vcpu->run->internal.ndata++] =\n\t\t\tvcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(!enable_vnmi &&\n\t\t     vmx->loaded_vmcs->soft_vnmi_blocked)) {\n\t\tif (!vmx_interrupt_blocked(vcpu)) {\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t} else if (vmx->loaded_vmcs->vnmi_blocked_time > 1000000000LL &&\n\t\t\t   vcpu->arch.nmi_pending) {\n\t\t\t/*\n\t\t\t * This CPU don't support us in finding the end of an\n\t\t\t * NMI-blocked window if the guest runs with IRQs\n\t\t\t * disabled. So we pull the trigger after 1 s of\n\t\t\t * futile waiting, but inform the user about this.\n\t\t\t */\n\t\t\tprintk(KERN_WARNING \"%s: Breaking out of NMI-blocked \"\n\t\t\t       \"state on VCPU %d after 1 s timeout\\n\",\n\t\t\t       __func__, vcpu->vcpu_id);\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t}\n\t}\n\n\tif (exit_fastpath != EXIT_FASTPATH_NONE)\n\t\treturn 1;\n\n\tif (exit_reason.basic >= kvm_vmx_max_exit_handlers)\n\t\tgoto unexpected_vmexit;\n#ifdef CONFIG_RETPOLINE\n\tif (exit_reason.basic == EXIT_REASON_MSR_WRITE)\n\t\treturn kvm_emulate_wrmsr(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_PREEMPTION_TIMER)\n\t\treturn handle_preemption_timer(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_INTERRUPT_WINDOW)\n\t\treturn handle_interrupt_window(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_EXTERNAL_INTERRUPT)\n\t\treturn handle_external_interrupt(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_HLT)\n\t\treturn kvm_emulate_halt(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_EPT_MISCONFIG)\n\t\treturn handle_ept_misconfig(vcpu);\n#endif\n\n\texit_handler_index = array_index_nospec((u16)exit_reason.basic,\n\t\t\t\t\t\tkvm_vmx_max_exit_handlers);\n\tif (!kvm_vmx_exit_handlers[exit_handler_index])\n\t\tgoto unexpected_vmexit;\n\n\treturn kvm_vmx_exit_handlers[exit_handler_index](vcpu);\n\nunexpected_vmexit:\n\tvcpu_unimpl(vcpu, \"vmx: unexpected exit reason 0x%x\\n\",\n\t\t    exit_reason.full);\n\tdump_vmcs();\n\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\tvcpu->run->internal.suberror =\n\t\t\tKVM_INTERNAL_ERROR_UNEXPECTED_EXIT_REASON;\n\tvcpu->run->internal.ndata = 2;\n\tvcpu->run->internal.data[0] = exit_reason.full;\n\tvcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;\n\treturn 0;\n}",
        "code_after_change": "static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tunion vmx_exit_reason exit_reason = vmx->exit_reason;\n\tu32 vectoring_info = vmx->idt_vectoring_info;\n\tu16 exit_handler_index;\n\n\t/*\n\t * Flush logged GPAs PML buffer, this will make dirty_bitmap more\n\t * updated. Another good is, in kvm_vm_ioctl_get_dirty_log, before\n\t * querying dirty_bitmap, we only need to kick all vcpus out of guest\n\t * mode as if vcpus is in root mode, the PML buffer must has been\n\t * flushed already.  Note, PML is never enabled in hardware while\n\t * running L2.\n\t */\n\tif (enable_pml && !is_guest_mode(vcpu))\n\t\tvmx_flush_pml_buffer(vcpu);\n\n\t/*\n\t * We should never reach this point with a pending nested VM-Enter, and\n\t * more specifically emulation of L2 due to invalid guest state (see\n\t * below) should never happen as that means we incorrectly allowed a\n\t * nested VM-Enter with an invalid vmcs12.\n\t */\n\tWARN_ON_ONCE(vmx->nested.nested_run_pending);\n\n\t/* If guest state is invalid, start emulating */\n\tif (vmx->emulation_required)\n\t\treturn handle_invalid_guest_state(vcpu);\n\n\tif (is_guest_mode(vcpu)) {\n\t\t/*\n\t\t * PML is never enabled when running L2, bail immediately if a\n\t\t * PML full exit occurs as something is horribly wrong.\n\t\t */\n\t\tif (exit_reason.basic == EXIT_REASON_PML_FULL)\n\t\t\tgoto unexpected_vmexit;\n\n\t\t/*\n\t\t * The host physical addresses of some pages of guest memory\n\t\t * are loaded into the vmcs02 (e.g. vmcs12's Virtual APIC\n\t\t * Page). The CPU may write to these pages via their host\n\t\t * physical address while L2 is running, bypassing any\n\t\t * address-translation-based dirty tracking (e.g. EPT write\n\t\t * protection).\n\t\t *\n\t\t * Mark them dirty on every exit from L2 to prevent them from\n\t\t * getting out of sync with dirty tracking.\n\t\t */\n\t\tnested_mark_vmcs12_pages_dirty(vcpu);\n\n\t\tif (nested_vmx_reflect_vmexit(vcpu))\n\t\t\treturn 1;\n\t}\n\n\tif (exit_reason.failed_vmentry) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= exit_reason.full;\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(vmx->fail)) {\n\t\tdump_vmcs();\n\t\tvcpu->run->exit_reason = KVM_EXIT_FAIL_ENTRY;\n\t\tvcpu->run->fail_entry.hardware_entry_failure_reason\n\t\t\t= vmcs_read32(VM_INSTRUCTION_ERROR);\n\t\tvcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Note:\n\t * Do not try to fix EXIT_REASON_EPT_MISCONFIG if it caused by\n\t * delivery event since it indicates guest is accessing MMIO.\n\t * The vm-exit can be triggered again after return to guest that\n\t * will cause infinite loop.\n\t */\n\tif ((vectoring_info & VECTORING_INFO_VALID_MASK) &&\n\t    (exit_reason.basic != EXIT_REASON_EXCEPTION_NMI &&\n\t     exit_reason.basic != EXIT_REASON_EPT_VIOLATION &&\n\t     exit_reason.basic != EXIT_REASON_PML_FULL &&\n\t     exit_reason.basic != EXIT_REASON_APIC_ACCESS &&\n\t     exit_reason.basic != EXIT_REASON_TASK_SWITCH)) {\n\t\tint ndata = 3;\n\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_DELIVERY_EV;\n\t\tvcpu->run->internal.data[0] = vectoring_info;\n\t\tvcpu->run->internal.data[1] = exit_reason.full;\n\t\tvcpu->run->internal.data[2] = vcpu->arch.exit_qualification;\n\t\tif (exit_reason.basic == EXIT_REASON_EPT_MISCONFIG) {\n\t\t\tvcpu->run->internal.data[ndata++] =\n\t\t\t\tvmcs_read64(GUEST_PHYSICAL_ADDRESS);\n\t\t}\n\t\tvcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;\n\t\tvcpu->run->internal.ndata = ndata;\n\t\treturn 0;\n\t}\n\n\tif (unlikely(!enable_vnmi &&\n\t\t     vmx->loaded_vmcs->soft_vnmi_blocked)) {\n\t\tif (!vmx_interrupt_blocked(vcpu)) {\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t} else if (vmx->loaded_vmcs->vnmi_blocked_time > 1000000000LL &&\n\t\t\t   vcpu->arch.nmi_pending) {\n\t\t\t/*\n\t\t\t * This CPU don't support us in finding the end of an\n\t\t\t * NMI-blocked window if the guest runs with IRQs\n\t\t\t * disabled. So we pull the trigger after 1 s of\n\t\t\t * futile waiting, but inform the user about this.\n\t\t\t */\n\t\t\tprintk(KERN_WARNING \"%s: Breaking out of NMI-blocked \"\n\t\t\t       \"state on VCPU %d after 1 s timeout\\n\",\n\t\t\t       __func__, vcpu->vcpu_id);\n\t\t\tvmx->loaded_vmcs->soft_vnmi_blocked = 0;\n\t\t}\n\t}\n\n\tif (exit_fastpath != EXIT_FASTPATH_NONE)\n\t\treturn 1;\n\n\tif (exit_reason.basic >= kvm_vmx_max_exit_handlers)\n\t\tgoto unexpected_vmexit;\n#ifdef CONFIG_RETPOLINE\n\tif (exit_reason.basic == EXIT_REASON_MSR_WRITE)\n\t\treturn kvm_emulate_wrmsr(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_PREEMPTION_TIMER)\n\t\treturn handle_preemption_timer(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_INTERRUPT_WINDOW)\n\t\treturn handle_interrupt_window(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_EXTERNAL_INTERRUPT)\n\t\treturn handle_external_interrupt(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_HLT)\n\t\treturn kvm_emulate_halt(vcpu);\n\telse if (exit_reason.basic == EXIT_REASON_EPT_MISCONFIG)\n\t\treturn handle_ept_misconfig(vcpu);\n#endif\n\n\texit_handler_index = array_index_nospec((u16)exit_reason.basic,\n\t\t\t\t\t\tkvm_vmx_max_exit_handlers);\n\tif (!kvm_vmx_exit_handlers[exit_handler_index])\n\t\tgoto unexpected_vmexit;\n\n\treturn kvm_vmx_exit_handlers[exit_handler_index](vcpu);\n\nunexpected_vmexit:\n\tvcpu_unimpl(vcpu, \"vmx: unexpected exit reason 0x%x\\n\",\n\t\t    exit_reason.full);\n\tdump_vmcs();\n\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\tvcpu->run->internal.suberror =\n\t\t\tKVM_INTERNAL_ERROR_UNEXPECTED_EXIT_REASON;\n\tvcpu->run->internal.ndata = 2;\n\tvcpu->run->internal.data[0] = exit_reason.full;\n\tvcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -84,19 +84,19 @@\n \t     exit_reason.basic != EXIT_REASON_PML_FULL &&\n \t     exit_reason.basic != EXIT_REASON_APIC_ACCESS &&\n \t     exit_reason.basic != EXIT_REASON_TASK_SWITCH)) {\n+\t\tint ndata = 3;\n+\n \t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n \t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_DELIVERY_EV;\n-\t\tvcpu->run->internal.ndata = 3;\n \t\tvcpu->run->internal.data[0] = vectoring_info;\n \t\tvcpu->run->internal.data[1] = exit_reason.full;\n \t\tvcpu->run->internal.data[2] = vcpu->arch.exit_qualification;\n \t\tif (exit_reason.basic == EXIT_REASON_EPT_MISCONFIG) {\n-\t\t\tvcpu->run->internal.ndata++;\n-\t\t\tvcpu->run->internal.data[3] =\n+\t\t\tvcpu->run->internal.data[ndata++] =\n \t\t\t\tvmcs_read64(GUEST_PHYSICAL_ADDRESS);\n \t\t}\n-\t\tvcpu->run->internal.data[vcpu->run->internal.ndata++] =\n-\t\t\tvcpu->arch.last_vmentry_cpu;\n+\t\tvcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;\n+\t\tvcpu->run->internal.ndata = ndata;\n \t\treturn 0;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tint ndata = 3;",
                "",
                "\t\t\tvcpu->run->internal.data[ndata++] =",
                "\t\tvcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;",
                "\t\tvcpu->run->internal.ndata = ndata;"
            ],
            "deleted": [
                "\t\tvcpu->run->internal.ndata = 3;",
                "\t\t\tvcpu->run->internal.ndata++;",
                "\t\t\tvcpu->run->internal.data[3] =",
                "\t\tvcpu->run->internal.data[vcpu->run->internal.ndata++] =",
                "\t\t\tvcpu->arch.last_vmentry_cpu;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in versions before 5.12. The value of internal.ndata, in the KVM API, is mapped to an array index, which can be updated by a user process at anytime which could lead to an out-of-bounds write. The highest threat from this vulnerability is to data integrity and system availability."
    },
    {
        "cve_id": "CVE-2021-3612",
        "code_before_change": "static int joydev_handle_JSIOCSBTNMAP(struct joydev *joydev,\n\t\t\t\t      void __user *argp, size_t len)\n{\n\t__u16 *keypam;\n\tint i;\n\tint retval = 0;\n\n\tlen = min(len, sizeof(joydev->keypam));\n\n\t/* Validate the map. */\n\tkeypam = memdup_user(argp, len);\n\tif (IS_ERR(keypam))\n\t\treturn PTR_ERR(keypam);\n\n\tfor (i = 0; i < joydev->nkey; i++) {\n\t\tif (keypam[i] > KEY_MAX || keypam[i] < BTN_MISC) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmemcpy(joydev->keypam, keypam, len);\n\n\tfor (i = 0; i < joydev->nkey; i++)\n\t\tjoydev->keymap[keypam[i] - BTN_MISC] = i;\n\n out:\n\tkfree(keypam);\n\treturn retval;\n}",
        "code_after_change": "static int joydev_handle_JSIOCSBTNMAP(struct joydev *joydev,\n\t\t\t\t      void __user *argp, size_t len)\n{\n\t__u16 *keypam;\n\tint i;\n\tint retval = 0;\n\n\tif (len % sizeof(*keypam))\n\t\treturn -EINVAL;\n\n\tlen = min(len, sizeof(joydev->keypam));\n\n\t/* Validate the map. */\n\tkeypam = memdup_user(argp, len);\n\tif (IS_ERR(keypam))\n\t\treturn PTR_ERR(keypam);\n\n\tfor (i = 0; i < (len / 2) && i < joydev->nkey; i++) {\n\t\tif (keypam[i] > KEY_MAX || keypam[i] < BTN_MISC) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmemcpy(joydev->keypam, keypam, len);\n\n\tfor (i = 0; i < joydev->nkey; i++)\n\t\tjoydev->keymap[keypam[i] - BTN_MISC] = i;\n\n out:\n\tkfree(keypam);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \t__u16 *keypam;\n \tint i;\n \tint retval = 0;\n+\n+\tif (len % sizeof(*keypam))\n+\t\treturn -EINVAL;\n \n \tlen = min(len, sizeof(joydev->keypam));\n \n@@ -12,7 +15,7 @@\n \tif (IS_ERR(keypam))\n \t\treturn PTR_ERR(keypam);\n \n-\tfor (i = 0; i < joydev->nkey; i++) {\n+\tfor (i = 0; i < (len / 2) && i < joydev->nkey; i++) {\n \t\tif (keypam[i] > KEY_MAX || keypam[i] < BTN_MISC) {\n \t\t\tretval = -EINVAL;\n \t\t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (len % sizeof(*keypam))",
                "\t\treturn -EINVAL;",
                "\tfor (i = 0; i < (len / 2) && i < joydev->nkey; i++) {"
            ],
            "deleted": [
                "\tfor (i = 0; i < joydev->nkey; i++) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in the Linux kernel's joystick devices subsystem in versions before 5.9-rc1, in the way the user calls ioctl JSIOCSBTNMAP. This flaw allows a local user to crash the system or possibly escalate their privileges on the system. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2021-3612",
        "code_before_change": "static int joydev_handle_JSIOCSAXMAP(struct joydev *joydev,\n\t\t\t\t     void __user *argp, size_t len)\n{\n\t__u8 *abspam;\n\tint i;\n\tint retval = 0;\n\n\tlen = min(len, sizeof(joydev->abspam));\n\n\t/* Validate the map. */\n\tabspam = memdup_user(argp, len);\n\tif (IS_ERR(abspam))\n\t\treturn PTR_ERR(abspam);\n\n\tfor (i = 0; i < joydev->nabs; i++) {\n\t\tif (abspam[i] > ABS_MAX) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmemcpy(joydev->abspam, abspam, len);\n\n\tfor (i = 0; i < joydev->nabs; i++)\n\t\tjoydev->absmap[joydev->abspam[i]] = i;\n\n out:\n\tkfree(abspam);\n\treturn retval;\n}",
        "code_after_change": "static int joydev_handle_JSIOCSAXMAP(struct joydev *joydev,\n\t\t\t\t     void __user *argp, size_t len)\n{\n\t__u8 *abspam;\n\tint i;\n\tint retval = 0;\n\n\tlen = min(len, sizeof(joydev->abspam));\n\n\t/* Validate the map. */\n\tabspam = memdup_user(argp, len);\n\tif (IS_ERR(abspam))\n\t\treturn PTR_ERR(abspam);\n\n\tfor (i = 0; i < len && i < joydev->nabs; i++) {\n\t\tif (abspam[i] > ABS_MAX) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmemcpy(joydev->abspam, abspam, len);\n\n\tfor (i = 0; i < joydev->nabs; i++)\n\t\tjoydev->absmap[joydev->abspam[i]] = i;\n\n out:\n\tkfree(abspam);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \tif (IS_ERR(abspam))\n \t\treturn PTR_ERR(abspam);\n \n-\tfor (i = 0; i < joydev->nabs; i++) {\n+\tfor (i = 0; i < len && i < joydev->nabs; i++) {\n \t\tif (abspam[i] > ABS_MAX) {\n \t\t\tretval = -EINVAL;\n \t\t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < len && i < joydev->nabs; i++) {"
            ],
            "deleted": [
                "\tfor (i = 0; i < joydev->nabs; i++) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in the Linux kernel's joystick devices subsystem in versions before 5.9-rc1, in the way the user calls ioctl JSIOCSBTNMAP. This flaw allows a local user to crash the system or possibly escalate their privileges on the system. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2021-37576",
        "code_before_change": "int kvmppc_rtas_hcall(struct kvm_vcpu *vcpu)\n{\n\tstruct rtas_token_definition *d;\n\tstruct rtas_args args;\n\trtas_arg_t *orig_rets;\n\tgpa_t args_phys;\n\tint rc;\n\n\t/*\n\t * r4 contains the guest physical address of the RTAS args\n\t * Mask off the top 4 bits since this is a guest real address\n\t */\n\targs_phys = kvmppc_get_gpr(vcpu, 4) & KVM_PAM;\n\n\tvcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);\n\trc = kvm_read_guest(vcpu->kvm, args_phys, &args, sizeof(args));\n\tsrcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);\n\tif (rc)\n\t\tgoto fail;\n\n\t/*\n\t * args->rets is a pointer into args->args. Now that we've\n\t * copied args we need to fix it up to point into our copy,\n\t * not the guest args. We also need to save the original\n\t * value so we can restore it on the way out.\n\t */\n\torig_rets = args.rets;\n\targs.rets = &args.args[be32_to_cpu(args.nargs)];\n\n\tmutex_lock(&vcpu->kvm->arch.rtas_token_lock);\n\n\trc = -ENOENT;\n\tlist_for_each_entry(d, &vcpu->kvm->arch.rtas_tokens, list) {\n\t\tif (d->token == be32_to_cpu(args.token)) {\n\t\t\td->handler->handler(vcpu, &args);\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&vcpu->kvm->arch.rtas_token_lock);\n\n\tif (rc == 0) {\n\t\targs.rets = orig_rets;\n\t\trc = kvm_write_guest(vcpu->kvm, args_phys, &args, sizeof(args));\n\t\tif (rc)\n\t\t\tgoto fail;\n\t}\n\n\treturn rc;\n\nfail:\n\t/*\n\t * We only get here if the guest has called RTAS with a bogus\n\t * args pointer. That means we can't get to the args, and so we\n\t * can't fail the RTAS call. So fail right out to userspace,\n\t * which should kill the guest.\n\t */\n\treturn rc;\n}",
        "code_after_change": "int kvmppc_rtas_hcall(struct kvm_vcpu *vcpu)\n{\n\tstruct rtas_token_definition *d;\n\tstruct rtas_args args;\n\trtas_arg_t *orig_rets;\n\tgpa_t args_phys;\n\tint rc;\n\n\t/*\n\t * r4 contains the guest physical address of the RTAS args\n\t * Mask off the top 4 bits since this is a guest real address\n\t */\n\targs_phys = kvmppc_get_gpr(vcpu, 4) & KVM_PAM;\n\n\tvcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);\n\trc = kvm_read_guest(vcpu->kvm, args_phys, &args, sizeof(args));\n\tsrcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);\n\tif (rc)\n\t\tgoto fail;\n\n\t/*\n\t * args->rets is a pointer into args->args. Now that we've\n\t * copied args we need to fix it up to point into our copy,\n\t * not the guest args. We also need to save the original\n\t * value so we can restore it on the way out.\n\t */\n\torig_rets = args.rets;\n\tif (be32_to_cpu(args.nargs) >= ARRAY_SIZE(args.args)) {\n\t\t/*\n\t\t * Don't overflow our args array: ensure there is room for\n\t\t * at least rets[0] (even if the call specifies 0 nret).\n\t\t *\n\t\t * Each handler must then check for the correct nargs and nret\n\t\t * values, but they may always return failure in rets[0].\n\t\t */\n\t\trc = -EINVAL;\n\t\tgoto fail;\n\t}\n\targs.rets = &args.args[be32_to_cpu(args.nargs)];\n\n\tmutex_lock(&vcpu->kvm->arch.rtas_token_lock);\n\n\trc = -ENOENT;\n\tlist_for_each_entry(d, &vcpu->kvm->arch.rtas_tokens, list) {\n\t\tif (d->token == be32_to_cpu(args.token)) {\n\t\t\td->handler->handler(vcpu, &args);\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&vcpu->kvm->arch.rtas_token_lock);\n\n\tif (rc == 0) {\n\t\targs.rets = orig_rets;\n\t\trc = kvm_write_guest(vcpu->kvm, args_phys, &args, sizeof(args));\n\t\tif (rc)\n\t\t\tgoto fail;\n\t}\n\n\treturn rc;\n\nfail:\n\t/*\n\t * We only get here if the guest has called RTAS with a bogus\n\t * args pointer or nargs/nret values that would overflow the\n\t * array. That means we can't get to the args, and so we can't\n\t * fail the RTAS call. So fail right out to userspace, which\n\t * should kill the guest.\n\t *\n\t * SLOF should actually pass the hcall return value from the\n\t * rtas handler call in r3, so enter_rtas could be modified to\n\t * return a failure indication in r3 and we could return such\n\t * errors to the guest rather than failing to host userspace.\n\t * However old guests that don't test for failure could then\n\t * continue silently after errors, so for now we won't do this.\n\t */\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,17 @@\n \t * value so we can restore it on the way out.\n \t */\n \torig_rets = args.rets;\n+\tif (be32_to_cpu(args.nargs) >= ARRAY_SIZE(args.args)) {\n+\t\t/*\n+\t\t * Don't overflow our args array: ensure there is room for\n+\t\t * at least rets[0] (even if the call specifies 0 nret).\n+\t\t *\n+\t\t * Each handler must then check for the correct nargs and nret\n+\t\t * values, but they may always return failure in rets[0].\n+\t\t */\n+\t\trc = -EINVAL;\n+\t\tgoto fail;\n+\t}\n \targs.rets = &args.args[be32_to_cpu(args.nargs)];\n \n \tmutex_lock(&vcpu->kvm->arch.rtas_token_lock);\n@@ -52,9 +63,17 @@\n fail:\n \t/*\n \t * We only get here if the guest has called RTAS with a bogus\n-\t * args pointer. That means we can't get to the args, and so we\n-\t * can't fail the RTAS call. So fail right out to userspace,\n-\t * which should kill the guest.\n+\t * args pointer or nargs/nret values that would overflow the\n+\t * array. That means we can't get to the args, and so we can't\n+\t * fail the RTAS call. So fail right out to userspace, which\n+\t * should kill the guest.\n+\t *\n+\t * SLOF should actually pass the hcall return value from the\n+\t * rtas handler call in r3, so enter_rtas could be modified to\n+\t * return a failure indication in r3 and we could return such\n+\t * errors to the guest rather than failing to host userspace.\n+\t * However old guests that don't test for failure could then\n+\t * continue silently after errors, so for now we won't do this.\n \t */\n \treturn rc;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (be32_to_cpu(args.nargs) >= ARRAY_SIZE(args.args)) {",
                "\t\t/*",
                "\t\t * Don't overflow our args array: ensure there is room for",
                "\t\t * at least rets[0] (even if the call specifies 0 nret).",
                "\t\t *",
                "\t\t * Each handler must then check for the correct nargs and nret",
                "\t\t * values, but they may always return failure in rets[0].",
                "\t\t */",
                "\t\trc = -EINVAL;",
                "\t\tgoto fail;",
                "\t}",
                "\t * args pointer or nargs/nret values that would overflow the",
                "\t * array. That means we can't get to the args, and so we can't",
                "\t * fail the RTAS call. So fail right out to userspace, which",
                "\t * should kill the guest.",
                "\t *",
                "\t * SLOF should actually pass the hcall return value from the",
                "\t * rtas handler call in r3, so enter_rtas could be modified to",
                "\t * return a failure indication in r3 and we could return such",
                "\t * errors to the guest rather than failing to host userspace.",
                "\t * However old guests that don't test for failure could then",
                "\t * continue silently after errors, so for now we won't do this."
            ],
            "deleted": [
                "\t * args pointer. That means we can't get to the args, and so we",
                "\t * can't fail the RTAS call. So fail right out to userspace,",
                "\t * which should kill the guest."
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "arch/powerpc/kvm/book3s_rtas.c in the Linux kernel through 5.13.5 on the powerpc platform allows KVM guest OS users to cause host OS memory corruption via rtas_args.nargs, aka CID-f62f3c20647e."
    },
    {
        "cve_id": "CVE-2021-38166",
        "code_before_change": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc(key_size * bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc(value_size * bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_lock(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\tbpf_lru_push_free(&htab->lru, &l->lru_node);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
        "code_after_change": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_lock(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\tbpf_lru_push_free(&htab->lru, &l->lru_node);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,8 +61,8 @@\n \t/* We cannot do copy_from_user or copy_to_user inside\n \t * the rcu_read_lock. Allocate enough space here.\n \t */\n-\tkeys = kvmalloc(key_size * bucket_size, GFP_USER | __GFP_NOWARN);\n-\tvalues = kvmalloc(value_size * bucket_size, GFP_USER | __GFP_NOWARN);\n+\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n+\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n \tif (!keys || !values) {\n \t\tret = -ENOMEM;\n \t\tgoto after_loop;",
        "function_modified_lines": {
            "added": [
                "\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);",
                "\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);"
            ],
            "deleted": [
                "\tkeys = kvmalloc(key_size * bucket_size, GFP_USER | __GFP_NOWARN);",
                "\tvalues = kvmalloc(value_size * bucket_size, GFP_USER | __GFP_NOWARN);"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-190"
        ],
        "cve_description": "In kernel/bpf/hashtab.c in the Linux kernel through 5.13.8, there is an integer overflow and out-of-bounds write when many elements are placed in a single bucket. NOTE: exploitation might be impractical without the CAP_SYS_ADMIN capability."
    },
    {
        "cve_id": "CVE-2021-39685",
        "code_before_change": "int\ncomposite_setup(struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_composite_dev\t*cdev = get_gadget_data(gadget);\n\tstruct usb_request\t\t*req = cdev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tint\t\t\t\tstatus = 0;\n\tu16\t\t\t\tw_index = le16_to_cpu(ctrl->wIndex);\n\tu8\t\t\t\tintf = w_index & 0xFF;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\tstruct usb_function\t\t*f = NULL;\n\tu8\t\t\t\tendp;\n\n\t/* partial re-init of the response message; the function or the\n\t * gadget might need to intercept e.g. a control-OUT completion\n\t * when we delegate to it.\n\t */\n\treq->zero = 0;\n\treq->context = cdev;\n\treq->complete = composite_setup_complete;\n\treq->length = 0;\n\tgadget->ep0->driver_data = cdev;\n\n\t/*\n\t * Don't let non-standard requests match any of the cases below\n\t * by accident.\n\t */\n\tif ((ctrl->bRequestType & USB_TYPE_MASK) != USB_TYPE_STANDARD)\n\t\tgoto unknown;\n\n\tswitch (ctrl->bRequest) {\n\n\t/* we handle all standard USB descriptors */\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tcdev->desc.bNumConfigurations =\n\t\t\t\tcount_configs(cdev, USB_DT_DEVICE);\n\t\t\tcdev->desc.bMaxPacketSize0 =\n\t\t\t\tcdev->gadget->ep0->maxpacket;\n\t\t\tif (gadget_is_superspeed(gadget)) {\n\t\t\t\tif (gadget->speed >= USB_SPEED_SUPER) {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0320);\n\t\t\t\t\tcdev->desc.bMaxPacketSize0 = 9;\n\t\t\t\t} else {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0210);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (gadget->lpm_capable)\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0201);\n\t\t\t\telse\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0200);\n\t\t\t}\n\n\t\t\tvalue = min(w_length, (u16) sizeof cdev->desc);\n\t\t\tmemcpy(req->buf, &cdev->desc, value);\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tdevice_qual(cdev);\n\t\t\tvalue = min_t(int, w_length,\n\t\t\t\tsizeof(struct usb_qualifier_descriptor));\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_desc(cdev, w_value);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tvalue = get_string(cdev, req->buf,\n\t\t\t\t\tw_index, w_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_BOS:\n\t\t\tif (gadget_is_superspeed(gadget) ||\n\t\t\t    gadget->lpm_capable) {\n\t\t\t\tvalue = bos_desc(cdev);\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase USB_DT_OTG:\n\t\t\tif (gadget_is_otg(gadget)) {\n\t\t\t\tstruct usb_configuration *config;\n\t\t\t\tint otg_desc_len = 0;\n\n\t\t\t\tif (cdev->config)\n\t\t\t\t\tconfig = cdev->config;\n\t\t\t\telse\n\t\t\t\t\tconfig = list_first_entry(\n\t\t\t\t\t\t\t&cdev->configs,\n\t\t\t\t\t\tstruct usb_configuration, list);\n\t\t\t\tif (!config)\n\t\t\t\t\tgoto done;\n\n\t\t\t\tif (gadget->otg_caps &&\n\t\t\t\t\t(gadget->otg_caps->otg_rev >= 0x0200))\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg20_descriptor);\n\t\t\t\telse\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg_descriptor);\n\n\t\t\t\tvalue = min_t(int, w_length, otg_desc_len);\n\t\t\t\tmemcpy(req->buf, config->descriptors[0], value);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* any number of configs can work */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unknown;\n\t\tif (gadget_is_otg(gadget)) {\n\t\t\tif (gadget->a_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP available\\n\");\n\t\t\telse if (gadget->a_alt_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP on another port\\n\");\n\t\t\telse\n\t\t\t\tVDBG(cdev, \"HNP inactive\\n\");\n\t\t}\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = set_config(cdev, ctrl, w_value);\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tif (cdev->config)\n\t\t\t*(u8 *)req->buf = cdev->config->bConfigurationValue;\n\t\telse\n\t\t\t*(u8 *)req->buf = 0;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\n\t/* function drivers must handle get/set altsetting */\n\tcase USB_REQ_SET_INTERFACE:\n\t\tif (ctrl->bRequestType != USB_RECIP_INTERFACE)\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If there's no get_alt() method, we know only altsetting zero\n\t\t * works. There is no need to check if set_alt() is not NULL\n\t\t * as we check this in usb_add_function().\n\t\t */\n\t\tif (w_value && !f->get_alt)\n\t\t\tbreak;\n\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = f->set_alt(f, w_index, w_value);\n\t\tif (value == USB_GADGET_DELAYED_STATUS) {\n\t\t\tDBG(cdev,\n\t\t\t \"%s: interface %d (%s) requested delayed status\\n\",\n\t\t\t\t\t__func__, intf, f->name);\n\t\t\tcdev->delayed_status++;\n\t\t\tDBG(cdev, \"delayed_status count %d\\n\",\n\t\t\t\t\tcdev->delayed_status);\n\t\t}\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_INTERFACE:\n\t\tif (ctrl->bRequestType != (USB_DIR_IN|USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\t/* lots of interfaces only need altsetting zero... */\n\t\tvalue = f->get_alt ? f->get_alt(f, w_index) : 0;\n\t\tif (value < 0)\n\t\t\tbreak;\n\t\t*((u8 *)req->buf) = value;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\tcase USB_REQ_GET_STATUS:\n\t\tif (gadget_is_otg(gadget) && gadget->hnp_polling_support &&\n\t\t\t\t\t\t(w_index == OTG_STS_SELECTOR)) {\n\t\t\tif (ctrl->bRequestType != (USB_DIR_IN |\n\t\t\t\t\t\t\tUSB_RECIP_DEVICE))\n\t\t\t\tgoto unknown;\n\t\t\t*((u8 *)req->buf) = gadget->host_request_flag;\n\t\t\tvalue = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * USB 3.0 additions:\n\t\t * Function driver should handle get_status request. If such cb\n\t\t * wasn't supplied we respond with default value = 0\n\t\t * Note: function driver should supply such cb only for the\n\t\t * first interface of the function\n\t\t */\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_IN | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tvalue = 2;\t/* This is the length of the get_status reply */\n\t\tput_unaligned_le16(0, req->buf);\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\tstatus = f->get_status ? f->get_status(f) : 0;\n\t\tif (status < 0)\n\t\t\tbreak;\n\t\tput_unaligned_le16(status & 0x0000ffff, req->buf);\n\t\tbreak;\n\t/*\n\t * Function drivers should handle SetFeature/ClearFeature\n\t * (FUNCTION_SUSPEND) request. function_suspend cb should be supplied\n\t * only for the first interface of the function\n\t */\n\tcase USB_REQ_CLEAR_FEATURE:\n\tcase USB_REQ_SET_FEATURE:\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_OUT | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tswitch (w_value) {\n\t\tcase USB_INTRF_FUNC_SUSPEND:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tif (!f)\n\t\t\t\tbreak;\n\t\t\tvalue = 0;\n\t\t\tif (f->func_suspend)\n\t\t\t\tvalue = f->func_suspend(f, w_index >> 8);\n\t\t\tif (value < 0) {\n\t\t\t\tERROR(cdev,\n\t\t\t\t      \"func_suspend() returned error %d\\n\",\n\t\t\t\t      value);\n\t\t\t\tvalue = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\nunknown:\n\t\t/*\n\t\t * OS descriptors handling\n\t\t */\n\t\tif (cdev->use_os_string && cdev->os_desc_config &&\n\t\t    (ctrl->bRequestType & USB_TYPE_VENDOR) &&\n\t\t    ctrl->bRequest == cdev->b_vendor_code) {\n\t\t\tstruct usb_configuration\t*os_desc_cfg;\n\t\t\tu8\t\t\t\t*buf;\n\t\t\tint\t\t\t\tinterface;\n\t\t\tint\t\t\t\tcount = 0;\n\n\t\t\treq = cdev->os_desc_req;\n\t\t\treq->context = cdev;\n\t\t\treq->complete = composite_setup_complete;\n\t\t\tbuf = req->buf;\n\t\t\tos_desc_cfg = cdev->os_desc_config;\n\t\t\tw_length = min_t(u16, w_length, USB_COMP_EP0_OS_DESC_BUFSIZ);\n\t\t\tmemset(buf, 0, w_length);\n\t\t\tbuf[5] = 0x01;\n\t\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\t\tcase USB_RECIP_DEVICE:\n\t\t\t\tif (w_index != 0x4 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\t/* Number of ext compat interfaces */\n\t\t\t\tcount = count_ext_compat(os_desc_cfg);\n\t\t\t\tbuf[8] = count;\n\t\t\t\tcount *= 24; /* 24 B/ext compat desc */\n\t\t\t\tcount += 16; /* header */\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x10) {\n\t\t\t\t\tvalue = fill_ext_compat(os_desc_cfg, buf);\n\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase USB_RECIP_INTERFACE:\n\t\t\t\tif (w_index != 0x5 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tinterface = w_value & 0xFF;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\tcount = count_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le16(count, buf + 8);\n\t\t\t\tcount = len_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x0A) {\n\t\t\t\t\tvalue = fill_ext_prop(os_desc_cfg,\n\t\t\t\t\t\t\t      interface, buf);\n\t\t\t\t\tif (value >= 0)\n\t\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgoto check_value;\n\t\t}\n\n\t\tVDBG(cdev,\n\t\t\t\"non-core control req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, w_index, w_length);\n\n\t\t/* functions always handle their interfaces and endpoints...\n\t\t * punt other recipients (other, WUSB, ...) to the current\n\t\t * configuration code.\n\t\t */\n\t\tif (cdev->config) {\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list)\n\t\t\t\tif (f->req_match &&\n\t\t\t\t    f->req_match(f, ctrl, false))\n\t\t\t\t\tgoto try_fun_setup;\n\t\t} else {\n\t\t\tstruct usb_configuration *c;\n\t\t\tlist_for_each_entry(c, &cdev->configs, list)\n\t\t\t\tlist_for_each_entry(f, &c->functions, list)\n\t\t\t\t\tif (f->req_match &&\n\t\t\t\t\t    f->req_match(f, ctrl, true))\n\t\t\t\t\t\tgoto try_fun_setup;\n\t\t}\n\t\tf = NULL;\n\n\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\tcase USB_RECIP_INTERFACE:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tbreak;\n\n\t\tcase USB_RECIP_ENDPOINT:\n\t\t\tif (!cdev->config)\n\t\t\t\tbreak;\n\t\t\tendp = ((w_index & 0x80) >> 3) | (w_index & 0x0f);\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list) {\n\t\t\t\tif (test_bit(endp, f->endpoints))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (&f->list == &cdev->config->functions)\n\t\t\t\tf = NULL;\n\t\t\tbreak;\n\t\t}\ntry_fun_setup:\n\t\tif (f && f->setup)\n\t\t\tvalue = f->setup(f, ctrl);\n\t\telse {\n\t\t\tstruct usb_configuration\t*c;\n\n\t\t\tc = cdev->config;\n\t\t\tif (!c)\n\t\t\t\tgoto done;\n\n\t\t\t/* try current config's setup */\n\t\t\tif (c->setup) {\n\t\t\t\tvalue = c->setup(c, ctrl);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* try the only function in the current config */\n\t\t\tif (!list_is_singular(&c->functions))\n\t\t\t\tgoto done;\n\t\t\tf = list_first_entry(&c->functions, struct usb_function,\n\t\t\t\t\t     list);\n\t\t\tif (f->setup)\n\t\t\t\tvalue = f->setup(f, ctrl);\n\t\t}\n\n\t\tgoto done;\n\t}\n\ncheck_value:\n\t/* respond with data transfer before status phase? */\n\tif (value >= 0 && value != USB_GADGET_DELAYED_STATUS) {\n\t\treq->length = value;\n\t\treq->context = cdev;\n\t\treq->zero = value < w_length;\n\t\tvalue = composite_ep0_queue(cdev, req, GFP_ATOMIC);\n\t\tif (value < 0) {\n\t\t\tDBG(cdev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t\tcomposite_setup_complete(gadget->ep0, req);\n\t\t}\n\t} else if (value == USB_GADGET_DELAYED_STATUS && w_length != 0) {\n\t\tWARN(cdev,\n\t\t\t\"%s: Delayed status not supported for w_length != 0\",\n\t\t\t__func__);\n\t}\n\ndone:\n\t/* device either stalls (value < 0) or reports success */\n\treturn value;\n}",
        "code_after_change": "int\ncomposite_setup(struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_composite_dev\t*cdev = get_gadget_data(gadget);\n\tstruct usb_request\t\t*req = cdev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tint\t\t\t\tstatus = 0;\n\tu16\t\t\t\tw_index = le16_to_cpu(ctrl->wIndex);\n\tu8\t\t\t\tintf = w_index & 0xFF;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\tstruct usb_function\t\t*f = NULL;\n\tu8\t\t\t\tendp;\n\n\tif (w_length > USB_COMP_EP0_BUFSIZ) {\n\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n\t\t\tgoto done;\n\t\t} else {\n\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n\n\t\t\t*temp = cpu_to_le16(USB_COMP_EP0_BUFSIZ);\n\t\t\tw_length = USB_COMP_EP0_BUFSIZ;\n\t\t}\n\t}\n\n\t/* partial re-init of the response message; the function or the\n\t * gadget might need to intercept e.g. a control-OUT completion\n\t * when we delegate to it.\n\t */\n\treq->zero = 0;\n\treq->context = cdev;\n\treq->complete = composite_setup_complete;\n\treq->length = 0;\n\tgadget->ep0->driver_data = cdev;\n\n\t/*\n\t * Don't let non-standard requests match any of the cases below\n\t * by accident.\n\t */\n\tif ((ctrl->bRequestType & USB_TYPE_MASK) != USB_TYPE_STANDARD)\n\t\tgoto unknown;\n\n\tswitch (ctrl->bRequest) {\n\n\t/* we handle all standard USB descriptors */\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tcdev->desc.bNumConfigurations =\n\t\t\t\tcount_configs(cdev, USB_DT_DEVICE);\n\t\t\tcdev->desc.bMaxPacketSize0 =\n\t\t\t\tcdev->gadget->ep0->maxpacket;\n\t\t\tif (gadget_is_superspeed(gadget)) {\n\t\t\t\tif (gadget->speed >= USB_SPEED_SUPER) {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0320);\n\t\t\t\t\tcdev->desc.bMaxPacketSize0 = 9;\n\t\t\t\t} else {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0210);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (gadget->lpm_capable)\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0201);\n\t\t\t\telse\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0200);\n\t\t\t}\n\n\t\t\tvalue = min(w_length, (u16) sizeof cdev->desc);\n\t\t\tmemcpy(req->buf, &cdev->desc, value);\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tdevice_qual(cdev);\n\t\t\tvalue = min_t(int, w_length,\n\t\t\t\tsizeof(struct usb_qualifier_descriptor));\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_desc(cdev, w_value);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tvalue = get_string(cdev, req->buf,\n\t\t\t\t\tw_index, w_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_BOS:\n\t\t\tif (gadget_is_superspeed(gadget) ||\n\t\t\t    gadget->lpm_capable) {\n\t\t\t\tvalue = bos_desc(cdev);\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase USB_DT_OTG:\n\t\t\tif (gadget_is_otg(gadget)) {\n\t\t\t\tstruct usb_configuration *config;\n\t\t\t\tint otg_desc_len = 0;\n\n\t\t\t\tif (cdev->config)\n\t\t\t\t\tconfig = cdev->config;\n\t\t\t\telse\n\t\t\t\t\tconfig = list_first_entry(\n\t\t\t\t\t\t\t&cdev->configs,\n\t\t\t\t\t\tstruct usb_configuration, list);\n\t\t\t\tif (!config)\n\t\t\t\t\tgoto done;\n\n\t\t\t\tif (gadget->otg_caps &&\n\t\t\t\t\t(gadget->otg_caps->otg_rev >= 0x0200))\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg20_descriptor);\n\t\t\t\telse\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg_descriptor);\n\n\t\t\t\tvalue = min_t(int, w_length, otg_desc_len);\n\t\t\t\tmemcpy(req->buf, config->descriptors[0], value);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* any number of configs can work */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unknown;\n\t\tif (gadget_is_otg(gadget)) {\n\t\t\tif (gadget->a_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP available\\n\");\n\t\t\telse if (gadget->a_alt_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP on another port\\n\");\n\t\t\telse\n\t\t\t\tVDBG(cdev, \"HNP inactive\\n\");\n\t\t}\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = set_config(cdev, ctrl, w_value);\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tif (cdev->config)\n\t\t\t*(u8 *)req->buf = cdev->config->bConfigurationValue;\n\t\telse\n\t\t\t*(u8 *)req->buf = 0;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\n\t/* function drivers must handle get/set altsetting */\n\tcase USB_REQ_SET_INTERFACE:\n\t\tif (ctrl->bRequestType != USB_RECIP_INTERFACE)\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If there's no get_alt() method, we know only altsetting zero\n\t\t * works. There is no need to check if set_alt() is not NULL\n\t\t * as we check this in usb_add_function().\n\t\t */\n\t\tif (w_value && !f->get_alt)\n\t\t\tbreak;\n\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = f->set_alt(f, w_index, w_value);\n\t\tif (value == USB_GADGET_DELAYED_STATUS) {\n\t\t\tDBG(cdev,\n\t\t\t \"%s: interface %d (%s) requested delayed status\\n\",\n\t\t\t\t\t__func__, intf, f->name);\n\t\t\tcdev->delayed_status++;\n\t\t\tDBG(cdev, \"delayed_status count %d\\n\",\n\t\t\t\t\tcdev->delayed_status);\n\t\t}\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_INTERFACE:\n\t\tif (ctrl->bRequestType != (USB_DIR_IN|USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\t/* lots of interfaces only need altsetting zero... */\n\t\tvalue = f->get_alt ? f->get_alt(f, w_index) : 0;\n\t\tif (value < 0)\n\t\t\tbreak;\n\t\t*((u8 *)req->buf) = value;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\tcase USB_REQ_GET_STATUS:\n\t\tif (gadget_is_otg(gadget) && gadget->hnp_polling_support &&\n\t\t\t\t\t\t(w_index == OTG_STS_SELECTOR)) {\n\t\t\tif (ctrl->bRequestType != (USB_DIR_IN |\n\t\t\t\t\t\t\tUSB_RECIP_DEVICE))\n\t\t\t\tgoto unknown;\n\t\t\t*((u8 *)req->buf) = gadget->host_request_flag;\n\t\t\tvalue = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * USB 3.0 additions:\n\t\t * Function driver should handle get_status request. If such cb\n\t\t * wasn't supplied we respond with default value = 0\n\t\t * Note: function driver should supply such cb only for the\n\t\t * first interface of the function\n\t\t */\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_IN | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tvalue = 2;\t/* This is the length of the get_status reply */\n\t\tput_unaligned_le16(0, req->buf);\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\tstatus = f->get_status ? f->get_status(f) : 0;\n\t\tif (status < 0)\n\t\t\tbreak;\n\t\tput_unaligned_le16(status & 0x0000ffff, req->buf);\n\t\tbreak;\n\t/*\n\t * Function drivers should handle SetFeature/ClearFeature\n\t * (FUNCTION_SUSPEND) request. function_suspend cb should be supplied\n\t * only for the first interface of the function\n\t */\n\tcase USB_REQ_CLEAR_FEATURE:\n\tcase USB_REQ_SET_FEATURE:\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_OUT | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tswitch (w_value) {\n\t\tcase USB_INTRF_FUNC_SUSPEND:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tif (!f)\n\t\t\t\tbreak;\n\t\t\tvalue = 0;\n\t\t\tif (f->func_suspend)\n\t\t\t\tvalue = f->func_suspend(f, w_index >> 8);\n\t\t\tif (value < 0) {\n\t\t\t\tERROR(cdev,\n\t\t\t\t      \"func_suspend() returned error %d\\n\",\n\t\t\t\t      value);\n\t\t\t\tvalue = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\nunknown:\n\t\t/*\n\t\t * OS descriptors handling\n\t\t */\n\t\tif (cdev->use_os_string && cdev->os_desc_config &&\n\t\t    (ctrl->bRequestType & USB_TYPE_VENDOR) &&\n\t\t    ctrl->bRequest == cdev->b_vendor_code) {\n\t\t\tstruct usb_configuration\t*os_desc_cfg;\n\t\t\tu8\t\t\t\t*buf;\n\t\t\tint\t\t\t\tinterface;\n\t\t\tint\t\t\t\tcount = 0;\n\n\t\t\treq = cdev->os_desc_req;\n\t\t\treq->context = cdev;\n\t\t\treq->complete = composite_setup_complete;\n\t\t\tbuf = req->buf;\n\t\t\tos_desc_cfg = cdev->os_desc_config;\n\t\t\tw_length = min_t(u16, w_length, USB_COMP_EP0_OS_DESC_BUFSIZ);\n\t\t\tmemset(buf, 0, w_length);\n\t\t\tbuf[5] = 0x01;\n\t\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\t\tcase USB_RECIP_DEVICE:\n\t\t\t\tif (w_index != 0x4 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\t/* Number of ext compat interfaces */\n\t\t\t\tcount = count_ext_compat(os_desc_cfg);\n\t\t\t\tbuf[8] = count;\n\t\t\t\tcount *= 24; /* 24 B/ext compat desc */\n\t\t\t\tcount += 16; /* header */\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x10) {\n\t\t\t\t\tvalue = fill_ext_compat(os_desc_cfg, buf);\n\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase USB_RECIP_INTERFACE:\n\t\t\t\tif (w_index != 0x5 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tinterface = w_value & 0xFF;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\tcount = count_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le16(count, buf + 8);\n\t\t\t\tcount = len_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x0A) {\n\t\t\t\t\tvalue = fill_ext_prop(os_desc_cfg,\n\t\t\t\t\t\t\t      interface, buf);\n\t\t\t\t\tif (value >= 0)\n\t\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgoto check_value;\n\t\t}\n\n\t\tVDBG(cdev,\n\t\t\t\"non-core control req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, w_index, w_length);\n\n\t\t/* functions always handle their interfaces and endpoints...\n\t\t * punt other recipients (other, WUSB, ...) to the current\n\t\t * configuration code.\n\t\t */\n\t\tif (cdev->config) {\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list)\n\t\t\t\tif (f->req_match &&\n\t\t\t\t    f->req_match(f, ctrl, false))\n\t\t\t\t\tgoto try_fun_setup;\n\t\t} else {\n\t\t\tstruct usb_configuration *c;\n\t\t\tlist_for_each_entry(c, &cdev->configs, list)\n\t\t\t\tlist_for_each_entry(f, &c->functions, list)\n\t\t\t\t\tif (f->req_match &&\n\t\t\t\t\t    f->req_match(f, ctrl, true))\n\t\t\t\t\t\tgoto try_fun_setup;\n\t\t}\n\t\tf = NULL;\n\n\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\tcase USB_RECIP_INTERFACE:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tbreak;\n\n\t\tcase USB_RECIP_ENDPOINT:\n\t\t\tif (!cdev->config)\n\t\t\t\tbreak;\n\t\t\tendp = ((w_index & 0x80) >> 3) | (w_index & 0x0f);\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list) {\n\t\t\t\tif (test_bit(endp, f->endpoints))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (&f->list == &cdev->config->functions)\n\t\t\t\tf = NULL;\n\t\t\tbreak;\n\t\t}\ntry_fun_setup:\n\t\tif (f && f->setup)\n\t\t\tvalue = f->setup(f, ctrl);\n\t\telse {\n\t\t\tstruct usb_configuration\t*c;\n\n\t\t\tc = cdev->config;\n\t\t\tif (!c)\n\t\t\t\tgoto done;\n\n\t\t\t/* try current config's setup */\n\t\t\tif (c->setup) {\n\t\t\t\tvalue = c->setup(c, ctrl);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* try the only function in the current config */\n\t\t\tif (!list_is_singular(&c->functions))\n\t\t\t\tgoto done;\n\t\t\tf = list_first_entry(&c->functions, struct usb_function,\n\t\t\t\t\t     list);\n\t\t\tif (f->setup)\n\t\t\t\tvalue = f->setup(f, ctrl);\n\t\t}\n\n\t\tgoto done;\n\t}\n\ncheck_value:\n\t/* respond with data transfer before status phase? */\n\tif (value >= 0 && value != USB_GADGET_DELAYED_STATUS) {\n\t\treq->length = value;\n\t\treq->context = cdev;\n\t\treq->zero = value < w_length;\n\t\tvalue = composite_ep0_queue(cdev, req, GFP_ATOMIC);\n\t\tif (value < 0) {\n\t\t\tDBG(cdev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t\tcomposite_setup_complete(gadget->ep0, req);\n\t\t}\n\t} else if (value == USB_GADGET_DELAYED_STATUS && w_length != 0) {\n\t\tWARN(cdev,\n\t\t\t\"%s: Delayed status not supported for w_length != 0\",\n\t\t\t__func__);\n\t}\n\ndone:\n\t/* device either stalls (value < 0) or reports success */\n\treturn value;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,18 @@\n \tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n \tstruct usb_function\t\t*f = NULL;\n \tu8\t\t\t\tendp;\n+\n+\tif (w_length > USB_COMP_EP0_BUFSIZ) {\n+\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n+\t\t\tgoto done;\n+\t\t} else {\n+\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n+\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n+\n+\t\t\t*temp = cpu_to_le16(USB_COMP_EP0_BUFSIZ);\n+\t\t\tw_length = USB_COMP_EP0_BUFSIZ;\n+\t\t}\n+\t}\n \n \t/* partial re-init of the response message; the function or the\n \t * gadget might need to intercept e.g. a control-OUT completion",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (w_length > USB_COMP_EP0_BUFSIZ) {",
                "\t\tif (ctrl->bRequestType == USB_DIR_OUT) {",
                "\t\t\tgoto done;",
                "\t\t} else {",
                "\t\t\t/* Cast away the const, we are going to overwrite on purpose. */",
                "\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;",
                "",
                "\t\t\t*temp = cpu_to_le16(USB_COMP_EP0_BUFSIZ);",
                "\t\t\tw_length = USB_COMP_EP0_BUFSIZ;",
                "\t\t}",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various setup methods of the USB gadget subsystem, there is a possible out of bounds write due to an incorrect flag check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-210292376References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2021-39685",
        "code_before_change": "static int dbgp_setup(struct usb_gadget *gadget,\n\t\t      const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_request *req = dbgp.req;\n\tu8 request = ctrl->bRequest;\n\tu16 value = le16_to_cpu(ctrl->wValue);\n\tu16 length = le16_to_cpu(ctrl->wLength);\n\tint err = -EOPNOTSUPP;\n\tvoid *data = NULL;\n\tu16 len = 0;\n\n\tif (request == USB_REQ_GET_DESCRIPTOR) {\n\t\tswitch (value>>8) {\n\t\tcase USB_DT_DEVICE:\n\t\t\tdev_dbg(&dbgp.gadget->dev, \"setup: desc device\\n\");\n\t\t\tlen = sizeof device_desc;\n\t\t\tdata = &device_desc;\n\t\t\tdevice_desc.bMaxPacketSize0 = gadget->ep0->maxpacket;\n\t\t\tbreak;\n\t\tcase USB_DT_DEBUG:\n\t\t\tdev_dbg(&dbgp.gadget->dev, \"setup: desc debug\\n\");\n\t\t\tlen = sizeof dbg_desc;\n\t\t\tdata = &dbg_desc;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto fail;\n\t\t}\n\t\terr = 0;\n\t} else if (request == USB_REQ_SET_FEATURE &&\n\t\t   value == USB_DEVICE_DEBUG_MODE) {\n\t\tdev_dbg(&dbgp.gadget->dev, \"setup: feat debug\\n\");\n#ifdef CONFIG_USB_G_DBGP_PRINTK\n\t\terr = dbgp_enable_ep();\n#else\n\t\terr = dbgp_configure_endpoints(gadget);\n\t\tif (err < 0) {\n\t\t\tgoto fail;\n\t\t}\n\t\terr = gserial_connect(dbgp.serial, tty_line);\n#endif\n\t\tif (err < 0)\n\t\t\tgoto fail;\n\t} else\n\t\tgoto fail;\n\n\treq->length = min(length, len);\n\treq->zero = len < req->length;\n\tif (data && req->length)\n\t\tmemcpy(req->buf, data, req->length);\n\n\treq->complete = dbgp_setup_complete;\n\treturn usb_ep_queue(gadget->ep0, req, GFP_ATOMIC);\n\nfail:\n\tdev_dbg(&dbgp.gadget->dev,\n\t\t\"setup: failure req %x v %x\\n\", request, value);\n\treturn err;\n}",
        "code_after_change": "static int dbgp_setup(struct usb_gadget *gadget,\n\t\t      const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_request *req = dbgp.req;\n\tu8 request = ctrl->bRequest;\n\tu16 value = le16_to_cpu(ctrl->wValue);\n\tu16 length = le16_to_cpu(ctrl->wLength);\n\tint err = -EOPNOTSUPP;\n\tvoid *data = NULL;\n\tu16 len = 0;\n\n\tif (length > DBGP_REQ_LEN) {\n\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n\t\t\treturn err;\n\t\t} else {\n\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n\n\t\t\t*temp = cpu_to_le16(DBGP_REQ_LEN);\n\t\t\tlength = DBGP_REQ_LEN;\n\t\t}\n\t}\n\n\n\tif (request == USB_REQ_GET_DESCRIPTOR) {\n\t\tswitch (value>>8) {\n\t\tcase USB_DT_DEVICE:\n\t\t\tdev_dbg(&dbgp.gadget->dev, \"setup: desc device\\n\");\n\t\t\tlen = sizeof device_desc;\n\t\t\tdata = &device_desc;\n\t\t\tdevice_desc.bMaxPacketSize0 = gadget->ep0->maxpacket;\n\t\t\tbreak;\n\t\tcase USB_DT_DEBUG:\n\t\t\tdev_dbg(&dbgp.gadget->dev, \"setup: desc debug\\n\");\n\t\t\tlen = sizeof dbg_desc;\n\t\t\tdata = &dbg_desc;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto fail;\n\t\t}\n\t\terr = 0;\n\t} else if (request == USB_REQ_SET_FEATURE &&\n\t\t   value == USB_DEVICE_DEBUG_MODE) {\n\t\tdev_dbg(&dbgp.gadget->dev, \"setup: feat debug\\n\");\n#ifdef CONFIG_USB_G_DBGP_PRINTK\n\t\terr = dbgp_enable_ep();\n#else\n\t\terr = dbgp_configure_endpoints(gadget);\n\t\tif (err < 0) {\n\t\t\tgoto fail;\n\t\t}\n\t\terr = gserial_connect(dbgp.serial, tty_line);\n#endif\n\t\tif (err < 0)\n\t\t\tgoto fail;\n\t} else\n\t\tgoto fail;\n\n\treq->length = min(length, len);\n\treq->zero = len < req->length;\n\tif (data && req->length)\n\t\tmemcpy(req->buf, data, req->length);\n\n\treq->complete = dbgp_setup_complete;\n\treturn usb_ep_queue(gadget->ep0, req, GFP_ATOMIC);\n\nfail:\n\tdev_dbg(&dbgp.gadget->dev,\n\t\t\"setup: failure req %x v %x\\n\", request, value);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,19 @@\n \tint err = -EOPNOTSUPP;\n \tvoid *data = NULL;\n \tu16 len = 0;\n+\n+\tif (length > DBGP_REQ_LEN) {\n+\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n+\t\t\treturn err;\n+\t\t} else {\n+\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n+\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n+\n+\t\t\t*temp = cpu_to_le16(DBGP_REQ_LEN);\n+\t\t\tlength = DBGP_REQ_LEN;\n+\t\t}\n+\t}\n+\n \n \tif (request == USB_REQ_GET_DESCRIPTOR) {\n \t\tswitch (value>>8) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (length > DBGP_REQ_LEN) {",
                "\t\tif (ctrl->bRequestType == USB_DIR_OUT) {",
                "\t\t\treturn err;",
                "\t\t} else {",
                "\t\t\t/* Cast away the const, we are going to overwrite on purpose. */",
                "\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;",
                "",
                "\t\t\t*temp = cpu_to_le16(DBGP_REQ_LEN);",
                "\t\t\tlength = DBGP_REQ_LEN;",
                "\t\t}",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various setup methods of the USB gadget subsystem, there is a possible out of bounds write due to an incorrect flag check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-210292376References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2021-39685",
        "code_before_change": "static int\ngadgetfs_setup (struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct dev_data\t\t\t*dev = get_gadget_data (gadget);\n\tstruct usb_request\t\t*req = dev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tstruct usb_gadgetfs_event\t*event;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\n\tspin_lock (&dev->lock);\n\tdev->setup_abort = 0;\n\tif (dev->state == STATE_DEV_UNCONNECTED) {\n\t\tif (gadget_is_dualspeed(gadget)\n\t\t\t\t&& gadget->speed == USB_SPEED_HIGH\n\t\t\t\t&& dev->hs_config == NULL) {\n\t\t\tspin_unlock(&dev->lock);\n\t\t\tERROR (dev, \"no high speed config??\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tdev->state = STATE_DEV_CONNECTED;\n\n\t\tINFO (dev, \"connected\\n\");\n\t\tevent = next_event (dev, GADGETFS_CONNECT);\n\t\tevent->u.speed = gadget->speed;\n\t\tep0_readable (dev);\n\n\t/* host may have given up waiting for response.  we can miss control\n\t * requests handled lower down (device/endpoint status and features);\n\t * then ep0_{read,write} will report the wrong status. controller\n\t * driver will have aborted pending i/o.\n\t */\n\t} else if (dev->state == STATE_DEV_SETUP)\n\t\tdev->setup_abort = 1;\n\n\treq->buf = dev->rbuf;\n\treq->context = NULL;\n\tswitch (ctrl->bRequest) {\n\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unrecognized;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tvalue = min (w_length, (u16) sizeof *dev->dev);\n\t\t\tdev->dev->bMaxPacketSize0 = dev->gadget->ep0->maxpacket;\n\t\t\treq->buf = dev->dev;\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!dev->hs_config)\n\t\t\t\tbreak;\n\t\t\tvalue = min (w_length, (u16)\n\t\t\t\tsizeof (struct usb_qualifier_descriptor));\n\t\t\tmake_qualifier (dev);\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_buf (dev,\n\t\t\t\t\tw_value >> 8,\n\t\t\t\t\tw_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min (w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tgoto unrecognized;\n\n\t\tdefault:\t\t// all others are errors\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* currently one config, two speeds */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unrecognized;\n\t\tif (0 == (u8) w_value) {\n\t\t\tvalue = 0;\n\t\t\tdev->current_config = 0;\n\t\t\tusb_gadget_vbus_draw(gadget, 8 /* mA */ );\n\t\t\t// user mode expected to disable endpoints\n\t\t} else {\n\t\t\tu8\tconfig, power;\n\n\t\t\tif (gadget_is_dualspeed(gadget)\n\t\t\t\t\t&& gadget->speed == USB_SPEED_HIGH) {\n\t\t\t\tconfig = dev->hs_config->bConfigurationValue;\n\t\t\t\tpower = dev->hs_config->bMaxPower;\n\t\t\t} else {\n\t\t\t\tconfig = dev->config->bConfigurationValue;\n\t\t\t\tpower = dev->config->bMaxPower;\n\t\t\t}\n\n\t\t\tif (config == (u8) w_value) {\n\t\t\t\tvalue = 0;\n\t\t\t\tdev->current_config = config;\n\t\t\t\tusb_gadget_vbus_draw(gadget, 2 * power);\n\t\t\t}\n\t\t}\n\n\t\t/* report SET_CONFIGURATION like any other control request,\n\t\t * except that usermode may not stall this.  the next\n\t\t * request mustn't be allowed start until this finishes:\n\t\t * endpoints and threads set up, etc.\n\t\t *\n\t\t * NOTE:  older PXA hardware (before PXA 255: without UDCCFR)\n\t\t * has bad/racey automagic that prevents synchronizing here.\n\t\t * even kernel mode drivers often miss them.\n\t\t */\n\t\tif (value == 0) {\n\t\t\tINFO (dev, \"configuration #%d\\n\", dev->current_config);\n\t\t\tusb_gadget_set_state(gadget, USB_STATE_CONFIGURED);\n\t\t\tif (dev->usermode_setup) {\n\t\t\t\tdev->setup_can_stall = 0;\n\t\t\t\tgoto delegate;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n#ifndef\tCONFIG_USB_PXA25X\n\t/* PXA automagically handles this request too */\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0x80)\n\t\t\tgoto unrecognized;\n\t\t*(u8 *)req->buf = dev->current_config;\n\t\tvalue = min (w_length, (u16) 1);\n\t\tbreak;\n#endif\n\n\tdefault:\nunrecognized:\n\t\tVDEBUG (dev, \"%s req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tdev->usermode_setup ? \"delegate\" : \"fail\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, le16_to_cpu(ctrl->wIndex), w_length);\n\n\t\t/* if there's an ep0 reader, don't stall */\n\t\tif (dev->usermode_setup) {\n\t\t\tdev->setup_can_stall = 1;\ndelegate:\n\t\t\tdev->setup_in = (ctrl->bRequestType & USB_DIR_IN)\n\t\t\t\t\t\t? 1 : 0;\n\t\t\tdev->setup_wLength = w_length;\n\t\t\tdev->setup_out_ready = 0;\n\t\t\tdev->setup_out_error = 0;\n\n\t\t\t/* read DATA stage for OUT right away */\n\t\t\tif (unlikely (!dev->setup_in && w_length)) {\n\t\t\t\tvalue = setup_req (gadget->ep0, dev->req,\n\t\t\t\t\t\t\tw_length);\n\t\t\t\tif (value < 0)\n\t\t\t\t\tbreak;\n\n\t\t\t\t++dev->udc_usage;\n\t\t\t\tspin_unlock (&dev->lock);\n\t\t\t\tvalue = usb_ep_queue (gadget->ep0, dev->req,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\tspin_lock (&dev->lock);\n\t\t\t\t--dev->udc_usage;\n\t\t\t\tif (value < 0) {\n\t\t\t\t\tclean_req (gadget->ep0, dev->req);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t/* we can't currently stall these */\n\t\t\t\tdev->setup_can_stall = 0;\n\t\t\t}\n\n\t\t\t/* state changes when reader collects event */\n\t\t\tevent = next_event (dev, GADGETFS_SETUP);\n\t\t\tevent->u.setup = *ctrl;\n\t\t\tep0_readable (dev);\n\t\t\tspin_unlock (&dev->lock);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* proceed with data transfer and status phases? */\n\tif (value >= 0 && dev->state != STATE_DEV_SETUP) {\n\t\treq->length = value;\n\t\treq->zero = value < w_length;\n\n\t\t++dev->udc_usage;\n\t\tspin_unlock (&dev->lock);\n\t\tvalue = usb_ep_queue (gadget->ep0, req, GFP_KERNEL);\n\t\tspin_lock(&dev->lock);\n\t\t--dev->udc_usage;\n\t\tspin_unlock(&dev->lock);\n\t\tif (value < 0) {\n\t\t\tDBG (dev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t}\n\t\treturn value;\n\t}\n\n\t/* device stalls when value < 0 */\n\tspin_unlock (&dev->lock);\n\treturn value;\n}",
        "code_after_change": "static int\ngadgetfs_setup (struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct dev_data\t\t\t*dev = get_gadget_data (gadget);\n\tstruct usb_request\t\t*req = dev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tstruct usb_gadgetfs_event\t*event;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\n\tif (w_length > RBUF_SIZE) {\n\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n\t\t\treturn value;\n\t\t} else {\n\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n\n\t\t\t*temp = cpu_to_le16(RBUF_SIZE);\n\t\t\tw_length = RBUF_SIZE;\n\t\t}\n\t}\n\n\tspin_lock (&dev->lock);\n\tdev->setup_abort = 0;\n\tif (dev->state == STATE_DEV_UNCONNECTED) {\n\t\tif (gadget_is_dualspeed(gadget)\n\t\t\t\t&& gadget->speed == USB_SPEED_HIGH\n\t\t\t\t&& dev->hs_config == NULL) {\n\t\t\tspin_unlock(&dev->lock);\n\t\t\tERROR (dev, \"no high speed config??\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tdev->state = STATE_DEV_CONNECTED;\n\n\t\tINFO (dev, \"connected\\n\");\n\t\tevent = next_event (dev, GADGETFS_CONNECT);\n\t\tevent->u.speed = gadget->speed;\n\t\tep0_readable (dev);\n\n\t/* host may have given up waiting for response.  we can miss control\n\t * requests handled lower down (device/endpoint status and features);\n\t * then ep0_{read,write} will report the wrong status. controller\n\t * driver will have aborted pending i/o.\n\t */\n\t} else if (dev->state == STATE_DEV_SETUP)\n\t\tdev->setup_abort = 1;\n\n\treq->buf = dev->rbuf;\n\treq->context = NULL;\n\tswitch (ctrl->bRequest) {\n\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unrecognized;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tvalue = min (w_length, (u16) sizeof *dev->dev);\n\t\t\tdev->dev->bMaxPacketSize0 = dev->gadget->ep0->maxpacket;\n\t\t\treq->buf = dev->dev;\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!dev->hs_config)\n\t\t\t\tbreak;\n\t\t\tvalue = min (w_length, (u16)\n\t\t\t\tsizeof (struct usb_qualifier_descriptor));\n\t\t\tmake_qualifier (dev);\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_buf (dev,\n\t\t\t\t\tw_value >> 8,\n\t\t\t\t\tw_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min (w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tgoto unrecognized;\n\n\t\tdefault:\t\t// all others are errors\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* currently one config, two speeds */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unrecognized;\n\t\tif (0 == (u8) w_value) {\n\t\t\tvalue = 0;\n\t\t\tdev->current_config = 0;\n\t\t\tusb_gadget_vbus_draw(gadget, 8 /* mA */ );\n\t\t\t// user mode expected to disable endpoints\n\t\t} else {\n\t\t\tu8\tconfig, power;\n\n\t\t\tif (gadget_is_dualspeed(gadget)\n\t\t\t\t\t&& gadget->speed == USB_SPEED_HIGH) {\n\t\t\t\tconfig = dev->hs_config->bConfigurationValue;\n\t\t\t\tpower = dev->hs_config->bMaxPower;\n\t\t\t} else {\n\t\t\t\tconfig = dev->config->bConfigurationValue;\n\t\t\t\tpower = dev->config->bMaxPower;\n\t\t\t}\n\n\t\t\tif (config == (u8) w_value) {\n\t\t\t\tvalue = 0;\n\t\t\t\tdev->current_config = config;\n\t\t\t\tusb_gadget_vbus_draw(gadget, 2 * power);\n\t\t\t}\n\t\t}\n\n\t\t/* report SET_CONFIGURATION like any other control request,\n\t\t * except that usermode may not stall this.  the next\n\t\t * request mustn't be allowed start until this finishes:\n\t\t * endpoints and threads set up, etc.\n\t\t *\n\t\t * NOTE:  older PXA hardware (before PXA 255: without UDCCFR)\n\t\t * has bad/racey automagic that prevents synchronizing here.\n\t\t * even kernel mode drivers often miss them.\n\t\t */\n\t\tif (value == 0) {\n\t\t\tINFO (dev, \"configuration #%d\\n\", dev->current_config);\n\t\t\tusb_gadget_set_state(gadget, USB_STATE_CONFIGURED);\n\t\t\tif (dev->usermode_setup) {\n\t\t\t\tdev->setup_can_stall = 0;\n\t\t\t\tgoto delegate;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n#ifndef\tCONFIG_USB_PXA25X\n\t/* PXA automagically handles this request too */\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0x80)\n\t\t\tgoto unrecognized;\n\t\t*(u8 *)req->buf = dev->current_config;\n\t\tvalue = min (w_length, (u16) 1);\n\t\tbreak;\n#endif\n\n\tdefault:\nunrecognized:\n\t\tVDEBUG (dev, \"%s req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tdev->usermode_setup ? \"delegate\" : \"fail\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, le16_to_cpu(ctrl->wIndex), w_length);\n\n\t\t/* if there's an ep0 reader, don't stall */\n\t\tif (dev->usermode_setup) {\n\t\t\tdev->setup_can_stall = 1;\ndelegate:\n\t\t\tdev->setup_in = (ctrl->bRequestType & USB_DIR_IN)\n\t\t\t\t\t\t? 1 : 0;\n\t\t\tdev->setup_wLength = w_length;\n\t\t\tdev->setup_out_ready = 0;\n\t\t\tdev->setup_out_error = 0;\n\n\t\t\t/* read DATA stage for OUT right away */\n\t\t\tif (unlikely (!dev->setup_in && w_length)) {\n\t\t\t\tvalue = setup_req (gadget->ep0, dev->req,\n\t\t\t\t\t\t\tw_length);\n\t\t\t\tif (value < 0)\n\t\t\t\t\tbreak;\n\n\t\t\t\t++dev->udc_usage;\n\t\t\t\tspin_unlock (&dev->lock);\n\t\t\t\tvalue = usb_ep_queue (gadget->ep0, dev->req,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\tspin_lock (&dev->lock);\n\t\t\t\t--dev->udc_usage;\n\t\t\t\tif (value < 0) {\n\t\t\t\t\tclean_req (gadget->ep0, dev->req);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t/* we can't currently stall these */\n\t\t\t\tdev->setup_can_stall = 0;\n\t\t\t}\n\n\t\t\t/* state changes when reader collects event */\n\t\t\tevent = next_event (dev, GADGETFS_SETUP);\n\t\t\tevent->u.setup = *ctrl;\n\t\t\tep0_readable (dev);\n\t\t\tspin_unlock (&dev->lock);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* proceed with data transfer and status phases? */\n\tif (value >= 0 && dev->state != STATE_DEV_SETUP) {\n\t\treq->length = value;\n\t\treq->zero = value < w_length;\n\n\t\t++dev->udc_usage;\n\t\tspin_unlock (&dev->lock);\n\t\tvalue = usb_ep_queue (gadget->ep0, req, GFP_KERNEL);\n\t\tspin_lock(&dev->lock);\n\t\t--dev->udc_usage;\n\t\tspin_unlock(&dev->lock);\n\t\tif (value < 0) {\n\t\t\tDBG (dev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t}\n\t\treturn value;\n\t}\n\n\t/* device stalls when value < 0 */\n\tspin_unlock (&dev->lock);\n\treturn value;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,18 @@\n \tstruct usb_gadgetfs_event\t*event;\n \tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n \tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n+\n+\tif (w_length > RBUF_SIZE) {\n+\t\tif (ctrl->bRequestType == USB_DIR_OUT) {\n+\t\t\treturn value;\n+\t\t} else {\n+\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n+\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n+\n+\t\t\t*temp = cpu_to_le16(RBUF_SIZE);\n+\t\t\tw_length = RBUF_SIZE;\n+\t\t}\n+\t}\n \n \tspin_lock (&dev->lock);\n \tdev->setup_abort = 0;",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (w_length > RBUF_SIZE) {",
                "\t\tif (ctrl->bRequestType == USB_DIR_OUT) {",
                "\t\t\treturn value;",
                "\t\t} else {",
                "\t\t\t/* Cast away the const, we are going to overwrite on purpose. */",
                "\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;",
                "",
                "\t\t\t*temp = cpu_to_le16(RBUF_SIZE);",
                "\t\t\tw_length = RBUF_SIZE;",
                "\t\t}",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In various setup methods of the USB gadget subsystem, there is a possible out of bounds write due to an incorrect flag check. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-210292376References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2021-4090",
        "code_before_change": "static __be32\nnfsd4_decode_bitmap4(struct nfsd4_compoundargs *argp, u32 *bmval, u32 bmlen)\n{\n\tu32 i, count;\n\t__be32 *p;\n\n\tif (xdr_stream_decode_u32(argp->xdr, &count) < 0)\n\t\treturn nfserr_bad_xdr;\n\t/* request sanity */\n\tif (count > 1000)\n\t\treturn nfserr_bad_xdr;\n\tp = xdr_inline_decode(argp->xdr, count << 2);\n\tif (!p)\n\t\treturn nfserr_bad_xdr;\n\ti = 0;\n\twhile (i < count)\n\t\tbmval[i++] = be32_to_cpup(p++);\n\twhile (i < bmlen)\n\t\tbmval[i++] = 0;\n\n\treturn nfs_ok;\n}",
        "code_after_change": "static __be32\nnfsd4_decode_bitmap4(struct nfsd4_compoundargs *argp, u32 *bmval, u32 bmlen)\n{\n\tu32 i, count;\n\t__be32 *p;\n\n\tif (xdr_stream_decode_u32(argp->xdr, &count) < 0)\n\t\treturn nfserr_bad_xdr;\n\t/* request sanity */\n\tif (count > 1000)\n\t\treturn nfserr_bad_xdr;\n\tp = xdr_inline_decode(argp->xdr, count << 2);\n\tif (!p)\n\t\treturn nfserr_bad_xdr;\n\tfor (i = 0; i < bmlen; i++)\n\t\tbmval[i] = (i < count) ? be32_to_cpup(p++) : 0;\n\n\treturn nfs_ok;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,11 +12,8 @@\n \tp = xdr_inline_decode(argp->xdr, count << 2);\n \tif (!p)\n \t\treturn nfserr_bad_xdr;\n-\ti = 0;\n-\twhile (i < count)\n-\t\tbmval[i++] = be32_to_cpup(p++);\n-\twhile (i < bmlen)\n-\t\tbmval[i++] = 0;\n+\tfor (i = 0; i < bmlen; i++)\n+\t\tbmval[i] = (i < count) ? be32_to_cpup(p++) : 0;\n \n \treturn nfs_ok;\n }",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < bmlen; i++)",
                "\t\tbmval[i] = (i < count) ? be32_to_cpup(p++) : 0;"
            ],
            "deleted": [
                "\ti = 0;",
                "\twhile (i < count)",
                "\t\tbmval[i++] = be32_to_cpup(p++);",
                "\twhile (i < bmlen)",
                "\t\tbmval[i++] = 0;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds (OOB) memory write flaw was found in the NFSD in the Linux kernel. Missing sanity may lead to a write beyond bmval[bmlen-1] in nfsd4_decode_bitmap4 in fs/nfsd/nfs4xdr.c. In this flaw, a local attacker with user privilege may gain access to out-of-bounds memory, leading to a system integrity and confidentiality threat."
    },
    {
        "cve_id": "CVE-2021-4093",
        "code_before_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n\tvcpu->arch.pio.count = 0;\n\n\treturn 1;\n}",
        "code_after_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tint size = vcpu->arch.pio.size;\n\tint port = vcpu->arch.pio.port;\n\n\tadvance_sev_es_emulated_ins(vcpu);\n\tif (vcpu->arch.sev_pio_count)\n\t\treturn kvm_sev_es_ins(vcpu, size, port);\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,10 @@\n static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n {\n-\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n-\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n-\tvcpu->arch.pio.count = 0;\n+\tint size = vcpu->arch.pio.size;\n+\tint port = vcpu->arch.pio.port;\n \n+\tadvance_sev_es_emulated_ins(vcpu);\n+\tif (vcpu->arch.sev_pio_count)\n+\t\treturn kvm_sev_es_ins(vcpu, size, port);\n \treturn 1;\n }",
        "function_modified_lines": {
            "added": [
                "\tint size = vcpu->arch.pio.size;",
                "\tint port = vcpu->arch.pio.port;",
                "\tadvance_sev_es_emulated_ins(vcpu);",
                "\tif (vcpu->arch.sev_pio_count)",
                "\t\treturn kvm_sev_es_ins(vcpu, size, port);"
            ],
            "deleted": [
                "\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,",
                "\t       vcpu->arch.pio.count * vcpu->arch.pio.size);",
                "\tvcpu->arch.pio.count = 0;"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the KVM's AMD code for supporting the Secure Encrypted Virtualization-Encrypted State (SEV-ES). A KVM guest using SEV-ES can trigger out-of-bounds reads and writes in the host kernel via a malicious VMGEXIT for a string I/O instruction (for example, outs or ins) using the exit reason SVM_EXIT_IOIO. This issue results in a crash of the entire system or a potential guest-to-host escape scenario."
    },
    {
        "cve_id": "CVE-2021-4093",
        "code_before_change": "int kvm_sev_es_string_io(struct kvm_vcpu *vcpu, unsigned int size,\n\t\t\t unsigned int port, void *data,  unsigned int count,\n\t\t\t int in)\n{\n\tvcpu->arch.sev_pio_data = data;\n\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)\n\t\t  : kvm_sev_es_outs(vcpu, size, port, count);\n}",
        "code_after_change": "int kvm_sev_es_string_io(struct kvm_vcpu *vcpu, unsigned int size,\n\t\t\t unsigned int port, void *data,  unsigned int count,\n\t\t\t int in)\n{\n\tvcpu->arch.sev_pio_data = data;\n\tvcpu->arch.sev_pio_count = count;\n\treturn in ? kvm_sev_es_ins(vcpu, size, port)\n\t\t  : kvm_sev_es_outs(vcpu, size, port);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n \t\t\t int in)\n {\n \tvcpu->arch.sev_pio_data = data;\n-\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)\n-\t\t  : kvm_sev_es_outs(vcpu, size, port, count);\n+\tvcpu->arch.sev_pio_count = count;\n+\treturn in ? kvm_sev_es_ins(vcpu, size, port)\n+\t\t  : kvm_sev_es_outs(vcpu, size, port);\n }",
        "function_modified_lines": {
            "added": [
                "\tvcpu->arch.sev_pio_count = count;",
                "\treturn in ? kvm_sev_es_ins(vcpu, size, port)",
                "\t\t  : kvm_sev_es_outs(vcpu, size, port);"
            ],
            "deleted": [
                "\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)",
                "\t\t  : kvm_sev_es_outs(vcpu, size, port, count);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the KVM's AMD code for supporting the Secure Encrypted Virtualization-Encrypted State (SEV-ES). A KVM guest using SEV-ES can trigger out-of-bounds reads and writes in the host kernel via a malicious VMGEXIT for a string I/O instruction (for example, outs or ins) using the exit reason SVM_EXIT_IOIO. This issue results in a crash of the entire system or a potential guest-to-host escape scenario."
    },
    {
        "cve_id": "CVE-2021-42008",
        "code_before_change": "static void decode_data(struct sixpack *sp, unsigned char inbyte)\n{\n\tunsigned char *buf;\n\n\tif (sp->rx_count != 3) {\n\t\tsp->raw_buf[sp->rx_count++] = inbyte;\n\n\t\treturn;\n\t}\n\n\tbuf = sp->raw_buf;\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\tbuf[0] | ((buf[1] << 2) & 0xc0);\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\t(buf[1] & 0x0f) | ((buf[2] << 2) & 0xf0);\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\t(buf[2] & 0x03) | (inbyte << 2);\n\tsp->rx_count = 0;\n}",
        "code_after_change": "static void decode_data(struct sixpack *sp, unsigned char inbyte)\n{\n\tunsigned char *buf;\n\n\tif (sp->rx_count != 3) {\n\t\tsp->raw_buf[sp->rx_count++] = inbyte;\n\n\t\treturn;\n\t}\n\n\tif (sp->rx_count_cooked + 2 >= sizeof(sp->cooked_buf)) {\n\t\tpr_err(\"6pack: cooked buffer overrun, data loss\\n\");\n\t\tsp->rx_count = 0;\n\t\treturn;\n\t}\n\n\tbuf = sp->raw_buf;\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\tbuf[0] | ((buf[1] << 2) & 0xc0);\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\t(buf[1] & 0x0f) | ((buf[2] << 2) & 0xf0);\n\tsp->cooked_buf[sp->rx_count_cooked++] =\n\t\t(buf[2] & 0x03) | (inbyte << 2);\n\tsp->rx_count = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,12 @@\n \tif (sp->rx_count != 3) {\n \t\tsp->raw_buf[sp->rx_count++] = inbyte;\n \n+\t\treturn;\n+\t}\n+\n+\tif (sp->rx_count_cooked + 2 >= sizeof(sp->cooked_buf)) {\n+\t\tpr_err(\"6pack: cooked buffer overrun, data loss\\n\");\n+\t\tsp->rx_count = 0;\n \t\treturn;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\treturn;",
                "\t}",
                "",
                "\tif (sp->rx_count_cooked + 2 >= sizeof(sp->cooked_buf)) {",
                "\t\tpr_err(\"6pack: cooked buffer overrun, data loss\\n\");",
                "\t\tsp->rx_count = 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The decode_data function in drivers/net/hamradio/6pack.c in the Linux kernel before 5.13.13 has a slab out-of-bounds write. Input from a process that has the CAP_NET_ADMIN capability can lead to root access."
    },
    {
        "cve_id": "CVE-2021-42327",
        "code_before_change": "static ssize_t dp_link_settings_write(struct file *f, const char __user *buf,\n\t\t\t\t size_t size, loff_t *pos)\n{\n\tstruct amdgpu_dm_connector *connector = file_inode(f)->i_private;\n\tstruct dc_link *link = connector->dc_link;\n\tstruct dc_link_settings prefer_link_settings;\n\tchar *wr_buf = NULL;\n\tconst uint32_t wr_buf_size = 40;\n\t/* 0: lane_count; 1: link_rate */\n\tint max_param_num = 2;\n\tuint8_t param_nums = 0;\n\tlong param[2];\n\tbool valid_input = true;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\n\twr_buf = kcalloc(wr_buf_size, sizeof(char), GFP_KERNEL);\n\tif (!wr_buf)\n\t\treturn -ENOSPC;\n\n\tif (parse_write_buffer_into_params(wr_buf, size,\n\t\t\t\t\t   (long *)param, buf,\n\t\t\t\t\t   max_param_num,\n\t\t\t\t\t   &param_nums)) {\n\t\tkfree(wr_buf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (param_nums <= 0) {\n\t\tkfree(wr_buf);\n\t\tDRM_DEBUG_DRIVER(\"user data not be read\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (param[0]) {\n\tcase LANE_COUNT_ONE:\n\tcase LANE_COUNT_TWO:\n\tcase LANE_COUNT_FOUR:\n\t\tbreak;\n\tdefault:\n\t\tvalid_input = false;\n\t\tbreak;\n\t}\n\n\tswitch (param[1]) {\n\tcase LINK_RATE_LOW:\n\tcase LINK_RATE_HIGH:\n\tcase LINK_RATE_RBR2:\n\tcase LINK_RATE_HIGH2:\n\tcase LINK_RATE_HIGH3:\n\t\tbreak;\n\tdefault:\n\t\tvalid_input = false;\n\t\tbreak;\n\t}\n\n\tif (!valid_input) {\n\t\tkfree(wr_buf);\n\t\tDRM_DEBUG_DRIVER(\"Invalid Input value No HW will be programmed\\n\");\n\t\treturn size;\n\t}\n\n\t/* save user force lane_count, link_rate to preferred settings\n\t * spread spectrum will not be changed\n\t */\n\tprefer_link_settings.link_spread = link->cur_link_settings.link_spread;\n\tprefer_link_settings.use_link_rate_set = false;\n\tprefer_link_settings.lane_count = param[0];\n\tprefer_link_settings.link_rate = param[1];\n\n\tdp_retrain_link_dp_test(link, &prefer_link_settings, false);\n\n\tkfree(wr_buf);\n\treturn size;\n}",
        "code_after_change": "static ssize_t dp_link_settings_write(struct file *f, const char __user *buf,\n\t\t\t\t size_t size, loff_t *pos)\n{\n\tstruct amdgpu_dm_connector *connector = file_inode(f)->i_private;\n\tstruct dc_link *link = connector->dc_link;\n\tstruct dc_link_settings prefer_link_settings;\n\tchar *wr_buf = NULL;\n\tconst uint32_t wr_buf_size = 40;\n\t/* 0: lane_count; 1: link_rate */\n\tint max_param_num = 2;\n\tuint8_t param_nums = 0;\n\tlong param[2];\n\tbool valid_input = true;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\n\twr_buf = kcalloc(wr_buf_size, sizeof(char), GFP_KERNEL);\n\tif (!wr_buf)\n\t\treturn -ENOSPC;\n\n\tif (parse_write_buffer_into_params(wr_buf, wr_buf_size,\n\t\t\t\t\t   (long *)param, buf,\n\t\t\t\t\t   max_param_num,\n\t\t\t\t\t   &param_nums)) {\n\t\tkfree(wr_buf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (param_nums <= 0) {\n\t\tkfree(wr_buf);\n\t\tDRM_DEBUG_DRIVER(\"user data not be read\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (param[0]) {\n\tcase LANE_COUNT_ONE:\n\tcase LANE_COUNT_TWO:\n\tcase LANE_COUNT_FOUR:\n\t\tbreak;\n\tdefault:\n\t\tvalid_input = false;\n\t\tbreak;\n\t}\n\n\tswitch (param[1]) {\n\tcase LINK_RATE_LOW:\n\tcase LINK_RATE_HIGH:\n\tcase LINK_RATE_RBR2:\n\tcase LINK_RATE_HIGH2:\n\tcase LINK_RATE_HIGH3:\n\t\tbreak;\n\tdefault:\n\t\tvalid_input = false;\n\t\tbreak;\n\t}\n\n\tif (!valid_input) {\n\t\tkfree(wr_buf);\n\t\tDRM_DEBUG_DRIVER(\"Invalid Input value No HW will be programmed\\n\");\n\t\treturn size;\n\t}\n\n\t/* save user force lane_count, link_rate to preferred settings\n\t * spread spectrum will not be changed\n\t */\n\tprefer_link_settings.link_spread = link->cur_link_settings.link_spread;\n\tprefer_link_settings.use_link_rate_set = false;\n\tprefer_link_settings.lane_count = param[0];\n\tprefer_link_settings.link_rate = param[1];\n\n\tdp_retrain_link_dp_test(link, &prefer_link_settings, false);\n\n\tkfree(wr_buf);\n\treturn size;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \tif (!wr_buf)\n \t\treturn -ENOSPC;\n \n-\tif (parse_write_buffer_into_params(wr_buf, size,\n+\tif (parse_write_buffer_into_params(wr_buf, wr_buf_size,\n \t\t\t\t\t   (long *)param, buf,\n \t\t\t\t\t   max_param_num,\n \t\t\t\t\t   &param_nums)) {",
        "function_modified_lines": {
            "added": [
                "\tif (parse_write_buffer_into_params(wr_buf, wr_buf_size,"
            ],
            "deleted": [
                "\tif (parse_write_buffer_into_params(wr_buf, size,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "dp_link_settings_write in drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_debugfs.c in the Linux kernel through 5.14.14 allows a heap-based buffer overflow by an attacker who can write a string to the AMD GPU display drivers debug filesystem. There are no checks on size within parse_write_buffer_into_params when it uses the size of copy_from_user to copy a userspace buffer into a 40-byte heap buffer."
    },
    {
        "cve_id": "CVE-2021-42739",
        "code_before_change": "int avc_ca_pmt(struct firedtv *fdtv, char *msg, int length)\n{\n\tstruct avc_command_frame *c = (void *)fdtv->avc_data;\n\tstruct avc_response_frame *r = (void *)fdtv->avc_data;\n\tint list_management;\n\tint program_info_length;\n\tint pmt_cmd_id;\n\tint read_pos;\n\tint write_pos;\n\tint es_info_length;\n\tint crc32_csum;\n\tint ret;\n\n\tif (unlikely(avc_debug & AVC_DEBUG_APPLICATION_PMT))\n\t\tdebug_pmt(msg, length);\n\n\tmutex_lock(&fdtv->avc_mutex);\n\n\tc->ctype   = AVC_CTYPE_CONTROL;\n\tc->subunit = AVC_SUBUNIT_TYPE_TUNER | fdtv->subunit;\n\tc->opcode  = AVC_OPCODE_VENDOR;\n\n\tif (msg[0] != EN50221_LIST_MANAGEMENT_ONLY) {\n\t\tdev_info(fdtv->device, \"forcing list_management to ONLY\\n\");\n\t\tmsg[0] = EN50221_LIST_MANAGEMENT_ONLY;\n\t}\n\t/* We take the cmd_id from the programme level only! */\n\tlist_management = msg[0];\n\tprogram_info_length = ((msg[4] & 0x0f) << 8) + msg[5];\n\tif (program_info_length > 0)\n\t\tprogram_info_length--; /* Remove pmt_cmd_id */\n\tpmt_cmd_id = msg[6];\n\n\tc->operand[0] = SFE_VENDOR_DE_COMPANYID_0;\n\tc->operand[1] = SFE_VENDOR_DE_COMPANYID_1;\n\tc->operand[2] = SFE_VENDOR_DE_COMPANYID_2;\n\tc->operand[3] = SFE_VENDOR_OPCODE_HOST2CA;\n\tc->operand[4] = 0; /* slot */\n\tc->operand[5] = SFE_VENDOR_TAG_CA_PMT; /* ca tag */\n\tc->operand[6] = 0; /* more/last */\n\t/* Use three bytes for length field in case length > 127 */\n\tc->operand[10] = list_management;\n\tc->operand[11] = 0x01; /* pmt_cmd=OK_descramble */\n\n\t/* TS program map table */\n\n\tc->operand[12] = 0x02; /* Table id=2 */\n\tc->operand[13] = 0x80; /* Section syntax + length */\n\n\tc->operand[15] = msg[1]; /* Program number */\n\tc->operand[16] = msg[2];\n\tc->operand[17] = msg[3]; /* Version number and current/next */\n\tc->operand[18] = 0x00; /* Section number=0 */\n\tc->operand[19] = 0x00; /* Last section number=0 */\n\tc->operand[20] = 0x1f; /* PCR_PID=1FFF */\n\tc->operand[21] = 0xff;\n\tc->operand[22] = (program_info_length >> 8); /* Program info length */\n\tc->operand[23] = (program_info_length & 0xff);\n\n\t/* CA descriptors at programme level */\n\tread_pos = 6;\n\twrite_pos = 24;\n\tif (program_info_length > 0) {\n\t\tpmt_cmd_id = msg[read_pos++];\n\t\tif (pmt_cmd_id != 1 && pmt_cmd_id != 4)\n\t\t\tdev_err(fdtv->device,\n\t\t\t\t\"invalid pmt_cmd_id %d\\n\", pmt_cmd_id);\n\t\tif (program_info_length > sizeof(c->operand) - 4 - write_pos) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmemcpy(&c->operand[write_pos], &msg[read_pos],\n\t\t       program_info_length);\n\t\tread_pos += program_info_length;\n\t\twrite_pos += program_info_length;\n\t}\n\twhile (read_pos < length) {\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tes_info_length =\n\t\t\t((msg[read_pos] & 0x0f) << 8) + msg[read_pos + 1];\n\t\tread_pos += 2;\n\t\tif (es_info_length > 0)\n\t\t\tes_info_length--; /* Remove pmt_cmd_id */\n\t\tc->operand[write_pos++] = es_info_length >> 8;\n\t\tc->operand[write_pos++] = es_info_length & 0xff;\n\t\tif (es_info_length > 0) {\n\t\t\tpmt_cmd_id = msg[read_pos++];\n\t\t\tif (pmt_cmd_id != 1 && pmt_cmd_id != 4)\n\t\t\t\tdev_err(fdtv->device, \"invalid pmt_cmd_id %d at stream level\\n\",\n\t\t\t\t\tpmt_cmd_id);\n\n\t\t\tif (es_info_length > sizeof(c->operand) - 4 -\n\t\t\t\t\t     write_pos) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tmemcpy(&c->operand[write_pos], &msg[read_pos],\n\t\t\t       es_info_length);\n\t\t\tread_pos += es_info_length;\n\t\t\twrite_pos += es_info_length;\n\t\t}\n\t}\n\twrite_pos += 4; /* CRC */\n\n\tc->operand[7] = 0x82;\n\tc->operand[8] = (write_pos - 10) >> 8;\n\tc->operand[9] = (write_pos - 10) & 0xff;\n\tc->operand[14] = write_pos - 15;\n\n\tcrc32_csum = crc32_be(0, &c->operand[10], c->operand[12] - 1);\n\tc->operand[write_pos - 4] = (crc32_csum >> 24) & 0xff;\n\tc->operand[write_pos - 3] = (crc32_csum >> 16) & 0xff;\n\tc->operand[write_pos - 2] = (crc32_csum >>  8) & 0xff;\n\tc->operand[write_pos - 1] = (crc32_csum >>  0) & 0xff;\n\tpad_operands(c, write_pos);\n\n\tfdtv->avc_data_length = ALIGN(3 + write_pos, 4);\n\tret = avc_write(fdtv);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (r->response != AVC_RESPONSE_ACCEPTED) {\n\t\tdev_err(fdtv->device,\n\t\t\t\"CA PMT failed with response 0x%x\\n\", r->response);\n\t\tret = -EACCES;\n\t}\nout:\n\tmutex_unlock(&fdtv->avc_mutex);\n\n\treturn ret;\n}",
        "code_after_change": "int avc_ca_pmt(struct firedtv *fdtv, char *msg, int length)\n{\n\tstruct avc_command_frame *c = (void *)fdtv->avc_data;\n\tstruct avc_response_frame *r = (void *)fdtv->avc_data;\n\tint list_management;\n\tint program_info_length;\n\tint pmt_cmd_id;\n\tint read_pos;\n\tint write_pos;\n\tint es_info_length;\n\tint crc32_csum;\n\tint ret;\n\n\tif (unlikely(avc_debug & AVC_DEBUG_APPLICATION_PMT))\n\t\tdebug_pmt(msg, length);\n\n\tmutex_lock(&fdtv->avc_mutex);\n\n\tc->ctype   = AVC_CTYPE_CONTROL;\n\tc->subunit = AVC_SUBUNIT_TYPE_TUNER | fdtv->subunit;\n\tc->opcode  = AVC_OPCODE_VENDOR;\n\n\tif (msg[0] != EN50221_LIST_MANAGEMENT_ONLY) {\n\t\tdev_info(fdtv->device, \"forcing list_management to ONLY\\n\");\n\t\tmsg[0] = EN50221_LIST_MANAGEMENT_ONLY;\n\t}\n\t/* We take the cmd_id from the programme level only! */\n\tlist_management = msg[0];\n\tprogram_info_length = ((msg[4] & 0x0f) << 8) + msg[5];\n\tif (program_info_length > 0)\n\t\tprogram_info_length--; /* Remove pmt_cmd_id */\n\tpmt_cmd_id = msg[6];\n\n\tc->operand[0] = SFE_VENDOR_DE_COMPANYID_0;\n\tc->operand[1] = SFE_VENDOR_DE_COMPANYID_1;\n\tc->operand[2] = SFE_VENDOR_DE_COMPANYID_2;\n\tc->operand[3] = SFE_VENDOR_OPCODE_HOST2CA;\n\tc->operand[4] = 0; /* slot */\n\tc->operand[5] = SFE_VENDOR_TAG_CA_PMT; /* ca tag */\n\tc->operand[6] = 0; /* more/last */\n\t/* Use three bytes for length field in case length > 127 */\n\tc->operand[10] = list_management;\n\tc->operand[11] = 0x01; /* pmt_cmd=OK_descramble */\n\n\t/* TS program map table */\n\n\tc->operand[12] = 0x02; /* Table id=2 */\n\tc->operand[13] = 0x80; /* Section syntax + length */\n\n\tc->operand[15] = msg[1]; /* Program number */\n\tc->operand[16] = msg[2];\n\tc->operand[17] = msg[3]; /* Version number and current/next */\n\tc->operand[18] = 0x00; /* Section number=0 */\n\tc->operand[19] = 0x00; /* Last section number=0 */\n\tc->operand[20] = 0x1f; /* PCR_PID=1FFF */\n\tc->operand[21] = 0xff;\n\tc->operand[22] = (program_info_length >> 8); /* Program info length */\n\tc->operand[23] = (program_info_length & 0xff);\n\n\t/* CA descriptors at programme level */\n\tread_pos = 6;\n\twrite_pos = 24;\n\tif (program_info_length > 0) {\n\t\tpmt_cmd_id = msg[read_pos++];\n\t\tif (pmt_cmd_id != 1 && pmt_cmd_id != 4)\n\t\t\tdev_err(fdtv->device,\n\t\t\t\t\"invalid pmt_cmd_id %d\\n\", pmt_cmd_id);\n\t\tif (program_info_length > sizeof(c->operand) - 4 - write_pos) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmemcpy(&c->operand[write_pos], &msg[read_pos],\n\t\t       program_info_length);\n\t\tread_pos += program_info_length;\n\t\twrite_pos += program_info_length;\n\t}\n\twhile (read_pos + 4 < length) {\n\t\tif (write_pos + 4 >= sizeof(c->operand) - 4) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tc->operand[write_pos++] = msg[read_pos++];\n\t\tes_info_length =\n\t\t\t((msg[read_pos] & 0x0f) << 8) + msg[read_pos + 1];\n\t\tread_pos += 2;\n\t\tif (es_info_length > 0)\n\t\t\tes_info_length--; /* Remove pmt_cmd_id */\n\t\tc->operand[write_pos++] = es_info_length >> 8;\n\t\tc->operand[write_pos++] = es_info_length & 0xff;\n\t\tif (es_info_length > 0) {\n\t\t\tif (read_pos >= length) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tpmt_cmd_id = msg[read_pos++];\n\t\t\tif (pmt_cmd_id != 1 && pmt_cmd_id != 4)\n\t\t\t\tdev_err(fdtv->device, \"invalid pmt_cmd_id %d at stream level\\n\",\n\t\t\t\t\tpmt_cmd_id);\n\n\t\t\tif (es_info_length > sizeof(c->operand) - 4 - write_pos ||\n\t\t\t    es_info_length > length - read_pos) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tmemcpy(&c->operand[write_pos], &msg[read_pos],\n\t\t\t       es_info_length);\n\t\t\tread_pos += es_info_length;\n\t\t\twrite_pos += es_info_length;\n\t\t}\n\t}\n\twrite_pos += 4; /* CRC */\n\n\tc->operand[7] = 0x82;\n\tc->operand[8] = (write_pos - 10) >> 8;\n\tc->operand[9] = (write_pos - 10) & 0xff;\n\tc->operand[14] = write_pos - 15;\n\n\tcrc32_csum = crc32_be(0, &c->operand[10], c->operand[12] - 1);\n\tc->operand[write_pos - 4] = (crc32_csum >> 24) & 0xff;\n\tc->operand[write_pos - 3] = (crc32_csum >> 16) & 0xff;\n\tc->operand[write_pos - 2] = (crc32_csum >>  8) & 0xff;\n\tc->operand[write_pos - 1] = (crc32_csum >>  0) & 0xff;\n\tpad_operands(c, write_pos);\n\n\tfdtv->avc_data_length = ALIGN(3 + write_pos, 4);\n\tret = avc_write(fdtv);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (r->response != AVC_RESPONSE_ACCEPTED) {\n\t\tdev_err(fdtv->device,\n\t\t\t\"CA PMT failed with response 0x%x\\n\", r->response);\n\t\tret = -EACCES;\n\t}\nout:\n\tmutex_unlock(&fdtv->avc_mutex);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -75,7 +75,11 @@\n \t\tread_pos += program_info_length;\n \t\twrite_pos += program_info_length;\n \t}\n-\twhile (read_pos < length) {\n+\twhile (read_pos + 4 < length) {\n+\t\tif (write_pos + 4 >= sizeof(c->operand) - 4) {\n+\t\t\tret = -EINVAL;\n+\t\t\tgoto out;\n+\t\t}\n \t\tc->operand[write_pos++] = msg[read_pos++];\n \t\tc->operand[write_pos++] = msg[read_pos++];\n \t\tc->operand[write_pos++] = msg[read_pos++];\n@@ -87,13 +91,17 @@\n \t\tc->operand[write_pos++] = es_info_length >> 8;\n \t\tc->operand[write_pos++] = es_info_length & 0xff;\n \t\tif (es_info_length > 0) {\n+\t\t\tif (read_pos >= length) {\n+\t\t\t\tret = -EINVAL;\n+\t\t\t\tgoto out;\n+\t\t\t}\n \t\t\tpmt_cmd_id = msg[read_pos++];\n \t\t\tif (pmt_cmd_id != 1 && pmt_cmd_id != 4)\n \t\t\t\tdev_err(fdtv->device, \"invalid pmt_cmd_id %d at stream level\\n\",\n \t\t\t\t\tpmt_cmd_id);\n \n-\t\t\tif (es_info_length > sizeof(c->operand) - 4 -\n-\t\t\t\t\t     write_pos) {\n+\t\t\tif (es_info_length > sizeof(c->operand) - 4 - write_pos ||\n+\t\t\t    es_info_length > length - read_pos) {\n \t\t\t\tret = -EINVAL;\n \t\t\t\tgoto out;\n \t\t\t}",
        "function_modified_lines": {
            "added": [
                "\twhile (read_pos + 4 < length) {",
                "\t\tif (write_pos + 4 >= sizeof(c->operand) - 4) {",
                "\t\t\tret = -EINVAL;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t\t\tif (read_pos >= length) {",
                "\t\t\t\tret = -EINVAL;",
                "\t\t\t\tgoto out;",
                "\t\t\t}",
                "\t\t\tif (es_info_length > sizeof(c->operand) - 4 - write_pos ||",
                "\t\t\t    es_info_length > length - read_pos) {"
            ],
            "deleted": [
                "\twhile (read_pos < length) {",
                "\t\t\tif (es_info_length > sizeof(c->operand) - 4 -",
                "\t\t\t\t\t     write_pos) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap-based buffer overflow flaw was found in the Linux kernel FireDTV media card driver, where the user calls the CA_SEND_MSG ioctl. This flaw allows a local user of the host machine to crash the system or escalate privileges on the system. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2021-42739",
        "code_before_change": "static int fdtv_ca_pmt(struct firedtv *fdtv, void *arg)\n{\n\tstruct ca_msg *msg = arg;\n\tint data_pos;\n\tint data_length;\n\tint i;\n\n\tdata_pos = 4;\n\tif (msg->msg[3] & 0x80) {\n\t\tdata_length = 0;\n\t\tfor (i = 0; i < (msg->msg[3] & 0x7f); i++)\n\t\t\tdata_length = (data_length << 8) + msg->msg[data_pos++];\n\t} else {\n\t\tdata_length = msg->msg[3];\n\t}\n\n\treturn avc_ca_pmt(fdtv, &msg->msg[data_pos], data_length);\n}",
        "code_after_change": "static int fdtv_ca_pmt(struct firedtv *fdtv, void *arg)\n{\n\tstruct ca_msg *msg = arg;\n\tint data_pos;\n\tint data_length;\n\tint i;\n\n\tdata_pos = 4;\n\tif (msg->msg[3] & 0x80) {\n\t\tdata_length = 0;\n\t\tfor (i = 0; i < (msg->msg[3] & 0x7f); i++)\n\t\t\tdata_length = (data_length << 8) + msg->msg[data_pos++];\n\t} else {\n\t\tdata_length = msg->msg[3];\n\t}\n\tif (data_length > sizeof(msg->msg) - data_pos)\n\t\treturn -EINVAL;\n\n\treturn avc_ca_pmt(fdtv, &msg->msg[data_pos], data_length);\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,6 +13,8 @@\n \t} else {\n \t\tdata_length = msg->msg[3];\n \t}\n+\tif (data_length > sizeof(msg->msg) - data_pos)\n+\t\treturn -EINVAL;\n \n \treturn avc_ca_pmt(fdtv, &msg->msg[data_pos], data_length);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (data_length > sizeof(msg->msg) - data_pos)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap-based buffer overflow flaw was found in the Linux kernel FireDTV media card driver, where the user calls the CA_SEND_MSG ioctl. This flaw allows a local user of the host machine to crash the system or escalate privileges on the system. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability."
    },
    {
        "cve_id": "CVE-2021-43975",
        "code_before_change": "int hw_atl_utils_fw_rpc_wait(struct aq_hw_s *self,\n\t\t\t     struct hw_atl_utils_fw_rpc **rpc)\n{\n\tstruct aq_hw_atl_utils_fw_rpc_tid_s sw;\n\tstruct aq_hw_atl_utils_fw_rpc_tid_s fw;\n\tint err = 0;\n\n\tdo {\n\t\tsw.val = aq_hw_read_reg(self, HW_ATL_RPC_CONTROL_ADR);\n\n\t\tself->rpc_tid = sw.tid;\n\n\t\terr = readx_poll_timeout_atomic(hw_atl_utils_rpc_state_get,\n\t\t\t\t\t\tself, fw.val,\n\t\t\t\t\t\tsw.tid == fw.tid,\n\t\t\t\t\t\t1000U, 100000U);\n\t\tif (err < 0)\n\t\t\tgoto err_exit;\n\n\t\terr = aq_hw_err_from_flags(self);\n\t\tif (err < 0)\n\t\t\tgoto err_exit;\n\n\t\tif (fw.len == 0xFFFFU) {\n\t\t\terr = hw_atl_utils_fw_rpc_call(self, sw.len);\n\t\t\tif (err < 0)\n\t\t\t\tgoto err_exit;\n\t\t}\n\t} while (sw.tid != fw.tid || 0xFFFFU == fw.len);\n\n\tif (rpc) {\n\t\tif (fw.len) {\n\t\t\terr =\n\t\t\thw_atl_utils_fw_downld_dwords(self,\n\t\t\t\t\t\t      self->rpc_addr,\n\t\t\t\t\t\t      (u32 *)(void *)\n\t\t\t\t\t\t      &self->rpc,\n\t\t\t\t\t\t      (fw.len + sizeof(u32) -\n\t\t\t\t\t\t       sizeof(u8)) /\n\t\t\t\t\t\t      sizeof(u32));\n\t\t\tif (err < 0)\n\t\t\t\tgoto err_exit;\n\t\t}\n\n\t\t*rpc = &self->rpc;\n\t}\n\nerr_exit:\n\treturn err;\n}",
        "code_after_change": "int hw_atl_utils_fw_rpc_wait(struct aq_hw_s *self,\n\t\t\t     struct hw_atl_utils_fw_rpc **rpc)\n{\n\tstruct aq_hw_atl_utils_fw_rpc_tid_s sw;\n\tstruct aq_hw_atl_utils_fw_rpc_tid_s fw;\n\tint err = 0;\n\n\tdo {\n\t\tsw.val = aq_hw_read_reg(self, HW_ATL_RPC_CONTROL_ADR);\n\n\t\tself->rpc_tid = sw.tid;\n\n\t\terr = readx_poll_timeout_atomic(hw_atl_utils_rpc_state_get,\n\t\t\t\t\t\tself, fw.val,\n\t\t\t\t\t\tsw.tid == fw.tid,\n\t\t\t\t\t\t1000U, 100000U);\n\t\tif (err < 0)\n\t\t\tgoto err_exit;\n\n\t\terr = aq_hw_err_from_flags(self);\n\t\tif (err < 0)\n\t\t\tgoto err_exit;\n\n\t\tif (fw.len == 0xFFFFU) {\n\t\t\tif (sw.len > sizeof(self->rpc)) {\n\t\t\t\tprintk(KERN_INFO \"Invalid sw len: %x\\n\", sw.len);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto err_exit;\n\t\t\t}\n\t\t\terr = hw_atl_utils_fw_rpc_call(self, sw.len);\n\t\t\tif (err < 0)\n\t\t\t\tgoto err_exit;\n\t\t}\n\t} while (sw.tid != fw.tid || 0xFFFFU == fw.len);\n\n\tif (rpc) {\n\t\tif (fw.len) {\n\t\t\tif (fw.len > sizeof(self->rpc)) {\n\t\t\t\tprintk(KERN_INFO \"Invalid fw len: %x\\n\", fw.len);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto err_exit;\n\t\t\t}\n\t\t\terr =\n\t\t\thw_atl_utils_fw_downld_dwords(self,\n\t\t\t\t\t\t      self->rpc_addr,\n\t\t\t\t\t\t      (u32 *)(void *)\n\t\t\t\t\t\t      &self->rpc,\n\t\t\t\t\t\t      (fw.len + sizeof(u32) -\n\t\t\t\t\t\t       sizeof(u8)) /\n\t\t\t\t\t\t      sizeof(u32));\n\t\t\tif (err < 0)\n\t\t\t\tgoto err_exit;\n\t\t}\n\n\t\t*rpc = &self->rpc;\n\t}\n\nerr_exit:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,11 @@\n \t\t\tgoto err_exit;\n \n \t\tif (fw.len == 0xFFFFU) {\n+\t\t\tif (sw.len > sizeof(self->rpc)) {\n+\t\t\t\tprintk(KERN_INFO \"Invalid sw len: %x\\n\", sw.len);\n+\t\t\t\terr = -EINVAL;\n+\t\t\t\tgoto err_exit;\n+\t\t\t}\n \t\t\terr = hw_atl_utils_fw_rpc_call(self, sw.len);\n \t\t\tif (err < 0)\n \t\t\t\tgoto err_exit;\n@@ -30,6 +35,11 @@\n \n \tif (rpc) {\n \t\tif (fw.len) {\n+\t\t\tif (fw.len > sizeof(self->rpc)) {\n+\t\t\t\tprintk(KERN_INFO \"Invalid fw len: %x\\n\", fw.len);\n+\t\t\t\terr = -EINVAL;\n+\t\t\t\tgoto err_exit;\n+\t\t\t}\n \t\t\terr =\n \t\t\thw_atl_utils_fw_downld_dwords(self,\n \t\t\t\t\t\t      self->rpc_addr,",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (sw.len > sizeof(self->rpc)) {",
                "\t\t\t\tprintk(KERN_INFO \"Invalid sw len: %x\\n\", sw.len);",
                "\t\t\t\terr = -EINVAL;",
                "\t\t\t\tgoto err_exit;",
                "\t\t\t}",
                "\t\t\tif (fw.len > sizeof(self->rpc)) {",
                "\t\t\t\tprintk(KERN_INFO \"Invalid fw len: %x\\n\", fw.len);",
                "\t\t\t\terr = -EINVAL;",
                "\t\t\t\tgoto err_exit;",
                "\t\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel through 5.15.2, hw_atl_utils_fw_rpc_wait in drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_utils.c allows an attacker (who can introduce a crafted device) to trigger an out-of-bounds write via a crafted length value."
    },
    {
        "cve_id": "CVE-2022-0435",
        "code_before_change": "static int tipc_link_proto_rcv(struct tipc_link *l, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *xmitq)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_gap_ack_blks *ga = NULL;\n\tbool reply = msg_probe(hdr), retransmitted = false;\n\tu16 dlen = msg_data_sz(hdr), glen = 0;\n\tu16 peers_snd_nxt =  msg_next_sent(hdr);\n\tu16 peers_tol = msg_link_tolerance(hdr);\n\tu16 peers_prio = msg_linkprio(hdr);\n\tu16 gap = msg_seq_gap(hdr);\n\tu16 ack = msg_ack(hdr);\n\tu16 rcv_nxt = l->rcv_nxt;\n\tu16 rcvgap = 0;\n\tint mtyp = msg_type(hdr);\n\tint rc = 0, released;\n\tchar *if_name;\n\tvoid *data;\n\n\ttrace_tipc_proto_rcv(skb, false, l->name);\n\tif (tipc_link_is_blocked(l) || !xmitq)\n\t\tgoto exit;\n\n\tif (tipc_own_addr(l->net) > msg_prevnode(hdr))\n\t\tl->net_plane = msg_net_plane(hdr);\n\n\tskb_linearize(skb);\n\thdr = buf_msg(skb);\n\tdata = msg_data(hdr);\n\n\tif (!tipc_link_validate_msg(l, hdr)) {\n\t\ttrace_tipc_skb_dump(skb, false, \"PROTO invalid (1)!\");\n\t\ttrace_tipc_link_dump(l, TIPC_DUMP_NONE, \"PROTO invalid (1)!\");\n\t\tgoto exit;\n\t}\n\n\tswitch (mtyp) {\n\tcase RESET_MSG:\n\tcase ACTIVATE_MSG:\n\t\t/* Complete own link name with peer's interface name */\n\t\tif_name =  strrchr(l->name, ':') + 1;\n\t\tif (sizeof(l->name) - (if_name - l->name) <= TIPC_MAX_IF_NAME)\n\t\t\tbreak;\n\t\tif (msg_data_sz(hdr) < TIPC_MAX_IF_NAME)\n\t\t\tbreak;\n\t\tstrncpy(if_name, data, TIPC_MAX_IF_NAME);\n\n\t\t/* Update own tolerance if peer indicates a non-zero value */\n\t\tif (in_range(peers_tol, TIPC_MIN_LINK_TOL, TIPC_MAX_LINK_TOL)) {\n\t\t\tl->tolerance = peers_tol;\n\t\t\tl->bc_rcvlink->tolerance = peers_tol;\n\t\t}\n\t\t/* Update own priority if peer's priority is higher */\n\t\tif (in_range(peers_prio, l->priority + 1, TIPC_MAX_LINK_PRI))\n\t\t\tl->priority = peers_prio;\n\n\t\t/* If peer is going down we want full re-establish cycle */\n\t\tif (msg_peer_stopping(hdr)) {\n\t\t\trc = tipc_link_fsm_evt(l, LINK_FAILURE_EVT);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* If this endpoint was re-created while peer was ESTABLISHING\n\t\t * it doesn't know current session number. Force re-synch.\n\t\t */\n\t\tif (mtyp == ACTIVATE_MSG && msg_dest_session_valid(hdr) &&\n\t\t    l->session != msg_dest_session(hdr)) {\n\t\t\tif (less(l->session, msg_dest_session(hdr)))\n\t\t\t\tl->session = msg_dest_session(hdr) + 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ACTIVATE_MSG serves as PEER_RESET if link is already down */\n\t\tif (mtyp == RESET_MSG || !link_is_up(l))\n\t\t\trc = tipc_link_fsm_evt(l, LINK_PEER_RESET_EVT);\n\n\t\t/* ACTIVATE_MSG takes up link if it was already locally reset */\n\t\tif (mtyp == ACTIVATE_MSG && l->state == LINK_ESTABLISHING)\n\t\t\trc = TIPC_LINK_UP_EVT;\n\n\t\tl->peer_session = msg_session(hdr);\n\t\tl->in_session = true;\n\t\tl->peer_bearer_id = msg_bearer_id(hdr);\n\t\tif (l->mtu > msg_max_pkt(hdr))\n\t\t\tl->mtu = msg_max_pkt(hdr);\n\t\tbreak;\n\n\tcase STATE_MSG:\n\t\tl->rcv_nxt_state = msg_seqno(hdr) + 1;\n\n\t\t/* Update own tolerance if peer indicates a non-zero value */\n\t\tif (in_range(peers_tol, TIPC_MIN_LINK_TOL, TIPC_MAX_LINK_TOL)) {\n\t\t\tl->tolerance = peers_tol;\n\t\t\tl->bc_rcvlink->tolerance = peers_tol;\n\t\t}\n\t\t/* Update own prio if peer indicates a different value */\n\t\tif ((peers_prio != l->priority) &&\n\t\t    in_range(peers_prio, 1, TIPC_MAX_LINK_PRI)) {\n\t\t\tl->priority = peers_prio;\n\t\t\trc = tipc_link_fsm_evt(l, LINK_FAILURE_EVT);\n\t\t}\n\n\t\tl->silent_intv_cnt = 0;\n\t\tl->stats.recv_states++;\n\t\tif (msg_probe(hdr))\n\t\t\tl->stats.recv_probes++;\n\n\t\tif (!link_is_up(l)) {\n\t\t\tif (l->state == LINK_ESTABLISHING)\n\t\t\t\trc = TIPC_LINK_UP_EVT;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Receive Gap ACK blocks from peer if any */\n\t\tglen = tipc_get_gap_ack_blks(&ga, l, hdr, true);\n\n\t\ttipc_mon_rcv(l->net, data + glen, dlen - glen, l->addr,\n\t\t\t     &l->mon_state, l->bearer_id);\n\n\t\t/* Send NACK if peer has sent pkts we haven't received yet */\n\t\tif ((reply || msg_is_keepalive(hdr)) &&\n\t\t    more(peers_snd_nxt, rcv_nxt) &&\n\t\t    !tipc_link_is_synching(l) &&\n\t\t    skb_queue_empty(&l->deferdq))\n\t\t\trcvgap = peers_snd_nxt - l->rcv_nxt;\n\t\tif (rcvgap || reply)\n\t\t\ttipc_link_build_proto_msg(l, STATE_MSG, 0, reply,\n\t\t\t\t\t\t  rcvgap, 0, 0, xmitq);\n\n\t\treleased = tipc_link_advance_transmq(l, l, ack, gap, ga, xmitq,\n\t\t\t\t\t\t     &retransmitted, &rc);\n\t\tif (gap)\n\t\t\tl->stats.recv_nacks++;\n\t\tif (released || retransmitted)\n\t\t\ttipc_link_update_cwin(l, released, retransmitted);\n\t\tif (released)\n\t\t\ttipc_link_advance_backlog(l, xmitq);\n\t\tif (unlikely(!skb_queue_empty(&l->wakeupq)))\n\t\t\tlink_prepare_wakeup(l);\n\t}\nexit:\n\tkfree_skb(skb);\n\treturn rc;\n}",
        "code_after_change": "static int tipc_link_proto_rcv(struct tipc_link *l, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *xmitq)\n{\n\tstruct tipc_msg *hdr = buf_msg(skb);\n\tstruct tipc_gap_ack_blks *ga = NULL;\n\tbool reply = msg_probe(hdr), retransmitted = false;\n\tu32 dlen = msg_data_sz(hdr), glen = 0;\n\tu16 peers_snd_nxt =  msg_next_sent(hdr);\n\tu16 peers_tol = msg_link_tolerance(hdr);\n\tu16 peers_prio = msg_linkprio(hdr);\n\tu16 gap = msg_seq_gap(hdr);\n\tu16 ack = msg_ack(hdr);\n\tu16 rcv_nxt = l->rcv_nxt;\n\tu16 rcvgap = 0;\n\tint mtyp = msg_type(hdr);\n\tint rc = 0, released;\n\tchar *if_name;\n\tvoid *data;\n\n\ttrace_tipc_proto_rcv(skb, false, l->name);\n\n\tif (dlen > U16_MAX)\n\t\tgoto exit;\n\n\tif (tipc_link_is_blocked(l) || !xmitq)\n\t\tgoto exit;\n\n\tif (tipc_own_addr(l->net) > msg_prevnode(hdr))\n\t\tl->net_plane = msg_net_plane(hdr);\n\n\tskb_linearize(skb);\n\thdr = buf_msg(skb);\n\tdata = msg_data(hdr);\n\n\tif (!tipc_link_validate_msg(l, hdr)) {\n\t\ttrace_tipc_skb_dump(skb, false, \"PROTO invalid (1)!\");\n\t\ttrace_tipc_link_dump(l, TIPC_DUMP_NONE, \"PROTO invalid (1)!\");\n\t\tgoto exit;\n\t}\n\n\tswitch (mtyp) {\n\tcase RESET_MSG:\n\tcase ACTIVATE_MSG:\n\t\t/* Complete own link name with peer's interface name */\n\t\tif_name =  strrchr(l->name, ':') + 1;\n\t\tif (sizeof(l->name) - (if_name - l->name) <= TIPC_MAX_IF_NAME)\n\t\t\tbreak;\n\t\tif (msg_data_sz(hdr) < TIPC_MAX_IF_NAME)\n\t\t\tbreak;\n\t\tstrncpy(if_name, data, TIPC_MAX_IF_NAME);\n\n\t\t/* Update own tolerance if peer indicates a non-zero value */\n\t\tif (in_range(peers_tol, TIPC_MIN_LINK_TOL, TIPC_MAX_LINK_TOL)) {\n\t\t\tl->tolerance = peers_tol;\n\t\t\tl->bc_rcvlink->tolerance = peers_tol;\n\t\t}\n\t\t/* Update own priority if peer's priority is higher */\n\t\tif (in_range(peers_prio, l->priority + 1, TIPC_MAX_LINK_PRI))\n\t\t\tl->priority = peers_prio;\n\n\t\t/* If peer is going down we want full re-establish cycle */\n\t\tif (msg_peer_stopping(hdr)) {\n\t\t\trc = tipc_link_fsm_evt(l, LINK_FAILURE_EVT);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* If this endpoint was re-created while peer was ESTABLISHING\n\t\t * it doesn't know current session number. Force re-synch.\n\t\t */\n\t\tif (mtyp == ACTIVATE_MSG && msg_dest_session_valid(hdr) &&\n\t\t    l->session != msg_dest_session(hdr)) {\n\t\t\tif (less(l->session, msg_dest_session(hdr)))\n\t\t\t\tl->session = msg_dest_session(hdr) + 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ACTIVATE_MSG serves as PEER_RESET if link is already down */\n\t\tif (mtyp == RESET_MSG || !link_is_up(l))\n\t\t\trc = tipc_link_fsm_evt(l, LINK_PEER_RESET_EVT);\n\n\t\t/* ACTIVATE_MSG takes up link if it was already locally reset */\n\t\tif (mtyp == ACTIVATE_MSG && l->state == LINK_ESTABLISHING)\n\t\t\trc = TIPC_LINK_UP_EVT;\n\n\t\tl->peer_session = msg_session(hdr);\n\t\tl->in_session = true;\n\t\tl->peer_bearer_id = msg_bearer_id(hdr);\n\t\tif (l->mtu > msg_max_pkt(hdr))\n\t\t\tl->mtu = msg_max_pkt(hdr);\n\t\tbreak;\n\n\tcase STATE_MSG:\n\t\tl->rcv_nxt_state = msg_seqno(hdr) + 1;\n\n\t\t/* Update own tolerance if peer indicates a non-zero value */\n\t\tif (in_range(peers_tol, TIPC_MIN_LINK_TOL, TIPC_MAX_LINK_TOL)) {\n\t\t\tl->tolerance = peers_tol;\n\t\t\tl->bc_rcvlink->tolerance = peers_tol;\n\t\t}\n\t\t/* Update own prio if peer indicates a different value */\n\t\tif ((peers_prio != l->priority) &&\n\t\t    in_range(peers_prio, 1, TIPC_MAX_LINK_PRI)) {\n\t\t\tl->priority = peers_prio;\n\t\t\trc = tipc_link_fsm_evt(l, LINK_FAILURE_EVT);\n\t\t}\n\n\t\tl->silent_intv_cnt = 0;\n\t\tl->stats.recv_states++;\n\t\tif (msg_probe(hdr))\n\t\t\tl->stats.recv_probes++;\n\n\t\tif (!link_is_up(l)) {\n\t\t\tif (l->state == LINK_ESTABLISHING)\n\t\t\t\trc = TIPC_LINK_UP_EVT;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Receive Gap ACK blocks from peer if any */\n\t\tglen = tipc_get_gap_ack_blks(&ga, l, hdr, true);\n\t\tif(glen > dlen)\n\t\t\tbreak;\n\t\ttipc_mon_rcv(l->net, data + glen, dlen - glen, l->addr,\n\t\t\t     &l->mon_state, l->bearer_id);\n\n\t\t/* Send NACK if peer has sent pkts we haven't received yet */\n\t\tif ((reply || msg_is_keepalive(hdr)) &&\n\t\t    more(peers_snd_nxt, rcv_nxt) &&\n\t\t    !tipc_link_is_synching(l) &&\n\t\t    skb_queue_empty(&l->deferdq))\n\t\t\trcvgap = peers_snd_nxt - l->rcv_nxt;\n\t\tif (rcvgap || reply)\n\t\t\ttipc_link_build_proto_msg(l, STATE_MSG, 0, reply,\n\t\t\t\t\t\t  rcvgap, 0, 0, xmitq);\n\n\t\treleased = tipc_link_advance_transmq(l, l, ack, gap, ga, xmitq,\n\t\t\t\t\t\t     &retransmitted, &rc);\n\t\tif (gap)\n\t\t\tl->stats.recv_nacks++;\n\t\tif (released || retransmitted)\n\t\t\ttipc_link_update_cwin(l, released, retransmitted);\n\t\tif (released)\n\t\t\ttipc_link_advance_backlog(l, xmitq);\n\t\tif (unlikely(!skb_queue_empty(&l->wakeupq)))\n\t\t\tlink_prepare_wakeup(l);\n\t}\nexit:\n\tkfree_skb(skb);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n \tstruct tipc_msg *hdr = buf_msg(skb);\n \tstruct tipc_gap_ack_blks *ga = NULL;\n \tbool reply = msg_probe(hdr), retransmitted = false;\n-\tu16 dlen = msg_data_sz(hdr), glen = 0;\n+\tu32 dlen = msg_data_sz(hdr), glen = 0;\n \tu16 peers_snd_nxt =  msg_next_sent(hdr);\n \tu16 peers_tol = msg_link_tolerance(hdr);\n \tu16 peers_prio = msg_linkprio(hdr);\n@@ -18,6 +18,10 @@\n \tvoid *data;\n \n \ttrace_tipc_proto_rcv(skb, false, l->name);\n+\n+\tif (dlen > U16_MAX)\n+\t\tgoto exit;\n+\n \tif (tipc_link_is_blocked(l) || !xmitq)\n \t\tgoto exit;\n \n@@ -113,7 +117,8 @@\n \n \t\t/* Receive Gap ACK blocks from peer if any */\n \t\tglen = tipc_get_gap_ack_blks(&ga, l, hdr, true);\n-\n+\t\tif(glen > dlen)\n+\t\t\tbreak;\n \t\ttipc_mon_rcv(l->net, data + glen, dlen - glen, l->addr,\n \t\t\t     &l->mon_state, l->bearer_id);\n ",
        "function_modified_lines": {
            "added": [
                "\tu32 dlen = msg_data_sz(hdr), glen = 0;",
                "",
                "\tif (dlen > U16_MAX)",
                "\t\tgoto exit;",
                "",
                "\t\tif(glen > dlen)",
                "\t\t\tbreak;"
            ],
            "deleted": [
                "\tu16 dlen = msg_data_sz(hdr), glen = 0;",
                ""
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A stack overflow flaw was found in the Linux kernel's TIPC protocol functionality in the way a user sends a packet with malicious content where the number of domain member nodes is higher than the 64 allowed. This flaw allows a remote user to crash the system or possibly escalate their privileges if they have access to the TIPC network."
    },
    {
        "cve_id": "CVE-2022-0435",
        "code_before_change": "void tipc_mon_rcv(struct net *net, void *data, u16 dlen, u32 addr,\n\t\t  struct tipc_mon_state *state, int bearer_id)\n{\n\tstruct tipc_monitor *mon = tipc_monitor(net, bearer_id);\n\tstruct tipc_mon_domain *arrv_dom = data;\n\tstruct tipc_mon_domain dom_bef;\n\tstruct tipc_mon_domain *dom;\n\tstruct tipc_peer *peer;\n\tu16 new_member_cnt = mon_le16_to_cpu(arrv_dom->member_cnt);\n\tint new_dlen = dom_rec_len(arrv_dom, new_member_cnt);\n\tu16 new_gen = mon_le16_to_cpu(arrv_dom->gen);\n\tu16 acked_gen = mon_le16_to_cpu(arrv_dom->ack_gen);\n\tu16 arrv_dlen = mon_le16_to_cpu(arrv_dom->len);\n\tbool probing = state->probing;\n\tint i, applied_bef;\n\n\tstate->probing = false;\n\n\t/* Sanity check received domain record */\n\tif (dlen < dom_rec_len(arrv_dom, 0))\n\t\treturn;\n\tif (dlen != dom_rec_len(arrv_dom, new_member_cnt))\n\t\treturn;\n\tif (dlen < new_dlen || arrv_dlen != new_dlen)\n\t\treturn;\n\n\t/* Synch generation numbers with peer if link just came up */\n\tif (!state->synched) {\n\t\tstate->peer_gen = new_gen - 1;\n\t\tstate->acked_gen = acked_gen;\n\t\tstate->synched = true;\n\t}\n\n\tif (more(acked_gen, state->acked_gen))\n\t\tstate->acked_gen = acked_gen;\n\n\t/* Drop duplicate unless we are waiting for a probe response */\n\tif (!more(new_gen, state->peer_gen) && !probing)\n\t\treturn;\n\n\twrite_lock_bh(&mon->lock);\n\tpeer = get_peer(mon, addr);\n\tif (!peer || !peer->is_up)\n\t\tgoto exit;\n\n\t/* Peer is confirmed, stop any ongoing probing */\n\tpeer->down_cnt = 0;\n\n\t/* Task is done for duplicate record */\n\tif (!more(new_gen, state->peer_gen))\n\t\tgoto exit;\n\n\tstate->peer_gen = new_gen;\n\n\t/* Cache current domain record for later use */\n\tdom_bef.member_cnt = 0;\n\tdom = peer->domain;\n\tif (dom)\n\t\tmemcpy(&dom_bef, dom, dom->len);\n\n\t/* Transform and store received domain record */\n\tif (!dom || (dom->len < new_dlen)) {\n\t\tkfree(dom);\n\t\tdom = kmalloc(new_dlen, GFP_ATOMIC);\n\t\tpeer->domain = dom;\n\t\tif (!dom)\n\t\t\tgoto exit;\n\t}\n\tdom->len = new_dlen;\n\tdom->gen = new_gen;\n\tdom->member_cnt = new_member_cnt;\n\tdom->up_map = mon_le64_to_cpu(arrv_dom->up_map);\n\tfor (i = 0; i < new_member_cnt; i++)\n\t\tdom->members[i] = mon_le32_to_cpu(arrv_dom->members[i]);\n\n\t/* Update peers affected by this domain record */\n\tapplied_bef = peer->applied;\n\tmon_apply_domain(mon, peer);\n\tmon_identify_lost_members(peer, &dom_bef, applied_bef);\n\tmon_assign_roles(mon, peer_head(peer));\nexit:\n\twrite_unlock_bh(&mon->lock);\n}",
        "code_after_change": "void tipc_mon_rcv(struct net *net, void *data, u16 dlen, u32 addr,\n\t\t  struct tipc_mon_state *state, int bearer_id)\n{\n\tstruct tipc_monitor *mon = tipc_monitor(net, bearer_id);\n\tstruct tipc_mon_domain *arrv_dom = data;\n\tstruct tipc_mon_domain dom_bef;\n\tstruct tipc_mon_domain *dom;\n\tstruct tipc_peer *peer;\n\tu16 new_member_cnt = mon_le16_to_cpu(arrv_dom->member_cnt);\n\tint new_dlen = dom_rec_len(arrv_dom, new_member_cnt);\n\tu16 new_gen = mon_le16_to_cpu(arrv_dom->gen);\n\tu16 acked_gen = mon_le16_to_cpu(arrv_dom->ack_gen);\n\tu16 arrv_dlen = mon_le16_to_cpu(arrv_dom->len);\n\tbool probing = state->probing;\n\tint i, applied_bef;\n\n\tstate->probing = false;\n\n\t/* Sanity check received domain record */\n\tif (new_member_cnt > MAX_MON_DOMAIN)\n\t\treturn;\n\tif (dlen < dom_rec_len(arrv_dom, 0))\n\t\treturn;\n\tif (dlen != dom_rec_len(arrv_dom, new_member_cnt))\n\t\treturn;\n\tif (dlen < new_dlen || arrv_dlen != new_dlen)\n\t\treturn;\n\n\t/* Synch generation numbers with peer if link just came up */\n\tif (!state->synched) {\n\t\tstate->peer_gen = new_gen - 1;\n\t\tstate->acked_gen = acked_gen;\n\t\tstate->synched = true;\n\t}\n\n\tif (more(acked_gen, state->acked_gen))\n\t\tstate->acked_gen = acked_gen;\n\n\t/* Drop duplicate unless we are waiting for a probe response */\n\tif (!more(new_gen, state->peer_gen) && !probing)\n\t\treturn;\n\n\twrite_lock_bh(&mon->lock);\n\tpeer = get_peer(mon, addr);\n\tif (!peer || !peer->is_up)\n\t\tgoto exit;\n\n\t/* Peer is confirmed, stop any ongoing probing */\n\tpeer->down_cnt = 0;\n\n\t/* Task is done for duplicate record */\n\tif (!more(new_gen, state->peer_gen))\n\t\tgoto exit;\n\n\tstate->peer_gen = new_gen;\n\n\t/* Cache current domain record for later use */\n\tdom_bef.member_cnt = 0;\n\tdom = peer->domain;\n\tif (dom)\n\t\tmemcpy(&dom_bef, dom, dom->len);\n\n\t/* Transform and store received domain record */\n\tif (!dom || (dom->len < new_dlen)) {\n\t\tkfree(dom);\n\t\tdom = kmalloc(new_dlen, GFP_ATOMIC);\n\t\tpeer->domain = dom;\n\t\tif (!dom)\n\t\t\tgoto exit;\n\t}\n\tdom->len = new_dlen;\n\tdom->gen = new_gen;\n\tdom->member_cnt = new_member_cnt;\n\tdom->up_map = mon_le64_to_cpu(arrv_dom->up_map);\n\tfor (i = 0; i < new_member_cnt; i++)\n\t\tdom->members[i] = mon_le32_to_cpu(arrv_dom->members[i]);\n\n\t/* Update peers affected by this domain record */\n\tapplied_bef = peer->applied;\n\tmon_apply_domain(mon, peer);\n\tmon_identify_lost_members(peer, &dom_bef, applied_bef);\n\tmon_assign_roles(mon, peer_head(peer));\nexit:\n\twrite_unlock_bh(&mon->lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,8 @@\n \tstate->probing = false;\n \n \t/* Sanity check received domain record */\n+\tif (new_member_cnt > MAX_MON_DOMAIN)\n+\t\treturn;\n \tif (dlen < dom_rec_len(arrv_dom, 0))\n \t\treturn;\n \tif (dlen != dom_rec_len(arrv_dom, new_member_cnt))",
        "function_modified_lines": {
            "added": [
                "\tif (new_member_cnt > MAX_MON_DOMAIN)",
                "\t\treturn;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A stack overflow flaw was found in the Linux kernel's TIPC protocol functionality in the way a user sends a packet with malicious content where the number of domain member nodes is higher than the 64 allowed. This flaw allows a remote user to crash the system or possibly escalate their privileges if they have access to the TIPC network."
    },
    {
        "cve_id": "CVE-2022-0995",
        "code_before_change": "long watch_queue_set_filter(struct pipe_inode_info *pipe,\n\t\t\t    struct watch_notification_filter __user *_filter)\n{\n\tstruct watch_notification_type_filter *tf;\n\tstruct watch_notification_filter filter;\n\tstruct watch_type_filter *q;\n\tstruct watch_filter *wfilter;\n\tstruct watch_queue *wqueue = pipe->watch_queue;\n\tint ret, nr_filter = 0, i;\n\n\tif (!wqueue)\n\t\treturn -ENODEV;\n\n\tif (!_filter) {\n\t\t/* Remove the old filter */\n\t\twfilter = NULL;\n\t\tgoto set;\n\t}\n\n\t/* Grab the user's filter specification */\n\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)\n\t\treturn -EFAULT;\n\tif (filter.nr_filters == 0 ||\n\t    filter.nr_filters > 16 ||\n\t    filter.__reserved != 0)\n\t\treturn -EINVAL;\n\n\ttf = memdup_user(_filter->filters, filter.nr_filters * sizeof(*tf));\n\tif (IS_ERR(tf))\n\t\treturn PTR_ERR(tf);\n\n\tret = -EINVAL;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||\n\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)\n\t\t\tgoto err_filter;\n\t\t/* Ignore any unknown types */\n\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * 8)\n\t\t\tcontinue;\n\t\tnr_filter++;\n\t}\n\n\t/* Now we need to build the internal filter from only the relevant\n\t * user-specified filters.\n\t */\n\tret = -ENOMEM;\n\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);\n\tif (!wfilter)\n\t\tgoto err_filter;\n\twfilter->nr_filters = nr_filter;\n\n\tq = wfilter->filters;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * BITS_PER_LONG)\n\t\t\tcontinue;\n\n\t\tq->type\t\t\t= tf[i].type;\n\t\tq->info_filter\t\t= tf[i].info_filter;\n\t\tq->info_mask\t\t= tf[i].info_mask;\n\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];\n\t\t__set_bit(q->type, wfilter->type_filter);\n\t\tq++;\n\t}\n\n\tkfree(tf);\nset:\n\tpipe_lock(pipe);\n\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,\n\t\t\t\t      lockdep_is_held(&pipe->mutex));\n\tpipe_unlock(pipe);\n\tif (wfilter)\n\t\tkfree_rcu(wfilter, rcu);\n\treturn 0;\n\nerr_filter:\n\tkfree(tf);\n\treturn ret;\n}",
        "code_after_change": "long watch_queue_set_filter(struct pipe_inode_info *pipe,\n\t\t\t    struct watch_notification_filter __user *_filter)\n{\n\tstruct watch_notification_type_filter *tf;\n\tstruct watch_notification_filter filter;\n\tstruct watch_type_filter *q;\n\tstruct watch_filter *wfilter;\n\tstruct watch_queue *wqueue = pipe->watch_queue;\n\tint ret, nr_filter = 0, i;\n\n\tif (!wqueue)\n\t\treturn -ENODEV;\n\n\tif (!_filter) {\n\t\t/* Remove the old filter */\n\t\twfilter = NULL;\n\t\tgoto set;\n\t}\n\n\t/* Grab the user's filter specification */\n\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)\n\t\treturn -EFAULT;\n\tif (filter.nr_filters == 0 ||\n\t    filter.nr_filters > 16 ||\n\t    filter.__reserved != 0)\n\t\treturn -EINVAL;\n\n\ttf = memdup_user(_filter->filters, filter.nr_filters * sizeof(*tf));\n\tif (IS_ERR(tf))\n\t\treturn PTR_ERR(tf);\n\n\tret = -EINVAL;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||\n\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)\n\t\t\tgoto err_filter;\n\t\t/* Ignore any unknown types */\n\t\tif (tf[i].type >= WATCH_TYPE__NR)\n\t\t\tcontinue;\n\t\tnr_filter++;\n\t}\n\n\t/* Now we need to build the internal filter from only the relevant\n\t * user-specified filters.\n\t */\n\tret = -ENOMEM;\n\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);\n\tif (!wfilter)\n\t\tgoto err_filter;\n\twfilter->nr_filters = nr_filter;\n\n\tq = wfilter->filters;\n\tfor (i = 0; i < filter.nr_filters; i++) {\n\t\tif (tf[i].type >= WATCH_TYPE__NR)\n\t\t\tcontinue;\n\n\t\tq->type\t\t\t= tf[i].type;\n\t\tq->info_filter\t\t= tf[i].info_filter;\n\t\tq->info_mask\t\t= tf[i].info_mask;\n\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];\n\t\t__set_bit(q->type, wfilter->type_filter);\n\t\tq++;\n\t}\n\n\tkfree(tf);\nset:\n\tpipe_lock(pipe);\n\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,\n\t\t\t\t      lockdep_is_held(&pipe->mutex));\n\tpipe_unlock(pipe);\n\tif (wfilter)\n\t\tkfree_rcu(wfilter, rcu);\n\treturn 0;\n\nerr_filter:\n\tkfree(tf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,7 +35,7 @@\n \t\t    tf[i].info_mask & WATCH_INFO_LENGTH)\n \t\t\tgoto err_filter;\n \t\t/* Ignore any unknown types */\n-\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * 8)\n+\t\tif (tf[i].type >= WATCH_TYPE__NR)\n \t\t\tcontinue;\n \t\tnr_filter++;\n \t}\n@@ -51,7 +51,7 @@\n \n \tq = wfilter->filters;\n \tfor (i = 0; i < filter.nr_filters; i++) {\n-\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * BITS_PER_LONG)\n+\t\tif (tf[i].type >= WATCH_TYPE__NR)\n \t\t\tcontinue;\n \n \t\tq->type\t\t\t= tf[i].type;",
        "function_modified_lines": {
            "added": [
                "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
                "\t\tif (tf[i].type >= WATCH_TYPE__NR)"
            ],
            "deleted": [
                "\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * 8)",
                "\t\tif (tf[i].type >= sizeof(wfilter->type_filter) * BITS_PER_LONG)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds (OOB) memory write flaw was found in the Linux kernel\u2019s watch_queue event notification subsystem. This flaw can overwrite parts of the kernel state, potentially allowing a local user to gain privileged access or cause a denial of service on the system."
    },
    {
        "cve_id": "CVE-2022-1015",
        "code_before_change": "int nft_parse_register_load(const struct nlattr *attr, u8 *sreg, u32 len)\n{\n\tu32 reg;\n\tint err;\n\n\treg = nft_parse_register(attr);\n\terr = nft_validate_register_load(reg, len);\n\tif (err < 0)\n\t\treturn err;\n\n\t*sreg = reg;\n\treturn 0;\n}",
        "code_after_change": "int nft_parse_register_load(const struct nlattr *attr, u8 *sreg, u32 len)\n{\n\tu32 reg;\n\tint err;\n\n\terr = nft_parse_register(attr, &reg);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = nft_validate_register_load(reg, len);\n\tif (err < 0)\n\t\treturn err;\n\n\t*sreg = reg;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,10 @@\n \tu32 reg;\n \tint err;\n \n-\treg = nft_parse_register(attr);\n+\terr = nft_parse_register(attr, &reg);\n+\tif (err < 0)\n+\t\treturn err;\n+\n \terr = nft_validate_register_load(reg, len);\n \tif (err < 0)\n \t\treturn err;",
        "function_modified_lines": {
            "added": [
                "\terr = nft_parse_register(attr, &reg);",
                "\tif (err < 0)",
                "\t\treturn err;",
                ""
            ],
            "deleted": [
                "\treg = nft_parse_register(attr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in linux/net/netfilter/nf_tables_api.c of the netfilter subsystem. This flaw allows a local user to cause an out-of-bounds write issue."
    },
    {
        "cve_id": "CVE-2022-1015",
        "code_before_change": "int nft_parse_register_store(const struct nft_ctx *ctx,\n\t\t\t     const struct nlattr *attr, u8 *dreg,\n\t\t\t     const struct nft_data *data,\n\t\t\t     enum nft_data_types type, unsigned int len)\n{\n\tint err;\n\tu32 reg;\n\n\treg = nft_parse_register(attr);\n\terr = nft_validate_register_store(ctx, reg, data, type, len);\n\tif (err < 0)\n\t\treturn err;\n\n\t*dreg = reg;\n\treturn 0;\n}",
        "code_after_change": "int nft_parse_register_store(const struct nft_ctx *ctx,\n\t\t\t     const struct nlattr *attr, u8 *dreg,\n\t\t\t     const struct nft_data *data,\n\t\t\t     enum nft_data_types type, unsigned int len)\n{\n\tint err;\n\tu32 reg;\n\n\terr = nft_parse_register(attr, &reg);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = nft_validate_register_store(ctx, reg, data, type, len);\n\tif (err < 0)\n\t\treturn err;\n\n\t*dreg = reg;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,10 @@\n \tint err;\n \tu32 reg;\n \n-\treg = nft_parse_register(attr);\n+\terr = nft_parse_register(attr, &reg);\n+\tif (err < 0)\n+\t\treturn err;\n+\n \terr = nft_validate_register_store(ctx, reg, data, type, len);\n \tif (err < 0)\n \t\treturn err;",
        "function_modified_lines": {
            "added": [
                "\terr = nft_parse_register(attr, &reg);",
                "\tif (err < 0)",
                "\t\treturn err;",
                ""
            ],
            "deleted": [
                "\treg = nft_parse_register(attr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the Linux kernel in linux/net/netfilter/nf_tables_api.c of the netfilter subsystem. This flaw allows a local user to cause an out-of-bounds write issue."
    },
    {
        "cve_id": "CVE-2022-1943",
        "code_before_change": "int udf_write_fi(struct inode *inode, struct fileIdentDesc *cfi,\n\t\t struct fileIdentDesc *sfi, struct udf_fileident_bh *fibh,\n\t\t uint8_t *impuse, uint8_t *fileident)\n{\n\tuint16_t crclen = fibh->eoffset - fibh->soffset - sizeof(struct tag);\n\tuint16_t crc;\n\tint offset;\n\tuint16_t liu = le16_to_cpu(cfi->lengthOfImpUse);\n\tuint8_t lfi = cfi->lengthFileIdent;\n\tint padlen = fibh->eoffset - fibh->soffset - liu - lfi -\n\t\tsizeof(struct fileIdentDesc);\n\tint adinicb = 0;\n\n\tif (UDF_I(inode)->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\tadinicb = 1;\n\n\toffset = fibh->soffset + sizeof(struct fileIdentDesc);\n\n\tif (impuse) {\n\t\tif (adinicb || (offset + liu < 0)) {\n\t\t\tmemcpy((uint8_t *)sfi->impUse, impuse, liu);\n\t\t} else if (offset >= 0) {\n\t\t\tmemcpy(fibh->ebh->b_data + offset, impuse, liu);\n\t\t} else {\n\t\t\tmemcpy((uint8_t *)sfi->impUse, impuse, -offset);\n\t\t\tmemcpy(fibh->ebh->b_data, impuse - offset,\n\t\t\t\tliu + offset);\n\t\t}\n\t}\n\n\toffset += liu;\n\n\tif (fileident) {\n\t\tif (adinicb || (offset + lfi < 0)) {\n\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, lfi);\n\t\t} else if (offset >= 0) {\n\t\t\tmemcpy(fibh->ebh->b_data + offset, fileident, lfi);\n\t\t} else {\n\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, -offset);\n\t\t\tmemcpy(fibh->ebh->b_data, fileident - offset,\n\t\t\t\tlfi + offset);\n\t\t}\n\t}\n\n\toffset += lfi;\n\n\tif (adinicb || (offset + padlen < 0)) {\n\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, padlen);\n\t} else if (offset >= 0) {\n\t\tmemset(fibh->ebh->b_data + offset, 0x00, padlen);\n\t} else {\n\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, -offset);\n\t\tmemset(fibh->ebh->b_data, 0x00, padlen + offset);\n\t}\n\n\tcrc = crc_itu_t(0, (uint8_t *)cfi + sizeof(struct tag),\n\t\t      sizeof(struct fileIdentDesc) - sizeof(struct tag));\n\n\tif (fibh->sbh == fibh->ebh) {\n\t\tcrc = crc_itu_t(crc, (uint8_t *)sfi->impUse,\n\t\t\t      crclen + sizeof(struct tag) -\n\t\t\t      sizeof(struct fileIdentDesc));\n\t} else if (sizeof(struct fileIdentDesc) >= -fibh->soffset) {\n\t\tcrc = crc_itu_t(crc, fibh->ebh->b_data +\n\t\t\t\t\tsizeof(struct fileIdentDesc) +\n\t\t\t\t\tfibh->soffset,\n\t\t\t      crclen + sizeof(struct tag) -\n\t\t\t\t\tsizeof(struct fileIdentDesc));\n\t} else {\n\t\tcrc = crc_itu_t(crc, (uint8_t *)sfi->impUse,\n\t\t\t      -fibh->soffset - sizeof(struct fileIdentDesc));\n\t\tcrc = crc_itu_t(crc, fibh->ebh->b_data, fibh->eoffset);\n\t}\n\n\tcfi->descTag.descCRC = cpu_to_le16(crc);\n\tcfi->descTag.descCRCLength = cpu_to_le16(crclen);\n\tcfi->descTag.tagChecksum = udf_tag_checksum(&cfi->descTag);\n\n\tif (adinicb || (sizeof(struct fileIdentDesc) <= -fibh->soffset)) {\n\t\tmemcpy((uint8_t *)sfi, (uint8_t *)cfi,\n\t\t\tsizeof(struct fileIdentDesc));\n\t} else {\n\t\tmemcpy((uint8_t *)sfi, (uint8_t *)cfi, -fibh->soffset);\n\t\tmemcpy(fibh->ebh->b_data, (uint8_t *)cfi - fibh->soffset,\n\t\t       sizeof(struct fileIdentDesc) + fibh->soffset);\n\t}\n\n\tif (adinicb) {\n\t\tmark_inode_dirty(inode);\n\t} else {\n\t\tif (fibh->sbh != fibh->ebh)\n\t\t\tmark_buffer_dirty_inode(fibh->ebh, inode);\n\t\tmark_buffer_dirty_inode(fibh->sbh, inode);\n\t}\n\tinode_inc_iversion(inode);\n\n\treturn 0;\n}",
        "code_after_change": "int udf_write_fi(struct inode *inode, struct fileIdentDesc *cfi,\n\t\t struct fileIdentDesc *sfi, struct udf_fileident_bh *fibh,\n\t\t uint8_t *impuse, uint8_t *fileident)\n{\n\tuint16_t crclen = fibh->eoffset - fibh->soffset - sizeof(struct tag);\n\tuint16_t crc;\n\tint offset;\n\tuint16_t liu = le16_to_cpu(cfi->lengthOfImpUse);\n\tuint8_t lfi = cfi->lengthFileIdent;\n\tint padlen = fibh->eoffset - fibh->soffset - liu - lfi -\n\t\tsizeof(struct fileIdentDesc);\n\tint adinicb = 0;\n\n\tif (UDF_I(inode)->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\tadinicb = 1;\n\n\toffset = fibh->soffset + sizeof(struct fileIdentDesc);\n\n\tif (impuse) {\n\t\tif (adinicb || (offset + liu < 0)) {\n\t\t\tmemcpy((uint8_t *)sfi->impUse, impuse, liu);\n\t\t} else if (offset >= 0) {\n\t\t\tmemcpy(fibh->ebh->b_data + offset, impuse, liu);\n\t\t} else {\n\t\t\tmemcpy((uint8_t *)sfi->impUse, impuse, -offset);\n\t\t\tmemcpy(fibh->ebh->b_data, impuse - offset,\n\t\t\t\tliu + offset);\n\t\t}\n\t}\n\n\toffset += liu;\n\n\tif (fileident) {\n\t\tif (adinicb || (offset + lfi < 0)) {\n\t\t\tmemcpy(sfi->impUse + liu, fileident, lfi);\n\t\t} else if (offset >= 0) {\n\t\t\tmemcpy(fibh->ebh->b_data + offset, fileident, lfi);\n\t\t} else {\n\t\t\tmemcpy(sfi->impUse + liu, fileident, -offset);\n\t\t\tmemcpy(fibh->ebh->b_data, fileident - offset,\n\t\t\t\tlfi + offset);\n\t\t}\n\t}\n\n\toffset += lfi;\n\n\tif (adinicb || (offset + padlen < 0)) {\n\t\tmemset(sfi->impUse + liu + lfi, 0x00, padlen);\n\t} else if (offset >= 0) {\n\t\tmemset(fibh->ebh->b_data + offset, 0x00, padlen);\n\t} else {\n\t\tmemset(sfi->impUse + liu + lfi, 0x00, -offset);\n\t\tmemset(fibh->ebh->b_data, 0x00, padlen + offset);\n\t}\n\n\tcrc = crc_itu_t(0, (uint8_t *)cfi + sizeof(struct tag),\n\t\t      sizeof(struct fileIdentDesc) - sizeof(struct tag));\n\n\tif (fibh->sbh == fibh->ebh) {\n\t\tcrc = crc_itu_t(crc, (uint8_t *)sfi->impUse,\n\t\t\t      crclen + sizeof(struct tag) -\n\t\t\t      sizeof(struct fileIdentDesc));\n\t} else if (sizeof(struct fileIdentDesc) >= -fibh->soffset) {\n\t\tcrc = crc_itu_t(crc, fibh->ebh->b_data +\n\t\t\t\t\tsizeof(struct fileIdentDesc) +\n\t\t\t\t\tfibh->soffset,\n\t\t\t      crclen + sizeof(struct tag) -\n\t\t\t\t\tsizeof(struct fileIdentDesc));\n\t} else {\n\t\tcrc = crc_itu_t(crc, (uint8_t *)sfi->impUse,\n\t\t\t      -fibh->soffset - sizeof(struct fileIdentDesc));\n\t\tcrc = crc_itu_t(crc, fibh->ebh->b_data, fibh->eoffset);\n\t}\n\n\tcfi->descTag.descCRC = cpu_to_le16(crc);\n\tcfi->descTag.descCRCLength = cpu_to_le16(crclen);\n\tcfi->descTag.tagChecksum = udf_tag_checksum(&cfi->descTag);\n\n\tif (adinicb || (sizeof(struct fileIdentDesc) <= -fibh->soffset)) {\n\t\tmemcpy((uint8_t *)sfi, (uint8_t *)cfi,\n\t\t\tsizeof(struct fileIdentDesc));\n\t} else {\n\t\tmemcpy((uint8_t *)sfi, (uint8_t *)cfi, -fibh->soffset);\n\t\tmemcpy(fibh->ebh->b_data, (uint8_t *)cfi - fibh->soffset,\n\t\t       sizeof(struct fileIdentDesc) + fibh->soffset);\n\t}\n\n\tif (adinicb) {\n\t\tmark_inode_dirty(inode);\n\t} else {\n\t\tif (fibh->sbh != fibh->ebh)\n\t\t\tmark_buffer_dirty_inode(fibh->ebh, inode);\n\t\tmark_buffer_dirty_inode(fibh->sbh, inode);\n\t}\n\tinode_inc_iversion(inode);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,11 +32,11 @@\n \n \tif (fileident) {\n \t\tif (adinicb || (offset + lfi < 0)) {\n-\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, lfi);\n+\t\t\tmemcpy(sfi->impUse + liu, fileident, lfi);\n \t\t} else if (offset >= 0) {\n \t\t\tmemcpy(fibh->ebh->b_data + offset, fileident, lfi);\n \t\t} else {\n-\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, -offset);\n+\t\t\tmemcpy(sfi->impUse + liu, fileident, -offset);\n \t\t\tmemcpy(fibh->ebh->b_data, fileident - offset,\n \t\t\t\tlfi + offset);\n \t\t}\n@@ -45,11 +45,11 @@\n \toffset += lfi;\n \n \tif (adinicb || (offset + padlen < 0)) {\n-\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, padlen);\n+\t\tmemset(sfi->impUse + liu + lfi, 0x00, padlen);\n \t} else if (offset >= 0) {\n \t\tmemset(fibh->ebh->b_data + offset, 0x00, padlen);\n \t} else {\n-\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, -offset);\n+\t\tmemset(sfi->impUse + liu + lfi, 0x00, -offset);\n \t\tmemset(fibh->ebh->b_data, 0x00, padlen + offset);\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\tmemcpy(sfi->impUse + liu, fileident, lfi);",
                "\t\t\tmemcpy(sfi->impUse + liu, fileident, -offset);",
                "\t\tmemset(sfi->impUse + liu + lfi, 0x00, padlen);",
                "\t\tmemset(sfi->impUse + liu + lfi, 0x00, -offset);"
            ],
            "deleted": [
                "\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, lfi);",
                "\t\t\tmemcpy(udf_get_fi_ident(sfi), fileident, -offset);",
                "\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, padlen);",
                "\t\tmemset(udf_get_fi_ident(sfi) + lfi, 0x00, -offset);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw out of bounds memory write in the Linux kernel UDF file system functionality was found in the way user triggers some file operation which triggers udf_write_fi(). A local user could use this flaw to crash the system or potentially"
    },
    {
        "cve_id": "CVE-2022-20369",
        "code_before_change": "int v4l2_m2m_qbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t  struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    (buf->flags & V4L2_BUF_FLAG_REQUEST_FD)) {\n\t\tdprintk(\"%s: requests cannot be used with capture buffers\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\tret = vb2_qbuf(vq, vdev->v4l2_dev->mdev, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * If the capture queue is streaming, but streaming hasn't started\n\t * on the device, but was asked to stop, mark the previously queued\n\t * buffer as DONE with LAST flag since it won't be queued on the\n\t * device.\n\t */\n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    vb2_is_streaming(vq) && !vb2_start_streaming_called(vq) &&\n\t   (v4l2_m2m_has_stopped(m2m_ctx) || v4l2_m2m_dst_buf_is_last(m2m_ctx)))\n\t\tv4l2_m2m_force_last_buf_done(m2m_ctx, vq);\n\telse if (!(buf->flags & V4L2_BUF_FLAG_IN_REQUEST))\n\t\tv4l2_m2m_try_schedule(m2m_ctx);\n\n\treturn 0;\n}",
        "code_after_change": "int v4l2_m2m_qbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t  struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    (buf->flags & V4L2_BUF_FLAG_REQUEST_FD)) {\n\t\tdprintk(\"%s: requests cannot be used with capture buffers\\n\",\n\t\t\t__func__);\n\t\treturn -EPERM;\n\t}\n\n\tret = vb2_qbuf(vq, vdev->v4l2_dev->mdev, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\t/*\n\t * If the capture queue is streaming, but streaming hasn't started\n\t * on the device, but was asked to stop, mark the previously queued\n\t * buffer as DONE with LAST flag since it won't be queued on the\n\t * device.\n\t */\n\tif (V4L2_TYPE_IS_CAPTURE(vq->type) &&\n\t    vb2_is_streaming(vq) && !vb2_start_streaming_called(vq) &&\n\t   (v4l2_m2m_has_stopped(m2m_ctx) || v4l2_m2m_dst_buf_is_last(m2m_ctx)))\n\t\tv4l2_m2m_force_last_buf_done(m2m_ctx, vq);\n\telse if (!(buf->flags & V4L2_BUF_FLAG_IN_REQUEST))\n\t\tv4l2_m2m_try_schedule(m2m_ctx);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,9 @@\n \tif (ret)\n \t\treturn ret;\n \n+\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n+\tv4l2_m2m_adjust_mem_offset(vq, buf);\n+\n \t/*\n \t * If the capture queue is streaming, but streaming hasn't started\n \t * on the device, but was asked to stop, mark the previously queued",
        "function_modified_lines": {
            "added": [
                "\t/* Adjust MMAP memory offsets for the CAPTURE queue */",
                "\tv4l2_m2m_adjust_mem_offset(vq, buf);",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In v4l2_m2m_querybuf of v4l2-mem2mem.c, there is a possible out of bounds write due to improper input validation. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-223375145References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2022-20369",
        "code_before_change": "int v4l2_m2m_prepare_buf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\treturn vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);\n}",
        "code_after_change": "int v4l2_m2m_prepare_buf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t\t struct v4l2_buffer *buf)\n{\n\tstruct video_device *vdev = video_devdata(file);\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,15 @@\n {\n \tstruct video_device *vdev = video_devdata(file);\n \tstruct vb2_queue *vq;\n+\tint ret;\n \n \tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n-\treturn vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);\n+\tret = vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n+\tv4l2_m2m_adjust_mem_offset(vq, buf);\n+\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tint ret;",
                "\tret = vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);",
                "\tif (ret)",
                "\t\treturn ret;",
                "",
                "\t/* Adjust MMAP memory offsets for the CAPTURE queue */",
                "\tv4l2_m2m_adjust_mem_offset(vq, buf);",
                "",
                "\treturn 0;"
            ],
            "deleted": [
                "\treturn vb2_prepare_buf(vq, vdev->v4l2_dev->mdev, buf);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In v4l2_m2m_querybuf of v4l2-mem2mem.c, there is a possible out of bounds write due to improper input validation. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-223375145References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2022-20369",
        "code_before_change": "int v4l2_m2m_dqbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t   struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\treturn vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);\n}",
        "code_after_change": "int v4l2_m2m_dqbuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t   struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,15 @@\n \t\t   struct v4l2_buffer *buf)\n {\n \tstruct vb2_queue *vq;\n+\tint ret;\n \n \tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n-\treturn vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);\n+\tret = vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);\n+\tif (ret)\n+\t\treturn ret;\n+\n+\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n+\tv4l2_m2m_adjust_mem_offset(vq, buf);\n+\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tint ret;",
                "\tret = vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);",
                "\tif (ret)",
                "\t\treturn ret;",
                "",
                "\t/* Adjust MMAP memory offsets for the CAPTURE queue */",
                "\tv4l2_m2m_adjust_mem_offset(vq, buf);",
                "",
                "\treturn 0;"
            ],
            "deleted": [
                "\treturn vb2_dqbuf(vq, buf, file->f_flags & O_NONBLOCK);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In v4l2_m2m_querybuf of v4l2-mem2mem.c, there is a possible out of bounds write due to improper input validation. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-223375145References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2022-20369",
        "code_before_change": "int v4l2_m2m_querybuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t      struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\tint ret = 0;\n\tunsigned int i;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_querybuf(vq, buf);\n\n\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n\tif (buf->memory == V4L2_MEMORY_MMAP && V4L2_TYPE_IS_CAPTURE(vq->type)) {\n\t\tif (V4L2_TYPE_IS_MULTIPLANAR(vq->type)) {\n\t\t\tfor (i = 0; i < buf->length; ++i)\n\t\t\t\tbuf->m.planes[i].m.mem_offset\n\t\t\t\t\t+= DST_QUEUE_OFF_BASE;\n\t\t} else {\n\t\t\tbuf->m.offset += DST_QUEUE_OFF_BASE;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "int v4l2_m2m_querybuf(struct file *file, struct v4l2_m2m_ctx *m2m_ctx,\n\t\t      struct v4l2_buffer *buf)\n{\n\tstruct vb2_queue *vq;\n\tint ret;\n\n\tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n\tret = vb2_querybuf(vq, buf);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Adjust MMAP memory offsets for the CAPTURE queue */\n\tv4l2_m2m_adjust_mem_offset(vq, buf);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,22 +2,15 @@\n \t\t      struct v4l2_buffer *buf)\n {\n \tstruct vb2_queue *vq;\n-\tint ret = 0;\n-\tunsigned int i;\n+\tint ret;\n \n \tvq = v4l2_m2m_get_vq(m2m_ctx, buf->type);\n \tret = vb2_querybuf(vq, buf);\n+\tif (ret)\n+\t\treturn ret;\n \n \t/* Adjust MMAP memory offsets for the CAPTURE queue */\n-\tif (buf->memory == V4L2_MEMORY_MMAP && V4L2_TYPE_IS_CAPTURE(vq->type)) {\n-\t\tif (V4L2_TYPE_IS_MULTIPLANAR(vq->type)) {\n-\t\t\tfor (i = 0; i < buf->length; ++i)\n-\t\t\t\tbuf->m.planes[i].m.mem_offset\n-\t\t\t\t\t+= DST_QUEUE_OFF_BASE;\n-\t\t} else {\n-\t\t\tbuf->m.offset += DST_QUEUE_OFF_BASE;\n-\t\t}\n-\t}\n+\tv4l2_m2m_adjust_mem_offset(vq, buf);\n \n-\treturn ret;\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tint ret;",
                "\tif (ret)",
                "\t\treturn ret;",
                "\tv4l2_m2m_adjust_mem_offset(vq, buf);",
                "\treturn 0;"
            ],
            "deleted": [
                "\tint ret = 0;",
                "\tunsigned int i;",
                "\tif (buf->memory == V4L2_MEMORY_MMAP && V4L2_TYPE_IS_CAPTURE(vq->type)) {",
                "\t\tif (V4L2_TYPE_IS_MULTIPLANAR(vq->type)) {",
                "\t\t\tfor (i = 0; i < buf->length; ++i)",
                "\t\t\t\tbuf->m.planes[i].m.mem_offset",
                "\t\t\t\t\t+= DST_QUEUE_OFF_BASE;",
                "\t\t} else {",
                "\t\t\tbuf->m.offset += DST_QUEUE_OFF_BASE;",
                "\t\t}",
                "\t}",
                "\treturn ret;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In v4l2_m2m_querybuf of v4l2-mem2mem.c, there is a possible out of bounds write due to improper input validation. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-223375145References: Upstream kernel"
    },
    {
        "cve_id": "CVE-2022-21499",
        "code_before_change": "static int kgdb_cpu_enter(struct kgdb_state *ks, struct pt_regs *regs,\n\t\tint exception_state)\n{\n\tunsigned long flags;\n\tint sstep_tries = 100;\n\tint error;\n\tint cpu;\n\tint trace_on = 0;\n\tint online_cpus = num_online_cpus();\n\tu64 time_left;\n\n\tkgdb_info[ks->cpu].enter_kgdb++;\n\tkgdb_info[ks->cpu].exception_state |= exception_state;\n\n\tif (exception_state == DCPU_WANT_MASTER)\n\t\tatomic_inc(&masters_in_kgdb);\n\telse\n\t\tatomic_inc(&slaves_in_kgdb);\n\n\tif (arch_kgdb_ops.disable_hw_break)\n\t\tarch_kgdb_ops.disable_hw_break(regs);\n\nacquirelock:\n\trcu_read_lock();\n\t/*\n\t * Interrupts will be restored by the 'trap return' code, except when\n\t * single stepping.\n\t */\n\tlocal_irq_save(flags);\n\n\tcpu = ks->cpu;\n\tkgdb_info[cpu].debuggerinfo = regs;\n\tkgdb_info[cpu].task = current;\n\tkgdb_info[cpu].ret_state = 0;\n\tkgdb_info[cpu].irq_depth = hardirq_count() >> HARDIRQ_SHIFT;\n\n\t/* Make sure the above info reaches the primary CPU */\n\tsmp_mb();\n\n\tif (exception_level == 1) {\n\t\tif (raw_spin_trylock(&dbg_master_lock))\n\t\t\tatomic_xchg(&kgdb_active, cpu);\n\t\tgoto cpu_master_loop;\n\t}\n\n\t/*\n\t * CPU will loop if it is a slave or request to become a kgdb\n\t * master cpu and acquire the kgdb_active lock:\n\t */\n\twhile (1) {\ncpu_loop:\n\t\tif (kgdb_info[cpu].exception_state & DCPU_NEXT_MASTER) {\n\t\t\tkgdb_info[cpu].exception_state &= ~DCPU_NEXT_MASTER;\n\t\t\tgoto cpu_master_loop;\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_WANT_MASTER) {\n\t\t\tif (raw_spin_trylock(&dbg_master_lock)) {\n\t\t\t\tatomic_xchg(&kgdb_active, cpu);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_WANT_BT) {\n\t\t\tdump_stack();\n\t\t\tkgdb_info[cpu].exception_state &= ~DCPU_WANT_BT;\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_IS_SLAVE) {\n\t\t\tif (!raw_spin_is_locked(&dbg_slave_lock))\n\t\t\t\tgoto return_normal;\n\t\t} else {\nreturn_normal:\n\t\t\t/* Return to normal operation by executing any\n\t\t\t * hw breakpoint fixup.\n\t\t\t */\n\t\t\tif (arch_kgdb_ops.correct_hw_break)\n\t\t\t\tarch_kgdb_ops.correct_hw_break();\n\t\t\tif (trace_on)\n\t\t\t\ttracing_on();\n\t\t\tkgdb_info[cpu].debuggerinfo = NULL;\n\t\t\tkgdb_info[cpu].task = NULL;\n\t\t\tkgdb_info[cpu].exception_state &=\n\t\t\t\t~(DCPU_WANT_MASTER | DCPU_IS_SLAVE);\n\t\t\tkgdb_info[cpu].enter_kgdb--;\n\t\t\tsmp_mb__before_atomic();\n\t\t\tatomic_dec(&slaves_in_kgdb);\n\t\t\tdbg_touch_watchdogs();\n\t\t\tlocal_irq_restore(flags);\n\t\t\trcu_read_unlock();\n\t\t\treturn 0;\n\t\t}\n\t\tcpu_relax();\n\t}\n\n\t/*\n\t * For single stepping, try to only enter on the processor\n\t * that was single stepping.  To guard against a deadlock, the\n\t * kernel will only try for the value of sstep_tries before\n\t * giving up and continuing on.\n\t */\n\tif (atomic_read(&kgdb_cpu_doing_single_step) != -1 &&\n\t    (kgdb_info[cpu].task &&\n\t     kgdb_info[cpu].task->pid != kgdb_sstep_pid) && --sstep_tries) {\n\t\tatomic_set(&kgdb_active, -1);\n\t\traw_spin_unlock(&dbg_master_lock);\n\t\tdbg_touch_watchdogs();\n\t\tlocal_irq_restore(flags);\n\t\trcu_read_unlock();\n\n\t\tgoto acquirelock;\n\t}\n\n\tif (!kgdb_io_ready(1)) {\n\t\tkgdb_info[cpu].ret_state = 1;\n\t\tgoto kgdb_restore; /* No I/O connection, resume the system */\n\t}\n\n\t/*\n\t * Don't enter if we have hit a removed breakpoint.\n\t */\n\tif (kgdb_skipexception(ks->ex_vector, ks->linux_regs))\n\t\tgoto kgdb_restore;\n\n\tatomic_inc(&ignore_console_lock_warning);\n\n\t/* Call the I/O driver's pre_exception routine */\n\tif (dbg_io_ops->pre_exception)\n\t\tdbg_io_ops->pre_exception();\n\n\t/*\n\t * Get the passive CPU lock which will hold all the non-primary\n\t * CPU in a spin state while the debugger is active\n\t */\n\tif (!kgdb_single_step)\n\t\traw_spin_lock(&dbg_slave_lock);\n\n#ifdef CONFIG_SMP\n\t/* If send_ready set, slaves are already waiting */\n\tif (ks->send_ready)\n\t\tatomic_set(ks->send_ready, 1);\n\n\t/* Signal the other CPUs to enter kgdb_wait() */\n\telse if ((!kgdb_single_step) && kgdb_do_roundup)\n\t\tkgdb_roundup_cpus();\n#endif\n\n\t/*\n\t * Wait for the other CPUs to be notified and be waiting for us:\n\t */\n\ttime_left = MSEC_PER_SEC;\n\twhile (kgdb_do_roundup && --time_left &&\n\t       (atomic_read(&masters_in_kgdb) + atomic_read(&slaves_in_kgdb)) !=\n\t\t   online_cpus)\n\t\tudelay(1000);\n\tif (!time_left)\n\t\tpr_crit(\"Timed out waiting for secondary CPUs.\\n\");\n\n\t/*\n\t * At this point the primary processor is completely\n\t * in the debugger and all secondary CPUs are quiescent\n\t */\n\tdbg_deactivate_sw_breakpoints();\n\tkgdb_single_step = 0;\n\tkgdb_contthread = current;\n\texception_level = 0;\n\ttrace_on = tracing_is_on();\n\tif (trace_on)\n\t\ttracing_off();\n\n\twhile (1) {\ncpu_master_loop:\n\t\tif (dbg_kdb_mode) {\n\t\t\tkgdb_connected = 1;\n\t\t\terror = kdb_stub(ks);\n\t\t\tif (error == -1)\n\t\t\t\tcontinue;\n\t\t\tkgdb_connected = 0;\n\t\t} else {\n\t\t\terror = gdb_serial_stub(ks);\n\t\t}\n\n\t\tif (error == DBG_PASS_EVENT) {\n\t\t\tdbg_kdb_mode = !dbg_kdb_mode;\n\t\t} else if (error == DBG_SWITCH_CPU_EVENT) {\n\t\t\tkgdb_info[dbg_switch_cpu].exception_state |=\n\t\t\t\tDCPU_NEXT_MASTER;\n\t\t\tgoto cpu_loop;\n\t\t} else {\n\t\t\tkgdb_info[cpu].ret_state = error;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdbg_activate_sw_breakpoints();\n\n\t/* Call the I/O driver's post_exception routine */\n\tif (dbg_io_ops->post_exception)\n\t\tdbg_io_ops->post_exception();\n\n\tatomic_dec(&ignore_console_lock_warning);\n\n\tif (!kgdb_single_step) {\n\t\traw_spin_unlock(&dbg_slave_lock);\n\t\t/* Wait till all the CPUs have quit from the debugger. */\n\t\twhile (kgdb_do_roundup && atomic_read(&slaves_in_kgdb))\n\t\t\tcpu_relax();\n\t}\n\nkgdb_restore:\n\tif (atomic_read(&kgdb_cpu_doing_single_step) != -1) {\n\t\tint sstep_cpu = atomic_read(&kgdb_cpu_doing_single_step);\n\t\tif (kgdb_info[sstep_cpu].task)\n\t\t\tkgdb_sstep_pid = kgdb_info[sstep_cpu].task->pid;\n\t\telse\n\t\t\tkgdb_sstep_pid = 0;\n\t}\n\tif (arch_kgdb_ops.correct_hw_break)\n\t\tarch_kgdb_ops.correct_hw_break();\n\tif (trace_on)\n\t\ttracing_on();\n\n\tkgdb_info[cpu].debuggerinfo = NULL;\n\tkgdb_info[cpu].task = NULL;\n\tkgdb_info[cpu].exception_state &=\n\t\t~(DCPU_WANT_MASTER | DCPU_IS_SLAVE);\n\tkgdb_info[cpu].enter_kgdb--;\n\tsmp_mb__before_atomic();\n\tatomic_dec(&masters_in_kgdb);\n\t/* Free kgdb_active */\n\tatomic_set(&kgdb_active, -1);\n\traw_spin_unlock(&dbg_master_lock);\n\tdbg_touch_watchdogs();\n\tlocal_irq_restore(flags);\n\trcu_read_unlock();\n\n\treturn kgdb_info[cpu].ret_state;\n}",
        "code_after_change": "static int kgdb_cpu_enter(struct kgdb_state *ks, struct pt_regs *regs,\n\t\tint exception_state)\n{\n\tunsigned long flags;\n\tint sstep_tries = 100;\n\tint error;\n\tint cpu;\n\tint trace_on = 0;\n\tint online_cpus = num_online_cpus();\n\tu64 time_left;\n\n\tkgdb_info[ks->cpu].enter_kgdb++;\n\tkgdb_info[ks->cpu].exception_state |= exception_state;\n\n\tif (exception_state == DCPU_WANT_MASTER)\n\t\tatomic_inc(&masters_in_kgdb);\n\telse\n\t\tatomic_inc(&slaves_in_kgdb);\n\n\tif (arch_kgdb_ops.disable_hw_break)\n\t\tarch_kgdb_ops.disable_hw_break(regs);\n\nacquirelock:\n\trcu_read_lock();\n\t/*\n\t * Interrupts will be restored by the 'trap return' code, except when\n\t * single stepping.\n\t */\n\tlocal_irq_save(flags);\n\n\tcpu = ks->cpu;\n\tkgdb_info[cpu].debuggerinfo = regs;\n\tkgdb_info[cpu].task = current;\n\tkgdb_info[cpu].ret_state = 0;\n\tkgdb_info[cpu].irq_depth = hardirq_count() >> HARDIRQ_SHIFT;\n\n\t/* Make sure the above info reaches the primary CPU */\n\tsmp_mb();\n\n\tif (exception_level == 1) {\n\t\tif (raw_spin_trylock(&dbg_master_lock))\n\t\t\tatomic_xchg(&kgdb_active, cpu);\n\t\tgoto cpu_master_loop;\n\t}\n\n\t/*\n\t * CPU will loop if it is a slave or request to become a kgdb\n\t * master cpu and acquire the kgdb_active lock:\n\t */\n\twhile (1) {\ncpu_loop:\n\t\tif (kgdb_info[cpu].exception_state & DCPU_NEXT_MASTER) {\n\t\t\tkgdb_info[cpu].exception_state &= ~DCPU_NEXT_MASTER;\n\t\t\tgoto cpu_master_loop;\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_WANT_MASTER) {\n\t\t\tif (raw_spin_trylock(&dbg_master_lock)) {\n\t\t\t\tatomic_xchg(&kgdb_active, cpu);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_WANT_BT) {\n\t\t\tdump_stack();\n\t\t\tkgdb_info[cpu].exception_state &= ~DCPU_WANT_BT;\n\t\t} else if (kgdb_info[cpu].exception_state & DCPU_IS_SLAVE) {\n\t\t\tif (!raw_spin_is_locked(&dbg_slave_lock))\n\t\t\t\tgoto return_normal;\n\t\t} else {\nreturn_normal:\n\t\t\t/* Return to normal operation by executing any\n\t\t\t * hw breakpoint fixup.\n\t\t\t */\n\t\t\tif (arch_kgdb_ops.correct_hw_break)\n\t\t\t\tarch_kgdb_ops.correct_hw_break();\n\t\t\tif (trace_on)\n\t\t\t\ttracing_on();\n\t\t\tkgdb_info[cpu].debuggerinfo = NULL;\n\t\t\tkgdb_info[cpu].task = NULL;\n\t\t\tkgdb_info[cpu].exception_state &=\n\t\t\t\t~(DCPU_WANT_MASTER | DCPU_IS_SLAVE);\n\t\t\tkgdb_info[cpu].enter_kgdb--;\n\t\t\tsmp_mb__before_atomic();\n\t\t\tatomic_dec(&slaves_in_kgdb);\n\t\t\tdbg_touch_watchdogs();\n\t\t\tlocal_irq_restore(flags);\n\t\t\trcu_read_unlock();\n\t\t\treturn 0;\n\t\t}\n\t\tcpu_relax();\n\t}\n\n\t/*\n\t * For single stepping, try to only enter on the processor\n\t * that was single stepping.  To guard against a deadlock, the\n\t * kernel will only try for the value of sstep_tries before\n\t * giving up and continuing on.\n\t */\n\tif (atomic_read(&kgdb_cpu_doing_single_step) != -1 &&\n\t    (kgdb_info[cpu].task &&\n\t     kgdb_info[cpu].task->pid != kgdb_sstep_pid) && --sstep_tries) {\n\t\tatomic_set(&kgdb_active, -1);\n\t\traw_spin_unlock(&dbg_master_lock);\n\t\tdbg_touch_watchdogs();\n\t\tlocal_irq_restore(flags);\n\t\trcu_read_unlock();\n\n\t\tgoto acquirelock;\n\t}\n\n\tif (!kgdb_io_ready(1)) {\n\t\tkgdb_info[cpu].ret_state = 1;\n\t\tgoto kgdb_restore; /* No I/O connection, resume the system */\n\t}\n\n\t/*\n\t * Don't enter if we have hit a removed breakpoint.\n\t */\n\tif (kgdb_skipexception(ks->ex_vector, ks->linux_regs))\n\t\tgoto kgdb_restore;\n\n\tatomic_inc(&ignore_console_lock_warning);\n\n\t/* Call the I/O driver's pre_exception routine */\n\tif (dbg_io_ops->pre_exception)\n\t\tdbg_io_ops->pre_exception();\n\n\t/*\n\t * Get the passive CPU lock which will hold all the non-primary\n\t * CPU in a spin state while the debugger is active\n\t */\n\tif (!kgdb_single_step)\n\t\traw_spin_lock(&dbg_slave_lock);\n\n#ifdef CONFIG_SMP\n\t/* If send_ready set, slaves are already waiting */\n\tif (ks->send_ready)\n\t\tatomic_set(ks->send_ready, 1);\n\n\t/* Signal the other CPUs to enter kgdb_wait() */\n\telse if ((!kgdb_single_step) && kgdb_do_roundup)\n\t\tkgdb_roundup_cpus();\n#endif\n\n\t/*\n\t * Wait for the other CPUs to be notified and be waiting for us:\n\t */\n\ttime_left = MSEC_PER_SEC;\n\twhile (kgdb_do_roundup && --time_left &&\n\t       (atomic_read(&masters_in_kgdb) + atomic_read(&slaves_in_kgdb)) !=\n\t\t   online_cpus)\n\t\tudelay(1000);\n\tif (!time_left)\n\t\tpr_crit(\"Timed out waiting for secondary CPUs.\\n\");\n\n\t/*\n\t * At this point the primary processor is completely\n\t * in the debugger and all secondary CPUs are quiescent\n\t */\n\tdbg_deactivate_sw_breakpoints();\n\tkgdb_single_step = 0;\n\tkgdb_contthread = current;\n\texception_level = 0;\n\ttrace_on = tracing_is_on();\n\tif (trace_on)\n\t\ttracing_off();\n\n\twhile (1) {\ncpu_master_loop:\n\t\tif (dbg_kdb_mode) {\n\t\t\tkgdb_connected = 1;\n\t\t\terror = kdb_stub(ks);\n\t\t\tif (error == -1)\n\t\t\t\tcontinue;\n\t\t\tkgdb_connected = 0;\n\t\t} else {\n\t\t\t/*\n\t\t\t * This is a brutal way to interfere with the debugger\n\t\t\t * and prevent gdb being used to poke at kernel memory.\n\t\t\t * This could cause trouble if lockdown is applied when\n\t\t\t * there is already an active gdb session. For now the\n\t\t\t * answer is simply \"don't do that\". Typically lockdown\n\t\t\t * *will* be applied before the debug core gets started\n\t\t\t * so only developers using kgdb for fairly advanced\n\t\t\t * early kernel debug can be biten by this. Hopefully\n\t\t\t * they are sophisticated enough to take care of\n\t\t\t * themselves, especially with help from the lockdown\n\t\t\t * message printed on the console!\n\t\t\t */\n\t\t\tif (security_locked_down(LOCKDOWN_DBG_WRITE_KERNEL)) {\n\t\t\t\tif (IS_ENABLED(CONFIG_KGDB_KDB)) {\n\t\t\t\t\t/* Switch back to kdb if possible... */\n\t\t\t\t\tdbg_kdb_mode = 1;\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... otherwise just bail */\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\terror = gdb_serial_stub(ks);\n\t\t}\n\n\t\tif (error == DBG_PASS_EVENT) {\n\t\t\tdbg_kdb_mode = !dbg_kdb_mode;\n\t\t} else if (error == DBG_SWITCH_CPU_EVENT) {\n\t\t\tkgdb_info[dbg_switch_cpu].exception_state |=\n\t\t\t\tDCPU_NEXT_MASTER;\n\t\t\tgoto cpu_loop;\n\t\t} else {\n\t\t\tkgdb_info[cpu].ret_state = error;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdbg_activate_sw_breakpoints();\n\n\t/* Call the I/O driver's post_exception routine */\n\tif (dbg_io_ops->post_exception)\n\t\tdbg_io_ops->post_exception();\n\n\tatomic_dec(&ignore_console_lock_warning);\n\n\tif (!kgdb_single_step) {\n\t\traw_spin_unlock(&dbg_slave_lock);\n\t\t/* Wait till all the CPUs have quit from the debugger. */\n\t\twhile (kgdb_do_roundup && atomic_read(&slaves_in_kgdb))\n\t\t\tcpu_relax();\n\t}\n\nkgdb_restore:\n\tif (atomic_read(&kgdb_cpu_doing_single_step) != -1) {\n\t\tint sstep_cpu = atomic_read(&kgdb_cpu_doing_single_step);\n\t\tif (kgdb_info[sstep_cpu].task)\n\t\t\tkgdb_sstep_pid = kgdb_info[sstep_cpu].task->pid;\n\t\telse\n\t\t\tkgdb_sstep_pid = 0;\n\t}\n\tif (arch_kgdb_ops.correct_hw_break)\n\t\tarch_kgdb_ops.correct_hw_break();\n\tif (trace_on)\n\t\ttracing_on();\n\n\tkgdb_info[cpu].debuggerinfo = NULL;\n\tkgdb_info[cpu].task = NULL;\n\tkgdb_info[cpu].exception_state &=\n\t\t~(DCPU_WANT_MASTER | DCPU_IS_SLAVE);\n\tkgdb_info[cpu].enter_kgdb--;\n\tsmp_mb__before_atomic();\n\tatomic_dec(&masters_in_kgdb);\n\t/* Free kgdb_active */\n\tatomic_set(&kgdb_active, -1);\n\traw_spin_unlock(&dbg_master_lock);\n\tdbg_touch_watchdogs();\n\tlocal_irq_restore(flags);\n\trcu_read_unlock();\n\n\treturn kgdb_info[cpu].ret_state;\n}",
        "patch": "--- code before\n+++ code after\n@@ -171,6 +171,29 @@\n \t\t\t\tcontinue;\n \t\t\tkgdb_connected = 0;\n \t\t} else {\n+\t\t\t/*\n+\t\t\t * This is a brutal way to interfere with the debugger\n+\t\t\t * and prevent gdb being used to poke at kernel memory.\n+\t\t\t * This could cause trouble if lockdown is applied when\n+\t\t\t * there is already an active gdb session. For now the\n+\t\t\t * answer is simply \"don't do that\". Typically lockdown\n+\t\t\t * *will* be applied before the debug core gets started\n+\t\t\t * so only developers using kgdb for fairly advanced\n+\t\t\t * early kernel debug can be biten by this. Hopefully\n+\t\t\t * they are sophisticated enough to take care of\n+\t\t\t * themselves, especially with help from the lockdown\n+\t\t\t * message printed on the console!\n+\t\t\t */\n+\t\t\tif (security_locked_down(LOCKDOWN_DBG_WRITE_KERNEL)) {\n+\t\t\t\tif (IS_ENABLED(CONFIG_KGDB_KDB)) {\n+\t\t\t\t\t/* Switch back to kdb if possible... */\n+\t\t\t\t\tdbg_kdb_mode = 1;\n+\t\t\t\t\tcontinue;\n+\t\t\t\t} else {\n+\t\t\t\t\t/* ... otherwise just bail */\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\t}\n \t\t\terror = gdb_serial_stub(ks);\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t/*",
                "\t\t\t * This is a brutal way to interfere with the debugger",
                "\t\t\t * and prevent gdb being used to poke at kernel memory.",
                "\t\t\t * This could cause trouble if lockdown is applied when",
                "\t\t\t * there is already an active gdb session. For now the",
                "\t\t\t * answer is simply \"don't do that\". Typically lockdown",
                "\t\t\t * *will* be applied before the debug core gets started",
                "\t\t\t * so only developers using kgdb for fairly advanced",
                "\t\t\t * early kernel debug can be biten by this. Hopefully",
                "\t\t\t * they are sophisticated enough to take care of",
                "\t\t\t * themselves, especially with help from the lockdown",
                "\t\t\t * message printed on the console!",
                "\t\t\t */",
                "\t\t\tif (security_locked_down(LOCKDOWN_DBG_WRITE_KERNEL)) {",
                "\t\t\t\tif (IS_ENABLED(CONFIG_KGDB_KDB)) {",
                "\t\t\t\t\t/* Switch back to kdb if possible... */",
                "\t\t\t\t\tdbg_kdb_mode = 1;",
                "\t\t\t\t\tcontinue;",
                "\t\t\t\t} else {",
                "\t\t\t\t\t/* ... otherwise just bail */",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}",
                "\t\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "KGDB and KDB allow read and write access to kernel memory, and thus should be restricted during lockdown. An attacker with access to a serial port could trigger the debugger so it is important that the debugger respect the lockdown mode when/if it is triggered. CVSS 3.1 Base Score 6.7 (Confidentiality, Integrity and Availability impacts). CVSS Vector: (CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H)."
    },
    {
        "cve_id": "CVE-2022-21499",
        "code_before_change": "static inline bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,\n\t\t\t\t   bool no_args)\n{\n\t/* permissions comes from userspace so needs massaging slightly */\n\tpermissions &= KDB_ENABLE_MASK;\n\tpermissions |= KDB_ENABLE_ALWAYS_SAFE;\n\n\t/* some commands change group when launched with no arguments */\n\tif (no_args)\n\t\tpermissions |= permissions << KDB_ENABLE_NO_ARGS_SHIFT;\n\n\tflags |= KDB_ENABLE_ALL;\n\n\treturn permissions & flags;\n}",
        "code_after_change": "static bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,\n\t\t\t\t   bool no_args)\n{\n\t/* permissions comes from userspace so needs massaging slightly */\n\tpermissions &= KDB_ENABLE_MASK;\n\tpermissions |= KDB_ENABLE_ALWAYS_SAFE;\n\n\t/* some commands change group when launched with no arguments */\n\tif (no_args)\n\t\tpermissions |= permissions << KDB_ENABLE_NO_ARGS_SHIFT;\n\n\tflags |= KDB_ENABLE_ALL;\n\n\treturn permissions & flags;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n-static inline bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,\n+static bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,\n \t\t\t\t   bool no_args)\n {\n \t/* permissions comes from userspace so needs massaging slightly */",
        "function_modified_lines": {
            "added": [
                "static bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,"
            ],
            "deleted": [
                "static inline bool kdb_check_flags(kdb_cmdflags_t flags, int permissions,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "KGDB and KDB allow read and write access to kernel memory, and thus should be restricted during lockdown. An attacker with access to a serial port could trigger the debugger so it is important that the debugger respect the lockdown mode when/if it is triggered. CVSS 3.1 Base Score 6.7 (Confidentiality, Integrity and Availability impacts). CVSS Vector: (CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H)."
    },
    {
        "cve_id": "CVE-2022-21499",
        "code_before_change": "static int kdb_local(kdb_reason_t reason, int error, struct pt_regs *regs,\n\t\t     kdb_dbtrap_t db_result)\n{\n\tchar *cmdbuf;\n\tint diag;\n\tstruct task_struct *kdb_current =\n\t\tkdb_curr_task(raw_smp_processor_id());\n\n\tKDB_DEBUG_STATE(\"kdb_local 1\", reason);\n\tkdb_go_count = 0;\n\tif (reason == KDB_REASON_DEBUG) {\n\t\t/* special case below */\n\t} else {\n\t\tkdb_printf(\"\\nEntering kdb (current=0x%px, pid %d) \",\n\t\t\t   kdb_current, kdb_current ? kdb_current->pid : 0);\n#if defined(CONFIG_SMP)\n\t\tkdb_printf(\"on processor %d \", raw_smp_processor_id());\n#endif\n\t}\n\n\tswitch (reason) {\n\tcase KDB_REASON_DEBUG:\n\t{\n\t\t/*\n\t\t * If re-entering kdb after a single step\n\t\t * command, don't print the message.\n\t\t */\n\t\tswitch (db_result) {\n\t\tcase KDB_DB_BPT:\n\t\t\tkdb_printf(\"\\nEntering kdb (0x%px, pid %d) \",\n\t\t\t\t   kdb_current, kdb_current->pid);\n#if defined(CONFIG_SMP)\n\t\t\tkdb_printf(\"on processor %d \", raw_smp_processor_id());\n#endif\n\t\t\tkdb_printf(\"due to Debug @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t\t   instruction_pointer(regs));\n\t\t\tbreak;\n\t\tcase KDB_DB_SS:\n\t\t\tbreak;\n\t\tcase KDB_DB_SSBPT:\n\t\t\tKDB_DEBUG_STATE(\"kdb_local 4\", reason);\n\t\t\treturn 1;\t/* kdba_db_trap did the work */\n\t\tdefault:\n\t\t\tkdb_printf(\"kdb: Bad result from kdba_db_trap: %d\\n\",\n\t\t\t\t   db_result);\n\t\t\tbreak;\n\t\t}\n\n\t}\n\t\tbreak;\n\tcase KDB_REASON_ENTER:\n\t\tif (KDB_STATE(KEYBOARD))\n\t\t\tkdb_printf(\"due to Keyboard Entry\\n\");\n\t\telse\n\t\t\tkdb_printf(\"due to KDB_ENTER()\\n\");\n\t\tbreak;\n\tcase KDB_REASON_KEYBOARD:\n\t\tKDB_STATE_SET(KEYBOARD);\n\t\tkdb_printf(\"due to Keyboard Entry\\n\");\n\t\tbreak;\n\tcase KDB_REASON_ENTER_SLAVE:\n\t\t/* drop through, slaves only get released via cpu switch */\n\tcase KDB_REASON_SWITCH:\n\t\tkdb_printf(\"due to cpu switch\\n\");\n\t\tbreak;\n\tcase KDB_REASON_OOPS:\n\t\tkdb_printf(\"Oops: %s\\n\", kdb_diemsg);\n\t\tkdb_printf(\"due to oops @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tkdb_dumpregs(regs);\n\t\tbreak;\n\tcase KDB_REASON_SYSTEM_NMI:\n\t\tkdb_printf(\"due to System NonMaskable Interrupt\\n\");\n\t\tbreak;\n\tcase KDB_REASON_NMI:\n\t\tkdb_printf(\"due to NonMaskable Interrupt @ \"\n\t\t\t   kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tbreak;\n\tcase KDB_REASON_SSTEP:\n\tcase KDB_REASON_BREAK:\n\t\tkdb_printf(\"due to %s @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   reason == KDB_REASON_BREAK ?\n\t\t\t   \"Breakpoint\" : \"SS trap\", instruction_pointer(regs));\n\t\t/*\n\t\t * Determine if this breakpoint is one that we\n\t\t * are interested in.\n\t\t */\n\t\tif (db_result != KDB_DB_BPT) {\n\t\t\tkdb_printf(\"kdb: error return from kdba_bp_trap: %d\\n\",\n\t\t\t\t   db_result);\n\t\t\tKDB_DEBUG_STATE(\"kdb_local 6\", reason);\n\t\t\treturn 0;\t/* Not for us, dismiss it */\n\t\t}\n\t\tbreak;\n\tcase KDB_REASON_RECURSE:\n\t\tkdb_printf(\"due to Recursion @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tbreak;\n\tdefault:\n\t\tkdb_printf(\"kdb: unexpected reason code: %d\\n\", reason);\n\t\tKDB_DEBUG_STATE(\"kdb_local 8\", reason);\n\t\treturn 0;\t/* Not for us, dismiss it */\n\t}\n\n\twhile (1) {\n\t\t/*\n\t\t * Initialize pager context.\n\t\t */\n\t\tkdb_nextline = 1;\n\t\tKDB_STATE_CLEAR(SUPPRESS);\n\t\tkdb_grepping_flag = 0;\n\t\t/* ensure the old search does not leak into '/' commands */\n\t\tkdb_grep_string[0] = '\\0';\n\n\t\tcmdbuf = cmd_cur;\n\t\t*cmdbuf = '\\0';\n\t\t*(cmd_hist[cmd_head]) = '\\0';\n\ndo_full_getstr:\n\t\t/* PROMPT can only be set if we have MEM_READ permission. */\n\t\tsnprintf(kdb_prompt_str, CMD_BUFLEN, kdbgetenv(\"PROMPT\"),\n\t\t\t raw_smp_processor_id());\n\t\tif (defcmd_in_progress)\n\t\t\tstrncat(kdb_prompt_str, \"[defcmd]\", CMD_BUFLEN);\n\n\t\t/*\n\t\t * Fetch command from keyboard\n\t\t */\n\t\tcmdbuf = kdb_getstr(cmdbuf, CMD_BUFLEN, kdb_prompt_str);\n\t\tif (*cmdbuf != '\\n') {\n\t\t\tif (*cmdbuf < 32) {\n\t\t\t\tif (cmdptr == cmd_head) {\n\t\t\t\t\tstrscpy(cmd_hist[cmd_head], cmd_cur,\n\t\t\t\t\t\tCMD_BUFLEN);\n\t\t\t\t\t*(cmd_hist[cmd_head] +\n\t\t\t\t\t  strlen(cmd_hist[cmd_head])-1) = '\\0';\n\t\t\t\t}\n\t\t\t\tif (!handle_ctrl_cmd(cmdbuf))\n\t\t\t\t\t*(cmd_cur+strlen(cmd_cur)-1) = '\\0';\n\t\t\t\tcmdbuf = cmd_cur;\n\t\t\t\tgoto do_full_getstr;\n\t\t\t} else {\n\t\t\t\tstrscpy(cmd_hist[cmd_head], cmd_cur,\n\t\t\t\t\tCMD_BUFLEN);\n\t\t\t}\n\n\t\t\tcmd_head = (cmd_head+1) % KDB_CMD_HISTORY_COUNT;\n\t\t\tif (cmd_head == cmd_tail)\n\t\t\t\tcmd_tail = (cmd_tail+1) % KDB_CMD_HISTORY_COUNT;\n\t\t}\n\n\t\tcmdptr = cmd_head;\n\t\tdiag = kdb_parse(cmdbuf);\n\t\tif (diag == KDB_NOTFOUND) {\n\t\t\tdrop_newline(cmdbuf);\n\t\t\tkdb_printf(\"Unknown kdb command: '%s'\\n\", cmdbuf);\n\t\t\tdiag = 0;\n\t\t}\n\t\tif (diag == KDB_CMD_GO\n\t\t || diag == KDB_CMD_CPU\n\t\t || diag == KDB_CMD_SS\n\t\t || diag == KDB_CMD_KGDB)\n\t\t\tbreak;\n\n\t\tif (diag)\n\t\t\tkdb_cmderror(diag);\n\t}\n\tKDB_DEBUG_STATE(\"kdb_local 9\", diag);\n\treturn diag;\n}",
        "code_after_change": "static int kdb_local(kdb_reason_t reason, int error, struct pt_regs *regs,\n\t\t     kdb_dbtrap_t db_result)\n{\n\tchar *cmdbuf;\n\tint diag;\n\tstruct task_struct *kdb_current =\n\t\tkdb_curr_task(raw_smp_processor_id());\n\n\tKDB_DEBUG_STATE(\"kdb_local 1\", reason);\n\n\tkdb_check_for_lockdown();\n\n\tkdb_go_count = 0;\n\tif (reason == KDB_REASON_DEBUG) {\n\t\t/* special case below */\n\t} else {\n\t\tkdb_printf(\"\\nEntering kdb (current=0x%px, pid %d) \",\n\t\t\t   kdb_current, kdb_current ? kdb_current->pid : 0);\n#if defined(CONFIG_SMP)\n\t\tkdb_printf(\"on processor %d \", raw_smp_processor_id());\n#endif\n\t}\n\n\tswitch (reason) {\n\tcase KDB_REASON_DEBUG:\n\t{\n\t\t/*\n\t\t * If re-entering kdb after a single step\n\t\t * command, don't print the message.\n\t\t */\n\t\tswitch (db_result) {\n\t\tcase KDB_DB_BPT:\n\t\t\tkdb_printf(\"\\nEntering kdb (0x%px, pid %d) \",\n\t\t\t\t   kdb_current, kdb_current->pid);\n#if defined(CONFIG_SMP)\n\t\t\tkdb_printf(\"on processor %d \", raw_smp_processor_id());\n#endif\n\t\t\tkdb_printf(\"due to Debug @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t\t   instruction_pointer(regs));\n\t\t\tbreak;\n\t\tcase KDB_DB_SS:\n\t\t\tbreak;\n\t\tcase KDB_DB_SSBPT:\n\t\t\tKDB_DEBUG_STATE(\"kdb_local 4\", reason);\n\t\t\treturn 1;\t/* kdba_db_trap did the work */\n\t\tdefault:\n\t\t\tkdb_printf(\"kdb: Bad result from kdba_db_trap: %d\\n\",\n\t\t\t\t   db_result);\n\t\t\tbreak;\n\t\t}\n\n\t}\n\t\tbreak;\n\tcase KDB_REASON_ENTER:\n\t\tif (KDB_STATE(KEYBOARD))\n\t\t\tkdb_printf(\"due to Keyboard Entry\\n\");\n\t\telse\n\t\t\tkdb_printf(\"due to KDB_ENTER()\\n\");\n\t\tbreak;\n\tcase KDB_REASON_KEYBOARD:\n\t\tKDB_STATE_SET(KEYBOARD);\n\t\tkdb_printf(\"due to Keyboard Entry\\n\");\n\t\tbreak;\n\tcase KDB_REASON_ENTER_SLAVE:\n\t\t/* drop through, slaves only get released via cpu switch */\n\tcase KDB_REASON_SWITCH:\n\t\tkdb_printf(\"due to cpu switch\\n\");\n\t\tbreak;\n\tcase KDB_REASON_OOPS:\n\t\tkdb_printf(\"Oops: %s\\n\", kdb_diemsg);\n\t\tkdb_printf(\"due to oops @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tkdb_dumpregs(regs);\n\t\tbreak;\n\tcase KDB_REASON_SYSTEM_NMI:\n\t\tkdb_printf(\"due to System NonMaskable Interrupt\\n\");\n\t\tbreak;\n\tcase KDB_REASON_NMI:\n\t\tkdb_printf(\"due to NonMaskable Interrupt @ \"\n\t\t\t   kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tbreak;\n\tcase KDB_REASON_SSTEP:\n\tcase KDB_REASON_BREAK:\n\t\tkdb_printf(\"due to %s @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   reason == KDB_REASON_BREAK ?\n\t\t\t   \"Breakpoint\" : \"SS trap\", instruction_pointer(regs));\n\t\t/*\n\t\t * Determine if this breakpoint is one that we\n\t\t * are interested in.\n\t\t */\n\t\tif (db_result != KDB_DB_BPT) {\n\t\t\tkdb_printf(\"kdb: error return from kdba_bp_trap: %d\\n\",\n\t\t\t\t   db_result);\n\t\t\tKDB_DEBUG_STATE(\"kdb_local 6\", reason);\n\t\t\treturn 0;\t/* Not for us, dismiss it */\n\t\t}\n\t\tbreak;\n\tcase KDB_REASON_RECURSE:\n\t\tkdb_printf(\"due to Recursion @ \" kdb_machreg_fmt \"\\n\",\n\t\t\t   instruction_pointer(regs));\n\t\tbreak;\n\tdefault:\n\t\tkdb_printf(\"kdb: unexpected reason code: %d\\n\", reason);\n\t\tKDB_DEBUG_STATE(\"kdb_local 8\", reason);\n\t\treturn 0;\t/* Not for us, dismiss it */\n\t}\n\n\twhile (1) {\n\t\t/*\n\t\t * Initialize pager context.\n\t\t */\n\t\tkdb_nextline = 1;\n\t\tKDB_STATE_CLEAR(SUPPRESS);\n\t\tkdb_grepping_flag = 0;\n\t\t/* ensure the old search does not leak into '/' commands */\n\t\tkdb_grep_string[0] = '\\0';\n\n\t\tcmdbuf = cmd_cur;\n\t\t*cmdbuf = '\\0';\n\t\t*(cmd_hist[cmd_head]) = '\\0';\n\ndo_full_getstr:\n\t\t/* PROMPT can only be set if we have MEM_READ permission. */\n\t\tsnprintf(kdb_prompt_str, CMD_BUFLEN, kdbgetenv(\"PROMPT\"),\n\t\t\t raw_smp_processor_id());\n\t\tif (defcmd_in_progress)\n\t\t\tstrncat(kdb_prompt_str, \"[defcmd]\", CMD_BUFLEN);\n\n\t\t/*\n\t\t * Fetch command from keyboard\n\t\t */\n\t\tcmdbuf = kdb_getstr(cmdbuf, CMD_BUFLEN, kdb_prompt_str);\n\t\tif (*cmdbuf != '\\n') {\n\t\t\tif (*cmdbuf < 32) {\n\t\t\t\tif (cmdptr == cmd_head) {\n\t\t\t\t\tstrscpy(cmd_hist[cmd_head], cmd_cur,\n\t\t\t\t\t\tCMD_BUFLEN);\n\t\t\t\t\t*(cmd_hist[cmd_head] +\n\t\t\t\t\t  strlen(cmd_hist[cmd_head])-1) = '\\0';\n\t\t\t\t}\n\t\t\t\tif (!handle_ctrl_cmd(cmdbuf))\n\t\t\t\t\t*(cmd_cur+strlen(cmd_cur)-1) = '\\0';\n\t\t\t\tcmdbuf = cmd_cur;\n\t\t\t\tgoto do_full_getstr;\n\t\t\t} else {\n\t\t\t\tstrscpy(cmd_hist[cmd_head], cmd_cur,\n\t\t\t\t\tCMD_BUFLEN);\n\t\t\t}\n\n\t\t\tcmd_head = (cmd_head+1) % KDB_CMD_HISTORY_COUNT;\n\t\t\tif (cmd_head == cmd_tail)\n\t\t\t\tcmd_tail = (cmd_tail+1) % KDB_CMD_HISTORY_COUNT;\n\t\t}\n\n\t\tcmdptr = cmd_head;\n\t\tdiag = kdb_parse(cmdbuf);\n\t\tif (diag == KDB_NOTFOUND) {\n\t\t\tdrop_newline(cmdbuf);\n\t\t\tkdb_printf(\"Unknown kdb command: '%s'\\n\", cmdbuf);\n\t\t\tdiag = 0;\n\t\t}\n\t\tif (diag == KDB_CMD_GO\n\t\t || diag == KDB_CMD_CPU\n\t\t || diag == KDB_CMD_SS\n\t\t || diag == KDB_CMD_KGDB)\n\t\t\tbreak;\n\n\t\tif (diag)\n\t\t\tkdb_cmderror(diag);\n\t}\n\tKDB_DEBUG_STATE(\"kdb_local 9\", diag);\n\treturn diag;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,9 @@\n \t\tkdb_curr_task(raw_smp_processor_id());\n \n \tKDB_DEBUG_STATE(\"kdb_local 1\", reason);\n+\n+\tkdb_check_for_lockdown();\n+\n \tkdb_go_count = 0;\n \tif (reason == KDB_REASON_DEBUG) {\n \t\t/* special case below */",
        "function_modified_lines": {
            "added": [
                "",
                "\tkdb_check_for_lockdown();",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "KGDB and KDB allow read and write access to kernel memory, and thus should be restricted during lockdown. An attacker with access to a serial port could trigger the debugger so it is important that the debugger respect the lockdown mode when/if it is triggered. CVSS 3.1 Base Score 6.7 (Confidentiality, Integrity and Availability impacts). CVSS Vector: (CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H)."
    },
    {
        "cve_id": "CVE-2022-2380",
        "code_before_change": "static ssize_t smtcfb_read(struct fb_info *info, char __user *buf,\n\t\t\t   size_t count, loff_t *ppos)\n{\n\tunsigned long p = *ppos;\n\n\tu32 *buffer, *dst;\n\tu32 __iomem *src;\n\tint c, i, cnt = 0, err = 0;\n\tunsigned long total_size;\n\n\tif (!info || !info->screen_base)\n\t\treturn -ENODEV;\n\n\tif (info->state != FBINFO_STATE_RUNNING)\n\t\treturn -EPERM;\n\n\ttotal_size = info->screen_size;\n\n\tif (total_size == 0)\n\t\ttotal_size = info->fix.smem_len;\n\n\tif (p >= total_size)\n\t\treturn 0;\n\n\tif (count >= total_size)\n\t\tcount = total_size;\n\n\tif (count + p > total_size)\n\t\tcount = total_size - p;\n\n\tbuffer = kmalloc((count > PAGE_SIZE) ? PAGE_SIZE : count, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\tsrc = (u32 __iomem *)(info->screen_base + p);\n\n\tif (info->fbops->fb_sync)\n\t\tinfo->fbops->fb_sync(info);\n\n\twhile (count) {\n\t\tc = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tdst = buffer;\n\t\tfor (i = c >> 2; i--;) {\n\t\t\t*dst = fb_readl(src++);\n\t\t\t*dst = big_swap(*dst);\n\t\t\tdst++;\n\t\t}\n\t\tif (c & 3) {\n\t\t\tu8 *dst8 = (u8 *)dst;\n\t\t\tu8 __iomem *src8 = (u8 __iomem *)src;\n\n\t\t\tfor (i = c & 3; i--;) {\n\t\t\t\tif (i & 1) {\n\t\t\t\t\t*dst8++ = fb_readb(++src8);\n\t\t\t\t} else {\n\t\t\t\t\t*dst8++ = fb_readb(--src8);\n\t\t\t\t\tsrc8 += 2;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsrc = (u32 __iomem *)src8;\n\t\t}\n\n\t\tif (copy_to_user(buf, buffer, c)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\t*ppos += c;\n\t\tbuf += c;\n\t\tcnt += c;\n\t\tcount -= c;\n\t}\n\n\tkfree(buffer);\n\n\treturn (err) ? err : cnt;\n}",
        "code_after_change": "static ssize_t smtcfb_read(struct fb_info *info, char __user *buf,\n\t\t\t   size_t count, loff_t *ppos)\n{\n\tunsigned long p = *ppos;\n\n\tu32 *buffer, *dst;\n\tu32 __iomem *src;\n\tint c, i, cnt = 0, err = 0;\n\tunsigned long total_size;\n\n\tif (!info || !info->screen_base)\n\t\treturn -ENODEV;\n\n\tif (info->state != FBINFO_STATE_RUNNING)\n\t\treturn -EPERM;\n\n\ttotal_size = info->screen_size;\n\n\tif (total_size == 0)\n\t\ttotal_size = info->fix.smem_len;\n\n\tif (p >= total_size)\n\t\treturn 0;\n\n\tif (count >= total_size)\n\t\tcount = total_size;\n\n\tif (count + p > total_size)\n\t\tcount = total_size - p;\n\n\tbuffer = kmalloc(PAGE_SIZE, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\tsrc = (u32 __iomem *)(info->screen_base + p);\n\n\tif (info->fbops->fb_sync)\n\t\tinfo->fbops->fb_sync(info);\n\n\twhile (count) {\n\t\tc = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tdst = buffer;\n\t\tfor (i = (c + 3) >> 2; i--;) {\n\t\t\tu32 val;\n\n\t\t\tval = fb_readl(src);\n\t\t\t*dst = big_swap(val);\n\t\t\tsrc++;\n\t\t\tdst++;\n\t\t}\n\n\t\tif (copy_to_user(buf, buffer, c)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\t*ppos += c;\n\t\tbuf += c;\n\t\tcnt += c;\n\t\tcount -= c;\n\t}\n\n\tkfree(buffer);\n\n\treturn (err) ? err : cnt;\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,7 +28,7 @@\n \tif (count + p > total_size)\n \t\tcount = total_size - p;\n \n-\tbuffer = kmalloc((count > PAGE_SIZE) ? PAGE_SIZE : count, GFP_KERNEL);\n+\tbuffer = kmalloc(PAGE_SIZE, GFP_KERNEL);\n \tif (!buffer)\n \t\treturn -ENOMEM;\n \n@@ -40,24 +40,13 @@\n \twhile (count) {\n \t\tc = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n \t\tdst = buffer;\n-\t\tfor (i = c >> 2; i--;) {\n-\t\t\t*dst = fb_readl(src++);\n-\t\t\t*dst = big_swap(*dst);\n+\t\tfor (i = (c + 3) >> 2; i--;) {\n+\t\t\tu32 val;\n+\n+\t\t\tval = fb_readl(src);\n+\t\t\t*dst = big_swap(val);\n+\t\t\tsrc++;\n \t\t\tdst++;\n-\t\t}\n-\t\tif (c & 3) {\n-\t\t\tu8 *dst8 = (u8 *)dst;\n-\t\t\tu8 __iomem *src8 = (u8 __iomem *)src;\n-\n-\t\t\tfor (i = c & 3; i--;) {\n-\t\t\t\tif (i & 1) {\n-\t\t\t\t\t*dst8++ = fb_readb(++src8);\n-\t\t\t\t} else {\n-\t\t\t\t\t*dst8++ = fb_readb(--src8);\n-\t\t\t\t\tsrc8 += 2;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\tsrc = (u32 __iomem *)src8;\n \t\t}\n \n \t\tif (copy_to_user(buf, buffer, c)) {",
        "function_modified_lines": {
            "added": [
                "\tbuffer = kmalloc(PAGE_SIZE, GFP_KERNEL);",
                "\t\tfor (i = (c + 3) >> 2; i--;) {",
                "\t\t\tu32 val;",
                "",
                "\t\t\tval = fb_readl(src);",
                "\t\t\t*dst = big_swap(val);",
                "\t\t\tsrc++;"
            ],
            "deleted": [
                "\tbuffer = kmalloc((count > PAGE_SIZE) ? PAGE_SIZE : count, GFP_KERNEL);",
                "\t\tfor (i = c >> 2; i--;) {",
                "\t\t\t*dst = fb_readl(src++);",
                "\t\t\t*dst = big_swap(*dst);",
                "\t\t}",
                "\t\tif (c & 3) {",
                "\t\t\tu8 *dst8 = (u8 *)dst;",
                "\t\t\tu8 __iomem *src8 = (u8 __iomem *)src;",
                "",
                "\t\t\tfor (i = c & 3; i--;) {",
                "\t\t\t\tif (i & 1) {",
                "\t\t\t\t\t*dst8++ = fb_readb(++src8);",
                "\t\t\t\t} else {",
                "\t\t\t\t\t*dst8++ = fb_readb(--src8);",
                "\t\t\t\t\tsrc8 += 2;",
                "\t\t\t\t}",
                "\t\t\t}",
                "\t\t\tsrc = (u32 __iomem *)src8;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The Linux kernel was found vulnerable out of bounds memory access in the drivers/video/fbdev/sm712fb.c:smtcfb_read() function. The vulnerability could result in local attackers being able to crash the kernel."
    },
    {
        "cve_id": "CVE-2022-2991",
        "code_before_change": "static void nvme_alloc_ns(struct nvme_ctrl *ctrl, unsigned nsid,\n\t\tstruct nvme_ns_ids *ids)\n{\n\tstruct nvme_ns *ns;\n\tstruct gendisk *disk;\n\tstruct nvme_id_ns *id;\n\tint node = ctrl->numa_node;\n\n\tif (nvme_identify_ns(ctrl, nsid, ids, &id))\n\t\treturn;\n\n\tns = kzalloc_node(sizeof(*ns), GFP_KERNEL, node);\n\tif (!ns)\n\t\tgoto out_free_id;\n\n\tns->queue = blk_mq_init_queue(ctrl->tagset);\n\tif (IS_ERR(ns->queue))\n\t\tgoto out_free_ns;\n\n\tif (ctrl->opts && ctrl->opts->data_digest)\n\t\tblk_queue_flag_set(QUEUE_FLAG_STABLE_WRITES, ns->queue);\n\n\tblk_queue_flag_set(QUEUE_FLAG_NONROT, ns->queue);\n\tif (ctrl->ops->flags & NVME_F_PCI_P2PDMA)\n\t\tblk_queue_flag_set(QUEUE_FLAG_PCI_P2PDMA, ns->queue);\n\n\tns->queue->queuedata = ns;\n\tns->ctrl = ctrl;\n\tkref_init(&ns->kref);\n\n\tif (nvme_init_ns_head(ns, nsid, ids, id->nmic & NVME_NS_NMIC_SHARED))\n\t\tgoto out_free_queue;\n\n\tdisk = alloc_disk_node(0, node);\n\tif (!disk)\n\t\tgoto out_unlink_ns;\n\n\tdisk->fops = &nvme_bdev_ops;\n\tdisk->private_data = ns;\n\tdisk->queue = ns->queue;\n\t/*\n\t * Without the multipath code enabled, multiple controller per\n\t * subsystems are visible as devices and thus we cannot use the\n\t * subsystem instance.\n\t */\n\tif (!nvme_mpath_set_disk_name(ns, disk->disk_name, &disk->flags))\n\t\tsprintf(disk->disk_name, \"nvme%dn%d\", ctrl->instance,\n\t\t\tns->head->instance);\n\tns->disk = disk;\n\n\tif (nvme_update_ns_info(ns, id))\n\t\tgoto out_put_disk;\n\n\tif ((ctrl->quirks & NVME_QUIRK_LIGHTNVM) && id->vs[0] == 0x1) {\n\t\tif (nvme_nvm_register(ns, disk->disk_name, node)) {\n\t\t\tdev_warn(ctrl->device, \"LightNVM init failure\\n\");\n\t\t\tgoto out_put_disk;\n\t\t}\n\t}\n\n\tdown_write(&ctrl->namespaces_rwsem);\n\tlist_add_tail(&ns->list, &ctrl->namespaces);\n\tup_write(&ctrl->namespaces_rwsem);\n\n\tnvme_get_ctrl(ctrl);\n\n\tdevice_add_disk(ctrl->device, ns->disk, nvme_ns_id_attr_groups);\n\tif (!nvme_ns_head_multipath(ns->head))\n\t\tnvme_add_ns_cdev(ns);\n\n\tnvme_mpath_add_disk(ns, id);\n\tnvme_fault_inject_init(&ns->fault_inject, ns->disk->disk_name);\n\tkfree(id);\n\n\treturn;\n out_put_disk:\n\t/* prevent double queue cleanup */\n\tns->disk->queue = NULL;\n\tput_disk(ns->disk);\n out_unlink_ns:\n\tmutex_lock(&ctrl->subsys->lock);\n\tlist_del_rcu(&ns->siblings);\n\tif (list_empty(&ns->head->list))\n\t\tlist_del_init(&ns->head->entry);\n\tmutex_unlock(&ctrl->subsys->lock);\n\tnvme_put_ns_head(ns->head);\n out_free_queue:\n\tblk_cleanup_queue(ns->queue);\n out_free_ns:\n\tkfree(ns);\n out_free_id:\n\tkfree(id);\n}",
        "code_after_change": "static void nvme_alloc_ns(struct nvme_ctrl *ctrl, unsigned nsid,\n\t\tstruct nvme_ns_ids *ids)\n{\n\tstruct nvme_ns *ns;\n\tstruct gendisk *disk;\n\tstruct nvme_id_ns *id;\n\tint node = ctrl->numa_node;\n\n\tif (nvme_identify_ns(ctrl, nsid, ids, &id))\n\t\treturn;\n\n\tns = kzalloc_node(sizeof(*ns), GFP_KERNEL, node);\n\tif (!ns)\n\t\tgoto out_free_id;\n\n\tns->queue = blk_mq_init_queue(ctrl->tagset);\n\tif (IS_ERR(ns->queue))\n\t\tgoto out_free_ns;\n\n\tif (ctrl->opts && ctrl->opts->data_digest)\n\t\tblk_queue_flag_set(QUEUE_FLAG_STABLE_WRITES, ns->queue);\n\n\tblk_queue_flag_set(QUEUE_FLAG_NONROT, ns->queue);\n\tif (ctrl->ops->flags & NVME_F_PCI_P2PDMA)\n\t\tblk_queue_flag_set(QUEUE_FLAG_PCI_P2PDMA, ns->queue);\n\n\tns->queue->queuedata = ns;\n\tns->ctrl = ctrl;\n\tkref_init(&ns->kref);\n\n\tif (nvme_init_ns_head(ns, nsid, ids, id->nmic & NVME_NS_NMIC_SHARED))\n\t\tgoto out_free_queue;\n\n\tdisk = alloc_disk_node(0, node);\n\tif (!disk)\n\t\tgoto out_unlink_ns;\n\n\tdisk->fops = &nvme_bdev_ops;\n\tdisk->private_data = ns;\n\tdisk->queue = ns->queue;\n\t/*\n\t * Without the multipath code enabled, multiple controller per\n\t * subsystems are visible as devices and thus we cannot use the\n\t * subsystem instance.\n\t */\n\tif (!nvme_mpath_set_disk_name(ns, disk->disk_name, &disk->flags))\n\t\tsprintf(disk->disk_name, \"nvme%dn%d\", ctrl->instance,\n\t\t\tns->head->instance);\n\tns->disk = disk;\n\n\tif (nvme_update_ns_info(ns, id))\n\t\tgoto out_put_disk;\n\n\tdown_write(&ctrl->namespaces_rwsem);\n\tlist_add_tail(&ns->list, &ctrl->namespaces);\n\tup_write(&ctrl->namespaces_rwsem);\n\n\tnvme_get_ctrl(ctrl);\n\n\tdevice_add_disk(ctrl->device, ns->disk, nvme_ns_id_attr_groups);\n\tif (!nvme_ns_head_multipath(ns->head))\n\t\tnvme_add_ns_cdev(ns);\n\n\tnvme_mpath_add_disk(ns, id);\n\tnvme_fault_inject_init(&ns->fault_inject, ns->disk->disk_name);\n\tkfree(id);\n\n\treturn;\n out_put_disk:\n\t/* prevent double queue cleanup */\n\tns->disk->queue = NULL;\n\tput_disk(ns->disk);\n out_unlink_ns:\n\tmutex_lock(&ctrl->subsys->lock);\n\tlist_del_rcu(&ns->siblings);\n\tif (list_empty(&ns->head->list))\n\t\tlist_del_init(&ns->head->entry);\n\tmutex_unlock(&ctrl->subsys->lock);\n\tnvme_put_ns_head(ns->head);\n out_free_queue:\n\tblk_cleanup_queue(ns->queue);\n out_free_ns:\n\tkfree(ns);\n out_free_id:\n\tkfree(id);\n}",
        "patch": "--- code before\n+++ code after\n@@ -51,13 +51,6 @@\n \tif (nvme_update_ns_info(ns, id))\n \t\tgoto out_put_disk;\n \n-\tif ((ctrl->quirks & NVME_QUIRK_LIGHTNVM) && id->vs[0] == 0x1) {\n-\t\tif (nvme_nvm_register(ns, disk->disk_name, node)) {\n-\t\t\tdev_warn(ctrl->device, \"LightNVM init failure\\n\");\n-\t\t\tgoto out_put_disk;\n-\t\t}\n-\t}\n-\n \tdown_write(&ctrl->namespaces_rwsem);\n \tlist_add_tail(&ns->list, &ctrl->namespaces);\n \tup_write(&ctrl->namespaces_rwsem);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif ((ctrl->quirks & NVME_QUIRK_LIGHTNVM) && id->vs[0] == 0x1) {",
                "\t\tif (nvme_nvm_register(ns, disk->disk_name, node)) {",
                "\t\t\tdev_warn(ctrl->device, \"LightNVM init failure\\n\");",
                "\t\t\tgoto out_put_disk;",
                "\t\t}",
                "\t}",
                ""
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap-based buffer overflow was found in the Linux kernel's LightNVM subsystem. The issue results from the lack of proper validation of the length of user-supplied data prior to copying it to a fixed-length heap-based buffer. This vulnerability allows a local attacker to escalate privileges and execute arbitrary code in the context of the kernel. The attacker must first obtain the ability to execute high-privileged code on the target system to exploit this vulnerability."
    },
    {
        "cve_id": "CVE-2022-2991",
        "code_before_change": "static void nvme_free_ns(struct kref *kref)\n{\n\tstruct nvme_ns *ns = container_of(kref, struct nvme_ns, kref);\n\n\tif (ns->ndev)\n\t\tnvme_nvm_unregister(ns);\n\n\tput_disk(ns->disk);\n\tnvme_put_ns_head(ns->head);\n\tnvme_put_ctrl(ns->ctrl);\n\tkfree(ns);\n}",
        "code_after_change": "static void nvme_free_ns(struct kref *kref)\n{\n\tstruct nvme_ns *ns = container_of(kref, struct nvme_ns, kref);\n\n\tput_disk(ns->disk);\n\tnvme_put_ns_head(ns->head);\n\tnvme_put_ctrl(ns->ctrl);\n\tkfree(ns);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,6 @@\n static void nvme_free_ns(struct kref *kref)\n {\n \tstruct nvme_ns *ns = container_of(kref, struct nvme_ns, kref);\n-\n-\tif (ns->ndev)\n-\t\tnvme_nvm_unregister(ns);\n \n \tput_disk(ns->disk);\n \tnvme_put_ns_head(ns->head);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tif (ns->ndev)",
                "\t\tnvme_nvm_unregister(ns);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap-based buffer overflow was found in the Linux kernel's LightNVM subsystem. The issue results from the lack of proper validation of the length of user-supplied data prior to copying it to a fixed-length heap-based buffer. This vulnerability allows a local attacker to escalate privileges and execute arbitrary code in the context of the kernel. The attacker must first obtain the ability to execute high-privileged code on the target system to exploit this vulnerability."
    },
    {
        "cve_id": "CVE-2022-2991",
        "code_before_change": "static int nvme_ns_ioctl(struct nvme_ns *ns, unsigned int cmd,\n\t\tvoid __user *argp)\n{\n\tswitch (cmd) {\n\tcase NVME_IOCTL_ID:\n\t\tforce_successful_syscall_return();\n\t\treturn ns->head->ns_id;\n\tcase NVME_IOCTL_IO_CMD:\n\t\treturn nvme_user_cmd(ns->ctrl, ns, argp);\n\t/*\n\t * struct nvme_user_io can have different padding on some 32-bit ABIs.\n\t * Just accept the compat version as all fields that are used are the\n\t * same size and at the same offset.\n\t */\n#ifdef COMPAT_FOR_U64_ALIGNMENT\n\tcase NVME_IOCTL_SUBMIT_IO32:\n#endif\n\tcase NVME_IOCTL_SUBMIT_IO:\n\t\treturn nvme_submit_io(ns, argp);\n\tcase NVME_IOCTL_IO64_CMD:\n\t\treturn nvme_user_cmd64(ns->ctrl, ns, argp);\n\tdefault:\n\t\tif (!ns->ndev)\n\t\t\treturn -ENOTTY;\n\t\treturn nvme_nvm_ioctl(ns, cmd, argp);\n\t}\n}",
        "code_after_change": "static int nvme_ns_ioctl(struct nvme_ns *ns, unsigned int cmd,\n\t\tvoid __user *argp)\n{\n\tswitch (cmd) {\n\tcase NVME_IOCTL_ID:\n\t\tforce_successful_syscall_return();\n\t\treturn ns->head->ns_id;\n\tcase NVME_IOCTL_IO_CMD:\n\t\treturn nvme_user_cmd(ns->ctrl, ns, argp);\n\t/*\n\t * struct nvme_user_io can have different padding on some 32-bit ABIs.\n\t * Just accept the compat version as all fields that are used are the\n\t * same size and at the same offset.\n\t */\n#ifdef COMPAT_FOR_U64_ALIGNMENT\n\tcase NVME_IOCTL_SUBMIT_IO32:\n#endif\n\tcase NVME_IOCTL_SUBMIT_IO:\n\t\treturn nvme_submit_io(ns, argp);\n\tcase NVME_IOCTL_IO64_CMD:\n\t\treturn nvme_user_cmd64(ns->ctrl, ns, argp);\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,8 +20,6 @@\n \tcase NVME_IOCTL_IO64_CMD:\n \t\treturn nvme_user_cmd64(ns->ctrl, ns, argp);\n \tdefault:\n-\t\tif (!ns->ndev)\n-\t\t\treturn -ENOTTY;\n-\t\treturn nvme_nvm_ioctl(ns, cmd, argp);\n+\t\treturn -ENOTTY;\n \t}\n }",
        "function_modified_lines": {
            "added": [
                "\t\treturn -ENOTTY;"
            ],
            "deleted": [
                "\t\tif (!ns->ndev)",
                "\t\t\treturn -ENOTTY;",
                "\t\treturn nvme_nvm_ioctl(ns, cmd, argp);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap-based buffer overflow was found in the Linux kernel's LightNVM subsystem. The issue results from the lack of proper validation of the length of user-supplied data prior to copying it to a fixed-length heap-based buffer. This vulnerability allows a local attacker to escalate privileges and execute arbitrary code in the context of the kernel. The attacker must first obtain the ability to execute high-privileged code on the target system to exploit this vulnerability."
    },
    {
        "cve_id": "CVE-2022-3028",
        "code_before_change": "static int pfkey_register(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs)\n{\n\tstruct pfkey_sock *pfk = pfkey_sk(sk);\n\tstruct sk_buff *supp_skb;\n\n\tif (hdr->sadb_msg_satype > SADB_SATYPE_MAX)\n\t\treturn -EINVAL;\n\n\tif (hdr->sadb_msg_satype != SADB_SATYPE_UNSPEC) {\n\t\tif (pfk->registered&(1<<hdr->sadb_msg_satype))\n\t\t\treturn -EEXIST;\n\t\tpfk->registered |= (1<<hdr->sadb_msg_satype);\n\t}\n\n\txfrm_probe_algs();\n\n\tsupp_skb = compose_sadb_supported(hdr, GFP_KERNEL | __GFP_ZERO);\n\tif (!supp_skb) {\n\t\tif (hdr->sadb_msg_satype != SADB_SATYPE_UNSPEC)\n\t\t\tpfk->registered &= ~(1<<hdr->sadb_msg_satype);\n\n\t\treturn -ENOBUFS;\n\t}\n\n\tpfkey_broadcast(supp_skb, GFP_KERNEL, BROADCAST_REGISTERED, sk,\n\t\t\tsock_net(sk));\n\treturn 0;\n}",
        "code_after_change": "static int pfkey_register(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs)\n{\n\tstruct pfkey_sock *pfk = pfkey_sk(sk);\n\tstruct sk_buff *supp_skb;\n\n\tif (hdr->sadb_msg_satype > SADB_SATYPE_MAX)\n\t\treturn -EINVAL;\n\n\tif (hdr->sadb_msg_satype != SADB_SATYPE_UNSPEC) {\n\t\tif (pfk->registered&(1<<hdr->sadb_msg_satype))\n\t\t\treturn -EEXIST;\n\t\tpfk->registered |= (1<<hdr->sadb_msg_satype);\n\t}\n\n\tmutex_lock(&pfkey_mutex);\n\txfrm_probe_algs();\n\n\tsupp_skb = compose_sadb_supported(hdr, GFP_KERNEL | __GFP_ZERO);\n\tmutex_unlock(&pfkey_mutex);\n\n\tif (!supp_skb) {\n\t\tif (hdr->sadb_msg_satype != SADB_SATYPE_UNSPEC)\n\t\t\tpfk->registered &= ~(1<<hdr->sadb_msg_satype);\n\n\t\treturn -ENOBUFS;\n\t}\n\n\tpfkey_broadcast(supp_skb, GFP_KERNEL, BROADCAST_REGISTERED, sk,\n\t\t\tsock_net(sk));\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,9 +12,12 @@\n \t\tpfk->registered |= (1<<hdr->sadb_msg_satype);\n \t}\n \n+\tmutex_lock(&pfkey_mutex);\n \txfrm_probe_algs();\n \n \tsupp_skb = compose_sadb_supported(hdr, GFP_KERNEL | __GFP_ZERO);\n+\tmutex_unlock(&pfkey_mutex);\n+\n \tif (!supp_skb) {\n \t\tif (hdr->sadb_msg_satype != SADB_SATYPE_UNSPEC)\n \t\t\tpfk->registered &= ~(1<<hdr->sadb_msg_satype);",
        "function_modified_lines": {
            "added": [
                "\tmutex_lock(&pfkey_mutex);",
                "\tmutex_unlock(&pfkey_mutex);",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-362",
            "CWE-787"
        ],
        "cve_description": "A race condition was found in the Linux kernel's IP framework for transforming packets (XFRM subsystem) when multiple calls to xfrm_probe_algs occurred simultaneously. This flaw could allow a local attacker to potentially trigger an out-of-bounds write or leak kernel heap memory by performing an out-of-bounds read and copying it into a socket."
    },
    {
        "cve_id": "CVE-2022-3577",
        "code_before_change": "static int bigben_probe(struct hid_device *hid,\n\tconst struct hid_device_id *id)\n{\n\tstruct bigben_device *bigben;\n\tstruct hid_input *hidinput;\n\tstruct list_head *report_list;\n\tstruct led_classdev *led;\n\tchar *name;\n\tsize_t name_sz;\n\tint n, error;\n\n\tbigben = devm_kzalloc(&hid->dev, sizeof(*bigben), GFP_KERNEL);\n\tif (!bigben)\n\t\treturn -ENOMEM;\n\thid_set_drvdata(hid, bigben);\n\tbigben->hid = hid;\n\tbigben->removed = false;\n\n\terror = hid_parse(hid);\n\tif (error) {\n\t\thid_err(hid, \"parse failed\\n\");\n\t\treturn error;\n\t}\n\n\terror = hid_hw_start(hid, HID_CONNECT_DEFAULT & ~HID_CONNECT_FF);\n\tif (error) {\n\t\thid_err(hid, \"hw start failed\\n\");\n\t\treturn error;\n\t}\n\n\treport_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tbigben->report = list_entry(report_list->next,\n\t\tstruct hid_report, list);\n\n\thidinput = list_first_entry(&hid->inputs, struct hid_input, list);\n\tset_bit(FF_RUMBLE, hidinput->input->ffbit);\n\n\tINIT_WORK(&bigben->worker, bigben_worker);\n\n\terror = input_ff_create_memless(hidinput->input, NULL,\n\t\thid_bigben_play_effect);\n\tif (error)\n\t\tgoto error_hw_stop;\n\n\tname_sz = strlen(dev_name(&hid->dev)) + strlen(\":red:bigben#\") + 1;\n\n\tfor (n = 0; n < NUM_LEDS; n++) {\n\t\tled = devm_kzalloc(\n\t\t\t&hid->dev,\n\t\t\tsizeof(struct led_classdev) + name_sz,\n\t\t\tGFP_KERNEL\n\t\t);\n\t\tif (!led) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto error_hw_stop;\n\t\t}\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz,\n\t\t\t\"%s:red:bigben%d\",\n\t\t\tdev_name(&hid->dev), n + 1\n\t\t);\n\t\tled->name = name;\n\t\tled->brightness = (n == 0) ? LED_ON : LED_OFF;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = bigben_get_led;\n\t\tled->brightness_set = bigben_set_led;\n\t\tbigben->leds[n] = led;\n\t\terror = devm_led_classdev_register(&hid->dev, led);\n\t\tif (error)\n\t\t\tgoto error_hw_stop;\n\t}\n\n\t/* initial state: LED1 is on, no rumble effect */\n\tbigben->led_state = BIT(0);\n\tbigben->right_motor_on = 0;\n\tbigben->left_motor_force = 0;\n\tbigben->work_led = true;\n\tbigben->work_ff = true;\n\tschedule_work(&bigben->worker);\n\n\thid_info(hid, \"LED and force feedback support for BigBen gamepad\\n\");\n\n\treturn 0;\n\nerror_hw_stop:\n\thid_hw_stop(hid);\n\treturn error;\n}",
        "code_after_change": "static int bigben_probe(struct hid_device *hid,\n\tconst struct hid_device_id *id)\n{\n\tstruct bigben_device *bigben;\n\tstruct hid_input *hidinput;\n\tstruct list_head *report_list;\n\tstruct led_classdev *led;\n\tchar *name;\n\tsize_t name_sz;\n\tint n, error;\n\n\tbigben = devm_kzalloc(&hid->dev, sizeof(*bigben), GFP_KERNEL);\n\tif (!bigben)\n\t\treturn -ENOMEM;\n\thid_set_drvdata(hid, bigben);\n\tbigben->hid = hid;\n\tbigben->removed = false;\n\n\terror = hid_parse(hid);\n\tif (error) {\n\t\thid_err(hid, \"parse failed\\n\");\n\t\treturn error;\n\t}\n\n\terror = hid_hw_start(hid, HID_CONNECT_DEFAULT & ~HID_CONNECT_FF);\n\tif (error) {\n\t\thid_err(hid, \"hw start failed\\n\");\n\t\treturn error;\n\t}\n\n\treport_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tbigben->report = list_entry(report_list->next,\n\t\tstruct hid_report, list);\n\n\tif (list_empty(&hid->inputs)) {\n\t\thid_err(hid, \"no inputs found\\n\");\n\t\terror = -ENODEV;\n\t\tgoto error_hw_stop;\n\t}\n\n\thidinput = list_first_entry(&hid->inputs, struct hid_input, list);\n\tset_bit(FF_RUMBLE, hidinput->input->ffbit);\n\n\tINIT_WORK(&bigben->worker, bigben_worker);\n\n\terror = input_ff_create_memless(hidinput->input, NULL,\n\t\thid_bigben_play_effect);\n\tif (error)\n\t\tgoto error_hw_stop;\n\n\tname_sz = strlen(dev_name(&hid->dev)) + strlen(\":red:bigben#\") + 1;\n\n\tfor (n = 0; n < NUM_LEDS; n++) {\n\t\tled = devm_kzalloc(\n\t\t\t&hid->dev,\n\t\t\tsizeof(struct led_classdev) + name_sz,\n\t\t\tGFP_KERNEL\n\t\t);\n\t\tif (!led) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto error_hw_stop;\n\t\t}\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz,\n\t\t\t\"%s:red:bigben%d\",\n\t\t\tdev_name(&hid->dev), n + 1\n\t\t);\n\t\tled->name = name;\n\t\tled->brightness = (n == 0) ? LED_ON : LED_OFF;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = bigben_get_led;\n\t\tled->brightness_set = bigben_set_led;\n\t\tbigben->leds[n] = led;\n\t\terror = devm_led_classdev_register(&hid->dev, led);\n\t\tif (error)\n\t\t\tgoto error_hw_stop;\n\t}\n\n\t/* initial state: LED1 is on, no rumble effect */\n\tbigben->led_state = BIT(0);\n\tbigben->right_motor_on = 0;\n\tbigben->left_motor_force = 0;\n\tbigben->work_led = true;\n\tbigben->work_ff = true;\n\tschedule_work(&bigben->worker);\n\n\thid_info(hid, \"LED and force feedback support for BigBen gamepad\\n\");\n\n\treturn 0;\n\nerror_hw_stop:\n\thid_hw_stop(hid);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,6 +31,12 @@\n \treport_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n \tbigben->report = list_entry(report_list->next,\n \t\tstruct hid_report, list);\n+\n+\tif (list_empty(&hid->inputs)) {\n+\t\thid_err(hid, \"no inputs found\\n\");\n+\t\terror = -ENODEV;\n+\t\tgoto error_hw_stop;\n+\t}\n \n \thidinput = list_first_entry(&hid->inputs, struct hid_input, list);\n \tset_bit(FF_RUMBLE, hidinput->input->ffbit);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (list_empty(&hid->inputs)) {",
                "\t\thid_err(hid, \"no inputs found\\n\");",
                "\t\terror = -ENODEV;",
                "\t\tgoto error_hw_stop;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory write flaw was found in the Linux kernel\u2019s Kid-friendly Wired Controller driver. This flaw allows a local user to crash or potentially escalate their privileges on the system. It is in bigben_probe of drivers/hid/hid-bigbenff.c. The reason is incorrect assumption - bigben devices all have inputs. However, malicious devices can break this assumption, leaking to out-of-bound write."
    },
    {
        "cve_id": "CVE-2022-36280",
        "code_before_change": "void vmw_kms_cursor_snoop(struct vmw_surface *srf,\n\t\t\t  struct ttm_object_file *tfile,\n\t\t\t  struct ttm_buffer_object *bo,\n\t\t\t  SVGA3dCmdHeader *header)\n{\n\tstruct ttm_bo_kmap_obj map;\n\tunsigned long kmap_offset;\n\tunsigned long kmap_num;\n\tSVGA3dCopyBox *box;\n\tunsigned box_count;\n\tvoid *virtual;\n\tbool dummy;\n\tstruct vmw_dma_cmd {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdSurfaceDMA dma;\n\t} *cmd;\n\tint i, ret;\n\n\tcmd = container_of(header, struct vmw_dma_cmd, header);\n\n\t/* No snooper installed, nothing to copy */\n\tif (!srf->snooper.image)\n\t\treturn;\n\n\tif (cmd->dma.host.face != 0 || cmd->dma.host.mipmap != 0) {\n\t\tDRM_ERROR(\"face and mipmap for cursors should never != 0\\n\");\n\t\treturn;\n\t}\n\n\tif (cmd->header.size < 64) {\n\t\tDRM_ERROR(\"at least one full copy box must be given\\n\");\n\t\treturn;\n\t}\n\n\tbox = (SVGA3dCopyBox *)&cmd[1];\n\tbox_count = (cmd->header.size - sizeof(SVGA3dCmdSurfaceDMA)) /\n\t\t\tsizeof(SVGA3dCopyBox);\n\n\tif (cmd->dma.guest.ptr.offset % PAGE_SIZE ||\n\t    box->x != 0    || box->y != 0    || box->z != 0    ||\n\t    box->srcx != 0 || box->srcy != 0 || box->srcz != 0 ||\n\t    box->d != 1    || box_count != 1) {\n\t\t/* TODO handle none page aligned offsets */\n\t\t/* TODO handle more dst & src != 0 */\n\t\t/* TODO handle more then one copy */\n\t\tDRM_ERROR(\"Can't snoop dma request for cursor!\\n\");\n\t\tDRM_ERROR(\"(%u, %u, %u) (%u, %u, %u) (%ux%ux%u) %u %u\\n\",\n\t\t\t  box->srcx, box->srcy, box->srcz,\n\t\t\t  box->x, box->y, box->z,\n\t\t\t  box->w, box->h, box->d, box_count,\n\t\t\t  cmd->dma.guest.ptr.offset);\n\t\treturn;\n\t}\n\n\tkmap_offset = cmd->dma.guest.ptr.offset >> PAGE_SHIFT;\n\tkmap_num = (64*64*4) >> PAGE_SHIFT;\n\n\tret = ttm_bo_reserve(bo, true, false, NULL);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"reserve failed\\n\");\n\t\treturn;\n\t}\n\n\tret = ttm_bo_kmap(bo, kmap_offset, kmap_num, &map);\n\tif (unlikely(ret != 0))\n\t\tgoto err_unreserve;\n\n\tvirtual = ttm_kmap_obj_virtual(&map, &dummy);\n\n\tif (box->w == 64 && cmd->dma.guest.pitch == 64*4) {\n\t\tmemcpy(srf->snooper.image, virtual, 64*64*4);\n\t} else {\n\t\t/* Image is unsigned pointer. */\n\t\tfor (i = 0; i < box->h; i++)\n\t\t\tmemcpy(srf->snooper.image + i * 64,\n\t\t\t       virtual + i * cmd->dma.guest.pitch,\n\t\t\t       box->w * 4);\n\t}\n\n\tsrf->snooper.age++;\n\n\tttm_bo_kunmap(&map);\nerr_unreserve:\n\tttm_bo_unreserve(bo);\n}",
        "code_after_change": "void vmw_kms_cursor_snoop(struct vmw_surface *srf,\n\t\t\t  struct ttm_object_file *tfile,\n\t\t\t  struct ttm_buffer_object *bo,\n\t\t\t  SVGA3dCmdHeader *header)\n{\n\tstruct ttm_bo_kmap_obj map;\n\tunsigned long kmap_offset;\n\tunsigned long kmap_num;\n\tSVGA3dCopyBox *box;\n\tunsigned box_count;\n\tvoid *virtual;\n\tbool dummy;\n\tstruct vmw_dma_cmd {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdSurfaceDMA dma;\n\t} *cmd;\n\tint i, ret;\n\n\tcmd = container_of(header, struct vmw_dma_cmd, header);\n\n\t/* No snooper installed, nothing to copy */\n\tif (!srf->snooper.image)\n\t\treturn;\n\n\tif (cmd->dma.host.face != 0 || cmd->dma.host.mipmap != 0) {\n\t\tDRM_ERROR(\"face and mipmap for cursors should never != 0\\n\");\n\t\treturn;\n\t}\n\n\tif (cmd->header.size < 64) {\n\t\tDRM_ERROR(\"at least one full copy box must be given\\n\");\n\t\treturn;\n\t}\n\n\tbox = (SVGA3dCopyBox *)&cmd[1];\n\tbox_count = (cmd->header.size - sizeof(SVGA3dCmdSurfaceDMA)) /\n\t\t\tsizeof(SVGA3dCopyBox);\n\n\tif (cmd->dma.guest.ptr.offset % PAGE_SIZE ||\n\t    box->x != 0    || box->y != 0    || box->z != 0    ||\n\t    box->srcx != 0 || box->srcy != 0 || box->srcz != 0 ||\n\t    box->d != 1    || box_count != 1 ||\n\t    box->w > 64 || box->h > 64) {\n\t\t/* TODO handle none page aligned offsets */\n\t\t/* TODO handle more dst & src != 0 */\n\t\t/* TODO handle more then one copy */\n\t\tDRM_ERROR(\"Can't snoop dma request for cursor!\\n\");\n\t\tDRM_ERROR(\"(%u, %u, %u) (%u, %u, %u) (%ux%ux%u) %u %u\\n\",\n\t\t\t  box->srcx, box->srcy, box->srcz,\n\t\t\t  box->x, box->y, box->z,\n\t\t\t  box->w, box->h, box->d, box_count,\n\t\t\t  cmd->dma.guest.ptr.offset);\n\t\treturn;\n\t}\n\n\tkmap_offset = cmd->dma.guest.ptr.offset >> PAGE_SHIFT;\n\tkmap_num = (64*64*4) >> PAGE_SHIFT;\n\n\tret = ttm_bo_reserve(bo, true, false, NULL);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"reserve failed\\n\");\n\t\treturn;\n\t}\n\n\tret = ttm_bo_kmap(bo, kmap_offset, kmap_num, &map);\n\tif (unlikely(ret != 0))\n\t\tgoto err_unreserve;\n\n\tvirtual = ttm_kmap_obj_virtual(&map, &dummy);\n\n\tif (box->w == 64 && cmd->dma.guest.pitch == 64*4) {\n\t\tmemcpy(srf->snooper.image, virtual, 64*64*4);\n\t} else {\n\t\t/* Image is unsigned pointer. */\n\t\tfor (i = 0; i < box->h; i++)\n\t\t\tmemcpy(srf->snooper.image + i * 64,\n\t\t\t       virtual + i * cmd->dma.guest.pitch,\n\t\t\t       box->w * 4);\n\t}\n\n\tsrf->snooper.age++;\n\n\tttm_bo_kunmap(&map);\nerr_unreserve:\n\tttm_bo_unreserve(bo);\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,7 +39,8 @@\n \tif (cmd->dma.guest.ptr.offset % PAGE_SIZE ||\n \t    box->x != 0    || box->y != 0    || box->z != 0    ||\n \t    box->srcx != 0 || box->srcy != 0 || box->srcz != 0 ||\n-\t    box->d != 1    || box_count != 1) {\n+\t    box->d != 1    || box_count != 1 ||\n+\t    box->w > 64 || box->h > 64) {\n \t\t/* TODO handle none page aligned offsets */\n \t\t/* TODO handle more dst & src != 0 */\n \t\t/* TODO handle more then one copy */",
        "function_modified_lines": {
            "added": [
                "\t    box->d != 1    || box_count != 1 ||",
                "\t    box->w > 64 || box->h > 64) {"
            ],
            "deleted": [
                "\t    box->d != 1    || box_count != 1) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds(OOB) memory access vulnerability was found in vmwgfx driver in drivers/gpu/vmxgfx/vmxgfx_kms.c in GPU component in the Linux kernel with device file '/dev/dri/renderD128 (or Dxxx)'. This flaw allows a local attacker with a user account on the system to gain privilege, causing a denial of service(DoS)."
    },
    {
        "cve_id": "CVE-2022-41674",
        "code_before_change": "static void\ncfg80211_update_notlisted_nontrans(struct wiphy *wiphy,\n\t\t\t\t   struct cfg80211_bss *nontrans_bss,\n\t\t\t\t   struct ieee80211_mgmt *mgmt, size_t len)\n{\n\tu8 *ie, *new_ie, *pos;\n\tconst struct element *nontrans_ssid;\n\tconst u8 *trans_ssid, *mbssid;\n\tsize_t ielen = len - offsetof(struct ieee80211_mgmt,\n\t\t\t\t      u.probe_resp.variable);\n\tsize_t new_ie_len;\n\tstruct cfg80211_bss_ies *new_ies;\n\tconst struct cfg80211_bss_ies *old;\n\tu8 cpy_len;\n\n\tlockdep_assert_held(&wiphy_to_rdev(wiphy)->bss_lock);\n\n\tie = mgmt->u.probe_resp.variable;\n\n\tnew_ie_len = ielen;\n\ttrans_ssid = cfg80211_find_ie(WLAN_EID_SSID, ie, ielen);\n\tif (!trans_ssid)\n\t\treturn;\n\tnew_ie_len -= trans_ssid[1];\n\tmbssid = cfg80211_find_ie(WLAN_EID_MULTIPLE_BSSID, ie, ielen);\n\t/*\n\t * It's not valid to have the MBSSID element before SSID\n\t * ignore if that happens - the code below assumes it is\n\t * after (while copying things inbetween).\n\t */\n\tif (!mbssid || mbssid < trans_ssid)\n\t\treturn;\n\tnew_ie_len -= mbssid[1];\n\n\tnontrans_ssid = ieee80211_bss_get_elem(nontrans_bss, WLAN_EID_SSID);\n\tif (!nontrans_ssid)\n\t\treturn;\n\n\tnew_ie_len += nontrans_ssid->datalen;\n\n\t/* generate new ie for nontrans BSS\n\t * 1. replace SSID with nontrans BSS' SSID\n\t * 2. skip MBSSID IE\n\t */\n\tnew_ie = kzalloc(new_ie_len, GFP_ATOMIC);\n\tif (!new_ie)\n\t\treturn;\n\n\tnew_ies = kzalloc(sizeof(*new_ies) + new_ie_len, GFP_ATOMIC);\n\tif (!new_ies)\n\t\tgoto out_free;\n\n\tpos = new_ie;\n\n\t/* copy the nontransmitted SSID */\n\tcpy_len = nontrans_ssid->datalen + 2;\n\tmemcpy(pos, nontrans_ssid, cpy_len);\n\tpos += cpy_len;\n\t/* copy the IEs between SSID and MBSSID */\n\tcpy_len = trans_ssid[1] + 2;\n\tmemcpy(pos, (trans_ssid + cpy_len), (mbssid - (trans_ssid + cpy_len)));\n\tpos += (mbssid - (trans_ssid + cpy_len));\n\t/* copy the IEs after MBSSID */\n\tcpy_len = mbssid[1] + 2;\n\tmemcpy(pos, mbssid + cpy_len, ((ie + ielen) - (mbssid + cpy_len)));\n\n\t/* update ie */\n\tnew_ies->len = new_ie_len;\n\tnew_ies->tsf = le64_to_cpu(mgmt->u.probe_resp.timestamp);\n\tnew_ies->from_beacon = ieee80211_is_beacon(mgmt->frame_control);\n\tmemcpy(new_ies->data, new_ie, new_ie_len);\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\told = rcu_access_pointer(nontrans_bss->proberesp_ies);\n\t\trcu_assign_pointer(nontrans_bss->proberesp_ies, new_ies);\n\t\trcu_assign_pointer(nontrans_bss->ies, new_ies);\n\t\tif (old)\n\t\t\tkfree_rcu((struct cfg80211_bss_ies *)old, rcu_head);\n\t} else {\n\t\told = rcu_access_pointer(nontrans_bss->beacon_ies);\n\t\trcu_assign_pointer(nontrans_bss->beacon_ies, new_ies);\n\t\trcu_assign_pointer(nontrans_bss->ies, new_ies);\n\t\tif (old)\n\t\t\tkfree_rcu((struct cfg80211_bss_ies *)old, rcu_head);\n\t}\n\nout_free:\n\tkfree(new_ie);\n}",
        "code_after_change": "static void\ncfg80211_update_notlisted_nontrans(struct wiphy *wiphy,\n\t\t\t\t   struct cfg80211_bss *nontrans_bss,\n\t\t\t\t   struct ieee80211_mgmt *mgmt, size_t len)\n{\n\tu8 *ie, *new_ie, *pos;\n\tconst struct element *nontrans_ssid;\n\tconst u8 *trans_ssid, *mbssid;\n\tsize_t ielen = len - offsetof(struct ieee80211_mgmt,\n\t\t\t\t      u.probe_resp.variable);\n\tsize_t new_ie_len;\n\tstruct cfg80211_bss_ies *new_ies;\n\tconst struct cfg80211_bss_ies *old;\n\tsize_t cpy_len;\n\n\tlockdep_assert_held(&wiphy_to_rdev(wiphy)->bss_lock);\n\n\tie = mgmt->u.probe_resp.variable;\n\n\tnew_ie_len = ielen;\n\ttrans_ssid = cfg80211_find_ie(WLAN_EID_SSID, ie, ielen);\n\tif (!trans_ssid)\n\t\treturn;\n\tnew_ie_len -= trans_ssid[1];\n\tmbssid = cfg80211_find_ie(WLAN_EID_MULTIPLE_BSSID, ie, ielen);\n\t/*\n\t * It's not valid to have the MBSSID element before SSID\n\t * ignore if that happens - the code below assumes it is\n\t * after (while copying things inbetween).\n\t */\n\tif (!mbssid || mbssid < trans_ssid)\n\t\treturn;\n\tnew_ie_len -= mbssid[1];\n\n\tnontrans_ssid = ieee80211_bss_get_elem(nontrans_bss, WLAN_EID_SSID);\n\tif (!nontrans_ssid)\n\t\treturn;\n\n\tnew_ie_len += nontrans_ssid->datalen;\n\n\t/* generate new ie for nontrans BSS\n\t * 1. replace SSID with nontrans BSS' SSID\n\t * 2. skip MBSSID IE\n\t */\n\tnew_ie = kzalloc(new_ie_len, GFP_ATOMIC);\n\tif (!new_ie)\n\t\treturn;\n\n\tnew_ies = kzalloc(sizeof(*new_ies) + new_ie_len, GFP_ATOMIC);\n\tif (!new_ies)\n\t\tgoto out_free;\n\n\tpos = new_ie;\n\n\t/* copy the nontransmitted SSID */\n\tcpy_len = nontrans_ssid->datalen + 2;\n\tmemcpy(pos, nontrans_ssid, cpy_len);\n\tpos += cpy_len;\n\t/* copy the IEs between SSID and MBSSID */\n\tcpy_len = trans_ssid[1] + 2;\n\tmemcpy(pos, (trans_ssid + cpy_len), (mbssid - (trans_ssid + cpy_len)));\n\tpos += (mbssid - (trans_ssid + cpy_len));\n\t/* copy the IEs after MBSSID */\n\tcpy_len = mbssid[1] + 2;\n\tmemcpy(pos, mbssid + cpy_len, ((ie + ielen) - (mbssid + cpy_len)));\n\n\t/* update ie */\n\tnew_ies->len = new_ie_len;\n\tnew_ies->tsf = le64_to_cpu(mgmt->u.probe_resp.timestamp);\n\tnew_ies->from_beacon = ieee80211_is_beacon(mgmt->frame_control);\n\tmemcpy(new_ies->data, new_ie, new_ie_len);\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\told = rcu_access_pointer(nontrans_bss->proberesp_ies);\n\t\trcu_assign_pointer(nontrans_bss->proberesp_ies, new_ies);\n\t\trcu_assign_pointer(nontrans_bss->ies, new_ies);\n\t\tif (old)\n\t\t\tkfree_rcu((struct cfg80211_bss_ies *)old, rcu_head);\n\t} else {\n\t\told = rcu_access_pointer(nontrans_bss->beacon_ies);\n\t\trcu_assign_pointer(nontrans_bss->beacon_ies, new_ies);\n\t\trcu_assign_pointer(nontrans_bss->ies, new_ies);\n\t\tif (old)\n\t\t\tkfree_rcu((struct cfg80211_bss_ies *)old, rcu_head);\n\t}\n\nout_free:\n\tkfree(new_ie);\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \tsize_t new_ie_len;\n \tstruct cfg80211_bss_ies *new_ies;\n \tconst struct cfg80211_bss_ies *old;\n-\tu8 cpy_len;\n+\tsize_t cpy_len;\n \n \tlockdep_assert_held(&wiphy_to_rdev(wiphy)->bss_lock);\n ",
        "function_modified_lines": {
            "added": [
                "\tsize_t cpy_len;"
            ],
            "deleted": [
                "\tu8 cpy_len;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.19.16. Attackers able to inject WLAN frames could cause a buffer overflow in the ieee80211_bss_info_update function in net/mac80211/scan.c."
    },
    {
        "cve_id": "CVE-2022-43750",
        "code_before_change": "static int mon_bin_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\t/* don't do anything here: \"fault\" will set up page table entries */\n\tvma->vm_ops = &mon_bin_vm_ops;\n\tvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\n\tvma->vm_private_data = filp->private_data;\n\tmon_bin_vma_open(vma);\n\treturn 0;\n}",
        "code_after_change": "static int mon_bin_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\t/* don't do anything here: \"fault\" will set up page table entries */\n\tvma->vm_ops = &mon_bin_vm_ops;\n\n\tif (vma->vm_flags & VM_WRITE)\n\t\treturn -EPERM;\n\n\tvma->vm_flags &= ~VM_MAYWRITE;\n\tvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\n\tvma->vm_private_data = filp->private_data;\n\tmon_bin_vma_open(vma);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,11 @@\n {\n \t/* don't do anything here: \"fault\" will set up page table entries */\n \tvma->vm_ops = &mon_bin_vm_ops;\n+\n+\tif (vma->vm_flags & VM_WRITE)\n+\t\treturn -EPERM;\n+\n+\tvma->vm_flags &= ~VM_MAYWRITE;\n \tvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\n \tvma->vm_private_data = filp->private_data;\n \tmon_bin_vma_open(vma);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (vma->vm_flags & VM_WRITE)",
                "\t\treturn -EPERM;",
                "",
                "\tvma->vm_flags &= ~VM_MAYWRITE;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "drivers/usb/mon/mon_bin.c in usbmon in the Linux kernel before 5.19.15 and 6.x before 6.0.1 allows a user-space client to corrupt the monitor's internal memory."
    },
    {
        "cve_id": "CVE-2022-4378",
        "code_before_change": "static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table,\n\t\tint write, void *buffer, size_t *lenp, loff_t *ppos,\n\t\tunsigned long convmul, unsigned long convdiv)\n{\n\tunsigned long *i, *min, *max;\n\tint vleft, first = 1, err = 0;\n\tsize_t left;\n\tchar *p;\n\n\tif (!data || !table->maxlen || !*lenp || (*ppos && !write)) {\n\t\t*lenp = 0;\n\t\treturn 0;\n\t}\n\n\ti = data;\n\tmin = table->extra1;\n\tmax = table->extra2;\n\tvleft = table->maxlen / sizeof(unsigned long);\n\tleft = *lenp;\n\n\tif (write) {\n\t\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\t\tgoto out;\n\n\t\tif (left > PAGE_SIZE - 1)\n\t\t\tleft = PAGE_SIZE - 1;\n\t\tp = buffer;\n\t}\n\n\tfor (; left && vleft--; i++, first = 0) {\n\t\tunsigned long val;\n\n\t\tif (write) {\n\t\t\tbool neg;\n\n\t\t\tleft -= proc_skip_spaces(&p);\n\t\t\tif (!left)\n\t\t\t\tbreak;\n\n\t\t\terr = proc_get_long(&p, &left, &val, &neg,\n\t\t\t\t\t     proc_wspace_sep,\n\t\t\t\t\t     sizeof(proc_wspace_sep), NULL);\n\t\t\tif (err || neg) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tval = convmul * val / convdiv;\n\t\t\tif ((min && val < *min) || (max && val > *max)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tWRITE_ONCE(*i, val);\n\t\t} else {\n\t\t\tval = convdiv * READ_ONCE(*i) / convmul;\n\t\t\tif (!first)\n\t\t\t\tproc_put_char(&buffer, &left, '\\t');\n\t\t\tproc_put_long(&buffer, &left, val, false);\n\t\t}\n\t}\n\n\tif (!write && !first && left && !err)\n\t\tproc_put_char(&buffer, &left, '\\n');\n\tif (write && !err)\n\t\tleft -= proc_skip_spaces(&p);\n\tif (write && first)\n\t\treturn err ? : -EINVAL;\n\t*lenp -= left;\nout:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "code_after_change": "static int __do_proc_doulongvec_minmax(void *data, struct ctl_table *table,\n\t\tint write, void *buffer, size_t *lenp, loff_t *ppos,\n\t\tunsigned long convmul, unsigned long convdiv)\n{\n\tunsigned long *i, *min, *max;\n\tint vleft, first = 1, err = 0;\n\tsize_t left;\n\tchar *p;\n\n\tif (!data || !table->maxlen || !*lenp || (*ppos && !write)) {\n\t\t*lenp = 0;\n\t\treturn 0;\n\t}\n\n\ti = data;\n\tmin = table->extra1;\n\tmax = table->extra2;\n\tvleft = table->maxlen / sizeof(unsigned long);\n\tleft = *lenp;\n\n\tif (write) {\n\t\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\t\tgoto out;\n\n\t\tif (left > PAGE_SIZE - 1)\n\t\t\tleft = PAGE_SIZE - 1;\n\t\tp = buffer;\n\t}\n\n\tfor (; left && vleft--; i++, first = 0) {\n\t\tunsigned long val;\n\n\t\tif (write) {\n\t\t\tbool neg;\n\n\t\t\tproc_skip_spaces(&p, &left);\n\t\t\tif (!left)\n\t\t\t\tbreak;\n\n\t\t\terr = proc_get_long(&p, &left, &val, &neg,\n\t\t\t\t\t     proc_wspace_sep,\n\t\t\t\t\t     sizeof(proc_wspace_sep), NULL);\n\t\t\tif (err || neg) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tval = convmul * val / convdiv;\n\t\t\tif ((min && val < *min) || (max && val > *max)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tWRITE_ONCE(*i, val);\n\t\t} else {\n\t\t\tval = convdiv * READ_ONCE(*i) / convmul;\n\t\t\tif (!first)\n\t\t\t\tproc_put_char(&buffer, &left, '\\t');\n\t\t\tproc_put_long(&buffer, &left, val, false);\n\t\t}\n\t}\n\n\tif (!write && !first && left && !err)\n\t\tproc_put_char(&buffer, &left, '\\n');\n\tif (write && !err)\n\t\tproc_skip_spaces(&p, &left);\n\tif (write && first)\n\t\treturn err ? : -EINVAL;\n\t*lenp -= left;\nout:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -33,7 +33,7 @@\n \t\tif (write) {\n \t\t\tbool neg;\n \n-\t\t\tleft -= proc_skip_spaces(&p);\n+\t\t\tproc_skip_spaces(&p, &left);\n \t\t\tif (!left)\n \t\t\t\tbreak;\n \n@@ -62,7 +62,7 @@\n \tif (!write && !first && left && !err)\n \t\tproc_put_char(&buffer, &left, '\\n');\n \tif (write && !err)\n-\t\tleft -= proc_skip_spaces(&p);\n+\t\tproc_skip_spaces(&p, &left);\n \tif (write && first)\n \t\treturn err ? : -EINVAL;\n \t*lenp -= left;",
        "function_modified_lines": {
            "added": [
                "\t\t\tproc_skip_spaces(&p, &left);",
                "\t\tproc_skip_spaces(&p, &left);"
            ],
            "deleted": [
                "\t\t\tleft -= proc_skip_spaces(&p);",
                "\t\tleft -= proc_skip_spaces(&p);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A stack overflow flaw was found in the Linux kernel's SYSCTL subsystem in how a user changes certain kernel parameters and variables. This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2022-4378",
        "code_before_change": "static int __do_proc_dointvec(void *tbl_data, struct ctl_table *table,\n\t\t  int write, void *buffer,\n\t\t  size_t *lenp, loff_t *ppos,\n\t\t  int (*conv)(bool *negp, unsigned long *lvalp, int *valp,\n\t\t\t      int write, void *data),\n\t\t  void *data)\n{\n\tint *i, vleft, first = 1, err = 0;\n\tsize_t left;\n\tchar *p;\n\n\tif (!tbl_data || !table->maxlen || !*lenp || (*ppos && !write)) {\n\t\t*lenp = 0;\n\t\treturn 0;\n\t}\n\n\ti = (int *) tbl_data;\n\tvleft = table->maxlen / sizeof(*i);\n\tleft = *lenp;\n\n\tif (!conv)\n\t\tconv = do_proc_dointvec_conv;\n\n\tif (write) {\n\t\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\t\tgoto out;\n\n\t\tif (left > PAGE_SIZE - 1)\n\t\t\tleft = PAGE_SIZE - 1;\n\t\tp = buffer;\n\t}\n\n\tfor (; left && vleft--; i++, first=0) {\n\t\tunsigned long lval;\n\t\tbool neg;\n\n\t\tif (write) {\n\t\t\tleft -= proc_skip_spaces(&p);\n\n\t\t\tif (!left)\n\t\t\t\tbreak;\n\t\t\terr = proc_get_long(&p, &left, &lval, &neg,\n\t\t\t\t\t     proc_wspace_sep,\n\t\t\t\t\t     sizeof(proc_wspace_sep), NULL);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tif (conv(&neg, &lval, i, 1, data)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (conv(&neg, &lval, i, 0, data)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!first)\n\t\t\t\tproc_put_char(&buffer, &left, '\\t');\n\t\t\tproc_put_long(&buffer, &left, lval, neg);\n\t\t}\n\t}\n\n\tif (!write && !first && left && !err)\n\t\tproc_put_char(&buffer, &left, '\\n');\n\tif (write && !err && left)\n\t\tleft -= proc_skip_spaces(&p);\n\tif (write && first)\n\t\treturn err ? : -EINVAL;\n\t*lenp -= left;\nout:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "code_after_change": "static int __do_proc_dointvec(void *tbl_data, struct ctl_table *table,\n\t\t  int write, void *buffer,\n\t\t  size_t *lenp, loff_t *ppos,\n\t\t  int (*conv)(bool *negp, unsigned long *lvalp, int *valp,\n\t\t\t      int write, void *data),\n\t\t  void *data)\n{\n\tint *i, vleft, first = 1, err = 0;\n\tsize_t left;\n\tchar *p;\n\n\tif (!tbl_data || !table->maxlen || !*lenp || (*ppos && !write)) {\n\t\t*lenp = 0;\n\t\treturn 0;\n\t}\n\n\ti = (int *) tbl_data;\n\tvleft = table->maxlen / sizeof(*i);\n\tleft = *lenp;\n\n\tif (!conv)\n\t\tconv = do_proc_dointvec_conv;\n\n\tif (write) {\n\t\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\t\tgoto out;\n\n\t\tif (left > PAGE_SIZE - 1)\n\t\t\tleft = PAGE_SIZE - 1;\n\t\tp = buffer;\n\t}\n\n\tfor (; left && vleft--; i++, first=0) {\n\t\tunsigned long lval;\n\t\tbool neg;\n\n\t\tif (write) {\n\t\t\tproc_skip_spaces(&p, &left);\n\n\t\t\tif (!left)\n\t\t\t\tbreak;\n\t\t\terr = proc_get_long(&p, &left, &lval, &neg,\n\t\t\t\t\t     proc_wspace_sep,\n\t\t\t\t\t     sizeof(proc_wspace_sep), NULL);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tif (conv(&neg, &lval, i, 1, data)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (conv(&neg, &lval, i, 0, data)) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!first)\n\t\t\t\tproc_put_char(&buffer, &left, '\\t');\n\t\t\tproc_put_long(&buffer, &left, lval, neg);\n\t\t}\n\t}\n\n\tif (!write && !first && left && !err)\n\t\tproc_put_char(&buffer, &left, '\\n');\n\tif (write && !err && left)\n\t\tproc_skip_spaces(&p, &left);\n\tif (write && first)\n\t\treturn err ? : -EINVAL;\n\t*lenp -= left;\nout:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,7 +35,7 @@\n \t\tbool neg;\n \n \t\tif (write) {\n-\t\t\tleft -= proc_skip_spaces(&p);\n+\t\t\tproc_skip_spaces(&p, &left);\n \n \t\t\tif (!left)\n \t\t\t\tbreak;\n@@ -62,7 +62,7 @@\n \tif (!write && !first && left && !err)\n \t\tproc_put_char(&buffer, &left, '\\n');\n \tif (write && !err && left)\n-\t\tleft -= proc_skip_spaces(&p);\n+\t\tproc_skip_spaces(&p, &left);\n \tif (write && first)\n \t\treturn err ? : -EINVAL;\n \t*lenp -= left;",
        "function_modified_lines": {
            "added": [
                "\t\t\tproc_skip_spaces(&p, &left);",
                "\t\tproc_skip_spaces(&p, &left);"
            ],
            "deleted": [
                "\t\t\tleft -= proc_skip_spaces(&p);",
                "\t\tleft -= proc_skip_spaces(&p);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A stack overflow flaw was found in the Linux kernel's SYSCTL subsystem in how a user changes certain kernel parameters and variables. This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2022-4378",
        "code_before_change": "static int do_proc_douintvec_w(unsigned int *tbl_data,\n\t\t\t       struct ctl_table *table,\n\t\t\t       void *buffer,\n\t\t\t       size_t *lenp, loff_t *ppos,\n\t\t\t       int (*conv)(unsigned long *lvalp,\n\t\t\t\t\t   unsigned int *valp,\n\t\t\t\t\t   int write, void *data),\n\t\t\t       void *data)\n{\n\tunsigned long lval;\n\tint err = 0;\n\tsize_t left;\n\tbool neg;\n\tchar *p = buffer;\n\n\tleft = *lenp;\n\n\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\tgoto bail_early;\n\n\tif (left > PAGE_SIZE - 1)\n\t\tleft = PAGE_SIZE - 1;\n\n\tleft -= proc_skip_spaces(&p);\n\tif (!left) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\terr = proc_get_long(&p, &left, &lval, &neg,\n\t\t\t     proc_wspace_sep,\n\t\t\t     sizeof(proc_wspace_sep), NULL);\n\tif (err || neg) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tif (conv(&lval, tbl_data, 1, data)) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tif (!err && left)\n\t\tleft -= proc_skip_spaces(&p);\n\nout_free:\n\tif (err)\n\t\treturn -EINVAL;\n\n\treturn 0;\n\n\t/* This is in keeping with old __do_proc_dointvec() */\nbail_early:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "code_after_change": "static int do_proc_douintvec_w(unsigned int *tbl_data,\n\t\t\t       struct ctl_table *table,\n\t\t\t       void *buffer,\n\t\t\t       size_t *lenp, loff_t *ppos,\n\t\t\t       int (*conv)(unsigned long *lvalp,\n\t\t\t\t\t   unsigned int *valp,\n\t\t\t\t\t   int write, void *data),\n\t\t\t       void *data)\n{\n\tunsigned long lval;\n\tint err = 0;\n\tsize_t left;\n\tbool neg;\n\tchar *p = buffer;\n\n\tleft = *lenp;\n\n\tif (proc_first_pos_non_zero_ignore(ppos, table))\n\t\tgoto bail_early;\n\n\tif (left > PAGE_SIZE - 1)\n\t\tleft = PAGE_SIZE - 1;\n\n\tproc_skip_spaces(&p, &left);\n\tif (!left) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\terr = proc_get_long(&p, &left, &lval, &neg,\n\t\t\t     proc_wspace_sep,\n\t\t\t     sizeof(proc_wspace_sep), NULL);\n\tif (err || neg) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tif (conv(&lval, tbl_data, 1, data)) {\n\t\terr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tif (!err && left)\n\t\tproc_skip_spaces(&p, &left);\n\nout_free:\n\tif (err)\n\t\treturn -EINVAL;\n\n\treturn 0;\n\n\t/* This is in keeping with old __do_proc_dointvec() */\nbail_early:\n\t*ppos += *lenp;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,7 +21,7 @@\n \tif (left > PAGE_SIZE - 1)\n \t\tleft = PAGE_SIZE - 1;\n \n-\tleft -= proc_skip_spaces(&p);\n+\tproc_skip_spaces(&p, &left);\n \tif (!left) {\n \t\terr = -EINVAL;\n \t\tgoto out_free;\n@@ -41,7 +41,7 @@\n \t}\n \n \tif (!err && left)\n-\t\tleft -= proc_skip_spaces(&p);\n+\t\tproc_skip_spaces(&p, &left);\n \n out_free:\n \tif (err)",
        "function_modified_lines": {
            "added": [
                "\tproc_skip_spaces(&p, &left);",
                "\t\tproc_skip_spaces(&p, &left);"
            ],
            "deleted": [
                "\tleft -= proc_skip_spaces(&p);",
                "\t\tleft -= proc_skip_spaces(&p);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A stack overflow flaw was found in the Linux kernel's SYSCTL subsystem in how a user changes certain kernel parameters and variables. This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "int smb2_allocate_rsp_buf(struct ksmbd_work *work)\n{\n\tstruct smb2_hdr *hdr = smb2_get_msg(work->request_buf);\n\tsize_t small_sz = MAX_CIFS_SMALL_BUFFER_SIZE;\n\tsize_t large_sz = small_sz + work->conn->vals->max_trans_size;\n\tsize_t sz = small_sz;\n\tint cmd = le16_to_cpu(hdr->Command);\n\n\tif (cmd == SMB2_IOCTL_HE || cmd == SMB2_QUERY_DIRECTORY_HE)\n\t\tsz = large_sz;\n\n\tif (cmd == SMB2_QUERY_INFO_HE) {\n\t\tstruct smb2_query_info_req *req;\n\n\t\treq = smb2_get_msg(work->request_buf);\n\t\tif (req->InfoType == SMB2_O_INFO_FILE &&\n\t\t    (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||\n\t\t     req->FileInfoClass == FILE_ALL_INFORMATION))\n\t\t\tsz = large_sz;\n\t}\n\n\t/* allocate large response buf for chained commands */\n\tif (le32_to_cpu(hdr->NextCommand) > 0)\n\t\tsz = large_sz;\n\n\twork->response_buf = kvmalloc(sz, GFP_KERNEL | __GFP_ZERO);\n\tif (!work->response_buf)\n\t\treturn -ENOMEM;\n\n\twork->response_sz = sz;\n\treturn 0;\n}",
        "code_after_change": "int smb2_allocate_rsp_buf(struct ksmbd_work *work)\n{\n\tstruct smb2_hdr *hdr = smb2_get_msg(work->request_buf);\n\tsize_t small_sz = MAX_CIFS_SMALL_BUFFER_SIZE;\n\tsize_t large_sz = small_sz + work->conn->vals->max_trans_size;\n\tsize_t sz = small_sz;\n\tint cmd = le16_to_cpu(hdr->Command);\n\n\tif (cmd == SMB2_IOCTL_HE || cmd == SMB2_QUERY_DIRECTORY_HE)\n\t\tsz = large_sz;\n\n\tif (cmd == SMB2_QUERY_INFO_HE) {\n\t\tstruct smb2_query_info_req *req;\n\n\t\treq = smb2_get_msg(work->request_buf);\n\t\tif ((req->InfoType == SMB2_O_INFO_FILE &&\n\t\t     (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||\n\t\t     req->FileInfoClass == FILE_ALL_INFORMATION)) ||\n\t\t    req->InfoType == SMB2_O_INFO_SECURITY)\n\t\t\tsz = large_sz;\n\t}\n\n\t/* allocate large response buf for chained commands */\n\tif (le32_to_cpu(hdr->NextCommand) > 0)\n\t\tsz = large_sz;\n\n\twork->response_buf = kvmalloc(sz, GFP_KERNEL | __GFP_ZERO);\n\tif (!work->response_buf)\n\t\treturn -ENOMEM;\n\n\twork->response_sz = sz;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,9 +13,10 @@\n \t\tstruct smb2_query_info_req *req;\n \n \t\treq = smb2_get_msg(work->request_buf);\n-\t\tif (req->InfoType == SMB2_O_INFO_FILE &&\n-\t\t    (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||\n-\t\t     req->FileInfoClass == FILE_ALL_INFORMATION))\n+\t\tif ((req->InfoType == SMB2_O_INFO_FILE &&\n+\t\t     (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||\n+\t\t     req->FileInfoClass == FILE_ALL_INFORMATION)) ||\n+\t\t    req->InfoType == SMB2_O_INFO_SECURITY)\n \t\t\tsz = large_sz;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif ((req->InfoType == SMB2_O_INFO_FILE &&",
                "\t\t     (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||",
                "\t\t     req->FileInfoClass == FILE_ALL_INFORMATION)) ||",
                "\t\t    req->InfoType == SMB2_O_INFO_SECURITY)"
            ],
            "deleted": [
                "\t\tif (req->InfoType == SMB2_O_INFO_FILE &&",
                "\t\t    (req->FileInfoClass == FILE_FULL_EA_INFORMATION ||",
                "\t\t     req->FileInfoClass == FILE_ALL_INFORMATION))"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "int smb2_open(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_tree_connect *tcon = work->tcon;\n\tstruct smb2_create_req *req;\n\tstruct smb2_create_rsp *rsp;\n\tstruct path path;\n\tstruct ksmbd_share_config *share = tcon->share_conf;\n\tstruct ksmbd_file *fp = NULL;\n\tstruct file *filp = NULL;\n\tstruct user_namespace *user_ns = NULL;\n\tstruct kstat stat;\n\tstruct create_context *context;\n\tstruct lease_ctx_info *lc = NULL;\n\tstruct create_ea_buf_req *ea_buf = NULL;\n\tstruct oplock_info *opinfo;\n\t__le32 *next_ptr = NULL;\n\tint req_op_level = 0, open_flags = 0, may_flags = 0, file_info = 0;\n\tint rc = 0;\n\tint contxt_cnt = 0, query_disk_id = 0;\n\tint maximal_access_ctxt = 0, posix_ctxt = 0;\n\tint s_type = 0;\n\tint next_off = 0;\n\tchar *name = NULL;\n\tchar *stream_name = NULL;\n\tbool file_present = false, created = false, already_permitted = false;\n\tint share_ret, need_truncate = 0;\n\tu64 time;\n\tumode_t posix_mode = 0;\n\t__le32 daccess, maximal_access = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (req->hdr.NextCommand && !work->next_smb2_rcv_hdr_off &&\n\t    (req->hdr.Flags & SMB2_FLAGS_RELATED_OPERATIONS)) {\n\t\tksmbd_debug(SMB, \"invalid flag in chained command\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\tsmb2_set_err_rsp(work);\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_share_config_flag(share, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe create request\\n\");\n\t\treturn create_smb2_pipe(work);\n\t}\n\n\tif (req->NameLength) {\n\t\tif ((req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t\t    *(char *)req->Buffer == '\\\\') {\n\t\t\tpr_err(\"not allow directory name included leading slash\\n\");\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tname = smb2_get_name(req->Buffer,\n\t\t\t\t     le16_to_cpu(req->NameLength),\n\t\t\t\t     work->conn->local_nls);\n\t\tif (IS_ERR(name)) {\n\t\t\trc = PTR_ERR(name);\n\t\t\tif (rc != -ENOMEM)\n\t\t\t\trc = -ENOENT;\n\t\t\tname = NULL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tksmbd_debug(SMB, \"converted name = %s\\n\", name);\n\t\tif (strchr(name, ':')) {\n\t\t\tif (!test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t    KSMBD_SHARE_FLAG_STREAMS)) {\n\t\t\t\trc = -EBADF;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\trc = parse_stream_name(name, &stream_name, &s_type);\n\t\t\tif (rc < 0)\n\t\t\t\tgoto err_out1;\n\t\t}\n\n\t\trc = ksmbd_validate_filename(name);\n\t\tif (rc < 0)\n\t\t\tgoto err_out1;\n\n\t\tif (ksmbd_share_veto_filename(share, name)) {\n\t\t\trc = -ENOENT;\n\t\t\tksmbd_debug(SMB, \"Reject open(), vetoed file: %s\\n\",\n\t\t\t\t    name);\n\t\t\tgoto err_out1;\n\t\t}\n\t} else {\n\t\tname = kstrdup(\"\", GFP_KERNEL);\n\t\tif (!name) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_out1;\n\t\t}\n\t}\n\n\treq_op_level = req->RequestedOplockLevel;\n\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE)\n\t\tlc = parse_lease_state(req);\n\n\tif (le32_to_cpu(req->ImpersonationLevel) > le32_to_cpu(IL_DELEGATE)) {\n\t\tpr_err(\"Invalid impersonationlevel : 0x%x\\n\",\n\t\t       le32_to_cpu(req->ImpersonationLevel));\n\t\trc = -EIO;\n\t\trsp->hdr.Status = STATUS_BAD_IMPERSONATION_LEVEL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateOptions && !(req->CreateOptions & CREATE_OPTIONS_MASK_LE)) {\n\t\tpr_err(\"Invalid create options : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateOptions));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t} else {\n\t\tif (req->CreateOptions & FILE_SEQUENTIAL_ONLY_LE &&\n\t\t    req->CreateOptions & FILE_RANDOM_ACCESS_LE)\n\t\t\treq->CreateOptions = ~(FILE_SEQUENTIAL_ONLY_LE);\n\n\t\tif (req->CreateOptions &\n\t\t    (FILE_OPEN_BY_FILE_ID_LE | CREATE_TREE_CONNECTION |\n\t\t     FILE_RESERVE_OPFILTER_LE)) {\n\t\t\trc = -EOPNOTSUPP;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (req->CreateOptions & FILE_NO_COMPRESSION_LE) {\n\t\t\t\treq->CreateOptions = ~(FILE_NO_COMPRESSION_LE);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (le32_to_cpu(req->CreateDisposition) >\n\t    le32_to_cpu(FILE_OVERWRITE_IF_LE)) {\n\t\tpr_err(\"Invalid create disposition : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateDisposition));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (!(req->DesiredAccess & DESIRED_ACCESS_MASK)) {\n\t\tpr_err(\"Invalid desired access : 0x%x\\n\",\n\t\t       le32_to_cpu(req->DesiredAccess));\n\t\trc = -EACCES;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->FileAttributes && !(req->FileAttributes & FILE_ATTRIBUTE_MASK_LE)) {\n\t\tpr_err(\"Invalid file attribute : 0x%x\\n\",\n\t\t       le32_to_cpu(req->FileAttributes));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\t/* Parse non-durable handle create contexts */\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tea_buf = (struct create_ea_buf_req *)context;\n\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t    sizeof(struct create_ea_buf_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\tif (req->CreateOptions & FILE_NO_EA_KNOWLEDGE_LE) {\n\t\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"get query maximal access context\\n\");\n\t\t\tmaximal_access_ctxt = 1;\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get timewarp context\\n\");\n\t\t\trc = -EBADF;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (tcon->posix_extensions) {\n\t\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX);\n\t\t\tif (IS_ERR(context)) {\n\t\t\t\trc = PTR_ERR(context);\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (context) {\n\t\t\t\tstruct create_posix *posix =\n\t\t\t\t\t(struct create_posix *)context;\n\t\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t\t    sizeof(struct create_posix) - 4) {\n\t\t\t\t\trc = -EINVAL;\n\t\t\t\t\tgoto err_out1;\n\t\t\t\t}\n\t\t\t\tksmbd_debug(SMB, \"get posix context\\n\");\n\n\t\t\t\tposix_mode = le32_to_cpu(posix->Mode);\n\t\t\t\tposix_ctxt = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ksmbd_override_fsids(work)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out1;\n\t}\n\n\trc = ksmbd_vfs_kern_path(work, name, LOOKUP_NO_SYMLINKS, &path, 1);\n\tif (!rc) {\n\t\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE) {\n\t\t\t/*\n\t\t\t * If file exists with under flags, return access\n\t\t\t * denied error.\n\t\t\t */\n\t\t\tif (req->CreateDisposition == FILE_OVERWRITE_IF_LE ||\n\t\t\t    req->CreateDisposition == FILE_OPEN_IF_LE) {\n\t\t\t\trc = -EACCES;\n\t\t\t\tpath_put(&path);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\t\trc = -EACCES;\n\t\t\t\tpath_put(&path);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t} else if (d_is_symlink(path.dentry)) {\n\t\t\trc = -EACCES;\n\t\t\tpath_put(&path);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tif (rc) {\n\t\tif (rc != -ENOENT)\n\t\t\tgoto err_out;\n\t\tksmbd_debug(SMB, \"can not get linux path for %s, rc = %d\\n\",\n\t\t\t    name, rc);\n\t\trc = 0;\n\t} else {\n\t\tfile_present = true;\n\t\tuser_ns = mnt_user_ns(path.mnt);\n\t\tgeneric_fillattr(user_ns, d_inode(path.dentry), &stat);\n\t}\n\tif (stream_name) {\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\t}\n\t\t} else {\n\t\t\tif (S_ISDIR(stat.mode) && s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\t\t}\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE &&\n\t\t    req->FileAttributes & FILE_ATTRIBUTE_NORMAL_LE) {\n\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\trc = -EIO;\n\t\t}\n\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (file_present && req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE &&\n\t    S_ISDIR(stat.mode) && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\tksmbd_debug(SMB, \"open() argument is a directory: %s, %x\\n\",\n\t\t\t    name, req->CreateOptions);\n\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (file_present && (req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t    !(req->CreateDisposition == FILE_CREATE_LE) &&\n\t    !S_ISDIR(stat.mode)) {\n\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (!stream_name && file_present &&\n\t    req->CreateDisposition == FILE_CREATE_LE) {\n\t\trc = -EEXIST;\n\t\tgoto err_out;\n\t}\n\n\tdaccess = smb_map_generic_desired_access(req->DesiredAccess);\n\n\tif (file_present && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\trc = smb_check_perm_dacl(conn, &path, &daccess,\n\t\t\t\t\t sess->user->uid);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (daccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tif (!file_present) {\n\t\t\tdaccess = cpu_to_le32(GENERIC_ALL_FLAGS);\n\t\t} else {\n\t\t\trc = ksmbd_vfs_query_maximal_access(user_ns,\n\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t    &daccess);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\talready_permitted = true;\n\t\t}\n\t\tmaximal_access = daccess;\n\t}\n\n\topen_flags = smb2_create_open_flags(file_present, daccess,\n\t\t\t\t\t    req->CreateDisposition,\n\t\t\t\t\t    &may_flags);\n\n\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tif (open_flags & O_CREAT) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t/*create file if not present */\n\tif (!file_present) {\n\t\trc = smb2_creat(work, &path, name, open_flags, posix_mode,\n\t\t\t\treq->CreateOptions & FILE_DIRECTORY_FILE_LE);\n\t\tif (rc) {\n\t\t\tif (rc == -ENOENT) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_OBJECT_PATH_NOT_FOUND;\n\t\t\t}\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tcreated = true;\n\t\tuser_ns = mnt_user_ns(path.mnt);\n\t\tif (ea_buf) {\n\t\t\tif (le32_to_cpu(ea_buf->ccontext.DataLength) <\n\t\t\t    sizeof(struct smb2_ea_info)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\trc = smb2_set_ea(&ea_buf->ea,\n\t\t\t\t\t le32_to_cpu(ea_buf->ccontext.DataLength),\n\t\t\t\t\t &path);\n\t\t\tif (rc == -EOPNOTSUPP)\n\t\t\t\trc = 0;\n\t\t\telse if (rc)\n\t\t\t\tgoto err_out;\n\t\t}\n\t} else if (!already_permitted) {\n\t\t/* FILE_READ_ATTRIBUTE is allowed without inode_permission,\n\t\t * because execute(search) permission on a parent directory,\n\t\t * is already granted.\n\t\t */\n\t\tif (daccess & ~(FILE_READ_ATTRIBUTES_LE | FILE_READ_CONTROL_LE)) {\n\t\t\trc = inode_permission(user_ns,\n\t\t\t\t\t      d_inode(path.dentry),\n\t\t\t\t\t      may_flags);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\n\t\t\tif ((daccess & FILE_DELETE_LE) ||\n\t\t\t    (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\t\t\trc = ksmbd_vfs_may_delete(user_ns,\n\t\t\t\t\t\t\t  path.dentry);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\t}\n\n\trc = ksmbd_query_inode_status(d_inode(path.dentry->d_parent));\n\tif (rc == KSMBD_INODE_STATUS_PENDING_DELETE) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\trc = 0;\n\tfilp = dentry_open(&path, open_flags, current_cred());\n\tif (IS_ERR(filp)) {\n\t\trc = PTR_ERR(filp);\n\t\tpr_err(\"dentry open for dir failed, rc %d\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\tif (file_present) {\n\t\tif (!(open_flags & O_TRUNC))\n\t\t\tfile_info = FILE_OPENED;\n\t\telse\n\t\t\tfile_info = FILE_OVERWRITTEN;\n\n\t\tif ((req->CreateDisposition & FILE_CREATE_MASK_LE) ==\n\t\t    FILE_SUPERSEDE_LE)\n\t\t\tfile_info = FILE_SUPERSEDED;\n\t} else if (open_flags & O_CREAT) {\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tksmbd_vfs_set_fadvise(filp, req->CreateOptions);\n\n\t/* Obtain Volatile-ID */\n\tfp = ksmbd_open_fd(work, filp);\n\tif (IS_ERR(fp)) {\n\t\tfput(filp);\n\t\trc = PTR_ERR(fp);\n\t\tfp = NULL;\n\t\tgoto err_out;\n\t}\n\n\t/* Get Persistent-ID */\n\tksmbd_open_durable_fd(fp);\n\tif (!has_file_id(fp->persistent_id)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tfp->cdoption = req->CreateDisposition;\n\tfp->daccess = daccess;\n\tfp->saccess = req->ShareAccess;\n\tfp->coption = req->CreateOptions;\n\n\t/* Set default windows and posix acls if creating new file */\n\tif (created) {\n\t\tint posix_acl_rc;\n\t\tstruct inode *inode = d_inode(path.dentry);\n\n\t\tposix_acl_rc = ksmbd_vfs_inherit_posix_acl(user_ns,\n\t\t\t\t\t\t\t   inode,\n\t\t\t\t\t\t\t   d_inode(path.dentry->d_parent));\n\t\tif (posix_acl_rc)\n\t\t\tksmbd_debug(SMB, \"inherit posix acl failed : %d\\n\", posix_acl_rc);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\trc = smb_inherit_dacl(conn, &path, sess->user->uid,\n\t\t\t\t\t      sess->user->gid);\n\t\t}\n\n\t\tif (rc) {\n\t\t\trc = smb2_create_sd_buffer(work, req, &path);\n\t\t\tif (rc) {\n\t\t\t\tif (posix_acl_rc)\n\t\t\t\t\tksmbd_vfs_set_init_posix_acl(user_ns,\n\t\t\t\t\t\t\t\t     inode);\n\n\t\t\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\t\t\tstruct smb_fattr fattr;\n\t\t\t\t\tstruct smb_ntsd *pntsd;\n\t\t\t\t\tint pntsd_size, ace_num = 0;\n\n\t\t\t\t\tksmbd_acls_fattr(&fattr, user_ns, inode);\n\t\t\t\t\tif (fattr.cf_acls)\n\t\t\t\t\t\tace_num = fattr.cf_acls->a_count;\n\t\t\t\t\tif (fattr.cf_dacls)\n\t\t\t\t\t\tace_num += fattr.cf_dacls->a_count;\n\n\t\t\t\t\tpntsd = kmalloc(sizeof(struct smb_ntsd) +\n\t\t\t\t\t\t\tsizeof(struct smb_sid) * 3 +\n\t\t\t\t\t\t\tsizeof(struct smb_acl) +\n\t\t\t\t\t\t\tsizeof(struct smb_ace) * ace_num * 2,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\t\tif (!pntsd)\n\t\t\t\t\t\tgoto err_out;\n\n\t\t\t\t\trc = build_sec_desc(user_ns,\n\t\t\t\t\t\t\t    pntsd, NULL,\n\t\t\t\t\t\t\t    OWNER_SECINFO |\n\t\t\t\t\t\t\t    GROUP_SECINFO |\n\t\t\t\t\t\t\t    DACL_SECINFO,\n\t\t\t\t\t\t\t    &pntsd_size, &fattr);\n\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\tif (rc) {\n\t\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = ksmbd_vfs_set_sd_xattr(conn,\n\t\t\t\t\t\t\t\t    user_ns,\n\t\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t\t    pntsd,\n\t\t\t\t\t\t\t\t    pntsd_size);\n\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\tif (rc)\n\t\t\t\t\t\tpr_err(\"failed to store ntacl in xattr : %d\\n\",\n\t\t\t\t\t\t       rc);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\trc = smb2_set_stream_name_xattr(&path,\n\t\t\t\t\t\tfp,\n\t\t\t\t\t\tstream_name,\n\t\t\t\t\t\ts_type);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tfp->attrib_only = !(req->DesiredAccess & ~(FILE_READ_ATTRIBUTES_LE |\n\t\t\tFILE_WRITE_ATTRIBUTES_LE | FILE_SYNCHRONIZE_LE));\n\tif (!S_ISDIR(file_inode(filp)->i_mode) && open_flags & O_TRUNC &&\n\t    !fp->attrib_only && !stream_name) {\n\t\tsmb_break_all_oplock(work, fp);\n\t\tneed_truncate = 1;\n\t}\n\n\t/* fp should be searchable through ksmbd_inode.m_fp_list\n\t * after daccess, saccess, attrib_only, and stream are\n\t * initialized.\n\t */\n\twrite_lock(&fp->f_ci->m_lock);\n\tlist_add(&fp->node, &fp->f_ci->m_fp_list);\n\twrite_unlock(&fp->f_ci->m_lock);\n\n\trc = ksmbd_vfs_getattr(&path, &stat);\n\tif (rc) {\n\t\tgeneric_fillattr(user_ns, d_inode(path.dentry), &stat);\n\t\trc = 0;\n\t}\n\n\t/* Check delete pending among previous fp before oplock break */\n\tif (ksmbd_inode_pending_delete(fp)) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\tshare_ret = ksmbd_smb_check_shared_mode(fp->filp, fp);\n\tif (!test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_OPLOCKS) ||\n\t    (req_op_level == SMB2_OPLOCK_LEVEL_LEASE &&\n\t     !(conn->vals->capabilities & SMB2_GLOBAL_CAP_LEASING))) {\n\t\tif (share_ret < 0 && !S_ISDIR(file_inode(fp->filp)->i_mode)) {\n\t\t\trc = share_ret;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE) {\n\t\t\treq_op_level = smb2_map_lease_to_oplock(lc->req_state);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"lease req for(%s) req oplock state 0x%x, lease state 0x%x\\n\",\n\t\t\t\t    name, req_op_level, lc->req_state);\n\t\t\trc = find_same_lease_key(sess, fp->f_ci, lc);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t} else if (open_flags == O_RDONLY &&\n\t\t\t   (req_op_level == SMB2_OPLOCK_LEVEL_BATCH ||\n\t\t\t    req_op_level == SMB2_OPLOCK_LEVEL_EXCLUSIVE))\n\t\t\treq_op_level = SMB2_OPLOCK_LEVEL_II;\n\n\t\trc = smb_grant_oplock(work, req_op_level,\n\t\t\t\t      fp->persistent_id, fp,\n\t\t\t\t      le32_to_cpu(req->hdr.Id.SyncId.TreeId),\n\t\t\t\t      lc, share_ret);\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)\n\t\tksmbd_fd_set_delete_on_close(fp, file_info);\n\n\tif (need_truncate) {\n\t\trc = smb2_create_truncate(&path);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\tstruct create_alloc_size_req *az_req;\n\n\t\taz_req = (struct create_alloc_size_req *)smb2_find_context_vals(req,\n\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE);\n\t\tif (IS_ERR(az_req)) {\n\t\t\trc = PTR_ERR(az_req);\n\t\t\tgoto err_out;\n\t\t} else if (az_req) {\n\t\t\tloff_t alloc_size;\n\t\t\tint err;\n\n\t\t\tif (le16_to_cpu(az_req->ccontext.DataOffset) +\n\t\t\t    le32_to_cpu(az_req->ccontext.DataLength) <\n\t\t\t    sizeof(struct create_alloc_size_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\talloc_size = le64_to_cpu(az_req->AllocationSize);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"request smb2 create allocate size : %llu\\n\",\n\t\t\t\t    alloc_size);\n\t\t\tsmb_break_all_levII_oplock(work, fp, 1);\n\t\t\terr = vfs_fallocate(fp->filp, FALLOC_FL_KEEP_SIZE, 0,\n\t\t\t\t\t    alloc_size);\n\t\t\tif (err < 0)\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"vfs_fallocate is failed : %d\\n\",\n\t\t\t\t\t    err);\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get query on disk id context\\n\");\n\t\t\tquery_disk_id = 1;\n\t\t}\n\t}\n\n\tif (stat.result_mask & STATX_BTIME)\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.btime);\n\telse\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.ctime);\n\tif (req->FileAttributes || fp->f_ci->m_fattr == 0)\n\t\tfp->f_ci->m_fattr =\n\t\t\tcpu_to_le32(smb2_get_dos_mode(&stat, le32_to_cpu(req->FileAttributes)));\n\n\tif (!created)\n\t\tsmb2_update_xattrs(tcon, &path, fp);\n\telse\n\t\tsmb2_new_xattrs(tcon, &path, fp);\n\n\tmemcpy(fp->client_guid, conn->ClientGUID, SMB2_CLIENT_GUID_SIZE);\n\n\tgeneric_fillattr(user_ns, file_inode(fp->filp),\n\t\t\t &stat);\n\n\trsp->StructureSize = cpu_to_le16(89);\n\trcu_read_lock();\n\topinfo = rcu_dereference(fp->f_opinfo);\n\trsp->OplockLevel = opinfo != NULL ? opinfo->level : 0;\n\trcu_read_unlock();\n\trsp->Flags = 0;\n\trsp->CreateAction = cpu_to_le32(file_info);\n\trsp->CreationTime = cpu_to_le64(fp->create_time);\n\ttime = ksmbd_UnixTimeToNT(stat.atime);\n\trsp->LastAccessTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.mtime);\n\trsp->LastWriteTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.ctime);\n\trsp->ChangeTime = cpu_to_le64(time);\n\trsp->AllocationSize = S_ISDIR(stat.mode) ? 0 :\n\t\tcpu_to_le64(stat.blocks << 9);\n\trsp->EndofFile = S_ISDIR(stat.mode) ? 0 : cpu_to_le64(stat.size);\n\trsp->FileAttributes = fp->f_ci->m_fattr;\n\n\trsp->Reserved2 = 0;\n\n\trsp->PersistentFileId = fp->persistent_id;\n\trsp->VolatileFileId = fp->volatile_id;\n\n\trsp->CreateContextsOffset = 0;\n\trsp->CreateContextsLength = 0;\n\tinc_rfc1001_len(work->response_buf, 88); /* StructureSize - 1*/\n\n\t/* If lease is request send lease context response */\n\tif (opinfo && opinfo->is_lease) {\n\t\tstruct create_context *lease_ccontext;\n\n\t\tksmbd_debug(SMB, \"lease granted on(%s) lease state 0x%x\\n\",\n\t\t\t    name, opinfo->o_lease->state);\n\t\trsp->OplockLevel = SMB2_OPLOCK_LEVEL_LEASE;\n\n\t\tlease_ccontext = (struct create_context *)rsp->Buffer;\n\t\tcontxt_cnt++;\n\t\tcreate_lease_buf(rsp->Buffer, opinfo->o_lease);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_lease_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_lease_size);\n\t\tnext_ptr = &lease_ccontext->Next;\n\t\tnext_off = conn->vals->create_lease_size;\n\t}\n\n\tif (maximal_access_ctxt) {\n\t\tstruct create_context *mxac_ccontext;\n\n\t\tif (maximal_access == 0)\n\t\t\tksmbd_vfs_query_maximal_access(user_ns,\n\t\t\t\t\t\t       path.dentry,\n\t\t\t\t\t\t       &maximal_access);\n\t\tmxac_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_mxac_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tle32_to_cpu(maximal_access));\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_mxac_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_mxac_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &mxac_ccontext->Next;\n\t\tnext_off = conn->vals->create_mxac_size;\n\t}\n\n\tif (query_disk_id) {\n\t\tstruct create_context *disk_id_ccontext;\n\n\t\tdisk_id_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_disk_id_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tstat.ino, tcon->id);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_disk_id_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_disk_id_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &disk_id_ccontext->Next;\n\t\tnext_off = conn->vals->create_disk_id_size;\n\t}\n\n\tif (posix_ctxt) {\n\t\tcontxt_cnt++;\n\t\tcreate_posix_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tfp);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_posix_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_posix_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t}\n\n\tif (contxt_cnt > 0) {\n\t\trsp->CreateContextsOffset =\n\t\t\tcpu_to_le32(offsetof(struct smb2_create_rsp, Buffer));\n\t}\n\nerr_out:\n\tif (file_present || created)\n\t\tpath_put(&path);\n\tksmbd_revert_fsids(work);\nerr_out1:\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\telse if (rc == -EOPNOTSUPP)\n\t\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\telse if (rc == -EACCES || rc == -ESTALE || rc == -EXDEV)\n\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\telse if (rc == -ENOENT)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_INVALID;\n\t\telse if (rc == -EPERM)\n\t\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\t\telse if (rc == -EBUSY)\n\t\t\trsp->hdr.Status = STATUS_DELETE_PENDING;\n\t\telse if (rc == -EBADF)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_NOT_FOUND;\n\t\telse if (rc == -ENOEXEC)\n\t\t\trsp->hdr.Status = STATUS_DUPLICATE_OBJECTID;\n\t\telse if (rc == -ENXIO)\n\t\t\trsp->hdr.Status = STATUS_NO_SUCH_DEVICE;\n\t\telse if (rc == -EEXIST)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_COLLISION;\n\t\telse if (rc == -EMFILE)\n\t\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\t\tif (!rsp->hdr.Status)\n\t\t\trsp->hdr.Status = STATUS_UNEXPECTED_IO_ERROR;\n\n\t\tif (fp)\n\t\t\tksmbd_fd_put(work, fp);\n\t\tsmb2_set_err_rsp(work);\n\t\tksmbd_debug(SMB, \"Error response: %x\\n\", rsp->hdr.Status);\n\t}\n\n\tkfree(name);\n\tkfree(lc);\n\n\treturn 0;\n}",
        "code_after_change": "int smb2_open(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_tree_connect *tcon = work->tcon;\n\tstruct smb2_create_req *req;\n\tstruct smb2_create_rsp *rsp;\n\tstruct path path;\n\tstruct ksmbd_share_config *share = tcon->share_conf;\n\tstruct ksmbd_file *fp = NULL;\n\tstruct file *filp = NULL;\n\tstruct user_namespace *user_ns = NULL;\n\tstruct kstat stat;\n\tstruct create_context *context;\n\tstruct lease_ctx_info *lc = NULL;\n\tstruct create_ea_buf_req *ea_buf = NULL;\n\tstruct oplock_info *opinfo;\n\t__le32 *next_ptr = NULL;\n\tint req_op_level = 0, open_flags = 0, may_flags = 0, file_info = 0;\n\tint rc = 0;\n\tint contxt_cnt = 0, query_disk_id = 0;\n\tint maximal_access_ctxt = 0, posix_ctxt = 0;\n\tint s_type = 0;\n\tint next_off = 0;\n\tchar *name = NULL;\n\tchar *stream_name = NULL;\n\tbool file_present = false, created = false, already_permitted = false;\n\tint share_ret, need_truncate = 0;\n\tu64 time;\n\tumode_t posix_mode = 0;\n\t__le32 daccess, maximal_access = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (req->hdr.NextCommand && !work->next_smb2_rcv_hdr_off &&\n\t    (req->hdr.Flags & SMB2_FLAGS_RELATED_OPERATIONS)) {\n\t\tksmbd_debug(SMB, \"invalid flag in chained command\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\tsmb2_set_err_rsp(work);\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_share_config_flag(share, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe create request\\n\");\n\t\treturn create_smb2_pipe(work);\n\t}\n\n\tif (req->NameLength) {\n\t\tif ((req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t\t    *(char *)req->Buffer == '\\\\') {\n\t\t\tpr_err(\"not allow directory name included leading slash\\n\");\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tname = smb2_get_name(req->Buffer,\n\t\t\t\t     le16_to_cpu(req->NameLength),\n\t\t\t\t     work->conn->local_nls);\n\t\tif (IS_ERR(name)) {\n\t\t\trc = PTR_ERR(name);\n\t\t\tif (rc != -ENOMEM)\n\t\t\t\trc = -ENOENT;\n\t\t\tname = NULL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tksmbd_debug(SMB, \"converted name = %s\\n\", name);\n\t\tif (strchr(name, ':')) {\n\t\t\tif (!test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t    KSMBD_SHARE_FLAG_STREAMS)) {\n\t\t\t\trc = -EBADF;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\trc = parse_stream_name(name, &stream_name, &s_type);\n\t\t\tif (rc < 0)\n\t\t\t\tgoto err_out1;\n\t\t}\n\n\t\trc = ksmbd_validate_filename(name);\n\t\tif (rc < 0)\n\t\t\tgoto err_out1;\n\n\t\tif (ksmbd_share_veto_filename(share, name)) {\n\t\t\trc = -ENOENT;\n\t\t\tksmbd_debug(SMB, \"Reject open(), vetoed file: %s\\n\",\n\t\t\t\t    name);\n\t\t\tgoto err_out1;\n\t\t}\n\t} else {\n\t\tname = kstrdup(\"\", GFP_KERNEL);\n\t\tif (!name) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_out1;\n\t\t}\n\t}\n\n\treq_op_level = req->RequestedOplockLevel;\n\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE)\n\t\tlc = parse_lease_state(req);\n\n\tif (le32_to_cpu(req->ImpersonationLevel) > le32_to_cpu(IL_DELEGATE)) {\n\t\tpr_err(\"Invalid impersonationlevel : 0x%x\\n\",\n\t\t       le32_to_cpu(req->ImpersonationLevel));\n\t\trc = -EIO;\n\t\trsp->hdr.Status = STATUS_BAD_IMPERSONATION_LEVEL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateOptions && !(req->CreateOptions & CREATE_OPTIONS_MASK_LE)) {\n\t\tpr_err(\"Invalid create options : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateOptions));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t} else {\n\t\tif (req->CreateOptions & FILE_SEQUENTIAL_ONLY_LE &&\n\t\t    req->CreateOptions & FILE_RANDOM_ACCESS_LE)\n\t\t\treq->CreateOptions = ~(FILE_SEQUENTIAL_ONLY_LE);\n\n\t\tif (req->CreateOptions &\n\t\t    (FILE_OPEN_BY_FILE_ID_LE | CREATE_TREE_CONNECTION |\n\t\t     FILE_RESERVE_OPFILTER_LE)) {\n\t\t\trc = -EOPNOTSUPP;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (req->CreateOptions & FILE_NO_COMPRESSION_LE) {\n\t\t\t\treq->CreateOptions = ~(FILE_NO_COMPRESSION_LE);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (le32_to_cpu(req->CreateDisposition) >\n\t    le32_to_cpu(FILE_OVERWRITE_IF_LE)) {\n\t\tpr_err(\"Invalid create disposition : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateDisposition));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (!(req->DesiredAccess & DESIRED_ACCESS_MASK)) {\n\t\tpr_err(\"Invalid desired access : 0x%x\\n\",\n\t\t       le32_to_cpu(req->DesiredAccess));\n\t\trc = -EACCES;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->FileAttributes && !(req->FileAttributes & FILE_ATTRIBUTE_MASK_LE)) {\n\t\tpr_err(\"Invalid file attribute : 0x%x\\n\",\n\t\t       le32_to_cpu(req->FileAttributes));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\t/* Parse non-durable handle create contexts */\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tea_buf = (struct create_ea_buf_req *)context;\n\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t    sizeof(struct create_ea_buf_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\tif (req->CreateOptions & FILE_NO_EA_KNOWLEDGE_LE) {\n\t\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"get query maximal access context\\n\");\n\t\t\tmaximal_access_ctxt = 1;\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get timewarp context\\n\");\n\t\t\trc = -EBADF;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (tcon->posix_extensions) {\n\t\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX);\n\t\t\tif (IS_ERR(context)) {\n\t\t\t\trc = PTR_ERR(context);\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (context) {\n\t\t\t\tstruct create_posix *posix =\n\t\t\t\t\t(struct create_posix *)context;\n\t\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t\t    sizeof(struct create_posix) - 4) {\n\t\t\t\t\trc = -EINVAL;\n\t\t\t\t\tgoto err_out1;\n\t\t\t\t}\n\t\t\t\tksmbd_debug(SMB, \"get posix context\\n\");\n\n\t\t\t\tposix_mode = le32_to_cpu(posix->Mode);\n\t\t\t\tposix_ctxt = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ksmbd_override_fsids(work)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out1;\n\t}\n\n\trc = ksmbd_vfs_kern_path(work, name, LOOKUP_NO_SYMLINKS, &path, 1);\n\tif (!rc) {\n\t\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE) {\n\t\t\t/*\n\t\t\t * If file exists with under flags, return access\n\t\t\t * denied error.\n\t\t\t */\n\t\t\tif (req->CreateDisposition == FILE_OVERWRITE_IF_LE ||\n\t\t\t    req->CreateDisposition == FILE_OPEN_IF_LE) {\n\t\t\t\trc = -EACCES;\n\t\t\t\tpath_put(&path);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\t\trc = -EACCES;\n\t\t\t\tpath_put(&path);\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t} else if (d_is_symlink(path.dentry)) {\n\t\t\trc = -EACCES;\n\t\t\tpath_put(&path);\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tif (rc) {\n\t\tif (rc != -ENOENT)\n\t\t\tgoto err_out;\n\t\tksmbd_debug(SMB, \"can not get linux path for %s, rc = %d\\n\",\n\t\t\t    name, rc);\n\t\trc = 0;\n\t} else {\n\t\tfile_present = true;\n\t\tuser_ns = mnt_user_ns(path.mnt);\n\t\tgeneric_fillattr(user_ns, d_inode(path.dentry), &stat);\n\t}\n\tif (stream_name) {\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\t}\n\t\t} else {\n\t\t\tif (S_ISDIR(stat.mode) && s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\t\t}\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE &&\n\t\t    req->FileAttributes & FILE_ATTRIBUTE_NORMAL_LE) {\n\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\trc = -EIO;\n\t\t}\n\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (file_present && req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE &&\n\t    S_ISDIR(stat.mode) && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\tksmbd_debug(SMB, \"open() argument is a directory: %s, %x\\n\",\n\t\t\t    name, req->CreateOptions);\n\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (file_present && (req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t    !(req->CreateDisposition == FILE_CREATE_LE) &&\n\t    !S_ISDIR(stat.mode)) {\n\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (!stream_name && file_present &&\n\t    req->CreateDisposition == FILE_CREATE_LE) {\n\t\trc = -EEXIST;\n\t\tgoto err_out;\n\t}\n\n\tdaccess = smb_map_generic_desired_access(req->DesiredAccess);\n\n\tif (file_present && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\trc = smb_check_perm_dacl(conn, &path, &daccess,\n\t\t\t\t\t sess->user->uid);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (daccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tif (!file_present) {\n\t\t\tdaccess = cpu_to_le32(GENERIC_ALL_FLAGS);\n\t\t} else {\n\t\t\trc = ksmbd_vfs_query_maximal_access(user_ns,\n\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t    &daccess);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\talready_permitted = true;\n\t\t}\n\t\tmaximal_access = daccess;\n\t}\n\n\topen_flags = smb2_create_open_flags(file_present, daccess,\n\t\t\t\t\t    req->CreateDisposition,\n\t\t\t\t\t    &may_flags);\n\n\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tif (open_flags & O_CREAT) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t/*create file if not present */\n\tif (!file_present) {\n\t\trc = smb2_creat(work, &path, name, open_flags, posix_mode,\n\t\t\t\treq->CreateOptions & FILE_DIRECTORY_FILE_LE);\n\t\tif (rc) {\n\t\t\tif (rc == -ENOENT) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_OBJECT_PATH_NOT_FOUND;\n\t\t\t}\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tcreated = true;\n\t\tuser_ns = mnt_user_ns(path.mnt);\n\t\tif (ea_buf) {\n\t\t\tif (le32_to_cpu(ea_buf->ccontext.DataLength) <\n\t\t\t    sizeof(struct smb2_ea_info)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\trc = smb2_set_ea(&ea_buf->ea,\n\t\t\t\t\t le32_to_cpu(ea_buf->ccontext.DataLength),\n\t\t\t\t\t &path);\n\t\t\tif (rc == -EOPNOTSUPP)\n\t\t\t\trc = 0;\n\t\t\telse if (rc)\n\t\t\t\tgoto err_out;\n\t\t}\n\t} else if (!already_permitted) {\n\t\t/* FILE_READ_ATTRIBUTE is allowed without inode_permission,\n\t\t * because execute(search) permission on a parent directory,\n\t\t * is already granted.\n\t\t */\n\t\tif (daccess & ~(FILE_READ_ATTRIBUTES_LE | FILE_READ_CONTROL_LE)) {\n\t\t\trc = inode_permission(user_ns,\n\t\t\t\t\t      d_inode(path.dentry),\n\t\t\t\t\t      may_flags);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\n\t\t\tif ((daccess & FILE_DELETE_LE) ||\n\t\t\t    (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\t\t\trc = ksmbd_vfs_may_delete(user_ns,\n\t\t\t\t\t\t\t  path.dentry);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\t}\n\n\trc = ksmbd_query_inode_status(d_inode(path.dentry->d_parent));\n\tif (rc == KSMBD_INODE_STATUS_PENDING_DELETE) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\trc = 0;\n\tfilp = dentry_open(&path, open_flags, current_cred());\n\tif (IS_ERR(filp)) {\n\t\trc = PTR_ERR(filp);\n\t\tpr_err(\"dentry open for dir failed, rc %d\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\tif (file_present) {\n\t\tif (!(open_flags & O_TRUNC))\n\t\t\tfile_info = FILE_OPENED;\n\t\telse\n\t\t\tfile_info = FILE_OVERWRITTEN;\n\n\t\tif ((req->CreateDisposition & FILE_CREATE_MASK_LE) ==\n\t\t    FILE_SUPERSEDE_LE)\n\t\t\tfile_info = FILE_SUPERSEDED;\n\t} else if (open_flags & O_CREAT) {\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tksmbd_vfs_set_fadvise(filp, req->CreateOptions);\n\n\t/* Obtain Volatile-ID */\n\tfp = ksmbd_open_fd(work, filp);\n\tif (IS_ERR(fp)) {\n\t\tfput(filp);\n\t\trc = PTR_ERR(fp);\n\t\tfp = NULL;\n\t\tgoto err_out;\n\t}\n\n\t/* Get Persistent-ID */\n\tksmbd_open_durable_fd(fp);\n\tif (!has_file_id(fp->persistent_id)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tfp->cdoption = req->CreateDisposition;\n\tfp->daccess = daccess;\n\tfp->saccess = req->ShareAccess;\n\tfp->coption = req->CreateOptions;\n\n\t/* Set default windows and posix acls if creating new file */\n\tif (created) {\n\t\tint posix_acl_rc;\n\t\tstruct inode *inode = d_inode(path.dentry);\n\n\t\tposix_acl_rc = ksmbd_vfs_inherit_posix_acl(user_ns,\n\t\t\t\t\t\t\t   inode,\n\t\t\t\t\t\t\t   d_inode(path.dentry->d_parent));\n\t\tif (posix_acl_rc)\n\t\t\tksmbd_debug(SMB, \"inherit posix acl failed : %d\\n\", posix_acl_rc);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\trc = smb_inherit_dacl(conn, &path, sess->user->uid,\n\t\t\t\t\t      sess->user->gid);\n\t\t}\n\n\t\tif (rc) {\n\t\t\trc = smb2_create_sd_buffer(work, req, &path);\n\t\t\tif (rc) {\n\t\t\t\tif (posix_acl_rc)\n\t\t\t\t\tksmbd_vfs_set_init_posix_acl(user_ns,\n\t\t\t\t\t\t\t\t     inode);\n\n\t\t\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\t\t\tstruct smb_fattr fattr;\n\t\t\t\t\tstruct smb_ntsd *pntsd;\n\t\t\t\t\tint pntsd_size, ace_num = 0;\n\n\t\t\t\t\tksmbd_acls_fattr(&fattr, user_ns, inode);\n\t\t\t\t\tif (fattr.cf_acls)\n\t\t\t\t\t\tace_num = fattr.cf_acls->a_count;\n\t\t\t\t\tif (fattr.cf_dacls)\n\t\t\t\t\t\tace_num += fattr.cf_dacls->a_count;\n\n\t\t\t\t\tpntsd = kmalloc(sizeof(struct smb_ntsd) +\n\t\t\t\t\t\t\tsizeof(struct smb_sid) * 3 +\n\t\t\t\t\t\t\tsizeof(struct smb_acl) +\n\t\t\t\t\t\t\tsizeof(struct smb_ace) * ace_num * 2,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\t\tif (!pntsd)\n\t\t\t\t\t\tgoto err_out;\n\n\t\t\t\t\trc = build_sec_desc(user_ns,\n\t\t\t\t\t\t\t    pntsd, NULL, 0,\n\t\t\t\t\t\t\t    OWNER_SECINFO |\n\t\t\t\t\t\t\t    GROUP_SECINFO |\n\t\t\t\t\t\t\t    DACL_SECINFO,\n\t\t\t\t\t\t\t    &pntsd_size, &fattr);\n\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\tif (rc) {\n\t\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = ksmbd_vfs_set_sd_xattr(conn,\n\t\t\t\t\t\t\t\t    user_ns,\n\t\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t\t    pntsd,\n\t\t\t\t\t\t\t\t    pntsd_size);\n\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\tif (rc)\n\t\t\t\t\t\tpr_err(\"failed to store ntacl in xattr : %d\\n\",\n\t\t\t\t\t\t       rc);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\trc = smb2_set_stream_name_xattr(&path,\n\t\t\t\t\t\tfp,\n\t\t\t\t\t\tstream_name,\n\t\t\t\t\t\ts_type);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tfp->attrib_only = !(req->DesiredAccess & ~(FILE_READ_ATTRIBUTES_LE |\n\t\t\tFILE_WRITE_ATTRIBUTES_LE | FILE_SYNCHRONIZE_LE));\n\tif (!S_ISDIR(file_inode(filp)->i_mode) && open_flags & O_TRUNC &&\n\t    !fp->attrib_only && !stream_name) {\n\t\tsmb_break_all_oplock(work, fp);\n\t\tneed_truncate = 1;\n\t}\n\n\t/* fp should be searchable through ksmbd_inode.m_fp_list\n\t * after daccess, saccess, attrib_only, and stream are\n\t * initialized.\n\t */\n\twrite_lock(&fp->f_ci->m_lock);\n\tlist_add(&fp->node, &fp->f_ci->m_fp_list);\n\twrite_unlock(&fp->f_ci->m_lock);\n\n\trc = ksmbd_vfs_getattr(&path, &stat);\n\tif (rc) {\n\t\tgeneric_fillattr(user_ns, d_inode(path.dentry), &stat);\n\t\trc = 0;\n\t}\n\n\t/* Check delete pending among previous fp before oplock break */\n\tif (ksmbd_inode_pending_delete(fp)) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\tshare_ret = ksmbd_smb_check_shared_mode(fp->filp, fp);\n\tif (!test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_OPLOCKS) ||\n\t    (req_op_level == SMB2_OPLOCK_LEVEL_LEASE &&\n\t     !(conn->vals->capabilities & SMB2_GLOBAL_CAP_LEASING))) {\n\t\tif (share_ret < 0 && !S_ISDIR(file_inode(fp->filp)->i_mode)) {\n\t\t\trc = share_ret;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE) {\n\t\t\treq_op_level = smb2_map_lease_to_oplock(lc->req_state);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"lease req for(%s) req oplock state 0x%x, lease state 0x%x\\n\",\n\t\t\t\t    name, req_op_level, lc->req_state);\n\t\t\trc = find_same_lease_key(sess, fp->f_ci, lc);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t} else if (open_flags == O_RDONLY &&\n\t\t\t   (req_op_level == SMB2_OPLOCK_LEVEL_BATCH ||\n\t\t\t    req_op_level == SMB2_OPLOCK_LEVEL_EXCLUSIVE))\n\t\t\treq_op_level = SMB2_OPLOCK_LEVEL_II;\n\n\t\trc = smb_grant_oplock(work, req_op_level,\n\t\t\t\t      fp->persistent_id, fp,\n\t\t\t\t      le32_to_cpu(req->hdr.Id.SyncId.TreeId),\n\t\t\t\t      lc, share_ret);\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)\n\t\tksmbd_fd_set_delete_on_close(fp, file_info);\n\n\tif (need_truncate) {\n\t\trc = smb2_create_truncate(&path);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\tstruct create_alloc_size_req *az_req;\n\n\t\taz_req = (struct create_alloc_size_req *)smb2_find_context_vals(req,\n\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE);\n\t\tif (IS_ERR(az_req)) {\n\t\t\trc = PTR_ERR(az_req);\n\t\t\tgoto err_out;\n\t\t} else if (az_req) {\n\t\t\tloff_t alloc_size;\n\t\t\tint err;\n\n\t\t\tif (le16_to_cpu(az_req->ccontext.DataOffset) +\n\t\t\t    le32_to_cpu(az_req->ccontext.DataLength) <\n\t\t\t    sizeof(struct create_alloc_size_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\talloc_size = le64_to_cpu(az_req->AllocationSize);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"request smb2 create allocate size : %llu\\n\",\n\t\t\t\t    alloc_size);\n\t\t\tsmb_break_all_levII_oplock(work, fp, 1);\n\t\t\terr = vfs_fallocate(fp->filp, FALLOC_FL_KEEP_SIZE, 0,\n\t\t\t\t\t    alloc_size);\n\t\t\tif (err < 0)\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"vfs_fallocate is failed : %d\\n\",\n\t\t\t\t\t    err);\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get query on disk id context\\n\");\n\t\t\tquery_disk_id = 1;\n\t\t}\n\t}\n\n\tif (stat.result_mask & STATX_BTIME)\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.btime);\n\telse\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.ctime);\n\tif (req->FileAttributes || fp->f_ci->m_fattr == 0)\n\t\tfp->f_ci->m_fattr =\n\t\t\tcpu_to_le32(smb2_get_dos_mode(&stat, le32_to_cpu(req->FileAttributes)));\n\n\tif (!created)\n\t\tsmb2_update_xattrs(tcon, &path, fp);\n\telse\n\t\tsmb2_new_xattrs(tcon, &path, fp);\n\n\tmemcpy(fp->client_guid, conn->ClientGUID, SMB2_CLIENT_GUID_SIZE);\n\n\tgeneric_fillattr(user_ns, file_inode(fp->filp),\n\t\t\t &stat);\n\n\trsp->StructureSize = cpu_to_le16(89);\n\trcu_read_lock();\n\topinfo = rcu_dereference(fp->f_opinfo);\n\trsp->OplockLevel = opinfo != NULL ? opinfo->level : 0;\n\trcu_read_unlock();\n\trsp->Flags = 0;\n\trsp->CreateAction = cpu_to_le32(file_info);\n\trsp->CreationTime = cpu_to_le64(fp->create_time);\n\ttime = ksmbd_UnixTimeToNT(stat.atime);\n\trsp->LastAccessTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.mtime);\n\trsp->LastWriteTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.ctime);\n\trsp->ChangeTime = cpu_to_le64(time);\n\trsp->AllocationSize = S_ISDIR(stat.mode) ? 0 :\n\t\tcpu_to_le64(stat.blocks << 9);\n\trsp->EndofFile = S_ISDIR(stat.mode) ? 0 : cpu_to_le64(stat.size);\n\trsp->FileAttributes = fp->f_ci->m_fattr;\n\n\trsp->Reserved2 = 0;\n\n\trsp->PersistentFileId = fp->persistent_id;\n\trsp->VolatileFileId = fp->volatile_id;\n\n\trsp->CreateContextsOffset = 0;\n\trsp->CreateContextsLength = 0;\n\tinc_rfc1001_len(work->response_buf, 88); /* StructureSize - 1*/\n\n\t/* If lease is request send lease context response */\n\tif (opinfo && opinfo->is_lease) {\n\t\tstruct create_context *lease_ccontext;\n\n\t\tksmbd_debug(SMB, \"lease granted on(%s) lease state 0x%x\\n\",\n\t\t\t    name, opinfo->o_lease->state);\n\t\trsp->OplockLevel = SMB2_OPLOCK_LEVEL_LEASE;\n\n\t\tlease_ccontext = (struct create_context *)rsp->Buffer;\n\t\tcontxt_cnt++;\n\t\tcreate_lease_buf(rsp->Buffer, opinfo->o_lease);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_lease_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_lease_size);\n\t\tnext_ptr = &lease_ccontext->Next;\n\t\tnext_off = conn->vals->create_lease_size;\n\t}\n\n\tif (maximal_access_ctxt) {\n\t\tstruct create_context *mxac_ccontext;\n\n\t\tif (maximal_access == 0)\n\t\t\tksmbd_vfs_query_maximal_access(user_ns,\n\t\t\t\t\t\t       path.dentry,\n\t\t\t\t\t\t       &maximal_access);\n\t\tmxac_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_mxac_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tle32_to_cpu(maximal_access));\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_mxac_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_mxac_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &mxac_ccontext->Next;\n\t\tnext_off = conn->vals->create_mxac_size;\n\t}\n\n\tif (query_disk_id) {\n\t\tstruct create_context *disk_id_ccontext;\n\n\t\tdisk_id_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_disk_id_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tstat.ino, tcon->id);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_disk_id_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_disk_id_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &disk_id_ccontext->Next;\n\t\tnext_off = conn->vals->create_disk_id_size;\n\t}\n\n\tif (posix_ctxt) {\n\t\tcontxt_cnt++;\n\t\tcreate_posix_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tfp);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_posix_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_posix_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t}\n\n\tif (contxt_cnt > 0) {\n\t\trsp->CreateContextsOffset =\n\t\t\tcpu_to_le32(offsetof(struct smb2_create_rsp, Buffer));\n\t}\n\nerr_out:\n\tif (file_present || created)\n\t\tpath_put(&path);\n\tksmbd_revert_fsids(work);\nerr_out1:\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\telse if (rc == -EOPNOTSUPP)\n\t\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\telse if (rc == -EACCES || rc == -ESTALE || rc == -EXDEV)\n\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\telse if (rc == -ENOENT)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_INVALID;\n\t\telse if (rc == -EPERM)\n\t\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\t\telse if (rc == -EBUSY)\n\t\t\trsp->hdr.Status = STATUS_DELETE_PENDING;\n\t\telse if (rc == -EBADF)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_NOT_FOUND;\n\t\telse if (rc == -ENOEXEC)\n\t\t\trsp->hdr.Status = STATUS_DUPLICATE_OBJECTID;\n\t\telse if (rc == -ENXIO)\n\t\t\trsp->hdr.Status = STATUS_NO_SUCH_DEVICE;\n\t\telse if (rc == -EEXIST)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_COLLISION;\n\t\telse if (rc == -EMFILE)\n\t\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\t\tif (!rsp->hdr.Status)\n\t\t\trsp->hdr.Status = STATUS_UNEXPECTED_IO_ERROR;\n\n\t\tif (fp)\n\t\t\tksmbd_fd_put(work, fp);\n\t\tsmb2_set_err_rsp(work);\n\t\tksmbd_debug(SMB, \"Error response: %x\\n\", rsp->hdr.Status);\n\t}\n\n\tkfree(name);\n\tkfree(lc);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -493,7 +493,7 @@\n \t\t\t\t\t\tgoto err_out;\n \n \t\t\t\t\trc = build_sec_desc(user_ns,\n-\t\t\t\t\t\t\t    pntsd, NULL,\n+\t\t\t\t\t\t\t    pntsd, NULL, 0,\n \t\t\t\t\t\t\t    OWNER_SECINFO |\n \t\t\t\t\t\t\t    GROUP_SECINFO |\n \t\t\t\t\t\t\t    DACL_SECINFO,",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t\t\t    pntsd, NULL, 0,"
            ],
            "deleted": [
                "\t\t\t\t\t\t\t    pntsd, NULL,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "static int smb2_calc_max_out_buf_len(struct ksmbd_work *work,\n\t\t\t\t     unsigned short hdr2_len,\n\t\t\t\t     unsigned int out_buf_len)\n{\n\tint free_len;\n\n\tif (out_buf_len > work->conn->vals->max_trans_size)\n\t\treturn -EINVAL;\n\n\tfree_len = (int)(work->response_sz -\n\t\t\t (get_rfc1002_len(work->response_buf) + 4)) -\n\t\thdr2_len;\n\tif (free_len < 0)\n\t\treturn -EINVAL;\n\n\treturn min_t(int, out_buf_len, free_len);\n}",
        "code_after_change": "static int smb2_calc_max_out_buf_len(struct ksmbd_work *work,\n\t\t\t\t     unsigned short hdr2_len,\n\t\t\t\t     unsigned int out_buf_len)\n{\n\tint free_len;\n\n\tif (out_buf_len > work->conn->vals->max_trans_size)\n\t\treturn -EINVAL;\n\n\tfree_len = smb2_resp_buf_len(work, hdr2_len);\n\tif (free_len < 0)\n\t\treturn -EINVAL;\n\n\treturn min_t(int, out_buf_len, free_len);\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,9 +7,7 @@\n \tif (out_buf_len > work->conn->vals->max_trans_size)\n \t\treturn -EINVAL;\n \n-\tfree_len = (int)(work->response_sz -\n-\t\t\t (get_rfc1002_len(work->response_buf) + 4)) -\n-\t\thdr2_len;\n+\tfree_len = smb2_resp_buf_len(work, hdr2_len);\n \tif (free_len < 0)\n \t\treturn -EINVAL;\n ",
        "function_modified_lines": {
            "added": [
                "\tfree_len = smb2_resp_buf_len(work, hdr2_len);"
            ],
            "deleted": [
                "\tfree_len = (int)(work->response_sz -",
                "\t\t\t (get_rfc1002_len(work->response_buf) + 4)) -",
                "\t\thdr2_len;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "static int smb2_get_info_sec(struct ksmbd_work *work,\n\t\t\t     struct smb2_query_info_req *req,\n\t\t\t     struct smb2_query_info_rsp *rsp)\n{\n\tstruct ksmbd_file *fp;\n\tstruct user_namespace *user_ns;\n\tstruct smb_ntsd *pntsd = (struct smb_ntsd *)rsp->Buffer, *ppntsd = NULL;\n\tstruct smb_fattr fattr = {{0}};\n\tstruct inode *inode;\n\t__u32 secdesclen;\n\tunsigned int id = KSMBD_NO_FID, pid = KSMBD_NO_FID;\n\tint addition_info = le32_to_cpu(req->AdditionalInformation);\n\tint rc;\n\n\tif (addition_info & ~(OWNER_SECINFO | GROUP_SECINFO | DACL_SECINFO |\n\t\t\t      PROTECTED_DACL_SECINFO |\n\t\t\t      UNPROTECTED_DACL_SECINFO)) {\n\t\tksmbd_debug(SMB, \"Unsupported addition info: 0x%x)\\n\",\n\t\t       addition_info);\n\n\t\tpntsd->revision = cpu_to_le16(1);\n\t\tpntsd->type = cpu_to_le16(SELF_RELATIVE | DACL_PROTECTED);\n\t\tpntsd->osidoffset = 0;\n\t\tpntsd->gsidoffset = 0;\n\t\tpntsd->sacloffset = 0;\n\t\tpntsd->dacloffset = 0;\n\n\t\tsecdesclen = sizeof(struct smb_ntsd);\n\t\trsp->OutputBufferLength = cpu_to_le32(secdesclen);\n\t\tinc_rfc1001_len(work->response_buf, secdesclen);\n\n\t\treturn 0;\n\t}\n\n\tif (work->next_smb2_rcv_hdr_off) {\n\t\tif (!has_file_id(req->VolatileFileId)) {\n\t\t\tksmbd_debug(SMB, \"Compound request set FID = %llu\\n\",\n\t\t\t\t    work->compound_fid);\n\t\t\tid = work->compound_fid;\n\t\t\tpid = work->compound_pfid;\n\t\t}\n\t}\n\n\tif (!has_file_id(id)) {\n\t\tid = req->VolatileFileId;\n\t\tpid = req->PersistentFileId;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, id, pid);\n\tif (!fp)\n\t\treturn -ENOENT;\n\n\tuser_ns = file_mnt_user_ns(fp->filp);\n\tinode = file_inode(fp->filp);\n\tksmbd_acls_fattr(&fattr, user_ns, inode);\n\n\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR))\n\t\tksmbd_vfs_get_sd_xattr(work->conn, user_ns,\n\t\t\t\t       fp->filp->f_path.dentry, &ppntsd);\n\n\trc = build_sec_desc(user_ns, pntsd, ppntsd, addition_info,\n\t\t\t    &secdesclen, &fattr);\n\tposix_acl_release(fattr.cf_acls);\n\tposix_acl_release(fattr.cf_dacls);\n\tkfree(ppntsd);\n\tksmbd_fd_put(work, fp);\n\tif (rc)\n\t\treturn rc;\n\n\trsp->OutputBufferLength = cpu_to_le32(secdesclen);\n\tinc_rfc1001_len(work->response_buf, secdesclen);\n\treturn 0;\n}",
        "code_after_change": "static int smb2_get_info_sec(struct ksmbd_work *work,\n\t\t\t     struct smb2_query_info_req *req,\n\t\t\t     struct smb2_query_info_rsp *rsp)\n{\n\tstruct ksmbd_file *fp;\n\tstruct user_namespace *user_ns;\n\tstruct smb_ntsd *pntsd = (struct smb_ntsd *)rsp->Buffer, *ppntsd = NULL;\n\tstruct smb_fattr fattr = {{0}};\n\tstruct inode *inode;\n\t__u32 secdesclen = 0;\n\tunsigned int id = KSMBD_NO_FID, pid = KSMBD_NO_FID;\n\tint addition_info = le32_to_cpu(req->AdditionalInformation);\n\tint rc = 0, ppntsd_size = 0;\n\n\tif (addition_info & ~(OWNER_SECINFO | GROUP_SECINFO | DACL_SECINFO |\n\t\t\t      PROTECTED_DACL_SECINFO |\n\t\t\t      UNPROTECTED_DACL_SECINFO)) {\n\t\tksmbd_debug(SMB, \"Unsupported addition info: 0x%x)\\n\",\n\t\t       addition_info);\n\n\t\tpntsd->revision = cpu_to_le16(1);\n\t\tpntsd->type = cpu_to_le16(SELF_RELATIVE | DACL_PROTECTED);\n\t\tpntsd->osidoffset = 0;\n\t\tpntsd->gsidoffset = 0;\n\t\tpntsd->sacloffset = 0;\n\t\tpntsd->dacloffset = 0;\n\n\t\tsecdesclen = sizeof(struct smb_ntsd);\n\t\trsp->OutputBufferLength = cpu_to_le32(secdesclen);\n\t\tinc_rfc1001_len(work->response_buf, secdesclen);\n\n\t\treturn 0;\n\t}\n\n\tif (work->next_smb2_rcv_hdr_off) {\n\t\tif (!has_file_id(req->VolatileFileId)) {\n\t\t\tksmbd_debug(SMB, \"Compound request set FID = %llu\\n\",\n\t\t\t\t    work->compound_fid);\n\t\t\tid = work->compound_fid;\n\t\t\tpid = work->compound_pfid;\n\t\t}\n\t}\n\n\tif (!has_file_id(id)) {\n\t\tid = req->VolatileFileId;\n\t\tpid = req->PersistentFileId;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, id, pid);\n\tif (!fp)\n\t\treturn -ENOENT;\n\n\tuser_ns = file_mnt_user_ns(fp->filp);\n\tinode = file_inode(fp->filp);\n\tksmbd_acls_fattr(&fattr, user_ns, inode);\n\n\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR))\n\t\tppntsd_size = ksmbd_vfs_get_sd_xattr(work->conn, user_ns,\n\t\t\t\t\t\t     fp->filp->f_path.dentry,\n\t\t\t\t\t\t     &ppntsd);\n\n\t/* Check if sd buffer size exceeds response buffer size */\n\tif (smb2_resp_buf_len(work, 8) > ppntsd_size)\n\t\trc = build_sec_desc(user_ns, pntsd, ppntsd, ppntsd_size,\n\t\t\t\t    addition_info, &secdesclen, &fattr);\n\tposix_acl_release(fattr.cf_acls);\n\tposix_acl_release(fattr.cf_dacls);\n\tkfree(ppntsd);\n\tksmbd_fd_put(work, fp);\n\tif (rc)\n\t\treturn rc;\n\n\trsp->OutputBufferLength = cpu_to_le32(secdesclen);\n\tinc_rfc1001_len(work->response_buf, secdesclen);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,10 +7,10 @@\n \tstruct smb_ntsd *pntsd = (struct smb_ntsd *)rsp->Buffer, *ppntsd = NULL;\n \tstruct smb_fattr fattr = {{0}};\n \tstruct inode *inode;\n-\t__u32 secdesclen;\n+\t__u32 secdesclen = 0;\n \tunsigned int id = KSMBD_NO_FID, pid = KSMBD_NO_FID;\n \tint addition_info = le32_to_cpu(req->AdditionalInformation);\n-\tint rc;\n+\tint rc = 0, ppntsd_size = 0;\n \n \tif (addition_info & ~(OWNER_SECINFO | GROUP_SECINFO | DACL_SECINFO |\n \t\t\t      PROTECTED_DACL_SECINFO |\n@@ -56,11 +56,14 @@\n \n \tif (test_share_config_flag(work->tcon->share_conf,\n \t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR))\n-\t\tksmbd_vfs_get_sd_xattr(work->conn, user_ns,\n-\t\t\t\t       fp->filp->f_path.dentry, &ppntsd);\n+\t\tppntsd_size = ksmbd_vfs_get_sd_xattr(work->conn, user_ns,\n+\t\t\t\t\t\t     fp->filp->f_path.dentry,\n+\t\t\t\t\t\t     &ppntsd);\n \n-\trc = build_sec_desc(user_ns, pntsd, ppntsd, addition_info,\n-\t\t\t    &secdesclen, &fattr);\n+\t/* Check if sd buffer size exceeds response buffer size */\n+\tif (smb2_resp_buf_len(work, 8) > ppntsd_size)\n+\t\trc = build_sec_desc(user_ns, pntsd, ppntsd, ppntsd_size,\n+\t\t\t\t    addition_info, &secdesclen, &fattr);\n \tposix_acl_release(fattr.cf_acls);\n \tposix_acl_release(fattr.cf_dacls);\n \tkfree(ppntsd);",
        "function_modified_lines": {
            "added": [
                "\t__u32 secdesclen = 0;",
                "\tint rc = 0, ppntsd_size = 0;",
                "\t\tppntsd_size = ksmbd_vfs_get_sd_xattr(work->conn, user_ns,",
                "\t\t\t\t\t\t     fp->filp->f_path.dentry,",
                "\t\t\t\t\t\t     &ppntsd);",
                "\t/* Check if sd buffer size exceeds response buffer size */",
                "\tif (smb2_resp_buf_len(work, 8) > ppntsd_size)",
                "\t\trc = build_sec_desc(user_ns, pntsd, ppntsd, ppntsd_size,",
                "\t\t\t\t    addition_info, &secdesclen, &fattr);"
            ],
            "deleted": [
                "\t__u32 secdesclen;",
                "\tint rc;",
                "\t\tksmbd_vfs_get_sd_xattr(work->conn, user_ns,",
                "\t\t\t\t       fp->filp->f_path.dentry, &ppntsd);",
                "\trc = build_sec_desc(user_ns, pntsd, ppntsd, addition_info,",
                "\t\t\t    &secdesclen, &fattr);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "int smb_inherit_dacl(struct ksmbd_conn *conn,\n\t\t     struct path *path,\n\t\t     unsigned int uid, unsigned int gid)\n{\n\tconst struct smb_sid *psid, *creator = NULL;\n\tstruct smb_ace *parent_aces, *aces;\n\tstruct smb_acl *parent_pdacl;\n\tstruct smb_ntsd *parent_pntsd = NULL;\n\tstruct smb_sid owner_sid, group_sid;\n\tstruct dentry *parent = path->dentry->d_parent;\n\tstruct user_namespace *user_ns = mnt_user_ns(path->mnt);\n\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0;\n\tint rc = 0, num_aces, dacloffset, pntsd_type, acl_len;\n\tchar *aces_base;\n\tbool is_dir = S_ISDIR(d_inode(path->dentry)->i_mode);\n\n\tacl_len = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n\t\t\t\t\t parent, &parent_pntsd);\n\tif (acl_len <= 0)\n\t\treturn -ENOENT;\n\tdacloffset = le32_to_cpu(parent_pntsd->dacloffset);\n\tif (!dacloffset) {\n\t\trc = -EINVAL;\n\t\tgoto free_parent_pntsd;\n\t}\n\n\tparent_pdacl = (struct smb_acl *)((char *)parent_pntsd + dacloffset);\n\tnum_aces = le32_to_cpu(parent_pdacl->num_aces);\n\tpntsd_type = le16_to_cpu(parent_pntsd->type);\n\n\taces_base = kmalloc(sizeof(struct smb_ace) * num_aces * 2, GFP_KERNEL);\n\tif (!aces_base) {\n\t\trc = -ENOMEM;\n\t\tgoto free_parent_pntsd;\n\t}\n\n\taces = (struct smb_ace *)aces_base;\n\tparent_aces = (struct smb_ace *)((char *)parent_pdacl +\n\t\t\tsizeof(struct smb_acl));\n\n\tif (pntsd_type & DACL_AUTO_INHERITED)\n\t\tinherited_flags = INHERITED_ACE;\n\n\tfor (i = 0; i < num_aces; i++) {\n\t\tflags = parent_aces->flags;\n\t\tif (!smb_inherit_flags(flags, is_dir))\n\t\t\tgoto pass;\n\t\tif (is_dir) {\n\t\t\tflags &= ~(INHERIT_ONLY_ACE | INHERITED_ACE);\n\t\t\tif (!(flags & CONTAINER_INHERIT_ACE))\n\t\t\t\tflags |= INHERIT_ONLY_ACE;\n\t\t\tif (flags & NO_PROPAGATE_INHERIT_ACE)\n\t\t\t\tflags = 0;\n\t\t} else {\n\t\t\tflags = 0;\n\t\t}\n\n\t\tif (!compare_sids(&creator_owner, &parent_aces->sid)) {\n\t\t\tcreator = &creator_owner;\n\t\t\tid_to_sid(uid, SIDOWNER, &owner_sid);\n\t\t\tpsid = &owner_sid;\n\t\t} else if (!compare_sids(&creator_group, &parent_aces->sid)) {\n\t\t\tcreator = &creator_group;\n\t\t\tid_to_sid(gid, SIDUNIX_GROUP, &group_sid);\n\t\t\tpsid = &group_sid;\n\t\t} else {\n\t\t\tcreator = NULL;\n\t\t\tpsid = &parent_aces->sid;\n\t\t}\n\n\t\tif (is_dir && creator && flags & CONTAINER_INHERIT_ACE) {\n\t\t\tsmb_set_ace(aces, psid, parent_aces->type, inherited_flags,\n\t\t\t\t    parent_aces->access_req);\n\t\t\tnt_size += le16_to_cpu(aces->size);\n\t\t\tace_cnt++;\n\t\t\taces = (struct smb_ace *)((char *)aces + le16_to_cpu(aces->size));\n\t\t\tflags |= INHERIT_ONLY_ACE;\n\t\t\tpsid = creator;\n\t\t} else if (is_dir && !(parent_aces->flags & NO_PROPAGATE_INHERIT_ACE)) {\n\t\t\tpsid = &parent_aces->sid;\n\t\t}\n\n\t\tsmb_set_ace(aces, psid, parent_aces->type, flags | inherited_flags,\n\t\t\t    parent_aces->access_req);\n\t\tnt_size += le16_to_cpu(aces->size);\n\t\taces = (struct smb_ace *)((char *)aces + le16_to_cpu(aces->size));\n\t\tace_cnt++;\npass:\n\t\tparent_aces =\n\t\t\t(struct smb_ace *)((char *)parent_aces + le16_to_cpu(parent_aces->size));\n\t}\n\n\tif (nt_size > 0) {\n\t\tstruct smb_ntsd *pntsd;\n\t\tstruct smb_acl *pdacl;\n\t\tstruct smb_sid *powner_sid = NULL, *pgroup_sid = NULL;\n\t\tint powner_sid_size = 0, pgroup_sid_size = 0, pntsd_size;\n\n\t\tif (parent_pntsd->osidoffset) {\n\t\t\tpowner_sid = (struct smb_sid *)((char *)parent_pntsd +\n\t\t\t\t\tle32_to_cpu(parent_pntsd->osidoffset));\n\t\t\tpowner_sid_size = 1 + 1 + 6 + (powner_sid->num_subauth * 4);\n\t\t}\n\t\tif (parent_pntsd->gsidoffset) {\n\t\t\tpgroup_sid = (struct smb_sid *)((char *)parent_pntsd +\n\t\t\t\t\tle32_to_cpu(parent_pntsd->gsidoffset));\n\t\t\tpgroup_sid_size = 1 + 1 + 6 + (pgroup_sid->num_subauth * 4);\n\t\t}\n\n\t\tpntsd = kzalloc(sizeof(struct smb_ntsd) + powner_sid_size +\n\t\t\t\tpgroup_sid_size + sizeof(struct smb_acl) +\n\t\t\t\tnt_size, GFP_KERNEL);\n\t\tif (!pntsd) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_aces_base;\n\t\t}\n\n\t\tpntsd->revision = cpu_to_le16(1);\n\t\tpntsd->type = cpu_to_le16(SELF_RELATIVE | DACL_PRESENT);\n\t\tif (le16_to_cpu(parent_pntsd->type) & DACL_AUTO_INHERITED)\n\t\t\tpntsd->type |= cpu_to_le16(DACL_AUTO_INHERITED);\n\t\tpntsd_size = sizeof(struct smb_ntsd);\n\t\tpntsd->osidoffset = parent_pntsd->osidoffset;\n\t\tpntsd->gsidoffset = parent_pntsd->gsidoffset;\n\t\tpntsd->dacloffset = parent_pntsd->dacloffset;\n\n\t\tif (pntsd->osidoffset) {\n\t\t\tstruct smb_sid *owner_sid = (struct smb_sid *)((char *)pntsd +\n\t\t\t\t\tle32_to_cpu(pntsd->osidoffset));\n\t\t\tmemcpy(owner_sid, powner_sid, powner_sid_size);\n\t\t\tpntsd_size += powner_sid_size;\n\t\t}\n\n\t\tif (pntsd->gsidoffset) {\n\t\t\tstruct smb_sid *group_sid = (struct smb_sid *)((char *)pntsd +\n\t\t\t\t\tle32_to_cpu(pntsd->gsidoffset));\n\t\t\tmemcpy(group_sid, pgroup_sid, pgroup_sid_size);\n\t\t\tpntsd_size += pgroup_sid_size;\n\t\t}\n\n\t\tif (pntsd->dacloffset) {\n\t\t\tstruct smb_ace *pace;\n\n\t\t\tpdacl = (struct smb_acl *)((char *)pntsd + le32_to_cpu(pntsd->dacloffset));\n\t\t\tpdacl->revision = cpu_to_le16(2);\n\t\t\tpdacl->size = cpu_to_le16(sizeof(struct smb_acl) + nt_size);\n\t\t\tpdacl->num_aces = cpu_to_le32(ace_cnt);\n\t\t\tpace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\t\t\tmemcpy(pace, aces_base, nt_size);\n\t\t\tpntsd_size += sizeof(struct smb_acl) + nt_size;\n\t\t}\n\n\t\tksmbd_vfs_set_sd_xattr(conn, user_ns,\n\t\t\t\t       path->dentry, pntsd, pntsd_size);\n\t\tkfree(pntsd);\n\t}\n\nfree_aces_base:\n\tkfree(aces_base);\nfree_parent_pntsd:\n\tkfree(parent_pntsd);\n\treturn rc;\n}",
        "code_after_change": "int smb_inherit_dacl(struct ksmbd_conn *conn,\n\t\t     struct path *path,\n\t\t     unsigned int uid, unsigned int gid)\n{\n\tconst struct smb_sid *psid, *creator = NULL;\n\tstruct smb_ace *parent_aces, *aces;\n\tstruct smb_acl *parent_pdacl;\n\tstruct smb_ntsd *parent_pntsd = NULL;\n\tstruct smb_sid owner_sid, group_sid;\n\tstruct dentry *parent = path->dentry->d_parent;\n\tstruct user_namespace *user_ns = mnt_user_ns(path->mnt);\n\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0, pdacl_size;\n\tint rc = 0, num_aces, dacloffset, pntsd_type, pntsd_size, acl_len, aces_size;\n\tchar *aces_base;\n\tbool is_dir = S_ISDIR(d_inode(path->dentry)->i_mode);\n\n\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n\t\t\t\t\t    parent, &parent_pntsd);\n\tif (pntsd_size <= 0)\n\t\treturn -ENOENT;\n\tdacloffset = le32_to_cpu(parent_pntsd->dacloffset);\n\tif (!dacloffset || (dacloffset + sizeof(struct smb_acl) > pntsd_size)) {\n\t\trc = -EINVAL;\n\t\tgoto free_parent_pntsd;\n\t}\n\n\tparent_pdacl = (struct smb_acl *)((char *)parent_pntsd + dacloffset);\n\tacl_len = pntsd_size - dacloffset;\n\tnum_aces = le32_to_cpu(parent_pdacl->num_aces);\n\tpntsd_type = le16_to_cpu(parent_pntsd->type);\n\tpdacl_size = le16_to_cpu(parent_pdacl->size);\n\n\tif (pdacl_size > acl_len || pdacl_size < sizeof(struct smb_acl)) {\n\t\trc = -EINVAL;\n\t\tgoto free_parent_pntsd;\n\t}\n\n\taces_base = kmalloc(sizeof(struct smb_ace) * num_aces * 2, GFP_KERNEL);\n\tif (!aces_base) {\n\t\trc = -ENOMEM;\n\t\tgoto free_parent_pntsd;\n\t}\n\n\taces = (struct smb_ace *)aces_base;\n\tparent_aces = (struct smb_ace *)((char *)parent_pdacl +\n\t\t\tsizeof(struct smb_acl));\n\taces_size = acl_len - sizeof(struct smb_acl);\n\n\tif (pntsd_type & DACL_AUTO_INHERITED)\n\t\tinherited_flags = INHERITED_ACE;\n\n\tfor (i = 0; i < num_aces; i++) {\n\t\tint pace_size;\n\n\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n\t\t\tbreak;\n\n\t\tpace_size = le16_to_cpu(parent_aces->size);\n\t\tif (pace_size > aces_size)\n\t\t\tbreak;\n\n\t\taces_size -= pace_size;\n\n\t\tflags = parent_aces->flags;\n\t\tif (!smb_inherit_flags(flags, is_dir))\n\t\t\tgoto pass;\n\t\tif (is_dir) {\n\t\t\tflags &= ~(INHERIT_ONLY_ACE | INHERITED_ACE);\n\t\t\tif (!(flags & CONTAINER_INHERIT_ACE))\n\t\t\t\tflags |= INHERIT_ONLY_ACE;\n\t\t\tif (flags & NO_PROPAGATE_INHERIT_ACE)\n\t\t\t\tflags = 0;\n\t\t} else {\n\t\t\tflags = 0;\n\t\t}\n\n\t\tif (!compare_sids(&creator_owner, &parent_aces->sid)) {\n\t\t\tcreator = &creator_owner;\n\t\t\tid_to_sid(uid, SIDOWNER, &owner_sid);\n\t\t\tpsid = &owner_sid;\n\t\t} else if (!compare_sids(&creator_group, &parent_aces->sid)) {\n\t\t\tcreator = &creator_group;\n\t\t\tid_to_sid(gid, SIDUNIX_GROUP, &group_sid);\n\t\t\tpsid = &group_sid;\n\t\t} else {\n\t\t\tcreator = NULL;\n\t\t\tpsid = &parent_aces->sid;\n\t\t}\n\n\t\tif (is_dir && creator && flags & CONTAINER_INHERIT_ACE) {\n\t\t\tsmb_set_ace(aces, psid, parent_aces->type, inherited_flags,\n\t\t\t\t    parent_aces->access_req);\n\t\t\tnt_size += le16_to_cpu(aces->size);\n\t\t\tace_cnt++;\n\t\t\taces = (struct smb_ace *)((char *)aces + le16_to_cpu(aces->size));\n\t\t\tflags |= INHERIT_ONLY_ACE;\n\t\t\tpsid = creator;\n\t\t} else if (is_dir && !(parent_aces->flags & NO_PROPAGATE_INHERIT_ACE)) {\n\t\t\tpsid = &parent_aces->sid;\n\t\t}\n\n\t\tsmb_set_ace(aces, psid, parent_aces->type, flags | inherited_flags,\n\t\t\t    parent_aces->access_req);\n\t\tnt_size += le16_to_cpu(aces->size);\n\t\taces = (struct smb_ace *)((char *)aces + le16_to_cpu(aces->size));\n\t\tace_cnt++;\npass:\n\t\tparent_aces = (struct smb_ace *)((char *)parent_aces + pace_size);\n\t}\n\n\tif (nt_size > 0) {\n\t\tstruct smb_ntsd *pntsd;\n\t\tstruct smb_acl *pdacl;\n\t\tstruct smb_sid *powner_sid = NULL, *pgroup_sid = NULL;\n\t\tint powner_sid_size = 0, pgroup_sid_size = 0, pntsd_size;\n\n\t\tif (parent_pntsd->osidoffset) {\n\t\t\tpowner_sid = (struct smb_sid *)((char *)parent_pntsd +\n\t\t\t\t\tle32_to_cpu(parent_pntsd->osidoffset));\n\t\t\tpowner_sid_size = 1 + 1 + 6 + (powner_sid->num_subauth * 4);\n\t\t}\n\t\tif (parent_pntsd->gsidoffset) {\n\t\t\tpgroup_sid = (struct smb_sid *)((char *)parent_pntsd +\n\t\t\t\t\tle32_to_cpu(parent_pntsd->gsidoffset));\n\t\t\tpgroup_sid_size = 1 + 1 + 6 + (pgroup_sid->num_subauth * 4);\n\t\t}\n\n\t\tpntsd = kzalloc(sizeof(struct smb_ntsd) + powner_sid_size +\n\t\t\t\tpgroup_sid_size + sizeof(struct smb_acl) +\n\t\t\t\tnt_size, GFP_KERNEL);\n\t\tif (!pntsd) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_aces_base;\n\t\t}\n\n\t\tpntsd->revision = cpu_to_le16(1);\n\t\tpntsd->type = cpu_to_le16(SELF_RELATIVE | DACL_PRESENT);\n\t\tif (le16_to_cpu(parent_pntsd->type) & DACL_AUTO_INHERITED)\n\t\t\tpntsd->type |= cpu_to_le16(DACL_AUTO_INHERITED);\n\t\tpntsd_size = sizeof(struct smb_ntsd);\n\t\tpntsd->osidoffset = parent_pntsd->osidoffset;\n\t\tpntsd->gsidoffset = parent_pntsd->gsidoffset;\n\t\tpntsd->dacloffset = parent_pntsd->dacloffset;\n\n\t\tif (pntsd->osidoffset) {\n\t\t\tstruct smb_sid *owner_sid = (struct smb_sid *)((char *)pntsd +\n\t\t\t\t\tle32_to_cpu(pntsd->osidoffset));\n\t\t\tmemcpy(owner_sid, powner_sid, powner_sid_size);\n\t\t\tpntsd_size += powner_sid_size;\n\t\t}\n\n\t\tif (pntsd->gsidoffset) {\n\t\t\tstruct smb_sid *group_sid = (struct smb_sid *)((char *)pntsd +\n\t\t\t\t\tle32_to_cpu(pntsd->gsidoffset));\n\t\t\tmemcpy(group_sid, pgroup_sid, pgroup_sid_size);\n\t\t\tpntsd_size += pgroup_sid_size;\n\t\t}\n\n\t\tif (pntsd->dacloffset) {\n\t\t\tstruct smb_ace *pace;\n\n\t\t\tpdacl = (struct smb_acl *)((char *)pntsd + le32_to_cpu(pntsd->dacloffset));\n\t\t\tpdacl->revision = cpu_to_le16(2);\n\t\t\tpdacl->size = cpu_to_le16(sizeof(struct smb_acl) + nt_size);\n\t\t\tpdacl->num_aces = cpu_to_le32(ace_cnt);\n\t\t\tpace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\t\t\tmemcpy(pace, aces_base, nt_size);\n\t\t\tpntsd_size += sizeof(struct smb_acl) + nt_size;\n\t\t}\n\n\t\tksmbd_vfs_set_sd_xattr(conn, user_ns,\n\t\t\t\t       path->dentry, pntsd, pntsd_size);\n\t\tkfree(pntsd);\n\t}\n\nfree_aces_base:\n\tkfree(aces_base);\nfree_parent_pntsd:\n\tkfree(parent_pntsd);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,24 +9,31 @@\n \tstruct smb_sid owner_sid, group_sid;\n \tstruct dentry *parent = path->dentry->d_parent;\n \tstruct user_namespace *user_ns = mnt_user_ns(path->mnt);\n-\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0;\n-\tint rc = 0, num_aces, dacloffset, pntsd_type, acl_len;\n+\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0, pdacl_size;\n+\tint rc = 0, num_aces, dacloffset, pntsd_type, pntsd_size, acl_len, aces_size;\n \tchar *aces_base;\n \tbool is_dir = S_ISDIR(d_inode(path->dentry)->i_mode);\n \n-\tacl_len = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n-\t\t\t\t\t parent, &parent_pntsd);\n-\tif (acl_len <= 0)\n+\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n+\t\t\t\t\t    parent, &parent_pntsd);\n+\tif (pntsd_size <= 0)\n \t\treturn -ENOENT;\n \tdacloffset = le32_to_cpu(parent_pntsd->dacloffset);\n-\tif (!dacloffset) {\n+\tif (!dacloffset || (dacloffset + sizeof(struct smb_acl) > pntsd_size)) {\n \t\trc = -EINVAL;\n \t\tgoto free_parent_pntsd;\n \t}\n \n \tparent_pdacl = (struct smb_acl *)((char *)parent_pntsd + dacloffset);\n+\tacl_len = pntsd_size - dacloffset;\n \tnum_aces = le32_to_cpu(parent_pdacl->num_aces);\n \tpntsd_type = le16_to_cpu(parent_pntsd->type);\n+\tpdacl_size = le16_to_cpu(parent_pdacl->size);\n+\n+\tif (pdacl_size > acl_len || pdacl_size < sizeof(struct smb_acl)) {\n+\t\trc = -EINVAL;\n+\t\tgoto free_parent_pntsd;\n+\t}\n \n \taces_base = kmalloc(sizeof(struct smb_ace) * num_aces * 2, GFP_KERNEL);\n \tif (!aces_base) {\n@@ -37,11 +44,23 @@\n \taces = (struct smb_ace *)aces_base;\n \tparent_aces = (struct smb_ace *)((char *)parent_pdacl +\n \t\t\tsizeof(struct smb_acl));\n+\taces_size = acl_len - sizeof(struct smb_acl);\n \n \tif (pntsd_type & DACL_AUTO_INHERITED)\n \t\tinherited_flags = INHERITED_ACE;\n \n \tfor (i = 0; i < num_aces; i++) {\n+\t\tint pace_size;\n+\n+\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n+\t\t\tbreak;\n+\n+\t\tpace_size = le16_to_cpu(parent_aces->size);\n+\t\tif (pace_size > aces_size)\n+\t\t\tbreak;\n+\n+\t\taces_size -= pace_size;\n+\n \t\tflags = parent_aces->flags;\n \t\tif (!smb_inherit_flags(flags, is_dir))\n \t\t\tgoto pass;\n@@ -86,8 +105,7 @@\n \t\taces = (struct smb_ace *)((char *)aces + le16_to_cpu(aces->size));\n \t\tace_cnt++;\n pass:\n-\t\tparent_aces =\n-\t\t\t(struct smb_ace *)((char *)parent_aces + le16_to_cpu(parent_aces->size));\n+\t\tparent_aces = (struct smb_ace *)((char *)parent_aces + pace_size);\n \t}\n \n \tif (nt_size > 0) {",
        "function_modified_lines": {
            "added": [
                "\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0, pdacl_size;",
                "\tint rc = 0, num_aces, dacloffset, pntsd_type, pntsd_size, acl_len, aces_size;",
                "\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,",
                "\t\t\t\t\t    parent, &parent_pntsd);",
                "\tif (pntsd_size <= 0)",
                "\tif (!dacloffset || (dacloffset + sizeof(struct smb_acl) > pntsd_size)) {",
                "\tacl_len = pntsd_size - dacloffset;",
                "\tpdacl_size = le16_to_cpu(parent_pdacl->size);",
                "",
                "\tif (pdacl_size > acl_len || pdacl_size < sizeof(struct smb_acl)) {",
                "\t\trc = -EINVAL;",
                "\t\tgoto free_parent_pntsd;",
                "\t}",
                "\taces_size = acl_len - sizeof(struct smb_acl);",
                "\t\tint pace_size;",
                "",
                "\t\tif (offsetof(struct smb_ace, access_req) > aces_size)",
                "\t\t\tbreak;",
                "",
                "\t\tpace_size = le16_to_cpu(parent_aces->size);",
                "\t\tif (pace_size > aces_size)",
                "\t\t\tbreak;",
                "",
                "\t\taces_size -= pace_size;",
                "",
                "\t\tparent_aces = (struct smb_ace *)((char *)parent_aces + pace_size);"
            ],
            "deleted": [
                "\tint inherited_flags = 0, flags = 0, i, ace_cnt = 0, nt_size = 0;",
                "\tint rc = 0, num_aces, dacloffset, pntsd_type, acl_len;",
                "\tacl_len = ksmbd_vfs_get_sd_xattr(conn, user_ns,",
                "\t\t\t\t\t parent, &parent_pntsd);",
                "\tif (acl_len <= 0)",
                "\tif (!dacloffset) {",
                "\t\tparent_aces =",
                "\t\t\t(struct smb_ace *)((char *)parent_aces + le16_to_cpu(parent_aces->size));"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "int smb_check_perm_dacl(struct ksmbd_conn *conn, struct path *path,\n\t\t\t__le32 *pdaccess, int uid)\n{\n\tstruct user_namespace *user_ns = mnt_user_ns(path->mnt);\n\tstruct smb_ntsd *pntsd = NULL;\n\tstruct smb_acl *pdacl;\n\tstruct posix_acl *posix_acls;\n\tint rc = 0, acl_size;\n\tstruct smb_sid sid;\n\tint granted = le32_to_cpu(*pdaccess & ~FILE_MAXIMAL_ACCESS_LE);\n\tstruct smb_ace *ace;\n\tint i, found = 0;\n\tunsigned int access_bits = 0;\n\tstruct smb_ace *others_ace = NULL;\n\tstruct posix_acl_entry *pa_entry;\n\tunsigned int sid_type = SIDOWNER;\n\tchar *end_of_acl;\n\n\tksmbd_debug(SMB, \"check permission using windows acl\\n\");\n\tacl_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n\t\t\t\t\t  path->dentry, &pntsd);\n\tif (acl_size <= 0 || !pntsd || !pntsd->dacloffset) {\n\t\tkfree(pntsd);\n\t\treturn 0;\n\t}\n\n\tpdacl = (struct smb_acl *)((char *)pntsd + le32_to_cpu(pntsd->dacloffset));\n\tend_of_acl = ((char *)pntsd) + acl_size;\n\tif (end_of_acl <= (char *)pdacl) {\n\t\tkfree(pntsd);\n\t\treturn 0;\n\t}\n\n\tif (end_of_acl < (char *)pdacl + le16_to_cpu(pdacl->size) ||\n\t    le16_to_cpu(pdacl->size) < sizeof(struct smb_acl)) {\n\t\tkfree(pntsd);\n\t\treturn 0;\n\t}\n\n\tif (!pdacl->num_aces) {\n\t\tif (!(le16_to_cpu(pdacl->size) - sizeof(struct smb_acl)) &&\n\t\t    *pdaccess & ~(FILE_READ_CONTROL_LE | FILE_WRITE_DAC_LE)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t\tkfree(pntsd);\n\t\treturn 0;\n\t}\n\n\tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tgranted = READ_CONTROL | WRITE_DAC | FILE_READ_ATTRIBUTES |\n\t\t\tDELETE;\n\n\t\tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\t\tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n\t\t\tgranted |= le32_to_cpu(ace->access_req);\n\t\t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n\t\t\tif (end_of_acl < (char *)ace)\n\t\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (!pdacl->num_aces)\n\t\t\tgranted = GENERIC_ALL_FLAGS;\n\t}\n\n\tif (!uid)\n\t\tsid_type = SIDUNIX_USER;\n\tid_to_sid(uid, sid_type, &sid);\n\n\tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n\t\tif (!compare_sids(&sid, &ace->sid) ||\n\t\t    !compare_sids(&sid_unix_NFS_mode, &ace->sid)) {\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (!compare_sids(&sid_everyone, &ace->sid))\n\t\t\tothers_ace = ace;\n\n\t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n\t\tif (end_of_acl < (char *)ace)\n\t\t\tgoto err_out;\n\t}\n\n\tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE && found) {\n\t\tgranted = READ_CONTROL | WRITE_DAC | FILE_READ_ATTRIBUTES |\n\t\t\tDELETE;\n\n\t\tgranted |= le32_to_cpu(ace->access_req);\n\n\t\tif (!pdacl->num_aces)\n\t\t\tgranted = GENERIC_ALL_FLAGS;\n\t}\n\n\tif (IS_ENABLED(CONFIG_FS_POSIX_ACL)) {\n\t\tposix_acls = get_acl(d_inode(path->dentry), ACL_TYPE_ACCESS);\n\t\tif (posix_acls && !found) {\n\t\t\tunsigned int id = -1;\n\n\t\t\tpa_entry = posix_acls->a_entries;\n\t\t\tfor (i = 0; i < posix_acls->a_count; i++, pa_entry++) {\n\t\t\t\tif (pa_entry->e_tag == ACL_USER)\n\t\t\t\t\tid = posix_acl_uid_translate(user_ns, pa_entry);\n\t\t\t\telse if (pa_entry->e_tag == ACL_GROUP)\n\t\t\t\t\tid = posix_acl_gid_translate(user_ns, pa_entry);\n\t\t\t\telse\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (id == uid) {\n\t\t\t\t\tmode_to_access_flags(pa_entry->e_perm,\n\t\t\t\t\t\t\t     0777,\n\t\t\t\t\t\t\t     &access_bits);\n\t\t\t\t\tif (!access_bits)\n\t\t\t\t\t\taccess_bits =\n\t\t\t\t\t\t\tSET_MINIMUM_RIGHTS;\n\t\t\t\t\tposix_acl_release(posix_acls);\n\t\t\t\t\tgoto check_access_bits;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (posix_acls)\n\t\t\tposix_acl_release(posix_acls);\n\t}\n\n\tif (!found) {\n\t\tif (others_ace) {\n\t\t\tace = others_ace;\n\t\t} else {\n\t\t\tksmbd_debug(SMB, \"Can't find corresponding sid\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tswitch (ace->type) {\n\tcase ACCESS_ALLOWED_ACE_TYPE:\n\t\taccess_bits = le32_to_cpu(ace->access_req);\n\t\tbreak;\n\tcase ACCESS_DENIED_ACE_TYPE:\n\tcase ACCESS_DENIED_CALLBACK_ACE_TYPE:\n\t\taccess_bits = le32_to_cpu(~ace->access_req);\n\t\tbreak;\n\t}\n\ncheck_access_bits:\n\tif (granted &\n\t    ~(access_bits | FILE_READ_ATTRIBUTES | READ_CONTROL | WRITE_DAC | DELETE)) {\n\t\tksmbd_debug(SMB, \"Access denied with winACL, granted : %x, access_req : %x\\n\",\n\t\t\t    granted, le32_to_cpu(ace->access_req));\n\t\trc = -EACCES;\n\t\tgoto err_out;\n\t}\n\n\t*pdaccess = cpu_to_le32(granted);\nerr_out:\n\tkfree(pntsd);\n\treturn rc;\n}",
        "code_after_change": "int smb_check_perm_dacl(struct ksmbd_conn *conn, struct path *path,\n\t\t\t__le32 *pdaccess, int uid)\n{\n\tstruct user_namespace *user_ns = mnt_user_ns(path->mnt);\n\tstruct smb_ntsd *pntsd = NULL;\n\tstruct smb_acl *pdacl;\n\tstruct posix_acl *posix_acls;\n\tint rc = 0, pntsd_size, acl_size, aces_size, pdacl_size, dacl_offset;\n\tstruct smb_sid sid;\n\tint granted = le32_to_cpu(*pdaccess & ~FILE_MAXIMAL_ACCESS_LE);\n\tstruct smb_ace *ace;\n\tint i, found = 0;\n\tunsigned int access_bits = 0;\n\tstruct smb_ace *others_ace = NULL;\n\tstruct posix_acl_entry *pa_entry;\n\tunsigned int sid_type = SIDOWNER;\n\tunsigned short ace_size;\n\n\tksmbd_debug(SMB, \"check permission using windows acl\\n\");\n\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n\t\t\t\t\t    path->dentry, &pntsd);\n\tif (pntsd_size <= 0 || !pntsd)\n\t\tgoto err_out;\n\n\tdacl_offset = le32_to_cpu(pntsd->dacloffset);\n\tif (!dacl_offset ||\n\t    (dacl_offset + sizeof(struct smb_acl) > pntsd_size))\n\t\tgoto err_out;\n\n\tpdacl = (struct smb_acl *)((char *)pntsd + le32_to_cpu(pntsd->dacloffset));\n\tacl_size = pntsd_size - dacl_offset;\n\tpdacl_size = le16_to_cpu(pdacl->size);\n\n\tif (pdacl_size > acl_size || pdacl_size < sizeof(struct smb_acl))\n\t\tgoto err_out;\n\n\tif (!pdacl->num_aces) {\n\t\tif (!(pdacl_size - sizeof(struct smb_acl)) &&\n\t\t    *pdaccess & ~(FILE_READ_CONTROL_LE | FILE_WRITE_DAC_LE)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t\tgoto err_out;\n\t}\n\n\tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tgranted = READ_CONTROL | WRITE_DAC | FILE_READ_ATTRIBUTES |\n\t\t\tDELETE;\n\n\t\tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\t\taces_size = acl_size - sizeof(struct smb_acl);\n\t\tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n\t\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n\t\t\t\tbreak;\n\t\t\tace_size = le16_to_cpu(ace->size);\n\t\t\tif (ace_size > aces_size)\n\t\t\t\tbreak;\n\t\t\taces_size -= ace_size;\n\t\t\tgranted |= le32_to_cpu(ace->access_req);\n\t\t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n\t\t}\n\n\t\tif (!pdacl->num_aces)\n\t\t\tgranted = GENERIC_ALL_FLAGS;\n\t}\n\n\tif (!uid)\n\t\tsid_type = SIDUNIX_USER;\n\tid_to_sid(uid, sid_type, &sid);\n\n\tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n\taces_size = acl_size - sizeof(struct smb_acl);\n\tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n\t\t\tbreak;\n\t\tace_size = le16_to_cpu(ace->size);\n\t\tif (ace_size > aces_size)\n\t\t\tbreak;\n\t\taces_size -= ace_size;\n\n\t\tif (!compare_sids(&sid, &ace->sid) ||\n\t\t    !compare_sids(&sid_unix_NFS_mode, &ace->sid)) {\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (!compare_sids(&sid_everyone, &ace->sid))\n\t\t\tothers_ace = ace;\n\n\t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n\t}\n\n\tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE && found) {\n\t\tgranted = READ_CONTROL | WRITE_DAC | FILE_READ_ATTRIBUTES |\n\t\t\tDELETE;\n\n\t\tgranted |= le32_to_cpu(ace->access_req);\n\n\t\tif (!pdacl->num_aces)\n\t\t\tgranted = GENERIC_ALL_FLAGS;\n\t}\n\n\tif (IS_ENABLED(CONFIG_FS_POSIX_ACL)) {\n\t\tposix_acls = get_acl(d_inode(path->dentry), ACL_TYPE_ACCESS);\n\t\tif (posix_acls && !found) {\n\t\t\tunsigned int id = -1;\n\n\t\t\tpa_entry = posix_acls->a_entries;\n\t\t\tfor (i = 0; i < posix_acls->a_count; i++, pa_entry++) {\n\t\t\t\tif (pa_entry->e_tag == ACL_USER)\n\t\t\t\t\tid = posix_acl_uid_translate(user_ns, pa_entry);\n\t\t\t\telse if (pa_entry->e_tag == ACL_GROUP)\n\t\t\t\t\tid = posix_acl_gid_translate(user_ns, pa_entry);\n\t\t\t\telse\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (id == uid) {\n\t\t\t\t\tmode_to_access_flags(pa_entry->e_perm,\n\t\t\t\t\t\t\t     0777,\n\t\t\t\t\t\t\t     &access_bits);\n\t\t\t\t\tif (!access_bits)\n\t\t\t\t\t\taccess_bits =\n\t\t\t\t\t\t\tSET_MINIMUM_RIGHTS;\n\t\t\t\t\tposix_acl_release(posix_acls);\n\t\t\t\t\tgoto check_access_bits;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (posix_acls)\n\t\t\tposix_acl_release(posix_acls);\n\t}\n\n\tif (!found) {\n\t\tif (others_ace) {\n\t\t\tace = others_ace;\n\t\t} else {\n\t\t\tksmbd_debug(SMB, \"Can't find corresponding sid\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tswitch (ace->type) {\n\tcase ACCESS_ALLOWED_ACE_TYPE:\n\t\taccess_bits = le32_to_cpu(ace->access_req);\n\t\tbreak;\n\tcase ACCESS_DENIED_ACE_TYPE:\n\tcase ACCESS_DENIED_CALLBACK_ACE_TYPE:\n\t\taccess_bits = le32_to_cpu(~ace->access_req);\n\t\tbreak;\n\t}\n\ncheck_access_bits:\n\tif (granted &\n\t    ~(access_bits | FILE_READ_ATTRIBUTES | READ_CONTROL | WRITE_DAC | DELETE)) {\n\t\tksmbd_debug(SMB, \"Access denied with winACL, granted : %x, access_req : %x\\n\",\n\t\t\t    granted, le32_to_cpu(ace->access_req));\n\t\trc = -EACCES;\n\t\tgoto err_out;\n\t}\n\n\t*pdaccess = cpu_to_le32(granted);\nerr_out:\n\tkfree(pntsd);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct smb_ntsd *pntsd = NULL;\n \tstruct smb_acl *pdacl;\n \tstruct posix_acl *posix_acls;\n-\tint rc = 0, acl_size;\n+\tint rc = 0, pntsd_size, acl_size, aces_size, pdacl_size, dacl_offset;\n \tstruct smb_sid sid;\n \tint granted = le32_to_cpu(*pdaccess & ~FILE_MAXIMAL_ACCESS_LE);\n \tstruct smb_ace *ace;\n@@ -14,37 +14,33 @@\n \tstruct smb_ace *others_ace = NULL;\n \tstruct posix_acl_entry *pa_entry;\n \tunsigned int sid_type = SIDOWNER;\n-\tchar *end_of_acl;\n+\tunsigned short ace_size;\n \n \tksmbd_debug(SMB, \"check permission using windows acl\\n\");\n-\tacl_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n-\t\t\t\t\t  path->dentry, &pntsd);\n-\tif (acl_size <= 0 || !pntsd || !pntsd->dacloffset) {\n-\t\tkfree(pntsd);\n-\t\treturn 0;\n-\t}\n+\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,\n+\t\t\t\t\t    path->dentry, &pntsd);\n+\tif (pntsd_size <= 0 || !pntsd)\n+\t\tgoto err_out;\n+\n+\tdacl_offset = le32_to_cpu(pntsd->dacloffset);\n+\tif (!dacl_offset ||\n+\t    (dacl_offset + sizeof(struct smb_acl) > pntsd_size))\n+\t\tgoto err_out;\n \n \tpdacl = (struct smb_acl *)((char *)pntsd + le32_to_cpu(pntsd->dacloffset));\n-\tend_of_acl = ((char *)pntsd) + acl_size;\n-\tif (end_of_acl <= (char *)pdacl) {\n-\t\tkfree(pntsd);\n-\t\treturn 0;\n-\t}\n+\tacl_size = pntsd_size - dacl_offset;\n+\tpdacl_size = le16_to_cpu(pdacl->size);\n \n-\tif (end_of_acl < (char *)pdacl + le16_to_cpu(pdacl->size) ||\n-\t    le16_to_cpu(pdacl->size) < sizeof(struct smb_acl)) {\n-\t\tkfree(pntsd);\n-\t\treturn 0;\n-\t}\n+\tif (pdacl_size > acl_size || pdacl_size < sizeof(struct smb_acl))\n+\t\tgoto err_out;\n \n \tif (!pdacl->num_aces) {\n-\t\tif (!(le16_to_cpu(pdacl->size) - sizeof(struct smb_acl)) &&\n+\t\tif (!(pdacl_size - sizeof(struct smb_acl)) &&\n \t\t    *pdaccess & ~(FILE_READ_CONTROL_LE | FILE_WRITE_DAC_LE)) {\n \t\t\trc = -EACCES;\n \t\t\tgoto err_out;\n \t\t}\n-\t\tkfree(pntsd);\n-\t\treturn 0;\n+\t\tgoto err_out;\n \t}\n \n \tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE) {\n@@ -52,11 +48,16 @@\n \t\t\tDELETE;\n \n \t\tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n+\t\taces_size = acl_size - sizeof(struct smb_acl);\n \t\tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n+\t\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n+\t\t\t\tbreak;\n+\t\t\tace_size = le16_to_cpu(ace->size);\n+\t\t\tif (ace_size > aces_size)\n+\t\t\t\tbreak;\n+\t\t\taces_size -= ace_size;\n \t\t\tgranted |= le32_to_cpu(ace->access_req);\n \t\t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n-\t\t\tif (end_of_acl < (char *)ace)\n-\t\t\t\tgoto err_out;\n \t\t}\n \n \t\tif (!pdacl->num_aces)\n@@ -68,7 +69,15 @@\n \tid_to_sid(uid, sid_type, &sid);\n \n \tace = (struct smb_ace *)((char *)pdacl + sizeof(struct smb_acl));\n+\taces_size = acl_size - sizeof(struct smb_acl);\n \tfor (i = 0; i < le32_to_cpu(pdacl->num_aces); i++) {\n+\t\tif (offsetof(struct smb_ace, access_req) > aces_size)\n+\t\t\tbreak;\n+\t\tace_size = le16_to_cpu(ace->size);\n+\t\tif (ace_size > aces_size)\n+\t\t\tbreak;\n+\t\taces_size -= ace_size;\n+\n \t\tif (!compare_sids(&sid, &ace->sid) ||\n \t\t    !compare_sids(&sid_unix_NFS_mode, &ace->sid)) {\n \t\t\tfound = 1;\n@@ -78,8 +87,6 @@\n \t\t\tothers_ace = ace;\n \n \t\tace = (struct smb_ace *)((char *)ace + le16_to_cpu(ace->size));\n-\t\tif (end_of_acl < (char *)ace)\n-\t\t\tgoto err_out;\n \t}\n \n \tif (*pdaccess & FILE_MAXIMAL_ACCESS_LE && found) {",
        "function_modified_lines": {
            "added": [
                "\tint rc = 0, pntsd_size, acl_size, aces_size, pdacl_size, dacl_offset;",
                "\tunsigned short ace_size;",
                "\tpntsd_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,",
                "\t\t\t\t\t    path->dentry, &pntsd);",
                "\tif (pntsd_size <= 0 || !pntsd)",
                "\t\tgoto err_out;",
                "",
                "\tdacl_offset = le32_to_cpu(pntsd->dacloffset);",
                "\tif (!dacl_offset ||",
                "\t    (dacl_offset + sizeof(struct smb_acl) > pntsd_size))",
                "\t\tgoto err_out;",
                "\tacl_size = pntsd_size - dacl_offset;",
                "\tpdacl_size = le16_to_cpu(pdacl->size);",
                "\tif (pdacl_size > acl_size || pdacl_size < sizeof(struct smb_acl))",
                "\t\tgoto err_out;",
                "\t\tif (!(pdacl_size - sizeof(struct smb_acl)) &&",
                "\t\tgoto err_out;",
                "\t\taces_size = acl_size - sizeof(struct smb_acl);",
                "\t\t\tif (offsetof(struct smb_ace, access_req) > aces_size)",
                "\t\t\t\tbreak;",
                "\t\t\tace_size = le16_to_cpu(ace->size);",
                "\t\t\tif (ace_size > aces_size)",
                "\t\t\t\tbreak;",
                "\t\t\taces_size -= ace_size;",
                "\taces_size = acl_size - sizeof(struct smb_acl);",
                "\t\tif (offsetof(struct smb_ace, access_req) > aces_size)",
                "\t\t\tbreak;",
                "\t\tace_size = le16_to_cpu(ace->size);",
                "\t\tif (ace_size > aces_size)",
                "\t\t\tbreak;",
                "\t\taces_size -= ace_size;",
                ""
            ],
            "deleted": [
                "\tint rc = 0, acl_size;",
                "\tchar *end_of_acl;",
                "\tacl_size = ksmbd_vfs_get_sd_xattr(conn, user_ns,",
                "\t\t\t\t\t  path->dentry, &pntsd);",
                "\tif (acl_size <= 0 || !pntsd || !pntsd->dacloffset) {",
                "\t\tkfree(pntsd);",
                "\t\treturn 0;",
                "\t}",
                "\tend_of_acl = ((char *)pntsd) + acl_size;",
                "\tif (end_of_acl <= (char *)pdacl) {",
                "\t\tkfree(pntsd);",
                "\t\treturn 0;",
                "\t}",
                "\tif (end_of_acl < (char *)pdacl + le16_to_cpu(pdacl->size) ||",
                "\t    le16_to_cpu(pdacl->size) < sizeof(struct smb_acl)) {",
                "\t\tkfree(pntsd);",
                "\t\treturn 0;",
                "\t}",
                "\t\tif (!(le16_to_cpu(pdacl->size) - sizeof(struct smb_acl)) &&",
                "\t\tkfree(pntsd);",
                "\t\treturn 0;",
                "\t\t\tif (end_of_acl < (char *)ace)",
                "\t\t\t\tgoto err_out;",
                "\t\tif (end_of_acl < (char *)ace)",
                "\t\t\tgoto err_out;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-47942",
        "code_before_change": "int ksmbd_vfs_get_sd_xattr(struct ksmbd_conn *conn,\n\t\t\t   struct user_namespace *user_ns,\n\t\t\t   struct dentry *dentry,\n\t\t\t   struct smb_ntsd **pntsd)\n{\n\tint rc;\n\tstruct ndr n;\n\tstruct inode *inode = d_inode(dentry);\n\tstruct ndr acl_ndr = {0};\n\tstruct xattr_ntacl acl;\n\tstruct xattr_smb_acl *smb_acl = NULL, *def_smb_acl = NULL;\n\t__u8 cmp_hash[XATTR_SD_HASH_SIZE] = {0};\n\n\trc = ksmbd_vfs_getxattr(user_ns, dentry, XATTR_NAME_SD, &n.data);\n\tif (rc <= 0)\n\t\treturn rc;\n\n\tn.length = rc;\n\trc = ndr_decode_v4_ntacl(&n, &acl);\n\tif (rc)\n\t\tgoto free_n_data;\n\n\tsmb_acl = ksmbd_vfs_make_xattr_posix_acl(user_ns, inode,\n\t\t\t\t\t\t ACL_TYPE_ACCESS);\n\tif (S_ISDIR(inode->i_mode))\n\t\tdef_smb_acl = ksmbd_vfs_make_xattr_posix_acl(user_ns, inode,\n\t\t\t\t\t\t\t     ACL_TYPE_DEFAULT);\n\n\trc = ndr_encode_posix_acl(&acl_ndr, user_ns, inode, smb_acl,\n\t\t\t\t  def_smb_acl);\n\tif (rc) {\n\t\tpr_err(\"failed to encode ndr to posix acl\\n\");\n\t\tgoto out_free;\n\t}\n\n\trc = ksmbd_gen_sd_hash(conn, acl_ndr.data, acl_ndr.offset, cmp_hash);\n\tif (rc) {\n\t\tpr_err(\"failed to generate hash for ndr acl\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (memcmp(cmp_hash, acl.posix_acl_hash, XATTR_SD_HASH_SIZE)) {\n\t\tpr_err(\"hash value diff\\n\");\n\t\trc = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t*pntsd = acl.sd_buf;\n\t(*pntsd)->osidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->osidoffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\t(*pntsd)->gsidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->gsidoffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\t(*pntsd)->dacloffset = cpu_to_le32(le32_to_cpu((*pntsd)->dacloffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\n\trc = acl.sd_size;\nout_free:\n\tkfree(acl_ndr.data);\n\tkfree(smb_acl);\n\tkfree(def_smb_acl);\n\tif (rc < 0) {\n\t\tkfree(acl.sd_buf);\n\t\t*pntsd = NULL;\n\t}\n\nfree_n_data:\n\tkfree(n.data);\n\treturn rc;\n}",
        "code_after_change": "int ksmbd_vfs_get_sd_xattr(struct ksmbd_conn *conn,\n\t\t\t   struct user_namespace *user_ns,\n\t\t\t   struct dentry *dentry,\n\t\t\t   struct smb_ntsd **pntsd)\n{\n\tint rc;\n\tstruct ndr n;\n\tstruct inode *inode = d_inode(dentry);\n\tstruct ndr acl_ndr = {0};\n\tstruct xattr_ntacl acl;\n\tstruct xattr_smb_acl *smb_acl = NULL, *def_smb_acl = NULL;\n\t__u8 cmp_hash[XATTR_SD_HASH_SIZE] = {0};\n\n\trc = ksmbd_vfs_getxattr(user_ns, dentry, XATTR_NAME_SD, &n.data);\n\tif (rc <= 0)\n\t\treturn rc;\n\n\tn.length = rc;\n\trc = ndr_decode_v4_ntacl(&n, &acl);\n\tif (rc)\n\t\tgoto free_n_data;\n\n\tsmb_acl = ksmbd_vfs_make_xattr_posix_acl(user_ns, inode,\n\t\t\t\t\t\t ACL_TYPE_ACCESS);\n\tif (S_ISDIR(inode->i_mode))\n\t\tdef_smb_acl = ksmbd_vfs_make_xattr_posix_acl(user_ns, inode,\n\t\t\t\t\t\t\t     ACL_TYPE_DEFAULT);\n\n\trc = ndr_encode_posix_acl(&acl_ndr, user_ns, inode, smb_acl,\n\t\t\t\t  def_smb_acl);\n\tif (rc) {\n\t\tpr_err(\"failed to encode ndr to posix acl\\n\");\n\t\tgoto out_free;\n\t}\n\n\trc = ksmbd_gen_sd_hash(conn, acl_ndr.data, acl_ndr.offset, cmp_hash);\n\tif (rc) {\n\t\tpr_err(\"failed to generate hash for ndr acl\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (memcmp(cmp_hash, acl.posix_acl_hash, XATTR_SD_HASH_SIZE)) {\n\t\tpr_err(\"hash value diff\\n\");\n\t\trc = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t*pntsd = acl.sd_buf;\n\tif (acl.sd_size < sizeof(struct smb_ntsd)) {\n\t\tpr_err(\"sd size is invalid\\n\");\n\t\tgoto out_free;\n\t}\n\n\t(*pntsd)->osidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->osidoffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\t(*pntsd)->gsidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->gsidoffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\t(*pntsd)->dacloffset = cpu_to_le32(le32_to_cpu((*pntsd)->dacloffset) -\n\t\t\t\t\t   NDR_NTSD_OFFSETOF);\n\n\trc = acl.sd_size;\nout_free:\n\tkfree(acl_ndr.data);\n\tkfree(smb_acl);\n\tkfree(def_smb_acl);\n\tif (rc < 0) {\n\t\tkfree(acl.sd_buf);\n\t\t*pntsd = NULL;\n\t}\n\nfree_n_data:\n\tkfree(n.data);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -46,6 +46,11 @@\n \t}\n \n \t*pntsd = acl.sd_buf;\n+\tif (acl.sd_size < sizeof(struct smb_ntsd)) {\n+\t\tpr_err(\"sd size is invalid\\n\");\n+\t\tgoto out_free;\n+\t}\n+\n \t(*pntsd)->osidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->osidoffset) -\n \t\t\t\t\t   NDR_NTSD_OFFSETOF);\n \t(*pntsd)->gsidoffset = cpu_to_le32(le32_to_cpu((*pntsd)->gsidoffset) -",
        "function_modified_lines": {
            "added": [
                "\tif (acl.sd_size < sizeof(struct smb_ntsd)) {",
                "\t\tpr_err(\"sd size is invalid\\n\");",
                "\t\tgoto out_free;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is a heap-based buffer overflow in set_ntacl_dacl, related to use of SMB2_QUERY_INFO_HE after a malformed SMB2_SET_INFO_HE command."
    },
    {
        "cve_id": "CVE-2022-48423",
        "code_before_change": "struct ATTRIB *mi_enum_attr(struct mft_inode *mi, struct ATTRIB *attr)\n{\n\tconst struct MFT_REC *rec = mi->mrec;\n\tu32 used = le32_to_cpu(rec->used);\n\tu32 t32, off, asize;\n\tu16 t16;\n\n\tif (!attr) {\n\t\tu32 total = le32_to_cpu(rec->total);\n\n\t\toff = le16_to_cpu(rec->attr_off);\n\n\t\tif (used > total)\n\t\t\treturn NULL;\n\n\t\tif (off >= used || off < MFTRECORD_FIXUP_OFFSET_1 ||\n\t\t    !IS_ALIGNED(off, 4)) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/* Skip non-resident records. */\n\t\tif (!is_rec_inuse(rec))\n\t\t\treturn NULL;\n\n\t\tattr = Add2Ptr(rec, off);\n\t} else {\n\t\t/* Check if input attr inside record. */\n\t\toff = PtrOffset(rec, attr);\n\t\tif (off >= used)\n\t\t\treturn NULL;\n\n\t\tasize = le32_to_cpu(attr->size);\n\t\tif (asize < SIZEOF_RESIDENT) {\n\t\t\t/* Impossible 'cause we should not return such attribute. */\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (off + asize < off) {\n\t\t\t/* overflow check */\n\t\t\treturn NULL;\n\t\t}\n\n\t\tattr = Add2Ptr(attr, asize);\n\t\toff += asize;\n\t}\n\n\tasize = le32_to_cpu(attr->size);\n\n\t/* Can we use the first field (attr->type). */\n\tif (off + 8 > used) {\n\t\tstatic_assert(ALIGN(sizeof(enum ATTR_TYPE), 8) == 8);\n\t\treturn NULL;\n\t}\n\n\tif (attr->type == ATTR_END) {\n\t\t/* End of enumeration. */\n\t\treturn NULL;\n\t}\n\n\t/* 0x100 is last known attribute for now. */\n\tt32 = le32_to_cpu(attr->type);\n\tif ((t32 & 0xf) || (t32 > 0x100))\n\t\treturn NULL;\n\n\t/* Check boundary. */\n\tif (off + asize > used)\n\t\treturn NULL;\n\n\t/* Check size of attribute. */\n\tif (!attr->non_res) {\n\t\tif (asize < SIZEOF_RESIDENT)\n\t\t\treturn NULL;\n\n\t\tt16 = le16_to_cpu(attr->res.data_off);\n\n\t\tif (t16 > asize)\n\t\t\treturn NULL;\n\n\t\tt32 = le32_to_cpu(attr->res.data_size);\n\t\tif (t16 + t32 > asize)\n\t\t\treturn NULL;\n\n\t\treturn attr;\n\t}\n\n\t/* Check some nonresident fields. */\n\tif (attr->name_len &&\n\t    le16_to_cpu(attr->name_off) + sizeof(short) * attr->name_len >\n\t\t    le16_to_cpu(attr->nres.run_off)) {\n\t\treturn NULL;\n\t}\n\n\tif (attr->nres.svcn || !is_attr_ext(attr)) {\n\t\tif (asize + 8 < SIZEOF_NONRESIDENT)\n\t\t\treturn NULL;\n\n\t\tif (attr->nres.c_unit)\n\t\t\treturn NULL;\n\t} else if (asize + 8 < SIZEOF_NONRESIDENT_EX)\n\t\treturn NULL;\n\n\treturn attr;\n}",
        "code_after_change": "struct ATTRIB *mi_enum_attr(struct mft_inode *mi, struct ATTRIB *attr)\n{\n\tconst struct MFT_REC *rec = mi->mrec;\n\tu32 used = le32_to_cpu(rec->used);\n\tu32 t32, off, asize;\n\tu16 t16;\n\n\tif (!attr) {\n\t\tu32 total = le32_to_cpu(rec->total);\n\n\t\toff = le16_to_cpu(rec->attr_off);\n\n\t\tif (used > total)\n\t\t\treturn NULL;\n\n\t\tif (off >= used || off < MFTRECORD_FIXUP_OFFSET_1 ||\n\t\t    !IS_ALIGNED(off, 4)) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/* Skip non-resident records. */\n\t\tif (!is_rec_inuse(rec))\n\t\t\treturn NULL;\n\n\t\tattr = Add2Ptr(rec, off);\n\t} else {\n\t\t/* Check if input attr inside record. */\n\t\toff = PtrOffset(rec, attr);\n\t\tif (off >= used)\n\t\t\treturn NULL;\n\n\t\tasize = le32_to_cpu(attr->size);\n\t\tif (asize < SIZEOF_RESIDENT) {\n\t\t\t/* Impossible 'cause we should not return such attribute. */\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (off + asize < off) {\n\t\t\t/* overflow check */\n\t\t\treturn NULL;\n\t\t}\n\n\t\tattr = Add2Ptr(attr, asize);\n\t\toff += asize;\n\t}\n\n\tasize = le32_to_cpu(attr->size);\n\n\t/* Can we use the first field (attr->type). */\n\tif (off + 8 > used) {\n\t\tstatic_assert(ALIGN(sizeof(enum ATTR_TYPE), 8) == 8);\n\t\treturn NULL;\n\t}\n\n\tif (attr->type == ATTR_END) {\n\t\t/* End of enumeration. */\n\t\treturn NULL;\n\t}\n\n\t/* 0x100 is last known attribute for now. */\n\tt32 = le32_to_cpu(attr->type);\n\tif ((t32 & 0xf) || (t32 > 0x100))\n\t\treturn NULL;\n\n\t/* Check boundary. */\n\tif (off + asize > used)\n\t\treturn NULL;\n\n\t/* Check size of attribute. */\n\tif (!attr->non_res) {\n\t\tif (asize < SIZEOF_RESIDENT)\n\t\t\treturn NULL;\n\n\t\tt16 = le16_to_cpu(attr->res.data_off);\n\n\t\tif (t16 > asize)\n\t\t\treturn NULL;\n\n\t\tt32 = le32_to_cpu(attr->res.data_size);\n\t\tif (t16 + t32 > asize)\n\t\t\treturn NULL;\n\n\t\tif (attr->name_len &&\n\t\t    le16_to_cpu(attr->name_off) + sizeof(short) * attr->name_len > t16) {\n\t\t\treturn NULL;\n\t\t}\n\n\t\treturn attr;\n\t}\n\n\t/* Check some nonresident fields. */\n\tif (attr->name_len &&\n\t    le16_to_cpu(attr->name_off) + sizeof(short) * attr->name_len >\n\t\t    le16_to_cpu(attr->nres.run_off)) {\n\t\treturn NULL;\n\t}\n\n\tif (attr->nres.svcn || !is_attr_ext(attr)) {\n\t\tif (asize + 8 < SIZEOF_NONRESIDENT)\n\t\t\treturn NULL;\n\n\t\tif (attr->nres.c_unit)\n\t\t\treturn NULL;\n\t} else if (asize + 8 < SIZEOF_NONRESIDENT_EX)\n\t\treturn NULL;\n\n\treturn attr;\n}",
        "patch": "--- code before\n+++ code after\n@@ -80,6 +80,11 @@\n \t\tif (t16 + t32 > asize)\n \t\t\treturn NULL;\n \n+\t\tif (attr->name_len &&\n+\t\t    le16_to_cpu(attr->name_off) + sizeof(short) * attr->name_len > t16) {\n+\t\t\treturn NULL;\n+\t\t}\n+\n \t\treturn attr;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (attr->name_len &&",
                "\t\t    le16_to_cpu(attr->name_off) + sizeof(short) * attr->name_len > t16) {",
                "\t\t\treturn NULL;",
                "\t\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel before 6.1.3, fs/ntfs3/record.c does not validate resident attribute names. An out-of-bounds write may occur."
    },
    {
        "cve_id": "CVE-2023-0210",
        "code_before_change": "int ksmbd_decode_ntlmssp_auth_blob(struct authenticate_message *authblob,\n\t\t\t\t   int blob_len, struct ksmbd_conn *conn,\n\t\t\t\t   struct ksmbd_session *sess)\n{\n\tchar *domain_name;\n\tunsigned int nt_off, dn_off;\n\tunsigned short nt_len, dn_len;\n\tint ret;\n\n\tif (blob_len < sizeof(struct authenticate_message)) {\n\t\tksmbd_debug(AUTH, \"negotiate blob len %d too small\\n\",\n\t\t\t    blob_len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (memcmp(authblob->Signature, \"NTLMSSP\", 8)) {\n\t\tksmbd_debug(AUTH, \"blob signature incorrect %s\\n\",\n\t\t\t    authblob->Signature);\n\t\treturn -EINVAL;\n\t}\n\n\tnt_off = le32_to_cpu(authblob->NtChallengeResponse.BufferOffset);\n\tnt_len = le16_to_cpu(authblob->NtChallengeResponse.Length);\n\tdn_off = le32_to_cpu(authblob->DomainName.BufferOffset);\n\tdn_len = le16_to_cpu(authblob->DomainName.Length);\n\n\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len)\n\t\treturn -EINVAL;\n\n\t/* TODO : use domain name that imported from configuration file */\n\tdomain_name = smb_strndup_from_utf16((const char *)authblob + dn_off,\n\t\t\t\t\t     dn_len, true, conn->local_nls);\n\tif (IS_ERR(domain_name))\n\t\treturn PTR_ERR(domain_name);\n\n\t/* process NTLMv2 authentication */\n\tksmbd_debug(AUTH, \"decode_ntlmssp_authenticate_blob dname%s\\n\",\n\t\t    domain_name);\n\tret = ksmbd_auth_ntlmv2(conn, sess,\n\t\t\t\t(struct ntlmv2_resp *)((char *)authblob + nt_off),\n\t\t\t\tnt_len - CIFS_ENCPWD_SIZE,\n\t\t\t\tdomain_name, conn->ntlmssp.cryptkey);\n\tkfree(domain_name);\n\n\t/* The recovered secondary session key */\n\tif (conn->ntlmssp.client_flags & NTLMSSP_NEGOTIATE_KEY_XCH) {\n\t\tstruct arc4_ctx *ctx_arc4;\n\t\tunsigned int sess_key_off, sess_key_len;\n\n\t\tsess_key_off = le32_to_cpu(authblob->SessionKey.BufferOffset);\n\t\tsess_key_len = le16_to_cpu(authblob->SessionKey.Length);\n\n\t\tif (blob_len < (u64)sess_key_off + sess_key_len)\n\t\t\treturn -EINVAL;\n\n\t\tctx_arc4 = kmalloc(sizeof(*ctx_arc4), GFP_KERNEL);\n\t\tif (!ctx_arc4)\n\t\t\treturn -ENOMEM;\n\n\t\tcifs_arc4_setkey(ctx_arc4, sess->sess_key,\n\t\t\t\t SMB2_NTLMV2_SESSKEY_SIZE);\n\t\tcifs_arc4_crypt(ctx_arc4, sess->sess_key,\n\t\t\t\t(char *)authblob + sess_key_off, sess_key_len);\n\t\tkfree_sensitive(ctx_arc4);\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "int ksmbd_decode_ntlmssp_auth_blob(struct authenticate_message *authblob,\n\t\t\t\t   int blob_len, struct ksmbd_conn *conn,\n\t\t\t\t   struct ksmbd_session *sess)\n{\n\tchar *domain_name;\n\tunsigned int nt_off, dn_off;\n\tunsigned short nt_len, dn_len;\n\tint ret;\n\n\tif (blob_len < sizeof(struct authenticate_message)) {\n\t\tksmbd_debug(AUTH, \"negotiate blob len %d too small\\n\",\n\t\t\t    blob_len);\n\t\treturn -EINVAL;\n\t}\n\n\tif (memcmp(authblob->Signature, \"NTLMSSP\", 8)) {\n\t\tksmbd_debug(AUTH, \"blob signature incorrect %s\\n\",\n\t\t\t    authblob->Signature);\n\t\treturn -EINVAL;\n\t}\n\n\tnt_off = le32_to_cpu(authblob->NtChallengeResponse.BufferOffset);\n\tnt_len = le16_to_cpu(authblob->NtChallengeResponse.Length);\n\tdn_off = le32_to_cpu(authblob->DomainName.BufferOffset);\n\tdn_len = le16_to_cpu(authblob->DomainName.Length);\n\n\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len ||\n\t    nt_len < CIFS_ENCPWD_SIZE)\n\t\treturn -EINVAL;\n\n\t/* TODO : use domain name that imported from configuration file */\n\tdomain_name = smb_strndup_from_utf16((const char *)authblob + dn_off,\n\t\t\t\t\t     dn_len, true, conn->local_nls);\n\tif (IS_ERR(domain_name))\n\t\treturn PTR_ERR(domain_name);\n\n\t/* process NTLMv2 authentication */\n\tksmbd_debug(AUTH, \"decode_ntlmssp_authenticate_blob dname%s\\n\",\n\t\t    domain_name);\n\tret = ksmbd_auth_ntlmv2(conn, sess,\n\t\t\t\t(struct ntlmv2_resp *)((char *)authblob + nt_off),\n\t\t\t\tnt_len - CIFS_ENCPWD_SIZE,\n\t\t\t\tdomain_name, conn->ntlmssp.cryptkey);\n\tkfree(domain_name);\n\n\t/* The recovered secondary session key */\n\tif (conn->ntlmssp.client_flags & NTLMSSP_NEGOTIATE_KEY_XCH) {\n\t\tstruct arc4_ctx *ctx_arc4;\n\t\tunsigned int sess_key_off, sess_key_len;\n\n\t\tsess_key_off = le32_to_cpu(authblob->SessionKey.BufferOffset);\n\t\tsess_key_len = le16_to_cpu(authblob->SessionKey.Length);\n\n\t\tif (blob_len < (u64)sess_key_off + sess_key_len)\n\t\t\treturn -EINVAL;\n\n\t\tctx_arc4 = kmalloc(sizeof(*ctx_arc4), GFP_KERNEL);\n\t\tif (!ctx_arc4)\n\t\t\treturn -ENOMEM;\n\n\t\tcifs_arc4_setkey(ctx_arc4, sess->sess_key,\n\t\t\t\t SMB2_NTLMV2_SESSKEY_SIZE);\n\t\tcifs_arc4_crypt(ctx_arc4, sess->sess_key,\n\t\t\t\t(char *)authblob + sess_key_off, sess_key_len);\n\t\tkfree_sensitive(ctx_arc4);\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,7 +24,8 @@\n \tdn_off = le32_to_cpu(authblob->DomainName.BufferOffset);\n \tdn_len = le16_to_cpu(authblob->DomainName.Length);\n \n-\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len)\n+\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len ||\n+\t    nt_len < CIFS_ENCPWD_SIZE)\n \t\treturn -EINVAL;\n \n \t/* TODO : use domain name that imported from configuration file */",
        "function_modified_lines": {
            "added": [
                "\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len ||",
                "\t    nt_len < CIFS_ENCPWD_SIZE)"
            ],
            "deleted": [
                "\tif (blob_len < (u64)dn_off + dn_len || blob_len < (u64)nt_off + nt_len)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A bug affects the Linux kernel\u2019s ksmbd NTLMv2 authentication and is known to crash the OS immediately in Linux-based systems."
    },
    {
        "cve_id": "CVE-2023-1073",
        "code_before_change": "struct hid_report *hid_validate_values(struct hid_device *hid,\n\t\t\t\t       enum hid_report_type type, unsigned int id,\n\t\t\t\t       unsigned int field_index,\n\t\t\t\t       unsigned int report_counts)\n{\n\tstruct hid_report *report;\n\n\tif (type > HID_FEATURE_REPORT) {\n\t\thid_err(hid, \"invalid HID report type %u\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tif (id >= HID_MAX_IDS) {\n\t\thid_err(hid, \"invalid HID report id %u\\n\", id);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * Explicitly not using hid_get_report() here since it depends on\n\t * ->numbered being checked, which may not always be the case when\n\t * drivers go to access report values.\n\t */\n\tif (id == 0) {\n\t\t/*\n\t\t * Validating on id 0 means we should examine the first\n\t\t * report in the list.\n\t\t */\n\t\treport = list_entry(\n\t\t\t\thid->report_enum[type].report_list.next,\n\t\t\t\tstruct hid_report, list);\n\t} else {\n\t\treport = hid->report_enum[type].report_id_hash[id];\n\t}\n\tif (!report) {\n\t\thid_err(hid, \"missing %s %u\\n\", hid_report_names[type], id);\n\t\treturn NULL;\n\t}\n\tif (report->maxfield <= field_index) {\n\t\thid_err(hid, \"not enough fields in %s %u\\n\",\n\t\t\thid_report_names[type], id);\n\t\treturn NULL;\n\t}\n\tif (report->field[field_index]->report_count < report_counts) {\n\t\thid_err(hid, \"not enough values in %s %u field %u\\n\",\n\t\t\thid_report_names[type], id, field_index);\n\t\treturn NULL;\n\t}\n\treturn report;\n}",
        "code_after_change": "struct hid_report *hid_validate_values(struct hid_device *hid,\n\t\t\t\t       enum hid_report_type type, unsigned int id,\n\t\t\t\t       unsigned int field_index,\n\t\t\t\t       unsigned int report_counts)\n{\n\tstruct hid_report *report;\n\n\tif (type > HID_FEATURE_REPORT) {\n\t\thid_err(hid, \"invalid HID report type %u\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tif (id >= HID_MAX_IDS) {\n\t\thid_err(hid, \"invalid HID report id %u\\n\", id);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * Explicitly not using hid_get_report() here since it depends on\n\t * ->numbered being checked, which may not always be the case when\n\t * drivers go to access report values.\n\t */\n\tif (id == 0) {\n\t\t/*\n\t\t * Validating on id 0 means we should examine the first\n\t\t * report in the list.\n\t\t */\n\t\treport = list_first_entry_or_null(\n\t\t\t\t&hid->report_enum[type].report_list,\n\t\t\t\tstruct hid_report, list);\n\t} else {\n\t\treport = hid->report_enum[type].report_id_hash[id];\n\t}\n\tif (!report) {\n\t\thid_err(hid, \"missing %s %u\\n\", hid_report_names[type], id);\n\t\treturn NULL;\n\t}\n\tif (report->maxfield <= field_index) {\n\t\thid_err(hid, \"not enough fields in %s %u\\n\",\n\t\t\thid_report_names[type], id);\n\t\treturn NULL;\n\t}\n\tif (report->field[field_index]->report_count < report_counts) {\n\t\thid_err(hid, \"not enough values in %s %u field %u\\n\",\n\t\t\thid_report_names[type], id, field_index);\n\t\treturn NULL;\n\t}\n\treturn report;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,8 @@\n \t\t * Validating on id 0 means we should examine the first\n \t\t * report in the list.\n \t\t */\n-\t\treport = list_entry(\n-\t\t\t\thid->report_enum[type].report_list.next,\n+\t\treport = list_first_entry_or_null(\n+\t\t\t\t&hid->report_enum[type].report_list,\n \t\t\t\tstruct hid_report, list);\n \t} else {\n \t\treport = hid->report_enum[type].report_id_hash[id];",
        "function_modified_lines": {
            "added": [
                "\t\treport = list_first_entry_or_null(",
                "\t\t\t\t&hid->report_enum[type].report_list,"
            ],
            "deleted": [
                "\t\treport = list_entry(",
                "\t\t\t\thid->report_enum[type].report_list.next,"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A memory corruption flaw was found in the Linux kernel\u2019s human interface device (HID) subsystem in how a user inserts a malicious USB device. This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2023-2124",
        "code_before_change": "STATIC int\nxlog_recover_buf_commit_pass2(\n\tstruct xlog\t\t\t*log,\n\tstruct list_head\t\t*buffer_list,\n\tstruct xlog_recover_item\t*item,\n\txfs_lsn_t\t\t\tcurrent_lsn)\n{\n\tstruct xfs_buf_log_format\t*buf_f = item->ri_buf[0].i_addr;\n\tstruct xfs_mount\t\t*mp = log->l_mp;\n\tstruct xfs_buf\t\t\t*bp;\n\tint\t\t\t\terror;\n\tuint\t\t\t\tbuf_flags;\n\txfs_lsn_t\t\t\tlsn;\n\n\t/*\n\t * In this pass we only want to recover all the buffers which have\n\t * not been cancelled and are not cancellation buffers themselves.\n\t */\n\tif (buf_f->blf_flags & XFS_BLF_CANCEL) {\n\t\tif (xlog_put_buffer_cancelled(log, buf_f->blf_blkno,\n\t\t\t\tbuf_f->blf_len))\n\t\t\tgoto cancelled;\n\t} else {\n\n\t\tif (xlog_is_buffer_cancelled(log, buf_f->blf_blkno,\n\t\t\t\tbuf_f->blf_len))\n\t\t\tgoto cancelled;\n\t}\n\n\ttrace_xfs_log_recover_buf_recover(log, buf_f);\n\n\tbuf_flags = 0;\n\tif (buf_f->blf_flags & XFS_BLF_INODE_BUF)\n\t\tbuf_flags |= XBF_UNMAPPED;\n\n\terror = xfs_buf_read(mp->m_ddev_targp, buf_f->blf_blkno, buf_f->blf_len,\n\t\t\t  buf_flags, &bp, NULL);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * Recover the buffer only if we get an LSN from it and it's less than\n\t * the lsn of the transaction we are replaying.\n\t *\n\t * Note that we have to be extremely careful of readahead here.\n\t * Readahead does not attach verfiers to the buffers so if we don't\n\t * actually do any replay after readahead because of the LSN we found\n\t * in the buffer if more recent than that current transaction then we\n\t * need to attach the verifier directly. Failure to do so can lead to\n\t * future recovery actions (e.g. EFI and unlinked list recovery) can\n\t * operate on the buffers and they won't get the verifier attached. This\n\t * can lead to blocks on disk having the correct content but a stale\n\t * CRC.\n\t *\n\t * It is safe to assume these clean buffers are currently up to date.\n\t * If the buffer is dirtied by a later transaction being replayed, then\n\t * the verifier will be reset to match whatever recover turns that\n\t * buffer into.\n\t */\n\tlsn = xlog_recover_get_buf_lsn(mp, bp, buf_f);\n\tif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\n\t\ttrace_xfs_log_recover_buf_skip(log, buf_f);\n\t\txlog_recover_validate_buf_type(mp, bp, buf_f, NULLCOMMITLSN);\n\t\tgoto out_release;\n\t}\n\n\tif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\n\t\terror = xlog_recover_do_inode_buffer(mp, item, bp, buf_f);\n\t\tif (error)\n\t\t\tgoto out_release;\n\t} else if (buf_f->blf_flags &\n\t\t  (XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\n\t\tbool\tdirty;\n\n\t\tdirty = xlog_recover_do_dquot_buffer(mp, log, item, bp, buf_f);\n\t\tif (!dirty)\n\t\t\tgoto out_release;\n\t} else {\n\t\txlog_recover_do_reg_buffer(mp, item, bp, buf_f, current_lsn);\n\t}\n\n\t/*\n\t * Perform delayed write on the buffer.  Asynchronous writes will be\n\t * slower when taking into account all the buffers to be flushed.\n\t *\n\t * Also make sure that only inode buffers with good sizes stay in\n\t * the buffer cache.  The kernel moves inodes in buffers of 1 block\n\t * or inode_cluster_size bytes, whichever is bigger.  The inode\n\t * buffers in the log can be a different size if the log was generated\n\t * by an older kernel using unclustered inode buffers or a newer kernel\n\t * running with a different inode cluster size.  Regardless, if\n\t * the inode buffer size isn't max(blocksize, inode_cluster_size)\n\t * for *our* value of inode_cluster_size, then we need to keep\n\t * the buffer out of the buffer cache so that the buffer won't\n\t * overlap with future reads of those inodes.\n\t */\n\tif (XFS_DINODE_MAGIC ==\n\t    be16_to_cpu(*((__be16 *)xfs_buf_offset(bp, 0))) &&\n\t    (BBTOB(bp->b_length) != M_IGEO(log->l_mp)->inode_cluster_size)) {\n\t\txfs_buf_stale(bp);\n\t\terror = xfs_bwrite(bp);\n\t} else {\n\t\tASSERT(bp->b_mount == mp);\n\t\tbp->b_flags |= _XBF_LOGRECOVERY;\n\t\txfs_buf_delwri_queue(bp, buffer_list);\n\t}\n\nout_release:\n\txfs_buf_relse(bp);\n\treturn error;\ncancelled:\n\ttrace_xfs_log_recover_buf_cancel(log, buf_f);\n\treturn 0;\n}",
        "code_after_change": "STATIC int\nxlog_recover_buf_commit_pass2(\n\tstruct xlog\t\t\t*log,\n\tstruct list_head\t\t*buffer_list,\n\tstruct xlog_recover_item\t*item,\n\txfs_lsn_t\t\t\tcurrent_lsn)\n{\n\tstruct xfs_buf_log_format\t*buf_f = item->ri_buf[0].i_addr;\n\tstruct xfs_mount\t\t*mp = log->l_mp;\n\tstruct xfs_buf\t\t\t*bp;\n\tint\t\t\t\terror;\n\tuint\t\t\t\tbuf_flags;\n\txfs_lsn_t\t\t\tlsn;\n\n\t/*\n\t * In this pass we only want to recover all the buffers which have\n\t * not been cancelled and are not cancellation buffers themselves.\n\t */\n\tif (buf_f->blf_flags & XFS_BLF_CANCEL) {\n\t\tif (xlog_put_buffer_cancelled(log, buf_f->blf_blkno,\n\t\t\t\tbuf_f->blf_len))\n\t\t\tgoto cancelled;\n\t} else {\n\n\t\tif (xlog_is_buffer_cancelled(log, buf_f->blf_blkno,\n\t\t\t\tbuf_f->blf_len))\n\t\t\tgoto cancelled;\n\t}\n\n\ttrace_xfs_log_recover_buf_recover(log, buf_f);\n\n\tbuf_flags = 0;\n\tif (buf_f->blf_flags & XFS_BLF_INODE_BUF)\n\t\tbuf_flags |= XBF_UNMAPPED;\n\n\terror = xfs_buf_read(mp->m_ddev_targp, buf_f->blf_blkno, buf_f->blf_len,\n\t\t\t  buf_flags, &bp, NULL);\n\tif (error)\n\t\treturn error;\n\n\t/*\n\t * Recover the buffer only if we get an LSN from it and it's less than\n\t * the lsn of the transaction we are replaying.\n\t *\n\t * Note that we have to be extremely careful of readahead here.\n\t * Readahead does not attach verfiers to the buffers so if we don't\n\t * actually do any replay after readahead because of the LSN we found\n\t * in the buffer if more recent than that current transaction then we\n\t * need to attach the verifier directly. Failure to do so can lead to\n\t * future recovery actions (e.g. EFI and unlinked list recovery) can\n\t * operate on the buffers and they won't get the verifier attached. This\n\t * can lead to blocks on disk having the correct content but a stale\n\t * CRC.\n\t *\n\t * It is safe to assume these clean buffers are currently up to date.\n\t * If the buffer is dirtied by a later transaction being replayed, then\n\t * the verifier will be reset to match whatever recover turns that\n\t * buffer into.\n\t */\n\tlsn = xlog_recover_get_buf_lsn(mp, bp, buf_f);\n\tif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\n\t\ttrace_xfs_log_recover_buf_skip(log, buf_f);\n\t\txlog_recover_validate_buf_type(mp, bp, buf_f, NULLCOMMITLSN);\n\n\t\t/*\n\t\t * We're skipping replay of this buffer log item due to the log\n\t\t * item LSN being behind the ondisk buffer.  Verify the buffer\n\t\t * contents since we aren't going to run the write verifier.\n\t\t */\n\t\tif (bp->b_ops) {\n\t\t\tbp->b_ops->verify_read(bp);\n\t\t\terror = bp->b_error;\n\t\t}\n\t\tgoto out_release;\n\t}\n\n\tif (buf_f->blf_flags & XFS_BLF_INODE_BUF) {\n\t\terror = xlog_recover_do_inode_buffer(mp, item, bp, buf_f);\n\t\tif (error)\n\t\t\tgoto out_release;\n\t} else if (buf_f->blf_flags &\n\t\t  (XFS_BLF_UDQUOT_BUF|XFS_BLF_PDQUOT_BUF|XFS_BLF_GDQUOT_BUF)) {\n\t\tbool\tdirty;\n\n\t\tdirty = xlog_recover_do_dquot_buffer(mp, log, item, bp, buf_f);\n\t\tif (!dirty)\n\t\t\tgoto out_release;\n\t} else {\n\t\txlog_recover_do_reg_buffer(mp, item, bp, buf_f, current_lsn);\n\t}\n\n\t/*\n\t * Perform delayed write on the buffer.  Asynchronous writes will be\n\t * slower when taking into account all the buffers to be flushed.\n\t *\n\t * Also make sure that only inode buffers with good sizes stay in\n\t * the buffer cache.  The kernel moves inodes in buffers of 1 block\n\t * or inode_cluster_size bytes, whichever is bigger.  The inode\n\t * buffers in the log can be a different size if the log was generated\n\t * by an older kernel using unclustered inode buffers or a newer kernel\n\t * running with a different inode cluster size.  Regardless, if\n\t * the inode buffer size isn't max(blocksize, inode_cluster_size)\n\t * for *our* value of inode_cluster_size, then we need to keep\n\t * the buffer out of the buffer cache so that the buffer won't\n\t * overlap with future reads of those inodes.\n\t */\n\tif (XFS_DINODE_MAGIC ==\n\t    be16_to_cpu(*((__be16 *)xfs_buf_offset(bp, 0))) &&\n\t    (BBTOB(bp->b_length) != M_IGEO(log->l_mp)->inode_cluster_size)) {\n\t\txfs_buf_stale(bp);\n\t\terror = xfs_bwrite(bp);\n\t} else {\n\t\tASSERT(bp->b_mount == mp);\n\t\tbp->b_flags |= _XBF_LOGRECOVERY;\n\t\txfs_buf_delwri_queue(bp, buffer_list);\n\t}\n\nout_release:\n\txfs_buf_relse(bp);\n\treturn error;\ncancelled:\n\ttrace_xfs_log_recover_buf_cancel(log, buf_f);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,6 +61,16 @@\n \tif (lsn && lsn != -1 && XFS_LSN_CMP(lsn, current_lsn) >= 0) {\n \t\ttrace_xfs_log_recover_buf_skip(log, buf_f);\n \t\txlog_recover_validate_buf_type(mp, bp, buf_f, NULLCOMMITLSN);\n+\n+\t\t/*\n+\t\t * We're skipping replay of this buffer log item due to the log\n+\t\t * item LSN being behind the ondisk buffer.  Verify the buffer\n+\t\t * contents since we aren't going to run the write verifier.\n+\t\t */\n+\t\tif (bp->b_ops) {\n+\t\t\tbp->b_ops->verify_read(bp);\n+\t\t\terror = bp->b_error;\n+\t\t}\n \t\tgoto out_release;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\t\t/*",
                "\t\t * We're skipping replay of this buffer log item due to the log",
                "\t\t * item LSN being behind the ondisk buffer.  Verify the buffer",
                "\t\t * contents since we aren't going to run the write verifier.",
                "\t\t */",
                "\t\tif (bp->b_ops) {",
                "\t\t\tbp->b_ops->verify_read(bp);",
                "\t\t\terror = bp->b_error;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds memory access flaw was found in the Linux kernel\u2019s XFS file system in how a user restores an XFS image after failure (with a dirty log journal). This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2023-21255",
        "code_before_change": "static void\nbinder_free_buf(struct binder_proc *proc,\n\t\tstruct binder_thread *thread,\n\t\tstruct binder_buffer *buffer, bool is_failure)\n{\n\tbinder_inner_proc_lock(proc);\n\tif (buffer->transaction) {\n\t\tbuffer->transaction->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tif (buffer->async_transaction && buffer->target_node) {\n\t\tstruct binder_node *buf_node;\n\t\tstruct binder_work *w;\n\n\t\tbuf_node = buffer->target_node;\n\t\tbinder_node_inner_lock(buf_node);\n\t\tBUG_ON(!buf_node->has_async_transaction);\n\t\tBUG_ON(buf_node->proc != proc);\n\t\tw = binder_dequeue_work_head_ilocked(\n\t\t\t\t&buf_node->async_todo);\n\t\tif (!w) {\n\t\t\tbuf_node->has_async_transaction = false;\n\t\t} else {\n\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\tw, &proc->todo);\n\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t}\n\t\tbinder_node_inner_unlock(buf_node);\n\t}\n\ttrace_binder_transaction_buffer_release(buffer);\n\tbinder_transaction_buffer_release(proc, thread, buffer, 0, is_failure);\n\tbinder_alloc_free_buf(&proc->alloc, buffer);\n}",
        "code_after_change": "static void\nbinder_free_buf(struct binder_proc *proc,\n\t\tstruct binder_thread *thread,\n\t\tstruct binder_buffer *buffer, bool is_failure)\n{\n\tbinder_inner_proc_lock(proc);\n\tif (buffer->transaction) {\n\t\tbuffer->transaction->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tif (buffer->async_transaction && buffer->target_node) {\n\t\tstruct binder_node *buf_node;\n\t\tstruct binder_work *w;\n\n\t\tbuf_node = buffer->target_node;\n\t\tbinder_node_inner_lock(buf_node);\n\t\tBUG_ON(!buf_node->has_async_transaction);\n\t\tBUG_ON(buf_node->proc != proc);\n\t\tw = binder_dequeue_work_head_ilocked(\n\t\t\t\t&buf_node->async_todo);\n\t\tif (!w) {\n\t\t\tbuf_node->has_async_transaction = false;\n\t\t} else {\n\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\tw, &proc->todo);\n\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t}\n\t\tbinder_node_inner_unlock(buf_node);\n\t}\n\ttrace_binder_transaction_buffer_release(buffer);\n\tbinder_release_entire_buffer(proc, thread, buffer, is_failure);\n\tbinder_alloc_free_buf(&proc->alloc, buffer);\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,6 +29,6 @@\n \t\tbinder_node_inner_unlock(buf_node);\n \t}\n \ttrace_binder_transaction_buffer_release(buffer);\n-\tbinder_transaction_buffer_release(proc, thread, buffer, 0, is_failure);\n+\tbinder_release_entire_buffer(proc, thread, buffer, is_failure);\n \tbinder_alloc_free_buf(&proc->alloc, buffer);\n }",
        "function_modified_lines": {
            "added": [
                "\tbinder_release_entire_buffer(proc, thread, buffer, is_failure);"
            ],
            "deleted": [
                "\tbinder_transaction_buffer_release(proc, thread, buffer, 0, is_failure);"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In multiple functions of binder.c, there is a possible memory corruption due to a use after free. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.\n\n"
    },
    {
        "cve_id": "CVE-2023-21255",
        "code_before_change": "static int binder_proc_transaction(struct binder_transaction *t,\n\t\t\t\t    struct binder_proc *proc,\n\t\t\t\t    struct binder_thread *thread)\n{\n\tstruct binder_node *node = t->buffer->target_node;\n\tbool oneway = !!(t->flags & TF_ONE_WAY);\n\tbool pending_async = false;\n\tstruct binder_transaction *t_outdated = NULL;\n\tbool frozen = false;\n\n\tBUG_ON(!node);\n\tbinder_node_lock(node);\n\tif (oneway) {\n\t\tBUG_ON(thread);\n\t\tif (node->has_async_transaction)\n\t\t\tpending_async = true;\n\t\telse\n\t\t\tnode->has_async_transaction = true;\n\t}\n\n\tbinder_inner_proc_lock(proc);\n\tif (proc->is_frozen) {\n\t\tfrozen = true;\n\t\tproc->sync_recv |= !oneway;\n\t\tproc->async_recv |= oneway;\n\t}\n\n\tif ((frozen && !oneway) || proc->is_dead ||\n\t\t\t(thread && thread->is_dead)) {\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_node_unlock(node);\n\t\treturn frozen ? BR_FROZEN_REPLY : BR_DEAD_REPLY;\n\t}\n\n\tif (!thread && !pending_async)\n\t\tthread = binder_select_thread_ilocked(proc);\n\n\tif (thread) {\n\t\tbinder_enqueue_thread_work_ilocked(thread, &t->work);\n\t} else if (!pending_async) {\n\t\tbinder_enqueue_work_ilocked(&t->work, &proc->todo);\n\t} else {\n\t\tif ((t->flags & TF_UPDATE_TXN) && frozen) {\n\t\t\tt_outdated = binder_find_outdated_transaction_ilocked(t,\n\t\t\t\t\t\t\t\t\t      &node->async_todo);\n\t\t\tif (t_outdated) {\n\t\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t\t     \"txn %d supersedes %d\\n\",\n\t\t\t\t\t     t->debug_id, t_outdated->debug_id);\n\t\t\t\tlist_del_init(&t_outdated->work.entry);\n\t\t\t\tproc->outstanding_txns--;\n\t\t\t}\n\t\t}\n\t\tbinder_enqueue_work_ilocked(&t->work, &node->async_todo);\n\t}\n\n\tif (!pending_async)\n\t\tbinder_wakeup_thread_ilocked(proc, thread, !oneway /* sync */);\n\n\tproc->outstanding_txns++;\n\tbinder_inner_proc_unlock(proc);\n\tbinder_node_unlock(node);\n\n\t/*\n\t * To reduce potential contention, free the outdated transaction and\n\t * buffer after releasing the locks.\n\t */\n\tif (t_outdated) {\n\t\tstruct binder_buffer *buffer = t_outdated->buffer;\n\n\t\tt_outdated->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t\ttrace_binder_transaction_update_buffer_release(buffer);\n\t\tbinder_transaction_buffer_release(proc, NULL, buffer, 0, 0);\n\t\tbinder_alloc_free_buf(&proc->alloc, buffer);\n\t\tkfree(t_outdated);\n\t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\n\t}\n\n\tif (oneway && frozen)\n\t\treturn BR_TRANSACTION_PENDING_FROZEN;\n\n\treturn 0;\n}",
        "code_after_change": "static int binder_proc_transaction(struct binder_transaction *t,\n\t\t\t\t    struct binder_proc *proc,\n\t\t\t\t    struct binder_thread *thread)\n{\n\tstruct binder_node *node = t->buffer->target_node;\n\tbool oneway = !!(t->flags & TF_ONE_WAY);\n\tbool pending_async = false;\n\tstruct binder_transaction *t_outdated = NULL;\n\tbool frozen = false;\n\n\tBUG_ON(!node);\n\tbinder_node_lock(node);\n\tif (oneway) {\n\t\tBUG_ON(thread);\n\t\tif (node->has_async_transaction)\n\t\t\tpending_async = true;\n\t\telse\n\t\t\tnode->has_async_transaction = true;\n\t}\n\n\tbinder_inner_proc_lock(proc);\n\tif (proc->is_frozen) {\n\t\tfrozen = true;\n\t\tproc->sync_recv |= !oneway;\n\t\tproc->async_recv |= oneway;\n\t}\n\n\tif ((frozen && !oneway) || proc->is_dead ||\n\t\t\t(thread && thread->is_dead)) {\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_node_unlock(node);\n\t\treturn frozen ? BR_FROZEN_REPLY : BR_DEAD_REPLY;\n\t}\n\n\tif (!thread && !pending_async)\n\t\tthread = binder_select_thread_ilocked(proc);\n\n\tif (thread) {\n\t\tbinder_enqueue_thread_work_ilocked(thread, &t->work);\n\t} else if (!pending_async) {\n\t\tbinder_enqueue_work_ilocked(&t->work, &proc->todo);\n\t} else {\n\t\tif ((t->flags & TF_UPDATE_TXN) && frozen) {\n\t\t\tt_outdated = binder_find_outdated_transaction_ilocked(t,\n\t\t\t\t\t\t\t\t\t      &node->async_todo);\n\t\t\tif (t_outdated) {\n\t\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t\t     \"txn %d supersedes %d\\n\",\n\t\t\t\t\t     t->debug_id, t_outdated->debug_id);\n\t\t\t\tlist_del_init(&t_outdated->work.entry);\n\t\t\t\tproc->outstanding_txns--;\n\t\t\t}\n\t\t}\n\t\tbinder_enqueue_work_ilocked(&t->work, &node->async_todo);\n\t}\n\n\tif (!pending_async)\n\t\tbinder_wakeup_thread_ilocked(proc, thread, !oneway /* sync */);\n\n\tproc->outstanding_txns++;\n\tbinder_inner_proc_unlock(proc);\n\tbinder_node_unlock(node);\n\n\t/*\n\t * To reduce potential contention, free the outdated transaction and\n\t * buffer after releasing the locks.\n\t */\n\tif (t_outdated) {\n\t\tstruct binder_buffer *buffer = t_outdated->buffer;\n\n\t\tt_outdated->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t\ttrace_binder_transaction_update_buffer_release(buffer);\n\t\tbinder_release_entire_buffer(proc, NULL, buffer, false);\n\t\tbinder_alloc_free_buf(&proc->alloc, buffer);\n\t\tkfree(t_outdated);\n\t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\n\t}\n\n\tif (oneway && frozen)\n\t\treturn BR_TRANSACTION_PENDING_FROZEN;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -71,7 +71,7 @@\n \t\tt_outdated->buffer = NULL;\n \t\tbuffer->transaction = NULL;\n \t\ttrace_binder_transaction_update_buffer_release(buffer);\n-\t\tbinder_transaction_buffer_release(proc, NULL, buffer, 0, 0);\n+\t\tbinder_release_entire_buffer(proc, NULL, buffer, false);\n \t\tbinder_alloc_free_buf(&proc->alloc, buffer);\n \t\tkfree(t_outdated);\n \t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);",
        "function_modified_lines": {
            "added": [
                "\t\tbinder_release_entire_buffer(proc, NULL, buffer, false);"
            ],
            "deleted": [
                "\t\tbinder_transaction_buffer_release(proc, NULL, buffer, 0, 0);"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "In multiple functions of binder.c, there is a possible memory corruption due to a use after free. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.\n\n"
    },
    {
        "cve_id": "CVE-2023-2194",
        "code_before_change": "static int slimpro_i2c_blkwr(struct slimpro_i2c_dev *ctx, u32 chip,\n\t\t\t     u32 addr, u32 addrlen, u32 protocol, u32 writelen,\n\t\t\t     void *data)\n{\n\tdma_addr_t paddr;\n\tu32 msg[3];\n\tint rc;\n\n\tmemcpy(ctx->dma_buffer, data, writelen);\n\tpaddr = dma_map_single(ctx->dev, ctx->dma_buffer, writelen,\n\t\t\t       DMA_TO_DEVICE);\n\tif (dma_mapping_error(ctx->dev, paddr)) {\n\t\tdev_err(&ctx->adapter.dev, \"Error in mapping dma buffer %p\\n\",\n\t\t\tctx->dma_buffer);\n\t\treturn -ENOMEM;\n\t}\n\n\tmsg[0] = SLIMPRO_IIC_ENCODE_MSG(SLIMPRO_IIC_BUS, chip, SLIMPRO_IIC_WRITE,\n\t\t\t\t\tprotocol, addrlen, writelen);\n\tmsg[1] = SLIMPRO_IIC_ENCODE_FLAG_BUFADDR |\n\t\t SLIMPRO_IIC_ENCODE_UPPER_BUFADDR(paddr) |\n\t\t SLIMPRO_IIC_ENCODE_ADDR(addr);\n\tmsg[2] = (u32)paddr;\n\n\tif (ctx->mbox_client.tx_block)\n\t\treinit_completion(&ctx->rd_complete);\n\n\trc = slimpro_i2c_send_msg(ctx, msg, msg);\n\n\tdma_unmap_single(ctx->dev, paddr, writelen, DMA_TO_DEVICE);\n\treturn rc;\n}",
        "code_after_change": "static int slimpro_i2c_blkwr(struct slimpro_i2c_dev *ctx, u32 chip,\n\t\t\t     u32 addr, u32 addrlen, u32 protocol, u32 writelen,\n\t\t\t     void *data)\n{\n\tdma_addr_t paddr;\n\tu32 msg[3];\n\tint rc;\n\n\tif (writelen > I2C_SMBUS_BLOCK_MAX)\n\t\treturn -EINVAL;\n\n\tmemcpy(ctx->dma_buffer, data, writelen);\n\tpaddr = dma_map_single(ctx->dev, ctx->dma_buffer, writelen,\n\t\t\t       DMA_TO_DEVICE);\n\tif (dma_mapping_error(ctx->dev, paddr)) {\n\t\tdev_err(&ctx->adapter.dev, \"Error in mapping dma buffer %p\\n\",\n\t\t\tctx->dma_buffer);\n\t\treturn -ENOMEM;\n\t}\n\n\tmsg[0] = SLIMPRO_IIC_ENCODE_MSG(SLIMPRO_IIC_BUS, chip, SLIMPRO_IIC_WRITE,\n\t\t\t\t\tprotocol, addrlen, writelen);\n\tmsg[1] = SLIMPRO_IIC_ENCODE_FLAG_BUFADDR |\n\t\t SLIMPRO_IIC_ENCODE_UPPER_BUFADDR(paddr) |\n\t\t SLIMPRO_IIC_ENCODE_ADDR(addr);\n\tmsg[2] = (u32)paddr;\n\n\tif (ctx->mbox_client.tx_block)\n\t\treinit_completion(&ctx->rd_complete);\n\n\trc = slimpro_i2c_send_msg(ctx, msg, msg);\n\n\tdma_unmap_single(ctx->dev, paddr, writelen, DMA_TO_DEVICE);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tdma_addr_t paddr;\n \tu32 msg[3];\n \tint rc;\n+\n+\tif (writelen > I2C_SMBUS_BLOCK_MAX)\n+\t\treturn -EINVAL;\n \n \tmemcpy(ctx->dma_buffer, data, writelen);\n \tpaddr = dma_map_single(ctx->dev, ctx->dma_buffer, writelen,",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (writelen > I2C_SMBUS_BLOCK_MAX)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds write vulnerability was found in the Linux kernel's SLIMpro I2C device driver. The userspace \"data->block[0]\" variable was not capped to a number between 0-255 and was used as the size of a memcpy, possibly writing beyond the end of dma_buffer. This flaw could allow a local privileged user to crash the system or potentially achieve code execution."
    },
    {
        "cve_id": "CVE-2023-2598",
        "code_before_change": "static int io_sqe_buffer_register(struct io_ring_ctx *ctx, struct iovec *iov,\n\t\t\t\t  struct io_mapped_ubuf **pimu,\n\t\t\t\t  struct page **last_hpage)\n{\n\tstruct io_mapped_ubuf *imu = NULL;\n\tstruct page **pages = NULL;\n\tunsigned long off;\n\tsize_t size;\n\tint ret, nr_pages, i;\n\tstruct folio *folio = NULL;\n\n\t*pimu = ctx->dummy_ubuf;\n\tif (!iov->iov_base)\n\t\treturn 0;\n\n\tret = -ENOMEM;\n\tpages = io_pin_pages((unsigned long) iov->iov_base, iov->iov_len,\n\t\t\t\t&nr_pages);\n\tif (IS_ERR(pages)) {\n\t\tret = PTR_ERR(pages);\n\t\tpages = NULL;\n\t\tgoto done;\n\t}\n\n\t/* If it's a huge page, try to coalesce them into a single bvec entry */\n\tif (nr_pages > 1) {\n\t\tfolio = page_folio(pages[0]);\n\t\tfor (i = 1; i < nr_pages; i++) {\n\t\t\tif (page_folio(pages[i]) != folio) {\n\t\t\t\tfolio = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (folio) {\n\t\t\t/*\n\t\t\t * The pages are bound to the folio, it doesn't\n\t\t\t * actually unpin them but drops all but one reference,\n\t\t\t * which is usually put down by io_buffer_unmap().\n\t\t\t * Note, needs a better helper.\n\t\t\t */\n\t\t\tunpin_user_pages(&pages[1], nr_pages - 1);\n\t\t\tnr_pages = 1;\n\t\t}\n\t}\n\n\timu = kvmalloc(struct_size(imu, bvec, nr_pages), GFP_KERNEL);\n\tif (!imu)\n\t\tgoto done;\n\n\tret = io_buffer_account_pin(ctx, pages, nr_pages, imu, last_hpage);\n\tif (ret) {\n\t\tunpin_user_pages(pages, nr_pages);\n\t\tgoto done;\n\t}\n\n\toff = (unsigned long) iov->iov_base & ~PAGE_MASK;\n\tsize = iov->iov_len;\n\t/* store original address for later verification */\n\timu->ubuf = (unsigned long) iov->iov_base;\n\timu->ubuf_end = imu->ubuf + iov->iov_len;\n\timu->nr_bvecs = nr_pages;\n\t*pimu = imu;\n\tret = 0;\n\n\tif (folio) {\n\t\tbvec_set_page(&imu->bvec[0], pages[0], size, off);\n\t\tgoto done;\n\t}\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tsize_t vec_len;\n\n\t\tvec_len = min_t(size_t, size, PAGE_SIZE - off);\n\t\tbvec_set_page(&imu->bvec[i], pages[i], vec_len, off);\n\t\toff = 0;\n\t\tsize -= vec_len;\n\t}\ndone:\n\tif (ret)\n\t\tkvfree(imu);\n\tkvfree(pages);\n\treturn ret;\n}",
        "code_after_change": "static int io_sqe_buffer_register(struct io_ring_ctx *ctx, struct iovec *iov,\n\t\t\t\t  struct io_mapped_ubuf **pimu,\n\t\t\t\t  struct page **last_hpage)\n{\n\tstruct io_mapped_ubuf *imu = NULL;\n\tstruct page **pages = NULL;\n\tunsigned long off;\n\tsize_t size;\n\tint ret, nr_pages, i;\n\tstruct folio *folio = NULL;\n\n\t*pimu = ctx->dummy_ubuf;\n\tif (!iov->iov_base)\n\t\treturn 0;\n\n\tret = -ENOMEM;\n\tpages = io_pin_pages((unsigned long) iov->iov_base, iov->iov_len,\n\t\t\t\t&nr_pages);\n\tif (IS_ERR(pages)) {\n\t\tret = PTR_ERR(pages);\n\t\tpages = NULL;\n\t\tgoto done;\n\t}\n\n\t/* If it's a huge page, try to coalesce them into a single bvec entry */\n\tif (nr_pages > 1) {\n\t\tfolio = page_folio(pages[0]);\n\t\tfor (i = 1; i < nr_pages; i++) {\n\t\t\t/*\n\t\t\t * Pages must be consecutive and on the same folio for\n\t\t\t * this to work\n\t\t\t */\n\t\t\tif (page_folio(pages[i]) != folio ||\n\t\t\t    pages[i] != pages[i - 1] + 1) {\n\t\t\t\tfolio = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (folio) {\n\t\t\t/*\n\t\t\t * The pages are bound to the folio, it doesn't\n\t\t\t * actually unpin them but drops all but one reference,\n\t\t\t * which is usually put down by io_buffer_unmap().\n\t\t\t * Note, needs a better helper.\n\t\t\t */\n\t\t\tunpin_user_pages(&pages[1], nr_pages - 1);\n\t\t\tnr_pages = 1;\n\t\t}\n\t}\n\n\timu = kvmalloc(struct_size(imu, bvec, nr_pages), GFP_KERNEL);\n\tif (!imu)\n\t\tgoto done;\n\n\tret = io_buffer_account_pin(ctx, pages, nr_pages, imu, last_hpage);\n\tif (ret) {\n\t\tunpin_user_pages(pages, nr_pages);\n\t\tgoto done;\n\t}\n\n\toff = (unsigned long) iov->iov_base & ~PAGE_MASK;\n\tsize = iov->iov_len;\n\t/* store original address for later verification */\n\timu->ubuf = (unsigned long) iov->iov_base;\n\timu->ubuf_end = imu->ubuf + iov->iov_len;\n\timu->nr_bvecs = nr_pages;\n\t*pimu = imu;\n\tret = 0;\n\n\tif (folio) {\n\t\tbvec_set_page(&imu->bvec[0], pages[0], size, off);\n\t\tgoto done;\n\t}\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tsize_t vec_len;\n\n\t\tvec_len = min_t(size_t, size, PAGE_SIZE - off);\n\t\tbvec_set_page(&imu->bvec[i], pages[i], vec_len, off);\n\t\toff = 0;\n\t\tsize -= vec_len;\n\t}\ndone:\n\tif (ret)\n\t\tkvfree(imu);\n\tkvfree(pages);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -26,7 +26,12 @@\n \tif (nr_pages > 1) {\n \t\tfolio = page_folio(pages[0]);\n \t\tfor (i = 1; i < nr_pages; i++) {\n-\t\t\tif (page_folio(pages[i]) != folio) {\n+\t\t\t/*\n+\t\t\t * Pages must be consecutive and on the same folio for\n+\t\t\t * this to work\n+\t\t\t */\n+\t\t\tif (page_folio(pages[i]) != folio ||\n+\t\t\t    pages[i] != pages[i - 1] + 1) {\n \t\t\t\tfolio = NULL;\n \t\t\t\tbreak;\n \t\t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t/*",
                "\t\t\t * Pages must be consecutive and on the same folio for",
                "\t\t\t * this to work",
                "\t\t\t */",
                "\t\t\tif (page_folio(pages[i]) != folio ||",
                "\t\t\t    pages[i] != pages[i - 1] + 1) {"
            ],
            "deleted": [
                "\t\t\tif (page_folio(pages[i]) != folio) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the fixed buffer registration code for io_uring (io_sqe_buffer_register in io_uring/rsrc.c) in the Linux kernel that allows out-of-bounds access to physical memory beyond the end of the buffer. This flaw enables full local privilege escalation."
    },
    {
        "cve_id": "CVE-2023-28410",
        "code_before_change": "static int\nvm_access(struct vm_area_struct *area, unsigned long addr,\n\t  void *buf, int len, int write)\n{\n\tstruct i915_mmap_offset *mmo = area->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\tstruct i915_gem_ww_ctx ww;\n\tvoid *vaddr;\n\tint err = 0;\n\n\tif (i915_gem_object_is_readonly(obj) && write)\n\t\treturn -EACCES;\n\n\taddr -= area->vm_start;\n\tif (addr >= obj->base.size)\n\t\treturn -EINVAL;\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\terr = i915_gem_object_lock(obj, &ww);\n\tif (err)\n\t\tgoto out;\n\n\t/* As this is primarily for debugging, let's focus on simplicity */\n\tvaddr = i915_gem_object_pin_map(obj, I915_MAP_FORCE_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto out;\n\t}\n\n\tif (write) {\n\t\tmemcpy(vaddr + addr, buf, len);\n\t\t__i915_gem_object_flush_map(obj, addr, len);\n\t} else {\n\t\tmemcpy(buf, vaddr + addr, len);\n\t}\n\n\ti915_gem_object_unpin_map(obj);\nout:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\n\tif (err)\n\t\treturn err;\n\n\treturn len;\n}",
        "code_after_change": "static int\nvm_access(struct vm_area_struct *area, unsigned long addr,\n\t  void *buf, int len, int write)\n{\n\tstruct i915_mmap_offset *mmo = area->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\tstruct i915_gem_ww_ctx ww;\n\tvoid *vaddr;\n\tint err = 0;\n\n\tif (i915_gem_object_is_readonly(obj) && write)\n\t\treturn -EACCES;\n\n\taddr -= area->vm_start;\n\tif (range_overflows_t(u64, addr, len, obj->base.size))\n\t\treturn -EINVAL;\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\terr = i915_gem_object_lock(obj, &ww);\n\tif (err)\n\t\tgoto out;\n\n\t/* As this is primarily for debugging, let's focus on simplicity */\n\tvaddr = i915_gem_object_pin_map(obj, I915_MAP_FORCE_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto out;\n\t}\n\n\tif (write) {\n\t\tmemcpy(vaddr + addr, buf, len);\n\t\t__i915_gem_object_flush_map(obj, addr, len);\n\t} else {\n\t\tmemcpy(buf, vaddr + addr, len);\n\t}\n\n\ti915_gem_object_unpin_map(obj);\nout:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\n\tif (err)\n\t\treturn err;\n\n\treturn len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \t\treturn -EACCES;\n \n \taddr -= area->vm_start;\n-\tif (addr >= obj->base.size)\n+\tif (range_overflows_t(u64, addr, len, obj->base.size))\n \t\treturn -EINVAL;\n \n \ti915_gem_ww_ctx_init(&ww, true);",
        "function_modified_lines": {
            "added": [
                "\tif (range_overflows_t(u64, addr, len, obj->base.size))"
            ],
            "deleted": [
                "\tif (addr >= obj->base.size)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Improper restriction of operations within the bounds of a memory buffer in some Intel(R) i915 Graphics drivers for linux before kernel version 6.2.10 may allow an authenticated user to potentially enable escalation of privilege via local access."
    },
    {
        "cve_id": "CVE-2023-3090",
        "code_before_change": "static int ipvlan_process_v4_outbound(struct sk_buff *skb)\n{\n\tconst struct iphdr *ip4h = ip_hdr(skb);\n\tstruct net_device *dev = skb->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct rtable *rt;\n\tint err, ret = NET_XMIT_DROP;\n\tstruct flowi4 fl4 = {\n\t\t.flowi4_oif = dev->ifindex,\n\t\t.flowi4_tos = RT_TOS(ip4h->tos),\n\t\t.flowi4_flags = FLOWI_FLAG_ANYSRC,\n\t\t.flowi4_mark = skb->mark,\n\t\t.daddr = ip4h->daddr,\n\t\t.saddr = ip4h->saddr,\n\t};\n\n\trt = ip_route_output_flow(net, &fl4, NULL);\n\tif (IS_ERR(rt))\n\t\tgoto err;\n\n\tif (rt->rt_type != RTN_UNICAST && rt->rt_type != RTN_LOCAL) {\n\t\tip_rt_put(rt);\n\t\tgoto err;\n\t}\n\tskb_dst_set(skb, &rt->dst);\n\terr = ip_local_out(net, skb->sk, skb);\n\tif (unlikely(net_xmit_eval(err)))\n\t\tdev->stats.tx_errors++;\n\telse\n\t\tret = NET_XMIT_SUCCESS;\n\tgoto out;\nerr:\n\tdev->stats.tx_errors++;\n\tkfree_skb(skb);\nout:\n\treturn ret;\n}",
        "code_after_change": "static int ipvlan_process_v4_outbound(struct sk_buff *skb)\n{\n\tconst struct iphdr *ip4h = ip_hdr(skb);\n\tstruct net_device *dev = skb->dev;\n\tstruct net *net = dev_net(dev);\n\tstruct rtable *rt;\n\tint err, ret = NET_XMIT_DROP;\n\tstruct flowi4 fl4 = {\n\t\t.flowi4_oif = dev->ifindex,\n\t\t.flowi4_tos = RT_TOS(ip4h->tos),\n\t\t.flowi4_flags = FLOWI_FLAG_ANYSRC,\n\t\t.flowi4_mark = skb->mark,\n\t\t.daddr = ip4h->daddr,\n\t\t.saddr = ip4h->saddr,\n\t};\n\n\trt = ip_route_output_flow(net, &fl4, NULL);\n\tif (IS_ERR(rt))\n\t\tgoto err;\n\n\tif (rt->rt_type != RTN_UNICAST && rt->rt_type != RTN_LOCAL) {\n\t\tip_rt_put(rt);\n\t\tgoto err;\n\t}\n\tskb_dst_set(skb, &rt->dst);\n\n\tmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));\n\n\terr = ip_local_out(net, skb->sk, skb);\n\tif (unlikely(net_xmit_eval(err)))\n\t\tdev->stats.tx_errors++;\n\telse\n\t\tret = NET_XMIT_SUCCESS;\n\tgoto out;\nerr:\n\tdev->stats.tx_errors++;\n\tkfree_skb(skb);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,6 +23,9 @@\n \t\tgoto err;\n \t}\n \tskb_dst_set(skb, &rt->dst);\n+\n+\tmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));\n+\n \terr = ip_local_out(net, skb->sk, skb);\n \tif (unlikely(net_xmit_eval(err)))\n \t\tdev->stats.tx_errors++;",
        "function_modified_lines": {
            "added": [
                "",
                "\tmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux Kernel ipvlan network driver can be exploited to achieve local privilege escalation.\n\nThe out-of-bounds write is caused by missing skb->cb  initialization in the ipvlan network driver. The vulnerability is reachable if\u00a0CONFIG_IPVLAN is enabled.\n\n\nWe recommend upgrading past commit 90cbed5247439a966b645b34eb0a2e037836ea8e.\n\n"
    },
    {
        "cve_id": "CVE-2023-31436",
        "code_before_change": "static int qfq_change_class(struct Qdisc *sch, u32 classid, u32 parentid,\n\t\t\t    struct nlattr **tca, unsigned long *arg,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct qfq_sched *q = qdisc_priv(sch);\n\tstruct qfq_class *cl = (struct qfq_class *)*arg;\n\tbool existing = false;\n\tstruct nlattr *tb[TCA_QFQ_MAX + 1];\n\tstruct qfq_aggregate *new_agg = NULL;\n\tu32 weight, lmax, inv_w;\n\tint err;\n\tint delta_w;\n\n\tif (tca[TCA_OPTIONS] == NULL) {\n\t\tpr_notice(\"qfq: no options\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb, TCA_QFQ_MAX, tca[TCA_OPTIONS],\n\t\t\t\t\t  qfq_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_QFQ_WEIGHT]) {\n\t\tweight = nla_get_u32(tb[TCA_QFQ_WEIGHT]);\n\t\tif (!weight || weight > (1UL << QFQ_MAX_WSHIFT)) {\n\t\t\tpr_notice(\"qfq: invalid weight %u\\n\", weight);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else\n\t\tweight = 1;\n\n\tif (tb[TCA_QFQ_LMAX]) {\n\t\tlmax = nla_get_u32(tb[TCA_QFQ_LMAX]);\n\t\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {\n\t\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else\n\t\tlmax = psched_mtu(qdisc_dev(sch));\n\n\tinv_w = ONE_FP / weight;\n\tweight = ONE_FP / inv_w;\n\n\tif (cl != NULL &&\n\t    lmax == cl->agg->lmax &&\n\t    weight == cl->agg->class_weight)\n\t\treturn 0; /* nothing to change */\n\n\tdelta_w = weight - (cl ? cl->agg->class_weight : 0);\n\n\tif (q->wsum + delta_w > QFQ_MAX_WSUM) {\n\t\tpr_notice(\"qfq: total weight out of range (%d + %u)\\n\",\n\t\t\t  delta_w, q->wsum);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cl != NULL) { /* modify existing class */\n\t\tif (tca[TCA_RATE]) {\n\t\t\terr = gen_replace_estimator(&cl->bstats, NULL,\n\t\t\t\t\t\t    &cl->rate_est,\n\t\t\t\t\t\t    NULL,\n\t\t\t\t\t\t    true,\n\t\t\t\t\t\t    tca[TCA_RATE]);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\texisting = true;\n\t\tgoto set_change_agg;\n\t}\n\n\t/* create and init new class */\n\tcl = kzalloc(sizeof(struct qfq_class), GFP_KERNEL);\n\tif (cl == NULL)\n\t\treturn -ENOBUFS;\n\n\tgnet_stats_basic_sync_init(&cl->bstats);\n\tcl->common.classid = classid;\n\tcl->deficit = lmax;\n\n\tcl->qdisc = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\n\t\t\t\t      classid, NULL);\n\tif (cl->qdisc == NULL)\n\t\tcl->qdisc = &noop_qdisc;\n\n\tif (tca[TCA_RATE]) {\n\t\terr = gen_new_estimator(&cl->bstats, NULL,\n\t\t\t\t\t&cl->rate_est,\n\t\t\t\t\tNULL,\n\t\t\t\t\ttrue,\n\t\t\t\t\ttca[TCA_RATE]);\n\t\tif (err)\n\t\t\tgoto destroy_class;\n\t}\n\n\tif (cl->qdisc != &noop_qdisc)\n\t\tqdisc_hash_add(cl->qdisc, true);\n\nset_change_agg:\n\tsch_tree_lock(sch);\n\tnew_agg = qfq_find_agg(q, lmax, weight);\n\tif (new_agg == NULL) { /* create new aggregate */\n\t\tsch_tree_unlock(sch);\n\t\tnew_agg = kzalloc(sizeof(*new_agg), GFP_KERNEL);\n\t\tif (new_agg == NULL) {\n\t\t\terr = -ENOBUFS;\n\t\t\tgen_kill_estimator(&cl->rate_est);\n\t\t\tgoto destroy_class;\n\t\t}\n\t\tsch_tree_lock(sch);\n\t\tqfq_init_agg(q, new_agg, lmax, weight);\n\t}\n\tif (existing)\n\t\tqfq_deact_rm_from_agg(q, cl);\n\telse\n\t\tqdisc_class_hash_insert(&q->clhash, &cl->common);\n\tqfq_add_to_agg(q, new_agg, cl);\n\tsch_tree_unlock(sch);\n\tqdisc_class_hash_grow(sch, &q->clhash);\n\n\t*arg = (unsigned long)cl;\n\treturn 0;\n\ndestroy_class:\n\tqdisc_put(cl->qdisc);\n\tkfree(cl);\n\treturn err;\n}",
        "code_after_change": "static int qfq_change_class(struct Qdisc *sch, u32 classid, u32 parentid,\n\t\t\t    struct nlattr **tca, unsigned long *arg,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct qfq_sched *q = qdisc_priv(sch);\n\tstruct qfq_class *cl = (struct qfq_class *)*arg;\n\tbool existing = false;\n\tstruct nlattr *tb[TCA_QFQ_MAX + 1];\n\tstruct qfq_aggregate *new_agg = NULL;\n\tu32 weight, lmax, inv_w;\n\tint err;\n\tint delta_w;\n\n\tif (tca[TCA_OPTIONS] == NULL) {\n\t\tpr_notice(\"qfq: no options\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb, TCA_QFQ_MAX, tca[TCA_OPTIONS],\n\t\t\t\t\t  qfq_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[TCA_QFQ_WEIGHT]) {\n\t\tweight = nla_get_u32(tb[TCA_QFQ_WEIGHT]);\n\t\tif (!weight || weight > (1UL << QFQ_MAX_WSHIFT)) {\n\t\t\tpr_notice(\"qfq: invalid weight %u\\n\", weight);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else\n\t\tweight = 1;\n\n\tif (tb[TCA_QFQ_LMAX])\n\t\tlmax = nla_get_u32(tb[TCA_QFQ_LMAX]);\n\telse\n\t\tlmax = psched_mtu(qdisc_dev(sch));\n\n\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {\n\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);\n\t\treturn -EINVAL;\n\t}\n\n\tinv_w = ONE_FP / weight;\n\tweight = ONE_FP / inv_w;\n\n\tif (cl != NULL &&\n\t    lmax == cl->agg->lmax &&\n\t    weight == cl->agg->class_weight)\n\t\treturn 0; /* nothing to change */\n\n\tdelta_w = weight - (cl ? cl->agg->class_weight : 0);\n\n\tif (q->wsum + delta_w > QFQ_MAX_WSUM) {\n\t\tpr_notice(\"qfq: total weight out of range (%d + %u)\\n\",\n\t\t\t  delta_w, q->wsum);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cl != NULL) { /* modify existing class */\n\t\tif (tca[TCA_RATE]) {\n\t\t\terr = gen_replace_estimator(&cl->bstats, NULL,\n\t\t\t\t\t\t    &cl->rate_est,\n\t\t\t\t\t\t    NULL,\n\t\t\t\t\t\t    true,\n\t\t\t\t\t\t    tca[TCA_RATE]);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\texisting = true;\n\t\tgoto set_change_agg;\n\t}\n\n\t/* create and init new class */\n\tcl = kzalloc(sizeof(struct qfq_class), GFP_KERNEL);\n\tif (cl == NULL)\n\t\treturn -ENOBUFS;\n\n\tgnet_stats_basic_sync_init(&cl->bstats);\n\tcl->common.classid = classid;\n\tcl->deficit = lmax;\n\n\tcl->qdisc = qdisc_create_dflt(sch->dev_queue, &pfifo_qdisc_ops,\n\t\t\t\t      classid, NULL);\n\tif (cl->qdisc == NULL)\n\t\tcl->qdisc = &noop_qdisc;\n\n\tif (tca[TCA_RATE]) {\n\t\terr = gen_new_estimator(&cl->bstats, NULL,\n\t\t\t\t\t&cl->rate_est,\n\t\t\t\t\tNULL,\n\t\t\t\t\ttrue,\n\t\t\t\t\ttca[TCA_RATE]);\n\t\tif (err)\n\t\t\tgoto destroy_class;\n\t}\n\n\tif (cl->qdisc != &noop_qdisc)\n\t\tqdisc_hash_add(cl->qdisc, true);\n\nset_change_agg:\n\tsch_tree_lock(sch);\n\tnew_agg = qfq_find_agg(q, lmax, weight);\n\tif (new_agg == NULL) { /* create new aggregate */\n\t\tsch_tree_unlock(sch);\n\t\tnew_agg = kzalloc(sizeof(*new_agg), GFP_KERNEL);\n\t\tif (new_agg == NULL) {\n\t\t\terr = -ENOBUFS;\n\t\t\tgen_kill_estimator(&cl->rate_est);\n\t\t\tgoto destroy_class;\n\t\t}\n\t\tsch_tree_lock(sch);\n\t\tqfq_init_agg(q, new_agg, lmax, weight);\n\t}\n\tif (existing)\n\t\tqfq_deact_rm_from_agg(q, cl);\n\telse\n\t\tqdisc_class_hash_insert(&q->clhash, &cl->common);\n\tqfq_add_to_agg(q, new_agg, cl);\n\tsch_tree_unlock(sch);\n\tqdisc_class_hash_grow(sch, &q->clhash);\n\n\t*arg = (unsigned long)cl;\n\treturn 0;\n\ndestroy_class:\n\tqdisc_put(cl->qdisc);\n\tkfree(cl);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,14 +30,15 @@\n \t} else\n \t\tweight = 1;\n \n-\tif (tb[TCA_QFQ_LMAX]) {\n+\tif (tb[TCA_QFQ_LMAX])\n \t\tlmax = nla_get_u32(tb[TCA_QFQ_LMAX]);\n-\t\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {\n-\t\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);\n-\t\t\treturn -EINVAL;\n-\t\t}\n-\t} else\n+\telse\n \t\tlmax = psched_mtu(qdisc_dev(sch));\n+\n+\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {\n+\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);\n+\t\treturn -EINVAL;\n+\t}\n \n \tinv_w = ONE_FP / weight;\n \tweight = ONE_FP / inv_w;",
        "function_modified_lines": {
            "added": [
                "\tif (tb[TCA_QFQ_LMAX])",
                "\telse",
                "",
                "\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {",
                "\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": [
                "\tif (tb[TCA_QFQ_LMAX]) {",
                "\t\tif (lmax < QFQ_MIN_LMAX || lmax > (1UL << QFQ_MTU_SHIFT)) {",
                "\t\t\tpr_notice(\"qfq: invalid max length %u\\n\", lmax);",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                "\t} else"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "qfq_change_class in net/sched/sch_qfq.c in the Linux kernel before 6.2.13 allows an out-of-bounds write because lmax can exceed QFQ_MIN_LMAX."
    },
    {
        "cve_id": "CVE-2023-34319",
        "code_before_change": "static void xenvif_get_requests(struct xenvif_queue *queue,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tstruct xen_netif_tx_request *first,\n\t\t\t\tstruct xen_netif_tx_request *txfrags,\n\t\t\t        unsigned *copy_ops,\n\t\t\t        unsigned *map_ops,\n\t\t\t\tunsigned int frag_overflow,\n\t\t\t\tstruct sk_buff *nskb,\n\t\t\t\tunsigned int extra_count,\n\t\t\t\tunsigned int data_len)\n{\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tskb_frag_t *frags = shinfo->frags;\n\tu16 pending_idx;\n\tpending_ring_idx_t index;\n\tunsigned int nr_slots;\n\tstruct gnttab_copy *cop = queue->tx_copy_ops + *copy_ops;\n\tstruct gnttab_map_grant_ref *gop = queue->tx_map_ops + *map_ops;\n\tstruct xen_netif_tx_request *txp = first;\n\n\tnr_slots = shinfo->nr_frags + 1;\n\n\tcopy_count(skb) = 0;\n\tXENVIF_TX_CB(skb)->split_mask = 0;\n\n\t/* Create copy ops for exactly data_len bytes into the skb head. */\n\t__skb_put(skb, data_len);\n\twhile (data_len > 0) {\n\t\tint amount = data_len > txp->size ? txp->size : data_len;\n\t\tbool split = false;\n\n\t\tcop->source.u.ref = txp->gref;\n\t\tcop->source.domid = queue->vif->domid;\n\t\tcop->source.offset = txp->offset;\n\n\t\tcop->dest.domid = DOMID_SELF;\n\t\tcop->dest.offset = (offset_in_page(skb->data +\n\t\t\t\t\t\t   skb_headlen(skb) -\n\t\t\t\t\t\t   data_len)) & ~XEN_PAGE_MASK;\n\t\tcop->dest.u.gmfn = virt_to_gfn(skb->data + skb_headlen(skb)\n\t\t\t\t               - data_len);\n\n\t\t/* Don't cross local page boundary! */\n\t\tif (cop->dest.offset + amount > XEN_PAGE_SIZE) {\n\t\t\tamount = XEN_PAGE_SIZE - cop->dest.offset;\n\t\t\tXENVIF_TX_CB(skb)->split_mask |= 1U << copy_count(skb);\n\t\t\tsplit = true;\n\t\t}\n\n\t\tcop->len = amount;\n\t\tcop->flags = GNTCOPY_source_gref;\n\n\t\tindex = pending_index(queue->pending_cons);\n\t\tpending_idx = queue->pending_ring[index];\n\t\tcallback_param(queue, pending_idx).ctx = NULL;\n\t\tcopy_pending_idx(skb, copy_count(skb)) = pending_idx;\n\t\tif (!split)\n\t\t\tcopy_count(skb)++;\n\n\t\tcop++;\n\t\tdata_len -= amount;\n\n\t\tif (amount == txp->size) {\n\t\t\t/* The copy op covered the full tx_request */\n\n\t\t\tmemcpy(&queue->pending_tx_info[pending_idx].req,\n\t\t\t       txp, sizeof(*txp));\n\t\t\tqueue->pending_tx_info[pending_idx].extra_count =\n\t\t\t\t(txp == first) ? extra_count : 0;\n\n\t\t\tif (txp == first)\n\t\t\t\ttxp = txfrags;\n\t\t\telse\n\t\t\t\ttxp++;\n\t\t\tqueue->pending_cons++;\n\t\t\tnr_slots--;\n\t\t} else {\n\t\t\t/* The copy op partially covered the tx_request.\n\t\t\t * The remainder will be mapped or copied in the next\n\t\t\t * iteration.\n\t\t\t */\n\t\t\ttxp->offset += amount;\n\t\t\ttxp->size -= amount;\n\t\t}\n\t}\n\n\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;\n\t     shinfo->nr_frags++, gop++) {\n\t\tindex = pending_index(queue->pending_cons++);\n\t\tpending_idx = queue->pending_ring[index];\n\t\txenvif_tx_create_map_op(queue, pending_idx, txp,\n\t\t\t\t        txp == first ? extra_count : 0, gop);\n\t\tfrag_set_pending_idx(&frags[shinfo->nr_frags], pending_idx);\n\n\t\tif (txp == first)\n\t\t\ttxp = txfrags;\n\t\telse\n\t\t\ttxp++;\n\t}\n\n\tif (frag_overflow) {\n\n\t\tshinfo = skb_shinfo(nskb);\n\t\tfrags = shinfo->frags;\n\n\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < frag_overflow;\n\t\t     shinfo->nr_frags++, txp++, gop++) {\n\t\t\tindex = pending_index(queue->pending_cons++);\n\t\t\tpending_idx = queue->pending_ring[index];\n\t\t\txenvif_tx_create_map_op(queue, pending_idx, txp, 0,\n\t\t\t\t\t\tgop);\n\t\t\tfrag_set_pending_idx(&frags[shinfo->nr_frags],\n\t\t\t\t\t     pending_idx);\n\t\t}\n\n\t\tskb_shinfo(skb)->frag_list = nskb;\n\t}\n\n\t(*copy_ops) = cop - queue->tx_copy_ops;\n\t(*map_ops) = gop - queue->tx_map_ops;\n}",
        "code_after_change": "static void xenvif_get_requests(struct xenvif_queue *queue,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tstruct xen_netif_tx_request *first,\n\t\t\t\tstruct xen_netif_tx_request *txfrags,\n\t\t\t        unsigned *copy_ops,\n\t\t\t        unsigned *map_ops,\n\t\t\t\tunsigned int frag_overflow,\n\t\t\t\tstruct sk_buff *nskb,\n\t\t\t\tunsigned int extra_count,\n\t\t\t\tunsigned int data_len)\n{\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tskb_frag_t *frags = shinfo->frags;\n\tu16 pending_idx;\n\tpending_ring_idx_t index;\n\tunsigned int nr_slots;\n\tstruct gnttab_copy *cop = queue->tx_copy_ops + *copy_ops;\n\tstruct gnttab_map_grant_ref *gop = queue->tx_map_ops + *map_ops;\n\tstruct xen_netif_tx_request *txp = first;\n\n\tnr_slots = shinfo->nr_frags + frag_overflow + 1;\n\n\tcopy_count(skb) = 0;\n\tXENVIF_TX_CB(skb)->split_mask = 0;\n\n\t/* Create copy ops for exactly data_len bytes into the skb head. */\n\t__skb_put(skb, data_len);\n\twhile (data_len > 0) {\n\t\tint amount = data_len > txp->size ? txp->size : data_len;\n\t\tbool split = false;\n\n\t\tcop->source.u.ref = txp->gref;\n\t\tcop->source.domid = queue->vif->domid;\n\t\tcop->source.offset = txp->offset;\n\n\t\tcop->dest.domid = DOMID_SELF;\n\t\tcop->dest.offset = (offset_in_page(skb->data +\n\t\t\t\t\t\t   skb_headlen(skb) -\n\t\t\t\t\t\t   data_len)) & ~XEN_PAGE_MASK;\n\t\tcop->dest.u.gmfn = virt_to_gfn(skb->data + skb_headlen(skb)\n\t\t\t\t               - data_len);\n\n\t\t/* Don't cross local page boundary! */\n\t\tif (cop->dest.offset + amount > XEN_PAGE_SIZE) {\n\t\t\tamount = XEN_PAGE_SIZE - cop->dest.offset;\n\t\t\tXENVIF_TX_CB(skb)->split_mask |= 1U << copy_count(skb);\n\t\t\tsplit = true;\n\t\t}\n\n\t\tcop->len = amount;\n\t\tcop->flags = GNTCOPY_source_gref;\n\n\t\tindex = pending_index(queue->pending_cons);\n\t\tpending_idx = queue->pending_ring[index];\n\t\tcallback_param(queue, pending_idx).ctx = NULL;\n\t\tcopy_pending_idx(skb, copy_count(skb)) = pending_idx;\n\t\tif (!split)\n\t\t\tcopy_count(skb)++;\n\n\t\tcop++;\n\t\tdata_len -= amount;\n\n\t\tif (amount == txp->size) {\n\t\t\t/* The copy op covered the full tx_request */\n\n\t\t\tmemcpy(&queue->pending_tx_info[pending_idx].req,\n\t\t\t       txp, sizeof(*txp));\n\t\t\tqueue->pending_tx_info[pending_idx].extra_count =\n\t\t\t\t(txp == first) ? extra_count : 0;\n\n\t\t\tif (txp == first)\n\t\t\t\ttxp = txfrags;\n\t\t\telse\n\t\t\t\ttxp++;\n\t\t\tqueue->pending_cons++;\n\t\t\tnr_slots--;\n\t\t} else {\n\t\t\t/* The copy op partially covered the tx_request.\n\t\t\t * The remainder will be mapped or copied in the next\n\t\t\t * iteration.\n\t\t\t */\n\t\t\ttxp->offset += amount;\n\t\t\ttxp->size -= amount;\n\t\t}\n\t}\n\n\tfor (shinfo->nr_frags = 0; nr_slots > 0 && shinfo->nr_frags < MAX_SKB_FRAGS;\n\t     shinfo->nr_frags++, gop++, nr_slots--) {\n\t\tindex = pending_index(queue->pending_cons++);\n\t\tpending_idx = queue->pending_ring[index];\n\t\txenvif_tx_create_map_op(queue, pending_idx, txp,\n\t\t\t\t        txp == first ? extra_count : 0, gop);\n\t\tfrag_set_pending_idx(&frags[shinfo->nr_frags], pending_idx);\n\n\t\tif (txp == first)\n\t\t\ttxp = txfrags;\n\t\telse\n\t\t\ttxp++;\n\t}\n\n\tif (nr_slots > 0) {\n\n\t\tshinfo = skb_shinfo(nskb);\n\t\tfrags = shinfo->frags;\n\n\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;\n\t\t     shinfo->nr_frags++, txp++, gop++) {\n\t\t\tindex = pending_index(queue->pending_cons++);\n\t\t\tpending_idx = queue->pending_ring[index];\n\t\t\txenvif_tx_create_map_op(queue, pending_idx, txp, 0,\n\t\t\t\t\t\tgop);\n\t\t\tfrag_set_pending_idx(&frags[shinfo->nr_frags],\n\t\t\t\t\t     pending_idx);\n\t\t}\n\n\t\tskb_shinfo(skb)->frag_list = nskb;\n\t} else if (nskb) {\n\t\t/* A frag_list skb was allocated but it is no longer needed\n\t\t * because enough slots were converted to copy ops above.\n\t\t */\n\t\tkfree_skb(nskb);\n\t}\n\n\t(*copy_ops) = cop - queue->tx_copy_ops;\n\t(*map_ops) = gop - queue->tx_map_ops;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \tstruct gnttab_map_grant_ref *gop = queue->tx_map_ops + *map_ops;\n \tstruct xen_netif_tx_request *txp = first;\n \n-\tnr_slots = shinfo->nr_frags + 1;\n+\tnr_slots = shinfo->nr_frags + frag_overflow + 1;\n \n \tcopy_count(skb) = 0;\n \tXENVIF_TX_CB(skb)->split_mask = 0;\n@@ -84,8 +84,8 @@\n \t\t}\n \t}\n \n-\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;\n-\t     shinfo->nr_frags++, gop++) {\n+\tfor (shinfo->nr_frags = 0; nr_slots > 0 && shinfo->nr_frags < MAX_SKB_FRAGS;\n+\t     shinfo->nr_frags++, gop++, nr_slots--) {\n \t\tindex = pending_index(queue->pending_cons++);\n \t\tpending_idx = queue->pending_ring[index];\n \t\txenvif_tx_create_map_op(queue, pending_idx, txp,\n@@ -98,12 +98,12 @@\n \t\t\ttxp++;\n \t}\n \n-\tif (frag_overflow) {\n+\tif (nr_slots > 0) {\n \n \t\tshinfo = skb_shinfo(nskb);\n \t\tfrags = shinfo->frags;\n \n-\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < frag_overflow;\n+\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;\n \t\t     shinfo->nr_frags++, txp++, gop++) {\n \t\t\tindex = pending_index(queue->pending_cons++);\n \t\t\tpending_idx = queue->pending_ring[index];\n@@ -114,6 +114,11 @@\n \t\t}\n \n \t\tskb_shinfo(skb)->frag_list = nskb;\n+\t} else if (nskb) {\n+\t\t/* A frag_list skb was allocated but it is no longer needed\n+\t\t * because enough slots were converted to copy ops above.\n+\t\t */\n+\t\tkfree_skb(nskb);\n \t}\n \n \t(*copy_ops) = cop - queue->tx_copy_ops;",
        "function_modified_lines": {
            "added": [
                "\tnr_slots = shinfo->nr_frags + frag_overflow + 1;",
                "\tfor (shinfo->nr_frags = 0; nr_slots > 0 && shinfo->nr_frags < MAX_SKB_FRAGS;",
                "\t     shinfo->nr_frags++, gop++, nr_slots--) {",
                "\tif (nr_slots > 0) {",
                "\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;",
                "\t} else if (nskb) {",
                "\t\t/* A frag_list skb was allocated but it is no longer needed",
                "\t\t * because enough slots were converted to copy ops above.",
                "\t\t */",
                "\t\tkfree_skb(nskb);"
            ],
            "deleted": [
                "\tnr_slots = shinfo->nr_frags + 1;",
                "\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < nr_slots;",
                "\t     shinfo->nr_frags++, gop++) {",
                "\tif (frag_overflow) {",
                "\t\tfor (shinfo->nr_frags = 0; shinfo->nr_frags < frag_overflow;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "The fix for XSA-423 added logic to Linux'es netback driver to deal with\na frontend splitting a packet in a way such that not all of the headers\nwould come in one piece.  Unfortunately the logic introduced there\ndidn't account for the extreme case of the entire packet being split\ninto as many pieces as permitted by the protocol, yet still being\nsmaller than the area that's specially dealt with to keep all (possible)\nheaders together.  Such an unusual packet would therefore trigger a\nbuffer overrun in the driver.\n"
    },
    {
        "cve_id": "CVE-2023-35001",
        "code_before_change": "void nft_byteorder_eval(const struct nft_expr *expr,\n\t\t\tstruct nft_regs *regs,\n\t\t\tconst struct nft_pktinfo *pkt)\n{\n\tconst struct nft_byteorder *priv = nft_expr_priv(expr);\n\tu32 *src = &regs->data[priv->sreg];\n\tu32 *dst = &regs->data[priv->dreg];\n\tunion { u32 u32; u16 u16; } *s, *d;\n\tunsigned int i;\n\n\ts = (void *)src;\n\td = (void *)dst;\n\n\tswitch (priv->size) {\n\tcase 8: {\n\t\tu64 src64;\n\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 8; i++) {\n\t\t\t\tsrc64 = nft_reg_load64(&src[i]);\n\t\t\t\tnft_reg_store64(&dst[i],\n\t\t\t\t\t\tbe64_to_cpu((__force __be64)src64));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 8; i++) {\n\t\t\t\tsrc64 = (__force __u64)\n\t\t\t\t\tcpu_to_be64(nft_reg_load64(&src[i]));\n\t\t\t\tnft_reg_store64(&dst[i], src64);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 4:\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 4; i++)\n\t\t\t\td[i].u32 = ntohl((__force __be32)s[i].u32);\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 4; i++)\n\t\t\t\td[i].u32 = (__force __u32)htonl(s[i].u32);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 2; i++)\n\t\t\t\td[i].u16 = ntohs((__force __be16)s[i].u16);\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 2; i++)\n\t\t\t\td[i].u16 = (__force __u16)htons(s[i].u16);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n}",
        "code_after_change": "void nft_byteorder_eval(const struct nft_expr *expr,\n\t\t\tstruct nft_regs *regs,\n\t\t\tconst struct nft_pktinfo *pkt)\n{\n\tconst struct nft_byteorder *priv = nft_expr_priv(expr);\n\tu32 *src = &regs->data[priv->sreg];\n\tu32 *dst = &regs->data[priv->dreg];\n\tu16 *s16, *d16;\n\tunsigned int i;\n\n\ts16 = (void *)src;\n\td16 = (void *)dst;\n\n\tswitch (priv->size) {\n\tcase 8: {\n\t\tu64 src64;\n\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 8; i++) {\n\t\t\t\tsrc64 = nft_reg_load64(&src[i]);\n\t\t\t\tnft_reg_store64(&dst[i],\n\t\t\t\t\t\tbe64_to_cpu((__force __be64)src64));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 8; i++) {\n\t\t\t\tsrc64 = (__force __u64)\n\t\t\t\t\tcpu_to_be64(nft_reg_load64(&src[i]));\n\t\t\t\tnft_reg_store64(&dst[i], src64);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\tcase 4:\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 4; i++)\n\t\t\t\tdst[i] = ntohl((__force __be32)src[i]);\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 4; i++)\n\t\t\t\tdst[i] = (__force __u32)htonl(src[i]);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\tswitch (priv->op) {\n\t\tcase NFT_BYTEORDER_NTOH:\n\t\t\tfor (i = 0; i < priv->len / 2; i++)\n\t\t\t\td16[i] = ntohs((__force __be16)s16[i]);\n\t\t\tbreak;\n\t\tcase NFT_BYTEORDER_HTON:\n\t\t\tfor (i = 0; i < priv->len / 2; i++)\n\t\t\t\td16[i] = (__force __u16)htons(s16[i]);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,11 +5,11 @@\n \tconst struct nft_byteorder *priv = nft_expr_priv(expr);\n \tu32 *src = &regs->data[priv->sreg];\n \tu32 *dst = &regs->data[priv->dreg];\n-\tunion { u32 u32; u16 u16; } *s, *d;\n+\tu16 *s16, *d16;\n \tunsigned int i;\n \n-\ts = (void *)src;\n-\td = (void *)dst;\n+\ts16 = (void *)src;\n+\td16 = (void *)dst;\n \n \tswitch (priv->size) {\n \tcase 8: {\n@@ -37,11 +37,11 @@\n \t\tswitch (priv->op) {\n \t\tcase NFT_BYTEORDER_NTOH:\n \t\t\tfor (i = 0; i < priv->len / 4; i++)\n-\t\t\t\td[i].u32 = ntohl((__force __be32)s[i].u32);\n+\t\t\t\tdst[i] = ntohl((__force __be32)src[i]);\n \t\t\tbreak;\n \t\tcase NFT_BYTEORDER_HTON:\n \t\t\tfor (i = 0; i < priv->len / 4; i++)\n-\t\t\t\td[i].u32 = (__force __u32)htonl(s[i].u32);\n+\t\t\t\tdst[i] = (__force __u32)htonl(src[i]);\n \t\t\tbreak;\n \t\t}\n \t\tbreak;\n@@ -49,11 +49,11 @@\n \t\tswitch (priv->op) {\n \t\tcase NFT_BYTEORDER_NTOH:\n \t\t\tfor (i = 0; i < priv->len / 2; i++)\n-\t\t\t\td[i].u16 = ntohs((__force __be16)s[i].u16);\n+\t\t\t\td16[i] = ntohs((__force __be16)s16[i]);\n \t\t\tbreak;\n \t\tcase NFT_BYTEORDER_HTON:\n \t\t\tfor (i = 0; i < priv->len / 2; i++)\n-\t\t\t\td[i].u16 = (__force __u16)htons(s[i].u16);\n+\t\t\t\td16[i] = (__force __u16)htons(s16[i]);\n \t\t\tbreak;\n \t\t}\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\tu16 *s16, *d16;",
                "\ts16 = (void *)src;",
                "\td16 = (void *)dst;",
                "\t\t\t\tdst[i] = ntohl((__force __be32)src[i]);",
                "\t\t\t\tdst[i] = (__force __u32)htonl(src[i]);",
                "\t\t\t\td16[i] = ntohs((__force __be16)s16[i]);",
                "\t\t\t\td16[i] = (__force __u16)htons(s16[i]);"
            ],
            "deleted": [
                "\tunion { u32 u32; u16 u16; } *s, *d;",
                "\ts = (void *)src;",
                "\td = (void *)dst;",
                "\t\t\t\td[i].u32 = ntohl((__force __be32)s[i].u32);",
                "\t\t\t\td[i].u32 = (__force __u32)htonl(s[i].u32);",
                "\t\t\t\td[i].u16 = ntohs((__force __be16)s[i].u16);",
                "\t\t\t\td[i].u16 = (__force __u16)htons(s[i].u16);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "Linux Kernel nftables Out-Of-Bounds Read/Write Vulnerability; nft_byteorder poorly handled vm register contents when CAP_NET_ADMIN is in any user or network namespace"
    },
    {
        "cve_id": "CVE-2023-35788",
        "code_before_change": "static int fl_set_geneve_opt(const struct nlattr *nla, struct fl_flow_key *key,\n\t\t\t     int depth, int option_len,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_MAX + 1];\n\tstruct nlattr *class = NULL, *type = NULL, *data = NULL;\n\tstruct geneve_opt *opt;\n\tint err, data_len = 0;\n\n\tif (option_len > sizeof(struct geneve_opt))\n\t\tdata_len = option_len - sizeof(struct geneve_opt);\n\n\topt = (struct geneve_opt *)&key->enc_opts.data[key->enc_opts.len];\n\tmemset(opt, 0xff, option_len);\n\topt->length = data_len / 4;\n\topt->r1 = 0;\n\topt->r2 = 0;\n\topt->r3 = 0;\n\n\t/* If no mask has been prodived we assume an exact match. */\n\tif (!depth)\n\t\treturn sizeof(struct geneve_opt) + data_len;\n\n\tif (nla_type(nla) != TCA_FLOWER_KEY_ENC_OPTS_GENEVE) {\n\t\tNL_SET_ERR_MSG(extack, \"Non-geneve option type for mask\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb,\n\t\t\t\t\t  TCA_FLOWER_KEY_ENC_OPT_GENEVE_MAX,\n\t\t\t\t\t  nla, geneve_opt_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* We are not allowed to omit any of CLASS, TYPE or DATA\n\t * fields from the key.\n\t */\n\tif (!option_len &&\n\t    (!tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS] ||\n\t     !tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE] ||\n\t     !tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA])) {\n\t\tNL_SET_ERR_MSG(extack, \"Missing tunnel key geneve option class, type or data\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Omitting any of CLASS, TYPE or DATA fields is allowed\n\t * for the mask.\n\t */\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA]) {\n\t\tint new_len = key->enc_opts.len;\n\n\t\tdata = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA];\n\t\tdata_len = nla_len(data);\n\t\tif (data_len < 4) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel key geneve option data is less than 4 bytes long\");\n\t\t\treturn -ERANGE;\n\t\t}\n\t\tif (data_len % 4) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel key geneve option data is not a multiple of 4 bytes long\");\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tnew_len += sizeof(struct geneve_opt) + data_len;\n\t\tBUILD_BUG_ON(FLOW_DIS_TUN_OPTS_MAX != IP_TUNNEL_OPTS_MAX);\n\t\tif (new_len > FLOW_DIS_TUN_OPTS_MAX) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel options exceeds max size\");\n\t\t\treturn -ERANGE;\n\t\t}\n\t\topt->length = data_len / 4;\n\t\tmemcpy(opt->opt_data, nla_data(data), data_len);\n\t}\n\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS]) {\n\t\tclass = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS];\n\t\topt->opt_class = nla_get_be16(class);\n\t}\n\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE]) {\n\t\ttype = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE];\n\t\topt->type = nla_get_u8(type);\n\t}\n\n\treturn sizeof(struct geneve_opt) + data_len;\n}",
        "code_after_change": "static int fl_set_geneve_opt(const struct nlattr *nla, struct fl_flow_key *key,\n\t\t\t     int depth, int option_len,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_MAX + 1];\n\tstruct nlattr *class = NULL, *type = NULL, *data = NULL;\n\tstruct geneve_opt *opt;\n\tint err, data_len = 0;\n\n\tif (option_len > sizeof(struct geneve_opt))\n\t\tdata_len = option_len - sizeof(struct geneve_opt);\n\n\tif (key->enc_opts.len > FLOW_DIS_TUN_OPTS_MAX - 4)\n\t\treturn -ERANGE;\n\n\topt = (struct geneve_opt *)&key->enc_opts.data[key->enc_opts.len];\n\tmemset(opt, 0xff, option_len);\n\topt->length = data_len / 4;\n\topt->r1 = 0;\n\topt->r2 = 0;\n\topt->r3 = 0;\n\n\t/* If no mask has been prodived we assume an exact match. */\n\tif (!depth)\n\t\treturn sizeof(struct geneve_opt) + data_len;\n\n\tif (nla_type(nla) != TCA_FLOWER_KEY_ENC_OPTS_GENEVE) {\n\t\tNL_SET_ERR_MSG(extack, \"Non-geneve option type for mask\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = nla_parse_nested_deprecated(tb,\n\t\t\t\t\t  TCA_FLOWER_KEY_ENC_OPT_GENEVE_MAX,\n\t\t\t\t\t  nla, geneve_opt_policy, extack);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* We are not allowed to omit any of CLASS, TYPE or DATA\n\t * fields from the key.\n\t */\n\tif (!option_len &&\n\t    (!tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS] ||\n\t     !tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE] ||\n\t     !tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA])) {\n\t\tNL_SET_ERR_MSG(extack, \"Missing tunnel key geneve option class, type or data\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Omitting any of CLASS, TYPE or DATA fields is allowed\n\t * for the mask.\n\t */\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA]) {\n\t\tint new_len = key->enc_opts.len;\n\n\t\tdata = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_DATA];\n\t\tdata_len = nla_len(data);\n\t\tif (data_len < 4) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel key geneve option data is less than 4 bytes long\");\n\t\t\treturn -ERANGE;\n\t\t}\n\t\tif (data_len % 4) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel key geneve option data is not a multiple of 4 bytes long\");\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tnew_len += sizeof(struct geneve_opt) + data_len;\n\t\tBUILD_BUG_ON(FLOW_DIS_TUN_OPTS_MAX != IP_TUNNEL_OPTS_MAX);\n\t\tif (new_len > FLOW_DIS_TUN_OPTS_MAX) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Tunnel options exceeds max size\");\n\t\t\treturn -ERANGE;\n\t\t}\n\t\topt->length = data_len / 4;\n\t\tmemcpy(opt->opt_data, nla_data(data), data_len);\n\t}\n\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS]) {\n\t\tclass = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_CLASS];\n\t\topt->opt_class = nla_get_be16(class);\n\t}\n\n\tif (tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE]) {\n\t\ttype = tb[TCA_FLOWER_KEY_ENC_OPT_GENEVE_TYPE];\n\t\topt->type = nla_get_u8(type);\n\t}\n\n\treturn sizeof(struct geneve_opt) + data_len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,9 @@\n \n \tif (option_len > sizeof(struct geneve_opt))\n \t\tdata_len = option_len - sizeof(struct geneve_opt);\n+\n+\tif (key->enc_opts.len > FLOW_DIS_TUN_OPTS_MAX - 4)\n+\t\treturn -ERANGE;\n \n \topt = (struct geneve_opt *)&key->enc_opts.data[key->enc_opts.len];\n \tmemset(opt, 0xff, option_len);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (key->enc_opts.len > FLOW_DIS_TUN_OPTS_MAX - 4)",
                "\t\treturn -ERANGE;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in fl_set_geneve_opt in net/sched/cls_flower.c in the Linux kernel before 6.3.7. It allows an out-of-bounds write in the flower classifier code via TCA_FLOWER_KEY_ENC_OPTS_GENEVE packets. This may result in denial of service or privilege escalation."
    },
    {
        "cve_id": "CVE-2023-3611",
        "code_before_change": "static int qfq_change_agg(struct Qdisc *sch, struct qfq_class *cl, u32 weight,\n\t\t\t   u32 lmax)\n{\n\tstruct qfq_sched *q = qdisc_priv(sch);\n\tstruct qfq_aggregate *new_agg = qfq_find_agg(q, lmax, weight);\n\n\tif (new_agg == NULL) { /* create new aggregate */\n\t\tnew_agg = kzalloc(sizeof(*new_agg), GFP_ATOMIC);\n\t\tif (new_agg == NULL)\n\t\t\treturn -ENOBUFS;\n\t\tqfq_init_agg(q, new_agg, lmax, weight);\n\t}\n\tqfq_deact_rm_from_agg(q, cl);\n\tqfq_add_to_agg(q, new_agg, cl);\n\n\treturn 0;\n}",
        "code_after_change": "static int qfq_change_agg(struct Qdisc *sch, struct qfq_class *cl, u32 weight,\n\t\t\t   u32 lmax)\n{\n\tstruct qfq_sched *q = qdisc_priv(sch);\n\tstruct qfq_aggregate *new_agg;\n\n\t/* 'lmax' can range from [QFQ_MIN_LMAX, pktlen + stab overhead] */\n\tif (lmax > QFQ_MAX_LMAX)\n\t\treturn -EINVAL;\n\n\tnew_agg = qfq_find_agg(q, lmax, weight);\n\tif (new_agg == NULL) { /* create new aggregate */\n\t\tnew_agg = kzalloc(sizeof(*new_agg), GFP_ATOMIC);\n\t\tif (new_agg == NULL)\n\t\t\treturn -ENOBUFS;\n\t\tqfq_init_agg(q, new_agg, lmax, weight);\n\t}\n\tqfq_deact_rm_from_agg(q, cl);\n\tqfq_add_to_agg(q, new_agg, cl);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,8 +2,13 @@\n \t\t\t   u32 lmax)\n {\n \tstruct qfq_sched *q = qdisc_priv(sch);\n-\tstruct qfq_aggregate *new_agg = qfq_find_agg(q, lmax, weight);\n+\tstruct qfq_aggregate *new_agg;\n \n+\t/* 'lmax' can range from [QFQ_MIN_LMAX, pktlen + stab overhead] */\n+\tif (lmax > QFQ_MAX_LMAX)\n+\t\treturn -EINVAL;\n+\n+\tnew_agg = qfq_find_agg(q, lmax, weight);\n \tif (new_agg == NULL) { /* create new aggregate */\n \t\tnew_agg = kzalloc(sizeof(*new_agg), GFP_ATOMIC);\n \t\tif (new_agg == NULL)",
        "function_modified_lines": {
            "added": [
                "\tstruct qfq_aggregate *new_agg;",
                "\t/* 'lmax' can range from [QFQ_MIN_LMAX, pktlen + stab overhead] */",
                "\tif (lmax > QFQ_MAX_LMAX)",
                "\t\treturn -EINVAL;",
                "",
                "\tnew_agg = qfq_find_agg(q, lmax, weight);"
            ],
            "deleted": [
                "\tstruct qfq_aggregate *new_agg = qfq_find_agg(q, lmax, weight);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An out-of-bounds write vulnerability in the Linux kernel's net/sched: sch_qfq component can be exploited to achieve local privilege escalation.\n\nThe qfq_change_agg() function in net/sched/sch_qfq.c allows an out-of-bounds write because lmax is updated according to packet sizes without bounds checks.\n\nWe recommend upgrading past commit 3e337087c3b5805fe0b8a46ba622a962880b5d64.\n\n"
    },
    {
        "cve_id": "CVE-2023-3812",
        "code_before_change": "static struct sk_buff *tun_napi_alloc_frags(struct tun_file *tfile,\n\t\t\t\t\t    size_t len,\n\t\t\t\t\t    const struct iov_iter *it)\n{\n\tstruct sk_buff *skb;\n\tsize_t linear;\n\tint err;\n\tint i;\n\n\tif (it->nr_segs > MAX_SKB_FRAGS + 1)\n\t\treturn ERR_PTR(-EMSGSIZE);\n\n\tlocal_bh_disable();\n\tskb = napi_get_frags(&tfile->napi);\n\tlocal_bh_enable();\n\tif (!skb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlinear = iov_iter_single_seg_count(it);\n\terr = __skb_grow(skb, linear);\n\tif (err)\n\t\tgoto free;\n\n\tskb->len = len;\n\tskb->data_len = len - linear;\n\tskb->truesize += skb->data_len;\n\n\tfor (i = 1; i < it->nr_segs; i++) {\n\t\tsize_t fragsz = it->iov[i].iov_len;\n\t\tstruct page *page;\n\t\tvoid *frag;\n\n\t\tif (fragsz == 0 || fragsz > PAGE_SIZE) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto free;\n\t\t}\n\t\tfrag = netdev_alloc_frag(fragsz);\n\t\tif (!frag) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free;\n\t\t}\n\t\tpage = virt_to_head_page(frag);\n\t\tskb_fill_page_desc(skb, i - 1, page,\n\t\t\t\t   frag - page_address(page), fragsz);\n\t}\n\n\treturn skb;\nfree:\n\t/* frees skb and all frags allocated with napi_alloc_frag() */\n\tnapi_free_frags(&tfile->napi);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "static struct sk_buff *tun_napi_alloc_frags(struct tun_file *tfile,\n\t\t\t\t\t    size_t len,\n\t\t\t\t\t    const struct iov_iter *it)\n{\n\tstruct sk_buff *skb;\n\tsize_t linear;\n\tint err;\n\tint i;\n\n\tif (it->nr_segs > MAX_SKB_FRAGS + 1 ||\n\t    len > (ETH_MAX_MTU - NET_SKB_PAD - NET_IP_ALIGN))\n\t\treturn ERR_PTR(-EMSGSIZE);\n\n\tlocal_bh_disable();\n\tskb = napi_get_frags(&tfile->napi);\n\tlocal_bh_enable();\n\tif (!skb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlinear = iov_iter_single_seg_count(it);\n\terr = __skb_grow(skb, linear);\n\tif (err)\n\t\tgoto free;\n\n\tskb->len = len;\n\tskb->data_len = len - linear;\n\tskb->truesize += skb->data_len;\n\n\tfor (i = 1; i < it->nr_segs; i++) {\n\t\tsize_t fragsz = it->iov[i].iov_len;\n\t\tstruct page *page;\n\t\tvoid *frag;\n\n\t\tif (fragsz == 0 || fragsz > PAGE_SIZE) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto free;\n\t\t}\n\t\tfrag = netdev_alloc_frag(fragsz);\n\t\tif (!frag) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free;\n\t\t}\n\t\tpage = virt_to_head_page(frag);\n\t\tskb_fill_page_desc(skb, i - 1, page,\n\t\t\t\t   frag - page_address(page), fragsz);\n\t}\n\n\treturn skb;\nfree:\n\t/* frees skb and all frags allocated with napi_alloc_frag() */\n\tnapi_free_frags(&tfile->napi);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,8 @@\n \tint err;\n \tint i;\n \n-\tif (it->nr_segs > MAX_SKB_FRAGS + 1)\n+\tif (it->nr_segs > MAX_SKB_FRAGS + 1 ||\n+\t    len > (ETH_MAX_MTU - NET_SKB_PAD - NET_IP_ALIGN))\n \t\treturn ERR_PTR(-EMSGSIZE);\n \n \tlocal_bh_disable();",
        "function_modified_lines": {
            "added": [
                "\tif (it->nr_segs > MAX_SKB_FRAGS + 1 ||",
                "\t    len > (ETH_MAX_MTU - NET_SKB_PAD - NET_IP_ALIGN))"
            ],
            "deleted": [
                "\tif (it->nr_segs > MAX_SKB_FRAGS + 1)"
            ]
        },
        "cwe": [
            "CWE-787",
            "CWE-416"
        ],
        "cve_description": "An out-of-bounds memory access flaw was found in the Linux kernel\u2019s TUN/TAP device driver functionality in how a user generates a malicious (too big) networking packet when napi frags is enabled. This flaw allows a local user to crash or potentially escalate their privileges on the system."
    },
    {
        "cve_id": "CVE-2023-4273",
        "code_before_change": "static int exfat_get_uniname_from_ext_entry(struct super_block *sb,\n\t\tstruct exfat_chain *p_dir, int entry, unsigned short *uniname)\n{\n\tint i, err;\n\tstruct exfat_entry_set_cache es;\n\n\terr = exfat_get_dentry_set(&es, sb, p_dir, entry, ES_ALL_ENTRIES);\n\tif (err)\n\t\treturn err;\n\n\t/*\n\t * First entry  : file entry\n\t * Second entry : stream-extension entry\n\t * Third entry  : first file-name entry\n\t * So, the index of first file-name dentry should start from 2.\n\t */\n\tfor (i = ES_IDX_FIRST_FILENAME; i < es.num_entries; i++) {\n\t\tstruct exfat_dentry *ep = exfat_get_dentry_cached(&es, i);\n\n\t\t/* end of name entry */\n\t\tif (exfat_get_entry_type(ep) != TYPE_EXTEND)\n\t\t\tbreak;\n\n\t\texfat_extract_uni_name(ep, uniname);\n\t\tuniname += EXFAT_FILE_NAME_LEN;\n\t}\n\n\texfat_put_dentry_set(&es, false);\n\treturn 0;\n}",
        "code_after_change": "static int exfat_get_uniname_from_ext_entry(struct super_block *sb,\n\t\tstruct exfat_chain *p_dir, int entry, unsigned short *uniname)\n{\n\tint i, err;\n\tstruct exfat_entry_set_cache es;\n\tunsigned int uni_len = 0, len;\n\n\terr = exfat_get_dentry_set(&es, sb, p_dir, entry, ES_ALL_ENTRIES);\n\tif (err)\n\t\treturn err;\n\n\t/*\n\t * First entry  : file entry\n\t * Second entry : stream-extension entry\n\t * Third entry  : first file-name entry\n\t * So, the index of first file-name dentry should start from 2.\n\t */\n\tfor (i = ES_IDX_FIRST_FILENAME; i < es.num_entries; i++) {\n\t\tstruct exfat_dentry *ep = exfat_get_dentry_cached(&es, i);\n\n\t\t/* end of name entry */\n\t\tif (exfat_get_entry_type(ep) != TYPE_EXTEND)\n\t\t\tbreak;\n\n\t\tlen = exfat_extract_uni_name(ep, uniname);\n\t\tuni_len += len;\n\t\tif (len != EXFAT_FILE_NAME_LEN || uni_len >= MAX_NAME_LENGTH)\n\t\t\tbreak;\n\t\tuniname += EXFAT_FILE_NAME_LEN;\n\t}\n\n\texfat_put_dentry_set(&es, false);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n {\n \tint i, err;\n \tstruct exfat_entry_set_cache es;\n+\tunsigned int uni_len = 0, len;\n \n \terr = exfat_get_dentry_set(&es, sb, p_dir, entry, ES_ALL_ENTRIES);\n \tif (err)\n@@ -21,7 +22,10 @@\n \t\tif (exfat_get_entry_type(ep) != TYPE_EXTEND)\n \t\t\tbreak;\n \n-\t\texfat_extract_uni_name(ep, uniname);\n+\t\tlen = exfat_extract_uni_name(ep, uniname);\n+\t\tuni_len += len;\n+\t\tif (len != EXFAT_FILE_NAME_LEN || uni_len >= MAX_NAME_LENGTH)\n+\t\t\tbreak;\n \t\tuniname += EXFAT_FILE_NAME_LEN;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tunsigned int uni_len = 0, len;",
                "\t\tlen = exfat_extract_uni_name(ep, uniname);",
                "\t\tuni_len += len;",
                "\t\tif (len != EXFAT_FILE_NAME_LEN || uni_len >= MAX_NAME_LENGTH)",
                "\t\t\tbreak;"
            ],
            "deleted": [
                "\t\texfat_extract_uni_name(ep, uniname);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the exFAT driver of the Linux kernel. The vulnerability exists in the implementation of the file name reconstruction function, which is responsible for reading file name entries from a directory index and merging file name parts belonging to one file into a single long file name. Since the file name characters are copied into a stack variable, a local privileged attacker could use this flaw to overflow the kernel stack."
    },
    {
        "cve_id": "CVE-2023-4273",
        "code_before_change": "int exfat_find_dir_entry(struct super_block *sb, struct exfat_inode_info *ei,\n\t\tstruct exfat_chain *p_dir, struct exfat_uni_name *p_uniname,\n\t\tstruct exfat_hint *hint_opt)\n{\n\tint i, rewind = 0, dentry = 0, end_eidx = 0, num_ext = 0, len;\n\tint order, step, name_len = 0;\n\tint dentries_per_clu;\n\tunsigned int entry_type;\n\tunsigned short *uniname = NULL;\n\tstruct exfat_chain clu;\n\tstruct exfat_hint *hint_stat = &ei->hint_stat;\n\tstruct exfat_hint_femp candi_empty;\n\tstruct exfat_sb_info *sbi = EXFAT_SB(sb);\n\tint num_entries = exfat_calc_num_entries(p_uniname);\n\n\tif (num_entries < 0)\n\t\treturn num_entries;\n\n\tdentries_per_clu = sbi->dentries_per_clu;\n\n\texfat_chain_dup(&clu, p_dir);\n\n\tif (hint_stat->eidx) {\n\t\tclu.dir = hint_stat->clu;\n\t\tdentry = hint_stat->eidx;\n\t\tend_eidx = dentry;\n\t}\n\n\texfat_reset_empty_hint(&ei->hint_femp);\n\nrewind:\n\torder = 0;\n\tstep = DIRENT_STEP_FILE;\n\texfat_reset_empty_hint(&candi_empty);\n\n\twhile (clu.dir != EXFAT_EOF_CLUSTER) {\n\t\ti = dentry & (dentries_per_clu - 1);\n\t\tfor (; i < dentries_per_clu; i++, dentry++) {\n\t\t\tstruct exfat_dentry *ep;\n\t\t\tstruct buffer_head *bh;\n\n\t\t\tif (rewind && dentry == end_eidx)\n\t\t\t\tgoto not_found;\n\n\t\t\tep = exfat_get_dentry(sb, &clu, i, &bh);\n\t\t\tif (!ep)\n\t\t\t\treturn -EIO;\n\n\t\t\tentry_type = exfat_get_entry_type(ep);\n\n\t\t\tif (entry_type == TYPE_UNUSED ||\n\t\t\t    entry_type == TYPE_DELETED) {\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\n\t\t\t\texfat_set_empty_hint(ei, &candi_empty, &clu,\n\t\t\t\t\t\tdentry, num_entries,\n\t\t\t\t\t\tentry_type);\n\n\t\t\t\tbrelse(bh);\n\t\t\t\tif (entry_type == TYPE_UNUSED)\n\t\t\t\t\tgoto not_found;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\texfat_reset_empty_hint(&candi_empty);\n\n\t\t\tif (entry_type == TYPE_FILE || entry_type == TYPE_DIR) {\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\thint_opt->clu = clu.dir;\n\t\t\t\thint_opt->eidx = i;\n\t\t\t\tnum_ext = ep->dentry.file.num_ext;\n\t\t\t\tstep = DIRENT_STEP_STRM;\n\t\t\t\tbrelse(bh);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (entry_type == TYPE_STREAM) {\n\t\t\t\tu16 name_hash;\n\n\t\t\t\tif (step != DIRENT_STEP_STRM) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t\tbrelse(bh);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\tname_hash = le16_to_cpu(\n\t\t\t\t\t\tep->dentry.stream.name_hash);\n\t\t\t\tif (p_uniname->name_hash == name_hash &&\n\t\t\t\t    p_uniname->name_len ==\n\t\t\t\t\t\tep->dentry.stream.name_len) {\n\t\t\t\t\tstep = DIRENT_STEP_NAME;\n\t\t\t\t\torder = 1;\n\t\t\t\t\tname_len = 0;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tbrelse(bh);\n\t\t\tif (entry_type == TYPE_EXTEND) {\n\t\t\t\tunsigned short entry_uniname[16], unichar;\n\n\t\t\t\tif (step != DIRENT_STEP_NAME) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (++order == 2)\n\t\t\t\t\tuniname = p_uniname->name;\n\t\t\t\telse\n\t\t\t\t\tuniname += EXFAT_FILE_NAME_LEN;\n\n\t\t\t\tlen = exfat_extract_uni_name(ep, entry_uniname);\n\t\t\t\tname_len += len;\n\n\t\t\t\tunichar = *(uniname+len);\n\t\t\t\t*(uniname+len) = 0x0;\n\n\t\t\t\tif (exfat_uniname_ncmp(sb, uniname,\n\t\t\t\t\tentry_uniname, len)) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t} else if (p_uniname->name_len == name_len) {\n\t\t\t\t\tif (order == num_ext)\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\tstep = DIRENT_STEP_SECD;\n\t\t\t\t}\n\n\t\t\t\t*(uniname+len) = unichar;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (entry_type &\n\t\t\t\t\t(TYPE_CRITICAL_SEC | TYPE_BENIGN_SEC)) {\n\t\t\t\tif (step == DIRENT_STEP_SECD) {\n\t\t\t\t\tif (++order == num_ext)\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tstep = DIRENT_STEP_FILE;\n\t\t}\n\n\t\tif (clu.flags == ALLOC_NO_FAT_CHAIN) {\n\t\t\tif (--clu.size > 0)\n\t\t\t\tclu.dir++;\n\t\t\telse\n\t\t\t\tclu.dir = EXFAT_EOF_CLUSTER;\n\t\t} else {\n\t\t\tif (exfat_get_next_cluster(sb, &clu.dir))\n\t\t\t\treturn -EIO;\n\t\t}\n\t}\n\nnot_found:\n\t/*\n\t * We started at not 0 index,so we should try to find target\n\t * from 0 index to the index we started at.\n\t */\n\tif (!rewind && end_eidx) {\n\t\trewind = 1;\n\t\tdentry = 0;\n\t\tclu.dir = p_dir->dir;\n\t\tgoto rewind;\n\t}\n\n\t/*\n\t * set the EXFAT_EOF_CLUSTER flag to avoid search\n\t * from the beginning again when allocated a new cluster\n\t */\n\tif (ei->hint_femp.eidx == EXFAT_HINT_NONE) {\n\t\tei->hint_femp.cur.dir = EXFAT_EOF_CLUSTER;\n\t\tei->hint_femp.eidx = p_dir->size * dentries_per_clu;\n\t\tei->hint_femp.count = 0;\n\t}\n\n\t/* initialized hint_stat */\n\thint_stat->clu = p_dir->dir;\n\thint_stat->eidx = 0;\n\treturn -ENOENT;\n\nfound:\n\t/* next dentry we'll find is out of this cluster */\n\tif (!((dentry + 1) & (dentries_per_clu - 1))) {\n\t\tint ret = 0;\n\n\t\tif (clu.flags == ALLOC_NO_FAT_CHAIN) {\n\t\t\tif (--clu.size > 0)\n\t\t\t\tclu.dir++;\n\t\t\telse\n\t\t\t\tclu.dir = EXFAT_EOF_CLUSTER;\n\t\t} else {\n\t\t\tret = exfat_get_next_cluster(sb, &clu.dir);\n\t\t}\n\n\t\tif (ret || clu.dir == EXFAT_EOF_CLUSTER) {\n\t\t\t/* just initialized hint_stat */\n\t\t\thint_stat->clu = p_dir->dir;\n\t\t\thint_stat->eidx = 0;\n\t\t\treturn (dentry - num_ext);\n\t\t}\n\t}\n\n\thint_stat->clu = clu.dir;\n\thint_stat->eidx = dentry + 1;\n\treturn dentry - num_ext;\n}",
        "code_after_change": "int exfat_find_dir_entry(struct super_block *sb, struct exfat_inode_info *ei,\n\t\tstruct exfat_chain *p_dir, struct exfat_uni_name *p_uniname,\n\t\tstruct exfat_hint *hint_opt)\n{\n\tint i, rewind = 0, dentry = 0, end_eidx = 0, num_ext = 0, len;\n\tint order, step, name_len = 0;\n\tint dentries_per_clu;\n\tunsigned int entry_type;\n\tunsigned short *uniname = NULL;\n\tstruct exfat_chain clu;\n\tstruct exfat_hint *hint_stat = &ei->hint_stat;\n\tstruct exfat_hint_femp candi_empty;\n\tstruct exfat_sb_info *sbi = EXFAT_SB(sb);\n\tint num_entries = exfat_calc_num_entries(p_uniname);\n\n\tif (num_entries < 0)\n\t\treturn num_entries;\n\n\tdentries_per_clu = sbi->dentries_per_clu;\n\n\texfat_chain_dup(&clu, p_dir);\n\n\tif (hint_stat->eidx) {\n\t\tclu.dir = hint_stat->clu;\n\t\tdentry = hint_stat->eidx;\n\t\tend_eidx = dentry;\n\t}\n\n\texfat_reset_empty_hint(&ei->hint_femp);\n\nrewind:\n\torder = 0;\n\tstep = DIRENT_STEP_FILE;\n\texfat_reset_empty_hint(&candi_empty);\n\n\twhile (clu.dir != EXFAT_EOF_CLUSTER) {\n\t\ti = dentry & (dentries_per_clu - 1);\n\t\tfor (; i < dentries_per_clu; i++, dentry++) {\n\t\t\tstruct exfat_dentry *ep;\n\t\t\tstruct buffer_head *bh;\n\n\t\t\tif (rewind && dentry == end_eidx)\n\t\t\t\tgoto not_found;\n\n\t\t\tep = exfat_get_dentry(sb, &clu, i, &bh);\n\t\t\tif (!ep)\n\t\t\t\treturn -EIO;\n\n\t\t\tentry_type = exfat_get_entry_type(ep);\n\n\t\t\tif (entry_type == TYPE_UNUSED ||\n\t\t\t    entry_type == TYPE_DELETED) {\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\n\t\t\t\texfat_set_empty_hint(ei, &candi_empty, &clu,\n\t\t\t\t\t\tdentry, num_entries,\n\t\t\t\t\t\tentry_type);\n\n\t\t\t\tbrelse(bh);\n\t\t\t\tif (entry_type == TYPE_UNUSED)\n\t\t\t\t\tgoto not_found;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\texfat_reset_empty_hint(&candi_empty);\n\n\t\t\tif (entry_type == TYPE_FILE || entry_type == TYPE_DIR) {\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\thint_opt->clu = clu.dir;\n\t\t\t\thint_opt->eidx = i;\n\t\t\t\tnum_ext = ep->dentry.file.num_ext;\n\t\t\t\tstep = DIRENT_STEP_STRM;\n\t\t\t\tbrelse(bh);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (entry_type == TYPE_STREAM) {\n\t\t\t\tu16 name_hash;\n\n\t\t\t\tif (step != DIRENT_STEP_STRM) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t\tbrelse(bh);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\tname_hash = le16_to_cpu(\n\t\t\t\t\t\tep->dentry.stream.name_hash);\n\t\t\t\tif (p_uniname->name_hash == name_hash &&\n\t\t\t\t    p_uniname->name_len ==\n\t\t\t\t\t\tep->dentry.stream.name_len) {\n\t\t\t\t\tstep = DIRENT_STEP_NAME;\n\t\t\t\t\torder = 1;\n\t\t\t\t\tname_len = 0;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tbrelse(bh);\n\t\t\tif (entry_type == TYPE_EXTEND) {\n\t\t\t\tunsigned short entry_uniname[16], unichar;\n\n\t\t\t\tif (step != DIRENT_STEP_NAME ||\n\t\t\t\t    name_len >= MAX_NAME_LENGTH) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (++order == 2)\n\t\t\t\t\tuniname = p_uniname->name;\n\t\t\t\telse\n\t\t\t\t\tuniname += EXFAT_FILE_NAME_LEN;\n\n\t\t\t\tlen = exfat_extract_uni_name(ep, entry_uniname);\n\t\t\t\tname_len += len;\n\n\t\t\t\tunichar = *(uniname+len);\n\t\t\t\t*(uniname+len) = 0x0;\n\n\t\t\t\tif (exfat_uniname_ncmp(sb, uniname,\n\t\t\t\t\tentry_uniname, len)) {\n\t\t\t\t\tstep = DIRENT_STEP_FILE;\n\t\t\t\t} else if (p_uniname->name_len == name_len) {\n\t\t\t\t\tif (order == num_ext)\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\tstep = DIRENT_STEP_SECD;\n\t\t\t\t}\n\n\t\t\t\t*(uniname+len) = unichar;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (entry_type &\n\t\t\t\t\t(TYPE_CRITICAL_SEC | TYPE_BENIGN_SEC)) {\n\t\t\t\tif (step == DIRENT_STEP_SECD) {\n\t\t\t\t\tif (++order == num_ext)\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tstep = DIRENT_STEP_FILE;\n\t\t}\n\n\t\tif (clu.flags == ALLOC_NO_FAT_CHAIN) {\n\t\t\tif (--clu.size > 0)\n\t\t\t\tclu.dir++;\n\t\t\telse\n\t\t\t\tclu.dir = EXFAT_EOF_CLUSTER;\n\t\t} else {\n\t\t\tif (exfat_get_next_cluster(sb, &clu.dir))\n\t\t\t\treturn -EIO;\n\t\t}\n\t}\n\nnot_found:\n\t/*\n\t * We started at not 0 index,so we should try to find target\n\t * from 0 index to the index we started at.\n\t */\n\tif (!rewind && end_eidx) {\n\t\trewind = 1;\n\t\tdentry = 0;\n\t\tclu.dir = p_dir->dir;\n\t\tgoto rewind;\n\t}\n\n\t/*\n\t * set the EXFAT_EOF_CLUSTER flag to avoid search\n\t * from the beginning again when allocated a new cluster\n\t */\n\tif (ei->hint_femp.eidx == EXFAT_HINT_NONE) {\n\t\tei->hint_femp.cur.dir = EXFAT_EOF_CLUSTER;\n\t\tei->hint_femp.eidx = p_dir->size * dentries_per_clu;\n\t\tei->hint_femp.count = 0;\n\t}\n\n\t/* initialized hint_stat */\n\thint_stat->clu = p_dir->dir;\n\thint_stat->eidx = 0;\n\treturn -ENOENT;\n\nfound:\n\t/* next dentry we'll find is out of this cluster */\n\tif (!((dentry + 1) & (dentries_per_clu - 1))) {\n\t\tint ret = 0;\n\n\t\tif (clu.flags == ALLOC_NO_FAT_CHAIN) {\n\t\t\tif (--clu.size > 0)\n\t\t\t\tclu.dir++;\n\t\t\telse\n\t\t\t\tclu.dir = EXFAT_EOF_CLUSTER;\n\t\t} else {\n\t\t\tret = exfat_get_next_cluster(sb, &clu.dir);\n\t\t}\n\n\t\tif (ret || clu.dir == EXFAT_EOF_CLUSTER) {\n\t\t\t/* just initialized hint_stat */\n\t\t\thint_stat->clu = p_dir->dir;\n\t\t\thint_stat->eidx = 0;\n\t\t\treturn (dentry - num_ext);\n\t\t}\n\t}\n\n\thint_stat->clu = clu.dir;\n\thint_stat->eidx = dentry + 1;\n\treturn dentry - num_ext;\n}",
        "patch": "--- code before\n+++ code after\n@@ -100,7 +100,8 @@\n \t\t\tif (entry_type == TYPE_EXTEND) {\n \t\t\t\tunsigned short entry_uniname[16], unichar;\n \n-\t\t\t\tif (step != DIRENT_STEP_NAME) {\n+\t\t\t\tif (step != DIRENT_STEP_NAME ||\n+\t\t\t\t    name_len >= MAX_NAME_LENGTH) {\n \t\t\t\t\tstep = DIRENT_STEP_FILE;\n \t\t\t\t\tcontinue;\n \t\t\t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tif (step != DIRENT_STEP_NAME ||",
                "\t\t\t\t    name_len >= MAX_NAME_LENGTH) {"
            ],
            "deleted": [
                "\t\t\t\tif (step != DIRENT_STEP_NAME) {"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the exFAT driver of the Linux kernel. The vulnerability exists in the implementation of the file name reconstruction function, which is responsible for reading file name entries from a directory index and merging file name parts belonging to one file into a single long file name. Since the file name characters are copied into a stack variable, a local privileged attacker could use this flaw to overflow the kernel stack."
    },
    {
        "cve_id": "CVE-2023-45863",
        "code_before_change": "char *kobject_get_path(const struct kobject *kobj, gfp_t gfp_mask)\n{\n\tchar *path;\n\tint len;\n\n\tlen = get_kobj_path_length(kobj);\n\tif (len == 0)\n\t\treturn NULL;\n\tpath = kzalloc(len, gfp_mask);\n\tif (!path)\n\t\treturn NULL;\n\tfill_kobj_path(kobj, path, len);\n\n\treturn path;\n}",
        "code_after_change": "char *kobject_get_path(const struct kobject *kobj, gfp_t gfp_mask)\n{\n\tchar *path;\n\tint len;\n\nretry:\n\tlen = get_kobj_path_length(kobj);\n\tif (len == 0)\n\t\treturn NULL;\n\tpath = kzalloc(len, gfp_mask);\n\tif (!path)\n\t\treturn NULL;\n\tif (fill_kobj_path(kobj, path, len)) {\n\t\tkfree(path);\n\t\tgoto retry;\n\t}\n\n\treturn path;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,13 +3,17 @@\n \tchar *path;\n \tint len;\n \n+retry:\n \tlen = get_kobj_path_length(kobj);\n \tif (len == 0)\n \t\treturn NULL;\n \tpath = kzalloc(len, gfp_mask);\n \tif (!path)\n \t\treturn NULL;\n-\tfill_kobj_path(kobj, path, len);\n+\tif (fill_kobj_path(kobj, path, len)) {\n+\t\tkfree(path);\n+\t\tgoto retry;\n+\t}\n \n \treturn path;\n }",
        "function_modified_lines": {
            "added": [
                "retry:",
                "\tif (fill_kobj_path(kobj, path, len)) {",
                "\t\tkfree(path);",
                "\t\tgoto retry;",
                "\t}"
            ],
            "deleted": [
                "\tfill_kobj_path(kobj, path, len);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in lib/kobject.c in the Linux kernel before 6.2.3. With root access, an attacker can trigger a race condition that results in a fill_kobj_path out-of-bounds write."
    },
    {
        "cve_id": "CVE-2023-45863",
        "code_before_change": "static void fill_kobj_path(const struct kobject *kobj, char *path, int length)\n{\n\tconst struct kobject *parent;\n\n\t--length;\n\tfor (parent = kobj; parent; parent = parent->parent) {\n\t\tint cur = strlen(kobject_name(parent));\n\t\t/* back up enough to print this name with '/' */\n\t\tlength -= cur;\n\t\tmemcpy(path + length, kobject_name(parent), cur);\n\t\t*(path + --length) = '/';\n\t}\n\n\tpr_debug(\"kobject: '%s' (%p): %s: path = '%s'\\n\", kobject_name(kobj),\n\t\t kobj, __func__, path);\n}",
        "code_after_change": "static int fill_kobj_path(const struct kobject *kobj, char *path, int length)\n{\n\tconst struct kobject *parent;\n\n\t--length;\n\tfor (parent = kobj; parent; parent = parent->parent) {\n\t\tint cur = strlen(kobject_name(parent));\n\t\t/* back up enough to print this name with '/' */\n\t\tlength -= cur;\n\t\tif (length <= 0)\n\t\t\treturn -EINVAL;\n\t\tmemcpy(path + length, kobject_name(parent), cur);\n\t\t*(path + --length) = '/';\n\t}\n\n\tpr_debug(\"kobject: '%s' (%p): %s: path = '%s'\\n\", kobject_name(kobj),\n\t\t kobj, __func__, path);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n-static void fill_kobj_path(const struct kobject *kobj, char *path, int length)\n+static int fill_kobj_path(const struct kobject *kobj, char *path, int length)\n {\n \tconst struct kobject *parent;\n \n@@ -7,10 +7,14 @@\n \t\tint cur = strlen(kobject_name(parent));\n \t\t/* back up enough to print this name with '/' */\n \t\tlength -= cur;\n+\t\tif (length <= 0)\n+\t\t\treturn -EINVAL;\n \t\tmemcpy(path + length, kobject_name(parent), cur);\n \t\t*(path + --length) = '/';\n \t}\n \n \tpr_debug(\"kobject: '%s' (%p): %s: path = '%s'\\n\", kobject_name(kobj),\n \t\t kobj, __func__, path);\n+\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "static int fill_kobj_path(const struct kobject *kobj, char *path, int length)",
                "\t\tif (length <= 0)",
                "\t\t\treturn -EINVAL;",
                "",
                "\treturn 0;"
            ],
            "deleted": [
                "static void fill_kobj_path(const struct kobject *kobj, char *path, int length)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in lib/kobject.c in the Linux kernel before 6.2.3. With root access, an attacker can trigger a race condition that results in a fill_kobj_path out-of-bounds write."
    },
    {
        "cve_id": "CVE-2023-5717",
        "code_before_change": "static void perf_group_detach(struct perf_event *event)\n{\n\tstruct perf_event *leader = event->group_leader;\n\tstruct perf_event *sibling, *tmp;\n\tstruct perf_event_context *ctx = event->ctx;\n\n\tlockdep_assert_held(&ctx->lock);\n\n\t/*\n\t * We can have double detach due to exit/hot-unplug + close.\n\t */\n\tif (!(event->attach_state & PERF_ATTACH_GROUP))\n\t\treturn;\n\n\tevent->attach_state &= ~PERF_ATTACH_GROUP;\n\n\tperf_put_aux_event(event);\n\n\t/*\n\t * If this is a sibling, remove it from its group.\n\t */\n\tif (leader != event) {\n\t\tlist_del_init(&event->sibling_list);\n\t\tevent->group_leader->nr_siblings--;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If this was a group event with sibling events then\n\t * upgrade the siblings to singleton events by adding them\n\t * to whatever list we are on.\n\t */\n\tlist_for_each_entry_safe(sibling, tmp, &event->sibling_list, sibling_list) {\n\n\t\tif (sibling->event_caps & PERF_EV_CAP_SIBLING)\n\t\t\tperf_remove_sibling_event(sibling);\n\n\t\tsibling->group_leader = sibling;\n\t\tlist_del_init(&sibling->sibling_list);\n\n\t\t/* Inherit group flags from the previous leader */\n\t\tsibling->group_caps = event->group_caps;\n\n\t\tif (sibling->attach_state & PERF_ATTACH_CONTEXT) {\n\t\t\tadd_event_to_groups(sibling, event->ctx);\n\n\t\t\tif (sibling->state == PERF_EVENT_STATE_ACTIVE)\n\t\t\t\tlist_add_tail(&sibling->active_list, get_event_list(sibling));\n\t\t}\n\n\t\tWARN_ON_ONCE(sibling->ctx != event->ctx);\n\t}\n\nout:\n\tfor_each_sibling_event(tmp, leader)\n\t\tperf_event__header_size(tmp);\n\n\tperf_event__header_size(leader);\n}",
        "code_after_change": "static void perf_group_detach(struct perf_event *event)\n{\n\tstruct perf_event *leader = event->group_leader;\n\tstruct perf_event *sibling, *tmp;\n\tstruct perf_event_context *ctx = event->ctx;\n\n\tlockdep_assert_held(&ctx->lock);\n\n\t/*\n\t * We can have double detach due to exit/hot-unplug + close.\n\t */\n\tif (!(event->attach_state & PERF_ATTACH_GROUP))\n\t\treturn;\n\n\tevent->attach_state &= ~PERF_ATTACH_GROUP;\n\n\tperf_put_aux_event(event);\n\n\t/*\n\t * If this is a sibling, remove it from its group.\n\t */\n\tif (leader != event) {\n\t\tlist_del_init(&event->sibling_list);\n\t\tevent->group_leader->nr_siblings--;\n\t\tevent->group_leader->group_generation++;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If this was a group event with sibling events then\n\t * upgrade the siblings to singleton events by adding them\n\t * to whatever list we are on.\n\t */\n\tlist_for_each_entry_safe(sibling, tmp, &event->sibling_list, sibling_list) {\n\n\t\tif (sibling->event_caps & PERF_EV_CAP_SIBLING)\n\t\t\tperf_remove_sibling_event(sibling);\n\n\t\tsibling->group_leader = sibling;\n\t\tlist_del_init(&sibling->sibling_list);\n\n\t\t/* Inherit group flags from the previous leader */\n\t\tsibling->group_caps = event->group_caps;\n\n\t\tif (sibling->attach_state & PERF_ATTACH_CONTEXT) {\n\t\t\tadd_event_to_groups(sibling, event->ctx);\n\n\t\t\tif (sibling->state == PERF_EVENT_STATE_ACTIVE)\n\t\t\t\tlist_add_tail(&sibling->active_list, get_event_list(sibling));\n\t\t}\n\n\t\tWARN_ON_ONCE(sibling->ctx != event->ctx);\n\t}\n\nout:\n\tfor_each_sibling_event(tmp, leader)\n\t\tperf_event__header_size(tmp);\n\n\tperf_event__header_size(leader);\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,7 @@\n \tif (leader != event) {\n \t\tlist_del_init(&event->sibling_list);\n \t\tevent->group_leader->nr_siblings--;\n+\t\tevent->group_leader->group_generation++;\n \t\tgoto out;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tevent->group_leader->group_generation++;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Linux Kernel Performance Events (perf) component can be exploited to achieve local privilege escalation.\n\nIf perf_read_group() is called while an event's sibling_list is smaller than its child's sibling_list, it can increment or write to memory locations outside of the allocated buffer.\n\nWe recommend upgrading past commit 32671e3799ca2e4590773fd0e63aaa4229e50c06.\n\n"
    },
    {
        "cve_id": "CVE-2023-5717",
        "code_before_change": "static int __perf_read_group_add(struct perf_event *leader,\n\t\t\t\t\tu64 read_format, u64 *values)\n{\n\tstruct perf_event_context *ctx = leader->ctx;\n\tstruct perf_event *sub;\n\tunsigned long flags;\n\tint n = 1; /* skip @nr */\n\tint ret;\n\n\tret = perf_event_read(leader, true);\n\tif (ret)\n\t\treturn ret;\n\n\traw_spin_lock_irqsave(&ctx->lock, flags);\n\n\t/*\n\t * Since we co-schedule groups, {enabled,running} times of siblings\n\t * will be identical to those of the leader, so we only publish one\n\t * set.\n\t */\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED) {\n\t\tvalues[n++] += leader->total_time_enabled +\n\t\t\tatomic64_read(&leader->child_total_time_enabled);\n\t}\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING) {\n\t\tvalues[n++] += leader->total_time_running +\n\t\t\tatomic64_read(&leader->child_total_time_running);\n\t}\n\n\t/*\n\t * Write {count,id} tuples for every sibling.\n\t */\n\tvalues[n++] += perf_event_count(leader);\n\tif (read_format & PERF_FORMAT_ID)\n\t\tvalues[n++] = primary_event_id(leader);\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tvalues[n++] = atomic64_read(&leader->lost_samples);\n\n\tfor_each_sibling_event(sub, leader) {\n\t\tvalues[n++] += perf_event_count(sub);\n\t\tif (read_format & PERF_FORMAT_ID)\n\t\t\tvalues[n++] = primary_event_id(sub);\n\t\tif (read_format & PERF_FORMAT_LOST)\n\t\t\tvalues[n++] = atomic64_read(&sub->lost_samples);\n\t}\n\n\traw_spin_unlock_irqrestore(&ctx->lock, flags);\n\treturn 0;\n}",
        "code_after_change": "static int __perf_read_group_add(struct perf_event *leader,\n\t\t\t\t\tu64 read_format, u64 *values)\n{\n\tstruct perf_event_context *ctx = leader->ctx;\n\tstruct perf_event *sub, *parent;\n\tunsigned long flags;\n\tint n = 1; /* skip @nr */\n\tint ret;\n\n\tret = perf_event_read(leader, true);\n\tif (ret)\n\t\treturn ret;\n\n\traw_spin_lock_irqsave(&ctx->lock, flags);\n\t/*\n\t * Verify the grouping between the parent and child (inherited)\n\t * events is still in tact.\n\t *\n\t * Specifically:\n\t *  - leader->ctx->lock pins leader->sibling_list\n\t *  - parent->child_mutex pins parent->child_list\n\t *  - parent->ctx->mutex pins parent->sibling_list\n\t *\n\t * Because parent->ctx != leader->ctx (and child_list nests inside\n\t * ctx->mutex), group destruction is not atomic between children, also\n\t * see perf_event_release_kernel(). Additionally, parent can grow the\n\t * group.\n\t *\n\t * Therefore it is possible to have parent and child groups in a\n\t * different configuration and summing over such a beast makes no sense\n\t * what so ever.\n\t *\n\t * Reject this.\n\t */\n\tparent = leader->parent;\n\tif (parent &&\n\t    (parent->group_generation != leader->group_generation ||\n\t     parent->nr_siblings != leader->nr_siblings)) {\n\t\tret = -ECHILD;\n\t\tgoto unlock;\n\t}\n\n\t/*\n\t * Since we co-schedule groups, {enabled,running} times of siblings\n\t * will be identical to those of the leader, so we only publish one\n\t * set.\n\t */\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED) {\n\t\tvalues[n++] += leader->total_time_enabled +\n\t\t\tatomic64_read(&leader->child_total_time_enabled);\n\t}\n\n\tif (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING) {\n\t\tvalues[n++] += leader->total_time_running +\n\t\t\tatomic64_read(&leader->child_total_time_running);\n\t}\n\n\t/*\n\t * Write {count,id} tuples for every sibling.\n\t */\n\tvalues[n++] += perf_event_count(leader);\n\tif (read_format & PERF_FORMAT_ID)\n\t\tvalues[n++] = primary_event_id(leader);\n\tif (read_format & PERF_FORMAT_LOST)\n\t\tvalues[n++] = atomic64_read(&leader->lost_samples);\n\n\tfor_each_sibling_event(sub, leader) {\n\t\tvalues[n++] += perf_event_count(sub);\n\t\tif (read_format & PERF_FORMAT_ID)\n\t\t\tvalues[n++] = primary_event_id(sub);\n\t\tif (read_format & PERF_FORMAT_LOST)\n\t\t\tvalues[n++] = atomic64_read(&sub->lost_samples);\n\t}\n\nunlock:\n\traw_spin_unlock_irqrestore(&ctx->lock, flags);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t\t\tu64 read_format, u64 *values)\n {\n \tstruct perf_event_context *ctx = leader->ctx;\n-\tstruct perf_event *sub;\n+\tstruct perf_event *sub, *parent;\n \tunsigned long flags;\n \tint n = 1; /* skip @nr */\n \tint ret;\n@@ -12,6 +12,33 @@\n \t\treturn ret;\n \n \traw_spin_lock_irqsave(&ctx->lock, flags);\n+\t/*\n+\t * Verify the grouping between the parent and child (inherited)\n+\t * events is still in tact.\n+\t *\n+\t * Specifically:\n+\t *  - leader->ctx->lock pins leader->sibling_list\n+\t *  - parent->child_mutex pins parent->child_list\n+\t *  - parent->ctx->mutex pins parent->sibling_list\n+\t *\n+\t * Because parent->ctx != leader->ctx (and child_list nests inside\n+\t * ctx->mutex), group destruction is not atomic between children, also\n+\t * see perf_event_release_kernel(). Additionally, parent can grow the\n+\t * group.\n+\t *\n+\t * Therefore it is possible to have parent and child groups in a\n+\t * different configuration and summing over such a beast makes no sense\n+\t * what so ever.\n+\t *\n+\t * Reject this.\n+\t */\n+\tparent = leader->parent;\n+\tif (parent &&\n+\t    (parent->group_generation != leader->group_generation ||\n+\t     parent->nr_siblings != leader->nr_siblings)) {\n+\t\tret = -ECHILD;\n+\t\tgoto unlock;\n+\t}\n \n \t/*\n \t * Since we co-schedule groups, {enabled,running} times of siblings\n@@ -45,6 +72,7 @@\n \t\t\tvalues[n++] = atomic64_read(&sub->lost_samples);\n \t}\n \n+unlock:\n \traw_spin_unlock_irqrestore(&ctx->lock, flags);\n-\treturn 0;\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct perf_event *sub, *parent;",
                "\t/*",
                "\t * Verify the grouping between the parent and child (inherited)",
                "\t * events is still in tact.",
                "\t *",
                "\t * Specifically:",
                "\t *  - leader->ctx->lock pins leader->sibling_list",
                "\t *  - parent->child_mutex pins parent->child_list",
                "\t *  - parent->ctx->mutex pins parent->sibling_list",
                "\t *",
                "\t * Because parent->ctx != leader->ctx (and child_list nests inside",
                "\t * ctx->mutex), group destruction is not atomic between children, also",
                "\t * see perf_event_release_kernel(). Additionally, parent can grow the",
                "\t * group.",
                "\t *",
                "\t * Therefore it is possible to have parent and child groups in a",
                "\t * different configuration and summing over such a beast makes no sense",
                "\t * what so ever.",
                "\t *",
                "\t * Reject this.",
                "\t */",
                "\tparent = leader->parent;",
                "\tif (parent &&",
                "\t    (parent->group_generation != leader->group_generation ||",
                "\t     parent->nr_siblings != leader->nr_siblings)) {",
                "\t\tret = -ECHILD;",
                "\t\tgoto unlock;",
                "\t}",
                "unlock:",
                "\treturn ret;"
            ],
            "deleted": [
                "\tstruct perf_event *sub;",
                "\treturn 0;"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Linux Kernel Performance Events (perf) component can be exploited to achieve local privilege escalation.\n\nIf perf_read_group() is called while an event's sibling_list is smaller than its child's sibling_list, it can increment or write to memory locations outside of the allocated buffer.\n\nWe recommend upgrading past commit 32671e3799ca2e4590773fd0e63aaa4229e50c06.\n\n"
    },
    {
        "cve_id": "CVE-2023-5717",
        "code_before_change": "static int perf_read_group(struct perf_event *event,\n\t\t\t\t   u64 read_format, char __user *buf)\n{\n\tstruct perf_event *leader = event->group_leader, *child;\n\tstruct perf_event_context *ctx = leader->ctx;\n\tint ret;\n\tu64 *values;\n\n\tlockdep_assert_held(&ctx->mutex);\n\n\tvalues = kzalloc(event->read_size, GFP_KERNEL);\n\tif (!values)\n\t\treturn -ENOMEM;\n\n\tvalues[0] = 1 + leader->nr_siblings;\n\n\t/*\n\t * By locking the child_mutex of the leader we effectively\n\t * lock the child list of all siblings.. XXX explain how.\n\t */\n\tmutex_lock(&leader->child_mutex);\n\n\tret = __perf_read_group_add(leader, read_format, values);\n\tif (ret)\n\t\tgoto unlock;\n\n\tlist_for_each_entry(child, &leader->child_list, child_list) {\n\t\tret = __perf_read_group_add(child, read_format, values);\n\t\tif (ret)\n\t\t\tgoto unlock;\n\t}\n\n\tmutex_unlock(&leader->child_mutex);\n\n\tret = event->read_size;\n\tif (copy_to_user(buf, values, event->read_size))\n\t\tret = -EFAULT;\n\tgoto out;\n\nunlock:\n\tmutex_unlock(&leader->child_mutex);\nout:\n\tkfree(values);\n\treturn ret;\n}",
        "code_after_change": "static int perf_read_group(struct perf_event *event,\n\t\t\t\t   u64 read_format, char __user *buf)\n{\n\tstruct perf_event *leader = event->group_leader, *child;\n\tstruct perf_event_context *ctx = leader->ctx;\n\tint ret;\n\tu64 *values;\n\n\tlockdep_assert_held(&ctx->mutex);\n\n\tvalues = kzalloc(event->read_size, GFP_KERNEL);\n\tif (!values)\n\t\treturn -ENOMEM;\n\n\tvalues[0] = 1 + leader->nr_siblings;\n\n\tmutex_lock(&leader->child_mutex);\n\n\tret = __perf_read_group_add(leader, read_format, values);\n\tif (ret)\n\t\tgoto unlock;\n\n\tlist_for_each_entry(child, &leader->child_list, child_list) {\n\t\tret = __perf_read_group_add(child, read_format, values);\n\t\tif (ret)\n\t\t\tgoto unlock;\n\t}\n\n\tmutex_unlock(&leader->child_mutex);\n\n\tret = event->read_size;\n\tif (copy_to_user(buf, values, event->read_size))\n\t\tret = -EFAULT;\n\tgoto out;\n\nunlock:\n\tmutex_unlock(&leader->child_mutex);\nout:\n\tkfree(values);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,10 +14,6 @@\n \n \tvalues[0] = 1 + leader->nr_siblings;\n \n-\t/*\n-\t * By locking the child_mutex of the leader we effectively\n-\t * lock the child list of all siblings.. XXX explain how.\n-\t */\n \tmutex_lock(&leader->child_mutex);\n \n \tret = __perf_read_group_add(leader, read_format, values);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t/*",
                "\t * By locking the child_mutex of the leader we effectively",
                "\t * lock the child list of all siblings.. XXX explain how.",
                "\t */"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Linux Kernel Performance Events (perf) component can be exploited to achieve local privilege escalation.\n\nIf perf_read_group() is called while an event's sibling_list is smaller than its child's sibling_list, it can increment or write to memory locations outside of the allocated buffer.\n\nWe recommend upgrading past commit 32671e3799ca2e4590773fd0e63aaa4229e50c06.\n\n"
    },
    {
        "cve_id": "CVE-2023-5717",
        "code_before_change": "static int inherit_group(struct perf_event *parent_event,\n\t      struct task_struct *parent,\n\t      struct perf_event_context *parent_ctx,\n\t      struct task_struct *child,\n\t      struct perf_event_context *child_ctx)\n{\n\tstruct perf_event *leader;\n\tstruct perf_event *sub;\n\tstruct perf_event *child_ctr;\n\n\tleader = inherit_event(parent_event, parent, parent_ctx,\n\t\t\t\t child, NULL, child_ctx);\n\tif (IS_ERR(leader))\n\t\treturn PTR_ERR(leader);\n\t/*\n\t * @leader can be NULL here because of is_orphaned_event(). In this\n\t * case inherit_event() will create individual events, similar to what\n\t * perf_group_detach() would do anyway.\n\t */\n\tfor_each_sibling_event(sub, parent_event) {\n\t\tchild_ctr = inherit_event(sub, parent, parent_ctx,\n\t\t\t\t\t    child, leader, child_ctx);\n\t\tif (IS_ERR(child_ctr))\n\t\t\treturn PTR_ERR(child_ctr);\n\n\t\tif (sub->aux_event == parent_event && child_ctr &&\n\t\t    !perf_get_aux_event(child_ctr, leader))\n\t\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int inherit_group(struct perf_event *parent_event,\n\t      struct task_struct *parent,\n\t      struct perf_event_context *parent_ctx,\n\t      struct task_struct *child,\n\t      struct perf_event_context *child_ctx)\n{\n\tstruct perf_event *leader;\n\tstruct perf_event *sub;\n\tstruct perf_event *child_ctr;\n\n\tleader = inherit_event(parent_event, parent, parent_ctx,\n\t\t\t\t child, NULL, child_ctx);\n\tif (IS_ERR(leader))\n\t\treturn PTR_ERR(leader);\n\t/*\n\t * @leader can be NULL here because of is_orphaned_event(). In this\n\t * case inherit_event() will create individual events, similar to what\n\t * perf_group_detach() would do anyway.\n\t */\n\tfor_each_sibling_event(sub, parent_event) {\n\t\tchild_ctr = inherit_event(sub, parent, parent_ctx,\n\t\t\t\t\t    child, leader, child_ctx);\n\t\tif (IS_ERR(child_ctr))\n\t\t\treturn PTR_ERR(child_ctr);\n\n\t\tif (sub->aux_event == parent_event && child_ctr &&\n\t\t    !perf_get_aux_event(child_ctr, leader))\n\t\t\treturn -EINVAL;\n\t}\n\tleader->group_generation = parent_event->group_generation;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,5 +27,6 @@\n \t\t    !perf_get_aux_event(child_ctr, leader))\n \t\t\treturn -EINVAL;\n \t}\n+\tleader->group_generation = parent_event->group_generation;\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tleader->group_generation = parent_event->group_generation;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Linux Kernel Performance Events (perf) component can be exploited to achieve local privilege escalation.\n\nIf perf_read_group() is called while an event's sibling_list is smaller than its child's sibling_list, it can increment or write to memory locations outside of the allocated buffer.\n\nWe recommend upgrading past commit 32671e3799ca2e4590773fd0e63aaa4229e50c06.\n\n"
    },
    {
        "cve_id": "CVE-2023-5717",
        "code_before_change": "static void perf_group_attach(struct perf_event *event)\n{\n\tstruct perf_event *group_leader = event->group_leader, *pos;\n\n\tlockdep_assert_held(&event->ctx->lock);\n\n\t/*\n\t * We can have double attach due to group movement (move_group) in\n\t * perf_event_open().\n\t */\n\tif (event->attach_state & PERF_ATTACH_GROUP)\n\t\treturn;\n\n\tevent->attach_state |= PERF_ATTACH_GROUP;\n\n\tif (group_leader == event)\n\t\treturn;\n\n\tWARN_ON_ONCE(group_leader->ctx != event->ctx);\n\n\tgroup_leader->group_caps &= event->event_caps;\n\n\tlist_add_tail(&event->sibling_list, &group_leader->sibling_list);\n\tgroup_leader->nr_siblings++;\n\n\tperf_event__header_size(group_leader);\n\n\tfor_each_sibling_event(pos, group_leader)\n\t\tperf_event__header_size(pos);\n}",
        "code_after_change": "static void perf_group_attach(struct perf_event *event)\n{\n\tstruct perf_event *group_leader = event->group_leader, *pos;\n\n\tlockdep_assert_held(&event->ctx->lock);\n\n\t/*\n\t * We can have double attach due to group movement (move_group) in\n\t * perf_event_open().\n\t */\n\tif (event->attach_state & PERF_ATTACH_GROUP)\n\t\treturn;\n\n\tevent->attach_state |= PERF_ATTACH_GROUP;\n\n\tif (group_leader == event)\n\t\treturn;\n\n\tWARN_ON_ONCE(group_leader->ctx != event->ctx);\n\n\tgroup_leader->group_caps &= event->event_caps;\n\n\tlist_add_tail(&event->sibling_list, &group_leader->sibling_list);\n\tgroup_leader->nr_siblings++;\n\tgroup_leader->group_generation++;\n\n\tperf_event__header_size(group_leader);\n\n\tfor_each_sibling_event(pos, group_leader)\n\t\tperf_event__header_size(pos);\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,7 @@\n \n \tlist_add_tail(&event->sibling_list, &group_leader->sibling_list);\n \tgroup_leader->nr_siblings++;\n+\tgroup_leader->group_generation++;\n \n \tperf_event__header_size(group_leader);\n ",
        "function_modified_lines": {
            "added": [
                "\tgroup_leader->group_generation++;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Linux Kernel Performance Events (perf) component can be exploited to achieve local privilege escalation.\n\nIf perf_read_group() is called while an event's sibling_list is smaller than its child's sibling_list, it can increment or write to memory locations outside of the allocated buffer.\n\nWe recommend upgrading past commit 32671e3799ca2e4590773fd0e63aaa4229e50c06.\n\n"
    },
    {
        "cve_id": "CVE-2023-6931",
        "code_before_change": "static bool perf_event_validate_size(struct perf_event *event)\n{\n\t/*\n\t * The values computed here will be over-written when we actually\n\t * attach the event.\n\t */\n\t__perf_event_read_size(event, event->group_leader->nr_siblings + 1);\n\t__perf_event_header_size(event, event->attr.sample_type & ~PERF_SAMPLE_READ);\n\tperf_event__id_header_size(event);\n\n\t/*\n\t * Sum the lot; should not exceed the 64k limit we have on records.\n\t * Conservative limit to allow for callchains and other variable fields.\n\t */\n\tif (event->read_size + event->header_size +\n\t    event->id_header_size + sizeof(struct perf_event_header) >= 16*1024)\n\t\treturn false;\n\n\treturn true;\n}",
        "code_after_change": "static bool perf_event_validate_size(struct perf_event *event)\n{\n\tstruct perf_event *sibling, *group_leader = event->group_leader;\n\n\tif (__perf_event_read_size(event->attr.read_format,\n\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n\t\treturn false;\n\n\tif (__perf_event_read_size(group_leader->attr.read_format,\n\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n\t\treturn false;\n\n\tfor_each_sibling_event(sibling, group_leader) {\n\t\tif (__perf_event_read_size(sibling->attr.read_format,\n\t\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,20 +1,20 @@\n static bool perf_event_validate_size(struct perf_event *event)\n {\n-\t/*\n-\t * The values computed here will be over-written when we actually\n-\t * attach the event.\n-\t */\n-\t__perf_event_read_size(event, event->group_leader->nr_siblings + 1);\n-\t__perf_event_header_size(event, event->attr.sample_type & ~PERF_SAMPLE_READ);\n-\tperf_event__id_header_size(event);\n+\tstruct perf_event *sibling, *group_leader = event->group_leader;\n \n-\t/*\n-\t * Sum the lot; should not exceed the 64k limit we have on records.\n-\t * Conservative limit to allow for callchains and other variable fields.\n-\t */\n-\tif (event->read_size + event->header_size +\n-\t    event->id_header_size + sizeof(struct perf_event_header) >= 16*1024)\n+\tif (__perf_event_read_size(event->attr.read_format,\n+\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n \t\treturn false;\n+\n+\tif (__perf_event_read_size(group_leader->attr.read_format,\n+\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n+\t\treturn false;\n+\n+\tfor_each_sibling_event(sibling, group_leader) {\n+\t\tif (__perf_event_read_size(sibling->attr.read_format,\n+\t\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)\n+\t\t\treturn false;\n+\t}\n \n \treturn true;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct perf_event *sibling, *group_leader = event->group_leader;",
                "\tif (__perf_event_read_size(event->attr.read_format,",
                "\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)",
                "",
                "\tif (__perf_event_read_size(group_leader->attr.read_format,",
                "\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)",
                "\t\treturn false;",
                "",
                "\tfor_each_sibling_event(sibling, group_leader) {",
                "\t\tif (__perf_event_read_size(sibling->attr.read_format,",
                "\t\t\t\t\t   group_leader->nr_siblings + 1) > 16*1024)",
                "\t\t\treturn false;",
                "\t}"
            ],
            "deleted": [
                "\t/*",
                "\t * The values computed here will be over-written when we actually",
                "\t * attach the event.",
                "\t */",
                "\t__perf_event_read_size(event, event->group_leader->nr_siblings + 1);",
                "\t__perf_event_header_size(event, event->attr.sample_type & ~PERF_SAMPLE_READ);",
                "\tperf_event__id_header_size(event);",
                "\t/*",
                "\t * Sum the lot; should not exceed the 64k limit we have on records.",
                "\t * Conservative limit to allow for callchains and other variable fields.",
                "\t */",
                "\tif (event->read_size + event->header_size +",
                "\t    event->id_header_size + sizeof(struct perf_event_header) >= 16*1024)"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Performance Events system component can be exploited to achieve local privilege escalation.\n\nA perf_event's read_size can overflow, leading to an heap out-of-bounds increment or write in perf_read_group().\n\nWe recommend upgrading past commit 382c27f4ed28f803b1f1473ac2d8db0afc795a1b.\n\n"
    },
    {
        "cve_id": "CVE-2023-6931",
        "code_before_change": "static void perf_event__header_size(struct perf_event *event)\n{\n\t__perf_event_read_size(event,\n\t\t\t       event->group_leader->nr_siblings);\n\t__perf_event_header_size(event, event->attr.sample_type);\n}",
        "code_after_change": "static void perf_event__header_size(struct perf_event *event)\n{\n\tevent->read_size =\n\t\t__perf_event_read_size(event->attr.read_format,\n\t\t\t\t       event->group_leader->nr_siblings);\n\t__perf_event_header_size(event, event->attr.sample_type);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,7 @@\n static void perf_event__header_size(struct perf_event *event)\n {\n-\t__perf_event_read_size(event,\n-\t\t\t       event->group_leader->nr_siblings);\n+\tevent->read_size =\n+\t\t__perf_event_read_size(event->attr.read_format,\n+\t\t\t\t       event->group_leader->nr_siblings);\n \t__perf_event_header_size(event, event->attr.sample_type);\n }",
        "function_modified_lines": {
            "added": [
                "\tevent->read_size =",
                "\t\t__perf_event_read_size(event->attr.read_format,",
                "\t\t\t\t       event->group_leader->nr_siblings);"
            ],
            "deleted": [
                "\t__perf_event_read_size(event,",
                "\t\t\t       event->group_leader->nr_siblings);"
            ]
        },
        "cwe": [
            "CWE-787"
        ],
        "cve_description": "A heap out-of-bounds write vulnerability in the Linux kernel's Performance Events system component can be exploited to achieve local privilege escalation.\n\nA perf_event's read_size can overflow, leading to an heap out-of-bounds increment or write in perf_read_group().\n\nWe recommend upgrading past commit 382c27f4ed28f803b1f1473ac2d8db0afc795a1b.\n\n"
    }
]