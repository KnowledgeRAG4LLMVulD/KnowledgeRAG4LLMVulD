[
    {
        "cve_id": "CVE-2014-7825",
        "code_before_change": "static void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "code_after_change": "static void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n \t\treturn;",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the perf subsystem, which allows local users to cause a denial of service (out-of-bounds read and OOPS) or bypass the ASLR protection mechanism via a crafted application.",
        "id": 590
    },
    {
        "cve_id": "CVE-2020-28974",
        "code_before_change": "int con_font_op(struct vc_data *vc, struct console_font_op *op)\n{\n\tswitch (op->op) {\n\tcase KD_FONT_OP_SET:\n\t\treturn con_font_set(vc, op);\n\tcase KD_FONT_OP_GET:\n\t\treturn con_font_get(vc, op);\n\tcase KD_FONT_OP_SET_DEFAULT:\n\t\treturn con_font_default(vc, op);\n\tcase KD_FONT_OP_COPY:\n\t\treturn con_font_copy(vc, op);\n\t}\n\treturn -ENOSYS;\n}",
        "code_after_change": "int con_font_op(struct vc_data *vc, struct console_font_op *op)\n{\n\tswitch (op->op) {\n\tcase KD_FONT_OP_SET:\n\t\treturn con_font_set(vc, op);\n\tcase KD_FONT_OP_GET:\n\t\treturn con_font_get(vc, op);\n\tcase KD_FONT_OP_SET_DEFAULT:\n\t\treturn con_font_default(vc, op);\n\tcase KD_FONT_OP_COPY:\n\t\t/* was buggy and never really used */\n\t\treturn -EINVAL;\n\t}\n\treturn -ENOSYS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,8 @@\n \tcase KD_FONT_OP_SET_DEFAULT:\n \t\treturn con_font_default(vc, op);\n \tcase KD_FONT_OP_COPY:\n-\t\treturn con_font_copy(vc, op);\n+\t\t/* was buggy and never really used */\n+\t\treturn -EINVAL;\n \t}\n \treturn -ENOSYS;\n }",
        "function_modified_lines": {
            "added": [
                "\t\t/* was buggy and never really used */",
                "\t\treturn -EINVAL;"
            ],
            "deleted": [
                "\t\treturn con_font_copy(vc, op);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A slab-out-of-bounds read in fbcon in the Linux kernel before 5.9.7 could be used by local attackers to read privileged information or potentially crash the kernel, aka CID-3c4e0dff2095. This occurs because KD_FONT_OP_COPY in drivers/tty/vt/vt.c can be used for manipulations such as font height.",
        "id": 2661
    },
    {
        "cve_id": "CVE-2017-9074",
        "code_before_change": "int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,\n\t\t int (*output)(struct net *, struct sock *, struct sk_buff *))\n{\n\tstruct sk_buff *frag;\n\tstruct rt6_info *rt = (struct rt6_info *)skb_dst(skb);\n\tstruct ipv6_pinfo *np = skb->sk && !dev_recursion_level() ?\n\t\t\t\tinet6_sk(skb->sk) : NULL;\n\tstruct ipv6hdr *tmp_hdr;\n\tstruct frag_hdr *fh;\n\tunsigned int mtu, hlen, left, len;\n\tint hroom, troom;\n\t__be32 frag_id;\n\tint ptr, offset = 0, err = 0;\n\tu8 *prevhdr, nexthdr = 0;\n\n\thlen = ip6_find_1stfragopt(skb, &prevhdr);\n\tnexthdr = *prevhdr;\n\n\tmtu = ip6_skb_dst_mtu(skb);\n\n\t/* We must not fragment if the socket is set to force MTU discovery\n\t * or if the skb it not generated by a local socket.\n\t */\n\tif (unlikely(!skb->ignore_df && skb->len > mtu))\n\t\tgoto fail_toobig;\n\n\tif (IP6CB(skb)->frag_max_size) {\n\t\tif (IP6CB(skb)->frag_max_size > mtu)\n\t\t\tgoto fail_toobig;\n\n\t\t/* don't send fragments larger than what we received */\n\t\tmtu = IP6CB(skb)->frag_max_size;\n\t\tif (mtu < IPV6_MIN_MTU)\n\t\t\tmtu = IPV6_MIN_MTU;\n\t}\n\n\tif (np && np->frag_size < mtu) {\n\t\tif (np->frag_size)\n\t\t\tmtu = np->frag_size;\n\t}\n\tif (mtu < hlen + sizeof(struct frag_hdr) + 8)\n\t\tgoto fail_toobig;\n\tmtu -= hlen + sizeof(struct frag_hdr);\n\n\tfrag_id = ipv6_select_ident(net, &ipv6_hdr(skb)->daddr,\n\t\t\t\t    &ipv6_hdr(skb)->saddr);\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL &&\n\t    (err = skb_checksum_help(skb)))\n\t\tgoto fail;\n\n\throom = LL_RESERVED_SPACE(rt->dst.dev);\n\tif (skb_has_frag_list(skb)) {\n\t\tunsigned int first_len = skb_pagelen(skb);\n\t\tstruct sk_buff *frag2;\n\n\t\tif (first_len - hlen > mtu ||\n\t\t    ((first_len - hlen) & 7) ||\n\t\t    skb_cloned(skb) ||\n\t\t    skb_headroom(skb) < (hroom + sizeof(struct frag_hdr)))\n\t\t\tgoto slow_path;\n\n\t\tskb_walk_frags(skb, frag) {\n\t\t\t/* Correct geometry. */\n\t\t\tif (frag->len > mtu ||\n\t\t\t    ((frag->len & 7) && frag->next) ||\n\t\t\t    skb_headroom(frag) < (hlen + hroom + sizeof(struct frag_hdr)))\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\t/* Partially cloned skb? */\n\t\t\tif (skb_shared(frag))\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\tBUG_ON(frag->sk);\n\t\t\tif (skb->sk) {\n\t\t\t\tfrag->sk = skb->sk;\n\t\t\t\tfrag->destructor = sock_wfree;\n\t\t\t}\n\t\t\tskb->truesize -= frag->truesize;\n\t\t}\n\n\t\terr = 0;\n\t\toffset = 0;\n\t\t/* BUILD HEADER */\n\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\ttmp_hdr = kmemdup(skb_network_header(skb), hlen, GFP_ATOMIC);\n\t\tif (!tmp_hdr) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tfrag = skb_shinfo(skb)->frag_list;\n\t\tskb_frag_list_init(skb);\n\n\t\t__skb_pull(skb, hlen);\n\t\tfh = (struct frag_hdr *)__skb_push(skb, sizeof(struct frag_hdr));\n\t\t__skb_push(skb, hlen);\n\t\tskb_reset_network_header(skb);\n\t\tmemcpy(skb_network_header(skb), tmp_hdr, hlen);\n\n\t\tfh->nexthdr = nexthdr;\n\t\tfh->reserved = 0;\n\t\tfh->frag_off = htons(IP6_MF);\n\t\tfh->identification = frag_id;\n\n\t\tfirst_len = skb_pagelen(skb);\n\t\tskb->data_len = first_len - skb_headlen(skb);\n\t\tskb->len = first_len;\n\t\tipv6_hdr(skb)->payload_len = htons(first_len -\n\t\t\t\t\t\t   sizeof(struct ipv6hdr));\n\n\t\tdst_hold(&rt->dst);\n\n\t\tfor (;;) {\n\t\t\t/* Prepare header of the next frame,\n\t\t\t * before previous one went down. */\n\t\t\tif (frag) {\n\t\t\t\tfrag->ip_summed = CHECKSUM_NONE;\n\t\t\t\tskb_reset_transport_header(frag);\n\t\t\t\tfh = (struct frag_hdr *)__skb_push(frag, sizeof(struct frag_hdr));\n\t\t\t\t__skb_push(frag, hlen);\n\t\t\t\tskb_reset_network_header(frag);\n\t\t\t\tmemcpy(skb_network_header(frag), tmp_hdr,\n\t\t\t\t       hlen);\n\t\t\t\toffset += skb->len - hlen - sizeof(struct frag_hdr);\n\t\t\t\tfh->nexthdr = nexthdr;\n\t\t\t\tfh->reserved = 0;\n\t\t\t\tfh->frag_off = htons(offset);\n\t\t\t\tif (frag->next)\n\t\t\t\t\tfh->frag_off |= htons(IP6_MF);\n\t\t\t\tfh->identification = frag_id;\n\t\t\t\tipv6_hdr(frag)->payload_len =\n\t\t\t\t\t\thtons(frag->len -\n\t\t\t\t\t\t      sizeof(struct ipv6hdr));\n\t\t\t\tip6_copy_metadata(frag, skb);\n\t\t\t}\n\n\t\t\terr = output(net, sk, skb);\n\t\t\tif (!err)\n\t\t\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t\t\t      IPSTATS_MIB_FRAGCREATES);\n\n\t\t\tif (err || !frag)\n\t\t\t\tbreak;\n\n\t\t\tskb = frag;\n\t\t\tfrag = skb->next;\n\t\t\tskb->next = NULL;\n\t\t}\n\n\t\tkfree(tmp_hdr);\n\n\t\tif (err == 0) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t\t      IPSTATS_MIB_FRAGOKS);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn 0;\n\t\t}\n\n\t\tkfree_skb_list(frag);\n\n\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\tip6_rt_put(rt);\n\t\treturn err;\n\nslow_path_clean:\n\t\tskb_walk_frags(skb, frag2) {\n\t\t\tif (frag2 == frag)\n\t\t\t\tbreak;\n\t\t\tfrag2->sk = NULL;\n\t\t\tfrag2->destructor = NULL;\n\t\t\tskb->truesize += frag2->truesize;\n\t\t}\n\t}\n\nslow_path:\n\tleft = skb->len - hlen;\t\t/* Space per frame */\n\tptr = hlen;\t\t\t/* Where to start from */\n\n\t/*\n\t *\tFragment the datagram.\n\t */\n\n\ttroom = rt->dst.dev->needed_tailroom;\n\n\t/*\n\t *\tKeep copying data until we run out.\n\t */\n\twhile (left > 0)\t{\n\t\tu8 *fragnexthdr_offset;\n\n\t\tlen = left;\n\t\t/* IF: it doesn't fit, use 'mtu' - the data space left */\n\t\tif (len > mtu)\n\t\t\tlen = mtu;\n\t\t/* IF: we are not sending up to and including the packet end\n\t\t   then align the next start on an eight byte boundary */\n\t\tif (len < left)\t{\n\t\t\tlen &= ~7;\n\t\t}\n\n\t\t/* Allocate buffer */\n\t\tfrag = alloc_skb(len + hlen + sizeof(struct frag_hdr) +\n\t\t\t\t hroom + troom, GFP_ATOMIC);\n\t\tif (!frag) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\t/*\n\t\t *\tSet up data on packet\n\t\t */\n\n\t\tip6_copy_metadata(frag, skb);\n\t\tskb_reserve(frag, hroom);\n\t\tskb_put(frag, len + hlen + sizeof(struct frag_hdr));\n\t\tskb_reset_network_header(frag);\n\t\tfh = (struct frag_hdr *)(skb_network_header(frag) + hlen);\n\t\tfrag->transport_header = (frag->network_header + hlen +\n\t\t\t\t\t  sizeof(struct frag_hdr));\n\n\t\t/*\n\t\t *\tCharge the memory for the fragment to any owner\n\t\t *\tit might possess\n\t\t */\n\t\tif (skb->sk)\n\t\t\tskb_set_owner_w(frag, skb->sk);\n\n\t\t/*\n\t\t *\tCopy the packet header into the new buffer.\n\t\t */\n\t\tskb_copy_from_linear_data(skb, skb_network_header(frag), hlen);\n\n\t\tfragnexthdr_offset = skb_network_header(frag);\n\t\tfragnexthdr_offset += prevhdr - skb_network_header(skb);\n\t\t*fragnexthdr_offset = NEXTHDR_FRAGMENT;\n\n\t\t/*\n\t\t *\tBuild fragment header.\n\t\t */\n\t\tfh->nexthdr = nexthdr;\n\t\tfh->reserved = 0;\n\t\tfh->identification = frag_id;\n\n\t\t/*\n\t\t *\tCopy a block of the IP datagram.\n\t\t */\n\t\tBUG_ON(skb_copy_bits(skb, ptr, skb_transport_header(frag),\n\t\t\t\t     len));\n\t\tleft -= len;\n\n\t\tfh->frag_off = htons(offset);\n\t\tif (left > 0)\n\t\t\tfh->frag_off |= htons(IP6_MF);\n\t\tipv6_hdr(frag)->payload_len = htons(frag->len -\n\t\t\t\t\t\t    sizeof(struct ipv6hdr));\n\n\t\tptr += len;\n\t\toffset += len;\n\n\t\t/*\n\t\t *\tPut this fragment into the sending queue.\n\t\t */\n\t\terr = output(net, sk, frag);\n\t\tif (err)\n\t\t\tgoto fail;\n\n\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t      IPSTATS_MIB_FRAGCREATES);\n\t}\n\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t      IPSTATS_MIB_FRAGOKS);\n\tconsume_skb(skb);\n\treturn err;\n\nfail_toobig:\n\tif (skb->sk && dst_allfrag(skb_dst(skb)))\n\t\tsk_nocaps_add(skb->sk, NETIF_F_GSO_MASK);\n\n\tskb->dev = skb_dst(skb)->dev;\n\ticmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu);\n\terr = -EMSGSIZE;\n\nfail:\n\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t      IPSTATS_MIB_FRAGFAILS);\n\tkfree_skb(skb);\n\treturn err;\n}",
        "code_after_change": "int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,\n\t\t int (*output)(struct net *, struct sock *, struct sk_buff *))\n{\n\tstruct sk_buff *frag;\n\tstruct rt6_info *rt = (struct rt6_info *)skb_dst(skb);\n\tstruct ipv6_pinfo *np = skb->sk && !dev_recursion_level() ?\n\t\t\t\tinet6_sk(skb->sk) : NULL;\n\tstruct ipv6hdr *tmp_hdr;\n\tstruct frag_hdr *fh;\n\tunsigned int mtu, hlen, left, len;\n\tint hroom, troom;\n\t__be32 frag_id;\n\tint ptr, offset = 0, err = 0;\n\tu8 *prevhdr, nexthdr = 0;\n\n\thlen = ip6_find_1stfragopt(skb, &prevhdr);\n\tif (hlen < 0) {\n\t\terr = hlen;\n\t\tgoto fail;\n\t}\n\tnexthdr = *prevhdr;\n\n\tmtu = ip6_skb_dst_mtu(skb);\n\n\t/* We must not fragment if the socket is set to force MTU discovery\n\t * or if the skb it not generated by a local socket.\n\t */\n\tif (unlikely(!skb->ignore_df && skb->len > mtu))\n\t\tgoto fail_toobig;\n\n\tif (IP6CB(skb)->frag_max_size) {\n\t\tif (IP6CB(skb)->frag_max_size > mtu)\n\t\t\tgoto fail_toobig;\n\n\t\t/* don't send fragments larger than what we received */\n\t\tmtu = IP6CB(skb)->frag_max_size;\n\t\tif (mtu < IPV6_MIN_MTU)\n\t\t\tmtu = IPV6_MIN_MTU;\n\t}\n\n\tif (np && np->frag_size < mtu) {\n\t\tif (np->frag_size)\n\t\t\tmtu = np->frag_size;\n\t}\n\tif (mtu < hlen + sizeof(struct frag_hdr) + 8)\n\t\tgoto fail_toobig;\n\tmtu -= hlen + sizeof(struct frag_hdr);\n\n\tfrag_id = ipv6_select_ident(net, &ipv6_hdr(skb)->daddr,\n\t\t\t\t    &ipv6_hdr(skb)->saddr);\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL &&\n\t    (err = skb_checksum_help(skb)))\n\t\tgoto fail;\n\n\throom = LL_RESERVED_SPACE(rt->dst.dev);\n\tif (skb_has_frag_list(skb)) {\n\t\tunsigned int first_len = skb_pagelen(skb);\n\t\tstruct sk_buff *frag2;\n\n\t\tif (first_len - hlen > mtu ||\n\t\t    ((first_len - hlen) & 7) ||\n\t\t    skb_cloned(skb) ||\n\t\t    skb_headroom(skb) < (hroom + sizeof(struct frag_hdr)))\n\t\t\tgoto slow_path;\n\n\t\tskb_walk_frags(skb, frag) {\n\t\t\t/* Correct geometry. */\n\t\t\tif (frag->len > mtu ||\n\t\t\t    ((frag->len & 7) && frag->next) ||\n\t\t\t    skb_headroom(frag) < (hlen + hroom + sizeof(struct frag_hdr)))\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\t/* Partially cloned skb? */\n\t\t\tif (skb_shared(frag))\n\t\t\t\tgoto slow_path_clean;\n\n\t\t\tBUG_ON(frag->sk);\n\t\t\tif (skb->sk) {\n\t\t\t\tfrag->sk = skb->sk;\n\t\t\t\tfrag->destructor = sock_wfree;\n\t\t\t}\n\t\t\tskb->truesize -= frag->truesize;\n\t\t}\n\n\t\terr = 0;\n\t\toffset = 0;\n\t\t/* BUILD HEADER */\n\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\ttmp_hdr = kmemdup(skb_network_header(skb), hlen, GFP_ATOMIC);\n\t\tif (!tmp_hdr) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tfrag = skb_shinfo(skb)->frag_list;\n\t\tskb_frag_list_init(skb);\n\n\t\t__skb_pull(skb, hlen);\n\t\tfh = (struct frag_hdr *)__skb_push(skb, sizeof(struct frag_hdr));\n\t\t__skb_push(skb, hlen);\n\t\tskb_reset_network_header(skb);\n\t\tmemcpy(skb_network_header(skb), tmp_hdr, hlen);\n\n\t\tfh->nexthdr = nexthdr;\n\t\tfh->reserved = 0;\n\t\tfh->frag_off = htons(IP6_MF);\n\t\tfh->identification = frag_id;\n\n\t\tfirst_len = skb_pagelen(skb);\n\t\tskb->data_len = first_len - skb_headlen(skb);\n\t\tskb->len = first_len;\n\t\tipv6_hdr(skb)->payload_len = htons(first_len -\n\t\t\t\t\t\t   sizeof(struct ipv6hdr));\n\n\t\tdst_hold(&rt->dst);\n\n\t\tfor (;;) {\n\t\t\t/* Prepare header of the next frame,\n\t\t\t * before previous one went down. */\n\t\t\tif (frag) {\n\t\t\t\tfrag->ip_summed = CHECKSUM_NONE;\n\t\t\t\tskb_reset_transport_header(frag);\n\t\t\t\tfh = (struct frag_hdr *)__skb_push(frag, sizeof(struct frag_hdr));\n\t\t\t\t__skb_push(frag, hlen);\n\t\t\t\tskb_reset_network_header(frag);\n\t\t\t\tmemcpy(skb_network_header(frag), tmp_hdr,\n\t\t\t\t       hlen);\n\t\t\t\toffset += skb->len - hlen - sizeof(struct frag_hdr);\n\t\t\t\tfh->nexthdr = nexthdr;\n\t\t\t\tfh->reserved = 0;\n\t\t\t\tfh->frag_off = htons(offset);\n\t\t\t\tif (frag->next)\n\t\t\t\t\tfh->frag_off |= htons(IP6_MF);\n\t\t\t\tfh->identification = frag_id;\n\t\t\t\tipv6_hdr(frag)->payload_len =\n\t\t\t\t\t\thtons(frag->len -\n\t\t\t\t\t\t      sizeof(struct ipv6hdr));\n\t\t\t\tip6_copy_metadata(frag, skb);\n\t\t\t}\n\n\t\t\terr = output(net, sk, skb);\n\t\t\tif (!err)\n\t\t\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t\t\t      IPSTATS_MIB_FRAGCREATES);\n\n\t\t\tif (err || !frag)\n\t\t\t\tbreak;\n\n\t\t\tskb = frag;\n\t\t\tfrag = skb->next;\n\t\t\tskb->next = NULL;\n\t\t}\n\n\t\tkfree(tmp_hdr);\n\n\t\tif (err == 0) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t\t      IPSTATS_MIB_FRAGOKS);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn 0;\n\t\t}\n\n\t\tkfree_skb_list(frag);\n\n\t\tIP6_INC_STATS(net, ip6_dst_idev(&rt->dst),\n\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\tip6_rt_put(rt);\n\t\treturn err;\n\nslow_path_clean:\n\t\tskb_walk_frags(skb, frag2) {\n\t\t\tif (frag2 == frag)\n\t\t\t\tbreak;\n\t\t\tfrag2->sk = NULL;\n\t\t\tfrag2->destructor = NULL;\n\t\t\tskb->truesize += frag2->truesize;\n\t\t}\n\t}\n\nslow_path:\n\tleft = skb->len - hlen;\t\t/* Space per frame */\n\tptr = hlen;\t\t\t/* Where to start from */\n\n\t/*\n\t *\tFragment the datagram.\n\t */\n\n\ttroom = rt->dst.dev->needed_tailroom;\n\n\t/*\n\t *\tKeep copying data until we run out.\n\t */\n\twhile (left > 0)\t{\n\t\tu8 *fragnexthdr_offset;\n\n\t\tlen = left;\n\t\t/* IF: it doesn't fit, use 'mtu' - the data space left */\n\t\tif (len > mtu)\n\t\t\tlen = mtu;\n\t\t/* IF: we are not sending up to and including the packet end\n\t\t   then align the next start on an eight byte boundary */\n\t\tif (len < left)\t{\n\t\t\tlen &= ~7;\n\t\t}\n\n\t\t/* Allocate buffer */\n\t\tfrag = alloc_skb(len + hlen + sizeof(struct frag_hdr) +\n\t\t\t\t hroom + troom, GFP_ATOMIC);\n\t\tif (!frag) {\n\t\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t\t      IPSTATS_MIB_FRAGFAILS);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\t/*\n\t\t *\tSet up data on packet\n\t\t */\n\n\t\tip6_copy_metadata(frag, skb);\n\t\tskb_reserve(frag, hroom);\n\t\tskb_put(frag, len + hlen + sizeof(struct frag_hdr));\n\t\tskb_reset_network_header(frag);\n\t\tfh = (struct frag_hdr *)(skb_network_header(frag) + hlen);\n\t\tfrag->transport_header = (frag->network_header + hlen +\n\t\t\t\t\t  sizeof(struct frag_hdr));\n\n\t\t/*\n\t\t *\tCharge the memory for the fragment to any owner\n\t\t *\tit might possess\n\t\t */\n\t\tif (skb->sk)\n\t\t\tskb_set_owner_w(frag, skb->sk);\n\n\t\t/*\n\t\t *\tCopy the packet header into the new buffer.\n\t\t */\n\t\tskb_copy_from_linear_data(skb, skb_network_header(frag), hlen);\n\n\t\tfragnexthdr_offset = skb_network_header(frag);\n\t\tfragnexthdr_offset += prevhdr - skb_network_header(skb);\n\t\t*fragnexthdr_offset = NEXTHDR_FRAGMENT;\n\n\t\t/*\n\t\t *\tBuild fragment header.\n\t\t */\n\t\tfh->nexthdr = nexthdr;\n\t\tfh->reserved = 0;\n\t\tfh->identification = frag_id;\n\n\t\t/*\n\t\t *\tCopy a block of the IP datagram.\n\t\t */\n\t\tBUG_ON(skb_copy_bits(skb, ptr, skb_transport_header(frag),\n\t\t\t\t     len));\n\t\tleft -= len;\n\n\t\tfh->frag_off = htons(offset);\n\t\tif (left > 0)\n\t\t\tfh->frag_off |= htons(IP6_MF);\n\t\tipv6_hdr(frag)->payload_len = htons(frag->len -\n\t\t\t\t\t\t    sizeof(struct ipv6hdr));\n\n\t\tptr += len;\n\t\toffset += len;\n\n\t\t/*\n\t\t *\tPut this fragment into the sending queue.\n\t\t */\n\t\terr = output(net, sk, frag);\n\t\tif (err)\n\t\t\tgoto fail;\n\n\t\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t\t      IPSTATS_MIB_FRAGCREATES);\n\t}\n\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t      IPSTATS_MIB_FRAGOKS);\n\tconsume_skb(skb);\n\treturn err;\n\nfail_toobig:\n\tif (skb->sk && dst_allfrag(skb_dst(skb)))\n\t\tsk_nocaps_add(skb->sk, NETIF_F_GSO_MASK);\n\n\tskb->dev = skb_dst(skb)->dev;\n\ticmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu);\n\terr = -EMSGSIZE;\n\nfail:\n\tIP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),\n\t\t      IPSTATS_MIB_FRAGFAILS);\n\tkfree_skb(skb);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,10 @@\n \tu8 *prevhdr, nexthdr = 0;\n \n \thlen = ip6_find_1stfragopt(skb, &prevhdr);\n+\tif (hlen < 0) {\n+\t\terr = hlen;\n+\t\tgoto fail;\n+\t}\n \tnexthdr = *prevhdr;\n \n \tmtu = ip6_skb_dst_mtu(skb);",
        "function_modified_lines": {
            "added": [
                "\tif (hlen < 0) {",
                "\t\terr = hlen;",
                "\t\tgoto fail;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The IPv6 fragmentation implementation in the Linux kernel through 4.11.1 does not consider that the nexthdr field may be associated with an invalid option, which allows local users to cause a denial of service (out-of-bounds read and BUG) or possibly have unspecified other impact via crafted socket and send system calls.",
        "id": 1562
    },
    {
        "cve_id": "CVE-2017-7277",
        "code_before_change": "void __skb_tstamp_tx(struct sk_buff *orig_skb,\n\t\t     struct skb_shared_hwtstamps *hwtstamps,\n\t\t     struct sock *sk, int tstype)\n{\n\tstruct sk_buff *skb;\n\tbool tsonly;\n\n\tif (!sk)\n\t\treturn;\n\n\ttsonly = sk->sk_tsflags & SOF_TIMESTAMPING_OPT_TSONLY;\n\tif (!skb_may_tx_timestamp(sk, tsonly))\n\t\treturn;\n\n\tif (tsonly) {\n#ifdef CONFIG_INET\n\t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n\t\t    sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n\t\telse\n#endif\n\t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t} else {\n\t\tskb = skb_clone(orig_skb, GFP_ATOMIC);\n\t}\n\tif (!skb)\n\t\treturn;\n\n\tif (tsonly) {\n\t\tskb_shinfo(skb)->tx_flags = skb_shinfo(orig_skb)->tx_flags;\n\t\tskb_shinfo(skb)->tskey = skb_shinfo(orig_skb)->tskey;\n\t}\n\n\tif (hwtstamps)\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\telse\n\t\tskb->tstamp = ktime_get_real();\n\n\t__skb_complete_tx_timestamp(skb, sk, tstype);\n}",
        "code_after_change": "void __skb_tstamp_tx(struct sk_buff *orig_skb,\n\t\t     struct skb_shared_hwtstamps *hwtstamps,\n\t\t     struct sock *sk, int tstype)\n{\n\tstruct sk_buff *skb;\n\tbool tsonly, opt_stats = false;\n\n\tif (!sk)\n\t\treturn;\n\n\ttsonly = sk->sk_tsflags & SOF_TIMESTAMPING_OPT_TSONLY;\n\tif (!skb_may_tx_timestamp(sk, tsonly))\n\t\treturn;\n\n\tif (tsonly) {\n#ifdef CONFIG_INET\n\t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n\t\t    sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n\t\t\topt_stats = true;\n\t\t} else\n#endif\n\t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t} else {\n\t\tskb = skb_clone(orig_skb, GFP_ATOMIC);\n\t}\n\tif (!skb)\n\t\treturn;\n\n\tif (tsonly) {\n\t\tskb_shinfo(skb)->tx_flags = skb_shinfo(orig_skb)->tx_flags;\n\t\tskb_shinfo(skb)->tskey = skb_shinfo(orig_skb)->tskey;\n\t}\n\n\tif (hwtstamps)\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\telse\n\t\tskb->tstamp = ktime_get_real();\n\n\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \t\t     struct sock *sk, int tstype)\n {\n \tstruct sk_buff *skb;\n-\tbool tsonly;\n+\tbool tsonly, opt_stats = false;\n \n \tif (!sk)\n \t\treturn;\n@@ -16,9 +16,10 @@\n #ifdef CONFIG_INET\n \t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n \t\t    sk->sk_protocol == IPPROTO_TCP &&\n-\t\t    sk->sk_type == SOCK_STREAM)\n+\t\t    sk->sk_type == SOCK_STREAM) {\n \t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n-\t\telse\n+\t\t\topt_stats = true;\n+\t\t} else\n #endif\n \t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n \t} else {\n@@ -37,5 +38,5 @@\n \telse\n \t\tskb->tstamp = ktime_get_real();\n \n-\t__skb_complete_tx_timestamp(skb, sk, tstype);\n+\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);\n }",
        "function_modified_lines": {
            "added": [
                "\tbool tsonly, opt_stats = false;",
                "\t\t    sk->sk_type == SOCK_STREAM) {",
                "\t\t\topt_stats = true;",
                "\t\t} else",
                "\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);"
            ],
            "deleted": [
                "\tbool tsonly;",
                "\t\t    sk->sk_type == SOCK_STREAM)",
                "\t\telse",
                "\t__skb_complete_tx_timestamp(skb, sk, tstype);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The TCP stack in the Linux kernel through 4.10.6 mishandles the SCM_TIMESTAMPING_OPT_STATS feature, which allows local users to obtain sensitive information from the kernel's internal socket data structures or cause a denial of service (out-of-bounds read) via crafted system calls, related to net/core/skbuff.c and net/socket.c.",
        "id": 1492
    },
    {
        "cve_id": "CVE-2019-15505",
        "code_before_change": "static int technisat_usb2_get_ir(struct dvb_usb_device *d)\n{\n\tstruct technisat_usb2_state *state = d->priv;\n\tu8 *buf = state->buf;\n\tu8 *b;\n\tint ret;\n\tstruct ir_raw_event ev;\n\n\tbuf[0] = GET_IR_DATA_VENDOR_REQUEST;\n\tbuf[1] = 0x08;\n\tbuf[2] = 0x8f;\n\tbuf[3] = MINIMUM_IR_BIT_TRANSITION_TICK_COUNT;\n\tbuf[4] = MAXIMUM_IR_BIT_TIME_TICK_COUNT;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\tret = usb_control_msg(d->udev, usb_sndctrlpipe(d->udev, 0),\n\t\t\tGET_IR_DATA_VENDOR_REQUEST,\n\t\t\tUSB_TYPE_VENDOR | USB_DIR_OUT,\n\t\t\t0, 0,\n\t\t\tbuf, 5, 500);\n\tif (ret < 0)\n\t\tgoto unlock;\n\n\tbuf[1] = 0;\n\tbuf[2] = 0;\n\tret = usb_control_msg(d->udev, usb_rcvctrlpipe(d->udev, 0),\n\t\t\tGET_IR_DATA_VENDOR_REQUEST,\n\t\t\tUSB_TYPE_VENDOR | USB_DIR_IN,\n\t\t\t0x8080, 0,\n\t\t\tbuf, 62, 500);\n\nunlock:\n\tmutex_unlock(&d->i2c_mutex);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (ret == 1)\n\t\treturn 0; /* no key pressed */\n\n\t/* decoding */\n\tb = buf+1;\n\n#if 0\n\tdeb_rc(\"RC: %d \", ret);\n\tdebug_dump(b, ret, deb_rc);\n#endif\n\n\tev.pulse = 0;\n\twhile (1) {\n\t\tev.pulse = !ev.pulse;\n\t\tev.duration = (*b * FIRMWARE_CLOCK_DIVISOR * FIRMWARE_CLOCK_TICK) / 1000;\n\t\tir_raw_event_store(d->rc_dev, &ev);\n\n\t\tb++;\n\t\tif (*b == 0xff) {\n\t\t\tev.pulse = 0;\n\t\t\tev.duration = 888888*2;\n\t\t\tir_raw_event_store(d->rc_dev, &ev);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tir_raw_event_handle(d->rc_dev);\n\n\treturn 1;\n}",
        "code_after_change": "static int technisat_usb2_get_ir(struct dvb_usb_device *d)\n{\n\tstruct technisat_usb2_state *state = d->priv;\n\tstruct ir_raw_event ev;\n\tu8 *buf = state->buf;\n\tint i, ret;\n\n\tbuf[0] = GET_IR_DATA_VENDOR_REQUEST;\n\tbuf[1] = 0x08;\n\tbuf[2] = 0x8f;\n\tbuf[3] = MINIMUM_IR_BIT_TRANSITION_TICK_COUNT;\n\tbuf[4] = MAXIMUM_IR_BIT_TIME_TICK_COUNT;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\tret = usb_control_msg(d->udev, usb_sndctrlpipe(d->udev, 0),\n\t\t\tGET_IR_DATA_VENDOR_REQUEST,\n\t\t\tUSB_TYPE_VENDOR | USB_DIR_OUT,\n\t\t\t0, 0,\n\t\t\tbuf, 5, 500);\n\tif (ret < 0)\n\t\tgoto unlock;\n\n\tbuf[1] = 0;\n\tbuf[2] = 0;\n\tret = usb_control_msg(d->udev, usb_rcvctrlpipe(d->udev, 0),\n\t\t\tGET_IR_DATA_VENDOR_REQUEST,\n\t\t\tUSB_TYPE_VENDOR | USB_DIR_IN,\n\t\t\t0x8080, 0,\n\t\t\tbuf, 62, 500);\n\nunlock:\n\tmutex_unlock(&d->i2c_mutex);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (ret == 1)\n\t\treturn 0; /* no key pressed */\n\n\t/* decoding */\n\n#if 0\n\tdeb_rc(\"RC: %d \", ret);\n\tdebug_dump(buf + 1, ret, deb_rc);\n#endif\n\n\tev.pulse = 0;\n\tfor (i = 1; i < ARRAY_SIZE(state->buf); i++) {\n\t\tif (buf[i] == 0xff) {\n\t\t\tev.pulse = 0;\n\t\t\tev.duration = 888888*2;\n\t\t\tir_raw_event_store(d->rc_dev, &ev);\n\t\t\tbreak;\n\t\t}\n\n\t\tev.pulse = !ev.pulse;\n\t\tev.duration = (buf[i] * FIRMWARE_CLOCK_DIVISOR *\n\t\t\t       FIRMWARE_CLOCK_TICK) / 1000;\n\t\tir_raw_event_store(d->rc_dev, &ev);\n\t}\n\n\tir_raw_event_handle(d->rc_dev);\n\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,9 @@\n static int technisat_usb2_get_ir(struct dvb_usb_device *d)\n {\n \tstruct technisat_usb2_state *state = d->priv;\n+\tstruct ir_raw_event ev;\n \tu8 *buf = state->buf;\n-\tu8 *b;\n-\tint ret;\n-\tstruct ir_raw_event ev;\n+\tint i, ret;\n \n \tbuf[0] = GET_IR_DATA_VENDOR_REQUEST;\n \tbuf[1] = 0x08;\n@@ -40,26 +39,25 @@\n \t\treturn 0; /* no key pressed */\n \n \t/* decoding */\n-\tb = buf+1;\n \n #if 0\n \tdeb_rc(\"RC: %d \", ret);\n-\tdebug_dump(b, ret, deb_rc);\n+\tdebug_dump(buf + 1, ret, deb_rc);\n #endif\n \n \tev.pulse = 0;\n-\twhile (1) {\n-\t\tev.pulse = !ev.pulse;\n-\t\tev.duration = (*b * FIRMWARE_CLOCK_DIVISOR * FIRMWARE_CLOCK_TICK) / 1000;\n-\t\tir_raw_event_store(d->rc_dev, &ev);\n-\n-\t\tb++;\n-\t\tif (*b == 0xff) {\n+\tfor (i = 1; i < ARRAY_SIZE(state->buf); i++) {\n+\t\tif (buf[i] == 0xff) {\n \t\t\tev.pulse = 0;\n \t\t\tev.duration = 888888*2;\n \t\t\tir_raw_event_store(d->rc_dev, &ev);\n \t\t\tbreak;\n \t\t}\n+\n+\t\tev.pulse = !ev.pulse;\n+\t\tev.duration = (buf[i] * FIRMWARE_CLOCK_DIVISOR *\n+\t\t\t       FIRMWARE_CLOCK_TICK) / 1000;\n+\t\tir_raw_event_store(d->rc_dev, &ev);\n \t}\n \n \tir_raw_event_handle(d->rc_dev);",
        "function_modified_lines": {
            "added": [
                "\tstruct ir_raw_event ev;",
                "\tint i, ret;",
                "\tdebug_dump(buf + 1, ret, deb_rc);",
                "\tfor (i = 1; i < ARRAY_SIZE(state->buf); i++) {",
                "\t\tif (buf[i] == 0xff) {",
                "",
                "\t\tev.pulse = !ev.pulse;",
                "\t\tev.duration = (buf[i] * FIRMWARE_CLOCK_DIVISOR *",
                "\t\t\t       FIRMWARE_CLOCK_TICK) / 1000;",
                "\t\tir_raw_event_store(d->rc_dev, &ev);"
            ],
            "deleted": [
                "\tu8 *b;",
                "\tint ret;",
                "\tstruct ir_raw_event ev;",
                "\tb = buf+1;",
                "\tdebug_dump(b, ret, deb_rc);",
                "\twhile (1) {",
                "\t\tev.pulse = !ev.pulse;",
                "\t\tev.duration = (*b * FIRMWARE_CLOCK_DIVISOR * FIRMWARE_CLOCK_TICK) / 1000;",
                "\t\tir_raw_event_store(d->rc_dev, &ev);",
                "",
                "\t\tb++;",
                "\t\tif (*b == 0xff) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/technisat-usb2.c in the Linux kernel through 5.2.9 has an out-of-bounds read via crafted USB device traffic (which may be remote via usbip or usbredir).",
        "id": 2018
    },
    {
        "cve_id": "CVE-2021-43389",
        "code_before_change": "int detach_capi_ctr(struct capi_ctr *ctr)\n{\n\tint err = 0;\n\n\tmutex_lock(&capi_controller_lock);\n\n\tctr_down(ctr, CAPI_CTR_DETACHED);\n\n\tif (capi_controller[ctr->cnr - 1] != ctr) {\n\t\terr = -EINVAL;\n\t\tgoto unlock_out;\n\t}\n\tcapi_controller[ctr->cnr - 1] = NULL;\n\tncontrollers--;\n\n\tif (ctr->procent)\n\t\tremove_proc_entry(ctr->procfn, NULL);\n\n\tprintk(KERN_NOTICE \"kcapi: controller [%03d]: %s unregistered\\n\",\n\t       ctr->cnr, ctr->name);\n\nunlock_out:\n\tmutex_unlock(&capi_controller_lock);\n\n\treturn err;\n}",
        "code_after_change": "int detach_capi_ctr(struct capi_ctr *ctr)\n{\n\tint err = 0;\n\n\tmutex_lock(&capi_controller_lock);\n\n\tctr_down(ctr, CAPI_CTR_DETACHED);\n\n\tif (ctr->cnr < 1 || ctr->cnr - 1 >= CAPI_MAXCONTR) {\n\t\terr = -EINVAL;\n\t\tgoto unlock_out;\n\t}\n\n\tif (capi_controller[ctr->cnr - 1] != ctr) {\n\t\terr = -EINVAL;\n\t\tgoto unlock_out;\n\t}\n\tcapi_controller[ctr->cnr - 1] = NULL;\n\tncontrollers--;\n\n\tif (ctr->procent)\n\t\tremove_proc_entry(ctr->procfn, NULL);\n\n\tprintk(KERN_NOTICE \"kcapi: controller [%03d]: %s unregistered\\n\",\n\t       ctr->cnr, ctr->name);\n\nunlock_out:\n\tmutex_unlock(&capi_controller_lock);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,11 @@\n \tmutex_lock(&capi_controller_lock);\n \n \tctr_down(ctr, CAPI_CTR_DETACHED);\n+\n+\tif (ctr->cnr < 1 || ctr->cnr - 1 >= CAPI_MAXCONTR) {\n+\t\terr = -EINVAL;\n+\t\tgoto unlock_out;\n+\t}\n \n \tif (capi_controller[ctr->cnr - 1] != ctr) {\n \t\terr = -EINVAL;",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (ctr->cnr < 1 || ctr->cnr - 1 >= CAPI_MAXCONTR) {",
                "\t\terr = -EINVAL;",
                "\t\tgoto unlock_out;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.14.15. There is an array-index-out-of-bounds flaw in the detach_capi_ctr function in drivers/isdn/capi/kcapi.c.",
        "id": 3164
    },
    {
        "cve_id": "CVE-2014-3180",
        "code_before_change": "static long compat_nanosleep_restart(struct restart_block *restart)\n{\n\tstruct compat_timespec __user *rmtp;\n\tstruct timespec rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\trestart->nanosleep.rmtp = (struct timespec __user *) &rmt;\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep_restart(restart);\n\tset_fs(oldfs);\n\n\tif (ret) {\n\t\trmtp = restart->nanosleep.compat_rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static long compat_nanosleep_restart(struct restart_block *restart)\n{\n\tstruct compat_timespec __user *rmtp;\n\tstruct timespec rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\trestart->nanosleep.rmtp = (struct timespec __user *) &rmt;\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep_restart(restart);\n\tset_fs(oldfs);\n\n\tif (ret == -ERESTART_RESTARTBLOCK) {\n\t\trmtp = restart->nanosleep.compat_rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \tret = hrtimer_nanosleep_restart(restart);\n \tset_fs(oldfs);\n \n-\tif (ret) {\n+\tif (ret == -ERESTART_RESTARTBLOCK) {\n \t\trmtp = restart->nanosleep.compat_rmtp;\n \n \t\tif (rmtp && compat_put_timespec(&rmt, rmtp))",
        "function_modified_lines": {
            "added": [
                "\tif (ret == -ERESTART_RESTARTBLOCK) {"
            ],
            "deleted": [
                "\tif (ret) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In kernel/compat.c in the Linux kernel before 3.17, as used in Google Chrome OS and other products, there is a possible out-of-bounds read. restart_syscall uses uninitialized data when restarting compat_sys_nanosleep. NOTE: this is disputed because the code path is unreachable",
        "id": 509
    },
    {
        "cve_id": "CVE-2023-1380",
        "code_before_change": "static s32 brcmf_get_assoc_ies(struct brcmf_cfg80211_info *cfg,\n\t\t\t       struct brcmf_if *ifp)\n{\n\tstruct brcmf_pub *drvr = cfg->pub;\n\tstruct brcmf_cfg80211_assoc_ielen_le *assoc_info;\n\tstruct brcmf_cfg80211_connect_info *conn_info = cfg_to_conn(cfg);\n\tstruct brcmf_cfg80211_edcf_acparam edcf_acparam_info[EDCF_AC_COUNT];\n\tu32 req_len;\n\tu32 resp_len;\n\ts32 err = 0;\n\n\tbrcmf_clear_assoc_ies(cfg);\n\n\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_info\",\n\t\t\t\t       cfg->extra_buf, WL_ASSOC_INFO_MAX);\n\tif (err) {\n\t\tbphy_err(drvr, \"could not get assoc info (%d)\\n\", err);\n\t\treturn err;\n\t}\n\tassoc_info =\n\t\t(struct brcmf_cfg80211_assoc_ielen_le *)cfg->extra_buf;\n\treq_len = le32_to_cpu(assoc_info->req_len);\n\tresp_len = le32_to_cpu(assoc_info->resp_len);\n\tif (req_len) {\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_req_ies\",\n\t\t\t\t\t       cfg->extra_buf,\n\t\t\t\t\t       WL_ASSOC_INFO_MAX);\n\t\tif (err) {\n\t\t\tbphy_err(drvr, \"could not get assoc req (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t\tconn_info->req_ie_len = req_len;\n\t\tconn_info->req_ie =\n\t\t    kmemdup(cfg->extra_buf, conn_info->req_ie_len,\n\t\t\t    GFP_KERNEL);\n\t\tif (!conn_info->req_ie)\n\t\t\tconn_info->req_ie_len = 0;\n\t} else {\n\t\tconn_info->req_ie_len = 0;\n\t\tconn_info->req_ie = NULL;\n\t}\n\tif (resp_len) {\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_resp_ies\",\n\t\t\t\t\t       cfg->extra_buf,\n\t\t\t\t\t       WL_ASSOC_INFO_MAX);\n\t\tif (err) {\n\t\t\tbphy_err(drvr, \"could not get assoc resp (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t\tconn_info->resp_ie_len = resp_len;\n\t\tconn_info->resp_ie =\n\t\t    kmemdup(cfg->extra_buf, conn_info->resp_ie_len,\n\t\t\t    GFP_KERNEL);\n\t\tif (!conn_info->resp_ie)\n\t\t\tconn_info->resp_ie_len = 0;\n\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"wme_ac_sta\",\n\t\t\t\t\t       edcf_acparam_info,\n\t\t\t\t\t       sizeof(edcf_acparam_info));\n\t\tif (err) {\n\t\t\tbrcmf_err(\"could not get wme_ac_sta (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\n\t\tbrcmf_wifi_prioritize_acparams(edcf_acparam_info,\n\t\t\t\t\t       cfg->ac_priority);\n\t} else {\n\t\tconn_info->resp_ie_len = 0;\n\t\tconn_info->resp_ie = NULL;\n\t}\n\tbrcmf_dbg(CONN, \"req len (%d) resp len (%d)\\n\",\n\t\t  conn_info->req_ie_len, conn_info->resp_ie_len);\n\n\treturn err;\n}",
        "code_after_change": "static s32 brcmf_get_assoc_ies(struct brcmf_cfg80211_info *cfg,\n\t\t\t       struct brcmf_if *ifp)\n{\n\tstruct brcmf_pub *drvr = cfg->pub;\n\tstruct brcmf_cfg80211_assoc_ielen_le *assoc_info;\n\tstruct brcmf_cfg80211_connect_info *conn_info = cfg_to_conn(cfg);\n\tstruct brcmf_cfg80211_edcf_acparam edcf_acparam_info[EDCF_AC_COUNT];\n\tu32 req_len;\n\tu32 resp_len;\n\ts32 err = 0;\n\n\tbrcmf_clear_assoc_ies(cfg);\n\n\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_info\",\n\t\t\t\t       cfg->extra_buf, WL_ASSOC_INFO_MAX);\n\tif (err) {\n\t\tbphy_err(drvr, \"could not get assoc info (%d)\\n\", err);\n\t\treturn err;\n\t}\n\tassoc_info =\n\t\t(struct brcmf_cfg80211_assoc_ielen_le *)cfg->extra_buf;\n\treq_len = le32_to_cpu(assoc_info->req_len);\n\tresp_len = le32_to_cpu(assoc_info->resp_len);\n\tif (req_len > WL_EXTRA_BUF_MAX || resp_len > WL_EXTRA_BUF_MAX) {\n\t\tbphy_err(drvr, \"invalid lengths in assoc info: req %u resp %u\\n\",\n\t\t\t req_len, resp_len);\n\t\treturn -EINVAL;\n\t}\n\tif (req_len) {\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_req_ies\",\n\t\t\t\t\t       cfg->extra_buf,\n\t\t\t\t\t       WL_ASSOC_INFO_MAX);\n\t\tif (err) {\n\t\t\tbphy_err(drvr, \"could not get assoc req (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t\tconn_info->req_ie_len = req_len;\n\t\tconn_info->req_ie =\n\t\t    kmemdup(cfg->extra_buf, conn_info->req_ie_len,\n\t\t\t    GFP_KERNEL);\n\t\tif (!conn_info->req_ie)\n\t\t\tconn_info->req_ie_len = 0;\n\t} else {\n\t\tconn_info->req_ie_len = 0;\n\t\tconn_info->req_ie = NULL;\n\t}\n\tif (resp_len) {\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_resp_ies\",\n\t\t\t\t\t       cfg->extra_buf,\n\t\t\t\t\t       WL_ASSOC_INFO_MAX);\n\t\tif (err) {\n\t\t\tbphy_err(drvr, \"could not get assoc resp (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\t\tconn_info->resp_ie_len = resp_len;\n\t\tconn_info->resp_ie =\n\t\t    kmemdup(cfg->extra_buf, conn_info->resp_ie_len,\n\t\t\t    GFP_KERNEL);\n\t\tif (!conn_info->resp_ie)\n\t\t\tconn_info->resp_ie_len = 0;\n\n\t\terr = brcmf_fil_iovar_data_get(ifp, \"wme_ac_sta\",\n\t\t\t\t\t       edcf_acparam_info,\n\t\t\t\t\t       sizeof(edcf_acparam_info));\n\t\tif (err) {\n\t\t\tbrcmf_err(\"could not get wme_ac_sta (%d)\\n\", err);\n\t\t\treturn err;\n\t\t}\n\n\t\tbrcmf_wifi_prioritize_acparams(edcf_acparam_info,\n\t\t\t\t\t       cfg->ac_priority);\n\t} else {\n\t\tconn_info->resp_ie_len = 0;\n\t\tconn_info->resp_ie = NULL;\n\t}\n\tbrcmf_dbg(CONN, \"req len (%d) resp len (%d)\\n\",\n\t\t  conn_info->req_ie_len, conn_info->resp_ie_len);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,11 @@\n \t\t(struct brcmf_cfg80211_assoc_ielen_le *)cfg->extra_buf;\n \treq_len = le32_to_cpu(assoc_info->req_len);\n \tresp_len = le32_to_cpu(assoc_info->resp_len);\n+\tif (req_len > WL_EXTRA_BUF_MAX || resp_len > WL_EXTRA_BUF_MAX) {\n+\t\tbphy_err(drvr, \"invalid lengths in assoc info: req %u resp %u\\n\",\n+\t\t\t req_len, resp_len);\n+\t\treturn -EINVAL;\n+\t}\n \tif (req_len) {\n \t\terr = brcmf_fil_iovar_data_get(ifp, \"assoc_req_ies\",\n \t\t\t\t\t       cfg->extra_buf,",
        "function_modified_lines": {
            "added": [
                "\tif (req_len > WL_EXTRA_BUF_MAX || resp_len > WL_EXTRA_BUF_MAX) {",
                "\t\tbphy_err(drvr, \"invalid lengths in assoc info: req %u resp %u\\n\",",
                "\t\t\t req_len, resp_len);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A slab-out-of-bound read problem was found in brcmf_get_assoc_ies in drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c in the Linux Kernel. This issue could occur when assoc_info->req_len data is bigger than the size of the buffer, defined as WL_EXTRA_BUF_MAX, leading to a denial of service.",
        "id": 3864
    },
    {
        "cve_id": "CVE-2023-39193",
        "code_before_change": "static int sctp_mt_check(const struct xt_mtchk_param *par)\n{\n\tconst struct xt_sctp_info *info = par->matchinfo;\n\n\tif (info->flags & ~XT_SCTP_VALID_FLAGS)\n\t\treturn -EINVAL;\n\tif (info->invflags & ~XT_SCTP_VALID_FLAGS)\n\t\treturn -EINVAL;\n\tif (info->invflags & ~info->flags)\n\t\treturn -EINVAL;\n\tif (!(info->flags & XT_SCTP_CHUNK_TYPES))\n\t\treturn 0;\n\tif (info->chunk_match_type & (SCTP_CHUNK_MATCH_ALL |\n\t    SCTP_CHUNK_MATCH_ANY | SCTP_CHUNK_MATCH_ONLY))\n\t\treturn 0;\n\treturn -EINVAL;\n}",
        "code_after_change": "static int sctp_mt_check(const struct xt_mtchk_param *par)\n{\n\tconst struct xt_sctp_info *info = par->matchinfo;\n\n\tif (info->flag_count > ARRAY_SIZE(info->flag_info))\n\t\treturn -EINVAL;\n\tif (info->flags & ~XT_SCTP_VALID_FLAGS)\n\t\treturn -EINVAL;\n\tif (info->invflags & ~XT_SCTP_VALID_FLAGS)\n\t\treturn -EINVAL;\n\tif (info->invflags & ~info->flags)\n\t\treturn -EINVAL;\n\tif (!(info->flags & XT_SCTP_CHUNK_TYPES))\n\t\treturn 0;\n\tif (info->chunk_match_type & (SCTP_CHUNK_MATCH_ALL |\n\t    SCTP_CHUNK_MATCH_ANY | SCTP_CHUNK_MATCH_ONLY))\n\t\treturn 0;\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,8 @@\n {\n \tconst struct xt_sctp_info *info = par->matchinfo;\n \n+\tif (info->flag_count > ARRAY_SIZE(info->flag_info))\n+\t\treturn -EINVAL;\n \tif (info->flags & ~XT_SCTP_VALID_FLAGS)\n \t\treturn -EINVAL;\n \tif (info->invflags & ~XT_SCTP_VALID_FLAGS)",
        "function_modified_lines": {
            "added": [
                "\tif (info->flag_count > ARRAY_SIZE(info->flag_info))",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A flaw was found in the Netfilter subsystem in the Linux kernel. The sctp_mt_check did not validate the flag_count field. This flaw allows a local privileged (CAP_NET_ADMIN) attacker to trigger an out-of-bounds read, leading to a crash or information disclosure.",
        "id": 4181
    },
    {
        "cve_id": "CVE-2017-16530",
        "code_before_change": "static int uas_find_uas_alt_setting(struct usb_interface *intf)\n{\n\tint i;\n\n\tfor (i = 0; i < intf->num_altsetting; i++) {\n\t\tstruct usb_host_interface *alt = &intf->altsetting[i];\n\n\t\tif (uas_is_interface(alt))\n\t\t\treturn alt->desc.bAlternateSetting;\n\t}\n\n\treturn -ENODEV;\n}",
        "code_after_change": "static struct usb_host_interface *uas_find_uas_alt_setting(\n\t\tstruct usb_interface *intf)\n{\n\tint i;\n\n\tfor (i = 0; i < intf->num_altsetting; i++) {\n\t\tstruct usb_host_interface *alt = &intf->altsetting[i];\n\n\t\tif (uas_is_interface(alt))\n\t\t\treturn alt;\n\t}\n\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,5 @@\n-static int uas_find_uas_alt_setting(struct usb_interface *intf)\n+static struct usb_host_interface *uas_find_uas_alt_setting(\n+\t\tstruct usb_interface *intf)\n {\n \tint i;\n \n@@ -6,8 +7,8 @@\n \t\tstruct usb_host_interface *alt = &intf->altsetting[i];\n \n \t\tif (uas_is_interface(alt))\n-\t\t\treturn alt->desc.bAlternateSetting;\n+\t\t\treturn alt;\n \t}\n \n-\treturn -ENODEV;\n+\treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "static struct usb_host_interface *uas_find_uas_alt_setting(",
                "\t\tstruct usb_interface *intf)",
                "\t\t\treturn alt;",
                "\treturn NULL;"
            ],
            "deleted": [
                "static int uas_find_uas_alt_setting(struct usb_interface *intf)",
                "\t\t\treturn alt->desc.bAlternateSetting;",
                "\treturn -ENODEV;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The uas driver in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device, related to drivers/usb/storage/uas-detect.h and drivers/usb/storage/uas.c.",
        "id": 1316
    },
    {
        "cve_id": "CVE-2023-6121",
        "code_before_change": "static void nvmet_execute_admin_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl = NULL;\n\tu16 status = 0;\n\tint ret;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\treq->error_loc = offsetof(struct nvmf_connect_command, recfmt);\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(d->cntlid != cpu_to_le16(0xffff))) {\n\t\tpr_warn(\"connect attempt for invalid controller ID %#x\\n\",\n\t\t\td->cntlid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n\t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n\tif (status)\n\t\tgoto out;\n\n\tctrl->pi_support = ctrl->port->pi_enable && ctrl->subsys->pi_support;\n\n\tuuid_copy(&ctrl->hostid, &d->hostid);\n\n\tret = nvmet_setup_auth(ctrl);\n\tif (ret < 0) {\n\t\tpr_err(\"Failed to setup authentication, error %d\\n\", ret);\n\t\tnvmet_ctrl_put(ctrl);\n\t\tif (ret == -EPERM)\n\t\t\tstatus = (NVME_SC_CONNECT_INVALID_HOST | NVME_SC_DNR);\n\t\telse\n\t\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status) {\n\t\tnvmet_ctrl_put(ctrl);\n\t\tgoto out;\n\t}\n\n\tpr_info(\"creating %s controller %d for subsystem %s for NQN %s%s%s.\\n\",\n\t\tnvmet_is_disc_subsys(ctrl->subsys) ? \"discovery\" : \"nvm\",\n\t\tctrl->cntlid, ctrl->subsys->subsysnqn, ctrl->hostnqn,\n\t\tctrl->pi_support ? \" T10-PI is enabled\" : \"\",\n\t\tnvmet_has_auth(ctrl) ? \" with DH-HMAC-CHAP\" : \"\");\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n}",
        "code_after_change": "static void nvmet_execute_admin_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl = NULL;\n\tu16 status = 0;\n\tint ret;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\treq->error_loc = offsetof(struct nvmf_connect_command, recfmt);\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(d->cntlid != cpu_to_le16(0xffff))) {\n\t\tpr_warn(\"connect attempt for invalid controller ID %#x\\n\",\n\t\t\td->cntlid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);\n\t\tgoto out;\n\t}\n\n\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n\t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n\tif (status)\n\t\tgoto out;\n\n\tctrl->pi_support = ctrl->port->pi_enable && ctrl->subsys->pi_support;\n\n\tuuid_copy(&ctrl->hostid, &d->hostid);\n\n\tret = nvmet_setup_auth(ctrl);\n\tif (ret < 0) {\n\t\tpr_err(\"Failed to setup authentication, error %d\\n\", ret);\n\t\tnvmet_ctrl_put(ctrl);\n\t\tif (ret == -EPERM)\n\t\t\tstatus = (NVME_SC_CONNECT_INVALID_HOST | NVME_SC_DNR);\n\t\telse\n\t\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status) {\n\t\tnvmet_ctrl_put(ctrl);\n\t\tgoto out;\n\t}\n\n\tpr_info(\"creating %s controller %d for subsystem %s for NQN %s%s%s.\\n\",\n\t\tnvmet_is_disc_subsys(ctrl->subsys) ? \"discovery\" : \"nvm\",\n\t\tctrl->cntlid, ctrl->subsys->subsysnqn, ctrl->hostnqn,\n\t\tctrl->pi_support ? \" T10-PI is enabled\" : \"\",\n\t\tnvmet_has_auth(ctrl) ? \" with DH-HMAC-CHAP\" : \"\");\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,6 +38,8 @@\n \t\tgoto out;\n \t}\n \n+\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n+\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n \tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n \t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n \tif (status)",
        "function_modified_lines": {
            "added": [
                "\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';",
                "\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in the NVMe-oF/TCP subsystem in the Linux kernel. This issue may allow a remote attacker to send a crafted TCP packet, triggering a heap-based buffer overflow that results in kmalloc data being printed and potentially leaked to the kernel ring buffer (dmesg).",
        "id": 4298
    },
    {
        "cve_id": "CVE-2016-7915",
        "code_before_change": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}",
        "code_after_change": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    value[n] - min < field->maxusage &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->value[n] - min < field->maxusage\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& value[n] - min < field->maxusage\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,6 +23,7 @@\n \t\t/* Ignore report if ErrorRollOver */\n \t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n \t\t    value[n] >= min && value[n] <= max &&\n+\t\t    value[n] - min < field->maxusage &&\n \t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n \t\t\tgoto exit;\n \t}\n@@ -35,11 +36,13 @@\n \t\t}\n \n \t\tif (field->value[n] >= min && field->value[n] <= max\n+\t\t\t&& field->value[n] - min < field->maxusage\n \t\t\t&& field->usage[field->value[n] - min].hid\n \t\t\t&& search(value, field->value[n], count))\n \t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n \n \t\tif (value[n] >= min && value[n] <= max\n+\t\t\t&& value[n] - min < field->maxusage\n \t\t\t&& field->usage[value[n] - min].hid\n \t\t\t&& search(field->value, value[n], count))\n \t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);",
        "function_modified_lines": {
            "added": [
                "\t\t    value[n] - min < field->maxusage &&",
                "\t\t\t&& field->value[n] - min < field->maxusage",
                "\t\t\t&& value[n] - min < field->maxusage"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The hid_input_field function in drivers/hid/hid-core.c in the Linux kernel before 4.6 allows physically proximate attackers to obtain sensitive information from kernel memory or cause a denial of service (out-of-bounds read) by connecting a device, as demonstrated by a Logitech DJ receiver.",
        "id": 1113
    },
    {
        "cve_id": "CVE-2020-0067",
        "code_before_change": "ssize_t f2fs_listxattr(struct dentry *dentry, char *buffer, size_t buffer_size)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tstruct f2fs_xattr_entry *entry;\n\tvoid *base_addr;\n\tint error = 0;\n\tsize_t rest = buffer_size;\n\n\tdown_read(&F2FS_I(inode)->i_xattr_sem);\n\terror = read_all_xattrs(inode, NULL, &base_addr);\n\tup_read(&F2FS_I(inode)->i_xattr_sem);\n\tif (error)\n\t\treturn error;\n\n\tlist_for_each_xattr(entry, base_addr) {\n\t\tconst struct xattr_handler *handler =\n\t\t\tf2fs_xattr_handler(entry->e_name_index);\n\t\tconst char *prefix;\n\t\tsize_t prefix_len;\n\t\tsize_t size;\n\n\t\tif (!handler || (handler->list && !handler->list(dentry)))\n\t\t\tcontinue;\n\n\t\tprefix = xattr_prefix(handler);\n\t\tprefix_len = strlen(prefix);\n\t\tsize = prefix_len + entry->e_name_len + 1;\n\t\tif (buffer) {\n\t\t\tif (size > rest) {\n\t\t\t\terror = -ERANGE;\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tmemcpy(buffer, prefix, prefix_len);\n\t\t\tbuffer += prefix_len;\n\t\t\tmemcpy(buffer, entry->e_name, entry->e_name_len);\n\t\t\tbuffer += entry->e_name_len;\n\t\t\t*buffer++ = 0;\n\t\t}\n\t\trest -= size;\n\t}\n\terror = buffer_size - rest;\ncleanup:\n\tkvfree(base_addr);\n\treturn error;\n}",
        "code_after_change": "ssize_t f2fs_listxattr(struct dentry *dentry, char *buffer, size_t buffer_size)\n{\n\tstruct inode *inode = d_inode(dentry);\n\tnid_t xnid = F2FS_I(inode)->i_xattr_nid;\n\tstruct f2fs_xattr_entry *entry;\n\tvoid *base_addr, *last_base_addr;\n\tint error = 0;\n\tsize_t rest = buffer_size;\n\n\tdown_read(&F2FS_I(inode)->i_xattr_sem);\n\terror = read_all_xattrs(inode, NULL, &base_addr);\n\tup_read(&F2FS_I(inode)->i_xattr_sem);\n\tif (error)\n\t\treturn error;\n\n\tlast_base_addr = (void *)base_addr + XATTR_SIZE(xnid, inode);\n\n\tlist_for_each_xattr(entry, base_addr) {\n\t\tconst struct xattr_handler *handler =\n\t\t\tf2fs_xattr_handler(entry->e_name_index);\n\t\tconst char *prefix;\n\t\tsize_t prefix_len;\n\t\tsize_t size;\n\n\t\tif ((void *)(entry) + sizeof(__u32) > last_base_addr ||\n\t\t\t(void *)XATTR_NEXT_ENTRY(entry) > last_base_addr) {\n\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has corrupted xattr\",\n\t\t\t\t\t\tinode->i_ino);\n\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tif (!handler || (handler->list && !handler->list(dentry)))\n\t\t\tcontinue;\n\n\t\tprefix = xattr_prefix(handler);\n\t\tprefix_len = strlen(prefix);\n\t\tsize = prefix_len + entry->e_name_len + 1;\n\t\tif (buffer) {\n\t\t\tif (size > rest) {\n\t\t\t\terror = -ERANGE;\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tmemcpy(buffer, prefix, prefix_len);\n\t\t\tbuffer += prefix_len;\n\t\t\tmemcpy(buffer, entry->e_name, entry->e_name_len);\n\t\t\tbuffer += entry->e_name_len;\n\t\t\t*buffer++ = 0;\n\t\t}\n\t\trest -= size;\n\t}\n\terror = buffer_size - rest;\ncleanup:\n\tkvfree(base_addr);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,9 @@\n ssize_t f2fs_listxattr(struct dentry *dentry, char *buffer, size_t buffer_size)\n {\n \tstruct inode *inode = d_inode(dentry);\n+\tnid_t xnid = F2FS_I(inode)->i_xattr_nid;\n \tstruct f2fs_xattr_entry *entry;\n-\tvoid *base_addr;\n+\tvoid *base_addr, *last_base_addr;\n \tint error = 0;\n \tsize_t rest = buffer_size;\n \n@@ -12,12 +13,23 @@\n \tif (error)\n \t\treturn error;\n \n+\tlast_base_addr = (void *)base_addr + XATTR_SIZE(xnid, inode);\n+\n \tlist_for_each_xattr(entry, base_addr) {\n \t\tconst struct xattr_handler *handler =\n \t\t\tf2fs_xattr_handler(entry->e_name_index);\n \t\tconst char *prefix;\n \t\tsize_t prefix_len;\n \t\tsize_t size;\n+\n+\t\tif ((void *)(entry) + sizeof(__u32) > last_base_addr ||\n+\t\t\t(void *)XATTR_NEXT_ENTRY(entry) > last_base_addr) {\n+\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has corrupted xattr\",\n+\t\t\t\t\t\tinode->i_ino);\n+\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n+\t\t\terror = -EFSCORRUPTED;\n+\t\t\tgoto cleanup;\n+\t\t}\n \n \t\tif (!handler || (handler->list && !handler->list(dentry)))\n \t\t\tcontinue;",
        "function_modified_lines": {
            "added": [
                "\tnid_t xnid = F2FS_I(inode)->i_xattr_nid;",
                "\tvoid *base_addr, *last_base_addr;",
                "\tlast_base_addr = (void *)base_addr + XATTR_SIZE(xnid, inode);",
                "",
                "",
                "\t\tif ((void *)(entry) + sizeof(__u32) > last_base_addr ||",
                "\t\t\t(void *)XATTR_NEXT_ENTRY(entry) > last_base_addr) {",
                "\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has corrupted xattr\",",
                "\t\t\t\t\t\tinode->i_ino);",
                "\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);",
                "\t\t\terror = -EFSCORRUPTED;",
                "\t\t\tgoto cleanup;",
                "\t\t}"
            ],
            "deleted": [
                "\tvoid *base_addr;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In f2fs_xattr_generic_list of xattr.c, there is a possible out of bounds read due to a missing bounds check. This could lead to local information disclosure with System execution privileges needed. User interaction is not required for exploitation.Product: Android. Versions: Android kernel. Android ID: A-120551147.",
        "id": 2375
    },
    {
        "cve_id": "CVE-2022-20132",
        "code_before_change": "static int logi_dj_probe(struct hid_device *hdev,\n\t\t\t const struct hid_device_id *id)\n{\n\tstruct hid_report_enum *rep_enum;\n\tstruct hid_report *rep;\n\tstruct dj_receiver_dev *djrcv_dev;\n\tstruct usb_interface *intf;\n\tunsigned int no_dj_interfaces = 0;\n\tbool has_hidpp = false;\n\tunsigned long flags;\n\tint retval;\n\n\t/*\n\t * Call to usbhid to fetch the HID descriptors of the current\n\t * interface subsequently call to the hid/hid-core to parse the\n\t * fetched descriptors.\n\t */\n\tretval = hid_parse(hdev);\n\tif (retval) {\n\t\thid_err(hdev, \"%s: parse failed\\n\", __func__);\n\t\treturn retval;\n\t}\n\n\t/*\n\t * Some KVMs add an extra interface for e.g. mouse emulation. If we\n\t * treat these as logitech-dj interfaces then this causes input events\n\t * reported through this extra interface to not be reported correctly.\n\t * To avoid this, we treat these as generic-hid devices.\n\t */\n\tswitch (id->driver_data) {\n\tcase recvr_type_dj:\t\tno_dj_interfaces = 3; break;\n\tcase recvr_type_hidpp:\t\tno_dj_interfaces = 2; break;\n\tcase recvr_type_gaming_hidpp:\tno_dj_interfaces = 3; break;\n\tcase recvr_type_mouse_only:\tno_dj_interfaces = 2; break;\n\tcase recvr_type_27mhz:\t\tno_dj_interfaces = 2; break;\n\tcase recvr_type_bluetooth:\tno_dj_interfaces = 2; break;\n\tcase recvr_type_dinovo:\t\tno_dj_interfaces = 2; break;\n\t}\n\tif (hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\tintf = to_usb_interface(hdev->dev.parent);\n\t\tif (intf && intf->altsetting->desc.bInterfaceNumber >=\n\t\t\t\t\t\t\tno_dj_interfaces) {\n\t\t\thdev->quirks |= HID_QUIRK_INPUT_PER_APP;\n\t\t\treturn hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\t\t}\n\t}\n\n\trep_enum = &hdev->report_enum[HID_INPUT_REPORT];\n\n\t/* no input reports, bail out */\n\tif (list_empty(&rep_enum->report_list))\n\t\treturn -ENODEV;\n\n\t/*\n\t * Check for the HID++ application.\n\t * Note: we should theoretically check for HID++ and DJ\n\t * collections, but this will do.\n\t */\n\tlist_for_each_entry(rep, &rep_enum->report_list, list) {\n\t\tif (rep->application == 0xff000001)\n\t\t\thas_hidpp = true;\n\t}\n\n\t/*\n\t * Ignore interfaces without DJ/HID++ collection, they will not carry\n\t * any data, dont create any hid_device for them.\n\t */\n\tif (!has_hidpp && id->driver_data == recvr_type_dj)\n\t\treturn -ENODEV;\n\n\t/* get the current application attached to the node */\n\trep = list_first_entry(&rep_enum->report_list, struct hid_report, list);\n\tdjrcv_dev = dj_get_receiver_dev(hdev, id->driver_data,\n\t\t\t\t\trep->application, has_hidpp);\n\tif (!djrcv_dev) {\n\t\thid_err(hdev, \"%s: dj_get_receiver_dev failed\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (!rep_enum->numbered)\n\t\tdjrcv_dev->unnumbered_application = rep->application;\n\n\t/* Starts the usb device and connects to upper interfaces hiddev and\n\t * hidraw */\n\tretval = hid_hw_start(hdev, HID_CONNECT_HIDRAW|HID_CONNECT_HIDDEV);\n\tif (retval) {\n\t\thid_err(hdev, \"%s: hid_hw_start returned error\\n\", __func__);\n\t\tgoto hid_hw_start_fail;\n\t}\n\n\tif (has_hidpp) {\n\t\tretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\n\t\tif (retval < 0) {\n\t\t\thid_err(hdev, \"%s: logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n\t\t\t\t__func__, retval);\n\t\t\tgoto switch_to_dj_mode_fail;\n\t\t}\n\t}\n\n\t/* This is enabling the polling urb on the IN endpoint */\n\tretval = hid_hw_open(hdev);\n\tif (retval < 0) {\n\t\thid_err(hdev, \"%s: hid_hw_open returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto llopen_failed;\n\t}\n\n\t/* Allow incoming packets to arrive: */\n\thid_device_io_start(hdev);\n\n\tif (has_hidpp) {\n\t\tspin_lock_irqsave(&djrcv_dev->lock, flags);\n\t\tdjrcv_dev->ready = true;\n\t\tspin_unlock_irqrestore(&djrcv_dev->lock, flags);\n\t\tretval = logi_dj_recv_query_paired_devices(djrcv_dev);\n\t\tif (retval < 0) {\n\t\t\thid_err(hdev, \"%s: logi_dj_recv_query_paired_devices error:%d\\n\",\n\t\t\t\t__func__, retval);\n\t\t\t/*\n\t\t\t * This can happen with a KVM, let the probe succeed,\n\t\t\t * logi_dj_recv_queue_unknown_work will retry later.\n\t\t\t */\n\t\t}\n\t}\n\n\treturn 0;\n\nllopen_failed:\nswitch_to_dj_mode_fail:\n\thid_hw_stop(hdev);\n\nhid_hw_start_fail:\n\tdj_put_receiver_dev(hdev);\n\treturn retval;\n}",
        "code_after_change": "static int logi_dj_probe(struct hid_device *hdev,\n\t\t\t const struct hid_device_id *id)\n{\n\tstruct hid_report_enum *rep_enum;\n\tstruct hid_report *rep;\n\tstruct dj_receiver_dev *djrcv_dev;\n\tstruct usb_interface *intf;\n\tunsigned int no_dj_interfaces = 0;\n\tbool has_hidpp = false;\n\tunsigned long flags;\n\tint retval;\n\n\t/*\n\t * Call to usbhid to fetch the HID descriptors of the current\n\t * interface subsequently call to the hid/hid-core to parse the\n\t * fetched descriptors.\n\t */\n\tretval = hid_parse(hdev);\n\tif (retval) {\n\t\thid_err(hdev, \"%s: parse failed\\n\", __func__);\n\t\treturn retval;\n\t}\n\n\t/*\n\t * Some KVMs add an extra interface for e.g. mouse emulation. If we\n\t * treat these as logitech-dj interfaces then this causes input events\n\t * reported through this extra interface to not be reported correctly.\n\t * To avoid this, we treat these as generic-hid devices.\n\t */\n\tswitch (id->driver_data) {\n\tcase recvr_type_dj:\t\tno_dj_interfaces = 3; break;\n\tcase recvr_type_hidpp:\t\tno_dj_interfaces = 2; break;\n\tcase recvr_type_gaming_hidpp:\tno_dj_interfaces = 3; break;\n\tcase recvr_type_mouse_only:\tno_dj_interfaces = 2; break;\n\tcase recvr_type_27mhz:\t\tno_dj_interfaces = 2; break;\n\tcase recvr_type_bluetooth:\tno_dj_interfaces = 2; break;\n\tcase recvr_type_dinovo:\t\tno_dj_interfaces = 2; break;\n\t}\n\tif (hid_is_usb(hdev)) {\n\t\tintf = to_usb_interface(hdev->dev.parent);\n\t\tif (intf && intf->altsetting->desc.bInterfaceNumber >=\n\t\t\t\t\t\t\tno_dj_interfaces) {\n\t\t\thdev->quirks |= HID_QUIRK_INPUT_PER_APP;\n\t\t\treturn hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\t\t}\n\t}\n\n\trep_enum = &hdev->report_enum[HID_INPUT_REPORT];\n\n\t/* no input reports, bail out */\n\tif (list_empty(&rep_enum->report_list))\n\t\treturn -ENODEV;\n\n\t/*\n\t * Check for the HID++ application.\n\t * Note: we should theoretically check for HID++ and DJ\n\t * collections, but this will do.\n\t */\n\tlist_for_each_entry(rep, &rep_enum->report_list, list) {\n\t\tif (rep->application == 0xff000001)\n\t\t\thas_hidpp = true;\n\t}\n\n\t/*\n\t * Ignore interfaces without DJ/HID++ collection, they will not carry\n\t * any data, dont create any hid_device for them.\n\t */\n\tif (!has_hidpp && id->driver_data == recvr_type_dj)\n\t\treturn -ENODEV;\n\n\t/* get the current application attached to the node */\n\trep = list_first_entry(&rep_enum->report_list, struct hid_report, list);\n\tdjrcv_dev = dj_get_receiver_dev(hdev, id->driver_data,\n\t\t\t\t\trep->application, has_hidpp);\n\tif (!djrcv_dev) {\n\t\thid_err(hdev, \"%s: dj_get_receiver_dev failed\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (!rep_enum->numbered)\n\t\tdjrcv_dev->unnumbered_application = rep->application;\n\n\t/* Starts the usb device and connects to upper interfaces hiddev and\n\t * hidraw */\n\tretval = hid_hw_start(hdev, HID_CONNECT_HIDRAW|HID_CONNECT_HIDDEV);\n\tif (retval) {\n\t\thid_err(hdev, \"%s: hid_hw_start returned error\\n\", __func__);\n\t\tgoto hid_hw_start_fail;\n\t}\n\n\tif (has_hidpp) {\n\t\tretval = logi_dj_recv_switch_to_dj_mode(djrcv_dev, 0);\n\t\tif (retval < 0) {\n\t\t\thid_err(hdev, \"%s: logi_dj_recv_switch_to_dj_mode returned error:%d\\n\",\n\t\t\t\t__func__, retval);\n\t\t\tgoto switch_to_dj_mode_fail;\n\t\t}\n\t}\n\n\t/* This is enabling the polling urb on the IN endpoint */\n\tretval = hid_hw_open(hdev);\n\tif (retval < 0) {\n\t\thid_err(hdev, \"%s: hid_hw_open returned error:%d\\n\",\n\t\t\t__func__, retval);\n\t\tgoto llopen_failed;\n\t}\n\n\t/* Allow incoming packets to arrive: */\n\thid_device_io_start(hdev);\n\n\tif (has_hidpp) {\n\t\tspin_lock_irqsave(&djrcv_dev->lock, flags);\n\t\tdjrcv_dev->ready = true;\n\t\tspin_unlock_irqrestore(&djrcv_dev->lock, flags);\n\t\tretval = logi_dj_recv_query_paired_devices(djrcv_dev);\n\t\tif (retval < 0) {\n\t\t\thid_err(hdev, \"%s: logi_dj_recv_query_paired_devices error:%d\\n\",\n\t\t\t\t__func__, retval);\n\t\t\t/*\n\t\t\t * This can happen with a KVM, let the probe succeed,\n\t\t\t * logi_dj_recv_queue_unknown_work will retry later.\n\t\t\t */\n\t\t}\n\t}\n\n\treturn 0;\n\nllopen_failed:\nswitch_to_dj_mode_fail:\n\thid_hw_stop(hdev);\n\nhid_hw_start_fail:\n\tdj_put_receiver_dev(hdev);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -36,7 +36,7 @@\n \tcase recvr_type_bluetooth:\tno_dj_interfaces = 2; break;\n \tcase recvr_type_dinovo:\t\tno_dj_interfaces = 2; break;\n \t}\n-\tif (hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif (hid_is_usb(hdev)) {\n \t\tintf = to_usb_interface(hdev->dev.parent);\n \t\tif (intf && intf->altsetting->desc.bInterfaceNumber >=\n \t\t\t\t\t\t\tno_dj_interfaces) {",
        "function_modified_lines": {
            "added": [
                "\tif (hid_is_usb(hdev)) {"
            ],
            "deleted": [
                "\tif (hid_is_using_ll_driver(hdev, &usb_hid_driver)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In lg_probe and related functions of hid-lg.c and other USB HID files, there is a possible out of bounds read due to improper input validation. This could lead to local information disclosure if a malicious USB HID device were plugged in, with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-188677105References: Upstream kernel",
        "id": 3333
    },
    {
        "cve_id": "CVE-2019-15927",
        "code_before_change": "static int build_audio_procunit(struct mixer_build *state, int unitid,\n\t\t\t\tvoid *raw_desc, struct procunit_info *list,\n\t\t\t\tchar *name)\n{\n\tstruct uac_processing_unit_descriptor *desc = raw_desc;\n\tint num_ins = desc->bNrInPins;\n\tstruct usb_mixer_elem_info *cval;\n\tstruct snd_kcontrol *kctl;\n\tint i, err, nameid, type, len;\n\tstruct procunit_info *info;\n\tstruct procunit_value_info *valinfo;\n\tconst struct usbmix_name_map *map;\n\tstatic struct procunit_value_info default_value_info[] = {\n\t\t{ 0x01, \"Switch\", USB_MIXER_BOOLEAN },\n\t\t{ 0 }\n\t};\n\tstatic struct procunit_info default_info = {\n\t\t0, NULL, default_value_info\n\t};\n\n\tif (desc->bLength < 13 || desc->bLength < 13 + num_ins ||\n\t    desc->bLength < num_ins + uac_processing_unit_bControlSize(desc, state->mixer->protocol)) {\n\t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < num_ins; i++) {\n\t\terr = parse_audio_unit(state, desc->baSourceID[i]);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\ttype = le16_to_cpu(desc->wProcessType);\n\tfor (info = list; info && info->type; info++)\n\t\tif (info->type == type)\n\t\t\tbreak;\n\tif (!info || !info->type)\n\t\tinfo = &default_info;\n\n\tfor (valinfo = info->values; valinfo->control; valinfo++) {\n\t\t__u8 *controls = uac_processing_unit_bmControls(desc, state->mixer->protocol);\n\n\t\tif (state->mixer->protocol == UAC_VERSION_1) {\n\t\t\tif (!(controls[valinfo->control / 8] &\n\t\t\t\t\t(1 << ((valinfo->control % 8) - 1))))\n\t\t\t\tcontinue;\n\t\t} else { /* UAC_VERSION_2/3 */\n\t\t\tif (!uac_v2v3_control_is_readable(controls[valinfo->control / 8],\n\t\t\t\t\t\t\t  valinfo->control))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tmap = find_map(state->map, unitid, valinfo->control);\n\t\tif (check_ignored_ctl(map))\n\t\t\tcontinue;\n\t\tcval = kzalloc(sizeof(*cval), GFP_KERNEL);\n\t\tif (!cval)\n\t\t\treturn -ENOMEM;\n\t\tsnd_usb_mixer_elem_init_std(&cval->head, state->mixer, unitid);\n\t\tcval->control = valinfo->control;\n\t\tcval->val_type = valinfo->val_type;\n\t\tcval->channels = 1;\n\n\t\tif (state->mixer->protocol > UAC_VERSION_1 &&\n\t\t    !uac_v2v3_control_is_writeable(controls[valinfo->control / 8],\n\t\t\t\t\t\t   valinfo->control))\n\t\t\tcval->master_readonly = 1;\n\n\t\t/* get min/max values */\n\t\tswitch (type) {\n\t\tcase UAC_PROCESS_UP_DOWNMIX: {\n\t\t\tbool mode_sel = false;\n\n\t\t\tswitch (state->mixer->protocol) {\n\t\t\tcase UAC_VERSION_1:\n\t\t\tcase UAC_VERSION_2:\n\t\t\tdefault:\n\t\t\t\tif (cval->control == UAC_UD_MODE_SELECT)\n\t\t\t\t\tmode_sel = true;\n\t\t\t\tbreak;\n\t\t\tcase UAC_VERSION_3:\n\t\t\t\tif (cval->control == UAC3_UD_MODE_SELECT)\n\t\t\t\t\tmode_sel = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (mode_sel) {\n\t\t\t\t__u8 *control_spec = uac_processing_unit_specific(desc,\n\t\t\t\t\t\t\t\tstate->mixer->protocol);\n\t\t\t\tcval->min = 1;\n\t\t\t\tcval->max = control_spec[0];\n\t\t\t\tcval->res = 1;\n\t\t\t\tcval->initialized = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tget_min_max(cval, valinfo->min_value);\n\t\t\tbreak;\n\t\t}\n\t\tcase USB_XU_CLOCK_RATE:\n\t\t\t/*\n\t\t\t * E-Mu USB 0404/0202/TrackerPre/0204\n\t\t\t * samplerate control quirk\n\t\t\t */\n\t\t\tcval->min = 0;\n\t\t\tcval->max = 5;\n\t\t\tcval->res = 1;\n\t\t\tcval->initialized = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tget_min_max(cval, valinfo->min_value);\n\t\t\tbreak;\n\t\t}\n\n\t\tkctl = snd_ctl_new1(&mixer_procunit_ctl, cval);\n\t\tif (!kctl) {\n\t\t\tkfree(cval);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tkctl->private_free = snd_usb_mixer_elem_free;\n\n\t\tif (check_mapped_name(map, kctl->id.name, sizeof(kctl->id.name))) {\n\t\t\t/* nothing */ ;\n\t\t} else if (info->name) {\n\t\t\tstrlcpy(kctl->id.name, info->name, sizeof(kctl->id.name));\n\t\t} else {\n\t\t\tnameid = uac_processing_unit_iProcessing(desc, state->mixer->protocol);\n\t\t\tlen = 0;\n\t\t\tif (nameid)\n\t\t\t\tlen = snd_usb_copy_string_desc(state->chip,\n\t\t\t\t\t\t\t       nameid,\n\t\t\t\t\t\t\t       kctl->id.name,\n\t\t\t\t\t\t\t       sizeof(kctl->id.name));\n\t\t\tif (!len)\n\t\t\t\tstrlcpy(kctl->id.name, name, sizeof(kctl->id.name));\n\t\t}\n\t\tappend_ctl_name(kctl, \" \");\n\t\tappend_ctl_name(kctl, valinfo->suffix);\n\n\t\tusb_audio_dbg(state->chip,\n\t\t\t      \"[%d] PU [%s] ch = %d, val = %d/%d\\n\",\n\t\t\t      cval->head.id, kctl->id.name, cval->channels,\n\t\t\t      cval->min, cval->max);\n\n\t\terr = snd_usb_mixer_add_control(&cval->head, kctl);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int build_audio_procunit(struct mixer_build *state, int unitid,\n\t\t\t\tvoid *raw_desc, struct procunit_info *list,\n\t\t\t\tchar *name)\n{\n\tstruct uac_processing_unit_descriptor *desc = raw_desc;\n\tint num_ins;\n\tstruct usb_mixer_elem_info *cval;\n\tstruct snd_kcontrol *kctl;\n\tint i, err, nameid, type, len;\n\tstruct procunit_info *info;\n\tstruct procunit_value_info *valinfo;\n\tconst struct usbmix_name_map *map;\n\tstatic struct procunit_value_info default_value_info[] = {\n\t\t{ 0x01, \"Switch\", USB_MIXER_BOOLEAN },\n\t\t{ 0 }\n\t};\n\tstatic struct procunit_info default_info = {\n\t\t0, NULL, default_value_info\n\t};\n\n\tif (desc->bLength < 13) {\n\t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);\n\t\treturn -EINVAL;\n\t}\n\n\tnum_ins = desc->bNrInPins;\n\tif (desc->bLength < 13 + num_ins ||\n\t    desc->bLength < num_ins + uac_processing_unit_bControlSize(desc, state->mixer->protocol)) {\n\t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < num_ins; i++) {\n\t\terr = parse_audio_unit(state, desc->baSourceID[i]);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\ttype = le16_to_cpu(desc->wProcessType);\n\tfor (info = list; info && info->type; info++)\n\t\tif (info->type == type)\n\t\t\tbreak;\n\tif (!info || !info->type)\n\t\tinfo = &default_info;\n\n\tfor (valinfo = info->values; valinfo->control; valinfo++) {\n\t\t__u8 *controls = uac_processing_unit_bmControls(desc, state->mixer->protocol);\n\n\t\tif (state->mixer->protocol == UAC_VERSION_1) {\n\t\t\tif (!(controls[valinfo->control / 8] &\n\t\t\t\t\t(1 << ((valinfo->control % 8) - 1))))\n\t\t\t\tcontinue;\n\t\t} else { /* UAC_VERSION_2/3 */\n\t\t\tif (!uac_v2v3_control_is_readable(controls[valinfo->control / 8],\n\t\t\t\t\t\t\t  valinfo->control))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tmap = find_map(state->map, unitid, valinfo->control);\n\t\tif (check_ignored_ctl(map))\n\t\t\tcontinue;\n\t\tcval = kzalloc(sizeof(*cval), GFP_KERNEL);\n\t\tif (!cval)\n\t\t\treturn -ENOMEM;\n\t\tsnd_usb_mixer_elem_init_std(&cval->head, state->mixer, unitid);\n\t\tcval->control = valinfo->control;\n\t\tcval->val_type = valinfo->val_type;\n\t\tcval->channels = 1;\n\n\t\tif (state->mixer->protocol > UAC_VERSION_1 &&\n\t\t    !uac_v2v3_control_is_writeable(controls[valinfo->control / 8],\n\t\t\t\t\t\t   valinfo->control))\n\t\t\tcval->master_readonly = 1;\n\n\t\t/* get min/max values */\n\t\tswitch (type) {\n\t\tcase UAC_PROCESS_UP_DOWNMIX: {\n\t\t\tbool mode_sel = false;\n\n\t\t\tswitch (state->mixer->protocol) {\n\t\t\tcase UAC_VERSION_1:\n\t\t\tcase UAC_VERSION_2:\n\t\t\tdefault:\n\t\t\t\tif (cval->control == UAC_UD_MODE_SELECT)\n\t\t\t\t\tmode_sel = true;\n\t\t\t\tbreak;\n\t\t\tcase UAC_VERSION_3:\n\t\t\t\tif (cval->control == UAC3_UD_MODE_SELECT)\n\t\t\t\t\tmode_sel = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (mode_sel) {\n\t\t\t\t__u8 *control_spec = uac_processing_unit_specific(desc,\n\t\t\t\t\t\t\t\tstate->mixer->protocol);\n\t\t\t\tcval->min = 1;\n\t\t\t\tcval->max = control_spec[0];\n\t\t\t\tcval->res = 1;\n\t\t\t\tcval->initialized = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tget_min_max(cval, valinfo->min_value);\n\t\t\tbreak;\n\t\t}\n\t\tcase USB_XU_CLOCK_RATE:\n\t\t\t/*\n\t\t\t * E-Mu USB 0404/0202/TrackerPre/0204\n\t\t\t * samplerate control quirk\n\t\t\t */\n\t\t\tcval->min = 0;\n\t\t\tcval->max = 5;\n\t\t\tcval->res = 1;\n\t\t\tcval->initialized = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tget_min_max(cval, valinfo->min_value);\n\t\t\tbreak;\n\t\t}\n\n\t\tkctl = snd_ctl_new1(&mixer_procunit_ctl, cval);\n\t\tif (!kctl) {\n\t\t\tkfree(cval);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tkctl->private_free = snd_usb_mixer_elem_free;\n\n\t\tif (check_mapped_name(map, kctl->id.name, sizeof(kctl->id.name))) {\n\t\t\t/* nothing */ ;\n\t\t} else if (info->name) {\n\t\t\tstrlcpy(kctl->id.name, info->name, sizeof(kctl->id.name));\n\t\t} else {\n\t\t\tnameid = uac_processing_unit_iProcessing(desc, state->mixer->protocol);\n\t\t\tlen = 0;\n\t\t\tif (nameid)\n\t\t\t\tlen = snd_usb_copy_string_desc(state->chip,\n\t\t\t\t\t\t\t       nameid,\n\t\t\t\t\t\t\t       kctl->id.name,\n\t\t\t\t\t\t\t       sizeof(kctl->id.name));\n\t\t\tif (!len)\n\t\t\t\tstrlcpy(kctl->id.name, name, sizeof(kctl->id.name));\n\t\t}\n\t\tappend_ctl_name(kctl, \" \");\n\t\tappend_ctl_name(kctl, valinfo->suffix);\n\n\t\tusb_audio_dbg(state->chip,\n\t\t\t      \"[%d] PU [%s] ch = %d, val = %d/%d\\n\",\n\t\t\t      cval->head.id, kctl->id.name, cval->channels,\n\t\t\t      cval->min, cval->max);\n\n\t\terr = snd_usb_mixer_add_control(&cval->head, kctl);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \t\t\t\tchar *name)\n {\n \tstruct uac_processing_unit_descriptor *desc = raw_desc;\n-\tint num_ins = desc->bNrInPins;\n+\tint num_ins;\n \tstruct usb_mixer_elem_info *cval;\n \tstruct snd_kcontrol *kctl;\n \tint i, err, nameid, type, len;\n@@ -18,7 +18,13 @@\n \t\t0, NULL, default_value_info\n \t};\n \n-\tif (desc->bLength < 13 || desc->bLength < 13 + num_ins ||\n+\tif (desc->bLength < 13) {\n+\t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);\n+\t\treturn -EINVAL;\n+\t}\n+\n+\tnum_ins = desc->bNrInPins;\n+\tif (desc->bLength < 13 + num_ins ||\n \t    desc->bLength < num_ins + uac_processing_unit_bControlSize(desc, state->mixer->protocol)) {\n \t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);\n \t\treturn -EINVAL;",
        "function_modified_lines": {
            "added": [
                "\tint num_ins;",
                "\tif (desc->bLength < 13) {",
                "\t\tusb_audio_err(state->chip, \"invalid %s descriptor (id %d)\\n\", name, unitid);",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\tnum_ins = desc->bNrInPins;",
                "\tif (desc->bLength < 13 + num_ins ||"
            ],
            "deleted": [
                "\tint num_ins = desc->bNrInPins;",
                "\tif (desc->bLength < 13 || desc->bLength < 13 + num_ins ||"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 4.20.2. An out-of-bounds access exists in the function build_audio_procunit in the file sound/usb/mixer.c.",
        "id": 2042
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\t/* Assuming scalar64_min_max_xor will be called so it is safe\n\t * to skip updating register for known case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "code_after_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,11 +6,10 @@\n \tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n \ts32 smin_val = src_reg->s32_min_value;\n \n-\t/* Assuming scalar64_min_max_xor will be called so it is safe\n-\t * to skip updating register for known case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get both minimum and maximum from the var32_off. */\n \tdst_reg->u32_min_value = var32_off.value;",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_xor will be called so it is safe",
                "\t * to skip updating register for known case.",
                "\t */",
                "\tif (src_known && dst_known)"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1).",
        "id": 3010
    },
    {
        "cve_id": "CVE-2020-35519",
        "code_before_change": "static int x25_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t       int addr_len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct x25_sock *x25 = x25_sk(sk);\n\tstruct sockaddr_x25 *addr = (struct sockaddr_x25 *)uaddr;\n\tstruct x25_route *rt;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\tif (sk->sk_state == TCP_ESTABLISHED && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_CONNECTED;\n\t\tgoto out; /* Connect completed during a ERESTARTSYS event */\n\t}\n\n\trc = -ECONNREFUSED;\n\tif (sk->sk_state == TCP_CLOSE && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_UNCONNECTED;\n\t\tgoto out;\n\t}\n\n\trc = -EISCONN;\t/* No reconnect on a seqpacket socket */\n\tif (sk->sk_state == TCP_ESTABLISHED)\n\t\tgoto out;\n\n\trc = -EALREADY;\t/* Do nothing if call is already in progress */\n\tif (sk->sk_state == TCP_SYN_SENT)\n\t\tgoto out;\n\n\tsk->sk_state   = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = -EINVAL;\n\tif (addr_len != sizeof(struct sockaddr_x25) ||\n\t    addr->sx25_family != AF_X25)\n\t\tgoto out;\n\n\trc = -ENETUNREACH;\n\trt = x25_get_route(&addr->sx25_addr);\n\tif (!rt)\n\t\tgoto out;\n\n\tx25->neighbour = x25_get_neigh(rt->dev);\n\tif (!x25->neighbour)\n\t\tgoto out_put_route;\n\n\tx25_limit_facilities(&x25->facilities, x25->neighbour);\n\n\tx25->lci = x25_new_lci(x25->neighbour);\n\tif (!x25->lci)\n\t\tgoto out_put_neigh;\n\n\trc = -EINVAL;\n\tif (sock_flag(sk, SOCK_ZAPPED)) /* Must bind first - autobinding does not work */\n\t\tgoto out_put_neigh;\n\n\tif (!strcmp(x25->source_addr.x25_addr, null_x25_address.x25_addr))\n\t\tmemset(&x25->source_addr, '\\0', X25_ADDR_LEN);\n\n\tx25->dest_addr = addr->sx25_addr;\n\n\t/* Move to connecting socket, start sending Connect Requests */\n\tsock->state   = SS_CONNECTING;\n\tsk->sk_state  = TCP_SYN_SENT;\n\n\tx25->state = X25_STATE_1;\n\n\tx25_write_internal(sk, X25_CALL_REQUEST);\n\n\tx25_start_heartbeat(sk);\n\tx25_start_t21timer(sk);\n\n\t/* Now the loop */\n\trc = -EINPROGRESS;\n\tif (sk->sk_state != TCP_ESTABLISHED && (flags & O_NONBLOCK))\n\t\tgoto out;\n\n\trc = x25_wait_for_connection_establishment(sk);\n\tif (rc)\n\t\tgoto out_put_neigh;\n\n\tsock->state = SS_CONNECTED;\n\trc = 0;\nout_put_neigh:\n\tif (rc && x25->neighbour) {\n\t\tread_lock_bh(&x25_list_lock);\n\t\tx25_neigh_put(x25->neighbour);\n\t\tx25->neighbour = NULL;\n\t\tread_unlock_bh(&x25_list_lock);\n\t\tx25->state = X25_STATE_0;\n\t}\nout_put_route:\n\tx25_route_put(rt);\nout:\n\trelease_sock(sk);\n\treturn rc;\n}",
        "code_after_change": "static int x25_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t       int addr_len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct x25_sock *x25 = x25_sk(sk);\n\tstruct sockaddr_x25 *addr = (struct sockaddr_x25 *)uaddr;\n\tstruct x25_route *rt;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\tif (sk->sk_state == TCP_ESTABLISHED && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_CONNECTED;\n\t\tgoto out; /* Connect completed during a ERESTARTSYS event */\n\t}\n\n\trc = -ECONNREFUSED;\n\tif (sk->sk_state == TCP_CLOSE && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_UNCONNECTED;\n\t\tgoto out;\n\t}\n\n\trc = -EISCONN;\t/* No reconnect on a seqpacket socket */\n\tif (sk->sk_state == TCP_ESTABLISHED)\n\t\tgoto out;\n\n\trc = -EALREADY;\t/* Do nothing if call is already in progress */\n\tif (sk->sk_state == TCP_SYN_SENT)\n\t\tgoto out;\n\n\tsk->sk_state   = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = -EINVAL;\n\tif (addr_len != sizeof(struct sockaddr_x25) ||\n\t    addr->sx25_family != AF_X25 ||\n\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)\n\t\tgoto out;\n\n\trc = -ENETUNREACH;\n\trt = x25_get_route(&addr->sx25_addr);\n\tif (!rt)\n\t\tgoto out;\n\n\tx25->neighbour = x25_get_neigh(rt->dev);\n\tif (!x25->neighbour)\n\t\tgoto out_put_route;\n\n\tx25_limit_facilities(&x25->facilities, x25->neighbour);\n\n\tx25->lci = x25_new_lci(x25->neighbour);\n\tif (!x25->lci)\n\t\tgoto out_put_neigh;\n\n\trc = -EINVAL;\n\tif (sock_flag(sk, SOCK_ZAPPED)) /* Must bind first - autobinding does not work */\n\t\tgoto out_put_neigh;\n\n\tif (!strcmp(x25->source_addr.x25_addr, null_x25_address.x25_addr))\n\t\tmemset(&x25->source_addr, '\\0', X25_ADDR_LEN);\n\n\tx25->dest_addr = addr->sx25_addr;\n\n\t/* Move to connecting socket, start sending Connect Requests */\n\tsock->state   = SS_CONNECTING;\n\tsk->sk_state  = TCP_SYN_SENT;\n\n\tx25->state = X25_STATE_1;\n\n\tx25_write_internal(sk, X25_CALL_REQUEST);\n\n\tx25_start_heartbeat(sk);\n\tx25_start_t21timer(sk);\n\n\t/* Now the loop */\n\trc = -EINPROGRESS;\n\tif (sk->sk_state != TCP_ESTABLISHED && (flags & O_NONBLOCK))\n\t\tgoto out;\n\n\trc = x25_wait_for_connection_establishment(sk);\n\tif (rc)\n\t\tgoto out_put_neigh;\n\n\tsock->state = SS_CONNECTED;\n\trc = 0;\nout_put_neigh:\n\tif (rc && x25->neighbour) {\n\t\tread_lock_bh(&x25_list_lock);\n\t\tx25_neigh_put(x25->neighbour);\n\t\tx25->neighbour = NULL;\n\t\tread_unlock_bh(&x25_list_lock);\n\t\tx25->state = X25_STATE_0;\n\t}\nout_put_route:\n\tx25_route_put(rt);\nout:\n\trelease_sock(sk);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,7 +32,8 @@\n \n \trc = -EINVAL;\n \tif (addr_len != sizeof(struct sockaddr_x25) ||\n-\t    addr->sx25_family != AF_X25)\n+\t    addr->sx25_family != AF_X25 ||\n+\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)\n \t\tgoto out;\n \n \trc = -ENETUNREACH;",
        "function_modified_lines": {
            "added": [
                "\t    addr->sx25_family != AF_X25 ||",
                "\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)"
            ],
            "deleted": [
                "\t    addr->sx25_family != AF_X25)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds (OOB) memory access flaw was found in x25_bind in net/x25/af_x25.c in the Linux kernel version v5.12-rc5. A bounds check failure allows a local attacker with a user account on the system to gain access to out-of-bounds memory, leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability.",
        "id": 2712
    },
    {
        "cve_id": "CVE-2018-10877",
        "code_before_change": "struct ext4_ext_path *\next4_find_extent(struct inode *inode, ext4_lblk_t block,\n\t\t struct ext4_ext_path **orig_path, int flags)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct buffer_head *bh;\n\tstruct ext4_ext_path *path = orig_path ? *orig_path : NULL;\n\tshort int depth, i, ppos = 0;\n\tint ret;\n\n\teh = ext_inode_hdr(inode);\n\tdepth = ext_depth(inode);\n\n\tif (path) {\n\t\text4_ext_drop_refs(path);\n\t\tif (depth > path[0].p_maxdepth) {\n\t\t\tkfree(path);\n\t\t\t*orig_path = path = NULL;\n\t\t}\n\t}\n\tif (!path) {\n\t\t/* account possible depth increase */\n\t\tpath = kzalloc(sizeof(struct ext4_ext_path) * (depth + 2),\n\t\t\t\tGFP_NOFS);\n\t\tif (unlikely(!path))\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\tpath[0].p_maxdepth = depth + 1;\n\t}\n\tpath[0].p_hdr = eh;\n\tpath[0].p_bh = NULL;\n\n\ti = depth;\n\t/* walk through the tree */\n\twhile (i) {\n\t\text_debug(\"depth %d: num %d, max %d\\n\",\n\t\t\t  ppos, le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\n\t\text4_ext_binsearch_idx(inode, path + ppos, block);\n\t\tpath[ppos].p_block = ext4_idx_pblock(path[ppos].p_idx);\n\t\tpath[ppos].p_depth = i;\n\t\tpath[ppos].p_ext = NULL;\n\n\t\tbh = read_extent_tree_block(inode, path[ppos].p_block, --i,\n\t\t\t\t\t    flags);\n\t\tif (IS_ERR(bh)) {\n\t\t\tret = PTR_ERR(bh);\n\t\t\tgoto err;\n\t\t}\n\n\t\teh = ext_block_hdr(bh);\n\t\tppos++;\n\t\tpath[ppos].p_bh = bh;\n\t\tpath[ppos].p_hdr = eh;\n\t}\n\n\tpath[ppos].p_depth = i;\n\tpath[ppos].p_ext = NULL;\n\tpath[ppos].p_idx = NULL;\n\n\t/* find extent */\n\text4_ext_binsearch(inode, path + ppos, block);\n\t/* if not an empty leaf */\n\tif (path[ppos].p_ext)\n\t\tpath[ppos].p_block = ext4_ext_pblock(path[ppos].p_ext);\n\n\text4_ext_show_path(inode, path);\n\n\treturn path;\n\nerr:\n\text4_ext_drop_refs(path);\n\tkfree(path);\n\tif (orig_path)\n\t\t*orig_path = NULL;\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "struct ext4_ext_path *\next4_find_extent(struct inode *inode, ext4_lblk_t block,\n\t\t struct ext4_ext_path **orig_path, int flags)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct buffer_head *bh;\n\tstruct ext4_ext_path *path = orig_path ? *orig_path : NULL;\n\tshort int depth, i, ppos = 0;\n\tint ret;\n\n\teh = ext_inode_hdr(inode);\n\tdepth = ext_depth(inode);\n\tif (depth < 0 || depth > EXT4_MAX_EXTENT_DEPTH) {\n\t\tEXT4_ERROR_INODE(inode, \"inode has invalid extent depth: %d\",\n\t\t\t\t depth);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto err;\n\t}\n\n\tif (path) {\n\t\text4_ext_drop_refs(path);\n\t\tif (depth > path[0].p_maxdepth) {\n\t\t\tkfree(path);\n\t\t\t*orig_path = path = NULL;\n\t\t}\n\t}\n\tif (!path) {\n\t\t/* account possible depth increase */\n\t\tpath = kzalloc(sizeof(struct ext4_ext_path) * (depth + 2),\n\t\t\t\tGFP_NOFS);\n\t\tif (unlikely(!path))\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\tpath[0].p_maxdepth = depth + 1;\n\t}\n\tpath[0].p_hdr = eh;\n\tpath[0].p_bh = NULL;\n\n\ti = depth;\n\t/* walk through the tree */\n\twhile (i) {\n\t\text_debug(\"depth %d: num %d, max %d\\n\",\n\t\t\t  ppos, le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\n\t\text4_ext_binsearch_idx(inode, path + ppos, block);\n\t\tpath[ppos].p_block = ext4_idx_pblock(path[ppos].p_idx);\n\t\tpath[ppos].p_depth = i;\n\t\tpath[ppos].p_ext = NULL;\n\n\t\tbh = read_extent_tree_block(inode, path[ppos].p_block, --i,\n\t\t\t\t\t    flags);\n\t\tif (IS_ERR(bh)) {\n\t\t\tret = PTR_ERR(bh);\n\t\t\tgoto err;\n\t\t}\n\n\t\teh = ext_block_hdr(bh);\n\t\tppos++;\n\t\tpath[ppos].p_bh = bh;\n\t\tpath[ppos].p_hdr = eh;\n\t}\n\n\tpath[ppos].p_depth = i;\n\tpath[ppos].p_ext = NULL;\n\tpath[ppos].p_idx = NULL;\n\n\t/* find extent */\n\text4_ext_binsearch(inode, path + ppos, block);\n\t/* if not an empty leaf */\n\tif (path[ppos].p_ext)\n\t\tpath[ppos].p_block = ext4_ext_pblock(path[ppos].p_ext);\n\n\text4_ext_show_path(inode, path);\n\n\treturn path;\n\nerr:\n\text4_ext_drop_refs(path);\n\tkfree(path);\n\tif (orig_path)\n\t\t*orig_path = NULL;\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,12 @@\n \n \teh = ext_inode_hdr(inode);\n \tdepth = ext_depth(inode);\n+\tif (depth < 0 || depth > EXT4_MAX_EXTENT_DEPTH) {\n+\t\tEXT4_ERROR_INODE(inode, \"inode has invalid extent depth: %d\",\n+\t\t\t\t depth);\n+\t\tret = -EFSCORRUPTED;\n+\t\tgoto err;\n+\t}\n \n \tif (path) {\n \t\text4_ext_drop_refs(path);",
        "function_modified_lines": {
            "added": [
                "\tif (depth < 0 || depth > EXT4_MAX_EXTENT_DEPTH) {",
                "\t\tEXT4_ERROR_INODE(inode, \"inode has invalid extent depth: %d\",",
                "\t\t\t\t depth);",
                "\t\tret = -EFSCORRUPTED;",
                "\t\tgoto err;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "Linux kernel ext4 filesystem is vulnerable to an out-of-bound access in the ext4_ext_drop_refs() function when operating on a crafted ext4 filesystem image.",
        "id": 1610
    },
    {
        "cve_id": "CVE-2022-1508",
        "code_before_change": "static int io_write(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t ret, ret2, io_size;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(WRITE, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, WRITE))\n\t\tgoto copy_iov;\n\n\t/* file path doesn't support NOWAIT for non-direct_IO */\n\tif (force_nonblock && !(kiocb->ki_flags & IOCB_DIRECT) &&\n\t    (req->flags & REQ_F_ISREG))\n\t\tgoto copy_iov;\n\n\tret = rw_verify_area(WRITE, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret))\n\t\tgoto out_free;\n\n\t/*\n\t * Open-code file_start_write here to grab freeze protection,\n\t * which will be released by another thread in\n\t * io_complete_rw().  Fool lockdep by telling it the lock got\n\t * released so that it doesn't complain about the held lock when\n\t * we return to userspace.\n\t */\n\tif (req->flags & REQ_F_ISREG) {\n\t\tsb_start_write(file_inode(req->file)->i_sb);\n\t\t__sb_writers_release(file_inode(req->file)->i_sb,\n\t\t\t\t\tSB_FREEZE_WRITE);\n\t}\n\tkiocb->ki_flags |= IOCB_WRITE;\n\n\tif (req->file->f_op->write_iter)\n\t\tret2 = call_write_iter(req->file, kiocb, iter);\n\telse if (req->file->f_op->write)\n\t\tret2 = loop_rw_iter(WRITE, req, iter);\n\telse\n\t\tret2 = -EINVAL;\n\n\tif (req->flags & REQ_F_REISSUE) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\tret2 = -EAGAIN;\n\t}\n\n\t/*\n\t * Raw bdev writes will return -EOPNOTSUPP for IOCB_NOWAIT. Just\n\t * retry them without IOCB_NOWAIT.\n\t */\n\tif (ret2 == -EOPNOTSUPP && (kiocb->ki_flags & IOCB_NOWAIT))\n\t\tret2 = -EAGAIN;\n\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\tif (ret2 == -EAGAIN && (req->flags & REQ_F_NOWAIT))\n\t\tgoto done;\n\tif (!force_nonblock || ret2 != -EAGAIN) {\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif ((req->ctx->flags & IORING_SETUP_IOPOLL) && ret2 == -EAGAIN)\n\t\t\tgoto copy_iov;\ndone:\n\t\tkiocb_done(kiocb, ret2, issue_flags);\n\t} else {\ncopy_iov:\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, false);\n\t\treturn ret ?: -EAGAIN;\n\t}\nout_free:\n\t/* it's reportedly faster than delegating the null check to kfree() */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn ret;\n}",
        "code_after_change": "static int io_write(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t ret, ret2, io_size;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(WRITE, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, WRITE))\n\t\tgoto copy_iov;\n\n\t/* file path doesn't support NOWAIT for non-direct_IO */\n\tif (force_nonblock && !(kiocb->ki_flags & IOCB_DIRECT) &&\n\t    (req->flags & REQ_F_ISREG))\n\t\tgoto copy_iov;\n\n\tret = rw_verify_area(WRITE, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret))\n\t\tgoto out_free;\n\n\t/*\n\t * Open-code file_start_write here to grab freeze protection,\n\t * which will be released by another thread in\n\t * io_complete_rw().  Fool lockdep by telling it the lock got\n\t * released so that it doesn't complain about the held lock when\n\t * we return to userspace.\n\t */\n\tif (req->flags & REQ_F_ISREG) {\n\t\tsb_start_write(file_inode(req->file)->i_sb);\n\t\t__sb_writers_release(file_inode(req->file)->i_sb,\n\t\t\t\t\tSB_FREEZE_WRITE);\n\t}\n\tkiocb->ki_flags |= IOCB_WRITE;\n\n\tif (req->file->f_op->write_iter)\n\t\tret2 = call_write_iter(req->file, kiocb, iter);\n\telse if (req->file->f_op->write)\n\t\tret2 = loop_rw_iter(WRITE, req, iter);\n\telse\n\t\tret2 = -EINVAL;\n\n\tif (req->flags & REQ_F_REISSUE) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\tret2 = -EAGAIN;\n\t}\n\n\t/*\n\t * Raw bdev writes will return -EOPNOTSUPP for IOCB_NOWAIT. Just\n\t * retry them without IOCB_NOWAIT.\n\t */\n\tif (ret2 == -EOPNOTSUPP && (kiocb->ki_flags & IOCB_NOWAIT))\n\t\tret2 = -EAGAIN;\n\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\tif (ret2 == -EAGAIN && (req->flags & REQ_F_NOWAIT))\n\t\tgoto done;\n\tif (!force_nonblock || ret2 != -EAGAIN) {\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif ((req->ctx->flags & IORING_SETUP_IOPOLL) && ret2 == -EAGAIN)\n\t\t\tgoto copy_iov;\ndone:\n\t\tkiocb_done(kiocb, ret2, issue_flags);\n\t} else {\ncopy_iov:\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, false);\n\t\treturn ret ?: -EAGAIN;\n\t}\nout_free:\n\t/* it's reportedly faster than delegating the null check to kfree() */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -81,6 +81,7 @@\n \t} else {\n copy_iov:\n \t\t/* some cases will consume bytes even on error returns */\n+\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n \t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n \t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, false);\n \t\treturn ret ?: -EAGAIN;",
        "function_modified_lines": {
            "added": [
                "\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read flaw was found in the Linux kernels io_uring module in the way a user triggers the io_read() function with some special parameters. This flaw allows a local user to read some memory out of bounds.",
        "id": 3262
    },
    {
        "cve_id": "CVE-2019-15926",
        "code_before_change": "static int ath6kl_wmi_cac_event_rx(struct wmi *wmi, u8 *datap, int len,\n\t\t\t\t   struct ath6kl_vif *vif)\n{\n\tstruct wmi_cac_event *reply;\n\tstruct ieee80211_tspec_ie *ts;\n\tu16 active_tsids, tsinfo;\n\tu8 tsid, index;\n\tu8 ts_id;\n\n\tif (len < sizeof(struct wmi_cac_event))\n\t\treturn -EINVAL;\n\n\treply = (struct wmi_cac_event *) datap;\n\n\tif ((reply->cac_indication == CAC_INDICATION_ADMISSION_RESP) &&\n\t    (reply->status_code != IEEE80211_TSPEC_STATUS_ADMISS_ACCEPTED)) {\n\t\tts = (struct ieee80211_tspec_ie *) &(reply->tspec_suggestion);\n\t\ttsinfo = le16_to_cpu(ts->tsinfo);\n\t\ttsid = (tsinfo >> IEEE80211_WMM_IE_TSPEC_TID_SHIFT) &\n\t\t\tIEEE80211_WMM_IE_TSPEC_TID_MASK;\n\n\t\tath6kl_wmi_delete_pstream_cmd(wmi, vif->fw_vif_idx,\n\t\t\t\t\t      reply->ac, tsid);\n\t} else if (reply->cac_indication == CAC_INDICATION_NO_RESP) {\n\t\t/*\n\t\t * Following assumes that there is only one outstanding\n\t\t * ADDTS request when this event is received\n\t\t */\n\t\tspin_lock_bh(&wmi->lock);\n\t\tactive_tsids = wmi->stream_exist_for_ac[reply->ac];\n\t\tspin_unlock_bh(&wmi->lock);\n\n\t\tfor (index = 0; index < sizeof(active_tsids) * 8; index++) {\n\t\t\tif ((active_tsids >> index) & 1)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (index < (sizeof(active_tsids) * 8))\n\t\t\tath6kl_wmi_delete_pstream_cmd(wmi, vif->fw_vif_idx,\n\t\t\t\t\t\t      reply->ac, index);\n\t}\n\n\t/*\n\t * Clear active tsids and Add missing handling\n\t * for delete qos stream from AP\n\t */\n\telse if (reply->cac_indication == CAC_INDICATION_DELETE) {\n\t\tts = (struct ieee80211_tspec_ie *) &(reply->tspec_suggestion);\n\t\ttsinfo = le16_to_cpu(ts->tsinfo);\n\t\tts_id = ((tsinfo >> IEEE80211_WMM_IE_TSPEC_TID_SHIFT) &\n\t\t\t IEEE80211_WMM_IE_TSPEC_TID_MASK);\n\n\t\tspin_lock_bh(&wmi->lock);\n\t\twmi->stream_exist_for_ac[reply->ac] &= ~(1 << ts_id);\n\t\tactive_tsids = wmi->stream_exist_for_ac[reply->ac];\n\t\tspin_unlock_bh(&wmi->lock);\n\n\t\t/* Indicate stream inactivity to driver layer only if all tsids\n\t\t * within this AC are deleted.\n\t\t */\n\t\tif (!active_tsids) {\n\t\t\tath6kl_indicate_tx_activity(wmi->parent_dev, reply->ac,\n\t\t\t\t\t\t    false);\n\t\t\twmi->fat_pipe_exist &= ~(1 << reply->ac);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int ath6kl_wmi_cac_event_rx(struct wmi *wmi, u8 *datap, int len,\n\t\t\t\t   struct ath6kl_vif *vif)\n{\n\tstruct wmi_cac_event *reply;\n\tstruct ieee80211_tspec_ie *ts;\n\tu16 active_tsids, tsinfo;\n\tu8 tsid, index;\n\tu8 ts_id;\n\n\tif (len < sizeof(struct wmi_cac_event))\n\t\treturn -EINVAL;\n\n\treply = (struct wmi_cac_event *) datap;\n\tif (reply->ac >= WMM_NUM_AC) {\n\t\tath6kl_err(\"invalid AC: %d\\n\", reply->ac);\n\t\treturn -EINVAL;\n\t}\n\n\tif ((reply->cac_indication == CAC_INDICATION_ADMISSION_RESP) &&\n\t    (reply->status_code != IEEE80211_TSPEC_STATUS_ADMISS_ACCEPTED)) {\n\t\tts = (struct ieee80211_tspec_ie *) &(reply->tspec_suggestion);\n\t\ttsinfo = le16_to_cpu(ts->tsinfo);\n\t\ttsid = (tsinfo >> IEEE80211_WMM_IE_TSPEC_TID_SHIFT) &\n\t\t\tIEEE80211_WMM_IE_TSPEC_TID_MASK;\n\n\t\tath6kl_wmi_delete_pstream_cmd(wmi, vif->fw_vif_idx,\n\t\t\t\t\t      reply->ac, tsid);\n\t} else if (reply->cac_indication == CAC_INDICATION_NO_RESP) {\n\t\t/*\n\t\t * Following assumes that there is only one outstanding\n\t\t * ADDTS request when this event is received\n\t\t */\n\t\tspin_lock_bh(&wmi->lock);\n\t\tactive_tsids = wmi->stream_exist_for_ac[reply->ac];\n\t\tspin_unlock_bh(&wmi->lock);\n\n\t\tfor (index = 0; index < sizeof(active_tsids) * 8; index++) {\n\t\t\tif ((active_tsids >> index) & 1)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (index < (sizeof(active_tsids) * 8))\n\t\t\tath6kl_wmi_delete_pstream_cmd(wmi, vif->fw_vif_idx,\n\t\t\t\t\t\t      reply->ac, index);\n\t}\n\n\t/*\n\t * Clear active tsids and Add missing handling\n\t * for delete qos stream from AP\n\t */\n\telse if (reply->cac_indication == CAC_INDICATION_DELETE) {\n\t\tts = (struct ieee80211_tspec_ie *) &(reply->tspec_suggestion);\n\t\ttsinfo = le16_to_cpu(ts->tsinfo);\n\t\tts_id = ((tsinfo >> IEEE80211_WMM_IE_TSPEC_TID_SHIFT) &\n\t\t\t IEEE80211_WMM_IE_TSPEC_TID_MASK);\n\n\t\tspin_lock_bh(&wmi->lock);\n\t\twmi->stream_exist_for_ac[reply->ac] &= ~(1 << ts_id);\n\t\tactive_tsids = wmi->stream_exist_for_ac[reply->ac];\n\t\tspin_unlock_bh(&wmi->lock);\n\n\t\t/* Indicate stream inactivity to driver layer only if all tsids\n\t\t * within this AC are deleted.\n\t\t */\n\t\tif (!active_tsids) {\n\t\t\tath6kl_indicate_tx_activity(wmi->parent_dev, reply->ac,\n\t\t\t\t\t\t    false);\n\t\t\twmi->fat_pipe_exist &= ~(1 << reply->ac);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,10 @@\n \t\treturn -EINVAL;\n \n \treply = (struct wmi_cac_event *) datap;\n+\tif (reply->ac >= WMM_NUM_AC) {\n+\t\tath6kl_err(\"invalid AC: %d\\n\", reply->ac);\n+\t\treturn -EINVAL;\n+\t}\n \n \tif ((reply->cac_indication == CAC_INDICATION_ADMISSION_RESP) &&\n \t    (reply->status_code != IEEE80211_TSPEC_STATUS_ADMISS_ACCEPTED)) {",
        "function_modified_lines": {
            "added": [
                "\tif (reply->ac >= WMM_NUM_AC) {",
                "\t\tath6kl_err(\"invalid AC: %d\\n\", reply->ac);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. Out of bounds access exists in the functions ath6kl_wmi_pstream_timeout_event_rx and ath6kl_wmi_cac_event_rx in the file drivers/net/wireless/ath/ath6kl/wmi.c.",
        "id": 2040
    },
    {
        "cve_id": "CVE-2021-29155",
        "code_before_change": "static int adjust_ptr_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t   struct bpf_insn *insn,\n\t\t\t\t   const struct bpf_reg_state *ptr_reg,\n\t\t\t\t   const struct bpf_reg_state *off_reg)\n{\n\tstruct bpf_verifier_state *vstate = env->cur_state;\n\tstruct bpf_func_state *state = vstate->frame[vstate->curframe];\n\tstruct bpf_reg_state *regs = state->regs, *dst_reg;\n\tbool known = tnum_is_const(off_reg->var_off);\n\ts64 smin_val = off_reg->smin_value, smax_val = off_reg->smax_value,\n\t    smin_ptr = ptr_reg->smin_value, smax_ptr = ptr_reg->smax_value;\n\tu64 umin_val = off_reg->umin_value, umax_val = off_reg->umax_value,\n\t    umin_ptr = ptr_reg->umin_value, umax_ptr = ptr_reg->umax_value;\n\tu32 dst = insn->dst_reg, src = insn->src_reg;\n\tu8 opcode = BPF_OP(insn->code);\n\tint ret;\n\n\tdst_reg = &regs[dst];\n\n\tif ((known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(env, dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops on pointers produce (meaningless) scalars */\n\t\tif (opcode == BPF_SUB && env->allow_ptr_leaks) {\n\t\t\t__mark_reg_unknown(env, dst_reg);\n\t\t\treturn 0;\n\t\t}\n\n\t\tverbose(env,\n\t\t\t\"R%d 32-bit pointer arithmetic prohibited\\n\",\n\t\t\tdst);\n\t\treturn -EACCES;\n\t}\n\n\tswitch (ptr_reg->type) {\n\tcase PTR_TO_MAP_VALUE_OR_NULL:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited, null-check it first\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tcase CONST_PTR_TO_MAP:\n\t\t/* smin_val represents the known value */\n\t\tif (known && smin_val == 0 && opcode == BPF_ADD)\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tcase PTR_TO_MAP_VALUE:\n\t\tif (!env->allow_ptr_leaks && !known && (smin_val < 0) != (smax_val < 0)) {\n\t\t\tverbose(env, \"R%d has unknown scalar with mixed signed bounds, pointer arithmetic with it prohibited for !root\\n\",\n\t\t\t\toff_reg == dst_reg ? dst : src);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tfallthrough;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t/* In case of 'scalar += pointer', dst_reg inherits pointer type and id.\n\t * The id may be overwritten later if we create a new variable offset.\n\t */\n\tdst_reg->type = ptr_reg->type;\n\tdst_reg->id = ptr_reg->id;\n\n\tif (!check_reg_sane_offset(env, off_reg, ptr_reg->type) ||\n\t    !check_reg_sane_offset(env, ptr_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t/* pointer types do not carry 32-bit bounds at the moment. */\n\t__mark_reg32_unbounded(dst_reg);\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, dst_reg, smin_val < 0);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"R%d tried to add from different maps, paths, or prohibited types\\n\", dst);\n\t\t\treturn ret;\n\t\t}\n\t\t/* We can take a fixed offset as long as it doesn't overflow\n\t\t * the s32 'off' field\n\t\t */\n\t\tif (known && (ptr_reg->off + smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off + smin_val))) {\n\t\t\t/* pointer += K.  Accumulate it into fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->off = ptr_reg->off + smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  Note that off_reg->off\n\t\t * == 0, since it's a scalar.\n\t\t * dst_reg gets the pointer type and since some positive\n\t\t * integer value was added to the pointer, give it a new 'id'\n\t\t * if it's a PTR_TO_PACKET.\n\t\t * this creates a new 'base' pointer, off_reg (variable) gets\n\t\t * added into the variable offset, and we copy the fixed offset\n\t\t * from ptr_reg.\n\t\t */\n\t\tif (signed_add_overflows(smin_ptr, smin_val) ||\n\t\t    signed_add_overflows(smax_ptr, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr + smin_val;\n\t\t\tdst_reg->smax_value = smax_ptr + smax_val;\n\t\t}\n\t\tif (umin_ptr + umin_val < umin_ptr ||\n\t\t    umax_ptr + umax_val < umax_ptr) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value = umin_ptr + umin_val;\n\t\t\tdst_reg->umax_value = umax_ptr + umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, dst_reg, smin_val < 0);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"R%d tried to sub from different maps, paths, or prohibited types\\n\", dst);\n\t\t\treturn ret;\n\t\t}\n\t\tif (dst_reg == off_reg) {\n\t\t\t/* scalar -= pointer.  Creates an unknown scalar */\n\t\t\tverbose(env, \"R%d tried to subtract pointer from scalar\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* We don't allow subtraction from FP, because (according to\n\t\t * test_verifier.c test \"invalid fp arithmetic\", JITs might not\n\t\t * be able to deal with it.\n\t\t */\n\t\tif (ptr_reg->type == PTR_TO_STACK) {\n\t\t\tverbose(env, \"R%d subtraction from stack pointer prohibited\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (known && (ptr_reg->off - smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off - smin_val))) {\n\t\t\t/* pointer -= K.  Subtract it from fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->id = ptr_reg->id;\n\t\t\tdst_reg->off = ptr_reg->off - smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  If the subtrahend is known\n\t\t * nonnegative, then any reg->range we had before is still good.\n\t\t */\n\t\tif (signed_sub_overflows(smin_ptr, smax_val) ||\n\t\t    signed_sub_overflows(smax_ptr, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr - smax_val;\n\t\t\tdst_reg->smax_value = smax_ptr - smin_val;\n\t\t}\n\t\tif (umin_ptr < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value = umin_ptr - umax_val;\n\t\t\tdst_reg->umax_value = umax_ptr - umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tif (smin_val < 0)\n\t\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\tcase BPF_OR:\n\tcase BPF_XOR:\n\t\t/* bitwise ops on pointers are troublesome, prohibit. */\n\t\tverbose(env, \"R%d bitwise operator %s on pointer prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\tdefault:\n\t\t/* other operators (e.g. MUL,LSH) produce non-pointer results */\n\t\tverbose(env, \"R%d pointer arithmetic with %s operator prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!check_reg_sane_offset(env, dst_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t__update_reg_bounds(dst_reg);\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\n\t/* For unprivileged we require that resulting offset must be in bounds\n\t * in order to be able to sanitize access later on.\n\t */\n\tif (!env->bypass_spec_v1) {\n\t\tif (dst_reg->type == PTR_TO_MAP_VALUE &&\n\t\t    check_map_access(env, dst, dst_reg->off, 1, false)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic of map value goes out of range, \"\n\t\t\t\t\"prohibited for !root\\n\", dst);\n\t\t\treturn -EACCES;\n\t\t} else if (dst_reg->type == PTR_TO_STACK &&\n\t\t\t   check_stack_access_for_ptr_arithmetic(\n\t\t\t\t   env, dst, dst_reg, dst_reg->off +\n\t\t\t\t   dst_reg->var_off.value)) {\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int adjust_ptr_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t   struct bpf_insn *insn,\n\t\t\t\t   const struct bpf_reg_state *ptr_reg,\n\t\t\t\t   const struct bpf_reg_state *off_reg)\n{\n\tstruct bpf_verifier_state *vstate = env->cur_state;\n\tstruct bpf_func_state *state = vstate->frame[vstate->curframe];\n\tstruct bpf_reg_state *regs = state->regs, *dst_reg;\n\tbool known = tnum_is_const(off_reg->var_off);\n\ts64 smin_val = off_reg->smin_value, smax_val = off_reg->smax_value,\n\t    smin_ptr = ptr_reg->smin_value, smax_ptr = ptr_reg->smax_value;\n\tu64 umin_val = off_reg->umin_value, umax_val = off_reg->umax_value,\n\t    umin_ptr = ptr_reg->umin_value, umax_ptr = ptr_reg->umax_value;\n\tu32 dst = insn->dst_reg, src = insn->src_reg;\n\tu8 opcode = BPF_OP(insn->code);\n\tint ret;\n\n\tdst_reg = &regs[dst];\n\n\tif ((known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(env, dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops on pointers produce (meaningless) scalars */\n\t\tif (opcode == BPF_SUB && env->allow_ptr_leaks) {\n\t\t\t__mark_reg_unknown(env, dst_reg);\n\t\t\treturn 0;\n\t\t}\n\n\t\tverbose(env,\n\t\t\t\"R%d 32-bit pointer arithmetic prohibited\\n\",\n\t\t\tdst);\n\t\treturn -EACCES;\n\t}\n\n\tswitch (ptr_reg->type) {\n\tcase PTR_TO_MAP_VALUE_OR_NULL:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited, null-check it first\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tcase CONST_PTR_TO_MAP:\n\t\t/* smin_val represents the known value */\n\t\tif (known && smin_val == 0 && opcode == BPF_ADD)\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tcase PTR_TO_MAP_VALUE:\n\t\tif (!env->env->bypass_spec_v1 && !known && (smin_val < 0) != (smax_val < 0)) {\n\t\t\tverbose(env, \"R%d has unknown scalar with mixed signed bounds, pointer arithmetic with it prohibited for !root\\n\",\n\t\t\t\toff_reg == dst_reg ? dst : src);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tfallthrough;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t/* In case of 'scalar += pointer', dst_reg inherits pointer type and id.\n\t * The id may be overwritten later if we create a new variable offset.\n\t */\n\tdst_reg->type = ptr_reg->type;\n\tdst_reg->id = ptr_reg->id;\n\n\tif (!check_reg_sane_offset(env, off_reg, ptr_reg->type) ||\n\t    !check_reg_sane_offset(env, ptr_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t/* pointer types do not carry 32-bit bounds at the moment. */\n\t__mark_reg32_unbounded(dst_reg);\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, dst_reg, smin_val < 0);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"R%d tried to add from different maps, paths, or prohibited types\\n\", dst);\n\t\t\treturn ret;\n\t\t}\n\t\t/* We can take a fixed offset as long as it doesn't overflow\n\t\t * the s32 'off' field\n\t\t */\n\t\tif (known && (ptr_reg->off + smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off + smin_val))) {\n\t\t\t/* pointer += K.  Accumulate it into fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->off = ptr_reg->off + smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  Note that off_reg->off\n\t\t * == 0, since it's a scalar.\n\t\t * dst_reg gets the pointer type and since some positive\n\t\t * integer value was added to the pointer, give it a new 'id'\n\t\t * if it's a PTR_TO_PACKET.\n\t\t * this creates a new 'base' pointer, off_reg (variable) gets\n\t\t * added into the variable offset, and we copy the fixed offset\n\t\t * from ptr_reg.\n\t\t */\n\t\tif (signed_add_overflows(smin_ptr, smin_val) ||\n\t\t    signed_add_overflows(smax_ptr, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr + smin_val;\n\t\t\tdst_reg->smax_value = smax_ptr + smax_val;\n\t\t}\n\t\tif (umin_ptr + umin_val < umin_ptr ||\n\t\t    umax_ptr + umax_val < umax_ptr) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value = umin_ptr + umin_val;\n\t\t\tdst_reg->umax_value = umax_ptr + umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, dst_reg, smin_val < 0);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"R%d tried to sub from different maps, paths, or prohibited types\\n\", dst);\n\t\t\treturn ret;\n\t\t}\n\t\tif (dst_reg == off_reg) {\n\t\t\t/* scalar -= pointer.  Creates an unknown scalar */\n\t\t\tverbose(env, \"R%d tried to subtract pointer from scalar\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* We don't allow subtraction from FP, because (according to\n\t\t * test_verifier.c test \"invalid fp arithmetic\", JITs might not\n\t\t * be able to deal with it.\n\t\t */\n\t\tif (ptr_reg->type == PTR_TO_STACK) {\n\t\t\tverbose(env, \"R%d subtraction from stack pointer prohibited\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (known && (ptr_reg->off - smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off - smin_val))) {\n\t\t\t/* pointer -= K.  Subtract it from fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->id = ptr_reg->id;\n\t\t\tdst_reg->off = ptr_reg->off - smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  If the subtrahend is known\n\t\t * nonnegative, then any reg->range we had before is still good.\n\t\t */\n\t\tif (signed_sub_overflows(smin_ptr, smax_val) ||\n\t\t    signed_sub_overflows(smax_ptr, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr - smax_val;\n\t\t\tdst_reg->smax_value = smax_ptr - smin_val;\n\t\t}\n\t\tif (umin_ptr < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value = umin_ptr - umax_val;\n\t\t\tdst_reg->umax_value = umax_ptr - umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tif (smin_val < 0)\n\t\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\tcase BPF_OR:\n\tcase BPF_XOR:\n\t\t/* bitwise ops on pointers are troublesome, prohibit. */\n\t\tverbose(env, \"R%d bitwise operator %s on pointer prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\tdefault:\n\t\t/* other operators (e.g. MUL,LSH) produce non-pointer results */\n\t\tverbose(env, \"R%d pointer arithmetic with %s operator prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!check_reg_sane_offset(env, dst_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t__update_reg_bounds(dst_reg);\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\n\t/* For unprivileged we require that resulting offset must be in bounds\n\t * in order to be able to sanitize access later on.\n\t */\n\tif (!env->bypass_spec_v1) {\n\t\tif (dst_reg->type == PTR_TO_MAP_VALUE &&\n\t\t    check_map_access(env, dst, dst_reg->off, 1, false)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic of map value goes out of range, \"\n\t\t\t\t\"prohibited for !root\\n\", dst);\n\t\t\treturn -EACCES;\n\t\t} else if (dst_reg->type == PTR_TO_STACK &&\n\t\t\t   check_stack_access_for_ptr_arithmetic(\n\t\t\t\t   env, dst, dst_reg, dst_reg->off +\n\t\t\t\t   dst_reg->var_off.value)) {\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,7 +61,7 @@\n \t\t\tdst, reg_type_str[ptr_reg->type]);\n \t\treturn -EACCES;\n \tcase PTR_TO_MAP_VALUE:\n-\t\tif (!env->allow_ptr_leaks && !known && (smin_val < 0) != (smax_val < 0)) {\n+\t\tif (!env->env->bypass_spec_v1 && !known && (smin_val < 0) != (smax_val < 0)) {\n \t\t\tverbose(env, \"R%d has unknown scalar with mixed signed bounds, pointer arithmetic with it prohibited for !root\\n\",\n \t\t\t\toff_reg == dst_reg ? dst : src);\n \t\t\treturn -EACCES;",
        "function_modified_lines": {
            "added": [
                "\t\tif (!env->env->bypass_spec_v1 && !known && (smin_val < 0) != (smax_val < 0)) {"
            ],
            "deleted": [
                "\t\tif (!env->allow_ptr_leaks && !known && (smin_val < 0) != (smax_val < 0)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.x. kernel/bpf/verifier.c performs undesirable out-of-bounds speculation on pointer arithmetic, leading to side-channel attacks that defeat Spectre mitigations and obtain sensitive information from kernel memory. Specifically, for sequences of pointer arithmetic operations, the pointer modification performed by the first operation is not correctly accounted for when restricting subsequent operations.",
        "id": 2944
    },
    {
        "cve_id": "CVE-2020-9383",
        "code_before_change": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}",
        "code_after_change": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,13 +1,16 @@\n static void set_fdc(int drive)\n {\n+\tunsigned int new_fdc = fdc;\n+\n \tif (drive >= 0 && drive < N_DRIVE) {\n-\t\tfdc = FDC(drive);\n+\t\tnew_fdc = FDC(drive);\n \t\tcurrent_drive = drive;\n \t}\n-\tif (fdc != 1 && fdc != 0) {\n+\tif (new_fdc >= N_FDC) {\n \t\tpr_info(\"bad fdc value\\n\");\n \t\treturn;\n \t}\n+\tfdc = new_fdc;\n \tset_dor(fdc, ~0, 8);\n #if N_FDC > 1\n \tset_dor(1 - fdc, ~8, 0);",
        "function_modified_lines": {
            "added": [
                "\tunsigned int new_fdc = fdc;",
                "",
                "\t\tnew_fdc = FDC(drive);",
                "\tif (new_fdc >= N_FDC) {",
                "\tfdc = new_fdc;"
            ],
            "deleted": [
                "\t\tfdc = FDC(drive);",
                "\tif (fdc != 1 && fdc != 0) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel 3.16 through 5.5.6. set_fdc in drivers/block/floppy.c leads to a wait_til_ready out-of-bounds read because the FDC index is not checked for errors before assigning it, aka CID-2e90ca68b0d2.",
        "id": 2811
    },
    {
        "cve_id": "CVE-2017-18344",
        "code_before_change": "static struct pid *good_sigevent(sigevent_t * event)\n{\n\tstruct task_struct *rtn = current->group_leader;\n\n\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\n\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\n\t\t !same_thread_group(rtn, current) ||\n\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\n\t\treturn NULL;\n\n\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\n\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\n\t\treturn NULL;\n\n\treturn task_pid(rtn);\n}",
        "code_after_change": "static struct pid *good_sigevent(sigevent_t * event)\n{\n\tstruct task_struct *rtn = current->group_leader;\n\n\tswitch (event->sigev_notify) {\n\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:\n\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);\n\t\tif (!rtn || !same_thread_group(rtn, current))\n\t\t\treturn NULL;\n\t\t/* FALLTHRU */\n\tcase SIGEV_SIGNAL:\n\tcase SIGEV_THREAD:\n\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)\n\t\t\treturn NULL;\n\t\t/* FALLTHRU */\n\tcase SIGEV_NONE:\n\t\treturn task_pid(rtn);\n\tdefault:\n\t\treturn NULL;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,15 +2,20 @@\n {\n \tstruct task_struct *rtn = current->group_leader;\n \n-\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\n-\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\n-\t\t !same_thread_group(rtn, current) ||\n-\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\n+\tswitch (event->sigev_notify) {\n+\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:\n+\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);\n+\t\tif (!rtn || !same_thread_group(rtn, current))\n+\t\t\treturn NULL;\n+\t\t/* FALLTHRU */\n+\tcase SIGEV_SIGNAL:\n+\tcase SIGEV_THREAD:\n+\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)\n+\t\t\treturn NULL;\n+\t\t/* FALLTHRU */\n+\tcase SIGEV_NONE:\n+\t\treturn task_pid(rtn);\n+\tdefault:\n \t\treturn NULL;\n-\n-\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\n-\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\n-\t\treturn NULL;\n-\n-\treturn task_pid(rtn);\n+\t}\n }",
        "function_modified_lines": {
            "added": [
                "\tswitch (event->sigev_notify) {",
                "\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:",
                "\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);",
                "\t\tif (!rtn || !same_thread_group(rtn, current))",
                "\t\t\treturn NULL;",
                "\t\t/* FALLTHRU */",
                "\tcase SIGEV_SIGNAL:",
                "\tcase SIGEV_THREAD:",
                "\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)",
                "\t\t\treturn NULL;",
                "\t\t/* FALLTHRU */",
                "\tcase SIGEV_NONE:",
                "\t\treturn task_pid(rtn);",
                "\tdefault:",
                "\t}"
            ],
            "deleted": [
                "\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&",
                "\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||",
                "\t\t !same_thread_group(rtn, current) ||",
                "\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))",
                "",
                "\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&",
                "\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))",
                "\t\treturn NULL;",
                "",
                "\treturn task_pid(rtn);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The timer_create syscall implementation in kernel/time/posix-timers.c in the Linux kernel before 4.14.8 doesn't properly validate the sigevent->sigev_notify field, which leads to out-of-bounds access in the show_timer function (called when /proc/$PID/timers is read). This allows userspace applications to read arbitrary kernel memory (on a kernel built with CONFIG_POSIX_TIMERS and CONFIG_CHECKPOINT_RESTORE).",
        "id": 1430
    },
    {
        "cve_id": "CVE-2018-13099",
        "code_before_change": "int f2fs_convert_inline_page(struct dnode_of_data *dn, struct page *page)\n{\n\tstruct f2fs_io_info fio = {\n\t\t.sbi = F2FS_I_SB(dn->inode),\n\t\t.ino = dn->inode->i_ino,\n\t\t.type = DATA,\n\t\t.op = REQ_OP_WRITE,\n\t\t.op_flags = REQ_SYNC | REQ_PRIO,\n\t\t.page = page,\n\t\t.encrypted_page = NULL,\n\t\t.io_type = FS_DATA_IO,\n\t};\n\tint dirty, err;\n\n\tif (!f2fs_exist_data(dn->inode))\n\t\tgoto clear_out;\n\n\terr = f2fs_reserve_block(dn, 0);\n\tif (err)\n\t\treturn err;\n\n\tf2fs_bug_on(F2FS_P_SB(page), PageWriteback(page));\n\n\tf2fs_do_read_inline_data(page, dn->inode_page);\n\tset_page_dirty(page);\n\n\t/* clear dirty state */\n\tdirty = clear_page_dirty_for_io(page);\n\n\t/* write data page to try to make data consistent */\n\tset_page_writeback(page);\n\tClearPageError(page);\n\tfio.old_blkaddr = dn->data_blkaddr;\n\tset_inode_flag(dn->inode, FI_HOT_DATA);\n\tf2fs_outplace_write_data(dn, &fio);\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\tif (dirty) {\n\t\tinode_dec_dirty_pages(dn->inode);\n\t\tf2fs_remove_dirty_inode(dn->inode);\n\t}\n\n\t/* this converted inline_data should be recovered. */\n\tset_inode_flag(dn->inode, FI_APPEND_WRITE);\n\n\t/* clear inline data and flag after data writeback */\n\tf2fs_truncate_inline_inode(dn->inode, dn->inode_page, 0);\n\tclear_inline_node(dn->inode_page);\nclear_out:\n\tstat_dec_inline_inode(dn->inode);\n\tclear_inode_flag(dn->inode, FI_INLINE_DATA);\n\tf2fs_put_dnode(dn);\n\treturn 0;\n}",
        "code_after_change": "int f2fs_convert_inline_page(struct dnode_of_data *dn, struct page *page)\n{\n\tstruct f2fs_io_info fio = {\n\t\t.sbi = F2FS_I_SB(dn->inode),\n\t\t.ino = dn->inode->i_ino,\n\t\t.type = DATA,\n\t\t.op = REQ_OP_WRITE,\n\t\t.op_flags = REQ_SYNC | REQ_PRIO,\n\t\t.page = page,\n\t\t.encrypted_page = NULL,\n\t\t.io_type = FS_DATA_IO,\n\t};\n\tint dirty, err;\n\n\tif (!f2fs_exist_data(dn->inode))\n\t\tgoto clear_out;\n\n\terr = f2fs_reserve_block(dn, 0);\n\tif (err)\n\t\treturn err;\n\n\tif (unlikely(dn->data_blkaddr != NEW_ADDR)) {\n\t\tf2fs_put_dnode(dn);\n\t\tset_sbi_flag(fio.sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(fio.sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, dn->inode->i_ino, dn->data_blkaddr);\n\t\treturn -EINVAL;\n\t}\n\n\tf2fs_bug_on(F2FS_P_SB(page), PageWriteback(page));\n\n\tf2fs_do_read_inline_data(page, dn->inode_page);\n\tset_page_dirty(page);\n\n\t/* clear dirty state */\n\tdirty = clear_page_dirty_for_io(page);\n\n\t/* write data page to try to make data consistent */\n\tset_page_writeback(page);\n\tClearPageError(page);\n\tfio.old_blkaddr = dn->data_blkaddr;\n\tset_inode_flag(dn->inode, FI_HOT_DATA);\n\tf2fs_outplace_write_data(dn, &fio);\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\tif (dirty) {\n\t\tinode_dec_dirty_pages(dn->inode);\n\t\tf2fs_remove_dirty_inode(dn->inode);\n\t}\n\n\t/* this converted inline_data should be recovered. */\n\tset_inode_flag(dn->inode, FI_APPEND_WRITE);\n\n\t/* clear inline data and flag after data writeback */\n\tf2fs_truncate_inline_inode(dn->inode, dn->inode_page, 0);\n\tclear_inline_node(dn->inode_page);\nclear_out:\n\tstat_dec_inline_inode(dn->inode);\n\tclear_inode_flag(dn->inode, FI_INLINE_DATA);\n\tf2fs_put_dnode(dn);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,6 +18,16 @@\n \terr = f2fs_reserve_block(dn, 0);\n \tif (err)\n \t\treturn err;\n+\n+\tif (unlikely(dn->data_blkaddr != NEW_ADDR)) {\n+\t\tf2fs_put_dnode(dn);\n+\t\tset_sbi_flag(fio.sbi, SBI_NEED_FSCK);\n+\t\tf2fs_msg(fio.sbi->sb, KERN_WARNING,\n+\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n+\t\t\t\"run fsck to fix.\",\n+\t\t\t__func__, dn->inode->i_ino, dn->data_blkaddr);\n+\t\treturn -EINVAL;\n+\t}\n \n \tf2fs_bug_on(F2FS_P_SB(page), PageWriteback(page));\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (unlikely(dn->data_blkaddr != NEW_ADDR)) {",
                "\t\tf2fs_put_dnode(dn);",
                "\t\tset_sbi_flag(fio.sbi, SBI_NEED_FSCK);",
                "\t\tf2fs_msg(fio.sbi->sb, KERN_WARNING,",
                "\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"",
                "\t\t\t\"run fsck to fix.\",",
                "\t\t\t__func__, dn->inode->i_ino, dn->data_blkaddr);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inline.c in the Linux kernel through 4.4. A denial of service (out-of-bounds memory access and BUG) can occur for a modified f2fs filesystem image in which an inline inode contains an invalid reserved blkaddr.",
        "id": 1674
    },
    {
        "cve_id": "CVE-2019-15090",
        "code_before_change": "void\nqedi_dbg_err(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t     const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\tchar nfunc[32];\n\n\tmemset(nfunc, 0, sizeof(nfunc));\n\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_err(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t       nfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n\n\tva_end(va);\n}",
        "code_after_change": "void\nqedi_dbg_err(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t     const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_err(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t       func, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n\n\tva_end(va);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,6 @@\n {\n \tva_list va;\n \tstruct va_format vaf;\n-\tchar nfunc[32];\n-\n-\tmemset(nfunc, 0, sizeof(nfunc));\n-\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n \n \tva_start(va, fmt);\n \n@@ -16,9 +12,9 @@\n \n \tif (likely(qedi) && likely(qedi->pdev))\n \t\tpr_err(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n-\t\t       nfunc, line, qedi->host_no, &vaf);\n+\t\t       func, line, qedi->host_no, &vaf);\n \telse\n-\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n+\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n \n \tva_end(va);\n }",
        "function_modified_lines": {
            "added": [
                "\t\t       func, line, qedi->host_no, &vaf);",
                "\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);"
            ],
            "deleted": [
                "\tchar nfunc[32];",
                "",
                "\tmemset(nfunc, 0, sizeof(nfunc));",
                "\tmemcpy(nfunc, func, sizeof(nfunc) - 1);",
                "\t\t       nfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_err(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in drivers/scsi/qedi/qedi_dbg.c in the Linux kernel before 5.1.12. In the qedi_dbg_* family of functions, there is an out-of-bounds read.",
        "id": 1985
    },
    {
        "cve_id": "CVE-2023-6121",
        "code_before_change": "static void nvmet_execute_io_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl;\n\tu16 qid = le16_to_cpu(c->qid);\n\tu16 status = 0;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tctrl = nvmet_ctrl_find_get(d->subsysnqn, d->hostnqn,\n\t\t\t\t   le16_to_cpu(d->cntlid), req);\n\tif (!ctrl) {\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(qid > ctrl->subsys->max_qid)) {\n\t\tpr_warn(\"invalid queue id (%d)\\n\", qid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_SQE(qid);\n\t\tgoto out_ctrl_put;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status)\n\t\tgoto out_ctrl_put;\n\n\tpr_debug(\"adding queue %d to ctrl %d.\\n\", qid, ctrl->cntlid);\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n\treturn;\n\nout_ctrl_put:\n\tnvmet_ctrl_put(ctrl);\n\tgoto out;\n}",
        "code_after_change": "static void nvmet_execute_io_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl;\n\tu16 qid = le16_to_cpu(c->qid);\n\tu16 status = 0;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\tctrl = nvmet_ctrl_find_get(d->subsysnqn, d->hostnqn,\n\t\t\t\t   le16_to_cpu(d->cntlid), req);\n\tif (!ctrl) {\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(qid > ctrl->subsys->max_qid)) {\n\t\tpr_warn(\"invalid queue id (%d)\\n\", qid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_SQE(qid);\n\t\tgoto out_ctrl_put;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status)\n\t\tgoto out_ctrl_put;\n\n\tpr_debug(\"adding queue %d to ctrl %d.\\n\", qid, ctrl->cntlid);\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n\treturn;\n\nout_ctrl_put:\n\tnvmet_ctrl_put(ctrl);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,6 +29,8 @@\n \t\tgoto out;\n \t}\n \n+\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n+\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n \tctrl = nvmet_ctrl_find_get(d->subsysnqn, d->hostnqn,\n \t\t\t\t   le16_to_cpu(d->cntlid), req);\n \tif (!ctrl) {",
        "function_modified_lines": {
            "added": [
                "\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';",
                "\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in the NVMe-oF/TCP subsystem in the Linux kernel. This issue may allow a remote attacker to send a crafted TCP packet, triggering a heap-based buffer overflow that results in kmalloc data being printed and potentially leaked to the kernel ring buffer (dmesg).",
        "id": 4299
    },
    {
        "cve_id": "CVE-2021-0941",
        "code_before_change": "static inline int __bpf_skb_change_tail(struct sk_buff *skb, u32 new_len,\n\t\t\t\t\tu64 flags)\n{\n\tu32 max_len = __bpf_skb_max_len(skb);\n\tu32 min_len = __bpf_skb_min_len(skb);\n\tint ret;\n\n\tif (unlikely(flags || new_len > max_len || new_len < min_len))\n\t\treturn -EINVAL;\n\tif (skb->encapsulation)\n\t\treturn -ENOTSUPP;\n\n\t/* The basic idea of this helper is that it's performing the\n\t * needed work to either grow or trim an skb, and eBPF program\n\t * rewrites the rest via helpers like bpf_skb_store_bytes(),\n\t * bpf_lX_csum_replace() and others rather than passing a raw\n\t * buffer here. This one is a slow path helper and intended\n\t * for replies with control messages.\n\t *\n\t * Like in bpf_skb_change_proto(), we want to keep this rather\n\t * minimal and without protocol specifics so that we are able\n\t * to separate concerns as in bpf_skb_store_bytes() should only\n\t * be the one responsible for writing buffers.\n\t *\n\t * It's really expected to be a slow path operation here for\n\t * control message replies, so we're implicitly linearizing,\n\t * uncloning and drop offloads from the skb by this.\n\t */\n\tret = __bpf_try_make_writable(skb, skb->len);\n\tif (!ret) {\n\t\tif (new_len > skb->len)\n\t\t\tret = bpf_skb_grow_rcsum(skb, new_len);\n\t\telse if (new_len < skb->len)\n\t\t\tret = bpf_skb_trim_rcsum(skb, new_len);\n\t\tif (!ret && skb_is_gso(skb))\n\t\t\tskb_gso_reset(skb);\n\t}\n\treturn ret;\n}",
        "code_after_change": "static inline int __bpf_skb_change_tail(struct sk_buff *skb, u32 new_len,\n\t\t\t\t\tu64 flags)\n{\n\tu32 max_len = BPF_SKB_MAX_LEN;\n\tu32 min_len = __bpf_skb_min_len(skb);\n\tint ret;\n\n\tif (unlikely(flags || new_len > max_len || new_len < min_len))\n\t\treturn -EINVAL;\n\tif (skb->encapsulation)\n\t\treturn -ENOTSUPP;\n\n\t/* The basic idea of this helper is that it's performing the\n\t * needed work to either grow or trim an skb, and eBPF program\n\t * rewrites the rest via helpers like bpf_skb_store_bytes(),\n\t * bpf_lX_csum_replace() and others rather than passing a raw\n\t * buffer here. This one is a slow path helper and intended\n\t * for replies with control messages.\n\t *\n\t * Like in bpf_skb_change_proto(), we want to keep this rather\n\t * minimal and without protocol specifics so that we are able\n\t * to separate concerns as in bpf_skb_store_bytes() should only\n\t * be the one responsible for writing buffers.\n\t *\n\t * It's really expected to be a slow path operation here for\n\t * control message replies, so we're implicitly linearizing,\n\t * uncloning and drop offloads from the skb by this.\n\t */\n\tret = __bpf_try_make_writable(skb, skb->len);\n\tif (!ret) {\n\t\tif (new_len > skb->len)\n\t\t\tret = bpf_skb_grow_rcsum(skb, new_len);\n\t\telse if (new_len < skb->len)\n\t\t\tret = bpf_skb_trim_rcsum(skb, new_len);\n\t\tif (!ret && skb_is_gso(skb))\n\t\t\tskb_gso_reset(skb);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static inline int __bpf_skb_change_tail(struct sk_buff *skb, u32 new_len,\n \t\t\t\t\tu64 flags)\n {\n-\tu32 max_len = __bpf_skb_max_len(skb);\n+\tu32 max_len = BPF_SKB_MAX_LEN;\n \tu32 min_len = __bpf_skb_min_len(skb);\n \tint ret;\n ",
        "function_modified_lines": {
            "added": [
                "\tu32 max_len = BPF_SKB_MAX_LEN;"
            ],
            "deleted": [
                "\tu32 max_len = __bpf_skb_max_len(skb);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-416"
        ],
        "cve_description": "In bpf_skb_change_head of filter.c, there is a possible out of bounds read due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-154177719References: Upstream kernel",
        "id": 2840
    },
    {
        "cve_id": "CVE-2014-3145",
        "code_before_change": "static u64 __skb_get_nlattr_nest(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = (struct nlattr *) &skb->data[A];\n\tif (nla->nla_len > A - skb->len)\n\t\treturn 0;\n\n\tnla = nla_find_nested(nla, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "code_after_change": "static u64 __skb_get_nlattr_nest(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (skb->len < sizeof(struct nlattr))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = (struct nlattr *) &skb->data[A];\n\tif (nla->nla_len > skb->len - A)\n\t\treturn 0;\n\n\tnla = nla_find_nested(nla, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,11 +6,14 @@\n \tif (skb_is_nonlinear(skb))\n \t\treturn 0;\n \n+\tif (skb->len < sizeof(struct nlattr))\n+\t\treturn 0;\n+\n \tif (A > skb->len - sizeof(struct nlattr))\n \t\treturn 0;\n \n \tnla = (struct nlattr *) &skb->data[A];\n-\tif (nla->nla_len > A - skb->len)\n+\tif (nla->nla_len > skb->len - A)\n \t\treturn 0;\n \n \tnla = nla_find_nested(nla, X);",
        "function_modified_lines": {
            "added": [
                "\tif (skb->len < sizeof(struct nlattr))",
                "\t\treturn 0;",
                "",
                "\tif (nla->nla_len > skb->len - A)"
            ],
            "deleted": [
                "\tif (nla->nla_len > A - skb->len)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The BPF_S_ANC_NLATTR_NEST extension implementation in the sk_run_filter function in net/core/filter.c in the Linux kernel through 3.14.3 uses the reverse order in a certain subtraction, which allows local users to cause a denial of service (over-read and system crash) via crafted BPF instructions.  NOTE: the affected code was moved to the __skb_get_nlattr_nest function before the vulnerability was announced.",
        "id": 505
    },
    {
        "cve_id": "CVE-2018-20854",
        "code_before_change": "static struct phy *serdes_simple_xlate(struct device *dev,\n\t\t\t\t       struct of_phandle_args *args)\n{\n\tstruct serdes_ctrl *ctrl = dev_get_drvdata(dev);\n\tunsigned int port, idx, i;\n\n\tif (args->args_count != 2)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tport = args->args[0];\n\tidx = args->args[1];\n\n\tfor (i = 0; i <= SERDES_MAX; i++) {\n\t\tstruct serdes_macro *macro = phy_get_drvdata(ctrl->phys[i]);\n\n\t\tif (idx != macro->idx)\n\t\t\tcontinue;\n\n\t\t/* SERDES6G(0) is the only SerDes capable of QSGMII */\n\t\tif (idx != SERDES6G(0) && macro->port >= 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\tmacro->port = port;\n\t\treturn ctrl->phys[i];\n\t}\n\n\treturn ERR_PTR(-ENODEV);\n}",
        "code_after_change": "static struct phy *serdes_simple_xlate(struct device *dev,\n\t\t\t\t       struct of_phandle_args *args)\n{\n\tstruct serdes_ctrl *ctrl = dev_get_drvdata(dev);\n\tunsigned int port, idx, i;\n\n\tif (args->args_count != 2)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tport = args->args[0];\n\tidx = args->args[1];\n\n\tfor (i = 0; i < SERDES_MAX; i++) {\n\t\tstruct serdes_macro *macro = phy_get_drvdata(ctrl->phys[i]);\n\n\t\tif (idx != macro->idx)\n\t\t\tcontinue;\n\n\t\t/* SERDES6G(0) is the only SerDes capable of QSGMII */\n\t\tif (idx != SERDES6G(0) && macro->port >= 0)\n\t\t\treturn ERR_PTR(-EBUSY);\n\n\t\tmacro->port = port;\n\t\treturn ctrl->phys[i];\n\t}\n\n\treturn ERR_PTR(-ENODEV);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \tport = args->args[0];\n \tidx = args->args[1];\n \n-\tfor (i = 0; i <= SERDES_MAX; i++) {\n+\tfor (i = 0; i < SERDES_MAX; i++) {\n \t\tstruct serdes_macro *macro = phy_get_drvdata(ctrl->phys[i]);\n \n \t\tif (idx != macro->idx)",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < SERDES_MAX; i++) {"
            ],
            "deleted": [
                "\tfor (i = 0; i <= SERDES_MAX; i++) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 4.20. drivers/phy/mscc/phy-ocelot-serdes.c has an off-by-one error with a resultant ctrl->phys out-of-bounds read.",
        "id": 1785
    },
    {
        "cve_id": "CVE-2017-7277",
        "code_before_change": "void skb_complete_tx_timestamp(struct sk_buff *skb,\n\t\t\t       struct skb_shared_hwtstamps *hwtstamps)\n{\n\tstruct sock *sk = skb->sk;\n\n\tif (!skb_may_tx_timestamp(sk, false))\n\t\treturn;\n\n\t/* Take a reference to prevent skb_orphan() from freeing the socket,\n\t * but only if the socket refcount is not zero.\n\t */\n\tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);\n\t\tsock_put(sk);\n\t}\n}",
        "code_after_change": "void skb_complete_tx_timestamp(struct sk_buff *skb,\n\t\t\t       struct skb_shared_hwtstamps *hwtstamps)\n{\n\tstruct sock *sk = skb->sk;\n\n\tif (!skb_may_tx_timestamp(sk, false))\n\t\treturn;\n\n\t/* Take a reference to prevent skb_orphan() from freeing the socket,\n\t * but only if the socket refcount is not zero.\n\t */\n\tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);\n\t\tsock_put(sk);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \t */\n \tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n \t\t*skb_hwtstamps(skb) = *hwtstamps;\n-\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);\n+\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);\n \t\tsock_put(sk);\n \t}\n }",
        "function_modified_lines": {
            "added": [
                "\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);"
            ],
            "deleted": [
                "\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The TCP stack in the Linux kernel through 4.10.6 mishandles the SCM_TIMESTAMPING_OPT_STATS feature, which allows local users to obtain sensitive information from the kernel's internal socket data structures or cause a denial of service (out-of-bounds read) via crafted system calls, related to net/core/skbuff.c and net/socket.c.",
        "id": 1493
    },
    {
        "cve_id": "CVE-2023-34256",
        "code_before_change": "static __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t__u16 crc = 0;\n\t__le32 le_group = cpu_to_le32(block_group);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sbi->s_sb)) {\n\t\t/* Use new metadata_csum algorithm */\n\t\t__u32 csum32;\n\t\t__u16 dummy_csum = 0;\n\n\t\tcsum32 = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&le_group,\n\t\t\t\t     sizeof(le_group));\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp, offset);\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)&dummy_csum,\n\t\t\t\t     sizeof(dummy_csum));\n\t\toffset += sizeof(dummy_csum);\n\t\tif (offset < sbi->s_desc_size)\n\t\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp + offset,\n\t\t\t\t\t     sbi->s_desc_size - offset);\n\n\t\tcrc = csum32 & 0xFFFF;\n\t\tgoto out;\n\t}\n\n\t/* old crc16 code */\n\tif (!ext4_has_feature_gdt_csum(sb))\n\t\treturn 0;\n\n\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t/* for checksum of struct ext4_group_desc do the rest...*/\n\tif (ext4_has_feature_64bit(sb) &&\n\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n\t\t\t\toffset);\n\nout:\n\treturn cpu_to_le16(crc);\n}",
        "code_after_change": "static __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t__u16 crc = 0;\n\t__le32 le_group = cpu_to_le32(block_group);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sbi->s_sb)) {\n\t\t/* Use new metadata_csum algorithm */\n\t\t__u32 csum32;\n\t\t__u16 dummy_csum = 0;\n\n\t\tcsum32 = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&le_group,\n\t\t\t\t     sizeof(le_group));\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp, offset);\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)&dummy_csum,\n\t\t\t\t     sizeof(dummy_csum));\n\t\toffset += sizeof(dummy_csum);\n\t\tif (offset < sbi->s_desc_size)\n\t\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp + offset,\n\t\t\t\t\t     sbi->s_desc_size - offset);\n\n\t\tcrc = csum32 & 0xFFFF;\n\t\tgoto out;\n\t}\n\n\t/* old crc16 code */\n\tif (!ext4_has_feature_gdt_csum(sb))\n\t\treturn 0;\n\n\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t/* for checksum of struct ext4_group_desc do the rest...*/\n\tif (ext4_has_feature_64bit(sb) && offset < sbi->s_desc_size)\n\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t    sbi->s_desc_size - offset);\n\nout:\n\treturn cpu_to_le16(crc);\n}",
        "patch": "--- code before\n+++ code after\n@@ -34,11 +34,9 @@\n \tcrc = crc16(crc, (__u8 *)gdp, offset);\n \toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n \t/* for checksum of struct ext4_group_desc do the rest...*/\n-\tif (ext4_has_feature_64bit(sb) &&\n-\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n+\tif (ext4_has_feature_64bit(sb) && offset < sbi->s_desc_size)\n \t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n-\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n-\t\t\t\toffset);\n+\t\t\t    sbi->s_desc_size - offset);\n \n out:\n \treturn cpu_to_le16(crc);",
        "function_modified_lines": {
            "added": [
                "\tif (ext4_has_feature_64bit(sb) && offset < sbi->s_desc_size)",
                "\t\t\t    sbi->s_desc_size - offset);"
            ],
            "deleted": [
                "\tif (ext4_has_feature_64bit(sb) &&",
                "\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))",
                "\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -",
                "\t\t\t\toffset);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.3. There is an out-of-bounds read in crc16 in lib/crc16.c when called from fs/ext4/super.c because ext4_group_desc_csum does not properly check an offset. NOTE: this is disputed by third parties because the kernel is not intended to defend against attackers with the stated \"When modifying the block device while it is mounted by the filesystem\" access.",
        "id": 4097
    },
    {
        "cve_id": "CVE-2019-3459",
        "code_before_change": "static void l2cap_conf_rfc_get(struct l2cap_chan *chan, void *rsp, int len)\n{\n\tint type, olen;\n\tunsigned long val;\n\t/* Use sane default values in case a misbehaving remote device\n\t * did not send an RFC or extended window size option.\n\t */\n\tu16 txwin_ext = chan->ack_win;\n\tstruct l2cap_conf_rfc rfc = {\n\t\t.mode = chan->mode,\n\t\t.retrans_timeout = cpu_to_le16(L2CAP_DEFAULT_RETRANS_TO),\n\t\t.monitor_timeout = cpu_to_le16(L2CAP_DEFAULT_MONITOR_TO),\n\t\t.max_pdu_size = cpu_to_le16(chan->imtu),\n\t\t.txwin_size = min_t(u16, chan->ack_win, L2CAP_DEFAULT_TX_WINDOW),\n\t};\n\n\tBT_DBG(\"chan %p, rsp %p, len %d\", chan, rsp, len);\n\n\tif ((chan->mode != L2CAP_MODE_ERTM) && (chan->mode != L2CAP_MODE_STREAMING))\n\t\treturn;\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *)val, olen);\n\t\t\tbreak;\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\ttxwin_ext = val;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tswitch (rfc.mode) {\n\tcase L2CAP_MODE_ERTM:\n\t\tchan->retrans_timeout = le16_to_cpu(rfc.retrans_timeout);\n\t\tchan->monitor_timeout = le16_to_cpu(rfc.monitor_timeout);\n\t\tchan->mps = le16_to_cpu(rfc.max_pdu_size);\n\t\tif (test_bit(FLAG_EXT_CTRL, &chan->flags))\n\t\t\tchan->ack_win = min_t(u16, chan->ack_win, txwin_ext);\n\t\telse\n\t\t\tchan->ack_win = min_t(u16, chan->ack_win,\n\t\t\t\t\t      rfc.txwin_size);\n\t\tbreak;\n\tcase L2CAP_MODE_STREAMING:\n\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t}\n}",
        "code_after_change": "static void l2cap_conf_rfc_get(struct l2cap_chan *chan, void *rsp, int len)\n{\n\tint type, olen;\n\tunsigned long val;\n\t/* Use sane default values in case a misbehaving remote device\n\t * did not send an RFC or extended window size option.\n\t */\n\tu16 txwin_ext = chan->ack_win;\n\tstruct l2cap_conf_rfc rfc = {\n\t\t.mode = chan->mode,\n\t\t.retrans_timeout = cpu_to_le16(L2CAP_DEFAULT_RETRANS_TO),\n\t\t.monitor_timeout = cpu_to_le16(L2CAP_DEFAULT_MONITOR_TO),\n\t\t.max_pdu_size = cpu_to_le16(chan->imtu),\n\t\t.txwin_size = min_t(u16, chan->ack_win, L2CAP_DEFAULT_TX_WINDOW),\n\t};\n\n\tBT_DBG(\"chan %p, rsp %p, len %d\", chan, rsp, len);\n\n\tif ((chan->mode != L2CAP_MODE_ERTM) && (chan->mode != L2CAP_MODE_STREAMING))\n\t\treturn;\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n\t\tif (len < 0)\n\t\t\tbreak;\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *)val, olen);\n\t\t\tbreak;\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\ttxwin_ext = val;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tswitch (rfc.mode) {\n\tcase L2CAP_MODE_ERTM:\n\t\tchan->retrans_timeout = le16_to_cpu(rfc.retrans_timeout);\n\t\tchan->monitor_timeout = le16_to_cpu(rfc.monitor_timeout);\n\t\tchan->mps = le16_to_cpu(rfc.max_pdu_size);\n\t\tif (test_bit(FLAG_EXT_CTRL, &chan->flags))\n\t\t\tchan->ack_win = min_t(u16, chan->ack_win, txwin_ext);\n\t\telse\n\t\t\tchan->ack_win = min_t(u16, chan->ack_win,\n\t\t\t\t\t      rfc.txwin_size);\n\t\tbreak;\n\tcase L2CAP_MODE_STREAMING:\n\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,8 @@\n \n \twhile (len >= L2CAP_CONF_OPT_SIZE) {\n \t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n+\t\tif (len < 0)\n+\t\t\tbreak;\n \n \t\tswitch (type) {\n \t\tcase L2CAP_CONF_RFC:",
        "function_modified_lines": {
            "added": [
                "\t\tif (len < 0)",
                "\t\t\tbreak;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A heap address information leak while using L2CAP_GET_CONF_OPT was discovered in the Linux kernel before 5.1-rc1.",
        "id": 2308
    },
    {
        "cve_id": "CVE-2020-28097",
        "code_before_change": "static int vgacon_switch(struct vc_data *c)\n{\n\tint x = c->vc_cols * VGA_FONTWIDTH;\n\tint y = c->vc_rows * c->vc_font.height;\n\tint rows = screen_info.orig_video_lines * vga_default_font_height/\n\t\tc->vc_font.height;\n\t/*\n\t * We need to save screen size here as it's the only way\n\t * we can spot the screen has been resized and we need to\n\t * set size of freshly allocated screens ourselves.\n\t */\n\tvga_video_num_columns = c->vc_cols;\n\tvga_video_num_lines = c->vc_rows;\n\n\t/* We can only copy out the size of the video buffer here,\n\t * otherwise we get into VGA BIOS */\n\n\tif (!vga_is_gfx) {\n\t\tscr_memcpyw((u16 *) c->vc_origin, (u16 *) c->vc_screenbuf,\n\t\t\t    c->vc_screenbuf_size > vga_vram_size ?\n\t\t\t\tvga_vram_size : c->vc_screenbuf_size);\n\n\t\tif ((vgacon_xres != x || vgacon_yres != y) &&\n\t\t    (!(vga_video_num_columns % 2) &&\n\t\t     vga_video_num_columns <= screen_info.orig_video_cols &&\n\t\t     vga_video_num_lines <= rows))\n\t\t\tvgacon_doresize(c, c->vc_cols, c->vc_rows);\n\t}\n\n\tvgacon_scrollback_switch(c->vc_num);\n\treturn 0;\t\t/* Redrawing not needed */\n}",
        "code_after_change": "static int vgacon_switch(struct vc_data *c)\n{\n\tint x = c->vc_cols * VGA_FONTWIDTH;\n\tint y = c->vc_rows * c->vc_font.height;\n\tint rows = screen_info.orig_video_lines * vga_default_font_height/\n\t\tc->vc_font.height;\n\t/*\n\t * We need to save screen size here as it's the only way\n\t * we can spot the screen has been resized and we need to\n\t * set size of freshly allocated screens ourselves.\n\t */\n\tvga_video_num_columns = c->vc_cols;\n\tvga_video_num_lines = c->vc_rows;\n\n\t/* We can only copy out the size of the video buffer here,\n\t * otherwise we get into VGA BIOS */\n\n\tif (!vga_is_gfx) {\n\t\tscr_memcpyw((u16 *) c->vc_origin, (u16 *) c->vc_screenbuf,\n\t\t\t    c->vc_screenbuf_size > vga_vram_size ?\n\t\t\t\tvga_vram_size : c->vc_screenbuf_size);\n\n\t\tif ((vgacon_xres != x || vgacon_yres != y) &&\n\t\t    (!(vga_video_num_columns % 2) &&\n\t\t     vga_video_num_columns <= screen_info.orig_video_cols &&\n\t\t     vga_video_num_lines <= rows))\n\t\t\tvgacon_doresize(c, c->vc_cols, c->vc_rows);\n\t}\n\n\treturn 0;\t\t/* Redrawing not needed */\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,6 +27,5 @@\n \t\t\tvgacon_doresize(c, c->vc_cols, c->vc_rows);\n \t}\n \n-\tvgacon_scrollback_switch(c->vc_num);\n \treturn 0;\t\t/* Redrawing not needed */\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tvgacon_scrollback_switch(c->vc_num);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The vgacon subsystem in the Linux kernel before 5.8.10 mishandles software scrollback. There is a vgacon_scrolldelta out-of-bounds read, aka CID-973c096f6a85.",
        "id": 2654
    },
    {
        "cve_id": "CVE-2018-19985",
        "code_before_change": "static int hso_get_config_data(struct usb_interface *interface)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\tu8 *config_data = kmalloc(17, GFP_KERNEL);\n\tu32 if_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\ts32 result;\n\n\tif (!config_data)\n\t\treturn -ENOMEM;\n\tif (usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t    0x86, 0xC0, 0, 0, config_data, 17,\n\t\t\t    USB_CTRL_SET_TIMEOUT) != 0x11) {\n\t\tkfree(config_data);\n\t\treturn -EIO;\n\t}\n\n\tswitch (config_data[if_num]) {\n\tcase 0x0:\n\t\tresult = 0;\n\t\tbreak;\n\tcase 0x1:\n\t\tresult = HSO_PORT_DIAG;\n\t\tbreak;\n\tcase 0x2:\n\t\tresult = HSO_PORT_GPS;\n\t\tbreak;\n\tcase 0x3:\n\t\tresult = HSO_PORT_GPS_CONTROL;\n\t\tbreak;\n\tcase 0x4:\n\t\tresult = HSO_PORT_APP;\n\t\tbreak;\n\tcase 0x5:\n\t\tresult = HSO_PORT_APP2;\n\t\tbreak;\n\tcase 0x6:\n\t\tresult = HSO_PORT_CONTROL;\n\t\tbreak;\n\tcase 0x7:\n\t\tresult = HSO_PORT_NETWORK;\n\t\tbreak;\n\tcase 0x8:\n\t\tresult = HSO_PORT_MODEM;\n\t\tbreak;\n\tcase 0x9:\n\t\tresult = HSO_PORT_MSD;\n\t\tbreak;\n\tcase 0xa:\n\t\tresult = HSO_PORT_PCSC;\n\t\tbreak;\n\tcase 0xb:\n\t\tresult = HSO_PORT_VOICE;\n\t\tbreak;\n\tdefault:\n\t\tresult = 0;\n\t}\n\n\tif (result)\n\t\tresult |= HSO_INTF_BULK;\n\n\tif (config_data[16] & 0x1)\n\t\tresult |= HSO_INFO_CRC_BUG;\n\n\tkfree(config_data);\n\treturn result;\n}",
        "code_after_change": "static int hso_get_config_data(struct usb_interface *interface)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\tu8 *config_data = kmalloc(17, GFP_KERNEL);\n\tu32 if_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\ts32 result;\n\n\tif (!config_data)\n\t\treturn -ENOMEM;\n\tif (usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t    0x86, 0xC0, 0, 0, config_data, 17,\n\t\t\t    USB_CTRL_SET_TIMEOUT) != 0x11) {\n\t\tkfree(config_data);\n\t\treturn -EIO;\n\t}\n\n\t/* check if we have a valid interface */\n\tif (if_num > 16) {\n\t\tkfree(config_data);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (config_data[if_num]) {\n\tcase 0x0:\n\t\tresult = 0;\n\t\tbreak;\n\tcase 0x1:\n\t\tresult = HSO_PORT_DIAG;\n\t\tbreak;\n\tcase 0x2:\n\t\tresult = HSO_PORT_GPS;\n\t\tbreak;\n\tcase 0x3:\n\t\tresult = HSO_PORT_GPS_CONTROL;\n\t\tbreak;\n\tcase 0x4:\n\t\tresult = HSO_PORT_APP;\n\t\tbreak;\n\tcase 0x5:\n\t\tresult = HSO_PORT_APP2;\n\t\tbreak;\n\tcase 0x6:\n\t\tresult = HSO_PORT_CONTROL;\n\t\tbreak;\n\tcase 0x7:\n\t\tresult = HSO_PORT_NETWORK;\n\t\tbreak;\n\tcase 0x8:\n\t\tresult = HSO_PORT_MODEM;\n\t\tbreak;\n\tcase 0x9:\n\t\tresult = HSO_PORT_MSD;\n\t\tbreak;\n\tcase 0xa:\n\t\tresult = HSO_PORT_PCSC;\n\t\tbreak;\n\tcase 0xb:\n\t\tresult = HSO_PORT_VOICE;\n\t\tbreak;\n\tdefault:\n\t\tresult = 0;\n\t}\n\n\tif (result)\n\t\tresult |= HSO_INTF_BULK;\n\n\tif (config_data[16] & 0x1)\n\t\tresult |= HSO_INFO_CRC_BUG;\n\n\tkfree(config_data);\n\treturn result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,6 +12,12 @@\n \t\t\t    USB_CTRL_SET_TIMEOUT) != 0x11) {\n \t\tkfree(config_data);\n \t\treturn -EIO;\n+\t}\n+\n+\t/* check if we have a valid interface */\n+\tif (if_num > 16) {\n+\t\tkfree(config_data);\n+\t\treturn -EINVAL;\n \t}\n \n \tswitch (config_data[if_num]) {",
        "function_modified_lines": {
            "added": [
                "\t}",
                "",
                "\t/* check if we have a valid interface */",
                "\tif (if_num > 16) {",
                "\t\tkfree(config_data);",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The function hso_get_config_data in drivers/net/usb/hso.c in the Linux kernel through 4.19.8 reads if_num from the USB device (as a u8) and uses it to index a small array, resulting in an object out-of-bounds (OOB) read that potentially allows arbitrary read in the kernel address space.",
        "id": 1753
    },
    {
        "cve_id": "CVE-2020-14314",
        "code_before_change": "static struct ext4_dir_entry_2 *do_split(handle_t *handle, struct inode *dir,\n\t\t\tstruct buffer_head **bh,struct dx_frame *frame,\n\t\t\tstruct dx_hash_info *hinfo)\n{\n\tunsigned blocksize = dir->i_sb->s_blocksize;\n\tunsigned count, continued;\n\tstruct buffer_head *bh2;\n\text4_lblk_t newblock;\n\tu32 hash2;\n\tstruct dx_map_entry *map;\n\tchar *data1 = (*bh)->b_data, *data2;\n\tunsigned split, move, size;\n\tstruct ext4_dir_entry_2 *de = NULL, *de2;\n\tint\tcsum_size = 0;\n\tint\terr = 0, i;\n\n\tif (ext4_has_metadata_csum(dir->i_sb))\n\t\tcsum_size = sizeof(struct ext4_dir_entry_tail);\n\n\tbh2 = ext4_append(handle, dir, &newblock);\n\tif (IS_ERR(bh2)) {\n\t\tbrelse(*bh);\n\t\t*bh = NULL;\n\t\treturn (struct ext4_dir_entry_2 *) bh2;\n\t}\n\n\tBUFFER_TRACE(*bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, *bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tBUFFER_TRACE(frame->bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tdata2 = bh2->b_data;\n\n\t/* create map in the end of data2 block */\n\tmap = (struct dx_map_entry *) (data2 + blocksize);\n\tcount = dx_make_map(dir, (struct ext4_dir_entry_2 *) data1,\n\t\t\t     blocksize, hinfo, map);\n\tmap -= count;\n\tdx_sort_map(map, count);\n\t/* Split the existing block in the middle, size-wise */\n\tsize = 0;\n\tmove = 0;\n\tfor (i = count-1; i >= 0; i--) {\n\t\t/* is more than half of this entry in 2nd half of the block? */\n\t\tif (size + map[i].size/2 > blocksize/2)\n\t\t\tbreak;\n\t\tsize += map[i].size;\n\t\tmove++;\n\t}\n\t/* map index at which we will split */\n\tsplit = count - move;\n\thash2 = map[split].hash;\n\tcontinued = hash2 == map[split - 1].hash;\n\tdxtrace(printk(KERN_INFO \"Split block %lu at %x, %i/%i\\n\",\n\t\t\t(unsigned long)dx_get_block(frame->at),\n\t\t\t\t\thash2, split, count-split));\n\n\t/* Fancy dance to stay within two buffers */\n\tde2 = dx_move_dirents(data1, data2, map + split, count - split,\n\t\t\t      blocksize);\n\tde = dx_pack_dirents(data1, blocksize);\n\tde->rec_len = ext4_rec_len_to_disk(data1 + (blocksize - csum_size) -\n\t\t\t\t\t   (char *) de,\n\t\t\t\t\t   blocksize);\n\tde2->rec_len = ext4_rec_len_to_disk(data2 + (blocksize - csum_size) -\n\t\t\t\t\t    (char *) de2,\n\t\t\t\t\t    blocksize);\n\tif (csum_size) {\n\t\text4_initialize_dirent_tail(*bh, blocksize);\n\t\text4_initialize_dirent_tail(bh2, blocksize);\n\t}\n\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data1,\n\t\t\tblocksize, 1));\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data2,\n\t\t\tblocksize, 1));\n\n\t/* Which block gets the new entry? */\n\tif (hinfo->hash >= hash2) {\n\t\tswap(*bh, bh2);\n\t\tde = de2;\n\t}\n\tdx_insert_block(frame, hash2 + continued, newblock);\n\terr = ext4_handle_dirty_dirblock(handle, dir, bh2);\n\tif (err)\n\t\tgoto journal_error;\n\terr = ext4_handle_dirty_dx_node(handle, dir, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\tbrelse(bh2);\n\tdxtrace(dx_show_index(\"frame\", frame->entries));\n\treturn de;\n\njournal_error:\n\tbrelse(*bh);\n\tbrelse(bh2);\n\t*bh = NULL;\n\text4_std_error(dir->i_sb, err);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "static struct ext4_dir_entry_2 *do_split(handle_t *handle, struct inode *dir,\n\t\t\tstruct buffer_head **bh,struct dx_frame *frame,\n\t\t\tstruct dx_hash_info *hinfo)\n{\n\tunsigned blocksize = dir->i_sb->s_blocksize;\n\tunsigned count, continued;\n\tstruct buffer_head *bh2;\n\text4_lblk_t newblock;\n\tu32 hash2;\n\tstruct dx_map_entry *map;\n\tchar *data1 = (*bh)->b_data, *data2;\n\tunsigned split, move, size;\n\tstruct ext4_dir_entry_2 *de = NULL, *de2;\n\tint\tcsum_size = 0;\n\tint\terr = 0, i;\n\n\tif (ext4_has_metadata_csum(dir->i_sb))\n\t\tcsum_size = sizeof(struct ext4_dir_entry_tail);\n\n\tbh2 = ext4_append(handle, dir, &newblock);\n\tif (IS_ERR(bh2)) {\n\t\tbrelse(*bh);\n\t\t*bh = NULL;\n\t\treturn (struct ext4_dir_entry_2 *) bh2;\n\t}\n\n\tBUFFER_TRACE(*bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, *bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tBUFFER_TRACE(frame->bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tdata2 = bh2->b_data;\n\n\t/* create map in the end of data2 block */\n\tmap = (struct dx_map_entry *) (data2 + blocksize);\n\tcount = dx_make_map(dir, (struct ext4_dir_entry_2 *) data1,\n\t\t\t     blocksize, hinfo, map);\n\tmap -= count;\n\tdx_sort_map(map, count);\n\t/* Ensure that neither split block is over half full */\n\tsize = 0;\n\tmove = 0;\n\tfor (i = count-1; i >= 0; i--) {\n\t\t/* is more than half of this entry in 2nd half of the block? */\n\t\tif (size + map[i].size/2 > blocksize/2)\n\t\t\tbreak;\n\t\tsize += map[i].size;\n\t\tmove++;\n\t}\n\t/*\n\t * map index at which we will split\n\t *\n\t * If the sum of active entries didn't exceed half the block size, just\n\t * split it in half by count; each resulting block will have at least\n\t * half the space free.\n\t */\n\tif (i > 0)\n\t\tsplit = count - move;\n\telse\n\t\tsplit = count/2;\n\n\thash2 = map[split].hash;\n\tcontinued = hash2 == map[split - 1].hash;\n\tdxtrace(printk(KERN_INFO \"Split block %lu at %x, %i/%i\\n\",\n\t\t\t(unsigned long)dx_get_block(frame->at),\n\t\t\t\t\thash2, split, count-split));\n\n\t/* Fancy dance to stay within two buffers */\n\tde2 = dx_move_dirents(data1, data2, map + split, count - split,\n\t\t\t      blocksize);\n\tde = dx_pack_dirents(data1, blocksize);\n\tde->rec_len = ext4_rec_len_to_disk(data1 + (blocksize - csum_size) -\n\t\t\t\t\t   (char *) de,\n\t\t\t\t\t   blocksize);\n\tde2->rec_len = ext4_rec_len_to_disk(data2 + (blocksize - csum_size) -\n\t\t\t\t\t    (char *) de2,\n\t\t\t\t\t    blocksize);\n\tif (csum_size) {\n\t\text4_initialize_dirent_tail(*bh, blocksize);\n\t\text4_initialize_dirent_tail(bh2, blocksize);\n\t}\n\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data1,\n\t\t\tblocksize, 1));\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data2,\n\t\t\tblocksize, 1));\n\n\t/* Which block gets the new entry? */\n\tif (hinfo->hash >= hash2) {\n\t\tswap(*bh, bh2);\n\t\tde = de2;\n\t}\n\tdx_insert_block(frame, hash2 + continued, newblock);\n\terr = ext4_handle_dirty_dirblock(handle, dir, bh2);\n\tif (err)\n\t\tgoto journal_error;\n\terr = ext4_handle_dirty_dx_node(handle, dir, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\tbrelse(bh2);\n\tdxtrace(dx_show_index(\"frame\", frame->entries));\n\treturn de;\n\njournal_error:\n\tbrelse(*bh);\n\tbrelse(bh2);\n\t*bh = NULL;\n\text4_std_error(dir->i_sb, err);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,7 +42,7 @@\n \t\t\t     blocksize, hinfo, map);\n \tmap -= count;\n \tdx_sort_map(map, count);\n-\t/* Split the existing block in the middle, size-wise */\n+\t/* Ensure that neither split block is over half full */\n \tsize = 0;\n \tmove = 0;\n \tfor (i = count-1; i >= 0; i--) {\n@@ -52,8 +52,18 @@\n \t\tsize += map[i].size;\n \t\tmove++;\n \t}\n-\t/* map index at which we will split */\n-\tsplit = count - move;\n+\t/*\n+\t * map index at which we will split\n+\t *\n+\t * If the sum of active entries didn't exceed half the block size, just\n+\t * split it in half by count; each resulting block will have at least\n+\t * half the space free.\n+\t */\n+\tif (i > 0)\n+\t\tsplit = count - move;\n+\telse\n+\t\tsplit = count/2;\n+\n \thash2 = map[split].hash;\n \tcontinued = hash2 == map[split - 1].hash;\n \tdxtrace(printk(KERN_INFO \"Split block %lu at %x, %i/%i\\n\",",
        "function_modified_lines": {
            "added": [
                "\t/* Ensure that neither split block is over half full */",
                "\t/*",
                "\t * map index at which we will split",
                "\t *",
                "\t * If the sum of active entries didn't exceed half the block size, just",
                "\t * split it in half by count; each resulting block will have at least",
                "\t * half the space free.",
                "\t */",
                "\tif (i > 0)",
                "\t\tsplit = count - move;",
                "\telse",
                "\t\tsplit = count/2;",
                ""
            ],
            "deleted": [
                "\t/* Split the existing block in the middle, size-wise */",
                "\t/* map index at which we will split */",
                "\tsplit = count - move;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A memory out-of-bounds read flaw was found in the Linux kernel before 5.9-rc2 with the ext3/ext4 file system, in the way it accesses a directory with broken indexing. This flaw allows a local user to crash the system if the directory exists. The highest threat from this vulnerability is to system availability.",
        "id": 2510
    },
    {
        "cve_id": "CVE-2021-27364",
        "code_before_change": "static int\niscsi_if_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh, uint32_t *group)\n{\n\tint err = 0;\n\tu32 portid;\n\tstruct iscsi_uevent *ev = nlmsg_data(nlh);\n\tstruct iscsi_transport *transport = NULL;\n\tstruct iscsi_internal *priv;\n\tstruct iscsi_cls_session *session;\n\tstruct iscsi_cls_conn *conn;\n\tstruct iscsi_endpoint *ep = NULL;\n\n\tif (nlh->nlmsg_type == ISCSI_UEVENT_PATH_UPDATE)\n\t\t*group = ISCSI_NL_GRP_UIP;\n\telse\n\t\t*group = ISCSI_NL_GRP_ISCSID;\n\n\tpriv = iscsi_if_transport_lookup(iscsi_ptr(ev->transport_handle));\n\tif (!priv)\n\t\treturn -EINVAL;\n\ttransport = priv->iscsi_transport;\n\n\tif (!try_module_get(transport->owner))\n\t\treturn -EINVAL;\n\n\tportid = NETLINK_CB(skb).portid;\n\n\tswitch (nlh->nlmsg_type) {\n\tcase ISCSI_UEVENT_CREATE_SESSION:\n\t\terr = iscsi_if_create_session(priv, ep, ev,\n\t\t\t\t\t      portid,\n\t\t\t\t\t      ev->u.c_session.initial_cmdsn,\n\t\t\t\t\t      ev->u.c_session.cmds_max,\n\t\t\t\t\t      ev->u.c_session.queue_depth);\n\t\tbreak;\n\tcase ISCSI_UEVENT_CREATE_BOUND_SESSION:\n\t\tep = iscsi_lookup_endpoint(ev->u.c_bound_session.ep_handle);\n\t\tif (!ep) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = iscsi_if_create_session(priv, ep, ev,\n\t\t\t\t\tportid,\n\t\t\t\t\tev->u.c_bound_session.initial_cmdsn,\n\t\t\t\t\tev->u.c_bound_session.cmds_max,\n\t\t\t\t\tev->u.c_bound_session.queue_depth);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_SESSION:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (!session)\n\t\t\terr = -EINVAL;\n\t\telse if (iscsi_session_has_conns(ev->u.d_session.sid))\n\t\t\terr = -EBUSY;\n\t\telse\n\t\t\ttransport->destroy_session(session);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_SESSION_ASYNC:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (!session)\n\t\t\terr = -EINVAL;\n\t\telse if (iscsi_session_has_conns(ev->u.d_session.sid))\n\t\t\terr = -EBUSY;\n\t\telse {\n\t\t\tunsigned long flags;\n\n\t\t\t/* Prevent this session from being found again */\n\t\t\tspin_lock_irqsave(&sesslock, flags);\n\t\t\tlist_del_init(&session->sess_list);\n\t\t\tspin_unlock_irqrestore(&sesslock, flags);\n\n\t\t\tqueue_work(iscsi_destroy_workq, &session->destroy_work);\n\t\t}\n\t\tbreak;\n\tcase ISCSI_UEVENT_UNBIND_SESSION:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (session)\n\t\t\tscsi_queue_work(iscsi_session_to_shost(session),\n\t\t\t\t\t&session->unbind_work);\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_CREATE_CONN:\n\t\terr = iscsi_if_create_conn(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_CONN:\n\t\terr = iscsi_if_destroy_conn(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_BIND_CONN:\n\t\tsession = iscsi_session_lookup(ev->u.b_conn.sid);\n\t\tconn = iscsi_conn_lookup(ev->u.b_conn.sid, ev->u.b_conn.cid);\n\n\t\tif (conn && conn->ep)\n\t\t\tiscsi_if_ep_disconnect(transport, conn->ep->id);\n\n\t\tif (!session || !conn) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&conn_mutex);\n\t\tev->r.retcode =\ttransport->bind_conn(session, conn,\n\t\t\t\t\t\tev->u.b_conn.transport_eph,\n\t\t\t\t\t\tev->u.b_conn.is_leading);\n\t\tmutex_unlock(&conn_mutex);\n\n\t\tif (ev->r.retcode || !transport->ep_connect)\n\t\t\tbreak;\n\n\t\tep = iscsi_lookup_endpoint(ev->u.b_conn.transport_eph);\n\t\tif (ep) {\n\t\t\tep->conn = conn;\n\n\t\t\tmutex_lock(&conn->ep_mutex);\n\t\t\tconn->ep = ep;\n\t\t\tmutex_unlock(&conn->ep_mutex);\n\t\t} else\n\t\t\tiscsi_cls_conn_printk(KERN_ERR, conn,\n\t\t\t\t\t      \"Could not set ep conn \"\n\t\t\t\t\t      \"binding\\n\");\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_PARAM:\n\t\terr = iscsi_set_param(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_START_CONN:\n\t\tconn = iscsi_conn_lookup(ev->u.start_conn.sid, ev->u.start_conn.cid);\n\t\tif (conn) {\n\t\t\tmutex_lock(&conn_mutex);\n\t\t\tev->r.retcode = transport->start_conn(conn);\n\t\t\tif (!ev->r.retcode)\n\t\t\t\tconn->state = ISCSI_CONN_UP;\n\t\t\tmutex_unlock(&conn_mutex);\n\t\t}\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_STOP_CONN:\n\t\tconn = iscsi_conn_lookup(ev->u.stop_conn.sid, ev->u.stop_conn.cid);\n\t\tif (conn)\n\t\t\tiscsi_if_stop_conn(conn, ev->u.stop_conn.flag);\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_SEND_PDU:\n\t\tconn = iscsi_conn_lookup(ev->u.send_pdu.sid, ev->u.send_pdu.cid);\n\t\tif (conn) {\n\t\t\tmutex_lock(&conn_mutex);\n\t\t\tev->r.retcode =\ttransport->send_pdu(conn,\n\t\t\t\t(struct iscsi_hdr*)((char*)ev + sizeof(*ev)),\n\t\t\t\t(char*)ev + sizeof(*ev) + ev->u.send_pdu.hdr_size,\n\t\t\t\tev->u.send_pdu.data_size);\n\t\t\tmutex_unlock(&conn_mutex);\n\t\t}\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_STATS:\n\t\terr = iscsi_if_get_stats(transport, nlh);\n\t\tbreak;\n\tcase ISCSI_UEVENT_TRANSPORT_EP_CONNECT:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_POLL:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_CONNECT_THROUGH_HOST:\n\t\terr = iscsi_if_transport_ep(transport, ev, nlh->nlmsg_type);\n\t\tbreak;\n\tcase ISCSI_UEVENT_TGT_DSCVR:\n\t\terr = iscsi_tgt_dscvr(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_HOST_PARAM:\n\t\terr = iscsi_set_host_param(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_PATH_UPDATE:\n\t\terr = iscsi_set_path(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_IFACE_PARAMS:\n\t\terr = iscsi_set_iface_params(transport, ev,\n\t\t\t\t\t     nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_PING:\n\t\terr = iscsi_send_ping(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_CHAP:\n\t\terr = iscsi_get_chap(transport, nlh);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DELETE_CHAP:\n\t\terr = iscsi_delete_chap(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_FLASHNODE_PARAMS:\n\t\terr = iscsi_set_flashnode_param(transport, ev,\n\t\t\t\t\t\tnlmsg_attrlen(nlh,\n\t\t\t\t\t\t\t      sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_NEW_FLASHNODE:\n\t\terr = iscsi_new_flashnode(transport, ev,\n\t\t\t\t\t  nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_DEL_FLASHNODE:\n\t\terr = iscsi_del_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGIN_FLASHNODE:\n\t\terr = iscsi_login_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGOUT_FLASHNODE:\n\t\terr = iscsi_logout_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGOUT_FLASHNODE_SID:\n\t\terr = iscsi_logout_flashnode_sid(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_CHAP:\n\t\terr = iscsi_set_chap(transport, ev,\n\t\t\t\t     nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_HOST_STATS:\n\t\terr = iscsi_get_host_stats(transport, nlh);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOSYS;\n\t\tbreak;\n\t}\n\n\tmodule_put(transport->owner);\n\treturn err;\n}",
        "code_after_change": "static int\niscsi_if_recv_msg(struct sk_buff *skb, struct nlmsghdr *nlh, uint32_t *group)\n{\n\tint err = 0;\n\tu32 portid;\n\tstruct iscsi_uevent *ev = nlmsg_data(nlh);\n\tstruct iscsi_transport *transport = NULL;\n\tstruct iscsi_internal *priv;\n\tstruct iscsi_cls_session *session;\n\tstruct iscsi_cls_conn *conn;\n\tstruct iscsi_endpoint *ep = NULL;\n\n\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlh->nlmsg_type == ISCSI_UEVENT_PATH_UPDATE)\n\t\t*group = ISCSI_NL_GRP_UIP;\n\telse\n\t\t*group = ISCSI_NL_GRP_ISCSID;\n\n\tpriv = iscsi_if_transport_lookup(iscsi_ptr(ev->transport_handle));\n\tif (!priv)\n\t\treturn -EINVAL;\n\ttransport = priv->iscsi_transport;\n\n\tif (!try_module_get(transport->owner))\n\t\treturn -EINVAL;\n\n\tportid = NETLINK_CB(skb).portid;\n\n\tswitch (nlh->nlmsg_type) {\n\tcase ISCSI_UEVENT_CREATE_SESSION:\n\t\terr = iscsi_if_create_session(priv, ep, ev,\n\t\t\t\t\t      portid,\n\t\t\t\t\t      ev->u.c_session.initial_cmdsn,\n\t\t\t\t\t      ev->u.c_session.cmds_max,\n\t\t\t\t\t      ev->u.c_session.queue_depth);\n\t\tbreak;\n\tcase ISCSI_UEVENT_CREATE_BOUND_SESSION:\n\t\tep = iscsi_lookup_endpoint(ev->u.c_bound_session.ep_handle);\n\t\tif (!ep) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\terr = iscsi_if_create_session(priv, ep, ev,\n\t\t\t\t\tportid,\n\t\t\t\t\tev->u.c_bound_session.initial_cmdsn,\n\t\t\t\t\tev->u.c_bound_session.cmds_max,\n\t\t\t\t\tev->u.c_bound_session.queue_depth);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_SESSION:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (!session)\n\t\t\terr = -EINVAL;\n\t\telse if (iscsi_session_has_conns(ev->u.d_session.sid))\n\t\t\terr = -EBUSY;\n\t\telse\n\t\t\ttransport->destroy_session(session);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_SESSION_ASYNC:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (!session)\n\t\t\terr = -EINVAL;\n\t\telse if (iscsi_session_has_conns(ev->u.d_session.sid))\n\t\t\terr = -EBUSY;\n\t\telse {\n\t\t\tunsigned long flags;\n\n\t\t\t/* Prevent this session from being found again */\n\t\t\tspin_lock_irqsave(&sesslock, flags);\n\t\t\tlist_del_init(&session->sess_list);\n\t\t\tspin_unlock_irqrestore(&sesslock, flags);\n\n\t\t\tqueue_work(iscsi_destroy_workq, &session->destroy_work);\n\t\t}\n\t\tbreak;\n\tcase ISCSI_UEVENT_UNBIND_SESSION:\n\t\tsession = iscsi_session_lookup(ev->u.d_session.sid);\n\t\tif (session)\n\t\t\tscsi_queue_work(iscsi_session_to_shost(session),\n\t\t\t\t\t&session->unbind_work);\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_CREATE_CONN:\n\t\terr = iscsi_if_create_conn(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DESTROY_CONN:\n\t\terr = iscsi_if_destroy_conn(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_BIND_CONN:\n\t\tsession = iscsi_session_lookup(ev->u.b_conn.sid);\n\t\tconn = iscsi_conn_lookup(ev->u.b_conn.sid, ev->u.b_conn.cid);\n\n\t\tif (conn && conn->ep)\n\t\t\tiscsi_if_ep_disconnect(transport, conn->ep->id);\n\n\t\tif (!session || !conn) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tmutex_lock(&conn_mutex);\n\t\tev->r.retcode =\ttransport->bind_conn(session, conn,\n\t\t\t\t\t\tev->u.b_conn.transport_eph,\n\t\t\t\t\t\tev->u.b_conn.is_leading);\n\t\tmutex_unlock(&conn_mutex);\n\n\t\tif (ev->r.retcode || !transport->ep_connect)\n\t\t\tbreak;\n\n\t\tep = iscsi_lookup_endpoint(ev->u.b_conn.transport_eph);\n\t\tif (ep) {\n\t\t\tep->conn = conn;\n\n\t\t\tmutex_lock(&conn->ep_mutex);\n\t\t\tconn->ep = ep;\n\t\t\tmutex_unlock(&conn->ep_mutex);\n\t\t} else\n\t\t\tiscsi_cls_conn_printk(KERN_ERR, conn,\n\t\t\t\t\t      \"Could not set ep conn \"\n\t\t\t\t\t      \"binding\\n\");\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_PARAM:\n\t\terr = iscsi_set_param(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_START_CONN:\n\t\tconn = iscsi_conn_lookup(ev->u.start_conn.sid, ev->u.start_conn.cid);\n\t\tif (conn) {\n\t\t\tmutex_lock(&conn_mutex);\n\t\t\tev->r.retcode = transport->start_conn(conn);\n\t\t\tif (!ev->r.retcode)\n\t\t\t\tconn->state = ISCSI_CONN_UP;\n\t\t\tmutex_unlock(&conn_mutex);\n\t\t}\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_STOP_CONN:\n\t\tconn = iscsi_conn_lookup(ev->u.stop_conn.sid, ev->u.stop_conn.cid);\n\t\tif (conn)\n\t\t\tiscsi_if_stop_conn(conn, ev->u.stop_conn.flag);\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_SEND_PDU:\n\t\tconn = iscsi_conn_lookup(ev->u.send_pdu.sid, ev->u.send_pdu.cid);\n\t\tif (conn) {\n\t\t\tmutex_lock(&conn_mutex);\n\t\t\tev->r.retcode =\ttransport->send_pdu(conn,\n\t\t\t\t(struct iscsi_hdr*)((char*)ev + sizeof(*ev)),\n\t\t\t\t(char*)ev + sizeof(*ev) + ev->u.send_pdu.hdr_size,\n\t\t\t\tev->u.send_pdu.data_size);\n\t\t\tmutex_unlock(&conn_mutex);\n\t\t}\n\t\telse\n\t\t\terr = -EINVAL;\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_STATS:\n\t\terr = iscsi_if_get_stats(transport, nlh);\n\t\tbreak;\n\tcase ISCSI_UEVENT_TRANSPORT_EP_CONNECT:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_POLL:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT:\n\tcase ISCSI_UEVENT_TRANSPORT_EP_CONNECT_THROUGH_HOST:\n\t\terr = iscsi_if_transport_ep(transport, ev, nlh->nlmsg_type);\n\t\tbreak;\n\tcase ISCSI_UEVENT_TGT_DSCVR:\n\t\terr = iscsi_tgt_dscvr(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_HOST_PARAM:\n\t\terr = iscsi_set_host_param(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_PATH_UPDATE:\n\t\terr = iscsi_set_path(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_IFACE_PARAMS:\n\t\terr = iscsi_set_iface_params(transport, ev,\n\t\t\t\t\t     nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_PING:\n\t\terr = iscsi_send_ping(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_CHAP:\n\t\terr = iscsi_get_chap(transport, nlh);\n\t\tbreak;\n\tcase ISCSI_UEVENT_DELETE_CHAP:\n\t\terr = iscsi_delete_chap(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_FLASHNODE_PARAMS:\n\t\terr = iscsi_set_flashnode_param(transport, ev,\n\t\t\t\t\t\tnlmsg_attrlen(nlh,\n\t\t\t\t\t\t\t      sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_NEW_FLASHNODE:\n\t\terr = iscsi_new_flashnode(transport, ev,\n\t\t\t\t\t  nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_DEL_FLASHNODE:\n\t\terr = iscsi_del_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGIN_FLASHNODE:\n\t\terr = iscsi_login_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGOUT_FLASHNODE:\n\t\terr = iscsi_logout_flashnode(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_LOGOUT_FLASHNODE_SID:\n\t\terr = iscsi_logout_flashnode_sid(transport, ev);\n\t\tbreak;\n\tcase ISCSI_UEVENT_SET_CHAP:\n\t\terr = iscsi_set_chap(transport, ev,\n\t\t\t\t     nlmsg_attrlen(nlh, sizeof(*ev)));\n\t\tbreak;\n\tcase ISCSI_UEVENT_GET_HOST_STATS:\n\t\terr = iscsi_get_host_stats(transport, nlh);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOSYS;\n\t\tbreak;\n\t}\n\n\tmodule_put(transport->owner);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,9 @@\n \tstruct iscsi_cls_conn *conn;\n \tstruct iscsi_endpoint *ep = NULL;\n \n+\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n+\t\treturn -EPERM;\n+\n \tif (nlh->nlmsg_type == ISCSI_UEVENT_PATH_UPDATE)\n \t\t*group = ISCSI_NL_GRP_UIP;\n \telse",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_SYS_ADMIN))",
                "\t\treturn -EPERM;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.3. drivers/scsi/scsi_transport_iscsi.c is adversely affected by the ability of an unprivileged user to craft Netlink messages.",
        "id": 2899
    },
    {
        "cve_id": "CVE-2015-9289",
        "code_before_change": "static int cx24116_send_diseqc_msg(struct dvb_frontend *fe,\n\tstruct dvb_diseqc_master_cmd *d)\n{\n\tstruct cx24116_state *state = fe->demodulator_priv;\n\tint i, ret;\n\n\t/* Dump DiSEqC message */\n\tif (debug) {\n\t\tprintk(KERN_INFO \"cx24116: %s(\", __func__);\n\t\tfor (i = 0 ; i < d->msg_len ;) {\n\t\t\tprintk(KERN_INFO \"0x%02x\", d->msg[i]);\n\t\t\tif (++i < d->msg_len)\n\t\t\t\tprintk(KERN_INFO \", \");\n\t\t}\n\t\tprintk(\") toneburst=%d\\n\", toneburst);\n\t}\n\n\t/* Validate length */\n\tif (d->msg_len > (CX24116_ARGLEN - CX24116_DISEQC_MSGOFS))\n\t\treturn -EINVAL;\n\n\t/* DiSEqC message */\n\tfor (i = 0; i < d->msg_len; i++)\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGOFS + i] = d->msg[i];\n\n\t/* DiSEqC message length */\n\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN] = d->msg_len;\n\n\t/* Command length */\n\tstate->dsec_cmd.len = CX24116_DISEQC_MSGOFS +\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN];\n\n\t/* DiSEqC toneburst */\n\tif (toneburst == CX24116_DISEQC_MESGCACHE)\n\t\t/* Message is cached */\n\t\treturn 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONEOFF)\n\t\t/* Message is sent without burst */\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] = 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONECACHE) {\n\t\t/*\n\t\t * Message is sent with derived else cached burst\n\t\t *\n\t\t * WRITE PORT GROUP COMMAND 38\n\t\t *\n\t\t * 0/A/A: E0 10 38 F0..F3\n\t\t * 1/B/B: E0 10 38 F4..F7\n\t\t * 2/C/A: E0 10 38 F8..FB\n\t\t * 3/D/B: E0 10 38 FC..FF\n\t\t *\n\t\t * databyte[3]= 8421:8421\n\t\t *              ABCD:WXYZ\n\t\t *              CLR :SET\n\t\t *\n\t\t *              WX= PORT SELECT 0..3    (X=TONEBURST)\n\t\t *              Y = VOLTAGE             (0=13V, 1=18V)\n\t\t *              Z = BAND                (0=LOW, 1=HIGH(22K))\n\t\t */\n\t\tif (d->msg_len >= 4 && d->msg[2] == 0x38)\n\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] =\n\t\t\t\t((d->msg[3] & 4) >> 2);\n\t\tif (debug)\n\t\t\tdprintk(\"%s burst=%d\\n\", __func__,\n\t\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST]);\n\t}\n\n\t/* Wait for LNB ready */\n\tret = cx24116_wait_for_lnb(fe);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t/* Wait for voltage/min repeat delay */\n\tmsleep(100);\n\n\t/* Command */\n\tret = cx24116_cmd_execute(fe, &state->dsec_cmd);\n\tif (ret != 0)\n\t\treturn ret;\n\t/*\n\t * Wait for send\n\t *\n\t * Eutelsat spec:\n\t * >15ms delay          + (XXX determine if FW does this, see set_tone)\n\t *  13.5ms per byte     +\n\t * >15ms delay          +\n\t *  12.5ms burst        +\n\t * >15ms delay            (XXX determine if FW does this, see set_tone)\n\t */\n\tmsleep((state->dsec_cmd.args[CX24116_DISEQC_MSGLEN] << 4) +\n\t\t((toneburst == CX24116_DISEQC_TONEOFF) ? 30 : 60));\n\n\treturn 0;\n}",
        "code_after_change": "static int cx24116_send_diseqc_msg(struct dvb_frontend *fe,\n\tstruct dvb_diseqc_master_cmd *d)\n{\n\tstruct cx24116_state *state = fe->demodulator_priv;\n\tint i, ret;\n\n\t/* Validate length */\n\tif (d->msg_len > sizeof(d->msg))\n                return -EINVAL;\n\n\t/* Dump DiSEqC message */\n\tif (debug) {\n\t\tprintk(KERN_INFO \"cx24116: %s(\", __func__);\n\t\tfor (i = 0 ; i < d->msg_len ;) {\n\t\t\tprintk(KERN_INFO \"0x%02x\", d->msg[i]);\n\t\t\tif (++i < d->msg_len)\n\t\t\t\tprintk(KERN_INFO \", \");\n\t\t}\n\t\tprintk(\") toneburst=%d\\n\", toneburst);\n\t}\n\n\t/* DiSEqC message */\n\tfor (i = 0; i < d->msg_len; i++)\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGOFS + i] = d->msg[i];\n\n\t/* DiSEqC message length */\n\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN] = d->msg_len;\n\n\t/* Command length */\n\tstate->dsec_cmd.len = CX24116_DISEQC_MSGOFS +\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN];\n\n\t/* DiSEqC toneburst */\n\tif (toneburst == CX24116_DISEQC_MESGCACHE)\n\t\t/* Message is cached */\n\t\treturn 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONEOFF)\n\t\t/* Message is sent without burst */\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] = 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONECACHE) {\n\t\t/*\n\t\t * Message is sent with derived else cached burst\n\t\t *\n\t\t * WRITE PORT GROUP COMMAND 38\n\t\t *\n\t\t * 0/A/A: E0 10 38 F0..F3\n\t\t * 1/B/B: E0 10 38 F4..F7\n\t\t * 2/C/A: E0 10 38 F8..FB\n\t\t * 3/D/B: E0 10 38 FC..FF\n\t\t *\n\t\t * databyte[3]= 8421:8421\n\t\t *              ABCD:WXYZ\n\t\t *              CLR :SET\n\t\t *\n\t\t *              WX= PORT SELECT 0..3    (X=TONEBURST)\n\t\t *              Y = VOLTAGE             (0=13V, 1=18V)\n\t\t *              Z = BAND                (0=LOW, 1=HIGH(22K))\n\t\t */\n\t\tif (d->msg_len >= 4 && d->msg[2] == 0x38)\n\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] =\n\t\t\t\t((d->msg[3] & 4) >> 2);\n\t\tif (debug)\n\t\t\tdprintk(\"%s burst=%d\\n\", __func__,\n\t\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST]);\n\t}\n\n\t/* Wait for LNB ready */\n\tret = cx24116_wait_for_lnb(fe);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t/* Wait for voltage/min repeat delay */\n\tmsleep(100);\n\n\t/* Command */\n\tret = cx24116_cmd_execute(fe, &state->dsec_cmd);\n\tif (ret != 0)\n\t\treturn ret;\n\t/*\n\t * Wait for send\n\t *\n\t * Eutelsat spec:\n\t * >15ms delay          + (XXX determine if FW does this, see set_tone)\n\t *  13.5ms per byte     +\n\t * >15ms delay          +\n\t *  12.5ms burst        +\n\t * >15ms delay            (XXX determine if FW does this, see set_tone)\n\t */\n\tmsleep((state->dsec_cmd.args[CX24116_DISEQC_MSGLEN] << 4) +\n\t\t((toneburst == CX24116_DISEQC_TONEOFF) ? 30 : 60));\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,10 @@\n {\n \tstruct cx24116_state *state = fe->demodulator_priv;\n \tint i, ret;\n+\n+\t/* Validate length */\n+\tif (d->msg_len > sizeof(d->msg))\n+                return -EINVAL;\n \n \t/* Dump DiSEqC message */\n \tif (debug) {\n@@ -14,10 +18,6 @@\n \t\t}\n \t\tprintk(\") toneburst=%d\\n\", toneburst);\n \t}\n-\n-\t/* Validate length */\n-\tif (d->msg_len > (CX24116_ARGLEN - CX24116_DISEQC_MSGOFS))\n-\t\treturn -EINVAL;\n \n \t/* DiSEqC message */\n \tfor (i = 0; i < d->msg_len; i++)",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* Validate length */",
                "\tif (d->msg_len > sizeof(d->msg))",
                "                return -EINVAL;"
            ],
            "deleted": [
                "",
                "\t/* Validate length */",
                "\tif (d->msg_len > (CX24116_ARGLEN - CX24116_DISEQC_MSGOFS))",
                "\t\treturn -EINVAL;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In the Linux kernel before 4.1.4, a buffer overflow occurs when checking userspace params in drivers/media/dvb-frontends/cx24116.c. The maximum size for a DiSEqC command is 6, according to the userspace API. However, the code allows larger values such as 23.",
        "id": 886
    },
    {
        "cve_id": "CVE-2023-2176",
        "code_before_change": "static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n\t\t\t const struct sockaddr *dst_addr)\n{\n\tstruct sockaddr_storage zero_sock = {};\n\n\tif (src_addr && src_addr->sa_family)\n\t\treturn rdma_bind_addr(id, src_addr);\n\n\t/*\n\t * When the src_addr is not specified, automatically supply an any addr\n\t */\n\tzero_sock.ss_family = dst_addr->sa_family;\n\tif (IS_ENABLED(CONFIG_IPV6) && dst_addr->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *src_addr6 =\n\t\t\t(struct sockaddr_in6 *)&zero_sock;\n\t\tstruct sockaddr_in6 *dst_addr6 =\n\t\t\t(struct sockaddr_in6 *)dst_addr;\n\n\t\tsrc_addr6->sin6_scope_id = dst_addr6->sin6_scope_id;\n\t\tif (ipv6_addr_type(&dst_addr6->sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tid->route.addr.dev_addr.bound_dev_if =\n\t\t\t\tdst_addr6->sin6_scope_id;\n\t} else if (dst_addr->sa_family == AF_IB) {\n\t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n\t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n\t}\n\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);\n}",
        "code_after_change": "static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n\t\t\t const struct sockaddr *dst_addr)\n{\n\tstruct rdma_id_private *id_priv =\n\t\tcontainer_of(id, struct rdma_id_private, id);\n\tstruct sockaddr_storage zero_sock = {};\n\n\tif (src_addr && src_addr->sa_family)\n\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);\n\n\t/*\n\t * When the src_addr is not specified, automatically supply an any addr\n\t */\n\tzero_sock.ss_family = dst_addr->sa_family;\n\tif (IS_ENABLED(CONFIG_IPV6) && dst_addr->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *src_addr6 =\n\t\t\t(struct sockaddr_in6 *)&zero_sock;\n\t\tstruct sockaddr_in6 *dst_addr6 =\n\t\t\t(struct sockaddr_in6 *)dst_addr;\n\n\t\tsrc_addr6->sin6_scope_id = dst_addr6->sin6_scope_id;\n\t\tif (ipv6_addr_type(&dst_addr6->sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tid->route.addr.dev_addr.bound_dev_if =\n\t\t\t\tdst_addr6->sin6_scope_id;\n\t} else if (dst_addr->sa_family == AF_IB) {\n\t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n\t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n\t}\n\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,12 @@\n static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n \t\t\t const struct sockaddr *dst_addr)\n {\n+\tstruct rdma_id_private *id_priv =\n+\t\tcontainer_of(id, struct rdma_id_private, id);\n \tstruct sockaddr_storage zero_sock = {};\n \n \tif (src_addr && src_addr->sa_family)\n-\t\treturn rdma_bind_addr(id, src_addr);\n+\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);\n \n \t/*\n \t * When the src_addr is not specified, automatically supply an any addr\n@@ -24,5 +26,5 @@\n \t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n \t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n \t}\n-\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);\n+\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct rdma_id_private *id_priv =",
                "\t\tcontainer_of(id, struct rdma_id_private, id);",
                "\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);",
                "\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);"
            ],
            "deleted": [
                "\t\treturn rdma_bind_addr(id, src_addr);",
                "\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A vulnerability was found in compare_netdev_and_ip in drivers/infiniband/core/cma.c in RDMA in the Linux Kernel. The improper cleanup results in out-of-boundary read, where a local user can utilize this problem to crash the system or escalation of privilege.",
        "id": 3930
    },
    {
        "cve_id": "CVE-2017-7558",
        "code_before_change": "static int inet_diag_msg_sctpladdrs_fill(struct sk_buff *skb,\n\t\t\t\t\t struct list_head *address_list)\n{\n\tstruct sctp_sockaddr_entry *laddr;\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tint addrcnt = 0;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tlist_for_each_entry_rcu(laddr, address_list, list)\n\t\taddrcnt++;\n\n\tattr = nla_reserve(skb, INET_DIAG_LOCALS, addrlen * addrcnt);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry_rcu(laddr, address_list, list) {\n\t\tmemcpy(info, &laddr->a, addrlen);\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int inet_diag_msg_sctpladdrs_fill(struct sk_buff *skb,\n\t\t\t\t\t struct list_head *address_list)\n{\n\tstruct sctp_sockaddr_entry *laddr;\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tint addrcnt = 0;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tlist_for_each_entry_rcu(laddr, address_list, list)\n\t\taddrcnt++;\n\n\tattr = nla_reserve(skb, INET_DIAG_LOCALS, addrlen * addrcnt);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry_rcu(laddr, address_list, list) {\n\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));\n\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,7 +16,8 @@\n \n \tinfo = nla_data(attr);\n \tlist_for_each_entry_rcu(laddr, address_list, list) {\n-\t\tmemcpy(info, &laddr->a, addrlen);\n+\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));\n+\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));\n \t\tinfo += addrlen;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));",
                "\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));"
            ],
            "deleted": [
                "\t\tmemcpy(info, &laddr->a, addrlen);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A kernel data leak due to an out-of-bound read was found in the Linux kernel in inet_diag_msg_sctp{,l}addr_fill() and sctp_get_sctp_info() functions present since version 4.7-rc1 through version 4.13. A data leak happens when these functions fill in sockaddr data structures used to export socket's diagnostic information. As a result, up to 100 bytes of the slab data could be leaked to a userspace.",
        "id": 1515
    },
    {
        "cve_id": "CVE-2022-3170",
        "code_before_change": "static unsigned long get_ctl_id_hash(const struct snd_ctl_elem_id *id)\n{\n\tunsigned long h;\n\tconst unsigned char *p;\n\n\th = id->iface;\n\th = MULTIPLIER * h + id->device;\n\th = MULTIPLIER * h + id->subdevice;\n\tfor (p = id->name; *p; p++)\n\t\th = MULTIPLIER * h + *p;\n\th = MULTIPLIER * h + id->index;\n\th &= LONG_MAX;\n\treturn h;\n}",
        "code_after_change": "static unsigned long get_ctl_id_hash(const struct snd_ctl_elem_id *id)\n{\n\tint i;\n\tunsigned long h;\n\n\th = id->iface;\n\th = MULTIPLIER * h + id->device;\n\th = MULTIPLIER * h + id->subdevice;\n\tfor (i = 0; id->name[i] && i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN; i++)\n\t\th = MULTIPLIER * h + id->name[i];\n\th = MULTIPLIER * h + id->index;\n\th &= LONG_MAX;\n\treturn h;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,13 +1,13 @@\n static unsigned long get_ctl_id_hash(const struct snd_ctl_elem_id *id)\n {\n+\tint i;\n \tunsigned long h;\n-\tconst unsigned char *p;\n \n \th = id->iface;\n \th = MULTIPLIER * h + id->device;\n \th = MULTIPLIER * h + id->subdevice;\n-\tfor (p = id->name; *p; p++)\n-\t\th = MULTIPLIER * h + *p;\n+\tfor (i = 0; id->name[i] && i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN; i++)\n+\t\th = MULTIPLIER * h + id->name[i];\n \th = MULTIPLIER * h + id->index;\n \th &= LONG_MAX;\n \treturn h;",
        "function_modified_lines": {
            "added": [
                "\tint i;",
                "\tfor (i = 0; id->name[i] && i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN; i++)",
                "\t\th = MULTIPLIER * h + id->name[i];"
            ],
            "deleted": [
                "\tconst unsigned char *p;",
                "\tfor (p = id->name; *p; p++)",
                "\t\th = MULTIPLIER * h + *p;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds access issue was found in the Linux kernel sound subsystem. It could occur when the 'id->name' provided by the user did not end with '\\0'. A privileged local user could pass a specially crafted name through ioctl() interface and crash the system or potentially escalate their privileges on the system.",
        "id": 3563
    },
    {
        "cve_id": "CVE-2019-15926",
        "code_before_change": "int ath6kl_wmi_delete_pstream_cmd(struct wmi *wmi, u8 if_idx, u8 traffic_class,\n\t\t\t\t  u8 tsid)\n{\n\tstruct sk_buff *skb;\n\tstruct wmi_delete_pstream_cmd *cmd;\n\tu16 active_tsids = 0;\n\tint ret;\n\n\tif (traffic_class > 3) {\n\t\tath6kl_err(\"invalid traffic class: %d\\n\", traffic_class);\n\t\treturn -EINVAL;\n\t}\n\n\tskb = ath6kl_wmi_get_new_buf(sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_delete_pstream_cmd *) skb->data;\n\tcmd->traffic_class = traffic_class;\n\tcmd->tsid = tsid;\n\n\tspin_lock_bh(&wmi->lock);\n\tactive_tsids = wmi->stream_exist_for_ac[traffic_class];\n\tspin_unlock_bh(&wmi->lock);\n\n\tif (!(active_tsids & (1 << tsid))) {\n\t\tdev_kfree_skb(skb);\n\t\tath6kl_dbg(ATH6KL_DBG_WMI,\n\t\t\t   \"TSID %d doesn't exist for traffic class: %d\\n\",\n\t\t\t   tsid, traffic_class);\n\t\treturn -ENODATA;\n\t}\n\n\tath6kl_dbg(ATH6KL_DBG_WMI,\n\t\t   \"sending delete_pstream_cmd: traffic class: %d tsid=%d\\n\",\n\t\t   traffic_class, tsid);\n\n\tret = ath6kl_wmi_cmd_send(wmi, if_idx, skb, WMI_DELETE_PSTREAM_CMDID,\n\t\t\t\t  SYNC_BEFORE_WMIFLAG);\n\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[traffic_class] &= ~(1 << tsid);\n\tactive_tsids = wmi->stream_exist_for_ac[traffic_class];\n\tspin_unlock_bh(&wmi->lock);\n\n\t/*\n\t * Indicate stream inactivity to driver layer only if all tsids\n\t * within this AC are deleted.\n\t */\n\tif (!active_tsids) {\n\t\tath6kl_indicate_tx_activity(wmi->parent_dev,\n\t\t\t\t\t    traffic_class, false);\n\t\twmi->fat_pipe_exist &= ~(1 << traffic_class);\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "int ath6kl_wmi_delete_pstream_cmd(struct wmi *wmi, u8 if_idx, u8 traffic_class,\n\t\t\t\t  u8 tsid)\n{\n\tstruct sk_buff *skb;\n\tstruct wmi_delete_pstream_cmd *cmd;\n\tu16 active_tsids = 0;\n\tint ret;\n\n\tif (traffic_class >= WMM_NUM_AC) {\n\t\tath6kl_err(\"invalid traffic class: %d\\n\", traffic_class);\n\t\treturn -EINVAL;\n\t}\n\n\tskb = ath6kl_wmi_get_new_buf(sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_delete_pstream_cmd *) skb->data;\n\tcmd->traffic_class = traffic_class;\n\tcmd->tsid = tsid;\n\n\tspin_lock_bh(&wmi->lock);\n\tactive_tsids = wmi->stream_exist_for_ac[traffic_class];\n\tspin_unlock_bh(&wmi->lock);\n\n\tif (!(active_tsids & (1 << tsid))) {\n\t\tdev_kfree_skb(skb);\n\t\tath6kl_dbg(ATH6KL_DBG_WMI,\n\t\t\t   \"TSID %d doesn't exist for traffic class: %d\\n\",\n\t\t\t   tsid, traffic_class);\n\t\treturn -ENODATA;\n\t}\n\n\tath6kl_dbg(ATH6KL_DBG_WMI,\n\t\t   \"sending delete_pstream_cmd: traffic class: %d tsid=%d\\n\",\n\t\t   traffic_class, tsid);\n\n\tret = ath6kl_wmi_cmd_send(wmi, if_idx, skb, WMI_DELETE_PSTREAM_CMDID,\n\t\t\t\t  SYNC_BEFORE_WMIFLAG);\n\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[traffic_class] &= ~(1 << tsid);\n\tactive_tsids = wmi->stream_exist_for_ac[traffic_class];\n\tspin_unlock_bh(&wmi->lock);\n\n\t/*\n\t * Indicate stream inactivity to driver layer only if all tsids\n\t * within this AC are deleted.\n\t */\n\tif (!active_tsids) {\n\t\tath6kl_indicate_tx_activity(wmi->parent_dev,\n\t\t\t\t\t    traffic_class, false);\n\t\twmi->fat_pipe_exist &= ~(1 << traffic_class);\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \tu16 active_tsids = 0;\n \tint ret;\n \n-\tif (traffic_class > 3) {\n+\tif (traffic_class >= WMM_NUM_AC) {\n \t\tath6kl_err(\"invalid traffic class: %d\\n\", traffic_class);\n \t\treturn -EINVAL;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (traffic_class >= WMM_NUM_AC) {"
            ],
            "deleted": [
                "\tif (traffic_class > 3) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. Out of bounds access exists in the functions ath6kl_wmi_pstream_timeout_event_rx and ath6kl_wmi_cac_event_rx in the file drivers/net/wireless/ath/ath6kl/wmi.c.",
        "id": 2041
    },
    {
        "cve_id": "CVE-2021-39711",
        "code_before_change": "int bpf_prog_test_run_skb(struct bpf_prog *prog, const union bpf_attr *kattr,\n\t\t\t  union bpf_attr __user *uattr)\n{\n\tbool is_l2 = false, is_direct_pkt_access = false;\n\tu32 size = kattr->test.data_size_in;\n\tu32 repeat = kattr->test.repeat;\n\tu32 retval, duration;\n\tstruct sk_buff *skb;\n\tvoid *data;\n\tint ret;\n\n\tdata = bpf_test_init(kattr, size, NET_SKB_PAD + NET_IP_ALIGN,\n\t\t\t     SKB_DATA_ALIGN(sizeof(struct skb_shared_info)));\n\tif (IS_ERR(data))\n\t\treturn PTR_ERR(data);\n\n\tswitch (prog->type) {\n\tcase BPF_PROG_TYPE_SCHED_CLS:\n\tcase BPF_PROG_TYPE_SCHED_ACT:\n\t\tis_l2 = true;\n\t\t/* fall through */\n\tcase BPF_PROG_TYPE_LWT_IN:\n\tcase BPF_PROG_TYPE_LWT_OUT:\n\tcase BPF_PROG_TYPE_LWT_XMIT:\n\t\tis_direct_pkt_access = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tskb = build_skb(data, 0);\n\tif (!skb) {\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\n\tskb_reserve(skb, NET_SKB_PAD + NET_IP_ALIGN);\n\t__skb_put(skb, size);\n\tskb->protocol = eth_type_trans(skb, current->nsproxy->net_ns->loopback_dev);\n\tskb_reset_network_header(skb);\n\n\tif (is_l2)\n\t\t__skb_push(skb, ETH_HLEN);\n\tif (is_direct_pkt_access)\n\t\tbpf_compute_data_pointers(skb);\n\tretval = bpf_test_run(prog, skb, repeat, &duration);\n\tif (!is_l2)\n\t\t__skb_push(skb, ETH_HLEN);\n\tsize = skb->len;\n\t/* bpf program can never convert linear skb to non-linear */\n\tif (WARN_ON_ONCE(skb_is_nonlinear(skb)))\n\t\tsize = skb_headlen(skb);\n\tret = bpf_test_finish(kattr, uattr, skb->data, size, retval, duration);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "code_after_change": "int bpf_prog_test_run_skb(struct bpf_prog *prog, const union bpf_attr *kattr,\n\t\t\t  union bpf_attr __user *uattr)\n{\n\tbool is_l2 = false, is_direct_pkt_access = false;\n\tu32 size = kattr->test.data_size_in;\n\tu32 repeat = kattr->test.repeat;\n\tu32 retval, duration;\n\tint hh_len = ETH_HLEN;\n\tstruct sk_buff *skb;\n\tvoid *data;\n\tint ret;\n\n\tdata = bpf_test_init(kattr, size, NET_SKB_PAD + NET_IP_ALIGN,\n\t\t\t     SKB_DATA_ALIGN(sizeof(struct skb_shared_info)));\n\tif (IS_ERR(data))\n\t\treturn PTR_ERR(data);\n\n\tswitch (prog->type) {\n\tcase BPF_PROG_TYPE_SCHED_CLS:\n\tcase BPF_PROG_TYPE_SCHED_ACT:\n\t\tis_l2 = true;\n\t\t/* fall through */\n\tcase BPF_PROG_TYPE_LWT_IN:\n\tcase BPF_PROG_TYPE_LWT_OUT:\n\tcase BPF_PROG_TYPE_LWT_XMIT:\n\t\tis_direct_pkt_access = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tskb = build_skb(data, 0);\n\tif (!skb) {\n\t\tkfree(data);\n\t\treturn -ENOMEM;\n\t}\n\n\tskb_reserve(skb, NET_SKB_PAD + NET_IP_ALIGN);\n\t__skb_put(skb, size);\n\tskb->protocol = eth_type_trans(skb, current->nsproxy->net_ns->loopback_dev);\n\tskb_reset_network_header(skb);\n\n\tif (is_l2)\n\t\t__skb_push(skb, hh_len);\n\tif (is_direct_pkt_access)\n\t\tbpf_compute_data_pointers(skb);\n\tretval = bpf_test_run(prog, skb, repeat, &duration);\n\tif (!is_l2) {\n\t\tif (skb_headroom(skb) < hh_len) {\n\t\t\tint nhead = HH_DATA_ALIGN(hh_len - skb_headroom(skb));\n\n\t\t\tif (pskb_expand_head(skb, nhead, 0, GFP_USER)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\t\tmemset(__skb_push(skb, hh_len), 0, hh_len);\n\t}\n\n\tsize = skb->len;\n\t/* bpf program can never convert linear skb to non-linear */\n\tif (WARN_ON_ONCE(skb_is_nonlinear(skb)))\n\t\tsize = skb_headlen(skb);\n\tret = bpf_test_finish(kattr, uattr, skb->data, size, retval, duration);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tu32 size = kattr->test.data_size_in;\n \tu32 repeat = kattr->test.repeat;\n \tu32 retval, duration;\n+\tint hh_len = ETH_HLEN;\n \tstruct sk_buff *skb;\n \tvoid *data;\n \tint ret;\n@@ -40,12 +41,22 @@\n \tskb_reset_network_header(skb);\n \n \tif (is_l2)\n-\t\t__skb_push(skb, ETH_HLEN);\n+\t\t__skb_push(skb, hh_len);\n \tif (is_direct_pkt_access)\n \t\tbpf_compute_data_pointers(skb);\n \tretval = bpf_test_run(prog, skb, repeat, &duration);\n-\tif (!is_l2)\n-\t\t__skb_push(skb, ETH_HLEN);\n+\tif (!is_l2) {\n+\t\tif (skb_headroom(skb) < hh_len) {\n+\t\t\tint nhead = HH_DATA_ALIGN(hh_len - skb_headroom(skb));\n+\n+\t\t\tif (pskb_expand_head(skb, nhead, 0, GFP_USER)) {\n+\t\t\t\tkfree_skb(skb);\n+\t\t\t\treturn -ENOMEM;\n+\t\t\t}\n+\t\t}\n+\t\tmemset(__skb_push(skb, hh_len), 0, hh_len);\n+\t}\n+\n \tsize = skb->len;\n \t/* bpf program can never convert linear skb to non-linear */\n \tif (WARN_ON_ONCE(skb_is_nonlinear(skb)))",
        "function_modified_lines": {
            "added": [
                "\tint hh_len = ETH_HLEN;",
                "\t\t__skb_push(skb, hh_len);",
                "\tif (!is_l2) {",
                "\t\tif (skb_headroom(skb) < hh_len) {",
                "\t\t\tint nhead = HH_DATA_ALIGN(hh_len - skb_headroom(skb));",
                "",
                "\t\t\tif (pskb_expand_head(skb, nhead, 0, GFP_USER)) {",
                "\t\t\t\tkfree_skb(skb);",
                "\t\t\t\treturn -ENOMEM;",
                "\t\t\t}",
                "\t\t}",
                "\t\tmemset(__skb_push(skb, hh_len), 0, hh_len);",
                "\t}",
                ""
            ],
            "deleted": [
                "\t\t__skb_push(skb, ETH_HLEN);",
                "\tif (!is_l2)",
                "\t\t__skb_push(skb, ETH_HLEN);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In bpf_prog_test_run_skb of test_run.c, there is a possible out of bounds read due to Incorrect Size Value. This could lead to local information disclosure with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-154175781References: Upstream kernel",
        "id": 3102
    },
    {
        "cve_id": "CVE-2022-1508",
        "code_before_change": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}",
        "code_after_change": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,6 +47,7 @@\n \t\tif (req->flags & REQ_F_NOWAIT)\n \t\t\tgoto done;\n \t\t/* some cases will consume bytes even on error returns */\n+\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n \t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n \t\tret = 0;\n \t} else if (ret == -EIOCBQUEUED) {",
        "function_modified_lines": {
            "added": [
                "\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read flaw was found in the Linux kernels io_uring module in the way a user triggers the io_read() function with some special parameters. This flaw allows a local user to read some memory out of bounds.",
        "id": 3263
    },
    {
        "cve_id": "CVE-2020-0430",
        "code_before_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* ctx accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t */\n\t\tif (reg->off) {\n\t\t\tverbose(env,\n\t\t\t\t\"dereference of modified ctx ptr R%d off=%d+%d, ctx+const is allowed, ctx+const+const is not\\n\",\n\t\t\t\tregno, reg->off, off - reg->off);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env,\n\t\t\t\t\"variable ctx access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE)\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\telse\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\tregs[value_regno].id = 0;\n\t\t\tregs[value_regno].off = 0;\n\t\t\tregs[value_regno].range = 0;\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* stack accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t * See check_stack_read().\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env, \"variable stack access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\toff += reg->var_off.value;\n\t\tif (off >= 0 || off < -MAX_BPF_STACK) {\n\t\t\tverbose(env, \"invalid stack off=%d size=%d\\n\", off,\n\t\t\t\tsize);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_WRITE)\n\t\t\terr = check_stack_write(env, state, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t\telse\n\t\t\terr = check_stack_read(env, state, off, size,\n\t\t\t\t\t       value_regno);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "code_after_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE)\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\telse\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\tregs[value_regno].id = 0;\n\t\t\tregs[value_regno].off = 0;\n\t\t\tregs[value_regno].range = 0;\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* stack accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t * See check_stack_read().\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env, \"variable stack access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\toff += reg->var_off.value;\n\t\tif (off >= 0 || off < -MAX_BPF_STACK) {\n\t\t\tverbose(env, \"invalid stack off=%d size=%d\\n\", off,\n\t\t\t\tsize);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_WRITE)\n\t\t\terr = check_stack_write(env, state, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t\telse\n\t\t\terr = check_stack_read(env, state, off, size,\n\t\t\t\t\t       value_regno);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,24 +38,11 @@\n \t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n \t\t\treturn -EACCES;\n \t\t}\n-\t\t/* ctx accesses must be at a fixed offset, so that we can\n-\t\t * determine what type of data were returned.\n-\t\t */\n-\t\tif (reg->off) {\n-\t\t\tverbose(env,\n-\t\t\t\t\"dereference of modified ctx ptr R%d off=%d+%d, ctx+const is allowed, ctx+const+const is not\\n\",\n-\t\t\t\tregno, reg->off, off - reg->off);\n-\t\t\treturn -EACCES;\n-\t\t}\n-\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n-\t\t\tchar tn_buf[48];\n \n-\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n-\t\t\tverbose(env,\n-\t\t\t\t\"variable ctx access var_off=%s off=%d size=%d\",\n-\t\t\t\ttn_buf, off, size);\n-\t\t\treturn -EACCES;\n-\t\t}\n+\t\terr = check_ctx_reg(env, reg, regno);\n+\t\tif (err < 0)\n+\t\t\treturn err;\n+\n \t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type);\n \t\tif (!err && t == BPF_READ && value_regno >= 0) {\n \t\t\t/* ctx access returns either a scalar, or a",
        "function_modified_lines": {
            "added": [
                "\t\terr = check_ctx_reg(env, reg, regno);",
                "\t\tif (err < 0)",
                "\t\t\treturn err;",
                ""
            ],
            "deleted": [
                "\t\t/* ctx accesses must be at a fixed offset, so that we can",
                "\t\t * determine what type of data were returned.",
                "\t\t */",
                "\t\tif (reg->off) {",
                "\t\t\tverbose(env,",
                "\t\t\t\t\"dereference of modified ctx ptr R%d off=%d+%d, ctx+const is allowed, ctx+const+const is not\\n\",",
                "\t\t\t\tregno, reg->off, off - reg->off);",
                "\t\t\treturn -EACCES;",
                "\t\t}",
                "\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {",
                "\t\t\tchar tn_buf[48];",
                "\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);",
                "\t\t\tverbose(env,",
                "\t\t\t\t\"variable ctx access var_off=%s off=%d size=%d\",",
                "\t\t\t\ttn_buf, off, size);",
                "\t\t\treturn -EACCES;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In skb_headlen of /include/linux/skbuff.h, there is a possible out of bounds read due to memory corruption. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-153881554",
        "id": 2383
    },
    {
        "cve_id": "CVE-2021-4093",
        "code_before_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n\tvcpu->arch.pio.count = 0;\n\n\treturn 1;\n}",
        "code_after_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tint size = vcpu->arch.pio.size;\n\tint port = vcpu->arch.pio.port;\n\n\tadvance_sev_es_emulated_ins(vcpu);\n\tif (vcpu->arch.sev_pio_count)\n\t\treturn kvm_sev_es_ins(vcpu, size, port);\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,10 @@\n static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n {\n-\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n-\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n-\tvcpu->arch.pio.count = 0;\n+\tint size = vcpu->arch.pio.size;\n+\tint port = vcpu->arch.pio.port;\n \n+\tadvance_sev_es_emulated_ins(vcpu);\n+\tif (vcpu->arch.sev_pio_count)\n+\t\treturn kvm_sev_es_ins(vcpu, size, port);\n \treturn 1;\n }",
        "function_modified_lines": {
            "added": [
                "\tint size = vcpu->arch.pio.size;",
                "\tint port = vcpu->arch.pio.port;",
                "\tadvance_sev_es_emulated_ins(vcpu);",
                "\tif (vcpu->arch.sev_pio_count)",
                "\t\treturn kvm_sev_es_ins(vcpu, size, port);"
            ],
            "deleted": [
                "\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,",
                "\t       vcpu->arch.pio.count * vcpu->arch.pio.size);",
                "\tvcpu->arch.pio.count = 0;"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the KVM's AMD code for supporting the Secure Encrypted Virtualization-Encrypted State (SEV-ES). A KVM guest using SEV-ES can trigger out-of-bounds reads and writes in the host kernel via a malicious VMGEXIT for a string I/O instruction (for example, outs or ins) using the exit reason SVM_EXIT_IOIO. This issue results in a crash of the entire system or a potential guest-to-host escape scenario.",
        "id": 3130
    },
    {
        "cve_id": "CVE-2014-3180",
        "code_before_change": "\nCOMPAT_SYSCALL_DEFINE2(nanosleep, struct compat_timespec __user *, rqtp,\n\t\t       struct compat_timespec __user *, rmtp)\n{\n\tstruct timespec tu, rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\tif (compat_get_timespec(&tu, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec_valid(&tu))\n\t\treturn -EINVAL;\n\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep(&tu,\n\t\t\t\trmtp ? (struct timespec __user *)&rmt : NULL,\n\t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n\tset_fs(oldfs);\n\n\tif (ret) {\n\t\tstruct restart_block *restart\n\t\t\t= &current_thread_info()->restart_block;\n\n\t\trestart->fn = compat_nanosleep_restart;\n\t\trestart->nanosleep.compat_rmtp = rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "\nCOMPAT_SYSCALL_DEFINE2(nanosleep, struct compat_timespec __user *, rqtp,\n\t\t       struct compat_timespec __user *, rmtp)\n{\n\tstruct timespec tu, rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\tif (compat_get_timespec(&tu, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec_valid(&tu))\n\t\treturn -EINVAL;\n\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep(&tu,\n\t\t\t\trmtp ? (struct timespec __user *)&rmt : NULL,\n\t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n\tset_fs(oldfs);\n\n\t/*\n\t * hrtimer_nanosleep() can only return 0 or\n\t * -ERESTART_RESTARTBLOCK here because:\n\t *\n\t * - we call it with HRTIMER_MODE_REL and therefor exclude the\n\t *   -ERESTARTNOHAND return path.\n\t *\n\t * - we supply the rmtp argument from the task stack (due to\n\t *   the necessary compat conversion. So the update cannot\n\t *   fail, which excludes the -EFAULT return path as well. If\n\t *   it fails nevertheless we have a bigger problem and wont\n\t *   reach this place anymore.\n\t *\n\t * - if the return value is 0, we do not have to update rmtp\n\t *    because there is no remaining time.\n\t *\n\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the\n\t * core implementation decides to return random nonsense.\n\t */\n\tif (ret == -ERESTART_RESTARTBLOCK) {\n\t\tstruct restart_block *restart\n\t\t\t= &current_thread_info()->restart_block;\n\n\t\trestart->fn = compat_nanosleep_restart;\n\t\trestart->nanosleep.compat_rmtp = rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,26 @@\n \t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n \tset_fs(oldfs);\n \n-\tif (ret) {\n+\t/*\n+\t * hrtimer_nanosleep() can only return 0 or\n+\t * -ERESTART_RESTARTBLOCK here because:\n+\t *\n+\t * - we call it with HRTIMER_MODE_REL and therefor exclude the\n+\t *   -ERESTARTNOHAND return path.\n+\t *\n+\t * - we supply the rmtp argument from the task stack (due to\n+\t *   the necessary compat conversion. So the update cannot\n+\t *   fail, which excludes the -EFAULT return path as well. If\n+\t *   it fails nevertheless we have a bigger problem and wont\n+\t *   reach this place anymore.\n+\t *\n+\t * - if the return value is 0, we do not have to update rmtp\n+\t *    because there is no remaining time.\n+\t *\n+\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the\n+\t * core implementation decides to return random nonsense.\n+\t */\n+\tif (ret == -ERESTART_RESTARTBLOCK) {\n \t\tstruct restart_block *restart\n \t\t\t= &current_thread_info()->restart_block;\n \n@@ -29,6 +48,5 @@\n \t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n \t\t\treturn -EFAULT;\n \t}\n-\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * hrtimer_nanosleep() can only return 0 or",
                "\t * -ERESTART_RESTARTBLOCK here because:",
                "\t *",
                "\t * - we call it with HRTIMER_MODE_REL and therefor exclude the",
                "\t *   -ERESTARTNOHAND return path.",
                "\t *",
                "\t * - we supply the rmtp argument from the task stack (due to",
                "\t *   the necessary compat conversion. So the update cannot",
                "\t *   fail, which excludes the -EFAULT return path as well. If",
                "\t *   it fails nevertheless we have a bigger problem and wont",
                "\t *   reach this place anymore.",
                "\t *",
                "\t * - if the return value is 0, we do not have to update rmtp",
                "\t *    because there is no remaining time.",
                "\t *",
                "\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the",
                "\t * core implementation decides to return random nonsense.",
                "\t */",
                "\tif (ret == -ERESTART_RESTARTBLOCK) {"
            ],
            "deleted": [
                "\tif (ret) {",
                ""
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In kernel/compat.c in the Linux kernel before 3.17, as used in Google Chrome OS and other products, there is a possible out-of-bounds read. restart_syscall uses uninitialized data when restarting compat_sys_nanosleep. NOTE: this is disputed because the code path is unreachable",
        "id": 510
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "static noinline int ntfs_set_ea(struct inode *inode, const char *name,\n\t\t\t\tsize_t name_len, const void *value,\n\t\t\t\tsize_t val_size, int flags, bool locked)\n{\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tstruct ntfs_sb_info *sbi = ni->mi.sbi;\n\tint err;\n\tstruct EA_INFO ea_info;\n\tconst struct EA_INFO *info;\n\tstruct EA_FULL *new_ea;\n\tstruct EA_FULL *ea_all = NULL;\n\tsize_t add, new_pack;\n\tu32 off, size;\n\t__le16 size_pack;\n\tstruct ATTRIB *attr;\n\tstruct ATTR_LIST_ENTRY *le;\n\tstruct mft_inode *mi;\n\tstruct runs_tree ea_run;\n\tu64 new_sz;\n\tvoid *p;\n\n\tif (!locked)\n\t\tni_lock(ni);\n\n\trun_init(&ea_run);\n\n\tif (name_len > 255) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out;\n\t}\n\n\tadd = ALIGN(struct_size(ea_all, name, 1 + name_len + val_size), 4);\n\n\terr = ntfs_read_ea(ni, &ea_all, add, &info);\n\tif (err)\n\t\tgoto out;\n\n\tif (!info) {\n\t\tmemset(&ea_info, 0, sizeof(ea_info));\n\t\tsize = 0;\n\t\tsize_pack = 0;\n\t} else {\n\t\tmemcpy(&ea_info, info, sizeof(ea_info));\n\t\tsize = le32_to_cpu(ea_info.size);\n\t\tsize_pack = ea_info.size_pack;\n\t}\n\n\tif (info && find_ea(ea_all, size, name, name_len, &off)) {\n\t\tstruct EA_FULL *ea;\n\t\tsize_t ea_sz;\n\n\t\tif (flags & XATTR_CREATE) {\n\t\t\terr = -EEXIST;\n\t\t\tgoto out;\n\t\t}\n\n\t\tea = Add2Ptr(ea_all, off);\n\n\t\t/*\n\t\t * Check simple case when we try to insert xattr with the same value\n\t\t * e.g. ntfs_save_wsl_perm\n\t\t */\n\t\tif (val_size && le16_to_cpu(ea->elength) == val_size &&\n\t\t    !memcmp(ea->name + ea->name_len + 1, value, val_size)) {\n\t\t\t/* xattr already contains the required value. */\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Remove current xattr. */\n\t\tif (ea->flags & FILE_NEED_EA)\n\t\t\tle16_add_cpu(&ea_info.count, -1);\n\n\t\tea_sz = unpacked_ea_size(ea);\n\n\t\tle16_add_cpu(&ea_info.size_pack, 0 - packed_ea_size(ea));\n\n\t\tmemmove(ea, Add2Ptr(ea, ea_sz), size - off - ea_sz);\n\n\t\tsize -= ea_sz;\n\t\tmemset(Add2Ptr(ea_all, size), 0, ea_sz);\n\n\t\tea_info.size = cpu_to_le32(size);\n\n\t\tif ((flags & XATTR_REPLACE) && !val_size) {\n\t\t\t/* Remove xattr. */\n\t\t\tgoto update_ea;\n\t\t}\n\t} else {\n\t\tif (flags & XATTR_REPLACE) {\n\t\t\terr = -ENODATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!ea_all) {\n\t\t\tea_all = kzalloc(add, GFP_NOFS);\n\t\t\tif (!ea_all) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Append new xattr. */\n\tnew_ea = Add2Ptr(ea_all, size);\n\tnew_ea->size = cpu_to_le32(add);\n\tnew_ea->flags = 0;\n\tnew_ea->name_len = name_len;\n\tnew_ea->elength = cpu_to_le16(val_size);\n\tmemcpy(new_ea->name, name, name_len);\n\tnew_ea->name[name_len] = 0;\n\tmemcpy(new_ea->name + name_len + 1, value, val_size);\n\tnew_pack = le16_to_cpu(ea_info.size_pack) + packed_ea_size(new_ea);\n\tea_info.size_pack = cpu_to_le16(new_pack);\n\t/* New size of ATTR_EA. */\n\tsize += add;\n\tea_info.size = cpu_to_le32(size);\n\n\t/*\n\t * 1. Check ea_info.size_pack for overflow.\n\t * 2. New attibute size must fit value from $AttrDef\n\t */\n\tif (new_pack > 0xffff || size > sbi->ea_max_size) {\n\t\tntfs_inode_warn(\n\t\t\tinode,\n\t\t\t\"The size of extended attributes must not exceed 64KiB\");\n\t\terr = -EFBIG; // -EINVAL?\n\t\tgoto out;\n\t}\n\nupdate_ea:\n\n\tif (!info) {\n\t\t/* Create xattr. */\n\t\tif (!size) {\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = ni_insert_resident(ni, sizeof(struct EA_INFO),\n\t\t\t\t\t ATTR_EA_INFO, NULL, 0, NULL, NULL,\n\t\t\t\t\t NULL);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\terr = ni_insert_resident(ni, 0, ATTR_EA, NULL, 0, NULL, NULL,\n\t\t\t\t\t NULL);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tnew_sz = size;\n\terr = attr_set_size(ni, ATTR_EA, NULL, 0, &ea_run, new_sz, &new_sz,\n\t\t\t    false, NULL);\n\tif (err)\n\t\tgoto out;\n\n\tle = NULL;\n\tattr = ni_find_attr(ni, NULL, &le, ATTR_EA_INFO, NULL, 0, NULL, &mi);\n\tif (!attr) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!size) {\n\t\t/* Delete xattr, ATTR_EA_INFO */\n\t\tni_remove_attr_le(ni, attr, mi, le);\n\t} else {\n\t\tp = resident_data_ex(attr, sizeof(struct EA_INFO));\n\t\tif (!p) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(p, &ea_info, sizeof(struct EA_INFO));\n\t\tmi->dirty = true;\n\t}\n\n\tle = NULL;\n\tattr = ni_find_attr(ni, NULL, &le, ATTR_EA, NULL, 0, NULL, &mi);\n\tif (!attr) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!size) {\n\t\t/* Delete xattr, ATTR_EA */\n\t\tni_remove_attr_le(ni, attr, mi, le);\n\t} else if (attr->non_res) {\n\t\terr = attr_load_runs_range(ni, ATTR_EA, NULL, 0, &ea_run, 0,\n\t\t\t\t\t   size);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\terr = ntfs_sb_write_run(sbi, &ea_run, 0, ea_all, size, 0);\n\t\tif (err)\n\t\t\tgoto out;\n\t} else {\n\t\tp = resident_data_ex(attr, size);\n\t\tif (!p) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(p, ea_all, size);\n\t\tmi->dirty = true;\n\t}\n\n\t/* Check if we delete the last xattr. */\n\tif (size)\n\t\tni->ni_flags |= NI_FLAG_EA;\n\telse\n\t\tni->ni_flags &= ~NI_FLAG_EA;\n\n\tif (ea_info.size_pack != size_pack)\n\t\tni->ni_flags |= NI_FLAG_UPDATE_PARENT;\n\tmark_inode_dirty(&ni->vfs_inode);\n\nout:\n\tif (!locked)\n\t\tni_unlock(ni);\n\n\trun_close(&ea_run);\n\tkfree(ea_all);\n\n\treturn err;\n}",
        "code_after_change": "static noinline int ntfs_set_ea(struct inode *inode, const char *name,\n\t\t\t\tsize_t name_len, const void *value,\n\t\t\t\tsize_t val_size, int flags, bool locked)\n{\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tstruct ntfs_sb_info *sbi = ni->mi.sbi;\n\tint err;\n\tstruct EA_INFO ea_info;\n\tconst struct EA_INFO *info;\n\tstruct EA_FULL *new_ea;\n\tstruct EA_FULL *ea_all = NULL;\n\tsize_t add, new_pack;\n\tu32 off, size, ea_sz;\n\t__le16 size_pack;\n\tstruct ATTRIB *attr;\n\tstruct ATTR_LIST_ENTRY *le;\n\tstruct mft_inode *mi;\n\tstruct runs_tree ea_run;\n\tu64 new_sz;\n\tvoid *p;\n\n\tif (!locked)\n\t\tni_lock(ni);\n\n\trun_init(&ea_run);\n\n\tif (name_len > 255) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out;\n\t}\n\n\tadd = ALIGN(struct_size(ea_all, name, 1 + name_len + val_size), 4);\n\n\terr = ntfs_read_ea(ni, &ea_all, add, &info);\n\tif (err)\n\t\tgoto out;\n\n\tif (!info) {\n\t\tmemset(&ea_info, 0, sizeof(ea_info));\n\t\tsize = 0;\n\t\tsize_pack = 0;\n\t} else {\n\t\tmemcpy(&ea_info, info, sizeof(ea_info));\n\t\tsize = le32_to_cpu(ea_info.size);\n\t\tsize_pack = ea_info.size_pack;\n\t}\n\n\tif (info && find_ea(ea_all, size, name, name_len, &off, &ea_sz)) {\n\t\tstruct EA_FULL *ea;\n\n\t\tif (flags & XATTR_CREATE) {\n\t\t\terr = -EEXIST;\n\t\t\tgoto out;\n\t\t}\n\n\t\tea = Add2Ptr(ea_all, off);\n\n\t\t/*\n\t\t * Check simple case when we try to insert xattr with the same value\n\t\t * e.g. ntfs_save_wsl_perm\n\t\t */\n\t\tif (val_size && le16_to_cpu(ea->elength) == val_size &&\n\t\t    !memcmp(ea->name + ea->name_len + 1, value, val_size)) {\n\t\t\t/* xattr already contains the required value. */\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Remove current xattr. */\n\t\tif (ea->flags & FILE_NEED_EA)\n\t\t\tle16_add_cpu(&ea_info.count, -1);\n\n\t\tle16_add_cpu(&ea_info.size_pack, 0 - packed_ea_size(ea));\n\n\t\tmemmove(ea, Add2Ptr(ea, ea_sz), size - off - ea_sz);\n\n\t\tsize -= ea_sz;\n\t\tmemset(Add2Ptr(ea_all, size), 0, ea_sz);\n\n\t\tea_info.size = cpu_to_le32(size);\n\n\t\tif ((flags & XATTR_REPLACE) && !val_size) {\n\t\t\t/* Remove xattr. */\n\t\t\tgoto update_ea;\n\t\t}\n\t} else {\n\t\tif (flags & XATTR_REPLACE) {\n\t\t\terr = -ENODATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!ea_all) {\n\t\t\tea_all = kzalloc(add, GFP_NOFS);\n\t\t\tif (!ea_all) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Append new xattr. */\n\tnew_ea = Add2Ptr(ea_all, size);\n\tnew_ea->size = cpu_to_le32(add);\n\tnew_ea->flags = 0;\n\tnew_ea->name_len = name_len;\n\tnew_ea->elength = cpu_to_le16(val_size);\n\tmemcpy(new_ea->name, name, name_len);\n\tnew_ea->name[name_len] = 0;\n\tmemcpy(new_ea->name + name_len + 1, value, val_size);\n\tnew_pack = le16_to_cpu(ea_info.size_pack) + packed_ea_size(new_ea);\n\tea_info.size_pack = cpu_to_le16(new_pack);\n\t/* New size of ATTR_EA. */\n\tsize += add;\n\tea_info.size = cpu_to_le32(size);\n\n\t/*\n\t * 1. Check ea_info.size_pack for overflow.\n\t * 2. New attibute size must fit value from $AttrDef\n\t */\n\tif (new_pack > 0xffff || size > sbi->ea_max_size) {\n\t\tntfs_inode_warn(\n\t\t\tinode,\n\t\t\t\"The size of extended attributes must not exceed 64KiB\");\n\t\terr = -EFBIG; // -EINVAL?\n\t\tgoto out;\n\t}\n\nupdate_ea:\n\n\tif (!info) {\n\t\t/* Create xattr. */\n\t\tif (!size) {\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = ni_insert_resident(ni, sizeof(struct EA_INFO),\n\t\t\t\t\t ATTR_EA_INFO, NULL, 0, NULL, NULL,\n\t\t\t\t\t NULL);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\terr = ni_insert_resident(ni, 0, ATTR_EA, NULL, 0, NULL, NULL,\n\t\t\t\t\t NULL);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tnew_sz = size;\n\terr = attr_set_size(ni, ATTR_EA, NULL, 0, &ea_run, new_sz, &new_sz,\n\t\t\t    false, NULL);\n\tif (err)\n\t\tgoto out;\n\n\tle = NULL;\n\tattr = ni_find_attr(ni, NULL, &le, ATTR_EA_INFO, NULL, 0, NULL, &mi);\n\tif (!attr) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!size) {\n\t\t/* Delete xattr, ATTR_EA_INFO */\n\t\tni_remove_attr_le(ni, attr, mi, le);\n\t} else {\n\t\tp = resident_data_ex(attr, sizeof(struct EA_INFO));\n\t\tif (!p) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(p, &ea_info, sizeof(struct EA_INFO));\n\t\tmi->dirty = true;\n\t}\n\n\tle = NULL;\n\tattr = ni_find_attr(ni, NULL, &le, ATTR_EA, NULL, 0, NULL, &mi);\n\tif (!attr) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!size) {\n\t\t/* Delete xattr, ATTR_EA */\n\t\tni_remove_attr_le(ni, attr, mi, le);\n\t} else if (attr->non_res) {\n\t\terr = attr_load_runs_range(ni, ATTR_EA, NULL, 0, &ea_run, 0,\n\t\t\t\t\t   size);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\terr = ntfs_sb_write_run(sbi, &ea_run, 0, ea_all, size, 0);\n\t\tif (err)\n\t\t\tgoto out;\n\t} else {\n\t\tp = resident_data_ex(attr, size);\n\t\tif (!p) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(p, ea_all, size);\n\t\tmi->dirty = true;\n\t}\n\n\t/* Check if we delete the last xattr. */\n\tif (size)\n\t\tni->ni_flags |= NI_FLAG_EA;\n\telse\n\t\tni->ni_flags &= ~NI_FLAG_EA;\n\n\tif (ea_info.size_pack != size_pack)\n\t\tni->ni_flags |= NI_FLAG_UPDATE_PARENT;\n\tmark_inode_dirty(&ni->vfs_inode);\n\nout:\n\tif (!locked)\n\t\tni_unlock(ni);\n\n\trun_close(&ea_run);\n\tkfree(ea_all);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \tstruct EA_FULL *new_ea;\n \tstruct EA_FULL *ea_all = NULL;\n \tsize_t add, new_pack;\n-\tu32 off, size;\n+\tu32 off, size, ea_sz;\n \t__le16 size_pack;\n \tstruct ATTRIB *attr;\n \tstruct ATTR_LIST_ENTRY *le;\n@@ -45,9 +45,8 @@\n \t\tsize_pack = ea_info.size_pack;\n \t}\n \n-\tif (info && find_ea(ea_all, size, name, name_len, &off)) {\n+\tif (info && find_ea(ea_all, size, name, name_len, &off, &ea_sz)) {\n \t\tstruct EA_FULL *ea;\n-\t\tsize_t ea_sz;\n \n \t\tif (flags & XATTR_CREATE) {\n \t\t\terr = -EEXIST;\n@@ -69,8 +68,6 @@\n \t\t/* Remove current xattr. */\n \t\tif (ea->flags & FILE_NEED_EA)\n \t\t\tle16_add_cpu(&ea_info.count, -1);\n-\n-\t\tea_sz = unpacked_ea_size(ea);\n \n \t\tle16_add_cpu(&ea_info.size_pack, 0 - packed_ea_size(ea));\n ",
        "function_modified_lines": {
            "added": [
                "\tu32 off, size, ea_sz;",
                "\tif (info && find_ea(ea_all, size, name, name_len, &off, &ea_sz)) {"
            ],
            "deleted": [
                "\tu32 off, size;",
                "\tif (info && find_ea(ea_all, size, name, name_len, &off)) {",
                "\t\tsize_t ea_sz;",
                "",
                "\t\tea_sz = unpacked_ea_size(ea);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3798
    },
    {
        "cve_id": "CVE-2023-3268",
        "code_before_change": "static size_t relay_file_read_start_pos(struct rchan_buf *buf)\n{\n\tsize_t read_subbuf, padding, padding_start, padding_end;\n\tsize_t subbuf_size = buf->chan->subbuf_size;\n\tsize_t n_subbufs = buf->chan->n_subbufs;\n\tsize_t consumed = buf->subbufs_consumed % n_subbufs;\n\tsize_t read_pos = consumed * subbuf_size + buf->bytes_consumed;\n\n\tread_subbuf = read_pos / subbuf_size;\n\tpadding = buf->padding[read_subbuf];\n\tpadding_start = (read_subbuf + 1) * subbuf_size - padding;\n\tpadding_end = (read_subbuf + 1) * subbuf_size;\n\tif (read_pos >= padding_start && read_pos < padding_end) {\n\t\tread_subbuf = (read_subbuf + 1) % n_subbufs;\n\t\tread_pos = read_subbuf * subbuf_size;\n\t}\n\n\treturn read_pos;\n}",
        "code_after_change": "static size_t relay_file_read_start_pos(struct rchan_buf *buf)\n{\n\tsize_t read_subbuf, padding, padding_start, padding_end;\n\tsize_t subbuf_size = buf->chan->subbuf_size;\n\tsize_t n_subbufs = buf->chan->n_subbufs;\n\tsize_t consumed = buf->subbufs_consumed % n_subbufs;\n\tsize_t read_pos = (consumed * subbuf_size + buf->bytes_consumed)\n\t\t\t% (n_subbufs * subbuf_size);\n\n\tread_subbuf = read_pos / subbuf_size;\n\tpadding = buf->padding[read_subbuf];\n\tpadding_start = (read_subbuf + 1) * subbuf_size - padding;\n\tpadding_end = (read_subbuf + 1) * subbuf_size;\n\tif (read_pos >= padding_start && read_pos < padding_end) {\n\t\tread_subbuf = (read_subbuf + 1) % n_subbufs;\n\t\tread_pos = read_subbuf * subbuf_size;\n\t}\n\n\treturn read_pos;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,8 @@\n \tsize_t subbuf_size = buf->chan->subbuf_size;\n \tsize_t n_subbufs = buf->chan->n_subbufs;\n \tsize_t consumed = buf->subbufs_consumed % n_subbufs;\n-\tsize_t read_pos = consumed * subbuf_size + buf->bytes_consumed;\n+\tsize_t read_pos = (consumed * subbuf_size + buf->bytes_consumed)\n+\t\t\t% (n_subbufs * subbuf_size);\n \n \tread_subbuf = read_pos / subbuf_size;\n \tpadding = buf->padding[read_subbuf];",
        "function_modified_lines": {
            "added": [
                "\tsize_t read_pos = (consumed * subbuf_size + buf->bytes_consumed)",
                "\t\t\t% (n_subbufs * subbuf_size);"
            ],
            "deleted": [
                "\tsize_t read_pos = consumed * subbuf_size + buf->bytes_consumed;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out of bounds (OOB) memory access flaw was found in the Linux kernel in relay_file_read_start_pos in kernel/relay.c in the relayfs. This flaw could allow a local attacker to crash the system or leak kernel internal information.",
        "id": 4052
    },
    {
        "cve_id": "CVE-2017-9074",
        "code_before_change": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,\n\t\t\t\t\t netdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *packet_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\t__wsum csum;\n\tint tnl_hlen;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\t/* Set the IPv6 fragment id if not set yet */\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\tif (skb->encapsulation && skb_shinfo(skb)->gso_type &\n\t    (SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))\n\t\tsegs = skb_udp_tunnel_segment(skb, features, true);\n\telse {\n\t\tconst struct ipv6hdr *ipv6h;\n\t\tstruct udphdr *uh;\n\n\t\tif (!pskb_may_pull(skb, sizeof(struct udphdr)))\n\t\t\tgoto out;\n\n\t\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t\t * do checksum of UDP packets sent as multiple IP fragments.\n\t\t */\n\n\t\tuh = udp_hdr(skb);\n\t\tipv6h = ipv6_hdr(skb);\n\n\t\tuh->check = 0;\n\t\tcsum = skb_checksum(skb, 0, skb->len, 0);\n\t\tuh->check = udp_v6_check(skb->len, &ipv6h->saddr,\n\t\t\t\t\t  &ipv6h->daddr, csum);\n\t\tif (uh->check == 0)\n\t\t\tuh->check = CSUM_MANGLED_0;\n\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\t/* If there is no outer header we can fake a checksum offload\n\t\t * due to the fact that we have already done the checksum in\n\t\t * software prior to segmenting the frame.\n\t\t */\n\t\tif (!skb->encap_hdr_csum)\n\t\t\tfeatures |= NETIF_F_HW_CSUM;\n\n\t\t/* Check if there is enough headroom to insert fragment header. */\n\t\ttnl_hlen = skb_tnl_header_len(skb);\n\t\tif (skb->mac_header < (tnl_hlen + frag_hdr_sz)) {\n\t\t\tif (gso_pskb_expand_head(skb, tnl_hlen + frag_hdr_sz))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t\t * bytes to insert fragment header.\n\t\t */\n\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\tnexthdr = *prevhdr;\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +\n\t\t\t     unfrag_ip6hlen + tnl_hlen;\n\t\tpacket_start = (u8 *) skb->head + SKB_GSO_CB(skb)->mac_offset;\n\t\tmemmove(packet_start-frag_hdr_sz, packet_start, unfrag_len);\n\n\t\tSKB_GSO_CB(skb)->mac_offset -= frag_hdr_sz;\n\t\tskb->mac_header -= frag_hdr_sz;\n\t\tskb->network_header -= frag_hdr_sz;\n\n\t\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\t\tfptr->nexthdr = nexthdr;\n\t\tfptr->reserved = 0;\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\t\tfptr->identification = skb_shinfo(skb)->ip6_frag_id;\n\n\t\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t\t * fragment header are updated in ipv6_gso_segment()\n\t\t */\n\t\tsegs = skb_segment(skb, features);\n\t}\n\nout:\n\treturn segs;\n}",
        "code_after_change": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,\n\t\t\t\t\t netdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *packet_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\t__wsum csum;\n\tint tnl_hlen;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\t/* Set the IPv6 fragment id if not set yet */\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\tif (skb->encapsulation && skb_shinfo(skb)->gso_type &\n\t    (SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))\n\t\tsegs = skb_udp_tunnel_segment(skb, features, true);\n\telse {\n\t\tconst struct ipv6hdr *ipv6h;\n\t\tstruct udphdr *uh;\n\n\t\tif (!pskb_may_pull(skb, sizeof(struct udphdr)))\n\t\t\tgoto out;\n\n\t\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t\t * do checksum of UDP packets sent as multiple IP fragments.\n\t\t */\n\n\t\tuh = udp_hdr(skb);\n\t\tipv6h = ipv6_hdr(skb);\n\n\t\tuh->check = 0;\n\t\tcsum = skb_checksum(skb, 0, skb->len, 0);\n\t\tuh->check = udp_v6_check(skb->len, &ipv6h->saddr,\n\t\t\t\t\t  &ipv6h->daddr, csum);\n\t\tif (uh->check == 0)\n\t\t\tuh->check = CSUM_MANGLED_0;\n\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\t/* If there is no outer header we can fake a checksum offload\n\t\t * due to the fact that we have already done the checksum in\n\t\t * software prior to segmenting the frame.\n\t\t */\n\t\tif (!skb->encap_hdr_csum)\n\t\t\tfeatures |= NETIF_F_HW_CSUM;\n\n\t\t/* Check if there is enough headroom to insert fragment header. */\n\t\ttnl_hlen = skb_tnl_header_len(skb);\n\t\tif (skb->mac_header < (tnl_hlen + frag_hdr_sz)) {\n\t\t\tif (gso_pskb_expand_head(skb, tnl_hlen + frag_hdr_sz))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t\t * bytes to insert fragment header.\n\t\t */\n\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\tif (unfrag_ip6hlen < 0)\n\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n\t\tnexthdr = *prevhdr;\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +\n\t\t\t     unfrag_ip6hlen + tnl_hlen;\n\t\tpacket_start = (u8 *) skb->head + SKB_GSO_CB(skb)->mac_offset;\n\t\tmemmove(packet_start-frag_hdr_sz, packet_start, unfrag_len);\n\n\t\tSKB_GSO_CB(skb)->mac_offset -= frag_hdr_sz;\n\t\tskb->mac_header -= frag_hdr_sz;\n\t\tskb->network_header -= frag_hdr_sz;\n\n\t\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\t\tfptr->nexthdr = nexthdr;\n\t\tfptr->reserved = 0;\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\t\tfptr->identification = skb_shinfo(skb)->ip6_frag_id;\n\n\t\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t\t * fragment header are updated in ipv6_gso_segment()\n\t\t */\n\t\tsegs = skb_segment(skb, features);\n\t}\n\nout:\n\treturn segs;\n}",
        "patch": "--- code before\n+++ code after\n@@ -72,6 +72,8 @@\n \t\t * bytes to insert fragment header.\n \t\t */\n \t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n+\t\tif (unfrag_ip6hlen < 0)\n+\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n \t\tnexthdr = *prevhdr;\n \t\t*prevhdr = NEXTHDR_FRAGMENT;\n \t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +",
        "function_modified_lines": {
            "added": [
                "\t\tif (unfrag_ip6hlen < 0)",
                "\t\t\treturn ERR_PTR(unfrag_ip6hlen);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The IPv6 fragmentation implementation in the Linux kernel through 4.11.1 does not consider that the nexthdr field may be associated with an invalid option, which allows local users to cause a denial of service (out-of-bounds read and BUG) or possibly have unspecified other impact via crafted socket and send system calls.",
        "id": 1563
    },
    {
        "cve_id": "CVE-2016-10208",
        "code_before_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}",
        "code_after_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) >= db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -519,6 +519,15 @@\n \t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n \tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n \t\t   EXT4_DESC_PER_BLOCK(sb);\n+\tif (ext4_has_feature_meta_bg(sb)) {\n+\t\tif (le32_to_cpu(es->s_first_meta_bg) >= db_count) {\n+\t\t\text4_msg(sb, KERN_WARNING,\n+\t\t\t\t \"first meta block group too large: %u \"\n+\t\t\t\t \"(group descriptor block count %u)\",\n+\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n+\t\t\tgoto failed_mount;\n+\t\t}\n+\t}\n \tsbi->s_group_desc = ext4_kvmalloc(db_count *\n \t\t\t\t\t  sizeof(struct buffer_head *),\n \t\t\t\t\t  GFP_KERNEL);",
        "function_modified_lines": {
            "added": [
                "\tif (ext4_has_feature_meta_bg(sb)) {",
                "\t\tif (le32_to_cpu(es->s_first_meta_bg) >= db_count) {",
                "\t\t\text4_msg(sb, KERN_WARNING,",
                "\t\t\t\t \"first meta block group too large: %u \"",
                "\t\t\t\t \"(group descriptor block count %u)\",",
                "\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);",
                "\t\t\tgoto failed_mount;",
                "\t\t}",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel through 4.9.8 does not properly validate meta block groups, which allows physically proximate attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image.",
        "id": 900
    },
    {
        "cve_id": "CVE-2019-19449",
        "code_before_change": "static int sanity_check_raw_super(struct f2fs_sb_info *sbi,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tblock_t segment_count, segs_per_sec, secs_per_zone, segment_count_main;\n\tblock_t total_sections, blocks_per_seg;\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tunsigned int blocksize;\n\tsize_t crc_offset = 0;\n\t__u32 crc = 0;\n\n\tif (le32_to_cpu(raw_super->magic) != F2FS_SUPER_MAGIC) {\n\t\tf2fs_info(sbi, \"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\t  F2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check checksum_offset and crc in superblock */\n\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_SB_CHKSUM)) {\n\t\tcrc_offset = le32_to_cpu(raw_super->checksum_offset);\n\t\tif (crc_offset !=\n\t\t\toffsetof(struct f2fs_super_block, crc)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum offset: %zu\",\n\t\t\t\t  crc_offset);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t\tcrc = le32_to_cpu(raw_super->crc);\n\t\tif (!f2fs_crc_valid(sbi, crc, raw_super, crc_offset)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum value: %u\", crc);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid page_cache_size (%lu), supports only 4KB\",\n\t\t\t  PAGE_SIZE);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_info(sbi, \"Invalid blocksize (%u), supports only 4KB\",\n\t\t\t  blocksize);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check log blocks per segment */\n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_info(sbi, \"Invalid log blocks per segment (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectorsize (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tsegment_count = le32_to_cpu(raw_super->segment_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tsegs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsecs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\ttotal_sections = le32_to_cpu(raw_super->section_count);\n\n\t/* blocks_per_seg should be 512, given the above check */\n\tblocks_per_seg = 1 << le32_to_cpu(raw_super->log_blocks_per_seg);\n\n\tif (segment_count > F2FS_MAX_SEGMENT ||\n\t\t\t\tsegment_count < F2FS_MIN_SEGMENTS) {\n\t\tf2fs_info(sbi, \"Invalid segment count (%u)\", segment_count);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (total_sections > segment_count_main || total_sections < 1 ||\n\t\t\tsegs_per_sec > segment_count || !segs_per_sec) {\n\t\tf2fs_info(sbi, \"Invalid segment/section count (%u, %u x %u)\",\n\t\t\t  segment_count, total_sections, segs_per_sec);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif ((segment_count / segs_per_sec) < total_sections) {\n\t\tf2fs_info(sbi, \"Small segment_count (%u < %u * %u)\",\n\t\t\t  segment_count, segs_per_sec, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (segment_count > (le64_to_cpu(raw_super->block_count) >> 9)) {\n\t\tf2fs_info(sbi, \"Wrong segment_count / block_count (%u > %llu)\",\n\t\t\t  segment_count, le64_to_cpu(raw_super->block_count));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (RDEV(0).path[0]) {\n\t\tblock_t dev_seg_count = le32_to_cpu(RDEV(0).total_segments);\n\t\tint i = 1;\n\n\t\twhile (i < MAX_DEVICES && RDEV(i).path[0]) {\n\t\t\tdev_seg_count += le32_to_cpu(RDEV(i).total_segments);\n\t\t\ti++;\n\t\t}\n\t\tif (segment_count != dev_seg_count) {\n\t\t\tf2fs_info(sbi, \"Segment count (%u) mismatch with total segments from devices (%u)\",\n\t\t\t\t\tsegment_count, dev_seg_count);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t} else {\n\t\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_BLKZONED) &&\n\t\t\t\t\t!bdev_is_zoned(sbi->sb->s_bdev)) {\n\t\t\tf2fs_info(sbi, \"Zoned block device path is missing\");\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\tif (secs_per_zone > total_sections || !secs_per_zone) {\n\t\tf2fs_info(sbi, \"Wrong secs_per_zone / total_sections (%u, %u)\",\n\t\t\t  secs_per_zone, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->extension_count) > F2FS_MAX_EXTENSION ||\n\t\t\traw_super->hot_ext_count > F2FS_MAX_EXTENSION ||\n\t\t\t(le32_to_cpu(raw_super->extension_count) +\n\t\t\traw_super->hot_ext_count) > F2FS_MAX_EXTENSION) {\n\t\tf2fs_info(sbi, \"Corrupted extension count (%u + %u > %u)\",\n\t\t\t  le32_to_cpu(raw_super->extension_count),\n\t\t\t  raw_super->hot_ext_count,\n\t\t\t  F2FS_MAX_EXTENSION);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (le32_to_cpu(raw_super->cp_payload) >\n\t\t\t\t(blocks_per_seg - F2FS_CP_PACKS)) {\n\t\tf2fs_info(sbi, \"Insane cp_payload (%u > %u)\",\n\t\t\t  le32_to_cpu(raw_super->cp_payload),\n\t\t\t  blocks_per_seg - F2FS_CP_PACKS);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check reserved ino info */\n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_info(sbi, \"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\t  le32_to_cpu(raw_super->node_ino),\n\t\t\t  le32_to_cpu(raw_super->meta_ino),\n\t\t\t  le32_to_cpu(raw_super->root_ino));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n\tif (sanity_check_area_boundary(sbi, bh))\n\t\treturn -EFSCORRUPTED;\n\n\treturn 0;\n}",
        "code_after_change": "static int sanity_check_raw_super(struct f2fs_sb_info *sbi,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tblock_t segment_count, segs_per_sec, secs_per_zone, segment_count_main;\n\tblock_t total_sections, blocks_per_seg;\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tunsigned int blocksize;\n\tsize_t crc_offset = 0;\n\t__u32 crc = 0;\n\n\tif (le32_to_cpu(raw_super->magic) != F2FS_SUPER_MAGIC) {\n\t\tf2fs_info(sbi, \"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\t  F2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check checksum_offset and crc in superblock */\n\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_SB_CHKSUM)) {\n\t\tcrc_offset = le32_to_cpu(raw_super->checksum_offset);\n\t\tif (crc_offset !=\n\t\t\toffsetof(struct f2fs_super_block, crc)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum offset: %zu\",\n\t\t\t\t  crc_offset);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t\tcrc = le32_to_cpu(raw_super->crc);\n\t\tif (!f2fs_crc_valid(sbi, crc, raw_super, crc_offset)) {\n\t\t\tf2fs_info(sbi, \"Invalid SB checksum value: %u\", crc);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid page_cache_size (%lu), supports only 4KB\",\n\t\t\t  PAGE_SIZE);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_info(sbi, \"Invalid blocksize (%u), supports only 4KB\",\n\t\t\t  blocksize);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check log blocks per segment */\n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_info(sbi, \"Invalid log blocks per segment (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectorsize (%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_info(sbi, \"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\t  le32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\t  le32_to_cpu(raw_super->log_sectorsize));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tsegment_count = le32_to_cpu(raw_super->segment_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tsegs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsecs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\ttotal_sections = le32_to_cpu(raw_super->section_count);\n\n\t/* blocks_per_seg should be 512, given the above check */\n\tblocks_per_seg = 1 << le32_to_cpu(raw_super->log_blocks_per_seg);\n\n\tif (segment_count > F2FS_MAX_SEGMENT ||\n\t\t\t\tsegment_count < F2FS_MIN_SEGMENTS) {\n\t\tf2fs_info(sbi, \"Invalid segment count (%u)\", segment_count);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (total_sections > segment_count_main || total_sections < 1 ||\n\t\t\tsegs_per_sec > segment_count || !segs_per_sec) {\n\t\tf2fs_info(sbi, \"Invalid segment/section count (%u, %u x %u)\",\n\t\t\t  segment_count, total_sections, segs_per_sec);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (segment_count_main != total_sections * segs_per_sec) {\n\t\tf2fs_info(sbi, \"Invalid segment/section count (%u != %u * %u)\",\n\t\t\t  segment_count_main, total_sections, segs_per_sec);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif ((segment_count / segs_per_sec) < total_sections) {\n\t\tf2fs_info(sbi, \"Small segment_count (%u < %u * %u)\",\n\t\t\t  segment_count, segs_per_sec, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (segment_count > (le64_to_cpu(raw_super->block_count) >> 9)) {\n\t\tf2fs_info(sbi, \"Wrong segment_count / block_count (%u > %llu)\",\n\t\t\t  segment_count, le64_to_cpu(raw_super->block_count));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (RDEV(0).path[0]) {\n\t\tblock_t dev_seg_count = le32_to_cpu(RDEV(0).total_segments);\n\t\tint i = 1;\n\n\t\twhile (i < MAX_DEVICES && RDEV(i).path[0]) {\n\t\t\tdev_seg_count += le32_to_cpu(RDEV(i).total_segments);\n\t\t\ti++;\n\t\t}\n\t\tif (segment_count != dev_seg_count) {\n\t\t\tf2fs_info(sbi, \"Segment count (%u) mismatch with total segments from devices (%u)\",\n\t\t\t\t\tsegment_count, dev_seg_count);\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t} else {\n\t\tif (__F2FS_HAS_FEATURE(raw_super, F2FS_FEATURE_BLKZONED) &&\n\t\t\t\t\t!bdev_is_zoned(sbi->sb->s_bdev)) {\n\t\t\tf2fs_info(sbi, \"Zoned block device path is missing\");\n\t\t\treturn -EFSCORRUPTED;\n\t\t}\n\t}\n\n\tif (secs_per_zone > total_sections || !secs_per_zone) {\n\t\tf2fs_info(sbi, \"Wrong secs_per_zone / total_sections (%u, %u)\",\n\t\t\t  secs_per_zone, total_sections);\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (le32_to_cpu(raw_super->extension_count) > F2FS_MAX_EXTENSION ||\n\t\t\traw_super->hot_ext_count > F2FS_MAX_EXTENSION ||\n\t\t\t(le32_to_cpu(raw_super->extension_count) +\n\t\t\traw_super->hot_ext_count) > F2FS_MAX_EXTENSION) {\n\t\tf2fs_info(sbi, \"Corrupted extension count (%u + %u > %u)\",\n\t\t\t  le32_to_cpu(raw_super->extension_count),\n\t\t\t  raw_super->hot_ext_count,\n\t\t\t  F2FS_MAX_EXTENSION);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\tif (le32_to_cpu(raw_super->cp_payload) >\n\t\t\t\t(blocks_per_seg - F2FS_CP_PACKS)) {\n\t\tf2fs_info(sbi, \"Insane cp_payload (%u > %u)\",\n\t\t\t  le32_to_cpu(raw_super->cp_payload),\n\t\t\t  blocks_per_seg - F2FS_CP_PACKS);\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check reserved ino info */\n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_info(sbi, \"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\t  le32_to_cpu(raw_super->node_ino),\n\t\t\t  le32_to_cpu(raw_super->meta_ino),\n\t\t\t  le32_to_cpu(raw_super->root_ino));\n\t\treturn -EFSCORRUPTED;\n\t}\n\n\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n\tif (sanity_check_area_boundary(sbi, bh))\n\t\treturn -EFSCORRUPTED;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -93,6 +93,12 @@\n \t\treturn -EFSCORRUPTED;\n \t}\n \n+\tif (segment_count_main != total_sections * segs_per_sec) {\n+\t\tf2fs_info(sbi, \"Invalid segment/section count (%u != %u * %u)\",\n+\t\t\t  segment_count_main, total_sections, segs_per_sec);\n+\t\treturn -EFSCORRUPTED;\n+\t}\n+\n \tif ((segment_count / segs_per_sec) < total_sections) {\n \t\tf2fs_info(sbi, \"Small segment_count (%u < %u * %u)\",\n \t\t\t  segment_count, segs_per_sec, total_sections);",
        "function_modified_lines": {
            "added": [
                "\tif (segment_count_main != total_sections * segs_per_sec) {",
                "\t\tf2fs_info(sbi, \"Invalid segment/section count (%u != %u * %u)\",",
                "\t\t\t  segment_count_main, total_sections, segs_per_sec);",
                "\t\treturn -EFSCORRUPTED;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted f2fs filesystem image can lead to slab-out-of-bounds read access in f2fs_build_segment_manager in fs/f2fs/segment.c, related to init_min_max_mtime in fs/f2fs/segment.c (because the second argument to get_seg_entry is not validated).",
        "id": 2196
    },
    {
        "cve_id": "CVE-2021-0941",
        "code_before_change": "static inline int __bpf_skb_change_head(struct sk_buff *skb, u32 head_room,\n\t\t\t\t\tu64 flags)\n{\n\tu32 max_len = __bpf_skb_max_len(skb);\n\tu32 new_len = skb->len + head_room;\n\tint ret;\n\n\tif (unlikely(flags || (!skb_is_gso(skb) && new_len > max_len) ||\n\t\t     new_len < skb->len))\n\t\treturn -EINVAL;\n\n\tret = skb_cow(skb, head_room);\n\tif (likely(!ret)) {\n\t\t/* Idea for this helper is that we currently only\n\t\t * allow to expand on mac header. This means that\n\t\t * skb->protocol network header, etc, stay as is.\n\t\t * Compared to bpf_skb_change_tail(), we're more\n\t\t * flexible due to not needing to linearize or\n\t\t * reset GSO. Intention for this helper is to be\n\t\t * used by an L3 skb that needs to push mac header\n\t\t * for redirection into L2 device.\n\t\t */\n\t\t__skb_push(skb, head_room);\n\t\tmemset(skb->data, 0, head_room);\n\t\tskb_reset_mac_header(skb);\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static inline int __bpf_skb_change_head(struct sk_buff *skb, u32 head_room,\n\t\t\t\t\tu64 flags)\n{\n\tu32 max_len = BPF_SKB_MAX_LEN;\n\tu32 new_len = skb->len + head_room;\n\tint ret;\n\n\tif (unlikely(flags || (!skb_is_gso(skb) && new_len > max_len) ||\n\t\t     new_len < skb->len))\n\t\treturn -EINVAL;\n\n\tret = skb_cow(skb, head_room);\n\tif (likely(!ret)) {\n\t\t/* Idea for this helper is that we currently only\n\t\t * allow to expand on mac header. This means that\n\t\t * skb->protocol network header, etc, stay as is.\n\t\t * Compared to bpf_skb_change_tail(), we're more\n\t\t * flexible due to not needing to linearize or\n\t\t * reset GSO. Intention for this helper is to be\n\t\t * used by an L3 skb that needs to push mac header\n\t\t * for redirection into L2 device.\n\t\t */\n\t\t__skb_push(skb, head_room);\n\t\tmemset(skb->data, 0, head_room);\n\t\tskb_reset_mac_header(skb);\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static inline int __bpf_skb_change_head(struct sk_buff *skb, u32 head_room,\n \t\t\t\t\tu64 flags)\n {\n-\tu32 max_len = __bpf_skb_max_len(skb);\n+\tu32 max_len = BPF_SKB_MAX_LEN;\n \tu32 new_len = skb->len + head_room;\n \tint ret;\n ",
        "function_modified_lines": {
            "added": [
                "\tu32 max_len = BPF_SKB_MAX_LEN;"
            ],
            "deleted": [
                "\tu32 max_len = __bpf_skb_max_len(skb);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-416"
        ],
        "cve_description": "In bpf_skb_change_head of filter.c, there is a possible out of bounds read due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-154177719References: Upstream kernel",
        "id": 2839
    },
    {
        "cve_id": "CVE-2018-1093",
        "code_before_change": "static ext4_fsblk_t ext4_valid_block_bitmap(struct super_block *sb,\n\t\t\t\t\t    struct ext4_group_desc *desc,\n\t\t\t\t\t    ext4_group_t block_group,\n\t\t\t\t\t    struct buffer_head *bh)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_grpblk_t offset;\n\text4_grpblk_t next_zero_bit;\n\text4_fsblk_t blk;\n\text4_fsblk_t group_first_block;\n\n\tif (ext4_has_feature_flex_bg(sb)) {\n\t\t/* with FLEX_BG, the inode/block bitmaps and itable\n\t\t * blocks may not be in the group at all\n\t\t * so the bitmap validation will be skipped for those groups\n\t\t * or it has to also read the block group where the bitmaps\n\t\t * are located to verify they are set.\n\t\t */\n\t\treturn 0;\n\t}\n\tgroup_first_block = ext4_group_first_block_no(sb, block_group);\n\n\t/* check whether block bitmap block number is set */\n\tblk = ext4_block_bitmap(sb, desc);\n\toffset = blk - group_first_block;\n\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n\t\t/* bad block bitmap */\n\t\treturn blk;\n\n\t/* check whether the inode bitmap block number is set */\n\tblk = ext4_inode_bitmap(sb, desc);\n\toffset = blk - group_first_block;\n\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n\t\t/* bad block bitmap */\n\t\treturn blk;\n\n\t/* check whether the inode table block number is set */\n\tblk = ext4_inode_table(sb, desc);\n\toffset = blk - group_first_block;\n\tnext_zero_bit = ext4_find_next_zero_bit(bh->b_data,\n\t\t\tEXT4_B2C(sbi, offset + sbi->s_itb_per_group),\n\t\t\tEXT4_B2C(sbi, offset));\n\tif (next_zero_bit <\n\t    EXT4_B2C(sbi, offset + sbi->s_itb_per_group))\n\t\t/* bad bitmap for inode tables */\n\t\treturn blk;\n\treturn 0;\n}",
        "code_after_change": "static ext4_fsblk_t ext4_valid_block_bitmap(struct super_block *sb,\n\t\t\t\t\t    struct ext4_group_desc *desc,\n\t\t\t\t\t    ext4_group_t block_group,\n\t\t\t\t\t    struct buffer_head *bh)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_grpblk_t offset;\n\text4_grpblk_t next_zero_bit;\n\text4_fsblk_t blk;\n\text4_fsblk_t group_first_block;\n\n\tif (ext4_has_feature_flex_bg(sb)) {\n\t\t/* with FLEX_BG, the inode/block bitmaps and itable\n\t\t * blocks may not be in the group at all\n\t\t * so the bitmap validation will be skipped for those groups\n\t\t * or it has to also read the block group where the bitmaps\n\t\t * are located to verify they are set.\n\t\t */\n\t\treturn 0;\n\t}\n\tgroup_first_block = ext4_group_first_block_no(sb, block_group);\n\n\t/* check whether block bitmap block number is set */\n\tblk = ext4_block_bitmap(sb, desc);\n\toffset = blk - group_first_block;\n\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n\t\t/* bad block bitmap */\n\t\treturn blk;\n\n\t/* check whether the inode bitmap block number is set */\n\tblk = ext4_inode_bitmap(sb, desc);\n\toffset = blk - group_first_block;\n\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n\t\t/* bad block bitmap */\n\t\treturn blk;\n\n\t/* check whether the inode table block number is set */\n\tblk = ext4_inode_table(sb, desc);\n\toffset = blk - group_first_block;\n\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n\t    EXT4_B2C(sbi, offset + sbi->s_itb_per_group) >= sb->s_blocksize)\n\t\treturn blk;\n\tnext_zero_bit = ext4_find_next_zero_bit(bh->b_data,\n\t\t\tEXT4_B2C(sbi, offset + sbi->s_itb_per_group),\n\t\t\tEXT4_B2C(sbi, offset));\n\tif (next_zero_bit <\n\t    EXT4_B2C(sbi, offset + sbi->s_itb_per_group))\n\t\t/* bad bitmap for inode tables */\n\t\treturn blk;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,20 +23,25 @@\n \t/* check whether block bitmap block number is set */\n \tblk = ext4_block_bitmap(sb, desc);\n \toffset = blk - group_first_block;\n-\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n+\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n+\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n \t\t/* bad block bitmap */\n \t\treturn blk;\n \n \t/* check whether the inode bitmap block number is set */\n \tblk = ext4_inode_bitmap(sb, desc);\n \toffset = blk - group_first_block;\n-\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n+\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n+\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))\n \t\t/* bad block bitmap */\n \t\treturn blk;\n \n \t/* check whether the inode table block number is set */\n \tblk = ext4_inode_table(sb, desc);\n \toffset = blk - group_first_block;\n+\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||\n+\t    EXT4_B2C(sbi, offset + sbi->s_itb_per_group) >= sb->s_blocksize)\n+\t\treturn blk;\n \tnext_zero_bit = ext4_find_next_zero_bit(bh->b_data,\n \t\t\tEXT4_B2C(sbi, offset + sbi->s_itb_per_group),\n \t\t\tEXT4_B2C(sbi, offset));",
        "function_modified_lines": {
            "added": [
                "\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||",
                "\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))",
                "\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||",
                "\t    !ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))",
                "\tif (offset < 0 || EXT4_B2C(sbi, offset) >= sb->s_blocksize ||",
                "\t    EXT4_B2C(sbi, offset + sbi->s_itb_per_group) >= sb->s_blocksize)",
                "\t\treturn blk;"
            ],
            "deleted": [
                "\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))",
                "\tif (!ext4_test_bit(EXT4_B2C(sbi, offset), bh->b_data))"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ext4_valid_block_bitmap function in fs/ext4/balloc.c in the Linux kernel through 4.15.15 allows attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image because balloc.c and ialloc.c do not validate bitmap block numbers.",
        "id": 1624
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "static int ntfs_get_ea(struct inode *inode, const char *name, size_t name_len,\n\t\t       void *buffer, size_t size, size_t *required)\n{\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tconst struct EA_INFO *info;\n\tstruct EA_FULL *ea_all = NULL;\n\tconst struct EA_FULL *ea;\n\tu32 off, len;\n\tint err;\n\n\tif (!(ni->ni_flags & NI_FLAG_EA))\n\t\treturn -ENODATA;\n\n\tif (!required)\n\t\tni_lock(ni);\n\n\tlen = 0;\n\n\tif (name_len > 255) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out;\n\t}\n\n\terr = ntfs_read_ea(ni, &ea_all, 0, &info);\n\tif (err)\n\t\tgoto out;\n\n\tif (!info)\n\t\tgoto out;\n\n\t/* Enumerate all xattrs. */\n\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off)) {\n\t\terr = -ENODATA;\n\t\tgoto out;\n\t}\n\tea = Add2Ptr(ea_all, off);\n\n\tlen = le16_to_cpu(ea->elength);\n\tif (!buffer) {\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\n\tif (len > size) {\n\t\terr = -ERANGE;\n\t\tif (required)\n\t\t\t*required = len;\n\t\tgoto out;\n\t}\n\n\tmemcpy(buffer, ea->name + ea->name_len + 1, len);\n\terr = 0;\n\nout:\n\tkfree(ea_all);\n\tif (!required)\n\t\tni_unlock(ni);\n\n\treturn err ? err : len;\n}",
        "code_after_change": "static int ntfs_get_ea(struct inode *inode, const char *name, size_t name_len,\n\t\t       void *buffer, size_t size, size_t *required)\n{\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tconst struct EA_INFO *info;\n\tstruct EA_FULL *ea_all = NULL;\n\tconst struct EA_FULL *ea;\n\tu32 off, len;\n\tint err;\n\n\tif (!(ni->ni_flags & NI_FLAG_EA))\n\t\treturn -ENODATA;\n\n\tif (!required)\n\t\tni_lock(ni);\n\n\tlen = 0;\n\n\tif (name_len > 255) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out;\n\t}\n\n\terr = ntfs_read_ea(ni, &ea_all, 0, &info);\n\tif (err)\n\t\tgoto out;\n\n\tif (!info)\n\t\tgoto out;\n\n\t/* Enumerate all xattrs. */\n\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off,\n\t\t     NULL)) {\n\t\terr = -ENODATA;\n\t\tgoto out;\n\t}\n\tea = Add2Ptr(ea_all, off);\n\n\tlen = le16_to_cpu(ea->elength);\n\tif (!buffer) {\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\n\tif (len > size) {\n\t\terr = -ERANGE;\n\t\tif (required)\n\t\t\t*required = len;\n\t\tgoto out;\n\t}\n\n\tmemcpy(buffer, ea->name + ea->name_len + 1, len);\n\terr = 0;\n\nout:\n\tkfree(ea_all);\n\tif (!required)\n\t\tni_unlock(ni);\n\n\treturn err ? err : len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,7 +29,8 @@\n \t\tgoto out;\n \n \t/* Enumerate all xattrs. */\n-\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off)) {\n+\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off,\n+\t\t     NULL)) {\n \t\terr = -ENODATA;\n \t\tgoto out;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off,",
                "\t\t     NULL)) {"
            ],
            "deleted": [
                "\tif (!find_ea(ea_all, le32_to_cpu(info->size), name, name_len, &off)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3800
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "static struct inode *ntfs_read_mft(struct inode *inode,\n\t\t\t\t   const struct cpu_str *name,\n\t\t\t\t   const struct MFT_REF *ref)\n{\n\tint err = 0;\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ntfs_sb_info *sbi = sb->s_fs_info;\n\tmode_t mode = 0;\n\tstruct ATTR_STD_INFO5 *std5 = NULL;\n\tstruct ATTR_LIST_ENTRY *le;\n\tstruct ATTRIB *attr;\n\tbool is_match = false;\n\tbool is_root = false;\n\tbool is_dir;\n\tunsigned long ino = inode->i_ino;\n\tu32 rp_fa = 0, asize, t32;\n\tu16 roff, rsize, names = 0;\n\tconst struct ATTR_FILE_NAME *fname = NULL;\n\tconst struct INDEX_ROOT *root;\n\tstruct REPARSE_DATA_BUFFER rp; // 0x18 bytes\n\tu64 t64;\n\tstruct MFT_REC *rec;\n\tstruct runs_tree *run;\n\n\tinode->i_op = NULL;\n\t/* Setup 'uid' and 'gid' */\n\tinode->i_uid = sbi->options->fs_uid;\n\tinode->i_gid = sbi->options->fs_gid;\n\n\terr = mi_init(&ni->mi, sbi, ino);\n\tif (err)\n\t\tgoto out;\n\n\tif (!sbi->mft.ni && ino == MFT_REC_MFT && !sb->s_root) {\n\t\tt64 = sbi->mft.lbo >> sbi->cluster_bits;\n\t\tt32 = bytes_to_cluster(sbi, MFT_REC_VOL * sbi->record_size);\n\t\tsbi->mft.ni = ni;\n\t\tinit_rwsem(&ni->file.run_lock);\n\n\t\tif (!run_add_entry(&ni->file.run, 0, t64, t32, true)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = mi_read(&ni->mi, ino == MFT_REC_MFT);\n\n\tif (err)\n\t\tgoto out;\n\n\trec = ni->mi.mrec;\n\n\tif (sbi->flags & NTFS_FLAGS_LOG_REPLAYING) {\n\t\t;\n\t} else if (ref->seq != rec->seq) {\n\t\terr = -EINVAL;\n\t\tntfs_err(sb, \"MFT: r=%lx, expect seq=%x instead of %x!\", ino,\n\t\t\t le16_to_cpu(ref->seq), le16_to_cpu(rec->seq));\n\t\tgoto out;\n\t} else if (!is_rec_inuse(rec)) {\n\t\terr = -EINVAL;\n\t\tntfs_err(sb, \"Inode r=%x is not in use!\", (u32)ino);\n\t\tgoto out;\n\t}\n\n\tif (le32_to_cpu(rec->total) != sbi->record_size) {\n\t\t/* Bad inode? */\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!is_rec_base(rec))\n\t\tgoto Ok;\n\n\t/* Record should contain $I30 root. */\n\tis_dir = rec->flags & RECORD_FLAG_DIR;\n\n\tinode->i_generation = le16_to_cpu(rec->seq);\n\n\t/* Enumerate all struct Attributes MFT. */\n\tle = NULL;\n\tattr = NULL;\n\n\t/*\n\t * To reduce tab pressure use goto instead of\n\t * while( (attr = ni_enum_attr_ex(ni, attr, &le, NULL) ))\n\t */\nnext_attr:\n\trun = NULL;\n\terr = -EINVAL;\n\tattr = ni_enum_attr_ex(ni, attr, &le, NULL);\n\tif (!attr)\n\t\tgoto end_enum;\n\n\tif (le && le->vcn) {\n\t\t/* This is non primary attribute segment. Ignore if not MFT. */\n\t\tif (ino != MFT_REC_MFT || attr->type != ATTR_DATA)\n\t\t\tgoto next_attr;\n\n\t\trun = &ni->file.run;\n\t\tasize = le32_to_cpu(attr->size);\n\t\tgoto attr_unpack_run;\n\t}\n\n\troff = attr->non_res ? 0 : le16_to_cpu(attr->res.data_off);\n\trsize = attr->non_res ? 0 : le32_to_cpu(attr->res.data_size);\n\tasize = le32_to_cpu(attr->size);\n\n\tif (le16_to_cpu(attr->name_off) + attr->name_len > asize)\n\t\tgoto out;\n\n\tif (attr->non_res) {\n\t\tt64 = le64_to_cpu(attr->nres.alloc_size);\n\t\tif (le64_to_cpu(attr->nres.data_size) > t64 ||\n\t\t    le64_to_cpu(attr->nres.valid_size) > t64)\n\t\t\tgoto out;\n\t}\n\n\tswitch (attr->type) {\n\tcase ATTR_STD:\n\t\tif (attr->non_res ||\n\t\t    asize < sizeof(struct ATTR_STD_INFO) + roff ||\n\t\t    rsize < sizeof(struct ATTR_STD_INFO))\n\t\t\tgoto out;\n\n\t\tif (std5)\n\t\t\tgoto next_attr;\n\n\t\tstd5 = Add2Ptr(attr, roff);\n\n#ifdef STATX_BTIME\n\t\tnt2kernel(std5->cr_time, &ni->i_crtime);\n#endif\n\t\tnt2kernel(std5->a_time, &inode->i_atime);\n\t\tnt2kernel(std5->c_time, &inode->i_ctime);\n\t\tnt2kernel(std5->m_time, &inode->i_mtime);\n\n\t\tni->std_fa = std5->fa;\n\n\t\tif (asize >= sizeof(struct ATTR_STD_INFO5) + roff &&\n\t\t    rsize >= sizeof(struct ATTR_STD_INFO5))\n\t\t\tni->std_security_id = std5->security_id;\n\t\tgoto next_attr;\n\n\tcase ATTR_LIST:\n\t\tif (attr->name_len || le || ino == MFT_REC_LOG)\n\t\t\tgoto out;\n\n\t\terr = ntfs_load_attr_list(ni, attr);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tle = NULL;\n\t\tattr = NULL;\n\t\tgoto next_attr;\n\n\tcase ATTR_NAME:\n\t\tif (attr->non_res || asize < SIZEOF_ATTRIBUTE_FILENAME + roff ||\n\t\t    rsize < SIZEOF_ATTRIBUTE_FILENAME)\n\t\t\tgoto out;\n\n\t\tfname = Add2Ptr(attr, roff);\n\t\tif (fname->type == FILE_NAME_DOS)\n\t\t\tgoto next_attr;\n\n\t\tnames += 1;\n\t\tif (name && name->len == fname->name_len &&\n\t\t    !ntfs_cmp_names_cpu(name, (struct le_str *)&fname->name_len,\n\t\t\t\t\tNULL, false))\n\t\t\tis_match = true;\n\n\t\tgoto next_attr;\n\n\tcase ATTR_DATA:\n\t\tif (is_dir) {\n\t\t\t/* Ignore data attribute in dir record. */\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tif (ino == MFT_REC_BADCLUST && !attr->non_res)\n\t\t\tgoto next_attr;\n\n\t\tif (attr->name_len &&\n\t\t    ((ino != MFT_REC_BADCLUST || !attr->non_res ||\n\t\t      attr->name_len != ARRAY_SIZE(BAD_NAME) ||\n\t\t      memcmp(attr_name(attr), BAD_NAME, sizeof(BAD_NAME))) &&\n\t\t     (ino != MFT_REC_SECURE || !attr->non_res ||\n\t\t      attr->name_len != ARRAY_SIZE(SDS_NAME) ||\n\t\t      memcmp(attr_name(attr), SDS_NAME, sizeof(SDS_NAME))))) {\n\t\t\t/* File contains stream attribute. Ignore it. */\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tif (is_attr_sparsed(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_SPARSE_FILE;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_SPARSE_FILE;\n\n\t\tif (is_attr_compressed(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_COMPRESSED;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_COMPRESSED;\n\n\t\tif (is_attr_encrypted(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_ENCRYPTED;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_ENCRYPTED;\n\n\t\tif (!attr->non_res) {\n\t\t\tni->i_valid = inode->i_size = rsize;\n\t\t\tinode_set_bytes(inode, rsize);\n\t\t}\n\n\t\tmode = S_IFREG | (0777 & sbi->options->fs_fmask_inv);\n\n\t\tif (!attr->non_res) {\n\t\t\tni->ni_flags |= NI_FLAG_RESIDENT;\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tinode_set_bytes(inode, attr_ondisk_size(attr));\n\n\t\tni->i_valid = le64_to_cpu(attr->nres.valid_size);\n\t\tinode->i_size = le64_to_cpu(attr->nres.data_size);\n\t\tif (!attr->nres.alloc_size)\n\t\t\tgoto next_attr;\n\n\t\trun = ino == MFT_REC_BITMAP ? &sbi->used.bitmap.run\n\t\t\t\t\t    : &ni->file.run;\n\t\tbreak;\n\n\tcase ATTR_ROOT:\n\t\tif (attr->non_res)\n\t\t\tgoto out;\n\n\t\troot = Add2Ptr(attr, roff);\n\t\tis_root = true;\n\n\t\tif (attr->name_len != ARRAY_SIZE(I30_NAME) ||\n\t\t    memcmp(attr_name(attr), I30_NAME, sizeof(I30_NAME)))\n\t\t\tgoto next_attr;\n\n\t\tif (root->type != ATTR_NAME ||\n\t\t    root->rule != NTFS_COLLATION_TYPE_FILENAME)\n\t\t\tgoto out;\n\n\t\tif (!is_dir)\n\t\t\tgoto next_attr;\n\n\t\tni->ni_flags |= NI_FLAG_DIR;\n\n\t\terr = indx_init(&ni->dir, sbi, attr, INDEX_MUTEX_I30);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tmode = sb->s_root\n\t\t\t       ? (S_IFDIR | (0777 & sbi->options->fs_dmask_inv))\n\t\t\t       : (S_IFDIR | 0777);\n\t\tgoto next_attr;\n\n\tcase ATTR_ALLOC:\n\t\tif (!is_root || attr->name_len != ARRAY_SIZE(I30_NAME) ||\n\t\t    memcmp(attr_name(attr), I30_NAME, sizeof(I30_NAME)))\n\t\t\tgoto next_attr;\n\n\t\tinode->i_size = le64_to_cpu(attr->nres.data_size);\n\t\tni->i_valid = le64_to_cpu(attr->nres.valid_size);\n\t\tinode_set_bytes(inode, le64_to_cpu(attr->nres.alloc_size));\n\n\t\trun = &ni->dir.alloc_run;\n\t\tbreak;\n\n\tcase ATTR_BITMAP:\n\t\tif (ino == MFT_REC_MFT) {\n\t\t\tif (!attr->non_res)\n\t\t\t\tgoto out;\n#ifndef CONFIG_NTFS3_64BIT_CLUSTER\n\t\t\t/* 0x20000000 = 2^32 / 8 */\n\t\t\tif (le64_to_cpu(attr->nres.alloc_size) >= 0x20000000)\n\t\t\t\tgoto out;\n#endif\n\t\t\trun = &sbi->mft.bitmap.run;\n\t\t\tbreak;\n\t\t} else if (is_dir && attr->name_len == ARRAY_SIZE(I30_NAME) &&\n\t\t\t   !memcmp(attr_name(attr), I30_NAME,\n\t\t\t\t   sizeof(I30_NAME)) &&\n\t\t\t   attr->non_res) {\n\t\t\trun = &ni->dir.bitmap_run;\n\t\t\tbreak;\n\t\t}\n\t\tgoto next_attr;\n\n\tcase ATTR_REPARSE:\n\t\tif (attr->name_len)\n\t\t\tgoto next_attr;\n\n\t\trp_fa = ni_parse_reparse(ni, attr, &rp);\n\t\tswitch (rp_fa) {\n\t\tcase REPARSE_LINK:\n\t\t\t/*\n\t\t\t * Normal symlink.\n\t\t\t * Assume one unicode symbol == one utf8.\n\t\t\t */\n\t\t\tinode->i_size = le16_to_cpu(rp.SymbolicLinkReparseBuffer\n\t\t\t\t\t\t\t    .PrintNameLength) /\n\t\t\t\t\tsizeof(u16);\n\n\t\t\tni->i_valid = inode->i_size;\n\n\t\t\t/* Clear directory bit. */\n\t\t\tif (ni->ni_flags & NI_FLAG_DIR) {\n\t\t\t\tindx_clear(&ni->dir);\n\t\t\t\tmemset(&ni->dir, 0, sizeof(ni->dir));\n\t\t\t\tni->ni_flags &= ~NI_FLAG_DIR;\n\t\t\t} else {\n\t\t\t\trun_close(&ni->file.run);\n\t\t\t}\n\t\t\tmode = S_IFLNK | 0777;\n\t\t\tis_dir = false;\n\t\t\tif (attr->non_res) {\n\t\t\t\trun = &ni->file.run;\n\t\t\t\tgoto attr_unpack_run; // Double break.\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase REPARSE_COMPRESSED:\n\t\t\tbreak;\n\n\t\tcase REPARSE_DEDUPLICATED:\n\t\t\tbreak;\n\t\t}\n\t\tgoto next_attr;\n\n\tcase ATTR_EA_INFO:\n\t\tif (!attr->name_len &&\n\t\t    resident_data_ex(attr, sizeof(struct EA_INFO))) {\n\t\t\tni->ni_flags |= NI_FLAG_EA;\n\t\t\t/*\n\t\t\t * ntfs_get_wsl_perm updates inode->i_uid, inode->i_gid, inode->i_mode\n\t\t\t */\n\t\t\tinode->i_mode = mode;\n\t\t\tntfs_get_wsl_perm(inode);\n\t\t\tmode = inode->i_mode;\n\t\t}\n\t\tgoto next_attr;\n\n\tdefault:\n\t\tgoto next_attr;\n\t}\n\nattr_unpack_run:\n\troff = le16_to_cpu(attr->nres.run_off);\n\n\tif (roff > asize) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tt64 = le64_to_cpu(attr->nres.svcn);\n\n\terr = run_unpack_ex(run, sbi, ino, t64, le64_to_cpu(attr->nres.evcn),\n\t\t\t    t64, Add2Ptr(attr, roff), asize - roff);\n\tif (err < 0)\n\t\tgoto out;\n\terr = 0;\n\tgoto next_attr;\n\nend_enum:\n\n\tif (!std5)\n\t\tgoto out;\n\n\tif (!is_match && name) {\n\t\t/* Reuse rec as buffer for ascii name. */\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (std5->fa & FILE_ATTRIBUTE_READONLY)\n\t\tmode &= ~0222;\n\n\tif (!names) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (names != le16_to_cpu(rec->hard_links)) {\n\t\t/* Correct minor error on the fly. Do not mark inode as dirty. */\n\t\trec->hard_links = cpu_to_le16(names);\n\t\tni->mi.dirty = true;\n\t}\n\n\tset_nlink(inode, names);\n\n\tif (S_ISDIR(mode)) {\n\t\tni->std_fa |= FILE_ATTRIBUTE_DIRECTORY;\n\n\t\t/*\n\t\t * Dot and dot-dot should be included in count but was not\n\t\t * included in enumeration.\n\t\t * Usually a hard links to directories are disabled.\n\t\t */\n\t\tinode->i_op = &ntfs_dir_inode_operations;\n\t\tinode->i_fop = &ntfs_dir_operations;\n\t\tni->i_valid = 0;\n\t} else if (S_ISLNK(mode)) {\n\t\tni->std_fa &= ~FILE_ATTRIBUTE_DIRECTORY;\n\t\tinode->i_op = &ntfs_link_inode_operations;\n\t\tinode->i_fop = NULL;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISREG(mode)) {\n\t\tni->std_fa &= ~FILE_ATTRIBUTE_DIRECTORY;\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t\tinode->i_fop = &ntfs_file_operations;\n\t\tinode->i_mapping->a_ops =\n\t\t\tis_compressed(ni) ? &ntfs_aops_cmpr : &ntfs_aops;\n\t\tif (ino != MFT_REC_MFT)\n\t\t\tinit_rwsem(&ni->file.run_lock);\n\t} else if (S_ISCHR(mode) || S_ISBLK(mode) || S_ISFIFO(mode) ||\n\t\t   S_ISSOCK(mode)) {\n\t\tinode->i_op = &ntfs_special_inode_operations;\n\t\tinit_special_inode(inode, mode, inode->i_rdev);\n\t} else if (fname && fname->home.low == cpu_to_le32(MFT_REC_EXTEND) &&\n\t\t   fname->home.seq == cpu_to_le16(MFT_REC_EXTEND)) {\n\t\t/* Records in $Extend are not a files or general directories. */\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t} else {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif ((sbi->options->sys_immutable &&\n\t     (std5->fa & FILE_ATTRIBUTE_SYSTEM)) &&\n\t    !S_ISFIFO(mode) && !S_ISSOCK(mode) && !S_ISLNK(mode)) {\n\t\tinode->i_flags |= S_IMMUTABLE;\n\t} else {\n\t\tinode->i_flags &= ~S_IMMUTABLE;\n\t}\n\n\tinode->i_mode = mode;\n\tif (!(ni->ni_flags & NI_FLAG_EA)) {\n\t\t/* If no xattr then no security (stored in xattr). */\n\t\tinode->i_flags |= S_NOSEC;\n\t}\n\nOk:\n\tif (ino == MFT_REC_MFT && !sb->s_root)\n\t\tsbi->mft.ni = NULL;\n\n\tunlock_new_inode(inode);\n\n\treturn inode;\n\nout:\n\tif (ino == MFT_REC_MFT && !sb->s_root)\n\t\tsbi->mft.ni = NULL;\n\n\tiget_failed(inode);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "static struct inode *ntfs_read_mft(struct inode *inode,\n\t\t\t\t   const struct cpu_str *name,\n\t\t\t\t   const struct MFT_REF *ref)\n{\n\tint err = 0;\n\tstruct ntfs_inode *ni = ntfs_i(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ntfs_sb_info *sbi = sb->s_fs_info;\n\tmode_t mode = 0;\n\tstruct ATTR_STD_INFO5 *std5 = NULL;\n\tstruct ATTR_LIST_ENTRY *le;\n\tstruct ATTRIB *attr;\n\tbool is_match = false;\n\tbool is_root = false;\n\tbool is_dir;\n\tunsigned long ino = inode->i_ino;\n\tu32 rp_fa = 0, asize, t32;\n\tu16 roff, rsize, names = 0;\n\tconst struct ATTR_FILE_NAME *fname = NULL;\n\tconst struct INDEX_ROOT *root;\n\tstruct REPARSE_DATA_BUFFER rp; // 0x18 bytes\n\tu64 t64;\n\tstruct MFT_REC *rec;\n\tstruct runs_tree *run;\n\n\tinode->i_op = NULL;\n\t/* Setup 'uid' and 'gid' */\n\tinode->i_uid = sbi->options->fs_uid;\n\tinode->i_gid = sbi->options->fs_gid;\n\n\terr = mi_init(&ni->mi, sbi, ino);\n\tif (err)\n\t\tgoto out;\n\n\tif (!sbi->mft.ni && ino == MFT_REC_MFT && !sb->s_root) {\n\t\tt64 = sbi->mft.lbo >> sbi->cluster_bits;\n\t\tt32 = bytes_to_cluster(sbi, MFT_REC_VOL * sbi->record_size);\n\t\tsbi->mft.ni = ni;\n\t\tinit_rwsem(&ni->file.run_lock);\n\n\t\tif (!run_add_entry(&ni->file.run, 0, t64, t32, true)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = mi_read(&ni->mi, ino == MFT_REC_MFT);\n\n\tif (err)\n\t\tgoto out;\n\n\trec = ni->mi.mrec;\n\n\tif (sbi->flags & NTFS_FLAGS_LOG_REPLAYING) {\n\t\t;\n\t} else if (ref->seq != rec->seq) {\n\t\terr = -EINVAL;\n\t\tntfs_err(sb, \"MFT: r=%lx, expect seq=%x instead of %x!\", ino,\n\t\t\t le16_to_cpu(ref->seq), le16_to_cpu(rec->seq));\n\t\tgoto out;\n\t} else if (!is_rec_inuse(rec)) {\n\t\terr = -ESTALE;\n\t\tntfs_err(sb, \"Inode r=%x is not in use!\", (u32)ino);\n\t\tgoto out;\n\t}\n\n\tif (le32_to_cpu(rec->total) != sbi->record_size) {\n\t\t/* Bad inode? */\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!is_rec_base(rec)) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Record should contain $I30 root. */\n\tis_dir = rec->flags & RECORD_FLAG_DIR;\n\n\tinode->i_generation = le16_to_cpu(rec->seq);\n\n\t/* Enumerate all struct Attributes MFT. */\n\tle = NULL;\n\tattr = NULL;\n\n\t/*\n\t * To reduce tab pressure use goto instead of\n\t * while( (attr = ni_enum_attr_ex(ni, attr, &le, NULL) ))\n\t */\nnext_attr:\n\trun = NULL;\n\terr = -EINVAL;\n\tattr = ni_enum_attr_ex(ni, attr, &le, NULL);\n\tif (!attr)\n\t\tgoto end_enum;\n\n\tif (le && le->vcn) {\n\t\t/* This is non primary attribute segment. Ignore if not MFT. */\n\t\tif (ino != MFT_REC_MFT || attr->type != ATTR_DATA)\n\t\t\tgoto next_attr;\n\n\t\trun = &ni->file.run;\n\t\tasize = le32_to_cpu(attr->size);\n\t\tgoto attr_unpack_run;\n\t}\n\n\troff = attr->non_res ? 0 : le16_to_cpu(attr->res.data_off);\n\trsize = attr->non_res ? 0 : le32_to_cpu(attr->res.data_size);\n\tasize = le32_to_cpu(attr->size);\n\n\tif (le16_to_cpu(attr->name_off) + attr->name_len > asize)\n\t\tgoto out;\n\n\tif (attr->non_res) {\n\t\tt64 = le64_to_cpu(attr->nres.alloc_size);\n\t\tif (le64_to_cpu(attr->nres.data_size) > t64 ||\n\t\t    le64_to_cpu(attr->nres.valid_size) > t64)\n\t\t\tgoto out;\n\t}\n\n\tswitch (attr->type) {\n\tcase ATTR_STD:\n\t\tif (attr->non_res ||\n\t\t    asize < sizeof(struct ATTR_STD_INFO) + roff ||\n\t\t    rsize < sizeof(struct ATTR_STD_INFO))\n\t\t\tgoto out;\n\n\t\tif (std5)\n\t\t\tgoto next_attr;\n\n\t\tstd5 = Add2Ptr(attr, roff);\n\n#ifdef STATX_BTIME\n\t\tnt2kernel(std5->cr_time, &ni->i_crtime);\n#endif\n\t\tnt2kernel(std5->a_time, &inode->i_atime);\n\t\tnt2kernel(std5->c_time, &inode->i_ctime);\n\t\tnt2kernel(std5->m_time, &inode->i_mtime);\n\n\t\tni->std_fa = std5->fa;\n\n\t\tif (asize >= sizeof(struct ATTR_STD_INFO5) + roff &&\n\t\t    rsize >= sizeof(struct ATTR_STD_INFO5))\n\t\t\tni->std_security_id = std5->security_id;\n\t\tgoto next_attr;\n\n\tcase ATTR_LIST:\n\t\tif (attr->name_len || le || ino == MFT_REC_LOG)\n\t\t\tgoto out;\n\n\t\terr = ntfs_load_attr_list(ni, attr);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tle = NULL;\n\t\tattr = NULL;\n\t\tgoto next_attr;\n\n\tcase ATTR_NAME:\n\t\tif (attr->non_res || asize < SIZEOF_ATTRIBUTE_FILENAME + roff ||\n\t\t    rsize < SIZEOF_ATTRIBUTE_FILENAME)\n\t\t\tgoto out;\n\n\t\tfname = Add2Ptr(attr, roff);\n\t\tif (fname->type == FILE_NAME_DOS)\n\t\t\tgoto next_attr;\n\n\t\tnames += 1;\n\t\tif (name && name->len == fname->name_len &&\n\t\t    !ntfs_cmp_names_cpu(name, (struct le_str *)&fname->name_len,\n\t\t\t\t\tNULL, false))\n\t\t\tis_match = true;\n\n\t\tgoto next_attr;\n\n\tcase ATTR_DATA:\n\t\tif (is_dir) {\n\t\t\t/* Ignore data attribute in dir record. */\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tif (ino == MFT_REC_BADCLUST && !attr->non_res)\n\t\t\tgoto next_attr;\n\n\t\tif (attr->name_len &&\n\t\t    ((ino != MFT_REC_BADCLUST || !attr->non_res ||\n\t\t      attr->name_len != ARRAY_SIZE(BAD_NAME) ||\n\t\t      memcmp(attr_name(attr), BAD_NAME, sizeof(BAD_NAME))) &&\n\t\t     (ino != MFT_REC_SECURE || !attr->non_res ||\n\t\t      attr->name_len != ARRAY_SIZE(SDS_NAME) ||\n\t\t      memcmp(attr_name(attr), SDS_NAME, sizeof(SDS_NAME))))) {\n\t\t\t/* File contains stream attribute. Ignore it. */\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tif (is_attr_sparsed(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_SPARSE_FILE;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_SPARSE_FILE;\n\n\t\tif (is_attr_compressed(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_COMPRESSED;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_COMPRESSED;\n\n\t\tif (is_attr_encrypted(attr))\n\t\t\tni->std_fa |= FILE_ATTRIBUTE_ENCRYPTED;\n\t\telse\n\t\t\tni->std_fa &= ~FILE_ATTRIBUTE_ENCRYPTED;\n\n\t\tif (!attr->non_res) {\n\t\t\tni->i_valid = inode->i_size = rsize;\n\t\t\tinode_set_bytes(inode, rsize);\n\t\t}\n\n\t\tmode = S_IFREG | (0777 & sbi->options->fs_fmask_inv);\n\n\t\tif (!attr->non_res) {\n\t\t\tni->ni_flags |= NI_FLAG_RESIDENT;\n\t\t\tgoto next_attr;\n\t\t}\n\n\t\tinode_set_bytes(inode, attr_ondisk_size(attr));\n\n\t\tni->i_valid = le64_to_cpu(attr->nres.valid_size);\n\t\tinode->i_size = le64_to_cpu(attr->nres.data_size);\n\t\tif (!attr->nres.alloc_size)\n\t\t\tgoto next_attr;\n\n\t\trun = ino == MFT_REC_BITMAP ? &sbi->used.bitmap.run\n\t\t\t\t\t    : &ni->file.run;\n\t\tbreak;\n\n\tcase ATTR_ROOT:\n\t\tif (attr->non_res)\n\t\t\tgoto out;\n\n\t\troot = Add2Ptr(attr, roff);\n\t\tis_root = true;\n\n\t\tif (attr->name_len != ARRAY_SIZE(I30_NAME) ||\n\t\t    memcmp(attr_name(attr), I30_NAME, sizeof(I30_NAME)))\n\t\t\tgoto next_attr;\n\n\t\tif (root->type != ATTR_NAME ||\n\t\t    root->rule != NTFS_COLLATION_TYPE_FILENAME)\n\t\t\tgoto out;\n\n\t\tif (!is_dir)\n\t\t\tgoto next_attr;\n\n\t\tni->ni_flags |= NI_FLAG_DIR;\n\n\t\terr = indx_init(&ni->dir, sbi, attr, INDEX_MUTEX_I30);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tmode = sb->s_root\n\t\t\t       ? (S_IFDIR | (0777 & sbi->options->fs_dmask_inv))\n\t\t\t       : (S_IFDIR | 0777);\n\t\tgoto next_attr;\n\n\tcase ATTR_ALLOC:\n\t\tif (!is_root || attr->name_len != ARRAY_SIZE(I30_NAME) ||\n\t\t    memcmp(attr_name(attr), I30_NAME, sizeof(I30_NAME)))\n\t\t\tgoto next_attr;\n\n\t\tinode->i_size = le64_to_cpu(attr->nres.data_size);\n\t\tni->i_valid = le64_to_cpu(attr->nres.valid_size);\n\t\tinode_set_bytes(inode, le64_to_cpu(attr->nres.alloc_size));\n\n\t\trun = &ni->dir.alloc_run;\n\t\tbreak;\n\n\tcase ATTR_BITMAP:\n\t\tif (ino == MFT_REC_MFT) {\n\t\t\tif (!attr->non_res)\n\t\t\t\tgoto out;\n#ifndef CONFIG_NTFS3_64BIT_CLUSTER\n\t\t\t/* 0x20000000 = 2^32 / 8 */\n\t\t\tif (le64_to_cpu(attr->nres.alloc_size) >= 0x20000000)\n\t\t\t\tgoto out;\n#endif\n\t\t\trun = &sbi->mft.bitmap.run;\n\t\t\tbreak;\n\t\t} else if (is_dir && attr->name_len == ARRAY_SIZE(I30_NAME) &&\n\t\t\t   !memcmp(attr_name(attr), I30_NAME,\n\t\t\t\t   sizeof(I30_NAME)) &&\n\t\t\t   attr->non_res) {\n\t\t\trun = &ni->dir.bitmap_run;\n\t\t\tbreak;\n\t\t}\n\t\tgoto next_attr;\n\n\tcase ATTR_REPARSE:\n\t\tif (attr->name_len)\n\t\t\tgoto next_attr;\n\n\t\trp_fa = ni_parse_reparse(ni, attr, &rp);\n\t\tswitch (rp_fa) {\n\t\tcase REPARSE_LINK:\n\t\t\t/*\n\t\t\t * Normal symlink.\n\t\t\t * Assume one unicode symbol == one utf8.\n\t\t\t */\n\t\t\tinode->i_size = le16_to_cpu(rp.SymbolicLinkReparseBuffer\n\t\t\t\t\t\t\t    .PrintNameLength) /\n\t\t\t\t\tsizeof(u16);\n\n\t\t\tni->i_valid = inode->i_size;\n\n\t\t\t/* Clear directory bit. */\n\t\t\tif (ni->ni_flags & NI_FLAG_DIR) {\n\t\t\t\tindx_clear(&ni->dir);\n\t\t\t\tmemset(&ni->dir, 0, sizeof(ni->dir));\n\t\t\t\tni->ni_flags &= ~NI_FLAG_DIR;\n\t\t\t} else {\n\t\t\t\trun_close(&ni->file.run);\n\t\t\t}\n\t\t\tmode = S_IFLNK | 0777;\n\t\t\tis_dir = false;\n\t\t\tif (attr->non_res) {\n\t\t\t\trun = &ni->file.run;\n\t\t\t\tgoto attr_unpack_run; // Double break.\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase REPARSE_COMPRESSED:\n\t\t\tbreak;\n\n\t\tcase REPARSE_DEDUPLICATED:\n\t\t\tbreak;\n\t\t}\n\t\tgoto next_attr;\n\n\tcase ATTR_EA_INFO:\n\t\tif (!attr->name_len &&\n\t\t    resident_data_ex(attr, sizeof(struct EA_INFO))) {\n\t\t\tni->ni_flags |= NI_FLAG_EA;\n\t\t\t/*\n\t\t\t * ntfs_get_wsl_perm updates inode->i_uid, inode->i_gid, inode->i_mode\n\t\t\t */\n\t\t\tinode->i_mode = mode;\n\t\t\tntfs_get_wsl_perm(inode);\n\t\t\tmode = inode->i_mode;\n\t\t}\n\t\tgoto next_attr;\n\n\tdefault:\n\t\tgoto next_attr;\n\t}\n\nattr_unpack_run:\n\troff = le16_to_cpu(attr->nres.run_off);\n\n\tif (roff > asize) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tt64 = le64_to_cpu(attr->nres.svcn);\n\n\terr = run_unpack_ex(run, sbi, ino, t64, le64_to_cpu(attr->nres.evcn),\n\t\t\t    t64, Add2Ptr(attr, roff), asize - roff);\n\tif (err < 0)\n\t\tgoto out;\n\terr = 0;\n\tgoto next_attr;\n\nend_enum:\n\n\tif (!std5)\n\t\tgoto out;\n\n\tif (!is_match && name) {\n\t\t/* Reuse rec as buffer for ascii name. */\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (std5->fa & FILE_ATTRIBUTE_READONLY)\n\t\tmode &= ~0222;\n\n\tif (!names) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (names != le16_to_cpu(rec->hard_links)) {\n\t\t/* Correct minor error on the fly. Do not mark inode as dirty. */\n\t\trec->hard_links = cpu_to_le16(names);\n\t\tni->mi.dirty = true;\n\t}\n\n\tset_nlink(inode, names);\n\n\tif (S_ISDIR(mode)) {\n\t\tni->std_fa |= FILE_ATTRIBUTE_DIRECTORY;\n\n\t\t/*\n\t\t * Dot and dot-dot should be included in count but was not\n\t\t * included in enumeration.\n\t\t * Usually a hard links to directories are disabled.\n\t\t */\n\t\tinode->i_op = &ntfs_dir_inode_operations;\n\t\tinode->i_fop = &ntfs_dir_operations;\n\t\tni->i_valid = 0;\n\t} else if (S_ISLNK(mode)) {\n\t\tni->std_fa &= ~FILE_ATTRIBUTE_DIRECTORY;\n\t\tinode->i_op = &ntfs_link_inode_operations;\n\t\tinode->i_fop = NULL;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISREG(mode)) {\n\t\tni->std_fa &= ~FILE_ATTRIBUTE_DIRECTORY;\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t\tinode->i_fop = &ntfs_file_operations;\n\t\tinode->i_mapping->a_ops =\n\t\t\tis_compressed(ni) ? &ntfs_aops_cmpr : &ntfs_aops;\n\t\tif (ino != MFT_REC_MFT)\n\t\t\tinit_rwsem(&ni->file.run_lock);\n\t} else if (S_ISCHR(mode) || S_ISBLK(mode) || S_ISFIFO(mode) ||\n\t\t   S_ISSOCK(mode)) {\n\t\tinode->i_op = &ntfs_special_inode_operations;\n\t\tinit_special_inode(inode, mode, inode->i_rdev);\n\t} else if (fname && fname->home.low == cpu_to_le32(MFT_REC_EXTEND) &&\n\t\t   fname->home.seq == cpu_to_le16(MFT_REC_EXTEND)) {\n\t\t/* Records in $Extend are not a files or general directories. */\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t} else {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif ((sbi->options->sys_immutable &&\n\t     (std5->fa & FILE_ATTRIBUTE_SYSTEM)) &&\n\t    !S_ISFIFO(mode) && !S_ISSOCK(mode) && !S_ISLNK(mode)) {\n\t\tinode->i_flags |= S_IMMUTABLE;\n\t} else {\n\t\tinode->i_flags &= ~S_IMMUTABLE;\n\t}\n\n\tinode->i_mode = mode;\n\tif (!(ni->ni_flags & NI_FLAG_EA)) {\n\t\t/* If no xattr then no security (stored in xattr). */\n\t\tinode->i_flags |= S_NOSEC;\n\t}\n\n\tif (ino == MFT_REC_MFT && !sb->s_root)\n\t\tsbi->mft.ni = NULL;\n\n\tunlock_new_inode(inode);\n\n\treturn inode;\n\nout:\n\tif (ino == MFT_REC_MFT && !sb->s_root)\n\t\tsbi->mft.ni = NULL;\n\n\tiget_failed(inode);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -59,7 +59,7 @@\n \t\t\t le16_to_cpu(ref->seq), le16_to_cpu(rec->seq));\n \t\tgoto out;\n \t} else if (!is_rec_inuse(rec)) {\n-\t\terr = -EINVAL;\n+\t\terr = -ESTALE;\n \t\tntfs_err(sb, \"Inode r=%x is not in use!\", (u32)ino);\n \t\tgoto out;\n \t}\n@@ -70,8 +70,10 @@\n \t\tgoto out;\n \t}\n \n-\tif (!is_rec_base(rec))\n-\t\tgoto Ok;\n+\tif (!is_rec_base(rec)) {\n+\t\terr = -EINVAL;\n+\t\tgoto out;\n+\t}\n \n \t/* Record should contain $I30 root. */\n \tis_dir = rec->flags & RECORD_FLAG_DIR;\n@@ -444,7 +446,6 @@\n \t\tinode->i_flags |= S_NOSEC;\n \t}\n \n-Ok:\n \tif (ino == MFT_REC_MFT && !sb->s_root)\n \t\tsbi->mft.ni = NULL;\n ",
        "function_modified_lines": {
            "added": [
                "\t\terr = -ESTALE;",
                "\tif (!is_rec_base(rec)) {",
                "\t\terr = -EINVAL;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": [
                "\t\terr = -EINVAL;",
                "\tif (!is_rec_base(rec))",
                "\t\tgoto Ok;",
                "Ok:"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3795
    },
    {
        "cve_id": "CVE-2017-9984",
        "code_before_change": "static irqreturn_t snd_msnd_interrupt(int irq, void *dev_id)\n{\n\tstruct snd_msnd *chip = dev_id;\n\tvoid *pwDSPQData = chip->mappedbase + DSPQ_DATA_BUFF;\n\n\t/* Send ack to DSP */\n\t/* inb(chip->io + HP_RXL); */\n\n\t/* Evaluate queued DSP messages */\n\twhile (readw(chip->DSPQ + JQS_wTail) != readw(chip->DSPQ + JQS_wHead)) {\n\t\tu16 wTmp;\n\n\t\tsnd_msnd_eval_dsp_msg(chip,\n\t\t\treadw(pwDSPQData + 2 * readw(chip->DSPQ + JQS_wHead)));\n\n\t\twTmp = readw(chip->DSPQ + JQS_wHead) + 1;\n\t\tif (wTmp > readw(chip->DSPQ + JQS_wSize))\n\t\t\twritew(0, chip->DSPQ + JQS_wHead);\n\t\telse\n\t\t\twritew(wTmp, chip->DSPQ + JQS_wHead);\n\t}\n\t/* Send ack to DSP */\n\tinb(chip->io + HP_RXL);\n\treturn IRQ_HANDLED;\n}",
        "code_after_change": "static irqreturn_t snd_msnd_interrupt(int irq, void *dev_id)\n{\n\tstruct snd_msnd *chip = dev_id;\n\tvoid *pwDSPQData = chip->mappedbase + DSPQ_DATA_BUFF;\n\tu16 head, tail, size;\n\n\t/* Send ack to DSP */\n\t/* inb(chip->io + HP_RXL); */\n\n\t/* Evaluate queued DSP messages */\n\thead = readw(chip->DSPQ + JQS_wHead);\n\ttail = readw(chip->DSPQ + JQS_wTail);\n\tsize = readw(chip->DSPQ + JQS_wSize);\n\tif (head > size || tail > size)\n\t\tgoto out;\n\twhile (head != tail) {\n\t\tsnd_msnd_eval_dsp_msg(chip, readw(pwDSPQData + 2 * head));\n\t\tif (++head > size)\n\t\t\thead = 0;\n\t\twritew(head, chip->DSPQ + JQS_wHead);\n\t}\n out:\n\t/* Send ack to DSP */\n\tinb(chip->io + HP_RXL);\n\treturn IRQ_HANDLED;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,23 +2,24 @@\n {\n \tstruct snd_msnd *chip = dev_id;\n \tvoid *pwDSPQData = chip->mappedbase + DSPQ_DATA_BUFF;\n+\tu16 head, tail, size;\n \n \t/* Send ack to DSP */\n \t/* inb(chip->io + HP_RXL); */\n \n \t/* Evaluate queued DSP messages */\n-\twhile (readw(chip->DSPQ + JQS_wTail) != readw(chip->DSPQ + JQS_wHead)) {\n-\t\tu16 wTmp;\n-\n-\t\tsnd_msnd_eval_dsp_msg(chip,\n-\t\t\treadw(pwDSPQData + 2 * readw(chip->DSPQ + JQS_wHead)));\n-\n-\t\twTmp = readw(chip->DSPQ + JQS_wHead) + 1;\n-\t\tif (wTmp > readw(chip->DSPQ + JQS_wSize))\n-\t\t\twritew(0, chip->DSPQ + JQS_wHead);\n-\t\telse\n-\t\t\twritew(wTmp, chip->DSPQ + JQS_wHead);\n+\thead = readw(chip->DSPQ + JQS_wHead);\n+\ttail = readw(chip->DSPQ + JQS_wTail);\n+\tsize = readw(chip->DSPQ + JQS_wSize);\n+\tif (head > size || tail > size)\n+\t\tgoto out;\n+\twhile (head != tail) {\n+\t\tsnd_msnd_eval_dsp_msg(chip, readw(pwDSPQData + 2 * head));\n+\t\tif (++head > size)\n+\t\t\thead = 0;\n+\t\twritew(head, chip->DSPQ + JQS_wHead);\n \t}\n+ out:\n \t/* Send ack to DSP */\n \tinb(chip->io + HP_RXL);\n \treturn IRQ_HANDLED;",
        "function_modified_lines": {
            "added": [
                "\tu16 head, tail, size;",
                "\thead = readw(chip->DSPQ + JQS_wHead);",
                "\ttail = readw(chip->DSPQ + JQS_wTail);",
                "\tsize = readw(chip->DSPQ + JQS_wSize);",
                "\tif (head > size || tail > size)",
                "\t\tgoto out;",
                "\twhile (head != tail) {",
                "\t\tsnd_msnd_eval_dsp_msg(chip, readw(pwDSPQData + 2 * head));",
                "\t\tif (++head > size)",
                "\t\t\thead = 0;",
                "\t\twritew(head, chip->DSPQ + JQS_wHead);",
                " out:"
            ],
            "deleted": [
                "\twhile (readw(chip->DSPQ + JQS_wTail) != readw(chip->DSPQ + JQS_wHead)) {",
                "\t\tu16 wTmp;",
                "",
                "\t\tsnd_msnd_eval_dsp_msg(chip,",
                "\t\t\treadw(pwDSPQData + 2 * readw(chip->DSPQ + JQS_wHead)));",
                "",
                "\t\twTmp = readw(chip->DSPQ + JQS_wHead) + 1;",
                "\t\tif (wTmp > readw(chip->DSPQ + JQS_wSize))",
                "\t\t\twritew(0, chip->DSPQ + JQS_wHead);",
                "\t\telse",
                "\t\t\twritew(wTmp, chip->DSPQ + JQS_wHead);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The snd_msnd_interrupt function in sound/isa/msnd/msnd_pinnacle.c in the Linux kernel through 4.11.7 allows local users to cause a denial of service (over-boundary access) or possibly have unspecified other impact by changing the value of a message queue head pointer between two kernel reads of that value, aka a \"double fetch\" vulnerability.",
        "id": 1572
    },
    {
        "cve_id": "CVE-2022-2785",
        "code_before_change": "static inline int skel_sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t  unsigned int size)\n{\n#ifdef __KERNEL__\n\treturn bpf_sys_bpf(cmd, attr, size);\n#else\n\treturn syscall(__NR_bpf, cmd, attr, size);\n#endif\n}",
        "code_after_change": "static inline int skel_sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t  unsigned int size)\n{\n#ifdef __KERNEL__\n\treturn kern_sys_bpf(cmd, attr, size);\n#else\n\treturn syscall(__NR_bpf, cmd, attr, size);\n#endif\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t  unsigned int size)\n {\n #ifdef __KERNEL__\n-\treturn bpf_sys_bpf(cmd, attr, size);\n+\treturn kern_sys_bpf(cmd, attr, size);\n #else\n \treturn syscall(__NR_bpf, cmd, attr, size);\n #endif",
        "function_modified_lines": {
            "added": [
                "\treturn kern_sys_bpf(cmd, attr, size);"
            ],
            "deleted": [
                "\treturn bpf_sys_bpf(cmd, attr, size);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "There exists an arbitrary memory read within the Linux Kernel BPF - Constants provided to fill pointers in structs passed in to bpf_sys_bpf are not verified and can point anywhere, including memory not owned by BPF. An attacker with CAP_BPF can arbitrarily read memory from anywhere on the system. We recommend upgrading past commit 86f44fcec22c",
        "id": 3497
    },
    {
        "cve_id": "CVE-2017-16530",
        "code_before_change": "static int uas_use_uas_driver(struct usb_interface *intf,\n\t\t\t      const struct usb_device_id *id,\n\t\t\t      unsigned long *flags_ret)\n{\n\tstruct usb_host_endpoint *eps[4] = { };\n\tstruct usb_device *udev = interface_to_usbdev(intf);\n\tstruct usb_hcd *hcd = bus_to_hcd(udev->bus);\n\tunsigned long flags = id->driver_info;\n\tint r, alt;\n\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn 0;\n\n\tr = uas_find_endpoints(&intf->altsetting[alt], eps);\n\tif (r < 0)\n\t\treturn 0;\n\n\t/*\n\t * ASMedia has a number of usb3 to sata bridge chips, at the time of\n\t * this writing the following versions exist:\n\t * ASM1051 - no uas support version\n\t * ASM1051 - with broken (*) uas support\n\t * ASM1053 - with working uas support, but problems with large xfers\n\t * ASM1153 - with working uas support\n\t *\n\t * Devices with these chips re-use a number of device-ids over the\n\t * entire line, so the device-id is useless to determine if we're\n\t * dealing with an ASM1051 (which we want to avoid).\n\t *\n\t * The ASM1153 can be identified by config.MaxPower == 0,\n\t * where as the ASM105x models have config.MaxPower == 36.\n\t *\n\t * Differentiating between the ASM1053 and ASM1051 is trickier, when\n\t * connected over USB-3 we can look at the number of streams supported,\n\t * ASM1051 supports 32 streams, where as early ASM1053 versions support\n\t * 16 streams, newer ASM1053-s also support 32 streams, but have a\n\t * different prod-id.\n\t *\n\t * (*) ASM1051 chips do work with UAS with some disks (with the\n\t *     US_FL_NO_REPORT_OPCODES quirk), but are broken with other disks\n\t */\n\tif (le16_to_cpu(udev->descriptor.idVendor) == 0x174c &&\n\t\t\t(le16_to_cpu(udev->descriptor.idProduct) == 0x5106 ||\n\t\t\t le16_to_cpu(udev->descriptor.idProduct) == 0x55aa)) {\n\t\tif (udev->actconfig->desc.bMaxPower == 0) {\n\t\t\t/* ASM1153, do nothing */\n\t\t} else if (udev->speed < USB_SPEED_SUPER) {\n\t\t\t/* No streams info, assume ASM1051 */\n\t\t\tflags |= US_FL_IGNORE_UAS;\n\t\t} else if (usb_ss_max_streams(&eps[1]->ss_ep_comp) == 32) {\n\t\t\t/* Possibly an ASM1051, disable uas */\n\t\t\tflags |= US_FL_IGNORE_UAS;\n\t\t} else {\n\t\t\t/* ASM1053, these have issues with large transfers */\n\t\t\tflags |= US_FL_MAX_SECTORS_240;\n\t\t}\n\t}\n\n\tusb_stor_adjust_quirks(udev, &flags);\n\n\tif (flags & US_FL_IGNORE_UAS) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"UAS is blacklisted for this device, using usb-storage instead\\n\");\n\t\treturn 0;\n\t}\n\n\tif (udev->bus->sg_tablesize == 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"The driver for the USB controller %s does not support scatter-gather which is\\n\",\n\t\t\thcd->driver->description);\n\t\tdev_warn(&udev->dev,\n\t\t\t\"required by the UAS driver. Please try an other USB controller if you wish to use UAS.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (udev->speed >= USB_SPEED_SUPER && !hcd->can_do_streams) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"USB controller %s does not support streams, which are required by the UAS driver.\\n\",\n\t\t\thcd_to_bus(hcd)->bus_name);\n\t\tdev_warn(&udev->dev,\n\t\t\t\"Please try an other USB controller if you wish to use UAS.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (flags_ret)\n\t\t*flags_ret = flags;\n\n\treturn 1;\n}",
        "code_after_change": "static int uas_use_uas_driver(struct usb_interface *intf,\n\t\t\t      const struct usb_device_id *id,\n\t\t\t      unsigned long *flags_ret)\n{\n\tstruct usb_host_endpoint *eps[4] = { };\n\tstruct usb_device *udev = interface_to_usbdev(intf);\n\tstruct usb_hcd *hcd = bus_to_hcd(udev->bus);\n\tunsigned long flags = id->driver_info;\n\tstruct usb_host_interface *alt;\n\tint r;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn 0;\n\n\tr = uas_find_endpoints(alt, eps);\n\tif (r < 0)\n\t\treturn 0;\n\n\t/*\n\t * ASMedia has a number of usb3 to sata bridge chips, at the time of\n\t * this writing the following versions exist:\n\t * ASM1051 - no uas support version\n\t * ASM1051 - with broken (*) uas support\n\t * ASM1053 - with working uas support, but problems with large xfers\n\t * ASM1153 - with working uas support\n\t *\n\t * Devices with these chips re-use a number of device-ids over the\n\t * entire line, so the device-id is useless to determine if we're\n\t * dealing with an ASM1051 (which we want to avoid).\n\t *\n\t * The ASM1153 can be identified by config.MaxPower == 0,\n\t * where as the ASM105x models have config.MaxPower == 36.\n\t *\n\t * Differentiating between the ASM1053 and ASM1051 is trickier, when\n\t * connected over USB-3 we can look at the number of streams supported,\n\t * ASM1051 supports 32 streams, where as early ASM1053 versions support\n\t * 16 streams, newer ASM1053-s also support 32 streams, but have a\n\t * different prod-id.\n\t *\n\t * (*) ASM1051 chips do work with UAS with some disks (with the\n\t *     US_FL_NO_REPORT_OPCODES quirk), but are broken with other disks\n\t */\n\tif (le16_to_cpu(udev->descriptor.idVendor) == 0x174c &&\n\t\t\t(le16_to_cpu(udev->descriptor.idProduct) == 0x5106 ||\n\t\t\t le16_to_cpu(udev->descriptor.idProduct) == 0x55aa)) {\n\t\tif (udev->actconfig->desc.bMaxPower == 0) {\n\t\t\t/* ASM1153, do nothing */\n\t\t} else if (udev->speed < USB_SPEED_SUPER) {\n\t\t\t/* No streams info, assume ASM1051 */\n\t\t\tflags |= US_FL_IGNORE_UAS;\n\t\t} else if (usb_ss_max_streams(&eps[1]->ss_ep_comp) == 32) {\n\t\t\t/* Possibly an ASM1051, disable uas */\n\t\t\tflags |= US_FL_IGNORE_UAS;\n\t\t} else {\n\t\t\t/* ASM1053, these have issues with large transfers */\n\t\t\tflags |= US_FL_MAX_SECTORS_240;\n\t\t}\n\t}\n\n\tusb_stor_adjust_quirks(udev, &flags);\n\n\tif (flags & US_FL_IGNORE_UAS) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"UAS is blacklisted for this device, using usb-storage instead\\n\");\n\t\treturn 0;\n\t}\n\n\tif (udev->bus->sg_tablesize == 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"The driver for the USB controller %s does not support scatter-gather which is\\n\",\n\t\t\thcd->driver->description);\n\t\tdev_warn(&udev->dev,\n\t\t\t\"required by the UAS driver. Please try an other USB controller if you wish to use UAS.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (udev->speed >= USB_SPEED_SUPER && !hcd->can_do_streams) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\"USB controller %s does not support streams, which are required by the UAS driver.\\n\",\n\t\t\thcd_to_bus(hcd)->bus_name);\n\t\tdev_warn(&udev->dev,\n\t\t\t\"Please try an other USB controller if you wish to use UAS.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (flags_ret)\n\t\t*flags_ret = flags;\n\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,14 +6,14 @@\n \tstruct usb_device *udev = interface_to_usbdev(intf);\n \tstruct usb_hcd *hcd = bus_to_hcd(udev->bus);\n \tunsigned long flags = id->driver_info;\n-\tint r, alt;\n-\n+\tstruct usb_host_interface *alt;\n+\tint r;\n \n \talt = uas_find_uas_alt_setting(intf);\n-\tif (alt < 0)\n+\tif (!alt)\n \t\treturn 0;\n \n-\tr = uas_find_endpoints(&intf->altsetting[alt], eps);\n+\tr = uas_find_endpoints(alt, eps);\n \tif (r < 0)\n \t\treturn 0;\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_host_interface *alt;",
                "\tint r;",
                "\tif (!alt)",
                "\tr = uas_find_endpoints(alt, eps);"
            ],
            "deleted": [
                "\tint r, alt;",
                "",
                "\tif (alt < 0)",
                "\tr = uas_find_endpoints(&intf->altsetting[alt], eps);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The uas driver in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device, related to drivers/usb/storage/uas-detect.h and drivers/usb/storage/uas.c.",
        "id": 1317
    },
    {
        "cve_id": "CVE-2017-16535",
        "code_before_change": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\t\tlength = cap->bLength;\n\n\t\tif (total_len < length)\n\t\t\tbreak;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}",
        "code_after_change": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\n\t\tif (total_len < sizeof(*cap) || total_len < cap->bLength) {\n\t\t\tdev->bos->desc->bNumDeviceCaps = i;\n\t\t\tbreak;\n\t\t}\n\t\tlength = cap->bLength;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -52,10 +52,12 @@\n \tfor (i = 0; i < num; i++) {\n \t\tbuffer += length;\n \t\tcap = (struct usb_dev_cap_header *)buffer;\n+\n+\t\tif (total_len < sizeof(*cap) || total_len < cap->bLength) {\n+\t\t\tdev->bos->desc->bNumDeviceCaps = i;\n+\t\t\tbreak;\n+\t\t}\n \t\tlength = cap->bLength;\n-\n-\t\tif (total_len < length)\n-\t\t\tbreak;\n \t\ttotal_len -= length;\n \n \t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t\tif (total_len < sizeof(*cap) || total_len < cap->bLength) {",
                "\t\t\tdev->bos->desc->bNumDeviceCaps = i;",
                "\t\t\tbreak;",
                "\t\t}"
            ],
            "deleted": [
                "",
                "\t\tif (total_len < length)",
                "\t\t\tbreak;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The usb_get_bos_descriptor function in drivers/usb/core/config.c in the Linux kernel before 4.13.10 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1322
    },
    {
        "cve_id": "CVE-2018-13098",
        "code_before_change": "static bool sanity_check_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "code_after_change": "static bool sanity_check_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode) &&\n\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n\t\t\t\"but extra_attr feature is off\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,5 +10,15 @@\n \t\t\t__func__, inode->i_ino);\n \t\treturn false;\n \t}\n+\n+\tif (f2fs_has_extra_attr(inode) &&\n+\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n+\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n+\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n+\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n+\t\t\t\"but extra_attr feature is off\",\n+\t\t\t__func__, inode->i_ino);\n+\t\treturn false;\n+\t}\n \treturn true;\n }",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (f2fs_has_extra_attr(inode) &&",
                "\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {",
                "\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);",
                "\t\tf2fs_msg(sbi->sb, KERN_WARNING,",
                "\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"",
                "\t\t\t\"but extra_attr feature is off\",",
                "\t\t\t__func__, inode->i_ino);",
                "\t\treturn false;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inode.c in the Linux kernel through 4.17.3. A denial of service (slab out-of-bounds read and BUG) can occur for a modified f2fs filesystem image in which FI_EXTRA_ATTR is set in an inode.",
        "id": 1671
    },
    {
        "cve_id": "CVE-2020-13143",
        "code_before_change": "static ssize_t gadget_dev_desc_UDC_store(struct config_item *item,\n\t\tconst char *page, size_t len)\n{\n\tstruct gadget_info *gi = to_gadget_info(item);\n\tchar *name;\n\tint ret;\n\n\tname = kstrdup(page, GFP_KERNEL);\n\tif (!name)\n\t\treturn -ENOMEM;\n\tif (name[len - 1] == '\\n')\n\t\tname[len - 1] = '\\0';\n\n\tmutex_lock(&gi->lock);\n\n\tif (!strlen(name)) {\n\t\tret = unregister_gadget(gi);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tkfree(name);\n\t} else {\n\t\tif (gi->composite.gadget_driver.udc_name) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto err;\n\t\t}\n\t\tgi->composite.gadget_driver.udc_name = name;\n\t\tret = usb_gadget_probe_driver(&gi->composite.gadget_driver);\n\t\tif (ret) {\n\t\t\tgi->composite.gadget_driver.udc_name = NULL;\n\t\t\tgoto err;\n\t\t}\n\t}\n\tmutex_unlock(&gi->lock);\n\treturn len;\nerr:\n\tkfree(name);\n\tmutex_unlock(&gi->lock);\n\treturn ret;\n}",
        "code_after_change": "static ssize_t gadget_dev_desc_UDC_store(struct config_item *item,\n\t\tconst char *page, size_t len)\n{\n\tstruct gadget_info *gi = to_gadget_info(item);\n\tchar *name;\n\tint ret;\n\n\tif (strlen(page) < len)\n\t\treturn -EOVERFLOW;\n\n\tname = kstrdup(page, GFP_KERNEL);\n\tif (!name)\n\t\treturn -ENOMEM;\n\tif (name[len - 1] == '\\n')\n\t\tname[len - 1] = '\\0';\n\n\tmutex_lock(&gi->lock);\n\n\tif (!strlen(name)) {\n\t\tret = unregister_gadget(gi);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tkfree(name);\n\t} else {\n\t\tif (gi->composite.gadget_driver.udc_name) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto err;\n\t\t}\n\t\tgi->composite.gadget_driver.udc_name = name;\n\t\tret = usb_gadget_probe_driver(&gi->composite.gadget_driver);\n\t\tif (ret) {\n\t\t\tgi->composite.gadget_driver.udc_name = NULL;\n\t\t\tgoto err;\n\t\t}\n\t}\n\tmutex_unlock(&gi->lock);\n\treturn len;\nerr:\n\tkfree(name);\n\tmutex_unlock(&gi->lock);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tstruct gadget_info *gi = to_gadget_info(item);\n \tchar *name;\n \tint ret;\n+\n+\tif (strlen(page) < len)\n+\t\treturn -EOVERFLOW;\n \n \tname = kstrdup(page, GFP_KERNEL);\n \tif (!name)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (strlen(page) < len)",
                "\t\treturn -EOVERFLOW;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "gadget_dev_desc_UDC_store in drivers/usb/gadget/configfs.c in the Linux kernel 3.16 through 5.6.13 relies on kstrdup without considering the possibility of an internal '\\0' value, which allows attackers to trigger an out-of-bounds read, aka CID-15753588bcd4.",
        "id": 2501
    },
    {
        "cve_id": "CVE-2023-38430",
        "code_before_change": "bool ksmbd_smb_request(struct ksmbd_conn *conn)\n{\n\treturn conn->request_buf[0] == 0;\n}",
        "code_after_change": "bool ksmbd_smb_request(struct ksmbd_conn *conn)\n{\n\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);\n\n\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {\n\t\tpr_err_ratelimited(\"smb2 compression not support yet\");\n\t\treturn false;\n\t}\n\n\tif (*proto != SMB1_PROTO_NUMBER &&\n\t    *proto != SMB2_PROTO_NUMBER &&\n\t    *proto != SMB2_TRANSFORM_PROTO_NUM)\n\t\treturn false;\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,16 @@\n bool ksmbd_smb_request(struct ksmbd_conn *conn)\n {\n-\treturn conn->request_buf[0] == 0;\n+\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);\n+\n+\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {\n+\t\tpr_err_ratelimited(\"smb2 compression not support yet\");\n+\t\treturn false;\n+\t}\n+\n+\tif (*proto != SMB1_PROTO_NUMBER &&\n+\t    *proto != SMB2_PROTO_NUMBER &&\n+\t    *proto != SMB2_TRANSFORM_PROTO_NUM)\n+\t\treturn false;\n+\n+\treturn true;\n }",
        "function_modified_lines": {
            "added": [
                "\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);",
                "",
                "\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {",
                "\t\tpr_err_ratelimited(\"smb2 compression not support yet\");",
                "\t\treturn false;",
                "\t}",
                "",
                "\tif (*proto != SMB1_PROTO_NUMBER &&",
                "\t    *proto != SMB2_PROTO_NUMBER &&",
                "\t    *proto != SMB2_TRANSFORM_PROTO_NUM)",
                "\t\treturn false;",
                "",
                "\treturn true;"
            ],
            "deleted": [
                "\treturn conn->request_buf[0] == 0;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.9. ksmbd does not validate the SMB request protocol ID, leading to an out-of-bounds read.",
        "id": 4142
    },
    {
        "cve_id": "CVE-2017-16530",
        "code_before_change": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}",
        "code_after_change": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,12 +1,12 @@\n static int uas_switch_interface(struct usb_device *udev,\n \t\t\t\tstruct usb_interface *intf)\n {\n-\tint alt;\n+\tstruct usb_host_interface *alt;\n \n \talt = uas_find_uas_alt_setting(intf);\n-\tif (alt < 0)\n-\t\treturn alt;\n+\tif (!alt)\n+\t\treturn -ENODEV;\n \n-\treturn usb_set_interface(udev,\n-\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n+\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n+\t\t\talt->desc.bAlternateSetting);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_host_interface *alt;",
                "\tif (!alt)",
                "\t\treturn -ENODEV;",
                "\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,",
                "\t\t\talt->desc.bAlternateSetting);"
            ],
            "deleted": [
                "\tint alt;",
                "\tif (alt < 0)",
                "\t\treturn alt;",
                "\treturn usb_set_interface(udev,",
                "\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The uas driver in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device, related to drivers/usb/storage/uas-detect.h and drivers/usb/storage/uas.c.",
        "id": 1318
    },
    {
        "cve_id": "CVE-2019-15925",
        "code_before_change": "static int hclge_tm_schd_mode_vnet_base_cfg(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tint ret;\n\tu8 i;\n\n\tret = hclge_tm_pri_schd_mode_cfg(hdev, vport->vport_id);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < kinfo->num_tc; i++) {\n\t\tu8 sch_mode = hdev->tm_info.tc_info[i].tc_sch_mode;\n\n\t\tret = hclge_tm_qs_schd_mode_cfg(hdev, vport->qs_offset + i,\n\t\t\t\t\t\tsch_mode);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int hclge_tm_schd_mode_vnet_base_cfg(struct hclge_vport *vport)\n{\n\tstruct hnae3_knic_private_info *kinfo = &vport->nic.kinfo;\n\tstruct hclge_dev *hdev = vport->back;\n\tint ret;\n\tu8 i;\n\n\tif (vport->vport_id >= HNAE3_MAX_TC)\n\t\treturn -EINVAL;\n\n\tret = hclge_tm_pri_schd_mode_cfg(hdev, vport->vport_id);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < kinfo->num_tc; i++) {\n\t\tu8 sch_mode = hdev->tm_info.tc_info[i].tc_sch_mode;\n\n\t\tret = hclge_tm_qs_schd_mode_cfg(hdev, vport->qs_offset + i,\n\t\t\t\t\t\tsch_mode);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tstruct hclge_dev *hdev = vport->back;\n \tint ret;\n \tu8 i;\n+\n+\tif (vport->vport_id >= HNAE3_MAX_TC)\n+\t\treturn -EINVAL;\n \n \tret = hclge_tm_pri_schd_mode_cfg(hdev, vport->vport_id);\n \tif (ret)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (vport->vport_id >= HNAE3_MAX_TC)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. An out of bounds access exists in the function hclge_tm_schd_mode_vnet_base_cfg in the file drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_tm.c.",
        "id": 2038
    },
    {
        "cve_id": "CVE-2017-9074",
        "code_before_change": "static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,\n\tnetdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tstruct ipv6hdr *ipv6h;\n\tconst struct net_offload *ops;\n\tint proto;\n\tstruct frag_hdr *fptr;\n\tunsigned int unfrag_ip6hlen;\n\tunsigned int payload_len;\n\tu8 *prevhdr;\n\tint offset = 0;\n\tbool encap, udpfrag;\n\tint nhoff;\n\tbool gso_partial;\n\n\tskb_reset_network_header(skb);\n\tnhoff = skb_network_header(skb) - skb_mac_header(skb);\n\tif (unlikely(!pskb_may_pull(skb, sizeof(*ipv6h))))\n\t\tgoto out;\n\n\tencap = SKB_GSO_CB(skb)->encap_level > 0;\n\tif (encap)\n\t\tfeatures &= skb->dev->hw_enc_features;\n\tSKB_GSO_CB(skb)->encap_level += sizeof(*ipv6h);\n\n\tipv6h = ipv6_hdr(skb);\n\t__skb_pull(skb, sizeof(*ipv6h));\n\tsegs = ERR_PTR(-EPROTONOSUPPORT);\n\n\tproto = ipv6_gso_pull_exthdrs(skb, ipv6h->nexthdr);\n\n\tif (skb->encapsulation &&\n\t    skb_shinfo(skb)->gso_type & (SKB_GSO_IPXIP4 | SKB_GSO_IPXIP6))\n\t\tudpfrag = proto == IPPROTO_UDP && encap;\n\telse\n\t\tudpfrag = proto == IPPROTO_UDP && !skb->encapsulation;\n\n\tops = rcu_dereference(inet6_offloads[proto]);\n\tif (likely(ops && ops->callbacks.gso_segment)) {\n\t\tskb_reset_transport_header(skb);\n\t\tsegs = ops->callbacks.gso_segment(skb, features);\n\t}\n\n\tif (IS_ERR_OR_NULL(segs))\n\t\tgoto out;\n\n\tgso_partial = !!(skb_shinfo(segs)->gso_type & SKB_GSO_PARTIAL);\n\n\tfor (skb = segs; skb; skb = skb->next) {\n\t\tipv6h = (struct ipv6hdr *)(skb_mac_header(skb) + nhoff);\n\t\tif (gso_partial)\n\t\t\tpayload_len = skb_shinfo(skb)->gso_size +\n\t\t\t\t      SKB_GSO_CB(skb)->data_offset +\n\t\t\t\t      skb->head - (unsigned char *)(ipv6h + 1);\n\t\telse\n\t\t\tpayload_len = skb->len - nhoff - sizeof(*ipv6h);\n\t\tipv6h->payload_len = htons(payload_len);\n\t\tskb->network_header = (u8 *)ipv6h - skb->head;\n\n\t\tif (udpfrag) {\n\t\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\t\tfptr = (struct frag_hdr *)((u8 *)ipv6h + unfrag_ip6hlen);\n\t\t\tfptr->frag_off = htons(offset);\n\t\t\tif (skb->next)\n\t\t\t\tfptr->frag_off |= htons(IP6_MF);\n\t\t\toffset += (ntohs(ipv6h->payload_len) -\n\t\t\t\t   sizeof(struct frag_hdr));\n\t\t}\n\t\tif (encap)\n\t\t\tskb_reset_inner_headers(skb);\n\t}\n\nout:\n\treturn segs;\n}",
        "code_after_change": "static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,\n\tnetdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tstruct ipv6hdr *ipv6h;\n\tconst struct net_offload *ops;\n\tint proto;\n\tstruct frag_hdr *fptr;\n\tunsigned int unfrag_ip6hlen;\n\tunsigned int payload_len;\n\tu8 *prevhdr;\n\tint offset = 0;\n\tbool encap, udpfrag;\n\tint nhoff;\n\tbool gso_partial;\n\n\tskb_reset_network_header(skb);\n\tnhoff = skb_network_header(skb) - skb_mac_header(skb);\n\tif (unlikely(!pskb_may_pull(skb, sizeof(*ipv6h))))\n\t\tgoto out;\n\n\tencap = SKB_GSO_CB(skb)->encap_level > 0;\n\tif (encap)\n\t\tfeatures &= skb->dev->hw_enc_features;\n\tSKB_GSO_CB(skb)->encap_level += sizeof(*ipv6h);\n\n\tipv6h = ipv6_hdr(skb);\n\t__skb_pull(skb, sizeof(*ipv6h));\n\tsegs = ERR_PTR(-EPROTONOSUPPORT);\n\n\tproto = ipv6_gso_pull_exthdrs(skb, ipv6h->nexthdr);\n\n\tif (skb->encapsulation &&\n\t    skb_shinfo(skb)->gso_type & (SKB_GSO_IPXIP4 | SKB_GSO_IPXIP6))\n\t\tudpfrag = proto == IPPROTO_UDP && encap;\n\telse\n\t\tudpfrag = proto == IPPROTO_UDP && !skb->encapsulation;\n\n\tops = rcu_dereference(inet6_offloads[proto]);\n\tif (likely(ops && ops->callbacks.gso_segment)) {\n\t\tskb_reset_transport_header(skb);\n\t\tsegs = ops->callbacks.gso_segment(skb, features);\n\t}\n\n\tif (IS_ERR_OR_NULL(segs))\n\t\tgoto out;\n\n\tgso_partial = !!(skb_shinfo(segs)->gso_type & SKB_GSO_PARTIAL);\n\n\tfor (skb = segs; skb; skb = skb->next) {\n\t\tipv6h = (struct ipv6hdr *)(skb_mac_header(skb) + nhoff);\n\t\tif (gso_partial)\n\t\t\tpayload_len = skb_shinfo(skb)->gso_size +\n\t\t\t\t      SKB_GSO_CB(skb)->data_offset +\n\t\t\t\t      skb->head - (unsigned char *)(ipv6h + 1);\n\t\telse\n\t\t\tpayload_len = skb->len - nhoff - sizeof(*ipv6h);\n\t\tipv6h->payload_len = htons(payload_len);\n\t\tskb->network_header = (u8 *)ipv6h - skb->head;\n\n\t\tif (udpfrag) {\n\t\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\t\tif (unfrag_ip6hlen < 0)\n\t\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n\t\t\tfptr = (struct frag_hdr *)((u8 *)ipv6h + unfrag_ip6hlen);\n\t\t\tfptr->frag_off = htons(offset);\n\t\t\tif (skb->next)\n\t\t\t\tfptr->frag_off |= htons(IP6_MF);\n\t\t\toffset += (ntohs(ipv6h->payload_len) -\n\t\t\t\t   sizeof(struct frag_hdr));\n\t\t}\n\t\tif (encap)\n\t\t\tskb_reset_inner_headers(skb);\n\t}\n\nout:\n\treturn segs;\n}",
        "patch": "--- code before\n+++ code after\n@@ -60,6 +60,8 @@\n \n \t\tif (udpfrag) {\n \t\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n+\t\t\tif (unfrag_ip6hlen < 0)\n+\t\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n \t\t\tfptr = (struct frag_hdr *)((u8 *)ipv6h + unfrag_ip6hlen);\n \t\t\tfptr->frag_off = htons(offset);\n \t\t\tif (skb->next)",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (unfrag_ip6hlen < 0)",
                "\t\t\t\treturn ERR_PTR(unfrag_ip6hlen);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The IPv6 fragmentation implementation in the Linux kernel through 4.11.1 does not consider that the nexthdr field may be associated with an invalid option, which allows local users to cause a denial of service (out-of-bounds read and BUG) or possibly have unspecified other impact via crafted socket and send system calls.",
        "id": 1561
    },
    {
        "cve_id": "CVE-2020-0430",
        "code_before_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected_type, type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (arg_type == ARG_PTR_TO_MAP_KEY ||\n\t    arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\texpected_type = PTR_TO_STACK;\n\t\tif (!type_is_pkt_pointer(type) && type != PTR_TO_MAP_VALUE &&\n\t\t    type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_SIZE ||\n\t\t   arg_type == ARG_CONST_SIZE_OR_ZERO) {\n\t\texpected_type = SCALAR_VALUE;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_MAP_PTR) {\n\t\texpected_type = CONST_PTR_TO_MAP;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_PTR_TO_CTX) {\n\t\texpected_type = PTR_TO_CTX;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\texpected_type = PTR_TO_STACK;\n\t\t/* One exception here. In case function allows for NULL to be\n\t\t * passed in as argument, it's a SCALAR_VALUE type. Final test\n\t\t * happens during stack boundary checking.\n\t\t */\n\t\tif (register_is_null(reg) &&\n\t\t    arg_type == ARG_PTR_TO_MEM_OR_NULL)\n\t\t\t/* final test in check_stack_boundary() */;\n\t\telse if (!type_is_pkt_pointer(type) &&\n\t\t\t type != PTR_TO_MAP_VALUE &&\n\t\t\t type != expected_type)\n\t\t\tgoto err_type;\n\t\tmeta->raw_mode = arg_type == ARG_PTR_TO_UNINIT_MEM;\n\t} else {\n\t\tverbose(env, \"unsupported arg_type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tmeta->map_ptr = reg->map_ptr;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* remember the mem_size which may be used later\n\t\t * to refine return values.\n\t\t */\n\t\tmeta->msize_smax_value = reg->smax_value;\n\t\tmeta->msize_umax_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t}\n\n\treturn err;\nerr_type:\n\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n\t\treg_type_str[type], reg_type_str[expected_type]);\n\treturn -EACCES;\n}",
        "code_after_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected_type, type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (arg_type == ARG_PTR_TO_MAP_KEY ||\n\t    arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\texpected_type = PTR_TO_STACK;\n\t\tif (!type_is_pkt_pointer(type) && type != PTR_TO_MAP_VALUE &&\n\t\t    type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_SIZE ||\n\t\t   arg_type == ARG_CONST_SIZE_OR_ZERO) {\n\t\texpected_type = SCALAR_VALUE;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_MAP_PTR) {\n\t\texpected_type = CONST_PTR_TO_MAP;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_PTR_TO_CTX) {\n\t\texpected_type = PTR_TO_CTX;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\texpected_type = PTR_TO_STACK;\n\t\t/* One exception here. In case function allows for NULL to be\n\t\t * passed in as argument, it's a SCALAR_VALUE type. Final test\n\t\t * happens during stack boundary checking.\n\t\t */\n\t\tif (register_is_null(reg) &&\n\t\t    arg_type == ARG_PTR_TO_MEM_OR_NULL)\n\t\t\t/* final test in check_stack_boundary() */;\n\t\telse if (!type_is_pkt_pointer(type) &&\n\t\t\t type != PTR_TO_MAP_VALUE &&\n\t\t\t type != expected_type)\n\t\t\tgoto err_type;\n\t\tmeta->raw_mode = arg_type == ARG_PTR_TO_UNINIT_MEM;\n\t} else {\n\t\tverbose(env, \"unsupported arg_type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tmeta->map_ptr = reg->map_ptr;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* remember the mem_size which may be used later\n\t\t * to refine return values.\n\t\t */\n\t\tmeta->msize_smax_value = reg->smax_value;\n\t\tmeta->msize_umax_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t}\n\n\treturn err;\nerr_type:\n\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n\t\treg_type_str[type], reg_type_str[expected_type]);\n\treturn -EACCES;\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,6 +47,9 @@\n \t\texpected_type = PTR_TO_CTX;\n \t\tif (type != expected_type)\n \t\t\tgoto err_type;\n+\t\terr = check_ctx_reg(env, reg, regno);\n+\t\tif (err < 0)\n+\t\t\treturn err;\n \t} else if (arg_type_is_mem_ptr(arg_type)) {\n \t\texpected_type = PTR_TO_STACK;\n \t\t/* One exception here. In case function allows for NULL to be",
        "function_modified_lines": {
            "added": [
                "\t\terr = check_ctx_reg(env, reg, regno);",
                "\t\tif (err < 0)",
                "\t\t\treturn err;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In skb_headlen of /include/linux/skbuff.h, there is a possible out of bounds read due to memory corruption. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-153881554",
        "id": 2384
    },
    {
        "cve_id": "CVE-2017-8831",
        "code_before_change": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\t/* msg wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\t\tmemcpy_fromio((u8 *)msg + space_rem, bus->m_pdwGetRing,\n\t\t\t\tsizeof(*msg) - space_rem);\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg->size = le16_to_cpu((__force __le16)msg->size);\n\tmsg->command = le32_to_cpu((__force __le32)msg->command);\n\tmsg->controlselector = le16_to_cpu((__force __le16)msg->controlselector);\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}",
        "code_after_change": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -75,11 +75,11 @@\n \tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n \tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n \tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n+\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n \n \t/* No need to update the read positions, because this was a peek */\n \t/* If the caller specifically want to peek, return */\n \tif (peekonly) {\n-\t\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n \t\tgoto peekout;\n \t}\n \n@@ -124,21 +124,15 @@\n \t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n \n \t\tif (space_rem < sizeof(*msg)) {\n-\t\t\t/* msg wraps around the ring */\n-\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, space_rem);\n-\t\t\tmemcpy_fromio((u8 *)msg + space_rem, bus->m_pdwGetRing,\n-\t\t\t\tsizeof(*msg) - space_rem);\n \t\t\tif (buf)\n \t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n \t\t\t\t\tspace_rem, buf_size);\n \n \t\t} else if (space_rem == sizeof(*msg)) {\n-\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n \t\t\tif (buf)\n \t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n \t\t} else {\n \t\t\t/* Additional data wraps around the ring */\n-\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n \t\t\tif (buf) {\n \t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n \t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n@@ -151,15 +145,10 @@\n \n \t} else {\n \t\t/* No wrapping */\n-\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n \t\tif (buf)\n \t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n \t\t\t\tbuf_size);\n \t}\n-\t/* Convert from little endian to CPU */\n-\tmsg->size = le16_to_cpu((__force __le16)msg->size);\n-\tmsg->command = le32_to_cpu((__force __le32)msg->command);\n-\tmsg->controlselector = le16_to_cpu((__force __le16)msg->controlselector);\n \n \t/* Update the read positions, adjusting the ring */\n \tsaa7164_writel(bus->m_dwGetReadPos, new_grp);",
        "function_modified_lines": {
            "added": [
                "\tmemcpy(msg, &msg_tmp, sizeof(*msg));"
            ],
            "deleted": [
                "\t\tmemcpy(msg, &msg_tmp, sizeof(*msg));",
                "\t\t\t/* msg wraps around the ring */",
                "\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, space_rem);",
                "\t\t\tmemcpy_fromio((u8 *)msg + space_rem, bus->m_pdwGetRing,",
                "\t\t\t\tsizeof(*msg) - space_rem);",
                "\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));",
                "\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));",
                "\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));",
                "\t/* Convert from little endian to CPU */",
                "\tmsg->size = le16_to_cpu((__force __le16)msg->size);",
                "\tmsg->command = le32_to_cpu((__force __le32)msg->command);",
                "\tmsg->controlselector = le16_to_cpu((__force __le16)msg->controlselector);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The saa7164_bus_get function in drivers/media/pci/saa7164/saa7164-bus.c in the Linux kernel through 4.11.5 allows local users to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact by changing a certain sequence-number value, aka a \"double fetch\" vulnerability.",
        "id": 1555
    },
    {
        "cve_id": "CVE-2023-6606",
        "code_before_change": "int\ncheckSMB(char *buf, unsigned int total_read, struct TCP_Server_Info *server)\n{\n\tstruct smb_hdr *smb = (struct smb_hdr *)buf;\n\t__u32 rfclen = be32_to_cpu(smb->smb_buf_length);\n\t__u32 clc_len;  /* calculated length */\n\tcifs_dbg(FYI, \"checkSMB Length: 0x%x, smb_buf_length: 0x%x\\n\",\n\t\t total_read, rfclen);\n\n\t/* is this frame too small to even get to a BCC? */\n\tif (total_read < 2 + sizeof(struct smb_hdr)) {\n\t\tif ((total_read >= sizeof(struct smb_hdr) - 1)\n\t\t\t    && (smb->Status.CifsError != 0)) {\n\t\t\t/* it's an error return */\n\t\t\tsmb->WordCount = 0;\n\t\t\t/* some error cases do not return wct and bcc */\n\t\t\treturn 0;\n\t\t} else if ((total_read == sizeof(struct smb_hdr) + 1) &&\n\t\t\t\t(smb->WordCount == 0)) {\n\t\t\tchar *tmp = (char *)smb;\n\t\t\t/* Need to work around a bug in two servers here */\n\t\t\t/* First, check if the part of bcc they sent was zero */\n\t\t\tif (tmp[sizeof(struct smb_hdr)] == 0) {\n\t\t\t\t/* some servers return only half of bcc\n\t\t\t\t * on simple responses (wct, bcc both zero)\n\t\t\t\t * in particular have seen this on\n\t\t\t\t * ulogoffX and FindClose. This leaves\n\t\t\t\t * one byte of bcc potentially unitialized\n\t\t\t\t */\n\t\t\t\t/* zero rest of bcc */\n\t\t\t\ttmp[sizeof(struct smb_hdr)+1] = 0;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tcifs_dbg(VFS, \"rcvd invalid byte count (bcc)\\n\");\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than smb header size\\n\");\n\t\t}\n\t\treturn -EIO;\n\t}\n\n\t/* otherwise, there is enough to get to the BCC */\n\tif (check_smb_hdr(smb))\n\t\treturn -EIO;\n\tclc_len = smbCalcSize(smb);\n\n\tif (4 + rfclen != total_read) {\n\t\tcifs_dbg(VFS, \"Length read does not match RFC1001 length %d\\n\",\n\t\t\t rfclen);\n\t\treturn -EIO;\n\t}\n\n\tif (4 + rfclen != clc_len) {\n\t\t__u16 mid = get_mid(smb);\n\t\t/* check if bcc wrapped around for large read responses */\n\t\tif ((rfclen > 64 * 1024) && (rfclen > clc_len)) {\n\t\t\t/* check if lengths match mod 64K */\n\t\t\tif (((4 + rfclen) & 0xFFFF) == (clc_len & 0xFFFF))\n\t\t\t\treturn 0; /* bcc wrapped */\n\t\t}\n\t\tcifs_dbg(FYI, \"Calculated size %u vs length %u mismatch for mid=%u\\n\",\n\t\t\t clc_len, 4 + rfclen, mid);\n\n\t\tif (4 + rfclen < clc_len) {\n\t\t\tcifs_dbg(VFS, \"RFC1001 size %u smaller than SMB for mid=%u\\n\",\n\t\t\t\t rfclen, mid);\n\t\t\treturn -EIO;\n\t\t} else if (rfclen > clc_len + 512) {\n\t\t\t/*\n\t\t\t * Some servers (Windows XP in particular) send more\n\t\t\t * data than the lengths in the SMB packet would\n\t\t\t * indicate on certain calls (byte range locks and\n\t\t\t * trans2 find first calls in particular). While the\n\t\t\t * client can handle such a frame by ignoring the\n\t\t\t * trailing data, we choose limit the amount of extra\n\t\t\t * data to 512 bytes.\n\t\t\t */\n\t\t\tcifs_dbg(VFS, \"RFC1001 size %u more than 512 bytes larger than SMB for mid=%u\\n\",\n\t\t\t\t rfclen, mid);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\treturn 0;\n}",
        "code_after_change": "int\ncheckSMB(char *buf, unsigned int total_read, struct TCP_Server_Info *server)\n{\n\tstruct smb_hdr *smb = (struct smb_hdr *)buf;\n\t__u32 rfclen = be32_to_cpu(smb->smb_buf_length);\n\t__u32 clc_len;  /* calculated length */\n\tcifs_dbg(FYI, \"checkSMB Length: 0x%x, smb_buf_length: 0x%x\\n\",\n\t\t total_read, rfclen);\n\n\t/* is this frame too small to even get to a BCC? */\n\tif (total_read < 2 + sizeof(struct smb_hdr)) {\n\t\tif ((total_read >= sizeof(struct smb_hdr) - 1)\n\t\t\t    && (smb->Status.CifsError != 0)) {\n\t\t\t/* it's an error return */\n\t\t\tsmb->WordCount = 0;\n\t\t\t/* some error cases do not return wct and bcc */\n\t\t\treturn 0;\n\t\t} else if ((total_read == sizeof(struct smb_hdr) + 1) &&\n\t\t\t\t(smb->WordCount == 0)) {\n\t\t\tchar *tmp = (char *)smb;\n\t\t\t/* Need to work around a bug in two servers here */\n\t\t\t/* First, check if the part of bcc they sent was zero */\n\t\t\tif (tmp[sizeof(struct smb_hdr)] == 0) {\n\t\t\t\t/* some servers return only half of bcc\n\t\t\t\t * on simple responses (wct, bcc both zero)\n\t\t\t\t * in particular have seen this on\n\t\t\t\t * ulogoffX and FindClose. This leaves\n\t\t\t\t * one byte of bcc potentially unitialized\n\t\t\t\t */\n\t\t\t\t/* zero rest of bcc */\n\t\t\t\ttmp[sizeof(struct smb_hdr)+1] = 0;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tcifs_dbg(VFS, \"rcvd invalid byte count (bcc)\\n\");\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than smb header size\\n\");\n\t\t}\n\t\treturn -EIO;\n\t} else if (total_read < sizeof(*smb) + 2 * smb->WordCount) {\n\t\tcifs_dbg(VFS, \"%s: can't read BCC due to invalid WordCount(%u)\\n\",\n\t\t\t __func__, smb->WordCount);\n\t\treturn -EIO;\n\t}\n\n\t/* otherwise, there is enough to get to the BCC */\n\tif (check_smb_hdr(smb))\n\t\treturn -EIO;\n\tclc_len = smbCalcSize(smb);\n\n\tif (4 + rfclen != total_read) {\n\t\tcifs_dbg(VFS, \"Length read does not match RFC1001 length %d\\n\",\n\t\t\t rfclen);\n\t\treturn -EIO;\n\t}\n\n\tif (4 + rfclen != clc_len) {\n\t\t__u16 mid = get_mid(smb);\n\t\t/* check if bcc wrapped around for large read responses */\n\t\tif ((rfclen > 64 * 1024) && (rfclen > clc_len)) {\n\t\t\t/* check if lengths match mod 64K */\n\t\t\tif (((4 + rfclen) & 0xFFFF) == (clc_len & 0xFFFF))\n\t\t\t\treturn 0; /* bcc wrapped */\n\t\t}\n\t\tcifs_dbg(FYI, \"Calculated size %u vs length %u mismatch for mid=%u\\n\",\n\t\t\t clc_len, 4 + rfclen, mid);\n\n\t\tif (4 + rfclen < clc_len) {\n\t\t\tcifs_dbg(VFS, \"RFC1001 size %u smaller than SMB for mid=%u\\n\",\n\t\t\t\t rfclen, mid);\n\t\t\treturn -EIO;\n\t\t} else if (rfclen > clc_len + 512) {\n\t\t\t/*\n\t\t\t * Some servers (Windows XP in particular) send more\n\t\t\t * data than the lengths in the SMB packet would\n\t\t\t * indicate on certain calls (byte range locks and\n\t\t\t * trans2 find first calls in particular). While the\n\t\t\t * client can handle such a frame by ignoring the\n\t\t\t * trailing data, we choose limit the amount of extra\n\t\t\t * data to 512 bytes.\n\t\t\t */\n\t\t\tcifs_dbg(VFS, \"RFC1001 size %u more than 512 bytes larger than SMB for mid=%u\\n\",\n\t\t\t\t rfclen, mid);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,6 +35,10 @@\n \t\t} else {\n \t\t\tcifs_dbg(VFS, \"Length less than smb header size\\n\");\n \t\t}\n+\t\treturn -EIO;\n+\t} else if (total_read < sizeof(*smb) + 2 * smb->WordCount) {\n+\t\tcifs_dbg(VFS, \"%s: can't read BCC due to invalid WordCount(%u)\\n\",\n+\t\t\t __func__, smb->WordCount);\n \t\treturn -EIO;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\treturn -EIO;",
                "\t} else if (total_read < sizeof(*smb) + 2 * smb->WordCount) {",
                "\t\tcifs_dbg(VFS, \"%s: can't read BCC due to invalid WordCount(%u)\\n\",",
                "\t\t\t __func__, smb->WordCount);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in smbCalcSize in fs/smb/client/netmisc.c in the Linux Kernel. This issue could allow a local attacker to crash the system or leak internal kernel information.",
        "id": 4304
    },
    {
        "cve_id": "CVE-2023-1194",
        "code_before_change": "struct lease_ctx_info *parse_lease_state(void *open_req)\n{\n\tchar *data_offset;\n\tstruct create_context *cc;\n\tunsigned int next = 0;\n\tchar *name;\n\tbool found = false;\n\tstruct smb2_create_req *req = (struct smb2_create_req *)open_req;\n\tstruct lease_ctx_info *lreq = kzalloc(sizeof(struct lease_ctx_info),\n\t\tGFP_KERNEL);\n\tif (!lreq)\n\t\treturn NULL;\n\n\tdata_offset = (char *)req + le32_to_cpu(req->CreateContextsOffset);\n\tcc = (struct create_context *)data_offset;\n\tdo {\n\t\tcc = (struct create_context *)((char *)cc + next);\n\t\tname = le16_to_cpu(cc->NameOffset) + (char *)cc;\n\t\tif (le16_to_cpu(cc->NameLength) != 4 ||\n\t\t    strncmp(name, SMB2_CREATE_REQUEST_LEASE, 4)) {\n\t\t\tnext = le32_to_cpu(cc->Next);\n\t\t\tcontinue;\n\t\t}\n\t\tfound = true;\n\t\tbreak;\n\t} while (next != 0);\n\n\tif (found) {\n\t\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {\n\t\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;\n\n\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n\t\t\tlreq->req_state = lc->lcontext.LeaseState;\n\t\t\tlreq->flags = lc->lcontext.LeaseFlags;\n\t\t\tlreq->duration = lc->lcontext.LeaseDuration;\n\t\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,\n\t\t\t       SMB2_LEASE_KEY_SIZE);\n\t\t\tlreq->version = 2;\n\t\t} else {\n\t\t\tstruct create_lease *lc = (struct create_lease *)cc;\n\n\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n\t\t\tlreq->req_state = lc->lcontext.LeaseState;\n\t\t\tlreq->flags = lc->lcontext.LeaseFlags;\n\t\t\tlreq->duration = lc->lcontext.LeaseDuration;\n\t\t\tlreq->version = 1;\n\t\t}\n\t\treturn lreq;\n\t}\n\n\tkfree(lreq);\n\treturn NULL;\n}",
        "code_after_change": "struct lease_ctx_info *parse_lease_state(void *open_req)\n{\n\tstruct create_context *cc;\n\tstruct smb2_create_req *req = (struct smb2_create_req *)open_req;\n\tstruct lease_ctx_info *lreq;\n\n\tcc = smb2_find_context_vals(req, SMB2_CREATE_REQUEST_LEASE, 4);\n\tif (IS_ERR_OR_NULL(cc))\n\t\treturn NULL;\n\n\tlreq = kzalloc(sizeof(struct lease_ctx_info), GFP_KERNEL);\n\tif (!lreq)\n\t\treturn NULL;\n\n\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {\n\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;\n\n\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n\t\tlreq->req_state = lc->lcontext.LeaseState;\n\t\tlreq->flags = lc->lcontext.LeaseFlags;\n\t\tlreq->duration = lc->lcontext.LeaseDuration;\n\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,\n\t\t\t\tSMB2_LEASE_KEY_SIZE);\n\t\tlreq->version = 2;\n\t} else {\n\t\tstruct create_lease *lc = (struct create_lease *)cc;\n\n\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n\t\tlreq->req_state = lc->lcontext.LeaseState;\n\t\tlreq->flags = lc->lcontext.LeaseFlags;\n\t\tlreq->duration = lc->lcontext.LeaseDuration;\n\t\tlreq->version = 1;\n\t}\n\treturn lreq;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,53 +1,35 @@\n struct lease_ctx_info *parse_lease_state(void *open_req)\n {\n-\tchar *data_offset;\n \tstruct create_context *cc;\n-\tunsigned int next = 0;\n-\tchar *name;\n-\tbool found = false;\n \tstruct smb2_create_req *req = (struct smb2_create_req *)open_req;\n-\tstruct lease_ctx_info *lreq = kzalloc(sizeof(struct lease_ctx_info),\n-\t\tGFP_KERNEL);\n+\tstruct lease_ctx_info *lreq;\n+\n+\tcc = smb2_find_context_vals(req, SMB2_CREATE_REQUEST_LEASE, 4);\n+\tif (IS_ERR_OR_NULL(cc))\n+\t\treturn NULL;\n+\n+\tlreq = kzalloc(sizeof(struct lease_ctx_info), GFP_KERNEL);\n \tif (!lreq)\n \t\treturn NULL;\n \n-\tdata_offset = (char *)req + le32_to_cpu(req->CreateContextsOffset);\n-\tcc = (struct create_context *)data_offset;\n-\tdo {\n-\t\tcc = (struct create_context *)((char *)cc + next);\n-\t\tname = le16_to_cpu(cc->NameOffset) + (char *)cc;\n-\t\tif (le16_to_cpu(cc->NameLength) != 4 ||\n-\t\t    strncmp(name, SMB2_CREATE_REQUEST_LEASE, 4)) {\n-\t\t\tnext = le32_to_cpu(cc->Next);\n-\t\t\tcontinue;\n-\t\t}\n-\t\tfound = true;\n-\t\tbreak;\n-\t} while (next != 0);\n+\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {\n+\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;\n \n-\tif (found) {\n-\t\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {\n-\t\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;\n+\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n+\t\tlreq->req_state = lc->lcontext.LeaseState;\n+\t\tlreq->flags = lc->lcontext.LeaseFlags;\n+\t\tlreq->duration = lc->lcontext.LeaseDuration;\n+\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,\n+\t\t\t\tSMB2_LEASE_KEY_SIZE);\n+\t\tlreq->version = 2;\n+\t} else {\n+\t\tstruct create_lease *lc = (struct create_lease *)cc;\n \n-\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n-\t\t\tlreq->req_state = lc->lcontext.LeaseState;\n-\t\t\tlreq->flags = lc->lcontext.LeaseFlags;\n-\t\t\tlreq->duration = lc->lcontext.LeaseDuration;\n-\t\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,\n-\t\t\t       SMB2_LEASE_KEY_SIZE);\n-\t\t\tlreq->version = 2;\n-\t\t} else {\n-\t\t\tstruct create_lease *lc = (struct create_lease *)cc;\n-\n-\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n-\t\t\tlreq->req_state = lc->lcontext.LeaseState;\n-\t\t\tlreq->flags = lc->lcontext.LeaseFlags;\n-\t\t\tlreq->duration = lc->lcontext.LeaseDuration;\n-\t\t\tlreq->version = 1;\n-\t\t}\n-\t\treturn lreq;\n+\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);\n+\t\tlreq->req_state = lc->lcontext.LeaseState;\n+\t\tlreq->flags = lc->lcontext.LeaseFlags;\n+\t\tlreq->duration = lc->lcontext.LeaseDuration;\n+\t\tlreq->version = 1;\n \t}\n-\n-\tkfree(lreq);\n-\treturn NULL;\n+\treturn lreq;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct lease_ctx_info *lreq;",
                "",
                "\tcc = smb2_find_context_vals(req, SMB2_CREATE_REQUEST_LEASE, 4);",
                "\tif (IS_ERR_OR_NULL(cc))",
                "\t\treturn NULL;",
                "",
                "\tlreq = kzalloc(sizeof(struct lease_ctx_info), GFP_KERNEL);",
                "\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {",
                "\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;",
                "\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);",
                "\t\tlreq->req_state = lc->lcontext.LeaseState;",
                "\t\tlreq->flags = lc->lcontext.LeaseFlags;",
                "\t\tlreq->duration = lc->lcontext.LeaseDuration;",
                "\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,",
                "\t\t\t\tSMB2_LEASE_KEY_SIZE);",
                "\t\tlreq->version = 2;",
                "\t} else {",
                "\t\tstruct create_lease *lc = (struct create_lease *)cc;",
                "\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);",
                "\t\tlreq->req_state = lc->lcontext.LeaseState;",
                "\t\tlreq->flags = lc->lcontext.LeaseFlags;",
                "\t\tlreq->duration = lc->lcontext.LeaseDuration;",
                "\t\tlreq->version = 1;",
                "\treturn lreq;"
            ],
            "deleted": [
                "\tchar *data_offset;",
                "\tunsigned int next = 0;",
                "\tchar *name;",
                "\tbool found = false;",
                "\tstruct lease_ctx_info *lreq = kzalloc(sizeof(struct lease_ctx_info),",
                "\t\tGFP_KERNEL);",
                "\tdata_offset = (char *)req + le32_to_cpu(req->CreateContextsOffset);",
                "\tcc = (struct create_context *)data_offset;",
                "\tdo {",
                "\t\tcc = (struct create_context *)((char *)cc + next);",
                "\t\tname = le16_to_cpu(cc->NameOffset) + (char *)cc;",
                "\t\tif (le16_to_cpu(cc->NameLength) != 4 ||",
                "\t\t    strncmp(name, SMB2_CREATE_REQUEST_LEASE, 4)) {",
                "\t\t\tnext = le32_to_cpu(cc->Next);",
                "\t\t\tcontinue;",
                "\t\t}",
                "\t\tfound = true;",
                "\t\tbreak;",
                "\t} while (next != 0);",
                "\tif (found) {",
                "\t\tif (sizeof(struct lease_context_v2) == le32_to_cpu(cc->DataLength)) {",
                "\t\t\tstruct create_lease_v2 *lc = (struct create_lease_v2 *)cc;",
                "\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);",
                "\t\t\tlreq->req_state = lc->lcontext.LeaseState;",
                "\t\t\tlreq->flags = lc->lcontext.LeaseFlags;",
                "\t\t\tlreq->duration = lc->lcontext.LeaseDuration;",
                "\t\t\tmemcpy(lreq->parent_lease_key, lc->lcontext.ParentLeaseKey,",
                "\t\t\t       SMB2_LEASE_KEY_SIZE);",
                "\t\t\tlreq->version = 2;",
                "\t\t} else {",
                "\t\t\tstruct create_lease *lc = (struct create_lease *)cc;",
                "",
                "\t\t\tmemcpy(lreq->lease_key, lc->lcontext.LeaseKey, SMB2_LEASE_KEY_SIZE);",
                "\t\t\tlreq->req_state = lc->lcontext.LeaseState;",
                "\t\t\tlreq->flags = lc->lcontext.LeaseFlags;",
                "\t\t\tlreq->duration = lc->lcontext.LeaseDuration;",
                "\t\t\tlreq->version = 1;",
                "\t\t}",
                "\t\treturn lreq;",
                "",
                "\tkfree(lreq);",
                "\treturn NULL;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds (OOB) memory read flaw was found in parse_lease_state in the KSMBD implementation of the in-kernel samba server and CIFS in the Linux kernel. When an attacker sends the CREATE command with a malformed payload to KSMBD, due to a missing check of `NameOffset` in the `parse_lease_state()` function, the `create_context` object can access invalid memory.",
        "id": 3855
    },
    {
        "cve_id": "CVE-2023-6040",
        "code_before_change": "static int nf_tables_newtable(struct sk_buff *skb, const struct nfnl_info *info,\n\t\t\t      const struct nlattr * const nla[])\n{\n\tstruct nftables_pernet *nft_net = nft_pernet(info->net);\n\tstruct netlink_ext_ack *extack = info->extack;\n\tu8 genmask = nft_genmask_next(info->net);\n\tu8 family = info->nfmsg->nfgen_family;\n\tstruct net *net = info->net;\n\tconst struct nlattr *attr;\n\tstruct nft_table *table;\n\tstruct nft_ctx ctx;\n\tu32 flags = 0;\n\tint err;\n\n\tlockdep_assert_held(&nft_net->commit_mutex);\n\tattr = nla[NFTA_TABLE_NAME];\n\ttable = nft_table_lookup(net, attr, family, genmask,\n\t\t\t\t NETLINK_CB(skb).portid);\n\tif (IS_ERR(table)) {\n\t\tif (PTR_ERR(table) != -ENOENT)\n\t\t\treturn PTR_ERR(table);\n\t} else {\n\t\tif (info->nlh->nlmsg_flags & NLM_F_EXCL) {\n\t\t\tNL_SET_BAD_ATTR(extack, attr);\n\t\t\treturn -EEXIST;\n\t\t}\n\t\tif (info->nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tnft_ctx_init(&ctx, net, skb, info->nlh, family, table, NULL, nla);\n\n\t\treturn nf_tables_updtable(&ctx);\n\t}\n\n\tif (nla[NFTA_TABLE_FLAGS]) {\n\t\tflags = ntohl(nla_get_be32(nla[NFTA_TABLE_FLAGS]));\n\t\tif (flags & ~NFT_TABLE_F_MASK)\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\terr = -ENOMEM;\n\ttable = kzalloc(sizeof(*table), GFP_KERNEL);\n\tif (table == NULL)\n\t\tgoto err_kzalloc;\n\n\ttable->name = nla_strdup(attr, GFP_KERNEL);\n\tif (table->name == NULL)\n\t\tgoto err_strdup;\n\n\tif (nla[NFTA_TABLE_USERDATA]) {\n\t\ttable->udata = nla_memdup(nla[NFTA_TABLE_USERDATA], GFP_KERNEL);\n\t\tif (table->udata == NULL)\n\t\t\tgoto err_table_udata;\n\n\t\ttable->udlen = nla_len(nla[NFTA_TABLE_USERDATA]);\n\t}\n\n\terr = rhltable_init(&table->chains_ht, &nft_chain_ht_params);\n\tif (err)\n\t\tgoto err_chain_ht;\n\n\tINIT_LIST_HEAD(&table->chains);\n\tINIT_LIST_HEAD(&table->sets);\n\tINIT_LIST_HEAD(&table->objects);\n\tINIT_LIST_HEAD(&table->flowtables);\n\ttable->family = family;\n\ttable->flags = flags;\n\ttable->handle = ++table_handle;\n\tif (table->flags & NFT_TABLE_F_OWNER)\n\t\ttable->nlpid = NETLINK_CB(skb).portid;\n\n\tnft_ctx_init(&ctx, net, skb, info->nlh, family, table, NULL, nla);\n\terr = nft_trans_table_add(&ctx, NFT_MSG_NEWTABLE);\n\tif (err < 0)\n\t\tgoto err_trans;\n\n\tlist_add_tail_rcu(&table->list, &nft_net->tables);\n\treturn 0;\nerr_trans:\n\trhltable_destroy(&table->chains_ht);\nerr_chain_ht:\n\tkfree(table->udata);\nerr_table_udata:\n\tkfree(table->name);\nerr_strdup:\n\tkfree(table);\nerr_kzalloc:\n\treturn err;\n}",
        "code_after_change": "static int nf_tables_newtable(struct sk_buff *skb, const struct nfnl_info *info,\n\t\t\t      const struct nlattr * const nla[])\n{\n\tstruct nftables_pernet *nft_net = nft_pernet(info->net);\n\tstruct netlink_ext_ack *extack = info->extack;\n\tu8 genmask = nft_genmask_next(info->net);\n\tu8 family = info->nfmsg->nfgen_family;\n\tstruct net *net = info->net;\n\tconst struct nlattr *attr;\n\tstruct nft_table *table;\n\tstruct nft_ctx ctx;\n\tu32 flags = 0;\n\tint err;\n\n\tif (!nft_supported_family(family))\n\t\treturn -EOPNOTSUPP;\n\n\tlockdep_assert_held(&nft_net->commit_mutex);\n\tattr = nla[NFTA_TABLE_NAME];\n\ttable = nft_table_lookup(net, attr, family, genmask,\n\t\t\t\t NETLINK_CB(skb).portid);\n\tif (IS_ERR(table)) {\n\t\tif (PTR_ERR(table) != -ENOENT)\n\t\t\treturn PTR_ERR(table);\n\t} else {\n\t\tif (info->nlh->nlmsg_flags & NLM_F_EXCL) {\n\t\t\tNL_SET_BAD_ATTR(extack, attr);\n\t\t\treturn -EEXIST;\n\t\t}\n\t\tif (info->nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tnft_ctx_init(&ctx, net, skb, info->nlh, family, table, NULL, nla);\n\n\t\treturn nf_tables_updtable(&ctx);\n\t}\n\n\tif (nla[NFTA_TABLE_FLAGS]) {\n\t\tflags = ntohl(nla_get_be32(nla[NFTA_TABLE_FLAGS]));\n\t\tif (flags & ~NFT_TABLE_F_MASK)\n\t\t\treturn -EOPNOTSUPP;\n\t}\n\n\terr = -ENOMEM;\n\ttable = kzalloc(sizeof(*table), GFP_KERNEL);\n\tif (table == NULL)\n\t\tgoto err_kzalloc;\n\n\ttable->name = nla_strdup(attr, GFP_KERNEL);\n\tif (table->name == NULL)\n\t\tgoto err_strdup;\n\n\tif (nla[NFTA_TABLE_USERDATA]) {\n\t\ttable->udata = nla_memdup(nla[NFTA_TABLE_USERDATA], GFP_KERNEL);\n\t\tif (table->udata == NULL)\n\t\t\tgoto err_table_udata;\n\n\t\ttable->udlen = nla_len(nla[NFTA_TABLE_USERDATA]);\n\t}\n\n\terr = rhltable_init(&table->chains_ht, &nft_chain_ht_params);\n\tif (err)\n\t\tgoto err_chain_ht;\n\n\tINIT_LIST_HEAD(&table->chains);\n\tINIT_LIST_HEAD(&table->sets);\n\tINIT_LIST_HEAD(&table->objects);\n\tINIT_LIST_HEAD(&table->flowtables);\n\ttable->family = family;\n\ttable->flags = flags;\n\ttable->handle = ++table_handle;\n\tif (table->flags & NFT_TABLE_F_OWNER)\n\t\ttable->nlpid = NETLINK_CB(skb).portid;\n\n\tnft_ctx_init(&ctx, net, skb, info->nlh, family, table, NULL, nla);\n\terr = nft_trans_table_add(&ctx, NFT_MSG_NEWTABLE);\n\tif (err < 0)\n\t\tgoto err_trans;\n\n\tlist_add_tail_rcu(&table->list, &nft_net->tables);\n\treturn 0;\nerr_trans:\n\trhltable_destroy(&table->chains_ht);\nerr_chain_ht:\n\tkfree(table->udata);\nerr_table_udata:\n\tkfree(table->name);\nerr_strdup:\n\tkfree(table);\nerr_kzalloc:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,9 @@\n \tstruct nft_ctx ctx;\n \tu32 flags = 0;\n \tint err;\n+\n+\tif (!nft_supported_family(family))\n+\t\treturn -EOPNOTSUPP;\n \n \tlockdep_assert_held(&nft_net->commit_mutex);\n \tattr = nla[NFTA_TABLE_NAME];",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!nft_supported_family(family))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds access vulnerability involving netfilter was reported and fixed as: f1082dd31fe4 (netfilter: nf_tables: Reject tables of unsupported family); While creating a new netfilter table, lack of a safeguard against invalid nf_tables family (pf) values within `nf_tables_newtable` function enables an attacker to achieve out-of-bounds access.",
        "id": 4295
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_or(struct bpf_reg_state *dst_reg,\n\t\t\t\tstruct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umin_val = src_reg->u32_min_value;\n\n\t/* Assuming scalar64_min_max_or will be called so it is safe\n\t * to skip updating register for known case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get our maximum from the var_off, and our minimum is the\n\t * maximum of the operands' minima\n\t */\n\tdst_reg->u32_min_value = max(dst_reg->u32_min_value, umin_val);\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ORing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "code_after_change": "static void scalar32_min_max_or(struct bpf_reg_state *dst_reg,\n\t\t\t\tstruct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umin_val = src_reg->u32_min_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get our maximum from the var_off, and our minimum is the\n\t * maximum of the operands' minima\n\t */\n\tdst_reg->u32_min_value = max(dst_reg->u32_min_value, umin_val);\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ORing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,11 +7,10 @@\n \ts32 smin_val = src_reg->s32_min_value;\n \tu32 umin_val = src_reg->u32_min_value;\n \n-\t/* Assuming scalar64_min_max_or will be called so it is safe\n-\t * to skip updating register for known case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get our maximum from the var_off, and our minimum is the\n \t * maximum of the operands' minima",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_or will be called so it is safe",
                "\t * to skip updating register for known case.",
                "\t */",
                "\tif (src_known && dst_known)"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1).",
        "id": 3012
    },
    {
        "cve_id": "CVE-2017-5897",
        "code_before_change": "static void ip6gre_err(struct sk_buff *skb, struct inet6_skb_parm *opt,\n\t\tu8 type, u8 code, int offset, __be32 info)\n{\n\tconst struct ipv6hdr *ipv6h = (const struct ipv6hdr *)skb->data;\n\t__be16 *p = (__be16 *)(skb->data + offset);\n\tint grehlen = offset + 4;\n\tstruct ip6_tnl *t;\n\t__be16 flags;\n\n\tflags = p[0];\n\tif (flags&(GRE_CSUM|GRE_KEY|GRE_SEQ|GRE_ROUTING|GRE_VERSION)) {\n\t\tif (flags&(GRE_VERSION|GRE_ROUTING))\n\t\t\treturn;\n\t\tif (flags&GRE_KEY) {\n\t\t\tgrehlen += 4;\n\t\t\tif (flags&GRE_CSUM)\n\t\t\t\tgrehlen += 4;\n\t\t}\n\t}\n\n\t/* If only 8 bytes returned, keyed message will be dropped here */\n\tif (!pskb_may_pull(skb, grehlen))\n\t\treturn;\n\tipv6h = (const struct ipv6hdr *)skb->data;\n\tp = (__be16 *)(skb->data + offset);\n\n\tt = ip6gre_tunnel_lookup(skb->dev, &ipv6h->daddr, &ipv6h->saddr,\n\t\t\t\tflags & GRE_KEY ?\n\t\t\t\t*(((__be32 *)p) + (grehlen / 4) - 1) : 0,\n\t\t\t\tp[1]);\n\tif (!t)\n\t\treturn;\n\n\tswitch (type) {\n\t\t__u32 teli;\n\t\tstruct ipv6_tlv_tnl_enc_lim *tel;\n\t\t__u32 mtu;\n\tcase ICMPV6_DEST_UNREACH:\n\t\tnet_dbg_ratelimited(\"%s: Path to destination invalid or inactive!\\n\",\n\t\t\t\t    t->parms.name);\n\t\tbreak;\n\tcase ICMPV6_TIME_EXCEED:\n\t\tif (code == ICMPV6_EXC_HOPLIMIT) {\n\t\t\tnet_dbg_ratelimited(\"%s: Too small hop limit or routing loop in tunnel!\\n\",\n\t\t\t\t\t    t->parms.name);\n\t\t}\n\t\tbreak;\n\tcase ICMPV6_PARAMPROB:\n\t\tteli = 0;\n\t\tif (code == ICMPV6_HDR_FIELD)\n\t\t\tteli = ip6_tnl_parse_tlv_enc_lim(skb, skb->data);\n\n\t\tif (teli && teli == be32_to_cpu(info) - 2) {\n\t\t\ttel = (struct ipv6_tlv_tnl_enc_lim *) &skb->data[teli];\n\t\t\tif (tel->encap_limit == 0) {\n\t\t\t\tnet_dbg_ratelimited(\"%s: Too small encapsulation limit or routing loop in tunnel!\\n\",\n\t\t\t\t\t\t    t->parms.name);\n\t\t\t}\n\t\t} else {\n\t\t\tnet_dbg_ratelimited(\"%s: Recipient unable to parse tunneled packet!\\n\",\n\t\t\t\t\t    t->parms.name);\n\t\t}\n\t\tbreak;\n\tcase ICMPV6_PKT_TOOBIG:\n\t\tmtu = be32_to_cpu(info) - offset;\n\t\tif (mtu < IPV6_MIN_MTU)\n\t\t\tmtu = IPV6_MIN_MTU;\n\t\tt->dev->mtu = mtu;\n\t\tbreak;\n\t}\n\n\tif (time_before(jiffies, t->err_time + IP6TUNNEL_ERR_TIMEO))\n\t\tt->err_count++;\n\telse\n\t\tt->err_count = 1;\n\tt->err_time = jiffies;\n}",
        "code_after_change": "static void ip6gre_err(struct sk_buff *skb, struct inet6_skb_parm *opt,\n\t\t       u8 type, u8 code, int offset, __be32 info)\n{\n\tconst struct gre_base_hdr *greh;\n\tconst struct ipv6hdr *ipv6h;\n\tint grehlen = sizeof(*greh);\n\tstruct ip6_tnl *t;\n\tint key_off = 0;\n\t__be16 flags;\n\t__be32 key;\n\n\tif (!pskb_may_pull(skb, offset + grehlen))\n\t\treturn;\n\tgreh = (const struct gre_base_hdr *)(skb->data + offset);\n\tflags = greh->flags;\n\tif (flags & (GRE_VERSION | GRE_ROUTING))\n\t\treturn;\n\tif (flags & GRE_CSUM)\n\t\tgrehlen += 4;\n\tif (flags & GRE_KEY) {\n\t\tkey_off = grehlen + offset;\n\t\tgrehlen += 4;\n\t}\n\n\tif (!pskb_may_pull(skb, offset + grehlen))\n\t\treturn;\n\tipv6h = (const struct ipv6hdr *)skb->data;\n\tgreh = (const struct gre_base_hdr *)(skb->data + offset);\n\tkey = key_off ? *(__be32 *)(skb->data + key_off) : 0;\n\n\tt = ip6gre_tunnel_lookup(skb->dev, &ipv6h->daddr, &ipv6h->saddr,\n\t\t\t\t key, greh->protocol);\n\tif (!t)\n\t\treturn;\n\n\tswitch (type) {\n\t\t__u32 teli;\n\t\tstruct ipv6_tlv_tnl_enc_lim *tel;\n\t\t__u32 mtu;\n\tcase ICMPV6_DEST_UNREACH:\n\t\tnet_dbg_ratelimited(\"%s: Path to destination invalid or inactive!\\n\",\n\t\t\t\t    t->parms.name);\n\t\tbreak;\n\tcase ICMPV6_TIME_EXCEED:\n\t\tif (code == ICMPV6_EXC_HOPLIMIT) {\n\t\t\tnet_dbg_ratelimited(\"%s: Too small hop limit or routing loop in tunnel!\\n\",\n\t\t\t\t\t    t->parms.name);\n\t\t}\n\t\tbreak;\n\tcase ICMPV6_PARAMPROB:\n\t\tteli = 0;\n\t\tif (code == ICMPV6_HDR_FIELD)\n\t\t\tteli = ip6_tnl_parse_tlv_enc_lim(skb, skb->data);\n\n\t\tif (teli && teli == be32_to_cpu(info) - 2) {\n\t\t\ttel = (struct ipv6_tlv_tnl_enc_lim *) &skb->data[teli];\n\t\t\tif (tel->encap_limit == 0) {\n\t\t\t\tnet_dbg_ratelimited(\"%s: Too small encapsulation limit or routing loop in tunnel!\\n\",\n\t\t\t\t\t\t    t->parms.name);\n\t\t\t}\n\t\t} else {\n\t\t\tnet_dbg_ratelimited(\"%s: Recipient unable to parse tunneled packet!\\n\",\n\t\t\t\t\t    t->parms.name);\n\t\t}\n\t\tbreak;\n\tcase ICMPV6_PKT_TOOBIG:\n\t\tmtu = be32_to_cpu(info) - offset;\n\t\tif (mtu < IPV6_MIN_MTU)\n\t\t\tmtu = IPV6_MIN_MTU;\n\t\tt->dev->mtu = mtu;\n\t\tbreak;\n\t}\n\n\tif (time_before(jiffies, t->err_time + IP6TUNNEL_ERR_TIMEO))\n\t\tt->err_count++;\n\telse\n\t\tt->err_count = 1;\n\tt->err_time = jiffies;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,33 +1,35 @@\n static void ip6gre_err(struct sk_buff *skb, struct inet6_skb_parm *opt,\n-\t\tu8 type, u8 code, int offset, __be32 info)\n+\t\t       u8 type, u8 code, int offset, __be32 info)\n {\n-\tconst struct ipv6hdr *ipv6h = (const struct ipv6hdr *)skb->data;\n-\t__be16 *p = (__be16 *)(skb->data + offset);\n-\tint grehlen = offset + 4;\n+\tconst struct gre_base_hdr *greh;\n+\tconst struct ipv6hdr *ipv6h;\n+\tint grehlen = sizeof(*greh);\n \tstruct ip6_tnl *t;\n+\tint key_off = 0;\n \t__be16 flags;\n+\t__be32 key;\n \n-\tflags = p[0];\n-\tif (flags&(GRE_CSUM|GRE_KEY|GRE_SEQ|GRE_ROUTING|GRE_VERSION)) {\n-\t\tif (flags&(GRE_VERSION|GRE_ROUTING))\n-\t\t\treturn;\n-\t\tif (flags&GRE_KEY) {\n-\t\t\tgrehlen += 4;\n-\t\t\tif (flags&GRE_CSUM)\n-\t\t\t\tgrehlen += 4;\n-\t\t}\n+\tif (!pskb_may_pull(skb, offset + grehlen))\n+\t\treturn;\n+\tgreh = (const struct gre_base_hdr *)(skb->data + offset);\n+\tflags = greh->flags;\n+\tif (flags & (GRE_VERSION | GRE_ROUTING))\n+\t\treturn;\n+\tif (flags & GRE_CSUM)\n+\t\tgrehlen += 4;\n+\tif (flags & GRE_KEY) {\n+\t\tkey_off = grehlen + offset;\n+\t\tgrehlen += 4;\n \t}\n \n-\t/* If only 8 bytes returned, keyed message will be dropped here */\n-\tif (!pskb_may_pull(skb, grehlen))\n+\tif (!pskb_may_pull(skb, offset + grehlen))\n \t\treturn;\n \tipv6h = (const struct ipv6hdr *)skb->data;\n-\tp = (__be16 *)(skb->data + offset);\n+\tgreh = (const struct gre_base_hdr *)(skb->data + offset);\n+\tkey = key_off ? *(__be32 *)(skb->data + key_off) : 0;\n \n \tt = ip6gre_tunnel_lookup(skb->dev, &ipv6h->daddr, &ipv6h->saddr,\n-\t\t\t\tflags & GRE_KEY ?\n-\t\t\t\t*(((__be32 *)p) + (grehlen / 4) - 1) : 0,\n-\t\t\t\tp[1]);\n+\t\t\t\t key, greh->protocol);\n \tif (!t)\n \t\treturn;\n ",
        "function_modified_lines": {
            "added": [
                "\t\t       u8 type, u8 code, int offset, __be32 info)",
                "\tconst struct gre_base_hdr *greh;",
                "\tconst struct ipv6hdr *ipv6h;",
                "\tint grehlen = sizeof(*greh);",
                "\tint key_off = 0;",
                "\t__be32 key;",
                "\tif (!pskb_may_pull(skb, offset + grehlen))",
                "\t\treturn;",
                "\tgreh = (const struct gre_base_hdr *)(skb->data + offset);",
                "\tflags = greh->flags;",
                "\tif (flags & (GRE_VERSION | GRE_ROUTING))",
                "\t\treturn;",
                "\tif (flags & GRE_CSUM)",
                "\t\tgrehlen += 4;",
                "\tif (flags & GRE_KEY) {",
                "\t\tkey_off = grehlen + offset;",
                "\t\tgrehlen += 4;",
                "\tif (!pskb_may_pull(skb, offset + grehlen))",
                "\tgreh = (const struct gre_base_hdr *)(skb->data + offset);",
                "\tkey = key_off ? *(__be32 *)(skb->data + key_off) : 0;",
                "\t\t\t\t key, greh->protocol);"
            ],
            "deleted": [
                "\t\tu8 type, u8 code, int offset, __be32 info)",
                "\tconst struct ipv6hdr *ipv6h = (const struct ipv6hdr *)skb->data;",
                "\t__be16 *p = (__be16 *)(skb->data + offset);",
                "\tint grehlen = offset + 4;",
                "\tflags = p[0];",
                "\tif (flags&(GRE_CSUM|GRE_KEY|GRE_SEQ|GRE_ROUTING|GRE_VERSION)) {",
                "\t\tif (flags&(GRE_VERSION|GRE_ROUTING))",
                "\t\t\treturn;",
                "\t\tif (flags&GRE_KEY) {",
                "\t\t\tgrehlen += 4;",
                "\t\t\tif (flags&GRE_CSUM)",
                "\t\t\t\tgrehlen += 4;",
                "\t\t}",
                "\t/* If only 8 bytes returned, keyed message will be dropped here */",
                "\tif (!pskb_may_pull(skb, grehlen))",
                "\tp = (__be16 *)(skb->data + offset);",
                "\t\t\t\tflags & GRE_KEY ?",
                "\t\t\t\t*(((__be32 *)p) + (grehlen / 4) - 1) : 0,",
                "\t\t\t\tp[1]);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ip6gre_err function in net/ipv6/ip6_gre.c in the Linux kernel allows remote attackers to have unspecified impact via vectors involving GRE flags in an IPv6 packet, which trigger an out-of-bounds access.",
        "id": 1473
    },
    {
        "cve_id": "CVE-2022-20132",
        "code_before_change": "static void wacom_update_name(struct wacom *wacom, const char *suffix)\n{\n\tstruct wacom_wac *wacom_wac = &wacom->wacom_wac;\n\tstruct wacom_features *features = &wacom_wac->features;\n\tchar name[WACOM_NAME_MAX - 20]; /* Leave some room for suffixes */\n\n\t/* Generic devices name unspecified */\n\tif ((features->type == HID_GENERIC) && !strcmp(\"Wacom HID\", features->name)) {\n\t\tchar *product_name = wacom->hdev->name;\n\n\t\tif (hid_is_using_ll_driver(wacom->hdev, &usb_hid_driver)) {\n\t\t\tstruct usb_interface *intf = to_usb_interface(wacom->hdev->dev.parent);\n\t\t\tstruct usb_device *dev = interface_to_usbdev(intf);\n\t\t\tproduct_name = dev->product;\n\t\t}\n\n\t\tif (wacom->hdev->bus == BUS_I2C) {\n\t\t\tsnprintf(name, sizeof(name), \"%s %X\",\n\t\t\t\t features->name, wacom->hdev->product);\n\t\t} else if (strstr(product_name, \"Wacom\") ||\n\t\t\t   strstr(product_name, \"wacom\") ||\n\t\t\t   strstr(product_name, \"WACOM\")) {\n\t\t\tstrlcpy(name, product_name, sizeof(name));\n\t\t} else {\n\t\t\tsnprintf(name, sizeof(name), \"Wacom %s\", product_name);\n\t\t}\n\n\t\t/* strip out excess whitespaces */\n\t\twhile (1) {\n\t\t\tchar *gap = strstr(name, \"  \");\n\t\t\tif (gap == NULL)\n\t\t\t\tbreak;\n\t\t\t/* shift everything including the terminator */\n\t\t\tmemmove(gap, gap+1, strlen(gap));\n\t\t}\n\n\t\t/* get rid of trailing whitespace */\n\t\tif (name[strlen(name)-1] == ' ')\n\t\t\tname[strlen(name)-1] = '\\0';\n\t} else {\n\t\tstrlcpy(name, features->name, sizeof(name));\n\t}\n\n\tsnprintf(wacom_wac->name, sizeof(wacom_wac->name), \"%s%s\",\n\t\t name, suffix);\n\n\t/* Append the device type to the name */\n\tsnprintf(wacom_wac->pen_name, sizeof(wacom_wac->pen_name),\n\t\t\"%s%s Pen\", name, suffix);\n\tsnprintf(wacom_wac->touch_name, sizeof(wacom_wac->touch_name),\n\t\t\"%s%s Finger\", name, suffix);\n\tsnprintf(wacom_wac->pad_name, sizeof(wacom_wac->pad_name),\n\t\t\"%s%s Pad\", name, suffix);\n}",
        "code_after_change": "static void wacom_update_name(struct wacom *wacom, const char *suffix)\n{\n\tstruct wacom_wac *wacom_wac = &wacom->wacom_wac;\n\tstruct wacom_features *features = &wacom_wac->features;\n\tchar name[WACOM_NAME_MAX - 20]; /* Leave some room for suffixes */\n\n\t/* Generic devices name unspecified */\n\tif ((features->type == HID_GENERIC) && !strcmp(\"Wacom HID\", features->name)) {\n\t\tchar *product_name = wacom->hdev->name;\n\n\t\tif (hid_is_usb(wacom->hdev)) {\n\t\t\tstruct usb_interface *intf = to_usb_interface(wacom->hdev->dev.parent);\n\t\t\tstruct usb_device *dev = interface_to_usbdev(intf);\n\t\t\tproduct_name = dev->product;\n\t\t}\n\n\t\tif (wacom->hdev->bus == BUS_I2C) {\n\t\t\tsnprintf(name, sizeof(name), \"%s %X\",\n\t\t\t\t features->name, wacom->hdev->product);\n\t\t} else if (strstr(product_name, \"Wacom\") ||\n\t\t\t   strstr(product_name, \"wacom\") ||\n\t\t\t   strstr(product_name, \"WACOM\")) {\n\t\t\tstrlcpy(name, product_name, sizeof(name));\n\t\t} else {\n\t\t\tsnprintf(name, sizeof(name), \"Wacom %s\", product_name);\n\t\t}\n\n\t\t/* strip out excess whitespaces */\n\t\twhile (1) {\n\t\t\tchar *gap = strstr(name, \"  \");\n\t\t\tif (gap == NULL)\n\t\t\t\tbreak;\n\t\t\t/* shift everything including the terminator */\n\t\t\tmemmove(gap, gap+1, strlen(gap));\n\t\t}\n\n\t\t/* get rid of trailing whitespace */\n\t\tif (name[strlen(name)-1] == ' ')\n\t\t\tname[strlen(name)-1] = '\\0';\n\t} else {\n\t\tstrlcpy(name, features->name, sizeof(name));\n\t}\n\n\tsnprintf(wacom_wac->name, sizeof(wacom_wac->name), \"%s%s\",\n\t\t name, suffix);\n\n\t/* Append the device type to the name */\n\tsnprintf(wacom_wac->pen_name, sizeof(wacom_wac->pen_name),\n\t\t\"%s%s Pen\", name, suffix);\n\tsnprintf(wacom_wac->touch_name, sizeof(wacom_wac->touch_name),\n\t\t\"%s%s Finger\", name, suffix);\n\tsnprintf(wacom_wac->pad_name, sizeof(wacom_wac->pad_name),\n\t\t\"%s%s Pad\", name, suffix);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tif ((features->type == HID_GENERIC) && !strcmp(\"Wacom HID\", features->name)) {\n \t\tchar *product_name = wacom->hdev->name;\n \n-\t\tif (hid_is_using_ll_driver(wacom->hdev, &usb_hid_driver)) {\n+\t\tif (hid_is_usb(wacom->hdev)) {\n \t\t\tstruct usb_interface *intf = to_usb_interface(wacom->hdev->dev.parent);\n \t\t\tstruct usb_device *dev = interface_to_usbdev(intf);\n \t\t\tproduct_name = dev->product;",
        "function_modified_lines": {
            "added": [
                "\t\tif (hid_is_usb(wacom->hdev)) {"
            ],
            "deleted": [
                "\t\tif (hid_is_using_ll_driver(wacom->hdev, &usb_hid_driver)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In lg_probe and related functions of hid-lg.c and other USB HID files, there is a possible out of bounds read due to improper input validation. This could lead to local information disclosure if a malicious USB HID device were plugged in, with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-188677105References: Upstream kernel",
        "id": 3336
    },
    {
        "cve_id": "CVE-2017-6347",
        "code_before_change": "static void ip_cmsg_recv_checksum(struct msghdr *msg, struct sk_buff *skb,\n\t\t\t\t  int tlen, int offset)\n{\n\t__wsum csum = skb->csum;\n\n\tif (skb->ip_summed != CHECKSUM_COMPLETE)\n\t\treturn;\n\n\tif (offset != 0)\n\t\tcsum = csum_sub(csum,\n\t\t\t\tcsum_partial(skb_transport_header(skb) + tlen,\n\t\t\t\t\t     offset, 0));\n\n\tput_cmsg(msg, SOL_IP, IP_CHECKSUM, sizeof(__wsum), &csum);\n}",
        "code_after_change": "static void ip_cmsg_recv_checksum(struct msghdr *msg, struct sk_buff *skb,\n\t\t\t\t  int tlen, int offset)\n{\n\t__wsum csum = skb->csum;\n\n\tif (skb->ip_summed != CHECKSUM_COMPLETE)\n\t\treturn;\n\n\tif (offset != 0) {\n\t\tint tend_off = skb_transport_offset(skb) + tlen;\n\t\tcsum = csum_sub(csum, skb_checksum(skb, tend_off, offset, 0));\n\t}\n\n\tput_cmsg(msg, SOL_IP, IP_CHECKSUM, sizeof(__wsum), &csum);\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,10 +6,10 @@\n \tif (skb->ip_summed != CHECKSUM_COMPLETE)\n \t\treturn;\n \n-\tif (offset != 0)\n-\t\tcsum = csum_sub(csum,\n-\t\t\t\tcsum_partial(skb_transport_header(skb) + tlen,\n-\t\t\t\t\t     offset, 0));\n+\tif (offset != 0) {\n+\t\tint tend_off = skb_transport_offset(skb) + tlen;\n+\t\tcsum = csum_sub(csum, skb_checksum(skb, tend_off, offset, 0));\n+\t}\n \n \tput_cmsg(msg, SOL_IP, IP_CHECKSUM, sizeof(__wsum), &csum);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (offset != 0) {",
                "\t\tint tend_off = skb_transport_offset(skb) + tlen;",
                "\t\tcsum = csum_sub(csum, skb_checksum(skb, tend_off, offset, 0));",
                "\t}"
            ],
            "deleted": [
                "\tif (offset != 0)",
                "\t\tcsum = csum_sub(csum,",
                "\t\t\t\tcsum_partial(skb_transport_header(skb) + tlen,",
                "\t\t\t\t\t     offset, 0));"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ip_cmsg_recv_checksum function in net/ipv4/ip_sockglue.c in the Linux kernel before 4.10.1 has incorrect expectations about skb data layout, which allows local users to cause a denial of service (buffer over-read) or possibly have unspecified other impact via crafted system calls, as demonstrated by use of the MSG_MORE flag in conjunction with loopback UDP transmission.",
        "id": 1484
    },
    {
        "cve_id": "CVE-2014-3145",
        "code_before_change": "static u64 __skb_get_nlattr(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = nla_find((struct nlattr *) &skb->data[A], skb->len - A, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "code_after_change": "static u64 __skb_get_nlattr(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (skb->len < sizeof(struct nlattr))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = nla_find((struct nlattr *) &skb->data[A], skb->len - A, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tstruct nlattr *nla;\n \n \tif (skb_is_nonlinear(skb))\n+\t\treturn 0;\n+\n+\tif (skb->len < sizeof(struct nlattr))\n \t\treturn 0;\n \n \tif (A > skb->len - sizeof(struct nlattr))",
        "function_modified_lines": {
            "added": [
                "\t\treturn 0;",
                "",
                "\tif (skb->len < sizeof(struct nlattr))"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The BPF_S_ANC_NLATTR_NEST extension implementation in the sk_run_filter function in net/core/filter.c in the Linux kernel through 3.14.3 uses the reverse order in a certain subtraction, which allows local users to cause a denial of service (over-read and system crash) via crafted BPF instructions.  NOTE: the affected code was moved to the __skb_get_nlattr_nest function before the vulnerability was announced.",
        "id": 506
    },
    {
        "cve_id": "CVE-2019-15090",
        "code_before_change": "void\nqedi_dbg_info(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      u32 level, const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\tchar nfunc[32];\n\n\tmemset(nfunc, 0, sizeof(nfunc));\n\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & level))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_info(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tnfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "code_after_change": "void\nqedi_dbg_info(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      u32 level, const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & level))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_info(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,6 @@\n {\n \tva_list va;\n \tstruct va_format vaf;\n-\tchar nfunc[32];\n-\n-\tmemset(nfunc, 0, sizeof(nfunc));\n-\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n \n \tva_start(va, fmt);\n \n@@ -19,9 +15,9 @@\n \n \tif (likely(qedi) && likely(qedi->pdev))\n \t\tpr_info(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n-\t\t\tnfunc, line, qedi->host_no, &vaf);\n+\t\t\tfunc, line, qedi->host_no, &vaf);\n \telse\n-\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n+\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n \n ret:\n \tva_end(va);",
        "function_modified_lines": {
            "added": [
                "\t\t\tfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);"
            ],
            "deleted": [
                "\tchar nfunc[32];",
                "",
                "\tmemset(nfunc, 0, sizeof(nfunc));",
                "\tmemcpy(nfunc, func, sizeof(nfunc) - 1);",
                "\t\t\tnfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_info(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in drivers/scsi/qedi/qedi_dbg.c in the Linux kernel before 5.1.12. In the qedi_dbg_* family of functions, there is an out-of-bounds read.",
        "id": 1983
    },
    {
        "cve_id": "CVE-2023-2176",
        "code_before_change": "int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)\n{\n\tstruct rdma_id_private *id_priv;\n\tint ret;\n\tstruct sockaddr  *daddr;\n\n\tif (addr->sa_family != AF_INET && addr->sa_family != AF_INET6 &&\n\t    addr->sa_family != AF_IB)\n\t\treturn -EAFNOSUPPORT;\n\n\tid_priv = container_of(id, struct rdma_id_private, id);\n\tif (!cma_comp_exch(id_priv, RDMA_CM_IDLE, RDMA_CM_ADDR_BOUND))\n\t\treturn -EINVAL;\n\n\tret = cma_check_linklocal(&id->route.addr.dev_addr, addr);\n\tif (ret)\n\t\tgoto err1;\n\n\tmemcpy(cma_src_addr(id_priv), addr, rdma_addr_size(addr));\n\tif (!cma_any_addr(addr)) {\n\t\tret = cma_translate_addr(addr, &id->route.addr.dev_addr);\n\t\tif (ret)\n\t\t\tgoto err1;\n\n\t\tret = cma_acquire_dev_by_src_ip(id_priv);\n\t\tif (ret)\n\t\t\tgoto err1;\n\t}\n\n\tif (!(id_priv->options & (1 << CMA_OPTION_AFONLY))) {\n\t\tif (addr->sa_family == AF_INET)\n\t\t\tid_priv->afonly = 1;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\telse if (addr->sa_family == AF_INET6) {\n\t\t\tstruct net *net = id_priv->id.route.addr.dev_addr.net;\n\n\t\t\tid_priv->afonly = net->ipv6.sysctl.bindv6only;\n\t\t}\n#endif\n\t}\n\tdaddr = cma_dst_addr(id_priv);\n\tdaddr->sa_family = addr->sa_family;\n\n\tret = cma_get_port(id_priv);\n\tif (ret)\n\t\tgoto err2;\n\n\tif (!cma_any_addr(addr))\n\t\trdma_restrack_add(&id_priv->res);\n\treturn 0;\nerr2:\n\tif (id_priv->cma_dev)\n\t\tcma_release_dev(id_priv);\nerr1:\n\tcma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_IDLE);\n\treturn ret;\n}",
        "code_after_change": "int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)\n{\n\tstruct rdma_id_private *id_priv =\n\t\tcontainer_of(id, struct rdma_id_private, id);\n\n\treturn rdma_bind_addr_dst(id_priv, addr, cma_dst_addr(id_priv));\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,57 +1,7 @@\n int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)\n {\n-\tstruct rdma_id_private *id_priv;\n-\tint ret;\n-\tstruct sockaddr  *daddr;\n+\tstruct rdma_id_private *id_priv =\n+\t\tcontainer_of(id, struct rdma_id_private, id);\n \n-\tif (addr->sa_family != AF_INET && addr->sa_family != AF_INET6 &&\n-\t    addr->sa_family != AF_IB)\n-\t\treturn -EAFNOSUPPORT;\n-\n-\tid_priv = container_of(id, struct rdma_id_private, id);\n-\tif (!cma_comp_exch(id_priv, RDMA_CM_IDLE, RDMA_CM_ADDR_BOUND))\n-\t\treturn -EINVAL;\n-\n-\tret = cma_check_linklocal(&id->route.addr.dev_addr, addr);\n-\tif (ret)\n-\t\tgoto err1;\n-\n-\tmemcpy(cma_src_addr(id_priv), addr, rdma_addr_size(addr));\n-\tif (!cma_any_addr(addr)) {\n-\t\tret = cma_translate_addr(addr, &id->route.addr.dev_addr);\n-\t\tif (ret)\n-\t\t\tgoto err1;\n-\n-\t\tret = cma_acquire_dev_by_src_ip(id_priv);\n-\t\tif (ret)\n-\t\t\tgoto err1;\n-\t}\n-\n-\tif (!(id_priv->options & (1 << CMA_OPTION_AFONLY))) {\n-\t\tif (addr->sa_family == AF_INET)\n-\t\t\tid_priv->afonly = 1;\n-#if IS_ENABLED(CONFIG_IPV6)\n-\t\telse if (addr->sa_family == AF_INET6) {\n-\t\t\tstruct net *net = id_priv->id.route.addr.dev_addr.net;\n-\n-\t\t\tid_priv->afonly = net->ipv6.sysctl.bindv6only;\n-\t\t}\n-#endif\n-\t}\n-\tdaddr = cma_dst_addr(id_priv);\n-\tdaddr->sa_family = addr->sa_family;\n-\n-\tret = cma_get_port(id_priv);\n-\tif (ret)\n-\t\tgoto err2;\n-\n-\tif (!cma_any_addr(addr))\n-\t\trdma_restrack_add(&id_priv->res);\n-\treturn 0;\n-err2:\n-\tif (id_priv->cma_dev)\n-\t\tcma_release_dev(id_priv);\n-err1:\n-\tcma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_IDLE);\n-\treturn ret;\n+\treturn rdma_bind_addr_dst(id_priv, addr, cma_dst_addr(id_priv));\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct rdma_id_private *id_priv =",
                "\t\tcontainer_of(id, struct rdma_id_private, id);",
                "\treturn rdma_bind_addr_dst(id_priv, addr, cma_dst_addr(id_priv));"
            ],
            "deleted": [
                "\tstruct rdma_id_private *id_priv;",
                "\tint ret;",
                "\tstruct sockaddr  *daddr;",
                "\tif (addr->sa_family != AF_INET && addr->sa_family != AF_INET6 &&",
                "\t    addr->sa_family != AF_IB)",
                "\t\treturn -EAFNOSUPPORT;",
                "",
                "\tid_priv = container_of(id, struct rdma_id_private, id);",
                "\tif (!cma_comp_exch(id_priv, RDMA_CM_IDLE, RDMA_CM_ADDR_BOUND))",
                "\t\treturn -EINVAL;",
                "",
                "\tret = cma_check_linklocal(&id->route.addr.dev_addr, addr);",
                "\tif (ret)",
                "\t\tgoto err1;",
                "",
                "\tmemcpy(cma_src_addr(id_priv), addr, rdma_addr_size(addr));",
                "\tif (!cma_any_addr(addr)) {",
                "\t\tret = cma_translate_addr(addr, &id->route.addr.dev_addr);",
                "\t\tif (ret)",
                "\t\t\tgoto err1;",
                "",
                "\t\tret = cma_acquire_dev_by_src_ip(id_priv);",
                "\t\tif (ret)",
                "\t\t\tgoto err1;",
                "\t}",
                "",
                "\tif (!(id_priv->options & (1 << CMA_OPTION_AFONLY))) {",
                "\t\tif (addr->sa_family == AF_INET)",
                "\t\t\tid_priv->afonly = 1;",
                "#if IS_ENABLED(CONFIG_IPV6)",
                "\t\telse if (addr->sa_family == AF_INET6) {",
                "\t\t\tstruct net *net = id_priv->id.route.addr.dev_addr.net;",
                "",
                "\t\t\tid_priv->afonly = net->ipv6.sysctl.bindv6only;",
                "\t\t}",
                "#endif",
                "\t}",
                "\tdaddr = cma_dst_addr(id_priv);",
                "\tdaddr->sa_family = addr->sa_family;",
                "",
                "\tret = cma_get_port(id_priv);",
                "\tif (ret)",
                "\t\tgoto err2;",
                "",
                "\tif (!cma_any_addr(addr))",
                "\t\trdma_restrack_add(&id_priv->res);",
                "\treturn 0;",
                "err2:",
                "\tif (id_priv->cma_dev)",
                "\t\tcma_release_dev(id_priv);",
                "err1:",
                "\tcma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_IDLE);",
                "\treturn ret;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A vulnerability was found in compare_netdev_and_ip in drivers/infiniband/core/cma.c in RDMA in the Linux Kernel. The improper cleanup results in out-of-boundary read, where a local user can utilize this problem to crash the system or escalation of privilege.",
        "id": 3931
    },
    {
        "cve_id": "CVE-2020-28097",
        "code_before_change": "static const char *vgacon_startup(void)\n{\n\tconst char *display_desc = NULL;\n\tu16 saved1, saved2;\n\tvolatile u16 *p;\n\n\tif (screen_info.orig_video_isVGA == VIDEO_TYPE_VLFB ||\n\t    screen_info.orig_video_isVGA == VIDEO_TYPE_EFI) {\n\t      no_vga:\n#ifdef CONFIG_DUMMY_CONSOLE\n\t\tconswitchp = &dummy_con;\n\t\treturn conswitchp->con_startup();\n#else\n\t\treturn NULL;\n#endif\n\t}\n\n\t/* boot_params.screen_info reasonably initialized? */\n\tif ((screen_info.orig_video_lines == 0) ||\n\t    (screen_info.orig_video_cols  == 0))\n\t\tgoto no_vga;\n\n\t/* VGA16 modes are not handled by VGACON */\n\tif ((screen_info.orig_video_mode == 0x0D) ||\t/* 320x200/4 */\n\t    (screen_info.orig_video_mode == 0x0E) ||\t/* 640x200/4 */\n\t    (screen_info.orig_video_mode == 0x10) ||\t/* 640x350/4 */\n\t    (screen_info.orig_video_mode == 0x12) ||\t/* 640x480/4 */\n\t    (screen_info.orig_video_mode == 0x6A))\t/* 800x600/4 (VESA) */\n\t\tgoto no_vga;\n\n\tvga_video_num_lines = screen_info.orig_video_lines;\n\tvga_video_num_columns = screen_info.orig_video_cols;\n\tvgastate.vgabase = NULL;\n\n\tif (screen_info.orig_video_mode == 7) {\n\t\t/* Monochrome display */\n\t\tvga_vram_base = 0xb0000;\n\t\tvga_video_port_reg = VGA_CRT_IM;\n\t\tvga_video_port_val = VGA_CRT_DM;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tstatic struct resource ega_console_resource =\n\t\t\t    { .name\t= \"ega\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_EGAM;\n\t\t\tvga_vram_size = 0x8000;\n\t\t\tdisplay_desc = \"EGA+\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &ega_console_resource);\n\t\t} else {\n\t\t\tstatic struct resource mda1_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BB };\n\t\t\tstatic struct resource mda2_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3BF,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_MDA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*MDA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda1_console_resource);\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda2_console_resource);\n\t\t\tvga_video_font_height = 14;\n\t\t}\n\t} else {\n\t\t/* If not, it is color. */\n\t\tvga_can_do_color = true;\n\t\tvga_vram_base = 0xb8000;\n\t\tvga_video_port_reg = VGA_CRT_IC;\n\t\tvga_video_port_val = VGA_CRT_DC;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tint i;\n\n\t\t\tvga_vram_size = 0x8000;\n\n\t\t\tif (!screen_info.orig_video_isVGA) {\n\t\t\t\tstatic struct resource ega_console_resource =\n\t\t\t\t    { .name\t= \"ega\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_EGAC;\n\t\t\t\tdisplay_desc = \"EGA\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &ega_console_resource);\n\t\t\t} else {\n\t\t\t\tstatic struct resource vga_console_resource =\n\t\t\t\t    { .name\t= \"vga+\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_VGAC;\n\t\t\t\tdisplay_desc = \"VGA+\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &vga_console_resource);\n\n\t\t\t\t/*\n\t\t\t\t * Normalise the palette registers, to point\n\t\t\t\t * the 16 screen colours to the first 16\n\t\t\t\t * DAC entries.\n\t\t\t\t */\n\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\tinb_p(VGA_IS1_RC);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t}\n\t\t\t\toutb_p(0x20, VGA_ATT_W);\n\n\t\t\t\t/*\n\t\t\t\t * Now set the DAC registers back to their\n\t\t\t\t * default values\n\t\t\t\t */\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\toutb_p(color_table[i], VGA_PEL_IW);\n\t\t\t\t\toutb_p(default_red[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_grn[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_blu[i], VGA_PEL_D);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tstatic struct resource cga_console_resource =\n\t\t\t    { .name\t= \"cga\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3D4,\n\t\t\t      .end\t= 0x3D5 };\n\t\t\tvga_video_type = VIDEO_TYPE_CGA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*CGA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &cga_console_resource);\n\t\t\tvga_video_font_height = 8;\n\t\t}\n\t}\n\n\tvga_vram_base = VGA_MAP_MEM(vga_vram_base, vga_vram_size);\n\tvga_vram_end = vga_vram_base + vga_vram_size;\n\n\t/*\n\t *      Find out if there is a graphics card present.\n\t *      Are there smarter methods around?\n\t */\n\tp = (volatile u16 *) vga_vram_base;\n\tsaved1 = scr_readw(p);\n\tsaved2 = scr_readw(p + 1);\n\tscr_writew(0xAA55, p);\n\tscr_writew(0x55AA, p + 1);\n\tif (scr_readw(p) != 0xAA55 || scr_readw(p + 1) != 0x55AA) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(0x55AA, p);\n\tscr_writew(0xAA55, p + 1);\n\tif (scr_readw(p) != 0x55AA || scr_readw(p + 1) != 0xAA55) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(saved1, p);\n\tscr_writew(saved2, p + 1);\n\n\tif (vga_video_type == VIDEO_TYPE_EGAC\n\t    || vga_video_type == VIDEO_TYPE_VGAC\n\t    || vga_video_type == VIDEO_TYPE_EGAM) {\n\t\tvga_hardscroll_enabled = vga_hardscroll_user_enable;\n\t\tvga_default_font_height = screen_info.orig_video_points;\n\t\tvga_video_font_height = screen_info.orig_video_points;\n\t\t/* This may be suboptimal but is a safe bet - go with it */\n\t\tvga_scan_lines =\n\t\t    vga_video_font_height * vga_video_num_lines;\n\t}\n\n\tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n\tvgacon_yres = vga_scan_lines;\n\n\tif (!vga_init_done) {\n\t\tvgacon_scrollback_startup();\n\t\tvga_init_done = true;\n\t}\n\n\treturn display_desc;\n}",
        "code_after_change": "static const char *vgacon_startup(void)\n{\n\tconst char *display_desc = NULL;\n\tu16 saved1, saved2;\n\tvolatile u16 *p;\n\n\tif (screen_info.orig_video_isVGA == VIDEO_TYPE_VLFB ||\n\t    screen_info.orig_video_isVGA == VIDEO_TYPE_EFI) {\n\t      no_vga:\n#ifdef CONFIG_DUMMY_CONSOLE\n\t\tconswitchp = &dummy_con;\n\t\treturn conswitchp->con_startup();\n#else\n\t\treturn NULL;\n#endif\n\t}\n\n\t/* boot_params.screen_info reasonably initialized? */\n\tif ((screen_info.orig_video_lines == 0) ||\n\t    (screen_info.orig_video_cols  == 0))\n\t\tgoto no_vga;\n\n\t/* VGA16 modes are not handled by VGACON */\n\tif ((screen_info.orig_video_mode == 0x0D) ||\t/* 320x200/4 */\n\t    (screen_info.orig_video_mode == 0x0E) ||\t/* 640x200/4 */\n\t    (screen_info.orig_video_mode == 0x10) ||\t/* 640x350/4 */\n\t    (screen_info.orig_video_mode == 0x12) ||\t/* 640x480/4 */\n\t    (screen_info.orig_video_mode == 0x6A))\t/* 800x600/4 (VESA) */\n\t\tgoto no_vga;\n\n\tvga_video_num_lines = screen_info.orig_video_lines;\n\tvga_video_num_columns = screen_info.orig_video_cols;\n\tvgastate.vgabase = NULL;\n\n\tif (screen_info.orig_video_mode == 7) {\n\t\t/* Monochrome display */\n\t\tvga_vram_base = 0xb0000;\n\t\tvga_video_port_reg = VGA_CRT_IM;\n\t\tvga_video_port_val = VGA_CRT_DM;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tstatic struct resource ega_console_resource =\n\t\t\t    { .name\t= \"ega\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_EGAM;\n\t\t\tvga_vram_size = 0x8000;\n\t\t\tdisplay_desc = \"EGA+\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &ega_console_resource);\n\t\t} else {\n\t\t\tstatic struct resource mda1_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BB };\n\t\t\tstatic struct resource mda2_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3BF,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_MDA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*MDA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda1_console_resource);\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda2_console_resource);\n\t\t\tvga_video_font_height = 14;\n\t\t}\n\t} else {\n\t\t/* If not, it is color. */\n\t\tvga_can_do_color = true;\n\t\tvga_vram_base = 0xb8000;\n\t\tvga_video_port_reg = VGA_CRT_IC;\n\t\tvga_video_port_val = VGA_CRT_DC;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tint i;\n\n\t\t\tvga_vram_size = 0x8000;\n\n\t\t\tif (!screen_info.orig_video_isVGA) {\n\t\t\t\tstatic struct resource ega_console_resource =\n\t\t\t\t    { .name\t= \"ega\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_EGAC;\n\t\t\t\tdisplay_desc = \"EGA\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &ega_console_resource);\n\t\t\t} else {\n\t\t\t\tstatic struct resource vga_console_resource =\n\t\t\t\t    { .name\t= \"vga+\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_VGAC;\n\t\t\t\tdisplay_desc = \"VGA+\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &vga_console_resource);\n\n\t\t\t\t/*\n\t\t\t\t * Normalise the palette registers, to point\n\t\t\t\t * the 16 screen colours to the first 16\n\t\t\t\t * DAC entries.\n\t\t\t\t */\n\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\tinb_p(VGA_IS1_RC);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t}\n\t\t\t\toutb_p(0x20, VGA_ATT_W);\n\n\t\t\t\t/*\n\t\t\t\t * Now set the DAC registers back to their\n\t\t\t\t * default values\n\t\t\t\t */\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\toutb_p(color_table[i], VGA_PEL_IW);\n\t\t\t\t\toutb_p(default_red[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_grn[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_blu[i], VGA_PEL_D);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tstatic struct resource cga_console_resource =\n\t\t\t    { .name\t= \"cga\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3D4,\n\t\t\t      .end\t= 0x3D5 };\n\t\t\tvga_video_type = VIDEO_TYPE_CGA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*CGA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &cga_console_resource);\n\t\t\tvga_video_font_height = 8;\n\t\t}\n\t}\n\n\tvga_vram_base = VGA_MAP_MEM(vga_vram_base, vga_vram_size);\n\tvga_vram_end = vga_vram_base + vga_vram_size;\n\n\t/*\n\t *      Find out if there is a graphics card present.\n\t *      Are there smarter methods around?\n\t */\n\tp = (volatile u16 *) vga_vram_base;\n\tsaved1 = scr_readw(p);\n\tsaved2 = scr_readw(p + 1);\n\tscr_writew(0xAA55, p);\n\tscr_writew(0x55AA, p + 1);\n\tif (scr_readw(p) != 0xAA55 || scr_readw(p + 1) != 0x55AA) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(0x55AA, p);\n\tscr_writew(0xAA55, p + 1);\n\tif (scr_readw(p) != 0x55AA || scr_readw(p + 1) != 0xAA55) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(saved1, p);\n\tscr_writew(saved2, p + 1);\n\n\tif (vga_video_type == VIDEO_TYPE_EGAC\n\t    || vga_video_type == VIDEO_TYPE_VGAC\n\t    || vga_video_type == VIDEO_TYPE_EGAM) {\n\t\tvga_hardscroll_enabled = vga_hardscroll_user_enable;\n\t\tvga_default_font_height = screen_info.orig_video_points;\n\t\tvga_video_font_height = screen_info.orig_video_points;\n\t\t/* This may be suboptimal but is a safe bet - go with it */\n\t\tvga_scan_lines =\n\t\t    vga_video_font_height * vga_video_num_lines;\n\t}\n\n\tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n\tvgacon_yres = vga_scan_lines;\n\n\tvga_init_done = true;\n\n\treturn display_desc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -180,10 +180,7 @@\n \tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n \tvgacon_yres = vga_scan_lines;\n \n-\tif (!vga_init_done) {\n-\t\tvgacon_scrollback_startup();\n-\t\tvga_init_done = true;\n-\t}\n+\tvga_init_done = true;\n \n \treturn display_desc;\n }",
        "function_modified_lines": {
            "added": [
                "\tvga_init_done = true;"
            ],
            "deleted": [
                "\tif (!vga_init_done) {",
                "\t\tvgacon_scrollback_startup();",
                "\t\tvga_init_done = true;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The vgacon subsystem in the Linux kernel before 5.8.10 mishandles software scrollback. There is a vgacon_scrolldelta out-of-bounds read, aka CID-973c096f6a85.",
        "id": 2656
    },
    {
        "cve_id": "CVE-2021-0605",
        "code_before_change": "static int pfkey_dump(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs)\n{\n\tu8 proto;\n\tstruct xfrm_address_filter *filter = NULL;\n\tstruct pfkey_sock *pfk = pfkey_sk(sk);\n\n\tmutex_lock(&pfk->dump_lock);\n\tif (pfk->dump.dump != NULL) {\n\t\tmutex_unlock(&pfk->dump_lock);\n\t\treturn -EBUSY;\n\t}\n\n\tproto = pfkey_satype2proto(hdr->sadb_msg_satype);\n\tif (proto == 0) {\n\t\tmutex_unlock(&pfk->dump_lock);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ext_hdrs[SADB_X_EXT_FILTER - 1]) {\n\t\tstruct sadb_x_filter *xfilter = ext_hdrs[SADB_X_EXT_FILTER - 1];\n\n\t\tfilter = kmalloc(sizeof(*filter), GFP_KERNEL);\n\t\tif (filter == NULL) {\n\t\t\tmutex_unlock(&pfk->dump_lock);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tmemcpy(&filter->saddr, &xfilter->sadb_x_filter_saddr,\n\t\t       sizeof(xfrm_address_t));\n\t\tmemcpy(&filter->daddr, &xfilter->sadb_x_filter_daddr,\n\t\t       sizeof(xfrm_address_t));\n\t\tfilter->family = xfilter->sadb_x_filter_family;\n\t\tfilter->splen = xfilter->sadb_x_filter_splen;\n\t\tfilter->dplen = xfilter->sadb_x_filter_dplen;\n\t}\n\n\tpfk->dump.msg_version = hdr->sadb_msg_version;\n\tpfk->dump.msg_portid = hdr->sadb_msg_pid;\n\tpfk->dump.dump = pfkey_dump_sa;\n\tpfk->dump.done = pfkey_dump_sa_done;\n\txfrm_state_walk_init(&pfk->dump.u.state, proto, filter);\n\tmutex_unlock(&pfk->dump_lock);\n\n\treturn pfkey_do_dump(pfk);\n}",
        "code_after_change": "static int pfkey_dump(struct sock *sk, struct sk_buff *skb, const struct sadb_msg *hdr, void * const *ext_hdrs)\n{\n\tu8 proto;\n\tstruct xfrm_address_filter *filter = NULL;\n\tstruct pfkey_sock *pfk = pfkey_sk(sk);\n\n\tmutex_lock(&pfk->dump_lock);\n\tif (pfk->dump.dump != NULL) {\n\t\tmutex_unlock(&pfk->dump_lock);\n\t\treturn -EBUSY;\n\t}\n\n\tproto = pfkey_satype2proto(hdr->sadb_msg_satype);\n\tif (proto == 0) {\n\t\tmutex_unlock(&pfk->dump_lock);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ext_hdrs[SADB_X_EXT_FILTER - 1]) {\n\t\tstruct sadb_x_filter *xfilter = ext_hdrs[SADB_X_EXT_FILTER - 1];\n\n\t\tif ((xfilter->sadb_x_filter_splen >=\n\t\t\t(sizeof(xfrm_address_t) << 3)) ||\n\t\t    (xfilter->sadb_x_filter_dplen >=\n\t\t\t(sizeof(xfrm_address_t) << 3))) {\n\t\t\tmutex_unlock(&pfk->dump_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tfilter = kmalloc(sizeof(*filter), GFP_KERNEL);\n\t\tif (filter == NULL) {\n\t\t\tmutex_unlock(&pfk->dump_lock);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tmemcpy(&filter->saddr, &xfilter->sadb_x_filter_saddr,\n\t\t       sizeof(xfrm_address_t));\n\t\tmemcpy(&filter->daddr, &xfilter->sadb_x_filter_daddr,\n\t\t       sizeof(xfrm_address_t));\n\t\tfilter->family = xfilter->sadb_x_filter_family;\n\t\tfilter->splen = xfilter->sadb_x_filter_splen;\n\t\tfilter->dplen = xfilter->sadb_x_filter_dplen;\n\t}\n\n\tpfk->dump.msg_version = hdr->sadb_msg_version;\n\tpfk->dump.msg_portid = hdr->sadb_msg_pid;\n\tpfk->dump.dump = pfkey_dump_sa;\n\tpfk->dump.done = pfkey_dump_sa_done;\n\txfrm_state_walk_init(&pfk->dump.u.state, proto, filter);\n\tmutex_unlock(&pfk->dump_lock);\n\n\treturn pfkey_do_dump(pfk);\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,13 @@\n \tif (ext_hdrs[SADB_X_EXT_FILTER - 1]) {\n \t\tstruct sadb_x_filter *xfilter = ext_hdrs[SADB_X_EXT_FILTER - 1];\n \n+\t\tif ((xfilter->sadb_x_filter_splen >=\n+\t\t\t(sizeof(xfrm_address_t) << 3)) ||\n+\t\t    (xfilter->sadb_x_filter_dplen >=\n+\t\t\t(sizeof(xfrm_address_t) << 3))) {\n+\t\t\tmutex_unlock(&pfk->dump_lock);\n+\t\t\treturn -EINVAL;\n+\t\t}\n \t\tfilter = kmalloc(sizeof(*filter), GFP_KERNEL);\n \t\tif (filter == NULL) {\n \t\t\tmutex_unlock(&pfk->dump_lock);",
        "function_modified_lines": {
            "added": [
                "\t\tif ((xfilter->sadb_x_filter_splen >=",
                "\t\t\t(sizeof(xfrm_address_t) << 3)) ||",
                "\t\t    (xfilter->sadb_x_filter_dplen >=",
                "\t\t\t(sizeof(xfrm_address_t) << 3))) {",
                "\t\t\tmutex_unlock(&pfk->dump_lock);",
                "\t\t\treturn -EINVAL;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In pfkey_dump of af_key.c, there is a possible out-of-bounds read due to a missing bounds check. This could lead to local information disclosure in the kernel with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-110373476",
        "id": 2828
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "static int indx_insert_into_root(struct ntfs_index *indx, struct ntfs_inode *ni,\n\t\t\t\t const struct NTFS_DE *new_de,\n\t\t\t\t struct NTFS_DE *root_de, const void *ctx,\n\t\t\t\t struct ntfs_fnd *fnd, bool undo)\n{\n\tint err = 0;\n\tstruct NTFS_DE *e, *e0, *re;\n\tstruct mft_inode *mi;\n\tstruct ATTRIB *attr;\n\tstruct INDEX_HDR *hdr;\n\tstruct indx_node *n;\n\tCLST new_vbn;\n\t__le64 *sub_vbn, t_vbn;\n\tu16 new_de_size;\n\tu32 hdr_used, hdr_total, asize, to_move;\n\tu32 root_size, new_root_size;\n\tstruct ntfs_sb_info *sbi;\n\tint ds_root;\n\tstruct INDEX_ROOT *root, *a_root;\n\n\t/* Get the record this root placed in. */\n\troot = indx_get_root(indx, ni, &attr, &mi);\n\tif (!root)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Try easy case:\n\t * hdr_insert_de will succeed if there's\n\t * room the root for the new entry.\n\t */\n\thdr = &root->ihdr;\n\tsbi = ni->mi.sbi;\n\tnew_de_size = le16_to_cpu(new_de->size);\n\thdr_used = le32_to_cpu(hdr->used);\n\thdr_total = le32_to_cpu(hdr->total);\n\tasize = le32_to_cpu(attr->size);\n\troot_size = le32_to_cpu(attr->res.data_size);\n\n\tds_root = new_de_size + hdr_used - hdr_total;\n\n\t/* If 'undo' is set then reduce requirements. */\n\tif ((undo || asize + ds_root < sbi->max_bytes_per_attr) &&\n\t    mi_resize_attr(mi, attr, ds_root)) {\n\t\thdr->total = cpu_to_le32(hdr_total + ds_root);\n\t\te = hdr_insert_de(indx, hdr, new_de, root_de, ctx);\n\t\tWARN_ON(!e);\n\t\tfnd_clear(fnd);\n\t\tfnd->root_de = e;\n\n\t\treturn 0;\n\t}\n\n\t/* Make a copy of root attribute to restore if error. */\n\ta_root = kmemdup(attr, asize, GFP_NOFS);\n\tif (!a_root)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Copy all the non-end entries from\n\t * the index root to the new buffer.\n\t */\n\tto_move = 0;\n\te0 = hdr_first_de(hdr);\n\n\t/* Calculate the size to copy. */\n\tfor (e = e0;; e = hdr_next_de(hdr, e)) {\n\t\tif (!e) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_free_root;\n\t\t}\n\n\t\tif (de_is_last(e))\n\t\t\tbreak;\n\t\tto_move += le16_to_cpu(e->size);\n\t}\n\n\tif (!to_move) {\n\t\tre = NULL;\n\t} else {\n\t\tre = kmemdup(e0, to_move, GFP_NOFS);\n\t\tif (!re) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_free_root;\n\t\t}\n\t}\n\n\tsub_vbn = NULL;\n\tif (de_has_vcn(e)) {\n\t\tt_vbn = de_get_vbn_le(e);\n\t\tsub_vbn = &t_vbn;\n\t}\n\n\tnew_root_size = sizeof(struct INDEX_ROOT) + sizeof(struct NTFS_DE) +\n\t\t\tsizeof(u64);\n\tds_root = new_root_size - root_size;\n\n\tif (ds_root > 0 && asize + ds_root > sbi->max_bytes_per_attr) {\n\t\t/* Make root external. */\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out_free_re;\n\t}\n\n\tif (ds_root)\n\t\tmi_resize_attr(mi, attr, ds_root);\n\n\t/* Fill first entry (vcn will be set later). */\n\te = (struct NTFS_DE *)(root + 1);\n\tmemset(e, 0, sizeof(struct NTFS_DE));\n\te->size = cpu_to_le16(sizeof(struct NTFS_DE) + sizeof(u64));\n\te->flags = NTFS_IE_HAS_SUBNODES | NTFS_IE_LAST;\n\n\thdr->flags = 1;\n\thdr->used = hdr->total =\n\t\tcpu_to_le32(new_root_size - offsetof(struct INDEX_ROOT, ihdr));\n\n\tfnd->root_de = hdr_first_de(hdr);\n\tmi->dirty = true;\n\n\t/* Create alloc and bitmap attributes (if not). */\n\terr = run_is_empty(&indx->alloc_run)\n\t\t      ? indx_create_allocate(indx, ni, &new_vbn)\n\t\t      : indx_add_allocate(indx, ni, &new_vbn);\n\n\t/* Layout of record may be changed, so rescan root. */\n\troot = indx_get_root(indx, ni, &attr, &mi);\n\tif (!root) {\n\t\t/* Bug? */\n\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n\t\terr = -EINVAL;\n\t\tgoto out_free_re;\n\t}\n\n\tif (err) {\n\t\t/* Restore root. */\n\t\tif (mi_resize_attr(mi, attr, -ds_root))\n\t\t\tmemcpy(attr, a_root, asize);\n\t\telse {\n\t\t\t/* Bug? */\n\t\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n\t\t}\n\t\tgoto out_free_re;\n\t}\n\n\te = (struct NTFS_DE *)(root + 1);\n\t*(__le64 *)(e + 1) = cpu_to_le64(new_vbn);\n\tmi->dirty = true;\n\n\t/* Now we can create/format the new buffer and copy the entries into. */\n\tn = indx_new(indx, ni, new_vbn, sub_vbn);\n\tif (IS_ERR(n)) {\n\t\terr = PTR_ERR(n);\n\t\tgoto out_free_re;\n\t}\n\n\thdr = &n->index->ihdr;\n\thdr_used = le32_to_cpu(hdr->used);\n\thdr_total = le32_to_cpu(hdr->total);\n\n\t/* Copy root entries into new buffer. */\n\thdr_insert_head(hdr, re, to_move);\n\n\t/* Update bitmap attribute. */\n\tindx_mark_used(indx, ni, new_vbn >> indx->idx2vbn_bits);\n\n\t/* Check if we can insert new entry new index buffer. */\n\tif (hdr_used + new_de_size > hdr_total) {\n\t\t/*\n\t\t * This occurs if MFT record is the same or bigger than index\n\t\t * buffer. Move all root new index and have no space to add\n\t\t * new entry classic case when MFT record is 1K and index\n\t\t * buffer 4K the problem should not occurs.\n\t\t */\n\t\tkfree(re);\n\t\tindx_write(indx, ni, n, 0);\n\n\t\tput_indx_node(n);\n\t\tfnd_clear(fnd);\n\t\terr = indx_insert_entry(indx, ni, new_de, ctx, fnd, undo);\n\t\tgoto out_free_root;\n\t}\n\n\t/*\n\t * Now root is a parent for new index buffer.\n\t * Insert NewEntry a new buffer.\n\t */\n\te = hdr_insert_de(indx, hdr, new_de, NULL, ctx);\n\tif (!e) {\n\t\terr = -EINVAL;\n\t\tgoto out_put_n;\n\t}\n\tfnd_push(fnd, n, e);\n\n\t/* Just write updates index into disk. */\n\tindx_write(indx, ni, n, 0);\n\n\tn = NULL;\n\nout_put_n:\n\tput_indx_node(n);\nout_free_re:\n\tkfree(re);\nout_free_root:\n\tkfree(a_root);\n\treturn err;\n}",
        "code_after_change": "static int indx_insert_into_root(struct ntfs_index *indx, struct ntfs_inode *ni,\n\t\t\t\t const struct NTFS_DE *new_de,\n\t\t\t\t struct NTFS_DE *root_de, const void *ctx,\n\t\t\t\t struct ntfs_fnd *fnd, bool undo)\n{\n\tint err = 0;\n\tstruct NTFS_DE *e, *e0, *re;\n\tstruct mft_inode *mi;\n\tstruct ATTRIB *attr;\n\tstruct INDEX_HDR *hdr;\n\tstruct indx_node *n;\n\tCLST new_vbn;\n\t__le64 *sub_vbn, t_vbn;\n\tu16 new_de_size;\n\tu32 hdr_used, hdr_total, asize, to_move;\n\tu32 root_size, new_root_size;\n\tstruct ntfs_sb_info *sbi;\n\tint ds_root;\n\tstruct INDEX_ROOT *root, *a_root;\n\n\t/* Get the record this root placed in. */\n\troot = indx_get_root(indx, ni, &attr, &mi);\n\tif (!root)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Try easy case:\n\t * hdr_insert_de will succeed if there's\n\t * room the root for the new entry.\n\t */\n\thdr = &root->ihdr;\n\tsbi = ni->mi.sbi;\n\tnew_de_size = le16_to_cpu(new_de->size);\n\thdr_used = le32_to_cpu(hdr->used);\n\thdr_total = le32_to_cpu(hdr->total);\n\tasize = le32_to_cpu(attr->size);\n\troot_size = le32_to_cpu(attr->res.data_size);\n\n\tds_root = new_de_size + hdr_used - hdr_total;\n\n\t/* If 'undo' is set then reduce requirements. */\n\tif ((undo || asize + ds_root < sbi->max_bytes_per_attr) &&\n\t    mi_resize_attr(mi, attr, ds_root)) {\n\t\thdr->total = cpu_to_le32(hdr_total + ds_root);\n\t\te = hdr_insert_de(indx, hdr, new_de, root_de, ctx);\n\t\tWARN_ON(!e);\n\t\tfnd_clear(fnd);\n\t\tfnd->root_de = e;\n\n\t\treturn 0;\n\t}\n\n\t/* Make a copy of root attribute to restore if error. */\n\ta_root = kmemdup(attr, asize, GFP_NOFS);\n\tif (!a_root)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Copy all the non-end entries from\n\t * the index root to the new buffer.\n\t */\n\tto_move = 0;\n\te0 = hdr_first_de(hdr);\n\n\t/* Calculate the size to copy. */\n\tfor (e = e0;; e = hdr_next_de(hdr, e)) {\n\t\tif (!e) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_free_root;\n\t\t}\n\n\t\tif (de_is_last(e))\n\t\t\tbreak;\n\t\tto_move += le16_to_cpu(e->size);\n\t}\n\n\tif (!to_move) {\n\t\tre = NULL;\n\t} else {\n\t\tre = kmemdup(e0, to_move, GFP_NOFS);\n\t\tif (!re) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_free_root;\n\t\t}\n\t}\n\n\tsub_vbn = NULL;\n\tif (de_has_vcn(e)) {\n\t\tt_vbn = de_get_vbn_le(e);\n\t\tsub_vbn = &t_vbn;\n\t}\n\n\tnew_root_size = sizeof(struct INDEX_ROOT) + sizeof(struct NTFS_DE) +\n\t\t\tsizeof(u64);\n\tds_root = new_root_size - root_size;\n\n\tif (ds_root > 0 && asize + ds_root > sbi->max_bytes_per_attr) {\n\t\t/* Make root external. */\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out_free_re;\n\t}\n\n\tif (ds_root)\n\t\tmi_resize_attr(mi, attr, ds_root);\n\n\t/* Fill first entry (vcn will be set later). */\n\te = (struct NTFS_DE *)(root + 1);\n\tmemset(e, 0, sizeof(struct NTFS_DE));\n\te->size = cpu_to_le16(sizeof(struct NTFS_DE) + sizeof(u64));\n\te->flags = NTFS_IE_HAS_SUBNODES | NTFS_IE_LAST;\n\n\thdr->flags = 1;\n\thdr->used = hdr->total =\n\t\tcpu_to_le32(new_root_size - offsetof(struct INDEX_ROOT, ihdr));\n\n\tfnd->root_de = hdr_first_de(hdr);\n\tmi->dirty = true;\n\n\t/* Create alloc and bitmap attributes (if not). */\n\terr = run_is_empty(&indx->alloc_run)\n\t\t      ? indx_create_allocate(indx, ni, &new_vbn)\n\t\t      : indx_add_allocate(indx, ni, &new_vbn);\n\n\t/* Layout of record may be changed, so rescan root. */\n\troot = indx_get_root(indx, ni, &attr, &mi);\n\tif (!root) {\n\t\t/* Bug? */\n\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n\t\terr = -EINVAL;\n\t\tgoto out_free_re;\n\t}\n\n\tif (err) {\n\t\t/* Restore root. */\n\t\tif (mi_resize_attr(mi, attr, -ds_root)) {\n\t\t\tmemcpy(attr, a_root, asize);\n\t\t} else {\n\t\t\t/* Bug? */\n\t\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n\t\t}\n\t\tgoto out_free_re;\n\t}\n\n\te = (struct NTFS_DE *)(root + 1);\n\t*(__le64 *)(e + 1) = cpu_to_le64(new_vbn);\n\tmi->dirty = true;\n\n\t/* Now we can create/format the new buffer and copy the entries into. */\n\tn = indx_new(indx, ni, new_vbn, sub_vbn);\n\tif (IS_ERR(n)) {\n\t\terr = PTR_ERR(n);\n\t\tgoto out_free_re;\n\t}\n\n\thdr = &n->index->ihdr;\n\thdr_used = le32_to_cpu(hdr->used);\n\thdr_total = le32_to_cpu(hdr->total);\n\n\t/* Copy root entries into new buffer. */\n\thdr_insert_head(hdr, re, to_move);\n\n\t/* Update bitmap attribute. */\n\tindx_mark_used(indx, ni, new_vbn >> indx->idx2vbn_bits);\n\n\t/* Check if we can insert new entry new index buffer. */\n\tif (hdr_used + new_de_size > hdr_total) {\n\t\t/*\n\t\t * This occurs if MFT record is the same or bigger than index\n\t\t * buffer. Move all root new index and have no space to add\n\t\t * new entry classic case when MFT record is 1K and index\n\t\t * buffer 4K the problem should not occurs.\n\t\t */\n\t\tkfree(re);\n\t\tindx_write(indx, ni, n, 0);\n\n\t\tput_indx_node(n);\n\t\tfnd_clear(fnd);\n\t\terr = indx_insert_entry(indx, ni, new_de, ctx, fnd, undo);\n\t\tgoto out_free_root;\n\t}\n\n\t/*\n\t * Now root is a parent for new index buffer.\n\t * Insert NewEntry a new buffer.\n\t */\n\te = hdr_insert_de(indx, hdr, new_de, NULL, ctx);\n\tif (!e) {\n\t\terr = -EINVAL;\n\t\tgoto out_put_n;\n\t}\n\tfnd_push(fnd, n, e);\n\n\t/* Just write updates index into disk. */\n\tindx_write(indx, ni, n, 0);\n\n\tn = NULL;\n\nout_put_n:\n\tput_indx_node(n);\nout_free_re:\n\tkfree(re);\nout_free_root:\n\tkfree(a_root);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -132,9 +132,9 @@\n \n \tif (err) {\n \t\t/* Restore root. */\n-\t\tif (mi_resize_attr(mi, attr, -ds_root))\n+\t\tif (mi_resize_attr(mi, attr, -ds_root)) {\n \t\t\tmemcpy(attr, a_root, asize);\n-\t\telse {\n+\t\t} else {\n \t\t\t/* Bug? */\n \t\t\tntfs_set_state(sbi, NTFS_DIRTY_ERROR);\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (mi_resize_attr(mi, attr, -ds_root)) {",
                "\t\t} else {"
            ],
            "deleted": [
                "\t\tif (mi_resize_attr(mi, attr, -ds_root))",
                "\t\telse {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3792
    },
    {
        "cve_id": "CVE-2019-15926",
        "code_before_change": "static int ath6kl_wmi_pstream_timeout_event_rx(struct wmi *wmi, u8 *datap,\n\t\t\t\t\t       int len)\n{\n\tstruct wmi_pstream_timeout_event *ev;\n\n\tif (len < sizeof(struct wmi_pstream_timeout_event))\n\t\treturn -EINVAL;\n\n\tev = (struct wmi_pstream_timeout_event *) datap;\n\n\t/*\n\t * When the pstream (fat pipe == AC) timesout, it means there were\n\t * no thinStreams within this pstream & it got implicitly created\n\t * due to data flow on this AC. We start the inactivity timer only\n\t * for implicitly created pstream. Just reset the host state.\n\t */\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[ev->traffic_class] = 0;\n\twmi->fat_pipe_exist &= ~(1 << ev->traffic_class);\n\tspin_unlock_bh(&wmi->lock);\n\n\t/* Indicate inactivity to driver layer for this fatpipe (pstream) */\n\tath6kl_indicate_tx_activity(wmi->parent_dev, ev->traffic_class, false);\n\n\treturn 0;\n}",
        "code_after_change": "static int ath6kl_wmi_pstream_timeout_event_rx(struct wmi *wmi, u8 *datap,\n\t\t\t\t\t       int len)\n{\n\tstruct wmi_pstream_timeout_event *ev;\n\n\tif (len < sizeof(struct wmi_pstream_timeout_event))\n\t\treturn -EINVAL;\n\n\tev = (struct wmi_pstream_timeout_event *) datap;\n\tif (ev->traffic_class >= WMM_NUM_AC) {\n\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * When the pstream (fat pipe == AC) timesout, it means there were\n\t * no thinStreams within this pstream & it got implicitly created\n\t * due to data flow on this AC. We start the inactivity timer only\n\t * for implicitly created pstream. Just reset the host state.\n\t */\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[ev->traffic_class] = 0;\n\twmi->fat_pipe_exist &= ~(1 << ev->traffic_class);\n\tspin_unlock_bh(&wmi->lock);\n\n\t/* Indicate inactivity to driver layer for this fatpipe (pstream) */\n\tath6kl_indicate_tx_activity(wmi->parent_dev, ev->traffic_class, false);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,10 @@\n \t\treturn -EINVAL;\n \n \tev = (struct wmi_pstream_timeout_event *) datap;\n+\tif (ev->traffic_class >= WMM_NUM_AC) {\n+\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);\n+\t\treturn -EINVAL;\n+\t}\n \n \t/*\n \t * When the pstream (fat pipe == AC) timesout, it means there were",
        "function_modified_lines": {
            "added": [
                "\tif (ev->traffic_class >= WMM_NUM_AC) {",
                "\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. Out of bounds access exists in the functions ath6kl_wmi_pstream_timeout_event_rx and ath6kl_wmi_cac_event_rx in the file drivers/net/wireless/ath/ath6kl/wmi.c.",
        "id": 2039
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "static int read_prepare(struct kvm_vcpu *vcpu, void *val, int bytes)\n{\n\tif (vcpu->mmio_read_completed) {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);\n\t\tvcpu->mmio_read_completed = 0;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int read_prepare(struct kvm_vcpu *vcpu, void *val, int bytes)\n{\n\tif (vcpu->mmio_read_completed) {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n\t\t\t       vcpu->mmio_fragments[0].gpa, val);\n\t\tvcpu->mmio_read_completed = 0;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n {\n \tif (vcpu->mmio_read_completed) {\n \t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n-\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);\n+\t\t\t       vcpu->mmio_fragments[0].gpa, val);\n \t\tvcpu->mmio_read_completed = 0;\n \t\treturn 1;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t       vcpu->mmio_fragments[0].gpa, val);"
            ],
            "deleted": [
                "\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1370
    },
    {
        "cve_id": "CVE-2023-38428",
        "code_before_change": "static struct ksmbd_user *session_user(struct ksmbd_conn *conn,\n\t\t\t\t       struct smb2_sess_setup_req *req)\n{\n\tstruct authenticate_message *authblob;\n\tstruct ksmbd_user *user;\n\tchar *name;\n\tunsigned int auth_msg_len, name_off, name_len, secbuf_len;\n\n\tsecbuf_len = le16_to_cpu(req->SecurityBufferLength);\n\tif (secbuf_len < sizeof(struct authenticate_message)) {\n\t\tksmbd_debug(SMB, \"blob len %d too small\\n\", secbuf_len);\n\t\treturn NULL;\n\t}\n\tauthblob = user_authblob(conn, req);\n\tname_off = le32_to_cpu(authblob->UserName.BufferOffset);\n\tname_len = le16_to_cpu(authblob->UserName.Length);\n\tauth_msg_len = le16_to_cpu(req->SecurityBufferOffset) + secbuf_len;\n\n\tif (auth_msg_len < (u64)name_off + name_len)\n\t\treturn NULL;\n\n\tname = smb_strndup_from_utf16((const char *)authblob + name_off,\n\t\t\t\t      name_len,\n\t\t\t\t      true,\n\t\t\t\t      conn->local_nls);\n\tif (IS_ERR(name)) {\n\t\tpr_err(\"cannot allocate memory\\n\");\n\t\treturn NULL;\n\t}\n\n\tksmbd_debug(SMB, \"session setup request for user %s\\n\", name);\n\tuser = ksmbd_login_user(name);\n\tkfree(name);\n\treturn user;\n}",
        "code_after_change": "static struct ksmbd_user *session_user(struct ksmbd_conn *conn,\n\t\t\t\t       struct smb2_sess_setup_req *req)\n{\n\tstruct authenticate_message *authblob;\n\tstruct ksmbd_user *user;\n\tchar *name;\n\tunsigned int name_off, name_len, secbuf_len;\n\n\tsecbuf_len = le16_to_cpu(req->SecurityBufferLength);\n\tif (secbuf_len < sizeof(struct authenticate_message)) {\n\t\tksmbd_debug(SMB, \"blob len %d too small\\n\", secbuf_len);\n\t\treturn NULL;\n\t}\n\tauthblob = user_authblob(conn, req);\n\tname_off = le32_to_cpu(authblob->UserName.BufferOffset);\n\tname_len = le16_to_cpu(authblob->UserName.Length);\n\n\tif (secbuf_len < (u64)name_off + name_len)\n\t\treturn NULL;\n\n\tname = smb_strndup_from_utf16((const char *)authblob + name_off,\n\t\t\t\t      name_len,\n\t\t\t\t      true,\n\t\t\t\t      conn->local_nls);\n\tif (IS_ERR(name)) {\n\t\tpr_err(\"cannot allocate memory\\n\");\n\t\treturn NULL;\n\t}\n\n\tksmbd_debug(SMB, \"session setup request for user %s\\n\", name);\n\tuser = ksmbd_login_user(name);\n\tkfree(name);\n\treturn user;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n \tstruct authenticate_message *authblob;\n \tstruct ksmbd_user *user;\n \tchar *name;\n-\tunsigned int auth_msg_len, name_off, name_len, secbuf_len;\n+\tunsigned int name_off, name_len, secbuf_len;\n \n \tsecbuf_len = le16_to_cpu(req->SecurityBufferLength);\n \tif (secbuf_len < sizeof(struct authenticate_message)) {\n@@ -14,9 +14,8 @@\n \tauthblob = user_authblob(conn, req);\n \tname_off = le32_to_cpu(authblob->UserName.BufferOffset);\n \tname_len = le16_to_cpu(authblob->UserName.Length);\n-\tauth_msg_len = le16_to_cpu(req->SecurityBufferOffset) + secbuf_len;\n \n-\tif (auth_msg_len < (u64)name_off + name_len)\n+\tif (secbuf_len < (u64)name_off + name_len)\n \t\treturn NULL;\n \n \tname = smb_strndup_from_utf16((const char *)authblob + name_off,",
        "function_modified_lines": {
            "added": [
                "\tunsigned int name_off, name_len, secbuf_len;",
                "\tif (secbuf_len < (u64)name_off + name_len)"
            ],
            "deleted": [
                "\tunsigned int auth_msg_len, name_off, name_len, secbuf_len;",
                "\tauth_msg_len = le16_to_cpu(req->SecurityBufferOffset) + secbuf_len;",
                "\tif (auth_msg_len < (u64)name_off + name_len)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.4. fs/ksmbd/smb2pdu.c in ksmbd does not properly check the UserName value because it does not consider the address of security buffer, leading to an out-of-bounds read.",
        "id": 4140
    },
    {
        "cve_id": "CVE-2019-15918",
        "code_before_change": "int\nSMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\t\tses->server->ops = &smb311_operations;\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}",
        "code_after_change": "int\nSMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t\tses->server->vals = &smb21_values;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\t\tses->server->ops = &smb311_operations;\n\t\t\tses->server->vals = &smb311_values;\n\t\t}\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -114,8 +114,11 @@\n \t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n \t\t\t/* ops set to 3.0 by default for default so update */\n \t\t\tses->server->ops = &smb21_operations;\n-\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n+\t\t\tses->server->vals = &smb21_values;\n+\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n \t\t\tses->server->ops = &smb311_operations;\n+\t\t\tses->server->vals = &smb311_values;\n+\t\t}\n \t} else if (le16_to_cpu(rsp->DialectRevision) !=\n \t\t\t\tses->server->vals->protocol_id) {\n \t\t/* if requested single dialect ensure returned dialect matched */",
        "function_modified_lines": {
            "added": [
                "\t\t\tses->server->vals = &smb21_values;",
                "\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {",
                "\t\t\tses->server->vals = &smb311_values;",
                "\t\t}"
            ],
            "deleted": [
                "\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.10. SMB2_negotiate in fs/cifs/smb2pdu.c has an out-of-bounds read because data structures are incompletely updated after a change from smb30 to smb21.",
        "id": 2025
    },
    {
        "cve_id": "CVE-2018-15471",
        "code_before_change": "u32 xenvif_set_hash_mapping(struct xenvif *vif, u32 gref, u32 len,\n\t\t\t    u32 off)\n{\n\tu32 *mapping = &vif->hash.mapping[off];\n\tstruct gnttab_copy copy_op = {\n\t\t.source.u.ref = gref,\n\t\t.source.domid = vif->domid,\n\t\t.dest.u.gmfn = virt_to_gfn(mapping),\n\t\t.dest.domid = DOMID_SELF,\n\t\t.dest.offset = xen_offset_in_page(mapping),\n\t\t.len = len * sizeof(u32),\n\t\t.flags = GNTCOPY_source_gref\n\t};\n\n\tif ((off + len > vif->hash.size) || copy_op.len > XEN_PAGE_SIZE)\n\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\n\twhile (len-- != 0)\n\t\tif (mapping[off++] >= vif->num_queues)\n\t\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\n\tif (copy_op.len != 0) {\n\t\tgnttab_batch_copy(&copy_op, 1);\n\n\t\tif (copy_op.status != GNTST_okay)\n\t\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\t}\n\n\treturn XEN_NETIF_CTRL_STATUS_SUCCESS;\n}",
        "code_after_change": "u32 xenvif_set_hash_mapping(struct xenvif *vif, u32 gref, u32 len,\n\t\t\t    u32 off)\n{\n\tu32 *mapping = vif->hash.mapping;\n\tstruct gnttab_copy copy_op = {\n\t\t.source.u.ref = gref,\n\t\t.source.domid = vif->domid,\n\t\t.dest.domid = DOMID_SELF,\n\t\t.len = len * sizeof(*mapping),\n\t\t.flags = GNTCOPY_source_gref\n\t};\n\n\tif ((off + len < off) || (off + len > vif->hash.size) ||\n\t    len > XEN_PAGE_SIZE / sizeof(*mapping))\n\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\n\tcopy_op.dest.u.gmfn = virt_to_gfn(mapping + off);\n\tcopy_op.dest.offset = xen_offset_in_page(mapping + off);\n\n\twhile (len-- != 0)\n\t\tif (mapping[off++] >= vif->num_queues)\n\t\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\n\tif (copy_op.len != 0) {\n\t\tgnttab_batch_copy(&copy_op, 1);\n\n\t\tif (copy_op.status != GNTST_okay)\n\t\t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n\t}\n\n\treturn XEN_NETIF_CTRL_STATUS_SUCCESS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,19 +1,21 @@\n u32 xenvif_set_hash_mapping(struct xenvif *vif, u32 gref, u32 len,\n \t\t\t    u32 off)\n {\n-\tu32 *mapping = &vif->hash.mapping[off];\n+\tu32 *mapping = vif->hash.mapping;\n \tstruct gnttab_copy copy_op = {\n \t\t.source.u.ref = gref,\n \t\t.source.domid = vif->domid,\n-\t\t.dest.u.gmfn = virt_to_gfn(mapping),\n \t\t.dest.domid = DOMID_SELF,\n-\t\t.dest.offset = xen_offset_in_page(mapping),\n-\t\t.len = len * sizeof(u32),\n+\t\t.len = len * sizeof(*mapping),\n \t\t.flags = GNTCOPY_source_gref\n \t};\n \n-\tif ((off + len > vif->hash.size) || copy_op.len > XEN_PAGE_SIZE)\n+\tif ((off + len < off) || (off + len > vif->hash.size) ||\n+\t    len > XEN_PAGE_SIZE / sizeof(*mapping))\n \t\treturn XEN_NETIF_CTRL_STATUS_INVALID_PARAMETER;\n+\n+\tcopy_op.dest.u.gmfn = virt_to_gfn(mapping + off);\n+\tcopy_op.dest.offset = xen_offset_in_page(mapping + off);\n \n \twhile (len-- != 0)\n \t\tif (mapping[off++] >= vif->num_queues)",
        "function_modified_lines": {
            "added": [
                "\tu32 *mapping = vif->hash.mapping;",
                "\t\t.len = len * sizeof(*mapping),",
                "\tif ((off + len < off) || (off + len > vif->hash.size) ||",
                "\t    len > XEN_PAGE_SIZE / sizeof(*mapping))",
                "",
                "\tcopy_op.dest.u.gmfn = virt_to_gfn(mapping + off);",
                "\tcopy_op.dest.offset = xen_offset_in_page(mapping + off);"
            ],
            "deleted": [
                "\tu32 *mapping = &vif->hash.mapping[off];",
                "\t\t.dest.u.gmfn = virt_to_gfn(mapping),",
                "\t\t.dest.offset = xen_offset_in_page(mapping),",
                "\t\t.len = len * sizeof(u32),",
                "\tif ((off + len > vif->hash.size) || copy_op.len > XEN_PAGE_SIZE)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in xenvif_set_hash_mapping in drivers/net/xen-netback/hash.c in the Linux kernel through 4.18.1, as used in Xen through 4.11.x and other products. The Linux netback driver allows frontends to control mapping of requests to request queues. When processing a request to set or change this mapping, some input validation (e.g., for an integer overflow) was missing or flawed, leading to OOB access in hash handling. A malicious or buggy frontend may cause the (usually privileged) backend to make out of bounds memory accesses, potentially resulting in one or more of privilege escalation, Denial of Service (DoS), or information leaks.",
        "id": 1707
    },
    {
        "cve_id": "CVE-2023-26607",
        "code_before_change": "static int ntfs_attr_find(const ATTR_TYPE type, const ntfschar *name,\n\t\tconst u32 name_len, const IGNORE_CASE_BOOL ic,\n\t\tconst u8 *val, const u32 val_len, ntfs_attr_search_ctx *ctx)\n{\n\tATTR_RECORD *a;\n\tntfs_volume *vol = ctx->ntfs_ino->vol;\n\tntfschar *upcase = vol->upcase;\n\tu32 upcase_len = vol->upcase_len;\n\n\t/*\n\t * Iterate over attributes in mft record starting at @ctx->attr, or the\n\t * attribute following that, if @ctx->is_first is 'true'.\n\t */\n\tif (ctx->is_first) {\n\t\ta = ctx->attr;\n\t\tctx->is_first = false;\n\t} else\n\t\ta = (ATTR_RECORD*)((u8*)ctx->attr +\n\t\t\t\tle32_to_cpu(ctx->attr->length));\n\tfor (;;\ta = (ATTR_RECORD*)((u8*)a + le32_to_cpu(a->length))) {\n\t\tu8 *mrec_end = (u8 *)ctx->mrec +\n\t\t               le32_to_cpu(ctx->mrec->bytes_allocated);\n\t\tu8 *name_end = (u8 *)a + le16_to_cpu(a->name_offset) +\n\t\t\t       a->name_length * sizeof(ntfschar);\n\t\tif ((u8*)a < (u8*)ctx->mrec || (u8*)a > mrec_end ||\n\t\t    name_end > mrec_end)\n\t\t\tbreak;\n\t\tctx->attr = a;\n\t\tif (unlikely(le32_to_cpu(a->type) > le32_to_cpu(type) ||\n\t\t\t\ta->type == AT_END))\n\t\t\treturn -ENOENT;\n\t\tif (unlikely(!a->length))\n\t\t\tbreak;\n\t\tif (a->type != type)\n\t\t\tcontinue;\n\t\t/*\n\t\t * If @name is present, compare the two names.  If @name is\n\t\t * missing, assume we want an unnamed attribute.\n\t\t */\n\t\tif (!name) {\n\t\t\t/* The search failed if the found attribute is named. */\n\t\t\tif (a->name_length)\n\t\t\t\treturn -ENOENT;\n\t\t} else if (!ntfs_are_names_equal(name, name_len,\n\t\t\t    (ntfschar*)((u8*)a + le16_to_cpu(a->name_offset)),\n\t\t\t    a->name_length, ic, upcase, upcase_len)) {\n\t\t\tregister int rc;\n\n\t\t\trc = ntfs_collate_names(name, name_len,\n\t\t\t\t\t(ntfschar*)((u8*)a +\n\t\t\t\t\tle16_to_cpu(a->name_offset)),\n\t\t\t\t\ta->name_length, 1, IGNORE_CASE,\n\t\t\t\t\tupcase, upcase_len);\n\t\t\t/*\n\t\t\t * If @name collates before a->name, there is no\n\t\t\t * matching attribute.\n\t\t\t */\n\t\t\tif (rc == -1)\n\t\t\t\treturn -ENOENT;\n\t\t\t/* If the strings are not equal, continue search. */\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t\trc = ntfs_collate_names(name, name_len,\n\t\t\t\t\t(ntfschar*)((u8*)a +\n\t\t\t\t\tle16_to_cpu(a->name_offset)),\n\t\t\t\t\ta->name_length, 1, CASE_SENSITIVE,\n\t\t\t\t\tupcase, upcase_len);\n\t\t\tif (rc == -1)\n\t\t\t\treturn -ENOENT;\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * The names match or @name not present and attribute is\n\t\t * unnamed.  If no @val specified, we have found the attribute\n\t\t * and are done.\n\t\t */\n\t\tif (!val)\n\t\t\treturn 0;\n\t\t/* @val is present; compare values. */\n\t\telse {\n\t\t\tregister int rc;\n\n\t\t\trc = memcmp(val, (u8*)a + le16_to_cpu(\n\t\t\t\t\ta->data.resident.value_offset),\n\t\t\t\t\tmin_t(u32, val_len, le32_to_cpu(\n\t\t\t\t\ta->data.resident.value_length)));\n\t\t\t/*\n\t\t\t * If @val collates before the current attribute's\n\t\t\t * value, there is no matching attribute.\n\t\t\t */\n\t\t\tif (!rc) {\n\t\t\t\tregister u32 avl;\n\n\t\t\t\tavl = le32_to_cpu(\n\t\t\t\t\t\ta->data.resident.value_length);\n\t\t\t\tif (val_len == avl)\n\t\t\t\t\treturn 0;\n\t\t\t\tif (val_len < avl)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t} else if (rc < 0)\n\t\t\t\treturn -ENOENT;\n\t\t}\n\t}\n\tntfs_error(vol->sb, \"Inode is corrupt.  Run chkdsk.\");\n\tNVolSetErrors(vol);\n\treturn -EIO;\n}",
        "code_after_change": "static int ntfs_attr_find(const ATTR_TYPE type, const ntfschar *name,\n\t\tconst u32 name_len, const IGNORE_CASE_BOOL ic,\n\t\tconst u8 *val, const u32 val_len, ntfs_attr_search_ctx *ctx)\n{\n\tATTR_RECORD *a;\n\tntfs_volume *vol = ctx->ntfs_ino->vol;\n\tntfschar *upcase = vol->upcase;\n\tu32 upcase_len = vol->upcase_len;\n\n\t/*\n\t * Iterate over attributes in mft record starting at @ctx->attr, or the\n\t * attribute following that, if @ctx->is_first is 'true'.\n\t */\n\tif (ctx->is_first) {\n\t\ta = ctx->attr;\n\t\tctx->is_first = false;\n\t} else\n\t\ta = (ATTR_RECORD*)((u8*)ctx->attr +\n\t\t\t\tle32_to_cpu(ctx->attr->length));\n\tfor (;;\ta = (ATTR_RECORD*)((u8*)a + le32_to_cpu(a->length))) {\n\t\tu8 *mrec_end = (u8 *)ctx->mrec +\n\t\t               le32_to_cpu(ctx->mrec->bytes_allocated);\n\t\tu8 *name_end;\n\n\t\t/* check whether ATTR_RECORD wrap */\n\t\tif ((u8 *)a < (u8 *)ctx->mrec)\n\t\t\tbreak;\n\n\t\t/* check whether Attribute Record Header is within bounds */\n\t\tif ((u8 *)a > mrec_end ||\n\t\t    (u8 *)a + sizeof(ATTR_RECORD) > mrec_end)\n\t\t\tbreak;\n\n\t\t/* check whether ATTR_RECORD's name is within bounds */\n\t\tname_end = (u8 *)a + le16_to_cpu(a->name_offset) +\n\t\t\t   a->name_length * sizeof(ntfschar);\n\t\tif (name_end > mrec_end)\n\t\t\tbreak;\n\n\t\tctx->attr = a;\n\t\tif (unlikely(le32_to_cpu(a->type) > le32_to_cpu(type) ||\n\t\t\t\ta->type == AT_END))\n\t\t\treturn -ENOENT;\n\t\tif (unlikely(!a->length))\n\t\t\tbreak;\n\t\tif (a->type != type)\n\t\t\tcontinue;\n\t\t/*\n\t\t * If @name is present, compare the two names.  If @name is\n\t\t * missing, assume we want an unnamed attribute.\n\t\t */\n\t\tif (!name) {\n\t\t\t/* The search failed if the found attribute is named. */\n\t\t\tif (a->name_length)\n\t\t\t\treturn -ENOENT;\n\t\t} else if (!ntfs_are_names_equal(name, name_len,\n\t\t\t    (ntfschar*)((u8*)a + le16_to_cpu(a->name_offset)),\n\t\t\t    a->name_length, ic, upcase, upcase_len)) {\n\t\t\tregister int rc;\n\n\t\t\trc = ntfs_collate_names(name, name_len,\n\t\t\t\t\t(ntfschar*)((u8*)a +\n\t\t\t\t\tle16_to_cpu(a->name_offset)),\n\t\t\t\t\ta->name_length, 1, IGNORE_CASE,\n\t\t\t\t\tupcase, upcase_len);\n\t\t\t/*\n\t\t\t * If @name collates before a->name, there is no\n\t\t\t * matching attribute.\n\t\t\t */\n\t\t\tif (rc == -1)\n\t\t\t\treturn -ENOENT;\n\t\t\t/* If the strings are not equal, continue search. */\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t\trc = ntfs_collate_names(name, name_len,\n\t\t\t\t\t(ntfschar*)((u8*)a +\n\t\t\t\t\tle16_to_cpu(a->name_offset)),\n\t\t\t\t\ta->name_length, 1, CASE_SENSITIVE,\n\t\t\t\t\tupcase, upcase_len);\n\t\t\tif (rc == -1)\n\t\t\t\treturn -ENOENT;\n\t\t\tif (rc)\n\t\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * The names match or @name not present and attribute is\n\t\t * unnamed.  If no @val specified, we have found the attribute\n\t\t * and are done.\n\t\t */\n\t\tif (!val)\n\t\t\treturn 0;\n\t\t/* @val is present; compare values. */\n\t\telse {\n\t\t\tregister int rc;\n\n\t\t\trc = memcmp(val, (u8*)a + le16_to_cpu(\n\t\t\t\t\ta->data.resident.value_offset),\n\t\t\t\t\tmin_t(u32, val_len, le32_to_cpu(\n\t\t\t\t\ta->data.resident.value_length)));\n\t\t\t/*\n\t\t\t * If @val collates before the current attribute's\n\t\t\t * value, there is no matching attribute.\n\t\t\t */\n\t\t\tif (!rc) {\n\t\t\t\tregister u32 avl;\n\n\t\t\t\tavl = le32_to_cpu(\n\t\t\t\t\t\ta->data.resident.value_length);\n\t\t\t\tif (val_len == avl)\n\t\t\t\t\treturn 0;\n\t\t\t\tif (val_len < avl)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t} else if (rc < 0)\n\t\t\t\treturn -ENOENT;\n\t\t}\n\t}\n\tntfs_error(vol->sb, \"Inode is corrupt.  Run chkdsk.\");\n\tNVolSetErrors(vol);\n\treturn -EIO;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,11 +20,23 @@\n \tfor (;;\ta = (ATTR_RECORD*)((u8*)a + le32_to_cpu(a->length))) {\n \t\tu8 *mrec_end = (u8 *)ctx->mrec +\n \t\t               le32_to_cpu(ctx->mrec->bytes_allocated);\n-\t\tu8 *name_end = (u8 *)a + le16_to_cpu(a->name_offset) +\n-\t\t\t       a->name_length * sizeof(ntfschar);\n-\t\tif ((u8*)a < (u8*)ctx->mrec || (u8*)a > mrec_end ||\n-\t\t    name_end > mrec_end)\n+\t\tu8 *name_end;\n+\n+\t\t/* check whether ATTR_RECORD wrap */\n+\t\tif ((u8 *)a < (u8 *)ctx->mrec)\n \t\t\tbreak;\n+\n+\t\t/* check whether Attribute Record Header is within bounds */\n+\t\tif ((u8 *)a > mrec_end ||\n+\t\t    (u8 *)a + sizeof(ATTR_RECORD) > mrec_end)\n+\t\t\tbreak;\n+\n+\t\t/* check whether ATTR_RECORD's name is within bounds */\n+\t\tname_end = (u8 *)a + le16_to_cpu(a->name_offset) +\n+\t\t\t   a->name_length * sizeof(ntfschar);\n+\t\tif (name_end > mrec_end)\n+\t\t\tbreak;\n+\n \t\tctx->attr = a;\n \t\tif (unlikely(le32_to_cpu(a->type) > le32_to_cpu(type) ||\n \t\t\t\ta->type == AT_END))",
        "function_modified_lines": {
            "added": [
                "\t\tu8 *name_end;",
                "",
                "\t\t/* check whether ATTR_RECORD wrap */",
                "\t\tif ((u8 *)a < (u8 *)ctx->mrec)",
                "",
                "\t\t/* check whether Attribute Record Header is within bounds */",
                "\t\tif ((u8 *)a > mrec_end ||",
                "\t\t    (u8 *)a + sizeof(ATTR_RECORD) > mrec_end)",
                "\t\t\tbreak;",
                "",
                "\t\t/* check whether ATTR_RECORD's name is within bounds */",
                "\t\tname_end = (u8 *)a + le16_to_cpu(a->name_offset) +",
                "\t\t\t   a->name_length * sizeof(ntfschar);",
                "\t\tif (name_end > mrec_end)",
                "\t\t\tbreak;",
                ""
            ],
            "deleted": [
                "\t\tu8 *name_end = (u8 *)a + le16_to_cpu(a->name_offset) +",
                "\t\t\t       a->name_length * sizeof(ntfschar);",
                "\t\tif ((u8*)a < (u8*)ctx->mrec || (u8*)a > mrec_end ||",
                "\t\t    name_end > mrec_end)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In the Linux kernel 6.0.8, there is an out-of-bounds read in ntfs_attr_find in fs/ntfs/attrib.c.",
        "id": 3973
    },
    {
        "cve_id": "CVE-2021-45469",
        "code_before_change": "static int __f2fs_setxattr(struct inode *inode, int index,\n\t\t\tconst char *name, const void *value, size_t size,\n\t\t\tstruct page *ipage, int flags)\n{\n\tstruct f2fs_xattr_entry *here, *last;\n\tvoid *base_addr, *last_base_addr;\n\tint found, newsize;\n\tsize_t len;\n\t__u32 new_hsize;\n\tint error;\n\n\tif (name == NULL)\n\t\treturn -EINVAL;\n\n\tif (value == NULL)\n\t\tsize = 0;\n\n\tlen = strlen(name);\n\n\tif (len > F2FS_NAME_LEN)\n\t\treturn -ERANGE;\n\n\tif (size > MAX_VALUE_LEN(inode))\n\t\treturn -E2BIG;\n\n\terror = read_all_xattrs(inode, ipage, &base_addr);\n\tif (error)\n\t\treturn error;\n\n\tlast_base_addr = (void *)base_addr + XATTR_SIZE(inode);\n\n\t/* find entry with wanted name. */\n\there = __find_xattr(base_addr, last_base_addr, index, len, name);\n\tif (!here) {\n\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has corrupted xattr\",\n\t\t\t\t\t\t\t\tinode->i_ino);\n\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n\t\terror = -EFSCORRUPTED;\n\t\tgoto exit;\n\t}\n\n\tfound = IS_XATTR_LAST_ENTRY(here) ? 0 : 1;\n\n\tif (found) {\n\t\tif ((flags & XATTR_CREATE)) {\n\t\t\terror = -EEXIST;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (value && f2fs_xattr_value_same(here, value, size))\n\t\t\tgoto same;\n\t} else if ((flags & XATTR_REPLACE)) {\n\t\terror = -ENODATA;\n\t\tgoto exit;\n\t}\n\n\tlast = here;\n\twhile (!IS_XATTR_LAST_ENTRY(last))\n\t\tlast = XATTR_NEXT_ENTRY(last);\n\n\tnewsize = XATTR_ALIGN(sizeof(struct f2fs_xattr_entry) + len + size);\n\n\t/* 1. Check space */\n\tif (value) {\n\t\tint free;\n\t\t/*\n\t\t * If value is NULL, it is remove operation.\n\t\t * In case of update operation, we calculate free.\n\t\t */\n\t\tfree = MIN_OFFSET(inode) - ((char *)last - (char *)base_addr);\n\t\tif (found)\n\t\t\tfree = free + ENTRY_SIZE(here);\n\n\t\tif (unlikely(free < newsize)) {\n\t\t\terror = -E2BIG;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\t/* 2. Remove old entry */\n\tif (found) {\n\t\t/*\n\t\t * If entry is found, remove old entry.\n\t\t * If not found, remove operation is not needed.\n\t\t */\n\t\tstruct f2fs_xattr_entry *next = XATTR_NEXT_ENTRY(here);\n\t\tint oldsize = ENTRY_SIZE(here);\n\n\t\tmemmove(here, next, (char *)last - (char *)next);\n\t\tlast = (struct f2fs_xattr_entry *)((char *)last - oldsize);\n\t\tmemset(last, 0, oldsize);\n\t}\n\n\tnew_hsize = (char *)last - (char *)base_addr;\n\n\t/* 3. Write new entry */\n\tif (value) {\n\t\tchar *pval;\n\t\t/*\n\t\t * Before we come here, old entry is removed.\n\t\t * We just write new entry.\n\t\t */\n\t\tlast->e_name_index = index;\n\t\tlast->e_name_len = len;\n\t\tmemcpy(last->e_name, name, len);\n\t\tpval = last->e_name + len;\n\t\tmemcpy(pval, value, size);\n\t\tlast->e_value_size = cpu_to_le16(size);\n\t\tnew_hsize += newsize;\n\t}\n\n\terror = write_all_xattrs(inode, new_hsize, base_addr, ipage);\n\tif (error)\n\t\tgoto exit;\n\n\tif (index == F2FS_XATTR_INDEX_ENCRYPTION &&\n\t\t\t!strcmp(name, F2FS_XATTR_NAME_ENCRYPTION_CONTEXT))\n\t\tf2fs_set_encrypted_inode(inode);\n\tf2fs_mark_inode_dirty_sync(inode, true);\n\tif (!error && S_ISDIR(inode->i_mode))\n\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_CP);\n\nsame:\n\tif (is_inode_flag_set(inode, FI_ACL_MODE)) {\n\t\tinode->i_mode = F2FS_I(inode)->i_acl_mode;\n\t\tinode->i_ctime = current_time(inode);\n\t\tclear_inode_flag(inode, FI_ACL_MODE);\n\t}\n\nexit:\n\tkfree(base_addr);\n\treturn error;\n}",
        "code_after_change": "static int __f2fs_setxattr(struct inode *inode, int index,\n\t\t\tconst char *name, const void *value, size_t size,\n\t\t\tstruct page *ipage, int flags)\n{\n\tstruct f2fs_xattr_entry *here, *last;\n\tvoid *base_addr, *last_base_addr;\n\tint found, newsize;\n\tsize_t len;\n\t__u32 new_hsize;\n\tint error;\n\n\tif (name == NULL)\n\t\treturn -EINVAL;\n\n\tif (value == NULL)\n\t\tsize = 0;\n\n\tlen = strlen(name);\n\n\tif (len > F2FS_NAME_LEN)\n\t\treturn -ERANGE;\n\n\tif (size > MAX_VALUE_LEN(inode))\n\t\treturn -E2BIG;\n\n\terror = read_all_xattrs(inode, ipage, &base_addr);\n\tif (error)\n\t\treturn error;\n\n\tlast_base_addr = (void *)base_addr + XATTR_SIZE(inode);\n\n\t/* find entry with wanted name. */\n\there = __find_xattr(base_addr, last_base_addr, index, len, name);\n\tif (!here) {\n\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has corrupted xattr\",\n\t\t\t\t\t\t\t\tinode->i_ino);\n\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n\t\terror = -EFSCORRUPTED;\n\t\tgoto exit;\n\t}\n\n\tfound = IS_XATTR_LAST_ENTRY(here) ? 0 : 1;\n\n\tif (found) {\n\t\tif ((flags & XATTR_CREATE)) {\n\t\t\terror = -EEXIST;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (value && f2fs_xattr_value_same(here, value, size))\n\t\t\tgoto same;\n\t} else if ((flags & XATTR_REPLACE)) {\n\t\terror = -ENODATA;\n\t\tgoto exit;\n\t}\n\n\tlast = here;\n\twhile (!IS_XATTR_LAST_ENTRY(last)) {\n\t\tif ((void *)(last) + sizeof(__u32) > last_base_addr ||\n\t\t\t(void *)XATTR_NEXT_ENTRY(last) > last_base_addr) {\n\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has invalid last xattr entry, entry_size: %zu\",\n\t\t\t\t\tinode->i_ino, ENTRY_SIZE(last));\n\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n\t\t\terror = -EFSCORRUPTED;\n\t\t\tgoto exit;\n\t\t}\n\t\tlast = XATTR_NEXT_ENTRY(last);\n\t}\n\n\tnewsize = XATTR_ALIGN(sizeof(struct f2fs_xattr_entry) + len + size);\n\n\t/* 1. Check space */\n\tif (value) {\n\t\tint free;\n\t\t/*\n\t\t * If value is NULL, it is remove operation.\n\t\t * In case of update operation, we calculate free.\n\t\t */\n\t\tfree = MIN_OFFSET(inode) - ((char *)last - (char *)base_addr);\n\t\tif (found)\n\t\t\tfree = free + ENTRY_SIZE(here);\n\n\t\tif (unlikely(free < newsize)) {\n\t\t\terror = -E2BIG;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\t/* 2. Remove old entry */\n\tif (found) {\n\t\t/*\n\t\t * If entry is found, remove old entry.\n\t\t * If not found, remove operation is not needed.\n\t\t */\n\t\tstruct f2fs_xattr_entry *next = XATTR_NEXT_ENTRY(here);\n\t\tint oldsize = ENTRY_SIZE(here);\n\n\t\tmemmove(here, next, (char *)last - (char *)next);\n\t\tlast = (struct f2fs_xattr_entry *)((char *)last - oldsize);\n\t\tmemset(last, 0, oldsize);\n\t}\n\n\tnew_hsize = (char *)last - (char *)base_addr;\n\n\t/* 3. Write new entry */\n\tif (value) {\n\t\tchar *pval;\n\t\t/*\n\t\t * Before we come here, old entry is removed.\n\t\t * We just write new entry.\n\t\t */\n\t\tlast->e_name_index = index;\n\t\tlast->e_name_len = len;\n\t\tmemcpy(last->e_name, name, len);\n\t\tpval = last->e_name + len;\n\t\tmemcpy(pval, value, size);\n\t\tlast->e_value_size = cpu_to_le16(size);\n\t\tnew_hsize += newsize;\n\t}\n\n\terror = write_all_xattrs(inode, new_hsize, base_addr, ipage);\n\tif (error)\n\t\tgoto exit;\n\n\tif (index == F2FS_XATTR_INDEX_ENCRYPTION &&\n\t\t\t!strcmp(name, F2FS_XATTR_NAME_ENCRYPTION_CONTEXT))\n\t\tf2fs_set_encrypted_inode(inode);\n\tf2fs_mark_inode_dirty_sync(inode, true);\n\tif (!error && S_ISDIR(inode->i_mode))\n\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_CP);\n\nsame:\n\tif (is_inode_flag_set(inode, FI_ACL_MODE)) {\n\t\tinode->i_mode = F2FS_I(inode)->i_acl_mode;\n\t\tinode->i_ctime = current_time(inode);\n\t\tclear_inode_flag(inode, FI_ACL_MODE);\n\t}\n\nexit:\n\tkfree(base_addr);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -55,8 +55,17 @@\n \t}\n \n \tlast = here;\n-\twhile (!IS_XATTR_LAST_ENTRY(last))\n+\twhile (!IS_XATTR_LAST_ENTRY(last)) {\n+\t\tif ((void *)(last) + sizeof(__u32) > last_base_addr ||\n+\t\t\t(void *)XATTR_NEXT_ENTRY(last) > last_base_addr) {\n+\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has invalid last xattr entry, entry_size: %zu\",\n+\t\t\t\t\tinode->i_ino, ENTRY_SIZE(last));\n+\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);\n+\t\t\terror = -EFSCORRUPTED;\n+\t\t\tgoto exit;\n+\t\t}\n \t\tlast = XATTR_NEXT_ENTRY(last);\n+\t}\n \n \tnewsize = XATTR_ALIGN(sizeof(struct f2fs_xattr_entry) + len + size);\n ",
        "function_modified_lines": {
            "added": [
                "\twhile (!IS_XATTR_LAST_ENTRY(last)) {",
                "\t\tif ((void *)(last) + sizeof(__u32) > last_base_addr ||",
                "\t\t\t(void *)XATTR_NEXT_ENTRY(last) > last_base_addr) {",
                "\t\t\tf2fs_err(F2FS_I_SB(inode), \"inode (%lu) has invalid last xattr entry, entry_size: %zu\",",
                "\t\t\t\t\tinode->i_ino, ENTRY_SIZE(last));",
                "\t\t\tset_sbi_flag(F2FS_I_SB(inode), SBI_NEED_FSCK);",
                "\t\t\terror = -EFSCORRUPTED;",
                "\t\t\tgoto exit;",
                "\t\t}",
                "\t}"
            ],
            "deleted": [
                "\twhile (!IS_XATTR_LAST_ENTRY(last))"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In __f2fs_setxattr in fs/f2fs/xattr.c in the Linux kernel through 5.15.11, there is an out-of-bounds memory access when an inode has an invalid last xattr entry.",
        "id": 3178
    },
    {
        "cve_id": "CVE-2017-16529",
        "code_before_change": "static int snd_usb_create_streams(struct snd_usb_audio *chip, int ctrlif)\n{\n\tstruct usb_device *dev = chip->dev;\n\tstruct usb_host_interface *host_iface;\n\tstruct usb_interface_descriptor *altsd;\n\tvoid *control_header;\n\tint i, protocol;\n\n\t/* find audiocontrol interface */\n\thost_iface = &usb_ifnum_to_if(dev, ctrlif)->altsetting[0];\n\tcontrol_header = snd_usb_find_csint_desc(host_iface->extra,\n\t\t\t\t\t\t host_iface->extralen,\n\t\t\t\t\t\t NULL, UAC_HEADER);\n\taltsd = get_iface_desc(host_iface);\n\tprotocol = altsd->bInterfaceProtocol;\n\n\tif (!control_header) {\n\t\tdev_err(&dev->dev, \"cannot find UAC_HEADER\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (protocol) {\n\tdefault:\n\t\tdev_warn(&dev->dev,\n\t\t\t \"unknown interface protocol %#02x, assuming v1\\n\",\n\t\t\t protocol);\n\t\t/* fall through */\n\n\tcase UAC_VERSION_1: {\n\t\tstruct uac1_ac_header_descriptor *h1 = control_header;\n\n\t\tif (!h1->bInCollection) {\n\t\t\tdev_info(&dev->dev, \"skipping empty audio interface (v1)\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (h1->bLength < sizeof(*h1) + h1->bInCollection) {\n\t\t\tdev_err(&dev->dev, \"invalid UAC_HEADER (v1)\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfor (i = 0; i < h1->bInCollection; i++)\n\t\t\tsnd_usb_create_stream(chip, ctrlif, h1->baInterfaceNr[i]);\n\n\t\tbreak;\n\t}\n\n\tcase UAC_VERSION_2: {\n\t\tstruct usb_interface_assoc_descriptor *assoc =\n\t\t\tusb_ifnum_to_if(dev, ctrlif)->intf_assoc;\n\n\t\tif (!assoc) {\n\t\t\t/*\n\t\t\t * Firmware writers cannot count to three.  So to find\n\t\t\t * the IAD on the NuForce UDH-100, also check the next\n\t\t\t * interface.\n\t\t\t */\n\t\t\tstruct usb_interface *iface =\n\t\t\t\tusb_ifnum_to_if(dev, ctrlif + 1);\n\t\t\tif (iface &&\n\t\t\t    iface->intf_assoc &&\n\t\t\t    iface->intf_assoc->bFunctionClass == USB_CLASS_AUDIO &&\n\t\t\t    iface->intf_assoc->bFunctionProtocol == UAC_VERSION_2)\n\t\t\t\tassoc = iface->intf_assoc;\n\t\t}\n\n\t\tif (!assoc) {\n\t\t\tdev_err(&dev->dev, \"Audio class v2 interfaces need an interface association\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfor (i = 0; i < assoc->bInterfaceCount; i++) {\n\t\t\tint intf = assoc->bFirstInterface + i;\n\n\t\t\tif (intf != ctrlif)\n\t\t\t\tsnd_usb_create_stream(chip, ctrlif, intf);\n\t\t}\n\n\t\tbreak;\n\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int snd_usb_create_streams(struct snd_usb_audio *chip, int ctrlif)\n{\n\tstruct usb_device *dev = chip->dev;\n\tstruct usb_host_interface *host_iface;\n\tstruct usb_interface_descriptor *altsd;\n\tvoid *control_header;\n\tint i, protocol;\n\tint rest_bytes;\n\n\t/* find audiocontrol interface */\n\thost_iface = &usb_ifnum_to_if(dev, ctrlif)->altsetting[0];\n\tcontrol_header = snd_usb_find_csint_desc(host_iface->extra,\n\t\t\t\t\t\t host_iface->extralen,\n\t\t\t\t\t\t NULL, UAC_HEADER);\n\taltsd = get_iface_desc(host_iface);\n\tprotocol = altsd->bInterfaceProtocol;\n\n\tif (!control_header) {\n\t\tdev_err(&dev->dev, \"cannot find UAC_HEADER\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\trest_bytes = (void *)(host_iface->extra + host_iface->extralen) -\n\t\tcontrol_header;\n\n\t/* just to be sure -- this shouldn't hit at all */\n\tif (rest_bytes <= 0) {\n\t\tdev_err(&dev->dev, \"invalid control header\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (protocol) {\n\tdefault:\n\t\tdev_warn(&dev->dev,\n\t\t\t \"unknown interface protocol %#02x, assuming v1\\n\",\n\t\t\t protocol);\n\t\t/* fall through */\n\n\tcase UAC_VERSION_1: {\n\t\tstruct uac1_ac_header_descriptor *h1 = control_header;\n\n\t\tif (rest_bytes < sizeof(*h1)) {\n\t\t\tdev_err(&dev->dev, \"too short v1 buffer descriptor\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!h1->bInCollection) {\n\t\t\tdev_info(&dev->dev, \"skipping empty audio interface (v1)\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (rest_bytes < h1->bLength) {\n\t\t\tdev_err(&dev->dev, \"invalid buffer length (v1)\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (h1->bLength < sizeof(*h1) + h1->bInCollection) {\n\t\t\tdev_err(&dev->dev, \"invalid UAC_HEADER (v1)\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfor (i = 0; i < h1->bInCollection; i++)\n\t\t\tsnd_usb_create_stream(chip, ctrlif, h1->baInterfaceNr[i]);\n\n\t\tbreak;\n\t}\n\n\tcase UAC_VERSION_2: {\n\t\tstruct usb_interface_assoc_descriptor *assoc =\n\t\t\tusb_ifnum_to_if(dev, ctrlif)->intf_assoc;\n\n\t\tif (!assoc) {\n\t\t\t/*\n\t\t\t * Firmware writers cannot count to three.  So to find\n\t\t\t * the IAD on the NuForce UDH-100, also check the next\n\t\t\t * interface.\n\t\t\t */\n\t\t\tstruct usb_interface *iface =\n\t\t\t\tusb_ifnum_to_if(dev, ctrlif + 1);\n\t\t\tif (iface &&\n\t\t\t    iface->intf_assoc &&\n\t\t\t    iface->intf_assoc->bFunctionClass == USB_CLASS_AUDIO &&\n\t\t\t    iface->intf_assoc->bFunctionProtocol == UAC_VERSION_2)\n\t\t\t\tassoc = iface->intf_assoc;\n\t\t}\n\n\t\tif (!assoc) {\n\t\t\tdev_err(&dev->dev, \"Audio class v2 interfaces need an interface association\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tfor (i = 0; i < assoc->bInterfaceCount; i++) {\n\t\t\tint intf = assoc->bFirstInterface + i;\n\n\t\t\tif (intf != ctrlif)\n\t\t\t\tsnd_usb_create_stream(chip, ctrlif, intf);\n\t\t}\n\n\t\tbreak;\n\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tstruct usb_interface_descriptor *altsd;\n \tvoid *control_header;\n \tint i, protocol;\n+\tint rest_bytes;\n \n \t/* find audiocontrol interface */\n \thost_iface = &usb_ifnum_to_if(dev, ctrlif)->altsetting[0];\n@@ -19,6 +20,15 @@\n \t\treturn -EINVAL;\n \t}\n \n+\trest_bytes = (void *)(host_iface->extra + host_iface->extralen) -\n+\t\tcontrol_header;\n+\n+\t/* just to be sure -- this shouldn't hit at all */\n+\tif (rest_bytes <= 0) {\n+\t\tdev_err(&dev->dev, \"invalid control header\\n\");\n+\t\treturn -EINVAL;\n+\t}\n+\n \tswitch (protocol) {\n \tdefault:\n \t\tdev_warn(&dev->dev,\n@@ -29,8 +39,18 @@\n \tcase UAC_VERSION_1: {\n \t\tstruct uac1_ac_header_descriptor *h1 = control_header;\n \n+\t\tif (rest_bytes < sizeof(*h1)) {\n+\t\t\tdev_err(&dev->dev, \"too short v1 buffer descriptor\\n\");\n+\t\t\treturn -EINVAL;\n+\t\t}\n+\n \t\tif (!h1->bInCollection) {\n \t\t\tdev_info(&dev->dev, \"skipping empty audio interface (v1)\\n\");\n+\t\t\treturn -EINVAL;\n+\t\t}\n+\n+\t\tif (rest_bytes < h1->bLength) {\n+\t\t\tdev_err(&dev->dev, \"invalid buffer length (v1)\\n\");\n \t\t\treturn -EINVAL;\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\tint rest_bytes;",
                "\trest_bytes = (void *)(host_iface->extra + host_iface->extralen) -",
                "\t\tcontrol_header;",
                "",
                "\t/* just to be sure -- this shouldn't hit at all */",
                "\tif (rest_bytes <= 0) {",
                "\t\tdev_err(&dev->dev, \"invalid control header\\n\");",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\t\tif (rest_bytes < sizeof(*h1)) {",
                "\t\t\tdev_err(&dev->dev, \"too short v1 buffer descriptor\\n\");",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                "",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                "",
                "\t\tif (rest_bytes < h1->bLength) {",
                "\t\t\tdev_err(&dev->dev, \"invalid buffer length (v1)\\n\");"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The snd_usb_create_streams function in sound/usb/card.c in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1315
    },
    {
        "cve_id": "CVE-2022-47943",
        "code_before_change": "int smb2_write(struct ksmbd_work *work)\n{\n\tstruct smb2_write_req *req;\n\tstruct smb2_write_rsp *rsp;\n\tstruct ksmbd_file *fp = NULL;\n\tloff_t offset;\n\tsize_t length;\n\tssize_t nbytes;\n\tchar *data_buf;\n\tbool writethrough = false, is_rdma_channel = false;\n\tint err = 0;\n\tunsigned int max_write_size = work->conn->vals->max_write_size;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe write request\\n\");\n\t\treturn smb2_write_pipe(work);\n\t}\n\n\toffset = le64_to_cpu(req->Offset);\n\tlength = le32_to_cpu(req->Length);\n\n\tif (req->Channel == SMB2_CHANNEL_RDMA_V1 ||\n\t    req->Channel == SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tis_rdma_channel = true;\n\t\tmax_write_size = get_smbd_max_read_write_size();\n\t\tlength = le32_to_cpu(req->RemainingBytes);\n\t}\n\n\tif (is_rdma_channel == true) {\n\t\tunsigned int ch_offset = le16_to_cpu(req->WriteChannelInfoOffset);\n\n\t\tif (req->Length != 0 || req->DataOffset != 0 ||\n\t\t    ch_offset < offsetof(struct smb2_write_req, Buffer)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\terr = smb2_set_remote_key_for_rdma(work,\n\t\t\t\t\t\t   (struct smb2_buffer_desc_v1 *)\n\t\t\t\t\t\t   ((char *)req + ch_offset),\n\t\t\t\t\t\t   req->Channel,\n\t\t\t\t\t\t   req->WriteChannelInfoLength);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tif (!test_tree_conn_flag(work->tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tksmbd_debug(SMB, \"User does not have write permission\\n\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, req->VolatileFileId, req->PersistentFileId);\n\tif (!fp) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!(fp->daccess & (FILE_WRITE_DATA_LE | FILE_READ_ATTRIBUTES_LE))) {\n\t\tpr_err(\"Not permitted to write : 0x%x\\n\", fp->daccess);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (length > max_write_size) {\n\t\tksmbd_debug(SMB, \"limiting write size to max size(%u)\\n\",\n\t\t\t    max_write_size);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tksmbd_debug(SMB, \"flags %u\\n\", le32_to_cpu(req->Flags));\n\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\twritethrough = true;\n\n\tif (is_rdma_channel == false) {\n\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n\t\t    get_rfc1002_len(work->request_buf)) {\n\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n\t\t\t       le16_to_cpu(req->DataOffset),\n\t\t\t       get_rfc1002_len(work->request_buf));\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n\t\t\t\t    le16_to_cpu(req->DataOffset));\n\n\t\tksmbd_debug(SMB, \"filename %pd, offset %lld, len %zu\\n\",\n\t\t\t    fp->filp->f_path.dentry, offset, length);\n\t\terr = ksmbd_vfs_write(work, fp, data_buf, length, &offset,\n\t\t\t\t      writethrough, &nbytes);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t} else {\n\t\t/* read data from the client using rdma channel, and\n\t\t * write the data.\n\t\t */\n\t\tnbytes = smb2_write_rdma_channel(work, req, fp, offset, length,\n\t\t\t\t\t\t writethrough);\n\t\tif (nbytes < 0) {\n\t\t\terr = (int)nbytes;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trsp->StructureSize = cpu_to_le16(17);\n\trsp->DataOffset = 0;\n\trsp->Reserved = 0;\n\trsp->DataLength = cpu_to_le32(nbytes);\n\trsp->DataRemaining = 0;\n\trsp->Reserved2 = 0;\n\tinc_rfc1001_len(work->response_buf, 16);\n\tksmbd_fd_put(work, fp);\n\treturn 0;\n\nout:\n\tif (err == -EAGAIN)\n\t\trsp->hdr.Status = STATUS_FILE_LOCK_CONFLICT;\n\telse if (err == -ENOSPC || err == -EFBIG)\n\t\trsp->hdr.Status = STATUS_DISK_FULL;\n\telse if (err == -ENOENT)\n\t\trsp->hdr.Status = STATUS_FILE_CLOSED;\n\telse if (err == -EACCES)\n\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\telse if (err == -ESHARE)\n\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\telse if (err == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse\n\t\trsp->hdr.Status = STATUS_INVALID_HANDLE;\n\n\tsmb2_set_err_rsp(work);\n\tksmbd_fd_put(work, fp);\n\treturn err;\n}",
        "code_after_change": "int smb2_write(struct ksmbd_work *work)\n{\n\tstruct smb2_write_req *req;\n\tstruct smb2_write_rsp *rsp;\n\tstruct ksmbd_file *fp = NULL;\n\tloff_t offset;\n\tsize_t length;\n\tssize_t nbytes;\n\tchar *data_buf;\n\tbool writethrough = false, is_rdma_channel = false;\n\tint err = 0;\n\tunsigned int max_write_size = work->conn->vals->max_write_size;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe write request\\n\");\n\t\treturn smb2_write_pipe(work);\n\t}\n\n\toffset = le64_to_cpu(req->Offset);\n\tlength = le32_to_cpu(req->Length);\n\n\tif (req->Channel == SMB2_CHANNEL_RDMA_V1 ||\n\t    req->Channel == SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tis_rdma_channel = true;\n\t\tmax_write_size = get_smbd_max_read_write_size();\n\t\tlength = le32_to_cpu(req->RemainingBytes);\n\t}\n\n\tif (is_rdma_channel == true) {\n\t\tunsigned int ch_offset = le16_to_cpu(req->WriteChannelInfoOffset);\n\n\t\tif (req->Length != 0 || req->DataOffset != 0 ||\n\t\t    ch_offset < offsetof(struct smb2_write_req, Buffer)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\terr = smb2_set_remote_key_for_rdma(work,\n\t\t\t\t\t\t   (struct smb2_buffer_desc_v1 *)\n\t\t\t\t\t\t   ((char *)req + ch_offset),\n\t\t\t\t\t\t   req->Channel,\n\t\t\t\t\t\t   req->WriteChannelInfoLength);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tif (!test_tree_conn_flag(work->tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tksmbd_debug(SMB, \"User does not have write permission\\n\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, req->VolatileFileId, req->PersistentFileId);\n\tif (!fp) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!(fp->daccess & (FILE_WRITE_DATA_LE | FILE_READ_ATTRIBUTES_LE))) {\n\t\tpr_err(\"Not permitted to write : 0x%x\\n\", fp->daccess);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (length > max_write_size) {\n\t\tksmbd_debug(SMB, \"limiting write size to max size(%u)\\n\",\n\t\t\t    max_write_size);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tksmbd_debug(SMB, \"flags %u\\n\", le32_to_cpu(req->Flags));\n\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\twritethrough = true;\n\n\tif (is_rdma_channel == false) {\n\t\tif (le16_to_cpu(req->DataOffset) <\n\t\t    offsetof(struct smb2_write_req, Buffer)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n\t\t\t\t    le16_to_cpu(req->DataOffset));\n\n\t\tksmbd_debug(SMB, \"filename %pd, offset %lld, len %zu\\n\",\n\t\t\t    fp->filp->f_path.dentry, offset, length);\n\t\terr = ksmbd_vfs_write(work, fp, data_buf, length, &offset,\n\t\t\t\t      writethrough, &nbytes);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t} else {\n\t\t/* read data from the client using rdma channel, and\n\t\t * write the data.\n\t\t */\n\t\tnbytes = smb2_write_rdma_channel(work, req, fp, offset, length,\n\t\t\t\t\t\t writethrough);\n\t\tif (nbytes < 0) {\n\t\t\terr = (int)nbytes;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trsp->StructureSize = cpu_to_le16(17);\n\trsp->DataOffset = 0;\n\trsp->Reserved = 0;\n\trsp->DataLength = cpu_to_le32(nbytes);\n\trsp->DataRemaining = 0;\n\trsp->Reserved2 = 0;\n\tinc_rfc1001_len(work->response_buf, 16);\n\tksmbd_fd_put(work, fp);\n\treturn 0;\n\nout:\n\tif (err == -EAGAIN)\n\t\trsp->hdr.Status = STATUS_FILE_LOCK_CONFLICT;\n\telse if (err == -ENOSPC || err == -EFBIG)\n\t\trsp->hdr.Status = STATUS_DISK_FULL;\n\telse if (err == -ENOENT)\n\t\trsp->hdr.Status = STATUS_FILE_CLOSED;\n\telse if (err == -EACCES)\n\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\telse if (err == -ESHARE)\n\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\telse if (err == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse\n\t\trsp->hdr.Status = STATUS_INVALID_HANDLE;\n\n\tsmb2_set_err_rsp(work);\n\tksmbd_fd_put(work, fp);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -75,14 +75,12 @@\n \t\twritethrough = true;\n \n \tif (is_rdma_channel == false) {\n-\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n-\t\t    get_rfc1002_len(work->request_buf)) {\n-\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n-\t\t\t       le16_to_cpu(req->DataOffset),\n-\t\t\t       get_rfc1002_len(work->request_buf));\n+\t\tif (le16_to_cpu(req->DataOffset) <\n+\t\t    offsetof(struct smb2_write_req, Buffer)) {\n \t\t\terr = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n+\n \t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n \t\t\t\t    le16_to_cpu(req->DataOffset));\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (le16_to_cpu(req->DataOffset) <",
                "\t\t    offsetof(struct smb2_write_req, Buffer)) {",
                ""
            ],
            "deleted": [
                "\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >",
                "\t\t    get_rfc1002_len(work->request_buf)) {",
                "\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",",
                "\t\t\t       le16_to_cpu(req->DataOffset),",
                "\t\t\t       get_rfc1002_len(work->request_buf));"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.19 before 5.19.2. There is an out-of-bounds read and OOPS for SMB2_WRITE, when there is a large length in the zero DataOffset case.",
        "id": 3777
    },
    {
        "cve_id": "CVE-2017-16533",
        "code_before_change": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tfor (n = 0; n < hdesc->bNumDescriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}",
        "code_after_change": "static int usbhid_parse(struct hid_device *hid)\n{\n\tstruct usb_interface *intf = to_usb_interface(hid->dev.parent);\n\tstruct usb_host_interface *interface = intf->cur_altsetting;\n\tstruct usb_device *dev = interface_to_usbdev (intf);\n\tstruct hid_descriptor *hdesc;\n\tu32 quirks = 0;\n\tunsigned int rsize = 0;\n\tchar *rdesc;\n\tint ret, n;\n\tint num_descriptors;\n\tsize_t offset = offsetof(struct hid_descriptor, desc);\n\n\tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n\t\t\tle16_to_cpu(dev->descriptor.idProduct));\n\n\tif (quirks & HID_QUIRK_IGNORE)\n\t\treturn -ENODEV;\n\n\t/* Many keyboards and mice don't like to be polled for reports,\n\t * so we will always set the HID_QUIRK_NOGET flag for them. */\n\tif (interface->desc.bInterfaceSubClass == USB_INTERFACE_SUBCLASS_BOOT) {\n\t\tif (interface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_KEYBOARD ||\n\t\t\tinterface->desc.bInterfaceProtocol == USB_INTERFACE_PROTOCOL_MOUSE)\n\t\t\t\tquirks |= HID_QUIRK_NOGET;\n\t}\n\n\tif (usb_get_extra_descriptor(interface, HID_DT_HID, &hdesc) &&\n\t    (!interface->desc.bNumEndpoints ||\n\t     usb_get_extra_descriptor(&interface->endpoint[0], HID_DT_HID, &hdesc))) {\n\t\tdbg_hid(\"class descriptor not present\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (hdesc->bLength < sizeof(struct hid_descriptor)) {\n\t\tdbg_hid(\"hid descriptor is too short\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\thid->version = le16_to_cpu(hdesc->bcdHID);\n\thid->country = hdesc->bCountryCode;\n\n\tnum_descriptors = min_t(int, hdesc->bNumDescriptors,\n\t       (hdesc->bLength - offset) / sizeof(struct hid_class_descriptor));\n\n\tfor (n = 0; n < num_descriptors; n++)\n\t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n\t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n\n\tif (!rsize || rsize > HID_MAX_DESCRIPTOR_SIZE) {\n\t\tdbg_hid(\"weird size of report descriptor (%u)\\n\", rsize);\n\t\treturn -EINVAL;\n\t}\n\n\trdesc = kmalloc(rsize, GFP_KERNEL);\n\tif (!rdesc)\n\t\treturn -ENOMEM;\n\n\thid_set_idle(dev, interface->desc.bInterfaceNumber, 0, 0);\n\n\tret = hid_get_class_descriptor(dev, interface->desc.bInterfaceNumber,\n\t\t\tHID_DT_REPORT, rdesc, rsize);\n\tif (ret < 0) {\n\t\tdbg_hid(\"reading report descriptor failed\\n\");\n\t\tkfree(rdesc);\n\t\tgoto err;\n\t}\n\n\tret = hid_parse_report(hid, rdesc, rsize);\n\tkfree(rdesc);\n\tif (ret) {\n\t\tdbg_hid(\"parsing report descriptor failed\\n\");\n\t\tgoto err;\n\t}\n\n\thid->quirks |= quirks;\n\n\treturn 0;\nerr:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,8 @@\n \tunsigned int rsize = 0;\n \tchar *rdesc;\n \tint ret, n;\n+\tint num_descriptors;\n+\tsize_t offset = offsetof(struct hid_descriptor, desc);\n \n \tquirks = usbhid_lookup_quirk(le16_to_cpu(dev->descriptor.idVendor),\n \t\t\tle16_to_cpu(dev->descriptor.idProduct));\n@@ -30,10 +32,18 @@\n \t\treturn -ENODEV;\n \t}\n \n+\tif (hdesc->bLength < sizeof(struct hid_descriptor)) {\n+\t\tdbg_hid(\"hid descriptor is too short\\n\");\n+\t\treturn -EINVAL;\n+\t}\n+\n \thid->version = le16_to_cpu(hdesc->bcdHID);\n \thid->country = hdesc->bCountryCode;\n \n-\tfor (n = 0; n < hdesc->bNumDescriptors; n++)\n+\tnum_descriptors = min_t(int, hdesc->bNumDescriptors,\n+\t       (hdesc->bLength - offset) / sizeof(struct hid_class_descriptor));\n+\n+\tfor (n = 0; n < num_descriptors; n++)\n \t\tif (hdesc->desc[n].bDescriptorType == HID_DT_REPORT)\n \t\t\trsize = le16_to_cpu(hdesc->desc[n].wDescriptorLength);\n ",
        "function_modified_lines": {
            "added": [
                "\tint num_descriptors;",
                "\tsize_t offset = offsetof(struct hid_descriptor, desc);",
                "\tif (hdesc->bLength < sizeof(struct hid_descriptor)) {",
                "\t\tdbg_hid(\"hid descriptor is too short\\n\");",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\tnum_descriptors = min_t(int, hdesc->bNumDescriptors,",
                "\t       (hdesc->bLength - offset) / sizeof(struct hid_class_descriptor));",
                "",
                "\tfor (n = 0; n < num_descriptors; n++)"
            ],
            "deleted": [
                "\tfor (n = 0; n < hdesc->bNumDescriptors; n++)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The usbhid_parse function in drivers/hid/usbhid/hid-core.c in the Linux kernel before 4.13.8 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1320
    },
    {
        "cve_id": "CVE-2017-18344",
        "code_before_change": "int common_timer_set(struct k_itimer *timr, int flags,\n\t\t     struct itimerspec64 *new_setting,\n\t\t     struct itimerspec64 *old_setting)\n{\n\tconst struct k_clock *kc = timr->kclock;\n\tbool sigev_none;\n\tktime_t expires;\n\n\tif (old_setting)\n\t\tcommon_timer_get(timr, old_setting);\n\n\t/* Prevent rearming by clearing the interval */\n\ttimr->it_interval = 0;\n\t/*\n\t * Careful here. On SMP systems the timer expiry function could be\n\t * active and spinning on timr->it_lock.\n\t */\n\tif (kc->timer_try_to_cancel(timr) < 0)\n\t\treturn TIMER_RETRY;\n\n\ttimr->it_active = 0;\n\ttimr->it_requeue_pending = (timr->it_requeue_pending + 2) &\n\t\t~REQUEUE_PENDING;\n\ttimr->it_overrun_last = 0;\n\n\t/* Switch off the timer when it_value is zero */\n\tif (!new_setting->it_value.tv_sec && !new_setting->it_value.tv_nsec)\n\t\treturn 0;\n\n\ttimr->it_interval = timespec64_to_ktime(new_setting->it_interval);\n\texpires = timespec64_to_ktime(new_setting->it_value);\n\tsigev_none = (timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE;\n\n\tkc->timer_arm(timr, expires, flags & TIMER_ABSTIME, sigev_none);\n\ttimr->it_active = !sigev_none;\n\treturn 0;\n}",
        "code_after_change": "int common_timer_set(struct k_itimer *timr, int flags,\n\t\t     struct itimerspec64 *new_setting,\n\t\t     struct itimerspec64 *old_setting)\n{\n\tconst struct k_clock *kc = timr->kclock;\n\tbool sigev_none;\n\tktime_t expires;\n\n\tif (old_setting)\n\t\tcommon_timer_get(timr, old_setting);\n\n\t/* Prevent rearming by clearing the interval */\n\ttimr->it_interval = 0;\n\t/*\n\t * Careful here. On SMP systems the timer expiry function could be\n\t * active and spinning on timr->it_lock.\n\t */\n\tif (kc->timer_try_to_cancel(timr) < 0)\n\t\treturn TIMER_RETRY;\n\n\ttimr->it_active = 0;\n\ttimr->it_requeue_pending = (timr->it_requeue_pending + 2) &\n\t\t~REQUEUE_PENDING;\n\ttimr->it_overrun_last = 0;\n\n\t/* Switch off the timer when it_value is zero */\n\tif (!new_setting->it_value.tv_sec && !new_setting->it_value.tv_nsec)\n\t\treturn 0;\n\n\ttimr->it_interval = timespec64_to_ktime(new_setting->it_interval);\n\texpires = timespec64_to_ktime(new_setting->it_value);\n\tsigev_none = timr->it_sigev_notify == SIGEV_NONE;\n\n\tkc->timer_arm(timr, expires, flags & TIMER_ABSTIME, sigev_none);\n\ttimr->it_active = !sigev_none;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,7 +29,7 @@\n \n \ttimr->it_interval = timespec64_to_ktime(new_setting->it_interval);\n \texpires = timespec64_to_ktime(new_setting->it_value);\n-\tsigev_none = (timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE;\n+\tsigev_none = timr->it_sigev_notify == SIGEV_NONE;\n \n \tkc->timer_arm(timr, expires, flags & TIMER_ABSTIME, sigev_none);\n \ttimr->it_active = !sigev_none;",
        "function_modified_lines": {
            "added": [
                "\tsigev_none = timr->it_sigev_notify == SIGEV_NONE;"
            ],
            "deleted": [
                "\tsigev_none = (timr->it_sigev_notify & ~SIGEV_THREAD_ID) == SIGEV_NONE;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The timer_create syscall implementation in kernel/time/posix-timers.c in the Linux kernel before 4.14.8 doesn't properly validate the sigevent->sigev_notify field, which leads to out-of-bounds access in the show_timer function (called when /proc/$PID/timers is read). This allows userspace applications to read arbitrary kernel memory (on a kernel built with CONFIG_POSIX_TIMERS and CONFIG_CHECKPOINT_RESTORE).",
        "id": 1432
    },
    {
        "cve_id": "CVE-2018-13098",
        "code_before_change": "struct inode *f2fs_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\tint ret = 0;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!(inode->i_state & I_NEW)) {\n\t\ttrace_f2fs_iget(inode);\n\t\treturn inode;\n\t}\n\tif (ino == F2FS_NODE_INO(sbi) || ino == F2FS_META_INO(sbi))\n\t\tgoto make_now;\n\n\tret = do_read_inode(inode);\n\tif (ret)\n\t\tgoto bad_inode;\n\tif (!sanity_check_inode(inode)) {\n\t\tret = -EINVAL;\n\t\tgoto bad_inode;\n\t}\nmake_now:\n\tif (ino == F2FS_NODE_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_node_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_META_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_meta_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_file_inode_operations;\n\t\tinode->i_fop = &f2fs_file_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_dir_inode_operations;\n\t\tinode->i_fop = &f2fs_dir_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (f2fs_encrypted_inode(inode))\n\t\t\tinode->i_op = &f2fs_encrypted_symlink_inode_operations;\n\t\telse\n\t\t\tinode->i_op = &f2fs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\t} else {\n\t\tret = -EIO;\n\t\tgoto bad_inode;\n\t}\n\tf2fs_set_inode_flags(inode);\n\tunlock_new_inode(inode);\n\ttrace_f2fs_iget(inode);\n\treturn inode;\n\nbad_inode:\n\tiget_failed(inode);\n\ttrace_f2fs_iget_exit(inode, ret);\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "struct inode *f2fs_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\tint ret = 0;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!(inode->i_state & I_NEW)) {\n\t\ttrace_f2fs_iget(inode);\n\t\treturn inode;\n\t}\n\tif (ino == F2FS_NODE_INO(sbi) || ino == F2FS_META_INO(sbi))\n\t\tgoto make_now;\n\n\tret = do_read_inode(inode);\n\tif (ret)\n\t\tgoto bad_inode;\nmake_now:\n\tif (ino == F2FS_NODE_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_node_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_META_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_meta_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_file_inode_operations;\n\t\tinode->i_fop = &f2fs_file_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_dir_inode_operations;\n\t\tinode->i_fop = &f2fs_dir_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (f2fs_encrypted_inode(inode))\n\t\t\tinode->i_op = &f2fs_encrypted_symlink_inode_operations;\n\t\telse\n\t\t\tinode->i_op = &f2fs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\t} else {\n\t\tret = -EIO;\n\t\tgoto bad_inode;\n\t}\n\tf2fs_set_inode_flags(inode);\n\tunlock_new_inode(inode);\n\ttrace_f2fs_iget(inode);\n\treturn inode;\n\nbad_inode:\n\tiget_failed(inode);\n\ttrace_f2fs_iget_exit(inode, ret);\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,10 +18,6 @@\n \tret = do_read_inode(inode);\n \tif (ret)\n \t\tgoto bad_inode;\n-\tif (!sanity_check_inode(inode)) {\n-\t\tret = -EINVAL;\n-\t\tgoto bad_inode;\n-\t}\n make_now:\n \tif (ino == F2FS_NODE_INO(sbi)) {\n \t\tinode->i_mapping->a_ops = &f2fs_node_aops;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (!sanity_check_inode(inode)) {",
                "\t\tret = -EINVAL;",
                "\t\tgoto bad_inode;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inode.c in the Linux kernel through 4.17.3. A denial of service (slab out-of-bounds read and BUG) can occur for a modified f2fs filesystem image in which FI_EXTRA_ATTR is set in an inode.",
        "id": 1672
    },
    {
        "cve_id": "CVE-2023-2176",
        "code_before_change": "static int resolve_prepare_src(struct rdma_id_private *id_priv,\n\t\t\t       struct sockaddr *src_addr,\n\t\t\t       const struct sockaddr *dst_addr)\n{\n\tint ret;\n\n\tmemcpy(cma_dst_addr(id_priv), dst_addr, rdma_addr_size(dst_addr));\n\tif (!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_ADDR_QUERY)) {\n\t\t/* For a well behaved ULP state will be RDMA_CM_IDLE */\n\t\tret = cma_bind_addr(&id_priv->id, src_addr, dst_addr);\n\t\tif (ret)\n\t\t\tgoto err_dst;\n\t\tif (WARN_ON(!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND,\n\t\t\t\t\t   RDMA_CM_ADDR_QUERY))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_dst;\n\t\t}\n\t}\n\n\tif (cma_family(id_priv) != dst_addr->sa_family) {\n\t\tret = -EINVAL;\n\t\tgoto err_state;\n\t}\n\treturn 0;\n\nerr_state:\n\tcma_comp_exch(id_priv, RDMA_CM_ADDR_QUERY, RDMA_CM_ADDR_BOUND);\nerr_dst:\n\tmemset(cma_dst_addr(id_priv), 0, rdma_addr_size(dst_addr));\n\treturn ret;\n}",
        "code_after_change": "static int resolve_prepare_src(struct rdma_id_private *id_priv,\n\t\t\t       struct sockaddr *src_addr,\n\t\t\t       const struct sockaddr *dst_addr)\n{\n\tint ret;\n\n\tif (!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_ADDR_QUERY)) {\n\t\t/* For a well behaved ULP state will be RDMA_CM_IDLE */\n\t\tret = cma_bind_addr(&id_priv->id, src_addr, dst_addr);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (WARN_ON(!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND,\n\t\t\t\t\t   RDMA_CM_ADDR_QUERY)))\n\t\t\treturn -EINVAL;\n\n\t}\n\n\tif (cma_family(id_priv) != dst_addr->sa_family) {\n\t\tret = -EINVAL;\n\t\tgoto err_state;\n\t}\n\treturn 0;\n\nerr_state:\n\tcma_comp_exch(id_priv, RDMA_CM_ADDR_QUERY, RDMA_CM_ADDR_BOUND);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,17 +4,15 @@\n {\n \tint ret;\n \n-\tmemcpy(cma_dst_addr(id_priv), dst_addr, rdma_addr_size(dst_addr));\n \tif (!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND, RDMA_CM_ADDR_QUERY)) {\n \t\t/* For a well behaved ULP state will be RDMA_CM_IDLE */\n \t\tret = cma_bind_addr(&id_priv->id, src_addr, dst_addr);\n \t\tif (ret)\n-\t\t\tgoto err_dst;\n+\t\t\treturn ret;\n \t\tif (WARN_ON(!cma_comp_exch(id_priv, RDMA_CM_ADDR_BOUND,\n-\t\t\t\t\t   RDMA_CM_ADDR_QUERY))) {\n-\t\t\tret = -EINVAL;\n-\t\t\tgoto err_dst;\n-\t\t}\n+\t\t\t\t\t   RDMA_CM_ADDR_QUERY)))\n+\t\t\treturn -EINVAL;\n+\n \t}\n \n \tif (cma_family(id_priv) != dst_addr->sa_family) {\n@@ -25,7 +23,5 @@\n \n err_state:\n \tcma_comp_exch(id_priv, RDMA_CM_ADDR_QUERY, RDMA_CM_ADDR_BOUND);\n-err_dst:\n-\tmemset(cma_dst_addr(id_priv), 0, rdma_addr_size(dst_addr));\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\t\t\treturn ret;",
                "\t\t\t\t\t   RDMA_CM_ADDR_QUERY)))",
                "\t\t\treturn -EINVAL;",
                ""
            ],
            "deleted": [
                "\tmemcpy(cma_dst_addr(id_priv), dst_addr, rdma_addr_size(dst_addr));",
                "\t\t\tgoto err_dst;",
                "\t\t\t\t\t   RDMA_CM_ADDR_QUERY))) {",
                "\t\t\tret = -EINVAL;",
                "\t\t\tgoto err_dst;",
                "\t\t}",
                "err_dst:",
                "\tmemset(cma_dst_addr(id_priv), 0, rdma_addr_size(dst_addr));"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A vulnerability was found in compare_netdev_and_ip in drivers/infiniband/core/cma.c in RDMA in the Linux Kernel. The improper cleanup results in out-of-boundary read, where a local user can utilize this problem to crash the system or escalation of privilege.",
        "id": 3929
    },
    {
        "cve_id": "CVE-2019-15925",
        "code_before_change": "static int hclge_shaper_para_calc(u32 ir, u8 shaper_level,\n\t\t\t\t  u8 *ir_b, u8 *ir_u, u8 *ir_s)\n{\n#define DIVISOR_CLK\t\t(1000 * 8)\n#define DIVISOR_IR_B_126\t(126 * DIVISOR_CLK)\n\n\tconst u16 tick_array[HCLGE_SHAPER_LVL_CNT] = {\n\t\t6 * 256,        /* Prioriy level */\n\t\t6 * 32,         /* Prioriy group level */\n\t\t6 * 8,          /* Port level */\n\t\t6 * 256         /* Qset level */\n\t};\n\tu8 ir_u_calc = 0;\n\tu8 ir_s_calc = 0;\n\tu32 ir_calc;\n\tu32 tick;\n\n\t/* Calc tick */\n\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)\n\t\treturn -EINVAL;\n\n\ttick = tick_array[shaper_level];\n\n\t/**\n\t * Calc the speed if ir_b = 126, ir_u = 0 and ir_s = 0\n\t * the formula is changed to:\n\t *\t\t126 * 1 * 8\n\t * ir_calc = ---------------- * 1000\n\t *\t\ttick * 1\n\t */\n\tir_calc = (DIVISOR_IR_B_126 + (tick >> 1) - 1) / tick;\n\n\tif (ir_calc == ir) {\n\t\t*ir_b = 126;\n\t\t*ir_u = 0;\n\t\t*ir_s = 0;\n\n\t\treturn 0;\n\t} else if (ir_calc > ir) {\n\t\t/* Increasing the denominator to select ir_s value */\n\t\twhile (ir_calc > ir) {\n\t\t\tir_s_calc++;\n\t\t\tir_calc = DIVISOR_IR_B_126 / (tick * (1 << ir_s_calc));\n\t\t}\n\n\t\tif (ir_calc == ir)\n\t\t\t*ir_b = 126;\n\t\telse\n\t\t\t*ir_b = (ir * tick * (1 << ir_s_calc) +\n\t\t\t\t (DIVISOR_CLK >> 1)) / DIVISOR_CLK;\n\t} else {\n\t\t/* Increasing the numerator to select ir_u value */\n\t\tu32 numerator;\n\n\t\twhile (ir_calc < ir) {\n\t\t\tir_u_calc++;\n\t\t\tnumerator = DIVISOR_IR_B_126 * (1 << ir_u_calc);\n\t\t\tir_calc = (numerator + (tick >> 1)) / tick;\n\t\t}\n\n\t\tif (ir_calc == ir) {\n\t\t\t*ir_b = 126;\n\t\t} else {\n\t\t\tu32 denominator = (DIVISOR_CLK * (1 << --ir_u_calc));\n\t\t\t*ir_b = (ir * tick + (denominator >> 1)) / denominator;\n\t\t}\n\t}\n\n\t*ir_u = ir_u_calc;\n\t*ir_s = ir_s_calc;\n\n\treturn 0;\n}",
        "code_after_change": "static int hclge_shaper_para_calc(u32 ir, u8 shaper_level,\n\t\t\t\t  u8 *ir_b, u8 *ir_u, u8 *ir_s)\n{\n#define DIVISOR_CLK\t\t(1000 * 8)\n#define DIVISOR_IR_B_126\t(126 * DIVISOR_CLK)\n\n\tconst u16 tick_array[HCLGE_SHAPER_LVL_CNT] = {\n\t\t6 * 256,        /* Prioriy level */\n\t\t6 * 32,         /* Prioriy group level */\n\t\t6 * 8,          /* Port level */\n\t\t6 * 256         /* Qset level */\n\t};\n\tu8 ir_u_calc = 0;\n\tu8 ir_s_calc = 0;\n\tu32 ir_calc;\n\tu32 tick;\n\n\t/* Calc tick */\n\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||\n\t    ir > HCLGE_ETHER_MAX_RATE)\n\t\treturn -EINVAL;\n\n\ttick = tick_array[shaper_level];\n\n\t/**\n\t * Calc the speed if ir_b = 126, ir_u = 0 and ir_s = 0\n\t * the formula is changed to:\n\t *\t\t126 * 1 * 8\n\t * ir_calc = ---------------- * 1000\n\t *\t\ttick * 1\n\t */\n\tir_calc = (DIVISOR_IR_B_126 + (tick >> 1) - 1) / tick;\n\n\tif (ir_calc == ir) {\n\t\t*ir_b = 126;\n\t\t*ir_u = 0;\n\t\t*ir_s = 0;\n\n\t\treturn 0;\n\t} else if (ir_calc > ir) {\n\t\t/* Increasing the denominator to select ir_s value */\n\t\twhile (ir_calc > ir) {\n\t\t\tir_s_calc++;\n\t\t\tir_calc = DIVISOR_IR_B_126 / (tick * (1 << ir_s_calc));\n\t\t}\n\n\t\tif (ir_calc == ir)\n\t\t\t*ir_b = 126;\n\t\telse\n\t\t\t*ir_b = (ir * tick * (1 << ir_s_calc) +\n\t\t\t\t (DIVISOR_CLK >> 1)) / DIVISOR_CLK;\n\t} else {\n\t\t/* Increasing the numerator to select ir_u value */\n\t\tu32 numerator;\n\n\t\twhile (ir_calc < ir) {\n\t\t\tir_u_calc++;\n\t\t\tnumerator = DIVISOR_IR_B_126 * (1 << ir_u_calc);\n\t\t\tir_calc = (numerator + (tick >> 1)) / tick;\n\t\t}\n\n\t\tif (ir_calc == ir) {\n\t\t\t*ir_b = 126;\n\t\t} else {\n\t\t\tu32 denominator = (DIVISOR_CLK * (1 << --ir_u_calc));\n\t\t\t*ir_b = (ir * tick + (denominator >> 1)) / denominator;\n\t\t}\n\t}\n\n\t*ir_u = ir_u_calc;\n\t*ir_s = ir_s_calc;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,7 +16,8 @@\n \tu32 tick;\n \n \t/* Calc tick */\n-\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)\n+\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||\n+\t    ir > HCLGE_ETHER_MAX_RATE)\n \t\treturn -EINVAL;\n \n \ttick = tick_array[shaper_level];",
        "function_modified_lines": {
            "added": [
                "\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||",
                "\t    ir > HCLGE_ETHER_MAX_RATE)"
            ],
            "deleted": [
                "\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. An out of bounds access exists in the function hclge_tm_schd_mode_vnet_base_cfg in the file drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_tm.c.",
        "id": 2037
    },
    {
        "cve_id": "CVE-2021-3743",
        "code_before_change": "int qrtr_endpoint_post(struct qrtr_endpoint *ep, const void *data, size_t len)\n{\n\tstruct qrtr_node *node = ep->node;\n\tconst struct qrtr_hdr_v1 *v1;\n\tconst struct qrtr_hdr_v2 *v2;\n\tstruct qrtr_sock *ipc;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tunsigned int size;\n\tunsigned int ver;\n\tsize_t hdrlen;\n\n\tif (len == 0 || len & 3)\n\t\treturn -EINVAL;\n\n\tskb = __netdev_alloc_skb(NULL, len, GFP_ATOMIC | __GFP_NOWARN);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\t/* Version field in v1 is little endian, so this works for both cases */\n\tver = *(u8*)data;\n\n\tswitch (ver) {\n\tcase QRTR_PROTO_VER_1:\n\t\tif (len < sizeof(*v1))\n\t\t\tgoto err;\n\t\tv1 = data;\n\t\thdrlen = sizeof(*v1);\n\n\t\tcb->type = le32_to_cpu(v1->type);\n\t\tcb->src_node = le32_to_cpu(v1->src_node_id);\n\t\tcb->src_port = le32_to_cpu(v1->src_port_id);\n\t\tcb->confirm_rx = !!v1->confirm_rx;\n\t\tcb->dst_node = le32_to_cpu(v1->dst_node_id);\n\t\tcb->dst_port = le32_to_cpu(v1->dst_port_id);\n\n\t\tsize = le32_to_cpu(v1->size);\n\t\tbreak;\n\tcase QRTR_PROTO_VER_2:\n\t\tif (len < sizeof(*v2))\n\t\t\tgoto err;\n\t\tv2 = data;\n\t\thdrlen = sizeof(*v2) + v2->optlen;\n\n\t\tcb->type = v2->type;\n\t\tcb->confirm_rx = !!(v2->flags & QRTR_FLAGS_CONFIRM_RX);\n\t\tcb->src_node = le16_to_cpu(v2->src_node_id);\n\t\tcb->src_port = le16_to_cpu(v2->src_port_id);\n\t\tcb->dst_node = le16_to_cpu(v2->dst_node_id);\n\t\tcb->dst_port = le16_to_cpu(v2->dst_port_id);\n\n\t\tif (cb->src_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->src_port = QRTR_PORT_CTRL;\n\t\tif (cb->dst_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->dst_port = QRTR_PORT_CTRL;\n\n\t\tsize = le32_to_cpu(v2->size);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"qrtr: Invalid version %d\\n\", ver);\n\t\tgoto err;\n\t}\n\n\tif (len != ALIGN(size, 4) + hdrlen)\n\t\tgoto err;\n\n\tif (cb->dst_port != QRTR_PORT_CTRL && cb->type != QRTR_TYPE_DATA &&\n\t    cb->type != QRTR_TYPE_RESUME_TX)\n\t\tgoto err;\n\n\tskb_put_data(skb, data + hdrlen, size);\n\n\tqrtr_node_assign(node, cb->src_node);\n\n\tif (cb->type == QRTR_TYPE_NEW_SERVER) {\n\t\t/* Remote node endpoint can bridge other distant nodes */\n\t\tconst struct qrtr_ctrl_pkt *pkt = data + hdrlen;\n\n\t\tqrtr_node_assign(node, le32_to_cpu(pkt->server.node));\n\t}\n\n\tif (cb->type == QRTR_TYPE_RESUME_TX) {\n\t\tqrtr_tx_resume(node, skb);\n\t} else {\n\t\tipc = qrtr_port_lookup(cb->dst_port);\n\t\tif (!ipc)\n\t\t\tgoto err;\n\n\t\tif (sock_queue_rcv_skb(&ipc->sk, skb))\n\t\t\tgoto err;\n\n\t\tqrtr_port_put(ipc);\n\t}\n\n\treturn 0;\n\nerr:\n\tkfree_skb(skb);\n\treturn -EINVAL;\n\n}",
        "code_after_change": "int qrtr_endpoint_post(struct qrtr_endpoint *ep, const void *data, size_t len)\n{\n\tstruct qrtr_node *node = ep->node;\n\tconst struct qrtr_hdr_v1 *v1;\n\tconst struct qrtr_hdr_v2 *v2;\n\tstruct qrtr_sock *ipc;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tsize_t size;\n\tunsigned int ver;\n\tsize_t hdrlen;\n\n\tif (len == 0 || len & 3)\n\t\treturn -EINVAL;\n\n\tskb = __netdev_alloc_skb(NULL, len, GFP_ATOMIC | __GFP_NOWARN);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\t/* Version field in v1 is little endian, so this works for both cases */\n\tver = *(u8*)data;\n\n\tswitch (ver) {\n\tcase QRTR_PROTO_VER_1:\n\t\tif (len < sizeof(*v1))\n\t\t\tgoto err;\n\t\tv1 = data;\n\t\thdrlen = sizeof(*v1);\n\n\t\tcb->type = le32_to_cpu(v1->type);\n\t\tcb->src_node = le32_to_cpu(v1->src_node_id);\n\t\tcb->src_port = le32_to_cpu(v1->src_port_id);\n\t\tcb->confirm_rx = !!v1->confirm_rx;\n\t\tcb->dst_node = le32_to_cpu(v1->dst_node_id);\n\t\tcb->dst_port = le32_to_cpu(v1->dst_port_id);\n\n\t\tsize = le32_to_cpu(v1->size);\n\t\tbreak;\n\tcase QRTR_PROTO_VER_2:\n\t\tif (len < sizeof(*v2))\n\t\t\tgoto err;\n\t\tv2 = data;\n\t\thdrlen = sizeof(*v2) + v2->optlen;\n\n\t\tcb->type = v2->type;\n\t\tcb->confirm_rx = !!(v2->flags & QRTR_FLAGS_CONFIRM_RX);\n\t\tcb->src_node = le16_to_cpu(v2->src_node_id);\n\t\tcb->src_port = le16_to_cpu(v2->src_port_id);\n\t\tcb->dst_node = le16_to_cpu(v2->dst_node_id);\n\t\tcb->dst_port = le16_to_cpu(v2->dst_port_id);\n\n\t\tif (cb->src_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->src_port = QRTR_PORT_CTRL;\n\t\tif (cb->dst_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->dst_port = QRTR_PORT_CTRL;\n\n\t\tsize = le32_to_cpu(v2->size);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"qrtr: Invalid version %d\\n\", ver);\n\t\tgoto err;\n\t}\n\n\tif (len != ALIGN(size, 4) + hdrlen)\n\t\tgoto err;\n\n\tif (cb->dst_port != QRTR_PORT_CTRL && cb->type != QRTR_TYPE_DATA &&\n\t    cb->type != QRTR_TYPE_RESUME_TX)\n\t\tgoto err;\n\n\tskb_put_data(skb, data + hdrlen, size);\n\n\tqrtr_node_assign(node, cb->src_node);\n\n\tif (cb->type == QRTR_TYPE_NEW_SERVER) {\n\t\t/* Remote node endpoint can bridge other distant nodes */\n\t\tconst struct qrtr_ctrl_pkt *pkt = data + hdrlen;\n\n\t\tqrtr_node_assign(node, le32_to_cpu(pkt->server.node));\n\t}\n\n\tif (cb->type == QRTR_TYPE_RESUME_TX) {\n\t\tqrtr_tx_resume(node, skb);\n\t} else {\n\t\tipc = qrtr_port_lookup(cb->dst_port);\n\t\tif (!ipc)\n\t\t\tgoto err;\n\n\t\tif (sock_queue_rcv_skb(&ipc->sk, skb))\n\t\t\tgoto err;\n\n\t\tqrtr_port_put(ipc);\n\t}\n\n\treturn 0;\n\nerr:\n\tkfree_skb(skb);\n\treturn -EINVAL;\n\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \tstruct qrtr_sock *ipc;\n \tstruct sk_buff *skb;\n \tstruct qrtr_cb *cb;\n-\tunsigned int size;\n+\tsize_t size;\n \tunsigned int ver;\n \tsize_t hdrlen;\n ",
        "function_modified_lines": {
            "added": [
                "\tsize_t size;"
            ],
            "deleted": [
                "\tunsigned int size;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds (OOB) memory read flaw was found in the Qualcomm IPC router protocol in the Linux kernel. A missing sanity check allows a local attacker to gain access to out-of-bounds memory, leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability.",
        "id": 3051
    },
    {
        "cve_id": "CVE-2021-3753",
        "code_before_change": "static int vt_kdsetmode(struct vc_data *vc, unsigned long mode)\n{\n\tswitch (mode) {\n\tcase KD_GRAPHICS:\n\t\tbreak;\n\tcase KD_TEXT0:\n\tcase KD_TEXT1:\n\t\tmode = KD_TEXT;\n\t\tfallthrough;\n\tcase KD_TEXT:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t/* FIXME: this needs the console lock extending */\n\tif (vc->vc_mode == mode)\n\t\treturn 0;\n\n\tvc->vc_mode = mode;\n\tif (vc->vc_num != fg_console)\n\t\treturn 0;\n\n\t/* explicitly blank/unblank the screen if switching modes */\n\tconsole_lock();\n\tif (mode == KD_TEXT)\n\t\tdo_unblank_screen(1);\n\telse\n\t\tdo_blank_screen(1);\n\tconsole_unlock();\n\n\treturn 0;\n}",
        "code_after_change": "static int vt_kdsetmode(struct vc_data *vc, unsigned long mode)\n{\n\tswitch (mode) {\n\tcase KD_GRAPHICS:\n\t\tbreak;\n\tcase KD_TEXT0:\n\tcase KD_TEXT1:\n\t\tmode = KD_TEXT;\n\t\tfallthrough;\n\tcase KD_TEXT:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (vc->vc_mode == mode)\n\t\treturn 0;\n\n\tvc->vc_mode = mode;\n\tif (vc->vc_num != fg_console)\n\t\treturn 0;\n\n\t/* explicitly blank/unblank the screen if switching modes */\n\tif (mode == KD_TEXT)\n\t\tdo_unblank_screen(1);\n\telse\n\t\tdo_blank_screen(1);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,7 +13,6 @@\n \t\treturn -EINVAL;\n \t}\n \n-\t/* FIXME: this needs the console lock extending */\n \tif (vc->vc_mode == mode)\n \t\treturn 0;\n \n@@ -22,12 +21,10 @@\n \t\treturn 0;\n \n \t/* explicitly blank/unblank the screen if switching modes */\n-\tconsole_lock();\n \tif (mode == KD_TEXT)\n \t\tdo_unblank_screen(1);\n \telse\n \t\tdo_blank_screen(1);\n-\tconsole_unlock();\n \n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t/* FIXME: this needs the console lock extending */",
                "\tconsole_lock();",
                "\tconsole_unlock();"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A race problem was seen in the vt_k_ioctl in drivers/tty/vt/vt_ioctl.c in the Linux kernel, which may cause an out of bounds read in vt as the write access to vc_mode is not protected by lock-in vt_ioctl (KDSETMDE). The highest threat from this vulnerability is to data confidentiality.",
        "id": 3056
    },
    {
        "cve_id": "CVE-2019-15666",
        "code_before_change": "static int verify_newpolicy_info(struct xfrm_userpolicy_info *p)\n{\n\tint ret;\n\n\tswitch (p->share) {\n\tcase XFRM_SHARE_ANY:\n\tcase XFRM_SHARE_SESSION:\n\tcase XFRM_SHARE_USER:\n\tcase XFRM_SHARE_UNIQUE:\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p->action) {\n\tcase XFRM_POLICY_ALLOW:\n\tcase XFRM_POLICY_BLOCK:\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p->sel.family) {\n\tcase AF_INET:\n\t\tif (p->sel.prefixlen_d > 32 || p->sel.prefixlen_s > 32)\n\t\t\treturn -EINVAL;\n\n\t\tbreak;\n\n\tcase AF_INET6:\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tif (p->sel.prefixlen_d > 128 || p->sel.prefixlen_s > 128)\n\t\t\treturn -EINVAL;\n\n\t\tbreak;\n#else\n\t\treturn  -EAFNOSUPPORT;\n#endif\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tret = verify_policy_dir(p->dir);\n\tif (ret)\n\t\treturn ret;\n\tif (p->index && ((p->index & XFRM_POLICY_MAX) != p->dir))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "code_after_change": "static int verify_newpolicy_info(struct xfrm_userpolicy_info *p)\n{\n\tint ret;\n\n\tswitch (p->share) {\n\tcase XFRM_SHARE_ANY:\n\tcase XFRM_SHARE_SESSION:\n\tcase XFRM_SHARE_USER:\n\tcase XFRM_SHARE_UNIQUE:\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p->action) {\n\tcase XFRM_POLICY_ALLOW:\n\tcase XFRM_POLICY_BLOCK:\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (p->sel.family) {\n\tcase AF_INET:\n\t\tif (p->sel.prefixlen_d > 32 || p->sel.prefixlen_s > 32)\n\t\t\treturn -EINVAL;\n\n\t\tbreak;\n\n\tcase AF_INET6:\n#if IS_ENABLED(CONFIG_IPV6)\n\t\tif (p->sel.prefixlen_d > 128 || p->sel.prefixlen_s > 128)\n\t\t\treturn -EINVAL;\n\n\t\tbreak;\n#else\n\t\treturn  -EAFNOSUPPORT;\n#endif\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tret = verify_policy_dir(p->dir);\n\tif (ret)\n\t\treturn ret;\n\tif (p->index && (xfrm_policy_id2dir(p->index) != p->dir))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -46,7 +46,7 @@\n \tret = verify_policy_dir(p->dir);\n \tif (ret)\n \t\treturn ret;\n-\tif (p->index && ((p->index & XFRM_POLICY_MAX) != p->dir))\n+\tif (p->index && (xfrm_policy_id2dir(p->index) != p->dir))\n \t\treturn -EINVAL;\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tif (p->index && (xfrm_policy_id2dir(p->index) != p->dir))"
            ],
            "deleted": [
                "\tif (p->index && ((p->index & XFRM_POLICY_MAX) != p->dir))"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.19. There is an out-of-bounds array access in __xfrm_policy_unlink, which will cause denial of service, because verify_newpolicy_info in net/xfrm/xfrm_user.c mishandles directory validation.",
        "id": 2020
    },
    {
        "cve_id": "CVE-2022-47940",
        "code_before_change": "int smb2_write(struct ksmbd_work *work)\n{\n\tstruct smb2_write_req *req;\n\tstruct smb2_write_rsp *rsp;\n\tstruct ksmbd_file *fp = NULL;\n\tloff_t offset;\n\tsize_t length;\n\tssize_t nbytes;\n\tchar *data_buf;\n\tbool writethrough = false;\n\tint err = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe write request\\n\");\n\t\treturn smb2_write_pipe(work);\n\t}\n\n\tif (req->Channel == SMB2_CHANNEL_RDMA_V1 ||\n\t    req->Channel == SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tunsigned int ch_offset = le16_to_cpu(req->WriteChannelInfoOffset);\n\n\t\tif (req->Length != 0 || req->DataOffset != 0 ||\n\t\t    ch_offset < offsetof(struct smb2_write_req, Buffer)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\terr = smb2_set_remote_key_for_rdma(work,\n\t\t\t\t\t\t   (struct smb2_buffer_desc_v1 *)\n\t\t\t\t\t\t   ((char *)req + ch_offset),\n\t\t\t\t\t\t   req->Channel,\n\t\t\t\t\t\t   req->WriteChannelInfoOffset,\n\t\t\t\t\t\t   req->WriteChannelInfoLength);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tif (!test_tree_conn_flag(work->tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tksmbd_debug(SMB, \"User does not have write permission\\n\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, req->VolatileFileId, req->PersistentFileId);\n\tif (!fp) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!(fp->daccess & (FILE_WRITE_DATA_LE | FILE_READ_ATTRIBUTES_LE))) {\n\t\tpr_err(\"Not permitted to write : 0x%x\\n\", fp->daccess);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\toffset = le64_to_cpu(req->Offset);\n\tlength = le32_to_cpu(req->Length);\n\n\tif (length > work->conn->vals->max_write_size) {\n\t\tksmbd_debug(SMB, \"limiting write size to max size(%u)\\n\",\n\t\t\t    work->conn->vals->max_write_size);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\twritethrough = true;\n\n\tif (req->Channel != SMB2_CHANNEL_RDMA_V1 &&\n\t    req->Channel != SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tif (le16_to_cpu(req->DataOffset) ==\n\t\t    offsetof(struct smb2_write_req, Buffer)) {\n\t\t\tdata_buf = (char *)&req->Buffer[0];\n\t\t} else {\n\t\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n\t\t\t    get_rfc1002_len(work->request_buf)) {\n\t\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n\t\t\t\t       le16_to_cpu(req->DataOffset),\n\t\t\t\t       get_rfc1002_len(work->request_buf));\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n\t\t\t\t\tle16_to_cpu(req->DataOffset));\n\t\t}\n\n\t\tksmbd_debug(SMB, \"flags %u\\n\", le32_to_cpu(req->Flags));\n\t\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\t\twritethrough = true;\n\n\t\tksmbd_debug(SMB, \"filename %pd, offset %lld, len %zu\\n\",\n\t\t\t    fp->filp->f_path.dentry, offset, length);\n\t\terr = ksmbd_vfs_write(work, fp, data_buf, length, &offset,\n\t\t\t\t      writethrough, &nbytes);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t} else {\n\t\t/* read data from the client using rdma channel, and\n\t\t * write the data.\n\t\t */\n\t\tnbytes = smb2_write_rdma_channel(work, req, fp, offset,\n\t\t\t\t\t\t le32_to_cpu(req->RemainingBytes),\n\t\t\t\t\t\t writethrough);\n\t\tif (nbytes < 0) {\n\t\t\terr = (int)nbytes;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trsp->StructureSize = cpu_to_le16(17);\n\trsp->DataOffset = 0;\n\trsp->Reserved = 0;\n\trsp->DataLength = cpu_to_le32(nbytes);\n\trsp->DataRemaining = 0;\n\trsp->Reserved2 = 0;\n\tinc_rfc1001_len(work->response_buf, 16);\n\tksmbd_fd_put(work, fp);\n\treturn 0;\n\nout:\n\tif (err == -EAGAIN)\n\t\trsp->hdr.Status = STATUS_FILE_LOCK_CONFLICT;\n\telse if (err == -ENOSPC || err == -EFBIG)\n\t\trsp->hdr.Status = STATUS_DISK_FULL;\n\telse if (err == -ENOENT)\n\t\trsp->hdr.Status = STATUS_FILE_CLOSED;\n\telse if (err == -EACCES)\n\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\telse if (err == -ESHARE)\n\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\telse if (err == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse\n\t\trsp->hdr.Status = STATUS_INVALID_HANDLE;\n\n\tsmb2_set_err_rsp(work);\n\tksmbd_fd_put(work, fp);\n\treturn err;\n}",
        "code_after_change": "int smb2_write(struct ksmbd_work *work)\n{\n\tstruct smb2_write_req *req;\n\tstruct smb2_write_rsp *rsp;\n\tstruct ksmbd_file *fp = NULL;\n\tloff_t offset;\n\tsize_t length;\n\tssize_t nbytes;\n\tchar *data_buf;\n\tbool writethrough = false;\n\tint err = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe write request\\n\");\n\t\treturn smb2_write_pipe(work);\n\t}\n\n\tif (req->Channel == SMB2_CHANNEL_RDMA_V1 ||\n\t    req->Channel == SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tunsigned int ch_offset = le16_to_cpu(req->WriteChannelInfoOffset);\n\n\t\tif (req->Length != 0 || req->DataOffset != 0 ||\n\t\t    ch_offset < offsetof(struct smb2_write_req, Buffer)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\terr = smb2_set_remote_key_for_rdma(work,\n\t\t\t\t\t\t   (struct smb2_buffer_desc_v1 *)\n\t\t\t\t\t\t   ((char *)req + ch_offset),\n\t\t\t\t\t\t   req->Channel,\n\t\t\t\t\t\t   req->WriteChannelInfoOffset,\n\t\t\t\t\t\t   req->WriteChannelInfoLength);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tif (!test_tree_conn_flag(work->tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tksmbd_debug(SMB, \"User does not have write permission\\n\");\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\tfp = ksmbd_lookup_fd_slow(work, req->VolatileFileId, req->PersistentFileId);\n\tif (!fp) {\n\t\terr = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!(fp->daccess & (FILE_WRITE_DATA_LE | FILE_READ_ATTRIBUTES_LE))) {\n\t\tpr_err(\"Not permitted to write : 0x%x\\n\", fp->daccess);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\n\toffset = le64_to_cpu(req->Offset);\n\tlength = le32_to_cpu(req->Length);\n\n\tif (length > work->conn->vals->max_write_size) {\n\t\tksmbd_debug(SMB, \"limiting write size to max size(%u)\\n\",\n\t\t\t    work->conn->vals->max_write_size);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\twritethrough = true;\n\n\tif (req->Channel != SMB2_CHANNEL_RDMA_V1 &&\n\t    req->Channel != SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n\t\t    get_rfc1002_len(work->request_buf)) {\n\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n\t\t\t       le16_to_cpu(req->DataOffset),\n\t\t\t       get_rfc1002_len(work->request_buf));\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n\t\t\t\t    le16_to_cpu(req->DataOffset));\n\n\t\tksmbd_debug(SMB, \"flags %u\\n\", le32_to_cpu(req->Flags));\n\t\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)\n\t\t\twritethrough = true;\n\n\t\tksmbd_debug(SMB, \"filename %pd, offset %lld, len %zu\\n\",\n\t\t\t    fp->filp->f_path.dentry, offset, length);\n\t\terr = ksmbd_vfs_write(work, fp, data_buf, length, &offset,\n\t\t\t\t      writethrough, &nbytes);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t} else {\n\t\t/* read data from the client using rdma channel, and\n\t\t * write the data.\n\t\t */\n\t\tnbytes = smb2_write_rdma_channel(work, req, fp, offset,\n\t\t\t\t\t\t le32_to_cpu(req->RemainingBytes),\n\t\t\t\t\t\t writethrough);\n\t\tif (nbytes < 0) {\n\t\t\terr = (int)nbytes;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trsp->StructureSize = cpu_to_le16(17);\n\trsp->DataOffset = 0;\n\trsp->Reserved = 0;\n\trsp->DataLength = cpu_to_le32(nbytes);\n\trsp->DataRemaining = 0;\n\trsp->Reserved2 = 0;\n\tinc_rfc1001_len(work->response_buf, 16);\n\tksmbd_fd_put(work, fp);\n\treturn 0;\n\nout:\n\tif (err == -EAGAIN)\n\t\trsp->hdr.Status = STATUS_FILE_LOCK_CONFLICT;\n\telse if (err == -ENOSPC || err == -EFBIG)\n\t\trsp->hdr.Status = STATUS_DISK_FULL;\n\telse if (err == -ENOENT)\n\t\trsp->hdr.Status = STATUS_FILE_CLOSED;\n\telse if (err == -EACCES)\n\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\telse if (err == -ESHARE)\n\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\telse if (err == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse\n\t\trsp->hdr.Status = STATUS_INVALID_HANDLE;\n\n\tsmb2_set_err_rsp(work);\n\tksmbd_fd_put(work, fp);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -69,22 +69,16 @@\n \n \tif (req->Channel != SMB2_CHANNEL_RDMA_V1 &&\n \t    req->Channel != SMB2_CHANNEL_RDMA_V1_INVALIDATE) {\n-\t\tif (le16_to_cpu(req->DataOffset) ==\n-\t\t    offsetof(struct smb2_write_req, Buffer)) {\n-\t\t\tdata_buf = (char *)&req->Buffer[0];\n-\t\t} else {\n-\t\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n-\t\t\t    get_rfc1002_len(work->request_buf)) {\n-\t\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n-\t\t\t\t       le16_to_cpu(req->DataOffset),\n-\t\t\t\t       get_rfc1002_len(work->request_buf));\n-\t\t\t\terr = -EINVAL;\n-\t\t\t\tgoto out;\n-\t\t\t}\n-\n-\t\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n-\t\t\t\t\tle16_to_cpu(req->DataOffset));\n+\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >\n+\t\t    get_rfc1002_len(work->request_buf)) {\n+\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",\n+\t\t\t       le16_to_cpu(req->DataOffset),\n+\t\t\t       get_rfc1002_len(work->request_buf));\n+\t\t\terr = -EINVAL;\n+\t\t\tgoto out;\n \t\t}\n+\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +\n+\t\t\t\t    le16_to_cpu(req->DataOffset));\n \n \t\tksmbd_debug(SMB, \"flags %u\\n\", le32_to_cpu(req->Flags));\n \t\tif (le32_to_cpu(req->Flags) & SMB2_WRITEFLAG_WRITE_THROUGH)",
        "function_modified_lines": {
            "added": [
                "\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >",
                "\t\t    get_rfc1002_len(work->request_buf)) {",
                "\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",",
                "\t\t\t       le16_to_cpu(req->DataOffset),",
                "\t\t\t       get_rfc1002_len(work->request_buf));",
                "\t\t\terr = -EINVAL;",
                "\t\t\tgoto out;",
                "\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +",
                "\t\t\t\t    le16_to_cpu(req->DataOffset));"
            ],
            "deleted": [
                "\t\tif (le16_to_cpu(req->DataOffset) ==",
                "\t\t    offsetof(struct smb2_write_req, Buffer)) {",
                "\t\t\tdata_buf = (char *)&req->Buffer[0];",
                "\t\t} else {",
                "\t\t\tif ((u64)le16_to_cpu(req->DataOffset) + length >",
                "\t\t\t    get_rfc1002_len(work->request_buf)) {",
                "\t\t\t\tpr_err(\"invalid write data offset %u, smb_len %u\\n\",",
                "\t\t\t\t       le16_to_cpu(req->DataOffset),",
                "\t\t\t\t       get_rfc1002_len(work->request_buf));",
                "\t\t\t\terr = -EINVAL;",
                "\t\t\t\tgoto out;",
                "\t\t\t}",
                "",
                "\t\t\tdata_buf = (char *)(((char *)&req->hdr.ProtocolId) +",
                "\t\t\t\t\tle16_to_cpu(req->DataOffset));"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in ksmbd in the Linux kernel 5.15 through 5.18 before 5.18.18. fs/ksmbd/smb2pdu.c lacks length validation in the non-padding case in smb2_write.",
        "id": 3768
    },
    {
        "cve_id": "CVE-2019-9245",
        "code_before_change": "int f2fs_getxattr(struct inode *inode, int index, const char *name,\n\t\tvoid *buffer, size_t buffer_size, struct page *ipage)\n{\n\tstruct f2fs_xattr_entry *entry = NULL;\n\tint error = 0;\n\tunsigned int size, len;\n\tvoid *base_addr = NULL;\n\n\tif (name == NULL)\n\t\treturn -EINVAL;\n\n\tlen = strlen(name);\n\tif (len > F2FS_NAME_LEN)\n\t\treturn -ERANGE;\n\n\tdown_read(&F2FS_I(inode)->i_xattr_sem);\n\terror = lookup_all_xattrs(inode, ipage, index, len, name,\n\t\t\t\t&entry, &base_addr);\n\tup_read(&F2FS_I(inode)->i_xattr_sem);\n\tif (error)\n\t\treturn error;\n\n\tsize = le16_to_cpu(entry->e_value_size);\n\n\tif (buffer && size > buffer_size) {\n\t\terror = -ERANGE;\n\t\tgoto out;\n\t}\n\n\tif (buffer) {\n\t\tchar *pval = entry->e_name + entry->e_name_len;\n\t\tmemcpy(buffer, pval, size);\n\t}\n\terror = size;\nout:\n\tkzfree(base_addr);\n\treturn error;\n}",
        "code_after_change": "int f2fs_getxattr(struct inode *inode, int index, const char *name,\n\t\tvoid *buffer, size_t buffer_size, struct page *ipage)\n{\n\tstruct f2fs_xattr_entry *entry = NULL;\n\tint error = 0;\n\tunsigned int size, len;\n\tvoid *base_addr = NULL;\n\tint base_size;\n\n\tif (name == NULL)\n\t\treturn -EINVAL;\n\n\tlen = strlen(name);\n\tif (len > F2FS_NAME_LEN)\n\t\treturn -ERANGE;\n\n\tdown_read(&F2FS_I(inode)->i_xattr_sem);\n\terror = lookup_all_xattrs(inode, ipage, index, len, name,\n\t\t\t\t&entry, &base_addr, &base_size);\n\tup_read(&F2FS_I(inode)->i_xattr_sem);\n\tif (error)\n\t\treturn error;\n\n\tsize = le16_to_cpu(entry->e_value_size);\n\n\tif (buffer && size > buffer_size) {\n\t\terror = -ERANGE;\n\t\tgoto out;\n\t}\n\n\tif (buffer) {\n\t\tchar *pval = entry->e_name + entry->e_name_len;\n\n\t\tif (base_size - (pval - (char *)base_addr) < size) {\n\t\t\terror = -ERANGE;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(buffer, pval, size);\n\t}\n\terror = size;\nout:\n\tkzfree(base_addr);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tint error = 0;\n \tunsigned int size, len;\n \tvoid *base_addr = NULL;\n+\tint base_size;\n \n \tif (name == NULL)\n \t\treturn -EINVAL;\n@@ -15,7 +16,7 @@\n \n \tdown_read(&F2FS_I(inode)->i_xattr_sem);\n \terror = lookup_all_xattrs(inode, ipage, index, len, name,\n-\t\t\t\t&entry, &base_addr);\n+\t\t\t\t&entry, &base_addr, &base_size);\n \tup_read(&F2FS_I(inode)->i_xattr_sem);\n \tif (error)\n \t\treturn error;\n@@ -29,6 +30,11 @@\n \n \tif (buffer) {\n \t\tchar *pval = entry->e_name + entry->e_name_len;\n+\n+\t\tif (base_size - (pval - (char *)base_addr) < size) {\n+\t\t\terror = -ERANGE;\n+\t\t\tgoto out;\n+\t\t}\n \t\tmemcpy(buffer, pval, size);\n \t}\n \terror = size;",
        "function_modified_lines": {
            "added": [
                "\tint base_size;",
                "\t\t\t\t&entry, &base_addr, &base_size);",
                "",
                "\t\tif (base_size - (pval - (char *)base_addr) < size) {",
                "\t\t\terror = -ERANGE;",
                "\t\t\tgoto out;",
                "\t\t}"
            ],
            "deleted": [
                "\t\t\t\t&entry, &base_addr);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In the Android kernel in the f2fs driver there is a possible out of bounds read due to a missing bounds check. This could lead to local information disclosure with System execution privileges needed. User interaction is not needed for exploitation.",
        "id": 2355
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "static int vcpu_mmio_read(struct kvm_vcpu *vcpu, gpa_t addr, int len, void *v)\n{\n\tint handled = 0;\n\tint n;\n\n\tdo {\n\t\tn = min(len, 8);\n\t\tif (!(lapic_in_kernel(vcpu) &&\n\t\t      !kvm_iodevice_read(vcpu, &vcpu->arch.apic->dev,\n\t\t\t\t\t addr, n, v))\n\t\t    && kvm_io_bus_read(vcpu, KVM_MMIO_BUS, addr, n, v))\n\t\t\tbreak;\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, *(u64 *)v);\n\t\thandled += n;\n\t\taddr += n;\n\t\tlen -= n;\n\t\tv += n;\n\t} while (len);\n\n\treturn handled;\n}",
        "code_after_change": "static int vcpu_mmio_read(struct kvm_vcpu *vcpu, gpa_t addr, int len, void *v)\n{\n\tint handled = 0;\n\tint n;\n\n\tdo {\n\t\tn = min(len, 8);\n\t\tif (!(lapic_in_kernel(vcpu) &&\n\t\t      !kvm_iodevice_read(vcpu, &vcpu->arch.apic->dev,\n\t\t\t\t\t addr, n, v))\n\t\t    && kvm_io_bus_read(vcpu, KVM_MMIO_BUS, addr, n, v))\n\t\t\tbreak;\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, v);\n\t\thandled += n;\n\t\taddr += n;\n\t\tlen -= n;\n\t\tv += n;\n\t} while (len);\n\n\treturn handled;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t\t\t\t\t addr, n, v))\n \t\t    && kvm_io_bus_read(vcpu, KVM_MMIO_BUS, addr, n, v))\n \t\t\tbreak;\n-\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, *(u64 *)v);\n+\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, v);\n \t\thandled += n;\n \t\taddr += n;\n \t\tlen -= n;",
        "function_modified_lines": {
            "added": [
                "\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, v);"
            ],
            "deleted": [
                "\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, n, addr, *(u64 *)v);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1369
    },
    {
        "cve_id": "CVE-2021-3444",
        "code_before_change": "static int fixup_bpf_calls(struct bpf_verifier_env *env)\n{\n\tstruct bpf_prog *prog = env->prog;\n\tbool expect_blinding = bpf_jit_blinding_enabled(prog);\n\tstruct bpf_insn *insn = prog->insnsi;\n\tconst struct bpf_func_proto *fn;\n\tconst int insn_cnt = prog->len;\n\tconst struct bpf_map_ops *ops;\n\tstruct bpf_insn_aux_data *aux;\n\tstruct bpf_insn insn_buf[16];\n\tstruct bpf_prog *new_prog;\n\tstruct bpf_map *map_ptr;\n\tint i, ret, cnt, delta = 0;\n\n\tfor (i = 0; i < insn_cnt; i++, insn++) {\n\t\tif (insn->code == (BPF_ALU64 | BPF_MOD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU64 | BPF_DIV | BPF_X) ||\n\t\t    insn->code == (BPF_ALU | BPF_MOD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU | BPF_DIV | BPF_X)) {\n\t\t\tbool is64 = BPF_CLASS(insn->code) == BPF_ALU64;\n\t\t\tbool isdiv = BPF_OP(insn->code) == BPF_DIV;\n\t\t\tstruct bpf_insn *patchlet;\n\t\t\tstruct bpf_insn chk_and_div[] = {\n\t\t\t\t/* Rx div 0 -> 0 */\n\t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n\t\t\t\t\t     BPF_JNE | BPF_K, insn->src_reg,\n\t\t\t\t\t     0, 2, 0),\n\t\t\t\tBPF_ALU32_REG(BPF_XOR, insn->dst_reg, insn->dst_reg),\n\t\t\t\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\t\t\t\t*insn,\n\t\t\t};\n\t\t\tstruct bpf_insn chk_and_mod[] = {\n\t\t\t\t/* Rx mod 0 -> Rx */\n\t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n\t\t\t\t\t     BPF_JEQ | BPF_K, insn->src_reg,\n\t\t\t\t\t     0, 1, 0),\n\t\t\t\t*insn,\n\t\t\t};\n\n\t\t\tpatchlet = isdiv ? chk_and_div : chk_and_mod;\n\t\t\tcnt = isdiv ? ARRAY_SIZE(chk_and_div) :\n\t\t\t\t      ARRAY_SIZE(chk_and_mod);\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, patchlet, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (BPF_CLASS(insn->code) == BPF_LD &&\n\t\t    (BPF_MODE(insn->code) == BPF_ABS ||\n\t\t     BPF_MODE(insn->code) == BPF_IND)) {\n\t\t\tcnt = env->ops->gen_ld_abs(insn, insn_buf);\n\t\t\tif (cnt == 0 || cnt >= ARRAY_SIZE(insn_buf)) {\n\t\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (insn->code == (BPF_ALU64 | BPF_ADD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU64 | BPF_SUB | BPF_X)) {\n\t\t\tconst u8 code_add = BPF_ALU64 | BPF_ADD | BPF_X;\n\t\t\tconst u8 code_sub = BPF_ALU64 | BPF_SUB | BPF_X;\n\t\t\tstruct bpf_insn insn_buf[16];\n\t\t\tstruct bpf_insn *patch = &insn_buf[0];\n\t\t\tbool issrc, isneg;\n\t\t\tu32 off_reg;\n\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (!aux->alu_state ||\n\t\t\t    aux->alu_state == BPF_ALU_NON_POINTER)\n\t\t\t\tcontinue;\n\n\t\t\tisneg = aux->alu_state & BPF_ALU_NEG_VALUE;\n\t\t\tissrc = (aux->alu_state & BPF_ALU_SANITIZE) ==\n\t\t\t\tBPF_ALU_SANITIZE_SRC;\n\n\t\t\toff_reg = issrc ? insn->src_reg : insn->dst_reg;\n\t\t\tif (isneg)\n\t\t\t\t*patch++ = BPF_ALU64_IMM(BPF_MUL, off_reg, -1);\n\t\t\t*patch++ = BPF_MOV32_IMM(BPF_REG_AX, aux->alu_limit - 1);\n\t\t\t*patch++ = BPF_ALU64_REG(BPF_SUB, BPF_REG_AX, off_reg);\n\t\t\t*patch++ = BPF_ALU64_REG(BPF_OR, BPF_REG_AX, off_reg);\n\t\t\t*patch++ = BPF_ALU64_IMM(BPF_NEG, BPF_REG_AX, 0);\n\t\t\t*patch++ = BPF_ALU64_IMM(BPF_ARSH, BPF_REG_AX, 63);\n\t\t\tif (issrc) {\n\t\t\t\t*patch++ = BPF_ALU64_REG(BPF_AND, BPF_REG_AX,\n\t\t\t\t\t\t\t off_reg);\n\t\t\t\tinsn->src_reg = BPF_REG_AX;\n\t\t\t} else {\n\t\t\t\t*patch++ = BPF_ALU64_REG(BPF_AND, off_reg,\n\t\t\t\t\t\t\t BPF_REG_AX);\n\t\t\t}\n\t\t\tif (isneg)\n\t\t\t\tinsn->code = insn->code == code_add ?\n\t\t\t\t\t     code_sub : code_add;\n\t\t\t*patch++ = *insn;\n\t\t\tif (issrc && isneg)\n\t\t\t\t*patch++ = BPF_ALU64_IMM(BPF_MUL, off_reg, -1);\n\t\t\tcnt = patch - insn_buf;\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (insn->code != (BPF_JMP | BPF_CALL))\n\t\t\tcontinue;\n\t\tif (insn->src_reg == BPF_PSEUDO_CALL)\n\t\t\tcontinue;\n\n\t\tif (insn->imm == BPF_FUNC_get_route_realm)\n\t\t\tprog->dst_needed = 1;\n\t\tif (insn->imm == BPF_FUNC_get_prandom_u32)\n\t\t\tbpf_user_rnd_init_once();\n\t\tif (insn->imm == BPF_FUNC_override_return)\n\t\t\tprog->kprobe_override = 1;\n\t\tif (insn->imm == BPF_FUNC_tail_call) {\n\t\t\t/* If we tail call into other programs, we\n\t\t\t * cannot make any assumptions since they can\n\t\t\t * be replaced dynamically during runtime in\n\t\t\t * the program array.\n\t\t\t */\n\t\t\tprog->cb_access = 1;\n\t\t\tif (!allow_tail_call_in_subprogs(env))\n\t\t\t\tprog->aux->stack_depth = MAX_BPF_STACK;\n\t\t\tprog->aux->max_pkt_offset = MAX_PACKET_OFF;\n\n\t\t\t/* mark bpf_tail_call as different opcode to avoid\n\t\t\t * conditional branch in the interpeter for every normal\n\t\t\t * call and to prevent accidental JITing by JIT compiler\n\t\t\t * that doesn't support bpf_tail_call yet\n\t\t\t */\n\t\t\tinsn->imm = 0;\n\t\t\tinsn->code = BPF_JMP | BPF_TAIL_CALL;\n\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (env->bpf_capable && !expect_blinding &&\n\t\t\t    prog->jit_requested &&\n\t\t\t    !bpf_map_key_poisoned(aux) &&\n\t\t\t    !bpf_map_ptr_poisoned(aux) &&\n\t\t\t    !bpf_map_ptr_unpriv(aux)) {\n\t\t\t\tstruct bpf_jit_poke_descriptor desc = {\n\t\t\t\t\t.reason = BPF_POKE_REASON_TAIL_CALL,\n\t\t\t\t\t.tail_call.map = BPF_MAP_PTR(aux->map_ptr_state),\n\t\t\t\t\t.tail_call.key = bpf_map_key_immediate(aux),\n\t\t\t\t\t.insn_idx = i + delta,\n\t\t\t\t};\n\n\t\t\t\tret = bpf_jit_add_poke_descriptor(prog, &desc);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tverbose(env, \"adding tail call poke descriptor failed\\n\");\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\n\t\t\t\tinsn->imm = ret + 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!bpf_map_ptr_unpriv(aux))\n\t\t\t\tcontinue;\n\n\t\t\t/* instead of changing every JIT dealing with tail_call\n\t\t\t * emit two extra insns:\n\t\t\t * if (index >= max_entries) goto out;\n\t\t\t * index &= array->index_mask;\n\t\t\t * to avoid out-of-bounds cpu speculation\n\t\t\t */\n\t\t\tif (bpf_map_ptr_poisoned(aux)) {\n\t\t\t\tverbose(env, \"tail_call abusing map_ptr\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tmap_ptr = BPF_MAP_PTR(aux->map_ptr_state);\n\t\t\tinsn_buf[0] = BPF_JMP_IMM(BPF_JGE, BPF_REG_3,\n\t\t\t\t\t\t  map_ptr->max_entries, 2);\n\t\t\tinsn_buf[1] = BPF_ALU32_IMM(BPF_AND, BPF_REG_3,\n\t\t\t\t\t\t    container_of(map_ptr,\n\t\t\t\t\t\t\t\t struct bpf_array,\n\t\t\t\t\t\t\t\t map)->index_mask);\n\t\t\tinsn_buf[2] = *insn;\n\t\t\tcnt = 3;\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* BPF_EMIT_CALL() assumptions in some of the map_gen_lookup\n\t\t * and other inlining handlers are currently limited to 64 bit\n\t\t * only.\n\t\t */\n\t\tif (prog->jit_requested && BITS_PER_LONG == 64 &&\n\t\t    (insn->imm == BPF_FUNC_map_lookup_elem ||\n\t\t     insn->imm == BPF_FUNC_map_update_elem ||\n\t\t     insn->imm == BPF_FUNC_map_delete_elem ||\n\t\t     insn->imm == BPF_FUNC_map_push_elem   ||\n\t\t     insn->imm == BPF_FUNC_map_pop_elem    ||\n\t\t     insn->imm == BPF_FUNC_map_peek_elem)) {\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (bpf_map_ptr_poisoned(aux))\n\t\t\t\tgoto patch_call_imm;\n\n\t\t\tmap_ptr = BPF_MAP_PTR(aux->map_ptr_state);\n\t\t\tops = map_ptr->ops;\n\t\t\tif (insn->imm == BPF_FUNC_map_lookup_elem &&\n\t\t\t    ops->map_gen_lookup) {\n\t\t\t\tcnt = ops->map_gen_lookup(map_ptr, insn_buf);\n\t\t\t\tif (cnt == -EOPNOTSUPP)\n\t\t\t\t\tgoto patch_map_ops_generic;\n\t\t\t\tif (cnt <= 0 || cnt >= ARRAY_SIZE(insn_buf)) {\n\t\t\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\n\t\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta,\n\t\t\t\t\t\t\t       insn_buf, cnt);\n\t\t\t\tif (!new_prog)\n\t\t\t\t\treturn -ENOMEM;\n\n\t\t\t\tdelta    += cnt - 1;\n\t\t\t\tenv->prog = prog = new_prog;\n\t\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_lookup_elem,\n\t\t\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_delete_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *key))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_update_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *key, void *value,\n\t\t\t\t\t      u64 flags))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_push_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value,\n\t\t\t\t\t      u64 flags))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_pop_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_peek_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value))NULL));\npatch_map_ops_generic:\n\t\t\tswitch (insn->imm) {\n\t\t\tcase BPF_FUNC_map_lookup_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_lookup_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_update_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_update_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_delete_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_delete_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_push_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_push_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_pop_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_pop_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_peek_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_peek_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tgoto patch_call_imm;\n\t\t}\n\n\t\tif (prog->jit_requested && BITS_PER_LONG == 64 &&\n\t\t    insn->imm == BPF_FUNC_jiffies64) {\n\t\t\tstruct bpf_insn ld_jiffies_addr[2] = {\n\t\t\t\tBPF_LD_IMM64(BPF_REG_0,\n\t\t\t\t\t     (unsigned long)&jiffies),\n\t\t\t};\n\n\t\t\tinsn_buf[0] = ld_jiffies_addr[0];\n\t\t\tinsn_buf[1] = ld_jiffies_addr[1];\n\t\t\tinsn_buf[2] = BPF_LDX_MEM(BPF_DW, BPF_REG_0,\n\t\t\t\t\t\t  BPF_REG_0, 0);\n\t\t\tcnt = 3;\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf,\n\t\t\t\t\t\t       cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\npatch_call_imm:\n\t\tfn = env->ops->get_func_proto(insn->imm, env->prog);\n\t\t/* all functions that have prototype and verifier allowed\n\t\t * programs to call them, must be real in-kernel functions\n\t\t */\n\t\tif (!fn->func) {\n\t\t\tverbose(env,\n\t\t\t\t\"kernel subsystem misconfigured func %s#%d\\n\",\n\t\t\t\tfunc_id_name(insn->imm), insn->imm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tinsn->imm = fn->func - __bpf_call_base;\n\t}\n\n\t/* Since poke tab is now finalized, publish aux to tracker. */\n\tfor (i = 0; i < prog->aux->size_poke_tab; i++) {\n\t\tmap_ptr = prog->aux->poke_tab[i].tail_call.map;\n\t\tif (!map_ptr->ops->map_poke_track ||\n\t\t    !map_ptr->ops->map_poke_untrack ||\n\t\t    !map_ptr->ops->map_poke_run) {\n\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = map_ptr->ops->map_poke_track(map_ptr, prog->aux);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"tracking tail call prog failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int fixup_bpf_calls(struct bpf_verifier_env *env)\n{\n\tstruct bpf_prog *prog = env->prog;\n\tbool expect_blinding = bpf_jit_blinding_enabled(prog);\n\tstruct bpf_insn *insn = prog->insnsi;\n\tconst struct bpf_func_proto *fn;\n\tconst int insn_cnt = prog->len;\n\tconst struct bpf_map_ops *ops;\n\tstruct bpf_insn_aux_data *aux;\n\tstruct bpf_insn insn_buf[16];\n\tstruct bpf_prog *new_prog;\n\tstruct bpf_map *map_ptr;\n\tint i, ret, cnt, delta = 0;\n\n\tfor (i = 0; i < insn_cnt; i++, insn++) {\n\t\tif (insn->code == (BPF_ALU64 | BPF_MOD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU64 | BPF_DIV | BPF_X) ||\n\t\t    insn->code == (BPF_ALU | BPF_MOD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU | BPF_DIV | BPF_X)) {\n\t\t\tbool is64 = BPF_CLASS(insn->code) == BPF_ALU64;\n\t\t\tbool isdiv = BPF_OP(insn->code) == BPF_DIV;\n\t\t\tstruct bpf_insn *patchlet;\n\t\t\tstruct bpf_insn chk_and_div[] = {\n\t\t\t\t/* [R,W]x div 0 -> 0 */\n\t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n\t\t\t\t\t     BPF_JNE | BPF_K, insn->src_reg,\n\t\t\t\t\t     0, 2, 0),\n\t\t\t\tBPF_ALU32_REG(BPF_XOR, insn->dst_reg, insn->dst_reg),\n\t\t\t\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\t\t\t\t*insn,\n\t\t\t};\n\t\t\tstruct bpf_insn chk_and_mod[] = {\n\t\t\t\t/* [R,W]x mod 0 -> [R,W]x */\n\t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n\t\t\t\t\t     BPF_JEQ | BPF_K, insn->src_reg,\n\t\t\t\t\t     0, 1 + (is64 ? 0 : 1), 0),\n\t\t\t\t*insn,\n\t\t\t\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n\t\t\t\tBPF_MOV32_REG(insn->dst_reg, insn->dst_reg),\n\t\t\t};\n\n\t\t\tpatchlet = isdiv ? chk_and_div : chk_and_mod;\n\t\t\tcnt = isdiv ? ARRAY_SIZE(chk_and_div) :\n\t\t\t\t      ARRAY_SIZE(chk_and_mod) - (is64 ? 2 : 0);\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, patchlet, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (BPF_CLASS(insn->code) == BPF_LD &&\n\t\t    (BPF_MODE(insn->code) == BPF_ABS ||\n\t\t     BPF_MODE(insn->code) == BPF_IND)) {\n\t\t\tcnt = env->ops->gen_ld_abs(insn, insn_buf);\n\t\t\tif (cnt == 0 || cnt >= ARRAY_SIZE(insn_buf)) {\n\t\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (insn->code == (BPF_ALU64 | BPF_ADD | BPF_X) ||\n\t\t    insn->code == (BPF_ALU64 | BPF_SUB | BPF_X)) {\n\t\t\tconst u8 code_add = BPF_ALU64 | BPF_ADD | BPF_X;\n\t\t\tconst u8 code_sub = BPF_ALU64 | BPF_SUB | BPF_X;\n\t\t\tstruct bpf_insn insn_buf[16];\n\t\t\tstruct bpf_insn *patch = &insn_buf[0];\n\t\t\tbool issrc, isneg;\n\t\t\tu32 off_reg;\n\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (!aux->alu_state ||\n\t\t\t    aux->alu_state == BPF_ALU_NON_POINTER)\n\t\t\t\tcontinue;\n\n\t\t\tisneg = aux->alu_state & BPF_ALU_NEG_VALUE;\n\t\t\tissrc = (aux->alu_state & BPF_ALU_SANITIZE) ==\n\t\t\t\tBPF_ALU_SANITIZE_SRC;\n\n\t\t\toff_reg = issrc ? insn->src_reg : insn->dst_reg;\n\t\t\tif (isneg)\n\t\t\t\t*patch++ = BPF_ALU64_IMM(BPF_MUL, off_reg, -1);\n\t\t\t*patch++ = BPF_MOV32_IMM(BPF_REG_AX, aux->alu_limit - 1);\n\t\t\t*patch++ = BPF_ALU64_REG(BPF_SUB, BPF_REG_AX, off_reg);\n\t\t\t*patch++ = BPF_ALU64_REG(BPF_OR, BPF_REG_AX, off_reg);\n\t\t\t*patch++ = BPF_ALU64_IMM(BPF_NEG, BPF_REG_AX, 0);\n\t\t\t*patch++ = BPF_ALU64_IMM(BPF_ARSH, BPF_REG_AX, 63);\n\t\t\tif (issrc) {\n\t\t\t\t*patch++ = BPF_ALU64_REG(BPF_AND, BPF_REG_AX,\n\t\t\t\t\t\t\t off_reg);\n\t\t\t\tinsn->src_reg = BPF_REG_AX;\n\t\t\t} else {\n\t\t\t\t*patch++ = BPF_ALU64_REG(BPF_AND, off_reg,\n\t\t\t\t\t\t\t BPF_REG_AX);\n\t\t\t}\n\t\t\tif (isneg)\n\t\t\t\tinsn->code = insn->code == code_add ?\n\t\t\t\t\t     code_sub : code_add;\n\t\t\t*patch++ = *insn;\n\t\t\tif (issrc && isneg)\n\t\t\t\t*patch++ = BPF_ALU64_IMM(BPF_MUL, off_reg, -1);\n\t\t\tcnt = patch - insn_buf;\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (insn->code != (BPF_JMP | BPF_CALL))\n\t\t\tcontinue;\n\t\tif (insn->src_reg == BPF_PSEUDO_CALL)\n\t\t\tcontinue;\n\n\t\tif (insn->imm == BPF_FUNC_get_route_realm)\n\t\t\tprog->dst_needed = 1;\n\t\tif (insn->imm == BPF_FUNC_get_prandom_u32)\n\t\t\tbpf_user_rnd_init_once();\n\t\tif (insn->imm == BPF_FUNC_override_return)\n\t\t\tprog->kprobe_override = 1;\n\t\tif (insn->imm == BPF_FUNC_tail_call) {\n\t\t\t/* If we tail call into other programs, we\n\t\t\t * cannot make any assumptions since they can\n\t\t\t * be replaced dynamically during runtime in\n\t\t\t * the program array.\n\t\t\t */\n\t\t\tprog->cb_access = 1;\n\t\t\tif (!allow_tail_call_in_subprogs(env))\n\t\t\t\tprog->aux->stack_depth = MAX_BPF_STACK;\n\t\t\tprog->aux->max_pkt_offset = MAX_PACKET_OFF;\n\n\t\t\t/* mark bpf_tail_call as different opcode to avoid\n\t\t\t * conditional branch in the interpeter for every normal\n\t\t\t * call and to prevent accidental JITing by JIT compiler\n\t\t\t * that doesn't support bpf_tail_call yet\n\t\t\t */\n\t\t\tinsn->imm = 0;\n\t\t\tinsn->code = BPF_JMP | BPF_TAIL_CALL;\n\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (env->bpf_capable && !expect_blinding &&\n\t\t\t    prog->jit_requested &&\n\t\t\t    !bpf_map_key_poisoned(aux) &&\n\t\t\t    !bpf_map_ptr_poisoned(aux) &&\n\t\t\t    !bpf_map_ptr_unpriv(aux)) {\n\t\t\t\tstruct bpf_jit_poke_descriptor desc = {\n\t\t\t\t\t.reason = BPF_POKE_REASON_TAIL_CALL,\n\t\t\t\t\t.tail_call.map = BPF_MAP_PTR(aux->map_ptr_state),\n\t\t\t\t\t.tail_call.key = bpf_map_key_immediate(aux),\n\t\t\t\t\t.insn_idx = i + delta,\n\t\t\t\t};\n\n\t\t\t\tret = bpf_jit_add_poke_descriptor(prog, &desc);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tverbose(env, \"adding tail call poke descriptor failed\\n\");\n\t\t\t\t\treturn ret;\n\t\t\t\t}\n\n\t\t\t\tinsn->imm = ret + 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!bpf_map_ptr_unpriv(aux))\n\t\t\t\tcontinue;\n\n\t\t\t/* instead of changing every JIT dealing with tail_call\n\t\t\t * emit two extra insns:\n\t\t\t * if (index >= max_entries) goto out;\n\t\t\t * index &= array->index_mask;\n\t\t\t * to avoid out-of-bounds cpu speculation\n\t\t\t */\n\t\t\tif (bpf_map_ptr_poisoned(aux)) {\n\t\t\t\tverbose(env, \"tail_call abusing map_ptr\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tmap_ptr = BPF_MAP_PTR(aux->map_ptr_state);\n\t\t\tinsn_buf[0] = BPF_JMP_IMM(BPF_JGE, BPF_REG_3,\n\t\t\t\t\t\t  map_ptr->max_entries, 2);\n\t\t\tinsn_buf[1] = BPF_ALU32_IMM(BPF_AND, BPF_REG_3,\n\t\t\t\t\t\t    container_of(map_ptr,\n\t\t\t\t\t\t\t\t struct bpf_array,\n\t\t\t\t\t\t\t\t map)->index_mask);\n\t\t\tinsn_buf[2] = *insn;\n\t\t\tcnt = 3;\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf, cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* BPF_EMIT_CALL() assumptions in some of the map_gen_lookup\n\t\t * and other inlining handlers are currently limited to 64 bit\n\t\t * only.\n\t\t */\n\t\tif (prog->jit_requested && BITS_PER_LONG == 64 &&\n\t\t    (insn->imm == BPF_FUNC_map_lookup_elem ||\n\t\t     insn->imm == BPF_FUNC_map_update_elem ||\n\t\t     insn->imm == BPF_FUNC_map_delete_elem ||\n\t\t     insn->imm == BPF_FUNC_map_push_elem   ||\n\t\t     insn->imm == BPF_FUNC_map_pop_elem    ||\n\t\t     insn->imm == BPF_FUNC_map_peek_elem)) {\n\t\t\taux = &env->insn_aux_data[i + delta];\n\t\t\tif (bpf_map_ptr_poisoned(aux))\n\t\t\t\tgoto patch_call_imm;\n\n\t\t\tmap_ptr = BPF_MAP_PTR(aux->map_ptr_state);\n\t\t\tops = map_ptr->ops;\n\t\t\tif (insn->imm == BPF_FUNC_map_lookup_elem &&\n\t\t\t    ops->map_gen_lookup) {\n\t\t\t\tcnt = ops->map_gen_lookup(map_ptr, insn_buf);\n\t\t\t\tif (cnt == -EOPNOTSUPP)\n\t\t\t\t\tgoto patch_map_ops_generic;\n\t\t\t\tif (cnt <= 0 || cnt >= ARRAY_SIZE(insn_buf)) {\n\t\t\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\n\t\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta,\n\t\t\t\t\t\t\t       insn_buf, cnt);\n\t\t\t\tif (!new_prog)\n\t\t\t\t\treturn -ENOMEM;\n\n\t\t\t\tdelta    += cnt - 1;\n\t\t\t\tenv->prog = prog = new_prog;\n\t\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_lookup_elem,\n\t\t\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_delete_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *key))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_update_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *key, void *value,\n\t\t\t\t\t      u64 flags))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_push_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value,\n\t\t\t\t\t      u64 flags))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_pop_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value))NULL));\n\t\t\tBUILD_BUG_ON(!__same_type(ops->map_peek_elem,\n\t\t\t\t     (int (*)(struct bpf_map *map, void *value))NULL));\npatch_map_ops_generic:\n\t\t\tswitch (insn->imm) {\n\t\t\tcase BPF_FUNC_map_lookup_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_lookup_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_update_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_update_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_delete_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_delete_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_push_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_push_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_pop_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_pop_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\tcase BPF_FUNC_map_peek_elem:\n\t\t\t\tinsn->imm = BPF_CAST_CALL(ops->map_peek_elem) -\n\t\t\t\t\t    __bpf_call_base;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tgoto patch_call_imm;\n\t\t}\n\n\t\tif (prog->jit_requested && BITS_PER_LONG == 64 &&\n\t\t    insn->imm == BPF_FUNC_jiffies64) {\n\t\t\tstruct bpf_insn ld_jiffies_addr[2] = {\n\t\t\t\tBPF_LD_IMM64(BPF_REG_0,\n\t\t\t\t\t     (unsigned long)&jiffies),\n\t\t\t};\n\n\t\t\tinsn_buf[0] = ld_jiffies_addr[0];\n\t\t\tinsn_buf[1] = ld_jiffies_addr[1];\n\t\t\tinsn_buf[2] = BPF_LDX_MEM(BPF_DW, BPF_REG_0,\n\t\t\t\t\t\t  BPF_REG_0, 0);\n\t\t\tcnt = 3;\n\n\t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, insn_buf,\n\t\t\t\t\t\t       cnt);\n\t\t\tif (!new_prog)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tdelta    += cnt - 1;\n\t\t\tenv->prog = prog = new_prog;\n\t\t\tinsn      = new_prog->insnsi + i + delta;\n\t\t\tcontinue;\n\t\t}\n\npatch_call_imm:\n\t\tfn = env->ops->get_func_proto(insn->imm, env->prog);\n\t\t/* all functions that have prototype and verifier allowed\n\t\t * programs to call them, must be real in-kernel functions\n\t\t */\n\t\tif (!fn->func) {\n\t\t\tverbose(env,\n\t\t\t\t\"kernel subsystem misconfigured func %s#%d\\n\",\n\t\t\t\tfunc_id_name(insn->imm), insn->imm);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tinsn->imm = fn->func - __bpf_call_base;\n\t}\n\n\t/* Since poke tab is now finalized, publish aux to tracker. */\n\tfor (i = 0; i < prog->aux->size_poke_tab; i++) {\n\t\tmap_ptr = prog->aux->poke_tab[i].tail_call.map;\n\t\tif (!map_ptr->ops->map_poke_track ||\n\t\t    !map_ptr->ops->map_poke_untrack ||\n\t\t    !map_ptr->ops->map_poke_run) {\n\t\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = map_ptr->ops->map_poke_track(map_ptr, prog->aux);\n\t\tif (ret < 0) {\n\t\t\tverbose(env, \"tracking tail call prog failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,7 +21,7 @@\n \t\t\tbool isdiv = BPF_OP(insn->code) == BPF_DIV;\n \t\t\tstruct bpf_insn *patchlet;\n \t\t\tstruct bpf_insn chk_and_div[] = {\n-\t\t\t\t/* Rx div 0 -> 0 */\n+\t\t\t\t/* [R,W]x div 0 -> 0 */\n \t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n \t\t\t\t\t     BPF_JNE | BPF_K, insn->src_reg,\n \t\t\t\t\t     0, 2, 0),\n@@ -30,16 +30,18 @@\n \t\t\t\t*insn,\n \t\t\t};\n \t\t\tstruct bpf_insn chk_and_mod[] = {\n-\t\t\t\t/* Rx mod 0 -> Rx */\n+\t\t\t\t/* [R,W]x mod 0 -> [R,W]x */\n \t\t\t\tBPF_RAW_INSN((is64 ? BPF_JMP : BPF_JMP32) |\n \t\t\t\t\t     BPF_JEQ | BPF_K, insn->src_reg,\n-\t\t\t\t\t     0, 1, 0),\n+\t\t\t\t\t     0, 1 + (is64 ? 0 : 1), 0),\n \t\t\t\t*insn,\n+\t\t\t\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),\n+\t\t\t\tBPF_MOV32_REG(insn->dst_reg, insn->dst_reg),\n \t\t\t};\n \n \t\t\tpatchlet = isdiv ? chk_and_div : chk_and_mod;\n \t\t\tcnt = isdiv ? ARRAY_SIZE(chk_and_div) :\n-\t\t\t\t      ARRAY_SIZE(chk_and_mod);\n+\t\t\t\t      ARRAY_SIZE(chk_and_mod) - (is64 ? 2 : 0);\n \n \t\t\tnew_prog = bpf_patch_insn_data(env, i + delta, patchlet, cnt);\n \t\t\tif (!new_prog)",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t/* [R,W]x div 0 -> 0 */",
                "\t\t\t\t/* [R,W]x mod 0 -> [R,W]x */",
                "\t\t\t\t\t     0, 1 + (is64 ? 0 : 1), 0),",
                "\t\t\t\tBPF_JMP_IMM(BPF_JA, 0, 0, 1),",
                "\t\t\t\tBPF_MOV32_REG(insn->dst_reg, insn->dst_reg),",
                "\t\t\t\t      ARRAY_SIZE(chk_and_mod) - (is64 ? 2 : 0);"
            ],
            "deleted": [
                "\t\t\t\t/* Rx div 0 -> 0 */",
                "\t\t\t\t/* Rx mod 0 -> Rx */",
                "\t\t\t\t\t     0, 1, 0),",
                "\t\t\t\t      ARRAY_SIZE(chk_and_mod);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-681"
        ],
        "cve_description": "The bpf verifier in the Linux kernel did not properly handle mod32 destination register truncation when the source register was known to be 0. A local attacker with the ability to load bpf programs could use this gain out-of-bounds reads in kernel memory leading to information disclosure (kernel memory), and possibly out-of-bounds writes that could potentially lead to code execution. This issue was addressed in the upstream kernel in commit 9b00f1b78809 (\"bpf: Fix truncation handling for mod32 dst reg wrt zero\") and in Linux stable kernels 5.11.2, 5.10.19, and 5.4.101.",
        "id": 2990
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "int indx_init(struct ntfs_index *indx, struct ntfs_sb_info *sbi,\n\t      const struct ATTRIB *attr, enum index_mutex_classed type)\n{\n\tu32 t32;\n\tconst struct INDEX_ROOT *root = resident_data(attr);\n\n\t/* Check root fields. */\n\tif (!root->index_block_clst)\n\t\treturn -EINVAL;\n\n\tindx->type = type;\n\tindx->idx2vbn_bits = __ffs(root->index_block_clst);\n\n\tt32 = le32_to_cpu(root->index_block_size);\n\tindx->index_bits = blksize_bits(t32);\n\n\t/* Check index record size. */\n\tif (t32 < sbi->cluster_size) {\n\t\t/* Index record is smaller than a cluster, use 512 blocks. */\n\t\tif (t32 != root->index_block_clst * SECTOR_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\t/* Check alignment to a cluster. */\n\t\tif ((sbi->cluster_size >> SECTOR_SHIFT) &\n\t\t    (root->index_block_clst - 1)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tindx->vbn2vbo_bits = SECTOR_SHIFT;\n\t} else {\n\t\t/* Index record must be a multiple of cluster size. */\n\t\tif (t32 != root->index_block_clst << sbi->cluster_bits)\n\t\t\treturn -EINVAL;\n\n\t\tindx->vbn2vbo_bits = sbi->cluster_bits;\n\t}\n\n\tinit_rwsem(&indx->run_lock);\n\n\tindx->cmp = get_cmp_func(root);\n\treturn indx->cmp ? 0 : -EINVAL;\n}",
        "code_after_change": "int indx_init(struct ntfs_index *indx, struct ntfs_sb_info *sbi,\n\t      const struct ATTRIB *attr, enum index_mutex_classed type)\n{\n\tu32 t32;\n\tconst struct INDEX_ROOT *root = resident_data(attr);\n\n\tt32 = le32_to_cpu(attr->res.data_size);\n\tif (t32 <= offsetof(struct INDEX_ROOT, ihdr) ||\n\t    !index_hdr_check(&root->ihdr,\n\t\t\t     t32 - offsetof(struct INDEX_ROOT, ihdr))) {\n\t\tgoto out;\n\t}\n\n\t/* Check root fields. */\n\tif (!root->index_block_clst)\n\t\tgoto out;\n\n\tindx->type = type;\n\tindx->idx2vbn_bits = __ffs(root->index_block_clst);\n\n\tt32 = le32_to_cpu(root->index_block_size);\n\tindx->index_bits = blksize_bits(t32);\n\n\t/* Check index record size. */\n\tif (t32 < sbi->cluster_size) {\n\t\t/* Index record is smaller than a cluster, use 512 blocks. */\n\t\tif (t32 != root->index_block_clst * SECTOR_SIZE)\n\t\t\tgoto out;\n\n\t\t/* Check alignment to a cluster. */\n\t\tif ((sbi->cluster_size >> SECTOR_SHIFT) &\n\t\t    (root->index_block_clst - 1)) {\n\t\t\tgoto out;\n\t\t}\n\n\t\tindx->vbn2vbo_bits = SECTOR_SHIFT;\n\t} else {\n\t\t/* Index record must be a multiple of cluster size. */\n\t\tif (t32 != root->index_block_clst << sbi->cluster_bits)\n\t\t\tgoto out;\n\n\t\tindx->vbn2vbo_bits = sbi->cluster_bits;\n\t}\n\n\tinit_rwsem(&indx->run_lock);\n\n\tindx->cmp = get_cmp_func(root);\n\tif (!indx->cmp)\n\t\tgoto out;\n\n\treturn 0;\n\nout:\n\tntfs_set_state(sbi, NTFS_DIRTY_DIRTY);\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,9 +4,16 @@\n \tu32 t32;\n \tconst struct INDEX_ROOT *root = resident_data(attr);\n \n+\tt32 = le32_to_cpu(attr->res.data_size);\n+\tif (t32 <= offsetof(struct INDEX_ROOT, ihdr) ||\n+\t    !index_hdr_check(&root->ihdr,\n+\t\t\t     t32 - offsetof(struct INDEX_ROOT, ihdr))) {\n+\t\tgoto out;\n+\t}\n+\n \t/* Check root fields. */\n \tif (!root->index_block_clst)\n-\t\treturn -EINVAL;\n+\t\tgoto out;\n \n \tindx->type = type;\n \tindx->idx2vbn_bits = __ffs(root->index_block_clst);\n@@ -18,19 +25,19 @@\n \tif (t32 < sbi->cluster_size) {\n \t\t/* Index record is smaller than a cluster, use 512 blocks. */\n \t\tif (t32 != root->index_block_clst * SECTOR_SIZE)\n-\t\t\treturn -EINVAL;\n+\t\t\tgoto out;\n \n \t\t/* Check alignment to a cluster. */\n \t\tif ((sbi->cluster_size >> SECTOR_SHIFT) &\n \t\t    (root->index_block_clst - 1)) {\n-\t\t\treturn -EINVAL;\n+\t\t\tgoto out;\n \t\t}\n \n \t\tindx->vbn2vbo_bits = SECTOR_SHIFT;\n \t} else {\n \t\t/* Index record must be a multiple of cluster size. */\n \t\tif (t32 != root->index_block_clst << sbi->cluster_bits)\n-\t\t\treturn -EINVAL;\n+\t\t\tgoto out;\n \n \t\tindx->vbn2vbo_bits = sbi->cluster_bits;\n \t}\n@@ -38,5 +45,12 @@\n \tinit_rwsem(&indx->run_lock);\n \n \tindx->cmp = get_cmp_func(root);\n-\treturn indx->cmp ? 0 : -EINVAL;\n+\tif (!indx->cmp)\n+\t\tgoto out;\n+\n+\treturn 0;\n+\n+out:\n+\tntfs_set_state(sbi, NTFS_DIRTY_DIRTY);\n+\treturn -EINVAL;\n }",
        "function_modified_lines": {
            "added": [
                "\tt32 = le32_to_cpu(attr->res.data_size);",
                "\tif (t32 <= offsetof(struct INDEX_ROOT, ihdr) ||",
                "\t    !index_hdr_check(&root->ihdr,",
                "\t\t\t     t32 - offsetof(struct INDEX_ROOT, ihdr))) {",
                "\t\tgoto out;",
                "\t}",
                "",
                "\t\tgoto out;",
                "\t\t\tgoto out;",
                "\t\t\tgoto out;",
                "\t\t\tgoto out;",
                "\tif (!indx->cmp)",
                "\t\tgoto out;",
                "",
                "\treturn 0;",
                "",
                "out:",
                "\tntfs_set_state(sbi, NTFS_DIRTY_DIRTY);",
                "\treturn -EINVAL;"
            ],
            "deleted": [
                "\t\treturn -EINVAL;",
                "\t\t\treturn -EINVAL;",
                "\t\t\treturn -EINVAL;",
                "\t\t\treturn -EINVAL;",
                "\treturn indx->cmp ? 0 : -EINVAL;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3794
    },
    {
        "cve_id": "CVE-2017-7558",
        "code_before_change": "int sctp_get_sctp_info(struct sock *sk, struct sctp_association *asoc,\n\t\t       struct sctp_info *info)\n{\n\tstruct sctp_transport *prim;\n\tstruct list_head *pos;\n\tint mask;\n\n\tmemset(info, 0, sizeof(*info));\n\tif (!asoc) {\n\t\tstruct sctp_sock *sp = sctp_sk(sk);\n\n\t\tinfo->sctpi_s_autoclose = sp->autoclose;\n\t\tinfo->sctpi_s_adaptation_ind = sp->adaptation_ind;\n\t\tinfo->sctpi_s_pd_point = sp->pd_point;\n\t\tinfo->sctpi_s_nodelay = sp->nodelay;\n\t\tinfo->sctpi_s_disable_fragments = sp->disable_fragments;\n\t\tinfo->sctpi_s_v4mapped = sp->v4mapped;\n\t\tinfo->sctpi_s_frag_interleave = sp->frag_interleave;\n\t\tinfo->sctpi_s_type = sp->type;\n\n\t\treturn 0;\n\t}\n\n\tinfo->sctpi_tag = asoc->c.my_vtag;\n\tinfo->sctpi_state = asoc->state;\n\tinfo->sctpi_rwnd = asoc->a_rwnd;\n\tinfo->sctpi_unackdata = asoc->unack_data;\n\tinfo->sctpi_penddata = sctp_tsnmap_pending(&asoc->peer.tsn_map);\n\tinfo->sctpi_instrms = asoc->stream.incnt;\n\tinfo->sctpi_outstrms = asoc->stream.outcnt;\n\tlist_for_each(pos, &asoc->base.inqueue.in_chunk_list)\n\t\tinfo->sctpi_inqueue++;\n\tlist_for_each(pos, &asoc->outqueue.out_chunk_list)\n\t\tinfo->sctpi_outqueue++;\n\tinfo->sctpi_overall_error = asoc->overall_error_count;\n\tinfo->sctpi_max_burst = asoc->max_burst;\n\tinfo->sctpi_maxseg = asoc->frag_point;\n\tinfo->sctpi_peer_rwnd = asoc->peer.rwnd;\n\tinfo->sctpi_peer_tag = asoc->c.peer_vtag;\n\n\tmask = asoc->peer.ecn_capable << 1;\n\tmask = (mask | asoc->peer.ipv4_address) << 1;\n\tmask = (mask | asoc->peer.ipv6_address) << 1;\n\tmask = (mask | asoc->peer.hostname_address) << 1;\n\tmask = (mask | asoc->peer.asconf_capable) << 1;\n\tmask = (mask | asoc->peer.prsctp_capable) << 1;\n\tmask = (mask | asoc->peer.auth_capable);\n\tinfo->sctpi_peer_capable = mask;\n\tmask = asoc->peer.sack_needed << 1;\n\tmask = (mask | asoc->peer.sack_generation) << 1;\n\tmask = (mask | asoc->peer.zero_window_announced);\n\tinfo->sctpi_peer_sack = mask;\n\n\tinfo->sctpi_isacks = asoc->stats.isacks;\n\tinfo->sctpi_osacks = asoc->stats.osacks;\n\tinfo->sctpi_opackets = asoc->stats.opackets;\n\tinfo->sctpi_ipackets = asoc->stats.ipackets;\n\tinfo->sctpi_rtxchunks = asoc->stats.rtxchunks;\n\tinfo->sctpi_outofseqtsns = asoc->stats.outofseqtsns;\n\tinfo->sctpi_idupchunks = asoc->stats.idupchunks;\n\tinfo->sctpi_gapcnt = asoc->stats.gapcnt;\n\tinfo->sctpi_ouodchunks = asoc->stats.ouodchunks;\n\tinfo->sctpi_iuodchunks = asoc->stats.iuodchunks;\n\tinfo->sctpi_oodchunks = asoc->stats.oodchunks;\n\tinfo->sctpi_iodchunks = asoc->stats.iodchunks;\n\tinfo->sctpi_octrlchunks = asoc->stats.octrlchunks;\n\tinfo->sctpi_ictrlchunks = asoc->stats.ictrlchunks;\n\n\tprim = asoc->peer.primary_path;\n\tmemcpy(&info->sctpi_p_address, &prim->ipaddr,\n\t       sizeof(struct sockaddr_storage));\n\tinfo->sctpi_p_state = prim->state;\n\tinfo->sctpi_p_cwnd = prim->cwnd;\n\tinfo->sctpi_p_srtt = prim->srtt;\n\tinfo->sctpi_p_rto = jiffies_to_msecs(prim->rto);\n\tinfo->sctpi_p_hbinterval = prim->hbinterval;\n\tinfo->sctpi_p_pathmaxrxt = prim->pathmaxrxt;\n\tinfo->sctpi_p_sackdelay = jiffies_to_msecs(prim->sackdelay);\n\tinfo->sctpi_p_ssthresh = prim->ssthresh;\n\tinfo->sctpi_p_partial_bytes_acked = prim->partial_bytes_acked;\n\tinfo->sctpi_p_flight_size = prim->flight_size;\n\tinfo->sctpi_p_error = prim->error_count;\n\n\treturn 0;\n}",
        "code_after_change": "int sctp_get_sctp_info(struct sock *sk, struct sctp_association *asoc,\n\t\t       struct sctp_info *info)\n{\n\tstruct sctp_transport *prim;\n\tstruct list_head *pos;\n\tint mask;\n\n\tmemset(info, 0, sizeof(*info));\n\tif (!asoc) {\n\t\tstruct sctp_sock *sp = sctp_sk(sk);\n\n\t\tinfo->sctpi_s_autoclose = sp->autoclose;\n\t\tinfo->sctpi_s_adaptation_ind = sp->adaptation_ind;\n\t\tinfo->sctpi_s_pd_point = sp->pd_point;\n\t\tinfo->sctpi_s_nodelay = sp->nodelay;\n\t\tinfo->sctpi_s_disable_fragments = sp->disable_fragments;\n\t\tinfo->sctpi_s_v4mapped = sp->v4mapped;\n\t\tinfo->sctpi_s_frag_interleave = sp->frag_interleave;\n\t\tinfo->sctpi_s_type = sp->type;\n\n\t\treturn 0;\n\t}\n\n\tinfo->sctpi_tag = asoc->c.my_vtag;\n\tinfo->sctpi_state = asoc->state;\n\tinfo->sctpi_rwnd = asoc->a_rwnd;\n\tinfo->sctpi_unackdata = asoc->unack_data;\n\tinfo->sctpi_penddata = sctp_tsnmap_pending(&asoc->peer.tsn_map);\n\tinfo->sctpi_instrms = asoc->stream.incnt;\n\tinfo->sctpi_outstrms = asoc->stream.outcnt;\n\tlist_for_each(pos, &asoc->base.inqueue.in_chunk_list)\n\t\tinfo->sctpi_inqueue++;\n\tlist_for_each(pos, &asoc->outqueue.out_chunk_list)\n\t\tinfo->sctpi_outqueue++;\n\tinfo->sctpi_overall_error = asoc->overall_error_count;\n\tinfo->sctpi_max_burst = asoc->max_burst;\n\tinfo->sctpi_maxseg = asoc->frag_point;\n\tinfo->sctpi_peer_rwnd = asoc->peer.rwnd;\n\tinfo->sctpi_peer_tag = asoc->c.peer_vtag;\n\n\tmask = asoc->peer.ecn_capable << 1;\n\tmask = (mask | asoc->peer.ipv4_address) << 1;\n\tmask = (mask | asoc->peer.ipv6_address) << 1;\n\tmask = (mask | asoc->peer.hostname_address) << 1;\n\tmask = (mask | asoc->peer.asconf_capable) << 1;\n\tmask = (mask | asoc->peer.prsctp_capable) << 1;\n\tmask = (mask | asoc->peer.auth_capable);\n\tinfo->sctpi_peer_capable = mask;\n\tmask = asoc->peer.sack_needed << 1;\n\tmask = (mask | asoc->peer.sack_generation) << 1;\n\tmask = (mask | asoc->peer.zero_window_announced);\n\tinfo->sctpi_peer_sack = mask;\n\n\tinfo->sctpi_isacks = asoc->stats.isacks;\n\tinfo->sctpi_osacks = asoc->stats.osacks;\n\tinfo->sctpi_opackets = asoc->stats.opackets;\n\tinfo->sctpi_ipackets = asoc->stats.ipackets;\n\tinfo->sctpi_rtxchunks = asoc->stats.rtxchunks;\n\tinfo->sctpi_outofseqtsns = asoc->stats.outofseqtsns;\n\tinfo->sctpi_idupchunks = asoc->stats.idupchunks;\n\tinfo->sctpi_gapcnt = asoc->stats.gapcnt;\n\tinfo->sctpi_ouodchunks = asoc->stats.ouodchunks;\n\tinfo->sctpi_iuodchunks = asoc->stats.iuodchunks;\n\tinfo->sctpi_oodchunks = asoc->stats.oodchunks;\n\tinfo->sctpi_iodchunks = asoc->stats.iodchunks;\n\tinfo->sctpi_octrlchunks = asoc->stats.octrlchunks;\n\tinfo->sctpi_ictrlchunks = asoc->stats.ictrlchunks;\n\n\tprim = asoc->peer.primary_path;\n\tmemcpy(&info->sctpi_p_address, &prim->ipaddr, sizeof(prim->ipaddr));\n\tinfo->sctpi_p_state = prim->state;\n\tinfo->sctpi_p_cwnd = prim->cwnd;\n\tinfo->sctpi_p_srtt = prim->srtt;\n\tinfo->sctpi_p_rto = jiffies_to_msecs(prim->rto);\n\tinfo->sctpi_p_hbinterval = prim->hbinterval;\n\tinfo->sctpi_p_pathmaxrxt = prim->pathmaxrxt;\n\tinfo->sctpi_p_sackdelay = jiffies_to_msecs(prim->sackdelay);\n\tinfo->sctpi_p_ssthresh = prim->ssthresh;\n\tinfo->sctpi_p_partial_bytes_acked = prim->partial_bytes_acked;\n\tinfo->sctpi_p_flight_size = prim->flight_size;\n\tinfo->sctpi_p_error = prim->error_count;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -67,8 +67,7 @@\n \tinfo->sctpi_ictrlchunks = asoc->stats.ictrlchunks;\n \n \tprim = asoc->peer.primary_path;\n-\tmemcpy(&info->sctpi_p_address, &prim->ipaddr,\n-\t       sizeof(struct sockaddr_storage));\n+\tmemcpy(&info->sctpi_p_address, &prim->ipaddr, sizeof(prim->ipaddr));\n \tinfo->sctpi_p_state = prim->state;\n \tinfo->sctpi_p_cwnd = prim->cwnd;\n \tinfo->sctpi_p_srtt = prim->srtt;",
        "function_modified_lines": {
            "added": [
                "\tmemcpy(&info->sctpi_p_address, &prim->ipaddr, sizeof(prim->ipaddr));"
            ],
            "deleted": [
                "\tmemcpy(&info->sctpi_p_address, &prim->ipaddr,",
                "\t       sizeof(struct sockaddr_storage));"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A kernel data leak due to an out-of-bound read was found in the Linux kernel in inet_diag_msg_sctp{,l}addr_fill() and sctp_get_sctp_info() functions present since version 4.7-rc1 through version 4.13. A data leak happens when these functions fill in sockaddr data structures used to export socket's diagnostic information. As a result, up to 100 bytes of the slab data could be leaked to a userspace.",
        "id": 1517
    },
    {
        "cve_id": "CVE-2021-4093",
        "code_before_change": "int kvm_sev_es_string_io(struct kvm_vcpu *vcpu, unsigned int size,\n\t\t\t unsigned int port, void *data,  unsigned int count,\n\t\t\t int in)\n{\n\tvcpu->arch.sev_pio_data = data;\n\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)\n\t\t  : kvm_sev_es_outs(vcpu, size, port, count);\n}",
        "code_after_change": "int kvm_sev_es_string_io(struct kvm_vcpu *vcpu, unsigned int size,\n\t\t\t unsigned int port, void *data,  unsigned int count,\n\t\t\t int in)\n{\n\tvcpu->arch.sev_pio_data = data;\n\tvcpu->arch.sev_pio_count = count;\n\treturn in ? kvm_sev_es_ins(vcpu, size, port)\n\t\t  : kvm_sev_es_outs(vcpu, size, port);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n \t\t\t int in)\n {\n \tvcpu->arch.sev_pio_data = data;\n-\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)\n-\t\t  : kvm_sev_es_outs(vcpu, size, port, count);\n+\tvcpu->arch.sev_pio_count = count;\n+\treturn in ? kvm_sev_es_ins(vcpu, size, port)\n+\t\t  : kvm_sev_es_outs(vcpu, size, port);\n }",
        "function_modified_lines": {
            "added": [
                "\tvcpu->arch.sev_pio_count = count;",
                "\treturn in ? kvm_sev_es_ins(vcpu, size, port)",
                "\t\t  : kvm_sev_es_outs(vcpu, size, port);"
            ],
            "deleted": [
                "\treturn in ? kvm_sev_es_ins(vcpu, size, port, count)",
                "\t\t  : kvm_sev_es_outs(vcpu, size, port, count);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the KVM's AMD code for supporting the Secure Encrypted Virtualization-Encrypted State (SEV-ES). A KVM guest using SEV-ES can trigger out-of-bounds reads and writes in the host kernel via a malicious VMGEXIT for a string I/O instruction (for example, outs or ins) using the exit reason SVM_EXIT_IOIO. This issue results in a crash of the entire system or a potential guest-to-host escape scenario.",
        "id": 3131
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "int io_mem_abort(struct kvm_vcpu *vcpu, struct kvm_run *run,\n\t\t phys_addr_t fault_ipa)\n{\n\tunsigned long data;\n\tunsigned long rt;\n\tint ret;\n\tbool is_write;\n\tint len;\n\tu8 data_buf[8];\n\n\t/*\n\t * Prepare MMIO operation. First decode the syndrome data we get\n\t * from the CPU. Then try if some in-kernel emulation feels\n\t * responsible, otherwise let user space do its magic.\n\t */\n\tif (kvm_vcpu_dabt_isvalid(vcpu)) {\n\t\tret = decode_hsr(vcpu, &is_write, &len);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tkvm_err(\"load/store instruction decoding not implemented\\n\");\n\t\treturn -ENOSYS;\n\t}\n\n\trt = vcpu->arch.mmio_decode.rt;\n\n\tif (is_write) {\n\t\tdata = vcpu_data_guest_to_host(vcpu, vcpu_get_reg(vcpu, rt),\n\t\t\t\t\t       len);\n\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, data);\n\t\tkvm_mmio_write_buf(data_buf, len, data);\n\n\t\tret = kvm_io_bus_write(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n\t\t\t\t       data_buf);\n\t} else {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, len,\n\t\t\t       fault_ipa, 0);\n\n\t\tret = kvm_io_bus_read(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n\t\t\t\t      data_buf);\n\t}\n\n\t/* Now prepare kvm_run for the potential return to userland. */\n\trun->mmio.is_write\t= is_write;\n\trun->mmio.phys_addr\t= fault_ipa;\n\trun->mmio.len\t\t= len;\n\n\tif (!ret) {\n\t\t/* We handled the access successfully in the kernel. */\n\t\tif (!is_write)\n\t\t\tmemcpy(run->mmio.data, data_buf, len);\n\t\tvcpu->stat.mmio_exit_kernel++;\n\t\tkvm_handle_mmio_return(vcpu, run);\n\t\treturn 1;\n\t}\n\n\tif (is_write)\n\t\tmemcpy(run->mmio.data, data_buf, len);\n\tvcpu->stat.mmio_exit_user++;\n\trun->exit_reason\t= KVM_EXIT_MMIO;\n\treturn 0;\n}",
        "code_after_change": "int io_mem_abort(struct kvm_vcpu *vcpu, struct kvm_run *run,\n\t\t phys_addr_t fault_ipa)\n{\n\tunsigned long data;\n\tunsigned long rt;\n\tint ret;\n\tbool is_write;\n\tint len;\n\tu8 data_buf[8];\n\n\t/*\n\t * Prepare MMIO operation. First decode the syndrome data we get\n\t * from the CPU. Then try if some in-kernel emulation feels\n\t * responsible, otherwise let user space do its magic.\n\t */\n\tif (kvm_vcpu_dabt_isvalid(vcpu)) {\n\t\tret = decode_hsr(vcpu, &is_write, &len);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tkvm_err(\"load/store instruction decoding not implemented\\n\");\n\t\treturn -ENOSYS;\n\t}\n\n\trt = vcpu->arch.mmio_decode.rt;\n\n\tif (is_write) {\n\t\tdata = vcpu_data_guest_to_host(vcpu, vcpu_get_reg(vcpu, rt),\n\t\t\t\t\t       len);\n\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, &data);\n\t\tkvm_mmio_write_buf(data_buf, len, data);\n\n\t\tret = kvm_io_bus_write(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n\t\t\t\t       data_buf);\n\t} else {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, len,\n\t\t\t       fault_ipa, NULL);\n\n\t\tret = kvm_io_bus_read(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n\t\t\t\t      data_buf);\n\t}\n\n\t/* Now prepare kvm_run for the potential return to userland. */\n\trun->mmio.is_write\t= is_write;\n\trun->mmio.phys_addr\t= fault_ipa;\n\trun->mmio.len\t\t= len;\n\n\tif (!ret) {\n\t\t/* We handled the access successfully in the kernel. */\n\t\tif (!is_write)\n\t\t\tmemcpy(run->mmio.data, data_buf, len);\n\t\tvcpu->stat.mmio_exit_kernel++;\n\t\tkvm_handle_mmio_return(vcpu, run);\n\t\treturn 1;\n\t}\n\n\tif (is_write)\n\t\tmemcpy(run->mmio.data, data_buf, len);\n\tvcpu->stat.mmio_exit_user++;\n\trun->exit_reason\t= KVM_EXIT_MMIO;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,14 +28,14 @@\n \t\tdata = vcpu_data_guest_to_host(vcpu, vcpu_get_reg(vcpu, rt),\n \t\t\t\t\t       len);\n \n-\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, data);\n+\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, &data);\n \t\tkvm_mmio_write_buf(data_buf, len, data);\n \n \t\tret = kvm_io_bus_write(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n \t\t\t\t       data_buf);\n \t} else {\n \t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, len,\n-\t\t\t       fault_ipa, 0);\n+\t\t\t       fault_ipa, NULL);\n \n \t\tret = kvm_io_bus_read(vcpu, KVM_MMIO_BUS, fault_ipa, len,\n \t\t\t\t      data_buf);",
        "function_modified_lines": {
            "added": [
                "\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, &data);",
                "\t\t\t       fault_ipa, NULL);"
            ],
            "deleted": [
                "\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_WRITE, len, fault_ipa, data);",
                "\t\t\t       fault_ipa, 0);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1372
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "int kvm_handle_mmio_return(struct kvm_vcpu *vcpu, struct kvm_run *run)\n{\n\tunsigned long data;\n\tunsigned int len;\n\tint mask;\n\n\tif (!run->mmio.is_write) {\n\t\tlen = run->mmio.len;\n\t\tif (len > sizeof(unsigned long))\n\t\t\treturn -EINVAL;\n\n\t\tdata = kvm_mmio_read_buf(run->mmio.data, len);\n\n\t\tif (vcpu->arch.mmio_decode.sign_extend &&\n\t\t    len < sizeof(unsigned long)) {\n\t\t\tmask = 1U << ((len * 8) - 1);\n\t\t\tdata = (data ^ mask) - mask;\n\t\t}\n\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, len, run->mmio.phys_addr,\n\t\t\t       data);\n\t\tdata = vcpu_data_host_to_guest(vcpu, data, len);\n\t\tvcpu_set_reg(vcpu, vcpu->arch.mmio_decode.rt, data);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "int kvm_handle_mmio_return(struct kvm_vcpu *vcpu, struct kvm_run *run)\n{\n\tunsigned long data;\n\tunsigned int len;\n\tint mask;\n\n\tif (!run->mmio.is_write) {\n\t\tlen = run->mmio.len;\n\t\tif (len > sizeof(unsigned long))\n\t\t\treturn -EINVAL;\n\n\t\tdata = kvm_mmio_read_buf(run->mmio.data, len);\n\n\t\tif (vcpu->arch.mmio_decode.sign_extend &&\n\t\t    len < sizeof(unsigned long)) {\n\t\t\tmask = 1U << ((len * 8) - 1);\n\t\t\tdata = (data ^ mask) - mask;\n\t\t}\n\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, len, run->mmio.phys_addr,\n\t\t\t       &data);\n\t\tdata = vcpu_data_host_to_guest(vcpu, data, len);\n\t\tvcpu_set_reg(vcpu, vcpu->arch.mmio_decode.rt, data);\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t\t}\n \n \t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, len, run->mmio.phys_addr,\n-\t\t\t       data);\n+\t\t\t       &data);\n \t\tdata = vcpu_data_host_to_guest(vcpu, data, len);\n \t\tvcpu_set_reg(vcpu, vcpu->arch.mmio_decode.rt, data);\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t       &data);"
            ],
            "deleted": [
                "\t\t\t       data);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1371
    },
    {
        "cve_id": "CVE-2018-13099",
        "code_before_change": "static int f2fs_move_inline_dirents(struct inode *dir, struct page *ipage,\n\t\t\t\t\t\t\tvoid *inline_dentry)\n{\n\tstruct page *page;\n\tstruct dnode_of_data dn;\n\tstruct f2fs_dentry_block *dentry_blk;\n\tstruct f2fs_dentry_ptr src, dst;\n\tint err;\n\n\tpage = f2fs_grab_cache_page(dir->i_mapping, 0, false);\n\tif (!page) {\n\t\tf2fs_put_page(ipage, 1);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_new_dnode(&dn, dir, ipage, NULL, 0);\n\terr = f2fs_reserve_block(&dn, 0);\n\tif (err)\n\t\tgoto out;\n\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\n\tdentry_blk = page_address(page);\n\n\tmake_dentry_ptr_inline(dir, &src, inline_dentry);\n\tmake_dentry_ptr_block(dir, &dst, dentry_blk);\n\n\t/* copy data from inline dentry block to new dentry block */\n\tmemcpy(dst.bitmap, src.bitmap, src.nr_bitmap);\n\tmemset(dst.bitmap + src.nr_bitmap, 0, dst.nr_bitmap - src.nr_bitmap);\n\t/*\n\t * we do not need to zero out remainder part of dentry and filename\n\t * field, since we have used bitmap for marking the usage status of\n\t * them, besides, we can also ignore copying/zeroing reserved space\n\t * of dentry block, because them haven't been used so far.\n\t */\n\tmemcpy(dst.dentry, src.dentry, SIZE_OF_DIR_ENTRY * src.max);\n\tmemcpy(dst.filename, src.filename, src.max * F2FS_SLOT_LEN);\n\n\tif (!PageUptodate(page))\n\t\tSetPageUptodate(page);\n\tset_page_dirty(page);\n\n\t/* clear inline dir and flag after data writeback */\n\tf2fs_truncate_inline_inode(dir, ipage, 0);\n\n\tstat_dec_inline_dir(dir);\n\tclear_inode_flag(dir, FI_INLINE_DENTRY);\n\n\tf2fs_i_depth_write(dir, 1);\n\tif (i_size_read(dir) < PAGE_SIZE)\n\t\tf2fs_i_size_write(dir, PAGE_SIZE);\nout:\n\tf2fs_put_page(page, 1);\n\treturn err;\n}",
        "code_after_change": "static int f2fs_move_inline_dirents(struct inode *dir, struct page *ipage,\n\t\t\t\t\t\t\tvoid *inline_dentry)\n{\n\tstruct page *page;\n\tstruct dnode_of_data dn;\n\tstruct f2fs_dentry_block *dentry_blk;\n\tstruct f2fs_dentry_ptr src, dst;\n\tint err;\n\n\tpage = f2fs_grab_cache_page(dir->i_mapping, 0, false);\n\tif (!page) {\n\t\tf2fs_put_page(ipage, 1);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_new_dnode(&dn, dir, ipage, NULL, 0);\n\terr = f2fs_reserve_block(&dn, 0);\n\tif (err)\n\t\tgoto out;\n\n\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {\n\t\tf2fs_put_dnode(&dn);\n\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);\n\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, dir->i_ino, dn.data_blkaddr);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\n\tdentry_blk = page_address(page);\n\n\tmake_dentry_ptr_inline(dir, &src, inline_dentry);\n\tmake_dentry_ptr_block(dir, &dst, dentry_blk);\n\n\t/* copy data from inline dentry block to new dentry block */\n\tmemcpy(dst.bitmap, src.bitmap, src.nr_bitmap);\n\tmemset(dst.bitmap + src.nr_bitmap, 0, dst.nr_bitmap - src.nr_bitmap);\n\t/*\n\t * we do not need to zero out remainder part of dentry and filename\n\t * field, since we have used bitmap for marking the usage status of\n\t * them, besides, we can also ignore copying/zeroing reserved space\n\t * of dentry block, because them haven't been used so far.\n\t */\n\tmemcpy(dst.dentry, src.dentry, SIZE_OF_DIR_ENTRY * src.max);\n\tmemcpy(dst.filename, src.filename, src.max * F2FS_SLOT_LEN);\n\n\tif (!PageUptodate(page))\n\t\tSetPageUptodate(page);\n\tset_page_dirty(page);\n\n\t/* clear inline dir and flag after data writeback */\n\tf2fs_truncate_inline_inode(dir, ipage, 0);\n\n\tstat_dec_inline_dir(dir);\n\tclear_inode_flag(dir, FI_INLINE_DENTRY);\n\n\tf2fs_i_depth_write(dir, 1);\n\tif (i_size_read(dir) < PAGE_SIZE)\n\t\tf2fs_i_size_write(dir, PAGE_SIZE);\nout:\n\tf2fs_put_page(page, 1);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,17 @@\n \terr = f2fs_reserve_block(&dn, 0);\n \tif (err)\n \t\tgoto out;\n+\n+\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {\n+\t\tf2fs_put_dnode(&dn);\n+\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);\n+\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,\n+\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n+\t\t\t\"run fsck to fix.\",\n+\t\t\t__func__, dir->i_ino, dn.data_blkaddr);\n+\t\terr = -EINVAL;\n+\t\tgoto out;\n+\t}\n \n \tf2fs_wait_on_page_writeback(page, DATA, true);\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {",
                "\t\tf2fs_put_dnode(&dn);",
                "\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);",
                "\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,",
                "\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"",
                "\t\t\t\"run fsck to fix.\",",
                "\t\t\t__func__, dir->i_ino, dn.data_blkaddr);",
                "\t\terr = -EINVAL;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inline.c in the Linux kernel through 4.4. A denial of service (out-of-bounds memory access and BUG) can occur for a modified f2fs filesystem image in which an inline inode contains an invalid reserved blkaddr.",
        "id": 1673
    },
    {
        "cve_id": "CVE-2016-9777",
        "code_before_change": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}",
        "code_after_change": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,5 @@\n static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n {\n \tioapic->rtc_status.pending_eoi = 0;\n-\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n+\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n }",
        "function_modified_lines": {
            "added": [
                "\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);"
            ],
            "deleted": [
                "\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "KVM in the Linux kernel before 4.8.12, when I/O APIC is enabled, does not properly restrict the VCPU index, which allows guest OS users to gain host OS privileges or cause a denial of service (out-of-bounds array access and host OS crash) via a crafted interrupt request, related to arch/x86/kvm/ioapic.c and arch/x86/kvm/ioapic.h.",
        "id": 1166
    },
    {
        "cve_id": "CVE-2023-39189",
        "code_before_change": "static int nfnl_osf_add_callback(struct sk_buff *skb,\n\t\t\t\t const struct nfnl_info *info,\n\t\t\t\t const struct nlattr * const osf_attrs[])\n{\n\tstruct nf_osf_user_finger *f;\n\tstruct nf_osf_finger *kf = NULL, *sf;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!osf_attrs[OSF_ATTR_FINGER])\n\t\treturn -EINVAL;\n\n\tif (!(info->nlh->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -EINVAL;\n\n\tf = nla_data(osf_attrs[OSF_ATTR_FINGER]);\n\n\tkf = kmalloc(sizeof(struct nf_osf_finger), GFP_KERNEL);\n\tif (!kf)\n\t\treturn -ENOMEM;\n\n\tmemcpy(&kf->finger, f, sizeof(struct nf_osf_user_finger));\n\n\tlist_for_each_entry(sf, &nf_osf_fingers[!!f->df], finger_entry) {\n\t\tif (memcmp(&sf->finger, f, sizeof(struct nf_osf_user_finger)))\n\t\t\tcontinue;\n\n\t\tkfree(kf);\n\t\tkf = NULL;\n\n\t\tif (info->nlh->nlmsg_flags & NLM_F_EXCL)\n\t\t\terr = -EEXIST;\n\t\tbreak;\n\t}\n\n\t/*\n\t * We are protected by nfnl mutex.\n\t */\n\tif (kf)\n\t\tlist_add_tail_rcu(&kf->finger_entry, &nf_osf_fingers[!!f->df]);\n\n\treturn err;\n}",
        "code_after_change": "static int nfnl_osf_add_callback(struct sk_buff *skb,\n\t\t\t\t const struct nfnl_info *info,\n\t\t\t\t const struct nlattr * const osf_attrs[])\n{\n\tstruct nf_osf_user_finger *f;\n\tstruct nf_osf_finger *kf = NULL, *sf;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!osf_attrs[OSF_ATTR_FINGER])\n\t\treturn -EINVAL;\n\n\tif (!(info->nlh->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -EINVAL;\n\n\tf = nla_data(osf_attrs[OSF_ATTR_FINGER]);\n\n\tif (f->opt_num > ARRAY_SIZE(f->opt))\n\t\treturn -EINVAL;\n\n\tif (!memchr(f->genre, 0, MAXGENRELEN) ||\n\t    !memchr(f->subtype, 0, MAXGENRELEN) ||\n\t    !memchr(f->version, 0, MAXGENRELEN))\n\t\treturn -EINVAL;\n\n\tkf = kmalloc(sizeof(struct nf_osf_finger), GFP_KERNEL);\n\tif (!kf)\n\t\treturn -ENOMEM;\n\n\tmemcpy(&kf->finger, f, sizeof(struct nf_osf_user_finger));\n\n\tlist_for_each_entry(sf, &nf_osf_fingers[!!f->df], finger_entry) {\n\t\tif (memcmp(&sf->finger, f, sizeof(struct nf_osf_user_finger)))\n\t\t\tcontinue;\n\n\t\tkfree(kf);\n\t\tkf = NULL;\n\n\t\tif (info->nlh->nlmsg_flags & NLM_F_EXCL)\n\t\t\terr = -EEXIST;\n\t\tbreak;\n\t}\n\n\t/*\n\t * We are protected by nfnl mutex.\n\t */\n\tif (kf)\n\t\tlist_add_tail_rcu(&kf->finger_entry, &nf_osf_fingers[!!f->df]);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,6 +16,14 @@\n \t\treturn -EINVAL;\n \n \tf = nla_data(osf_attrs[OSF_ATTR_FINGER]);\n+\n+\tif (f->opt_num > ARRAY_SIZE(f->opt))\n+\t\treturn -EINVAL;\n+\n+\tif (!memchr(f->genre, 0, MAXGENRELEN) ||\n+\t    !memchr(f->subtype, 0, MAXGENRELEN) ||\n+\t    !memchr(f->version, 0, MAXGENRELEN))\n+\t\treturn -EINVAL;\n \n \tkf = kmalloc(sizeof(struct nf_osf_finger), GFP_KERNEL);\n \tif (!kf)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (f->opt_num > ARRAY_SIZE(f->opt))",
                "\t\treturn -EINVAL;",
                "",
                "\tif (!memchr(f->genre, 0, MAXGENRELEN) ||",
                "\t    !memchr(f->subtype, 0, MAXGENRELEN) ||",
                "\t    !memchr(f->version, 0, MAXGENRELEN))",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A flaw was found in the Netfilter subsystem in the Linux kernel. The nfnl_osf_add_callback function did not validate the user mode controlled opt_num field. This flaw allows a local privileged (CAP_NET_ADMIN) attacker to trigger an out-of-bounds read, leading to a crash or information disclosure.",
        "id": 4176
    },
    {
        "cve_id": "CVE-2018-19985",
        "code_before_change": "static int hso_probe(struct usb_interface *interface,\n\t\t     const struct usb_device_id *id)\n{\n\tint mux, i, if_num, port_spec;\n\tunsigned char port_mask;\n\tstruct hso_device *hso_dev = NULL;\n\tstruct hso_shared_int *shared_int;\n\tstruct hso_device *tmp_dev = NULL;\n\n\tif (interface->cur_altsetting->desc.bInterfaceClass != 0xFF) {\n\t\tdev_err(&interface->dev, \"Not our interface\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* Get the interface/port specification from either driver_info or from\n\t * the device itself */\n\tif (id->driver_info)\n\t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n\telse\n\t\tport_spec = hso_get_config_data(interface);\n\n\t/* Check if we need to switch to alt interfaces prior to port\n\t * configuration */\n\tif (interface->num_altsetting > 1)\n\t\tusb_set_interface(interface_to_usbdev(interface), if_num, 1);\n\tinterface->needs_remote_wakeup = 1;\n\n\t/* Allocate new hso device(s) */\n\tswitch (port_spec & HSO_INTF_MASK) {\n\tcase HSO_INTF_MUX:\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\t/* Create the network device */\n\t\t\tif (!disable_net) {\n\t\t\t\thso_dev = hso_create_net_device(interface,\n\t\t\t\t\t\t\t\tport_spec);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t\ttmp_dev = hso_dev;\n\t\t\t}\n\t\t}\n\n\t\tif (hso_get_mux_ports(interface, &port_mask))\n\t\t\t/* TODO: de-allocate everything */\n\t\t\tgoto exit;\n\n\t\tshared_int = hso_create_shared_int(interface);\n\t\tif (!shared_int)\n\t\t\tgoto exit;\n\n\t\tfor (i = 1, mux = 0; i < 0x100; i = i << 1, mux++) {\n\t\t\tif (port_mask & i) {\n\t\t\t\thso_dev = hso_create_mux_serial_device(\n\t\t\t\t\t\tinterface, i, shared_int);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif (tmp_dev)\n\t\t\thso_dev = tmp_dev;\n\t\tbreak;\n\n\tcase HSO_INTF_BULK:\n\t\t/* It's a regular bulk interface */\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\tif (!disable_net)\n\t\t\t\thso_dev =\n\t\t\t\t    hso_create_net_device(interface, port_spec);\n\t\t} else {\n\t\t\thso_dev =\n\t\t\t    hso_create_bulk_serial_device(interface, port_spec);\n\t\t}\n\t\tif (!hso_dev)\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tgoto exit;\n\t}\n\n\t/* save our data pointer in this device */\n\tusb_set_intfdata(interface, hso_dev);\n\n\t/* done */\n\treturn 0;\nexit:\n\thso_free_interface(interface);\n\treturn -ENODEV;\n}",
        "code_after_change": "static int hso_probe(struct usb_interface *interface,\n\t\t     const struct usb_device_id *id)\n{\n\tint mux, i, if_num, port_spec;\n\tunsigned char port_mask;\n\tstruct hso_device *hso_dev = NULL;\n\tstruct hso_shared_int *shared_int;\n\tstruct hso_device *tmp_dev = NULL;\n\n\tif (interface->cur_altsetting->desc.bInterfaceClass != 0xFF) {\n\t\tdev_err(&interface->dev, \"Not our interface\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* Get the interface/port specification from either driver_info or from\n\t * the device itself */\n\tif (id->driver_info) {\n\t\t/* if_num is controlled by the device, driver_info is a 0 terminated\n\t\t * array. Make sure, the access is in bounds! */\n\t\tfor (i = 0; i <= if_num; ++i)\n\t\t\tif (((u32 *)(id->driver_info))[i] == 0)\n\t\t\t\tgoto exit;\n\t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n\t} else {\n\t\tport_spec = hso_get_config_data(interface);\n\t\tif (port_spec < 0)\n\t\t\tgoto exit;\n\t}\n\n\t/* Check if we need to switch to alt interfaces prior to port\n\t * configuration */\n\tif (interface->num_altsetting > 1)\n\t\tusb_set_interface(interface_to_usbdev(interface), if_num, 1);\n\tinterface->needs_remote_wakeup = 1;\n\n\t/* Allocate new hso device(s) */\n\tswitch (port_spec & HSO_INTF_MASK) {\n\tcase HSO_INTF_MUX:\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\t/* Create the network device */\n\t\t\tif (!disable_net) {\n\t\t\t\thso_dev = hso_create_net_device(interface,\n\t\t\t\t\t\t\t\tport_spec);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t\ttmp_dev = hso_dev;\n\t\t\t}\n\t\t}\n\n\t\tif (hso_get_mux_ports(interface, &port_mask))\n\t\t\t/* TODO: de-allocate everything */\n\t\t\tgoto exit;\n\n\t\tshared_int = hso_create_shared_int(interface);\n\t\tif (!shared_int)\n\t\t\tgoto exit;\n\n\t\tfor (i = 1, mux = 0; i < 0x100; i = i << 1, mux++) {\n\t\t\tif (port_mask & i) {\n\t\t\t\thso_dev = hso_create_mux_serial_device(\n\t\t\t\t\t\tinterface, i, shared_int);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif (tmp_dev)\n\t\t\thso_dev = tmp_dev;\n\t\tbreak;\n\n\tcase HSO_INTF_BULK:\n\t\t/* It's a regular bulk interface */\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\tif (!disable_net)\n\t\t\t\thso_dev =\n\t\t\t\t    hso_create_net_device(interface, port_spec);\n\t\t} else {\n\t\t\thso_dev =\n\t\t\t    hso_create_bulk_serial_device(interface, port_spec);\n\t\t}\n\t\tif (!hso_dev)\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tgoto exit;\n\t}\n\n\t/* save our data pointer in this device */\n\tusb_set_intfdata(interface, hso_dev);\n\n\t/* done */\n\treturn 0;\nexit:\n\thso_free_interface(interface);\n\treturn -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,10 +16,18 @@\n \n \t/* Get the interface/port specification from either driver_info or from\n \t * the device itself */\n-\tif (id->driver_info)\n+\tif (id->driver_info) {\n+\t\t/* if_num is controlled by the device, driver_info is a 0 terminated\n+\t\t * array. Make sure, the access is in bounds! */\n+\t\tfor (i = 0; i <= if_num; ++i)\n+\t\t\tif (((u32 *)(id->driver_info))[i] == 0)\n+\t\t\t\tgoto exit;\n \t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n-\telse\n+\t} else {\n \t\tport_spec = hso_get_config_data(interface);\n+\t\tif (port_spec < 0)\n+\t\t\tgoto exit;\n+\t}\n \n \t/* Check if we need to switch to alt interfaces prior to port\n \t * configuration */",
        "function_modified_lines": {
            "added": [
                "\tif (id->driver_info) {",
                "\t\t/* if_num is controlled by the device, driver_info is a 0 terminated",
                "\t\t * array. Make sure, the access is in bounds! */",
                "\t\tfor (i = 0; i <= if_num; ++i)",
                "\t\t\tif (((u32 *)(id->driver_info))[i] == 0)",
                "\t\t\t\tgoto exit;",
                "\t} else {",
                "\t\tif (port_spec < 0)",
                "\t\t\tgoto exit;",
                "\t}"
            ],
            "deleted": [
                "\tif (id->driver_info)",
                "\telse"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The function hso_get_config_data in drivers/net/usb/hso.c in the Linux kernel through 4.19.8 reads if_num from the USB device (as a u8) and uses it to index a small array, resulting in an object out-of-bounds (OOB) read that potentially allows arbitrary read in the kernel address space.",
        "id": 1752
    },
    {
        "cve_id": "CVE-2019-9445",
        "code_before_change": "int f2fs_fill_dentries(struct dir_context *ctx, struct f2fs_dentry_ptr *d,\n\t\t\tunsigned int start_pos, struct fscrypt_str *fstr)\n{\n\tunsigned char d_type = DT_UNKNOWN;\n\tunsigned int bit_pos;\n\tstruct f2fs_dir_entry *de = NULL;\n\tstruct fscrypt_str de_name = FSTR_INIT(NULL, 0);\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(d->inode);\n\tstruct blk_plug plug;\n\tbool readdir_ra = sbi->readdir_ra == 1;\n\tint err = 0;\n\n\tbit_pos = ((unsigned long)ctx->pos % d->max);\n\n\tif (readdir_ra)\n\t\tblk_start_plug(&plug);\n\n\twhile (bit_pos < d->max) {\n\t\tbit_pos = find_next_bit_le(d->bitmap, d->max, bit_pos);\n\t\tif (bit_pos >= d->max)\n\t\t\tbreak;\n\n\t\tde = &d->dentry[bit_pos];\n\t\tif (de->name_len == 0) {\n\t\t\tbit_pos++;\n\t\t\tctx->pos = start_pos + bit_pos;\n\t\t\tprintk_ratelimited(\n\t\t\t\t\"%s, invalid namelen(0), ino:%u, run fsck to fix.\",\n\t\t\t\tKERN_WARNING, le32_to_cpu(de->ino));\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tcontinue;\n\t\t}\n\n\t\td_type = f2fs_get_de_type(de);\n\n\t\tde_name.name = d->filename[bit_pos];\n\t\tde_name.len = le16_to_cpu(de->name_len);\n\n\t\t/* check memory boundary before moving forward */\n\t\tbit_pos += GET_DENTRY_SLOTS(le16_to_cpu(de->name_len));\n\t\tif (unlikely(bit_pos > d->max)) {\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: corrupted namelen=%d, run fsck to fix.\",\n\t\t\t\t__func__, le16_to_cpu(de->name_len));\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (f2fs_encrypted_inode(d->inode)) {\n\t\t\tint save_len = fstr->len;\n\n\t\t\terr = fscrypt_fname_disk_to_usr(d->inode,\n\t\t\t\t\t\t(u32)de->hash_code, 0,\n\t\t\t\t\t\t&de_name, fstr);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tde_name = *fstr;\n\t\t\tfstr->len = save_len;\n\t\t}\n\n\t\tif (!dir_emit(ctx, de_name.name, de_name.len,\n\t\t\t\t\tle32_to_cpu(de->ino), d_type)) {\n\t\t\terr = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (readdir_ra)\n\t\t\tf2fs_ra_node_page(sbi, le32_to_cpu(de->ino));\n\n\t\tctx->pos = start_pos + bit_pos;\n\t}\nout:\n\tif (readdir_ra)\n\t\tblk_finish_plug(&plug);\n\treturn err;\n}",
        "code_after_change": "int f2fs_fill_dentries(struct dir_context *ctx, struct f2fs_dentry_ptr *d,\n\t\t\tunsigned int start_pos, struct fscrypt_str *fstr)\n{\n\tunsigned char d_type = DT_UNKNOWN;\n\tunsigned int bit_pos;\n\tstruct f2fs_dir_entry *de = NULL;\n\tstruct fscrypt_str de_name = FSTR_INIT(NULL, 0);\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(d->inode);\n\tstruct blk_plug plug;\n\tbool readdir_ra = sbi->readdir_ra == 1;\n\tint err = 0;\n\n\tbit_pos = ((unsigned long)ctx->pos % d->max);\n\n\tif (readdir_ra)\n\t\tblk_start_plug(&plug);\n\n\twhile (bit_pos < d->max) {\n\t\tbit_pos = find_next_bit_le(d->bitmap, d->max, bit_pos);\n\t\tif (bit_pos >= d->max)\n\t\t\tbreak;\n\n\t\tde = &d->dentry[bit_pos];\n\t\tif (de->name_len == 0) {\n\t\t\tbit_pos++;\n\t\t\tctx->pos = start_pos + bit_pos;\n\t\t\tprintk_ratelimited(\n\t\t\t\t\"%s, invalid namelen(0), ino:%u, run fsck to fix.\",\n\t\t\t\tKERN_WARNING, le32_to_cpu(de->ino));\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tcontinue;\n\t\t}\n\n\t\td_type = f2fs_get_de_type(de);\n\n\t\tde_name.name = d->filename[bit_pos];\n\t\tde_name.len = le16_to_cpu(de->name_len);\n\n\t\t/* check memory boundary before moving forward */\n\t\tbit_pos += GET_DENTRY_SLOTS(le16_to_cpu(de->name_len));\n\t\tif (unlikely(bit_pos > d->max ||\n\t\t\t\tle16_to_cpu(de->name_len) > F2FS_NAME_LEN)) {\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: corrupted namelen=%d, run fsck to fix.\",\n\t\t\t\t__func__, le16_to_cpu(de->name_len));\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (f2fs_encrypted_inode(d->inode)) {\n\t\t\tint save_len = fstr->len;\n\n\t\t\terr = fscrypt_fname_disk_to_usr(d->inode,\n\t\t\t\t\t\t(u32)de->hash_code, 0,\n\t\t\t\t\t\t&de_name, fstr);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tde_name = *fstr;\n\t\t\tfstr->len = save_len;\n\t\t}\n\n\t\tif (!dir_emit(ctx, de_name.name, de_name.len,\n\t\t\t\t\tle32_to_cpu(de->ino), d_type)) {\n\t\t\terr = 1;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (readdir_ra)\n\t\t\tf2fs_ra_node_page(sbi, le32_to_cpu(de->ino));\n\n\t\tctx->pos = start_pos + bit_pos;\n\t}\nout:\n\tif (readdir_ra)\n\t\tblk_finish_plug(&plug);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,7 +38,8 @@\n \n \t\t/* check memory boundary before moving forward */\n \t\tbit_pos += GET_DENTRY_SLOTS(le16_to_cpu(de->name_len));\n-\t\tif (unlikely(bit_pos > d->max)) {\n+\t\tif (unlikely(bit_pos > d->max ||\n+\t\t\t\tle16_to_cpu(de->name_len) > F2FS_NAME_LEN)) {\n \t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n \t\t\t\t\"%s: corrupted namelen=%d, run fsck to fix.\",\n \t\t\t\t__func__, le16_to_cpu(de->name_len));",
        "function_modified_lines": {
            "added": [
                "\t\tif (unlikely(bit_pos > d->max ||",
                "\t\t\t\tle16_to_cpu(de->name_len) > F2FS_NAME_LEN)) {"
            ],
            "deleted": [
                "\t\tif (unlikely(bit_pos > d->max)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In the Android kernel in F2FS driver there is a possible out of bounds read due to a missing bounds check. This could lead to local information disclosure with system execution privileges needed. User interaction is not needed for exploitation.",
        "id": 2356
    },
    {
        "cve_id": "CVE-2023-38426",
        "code_before_change": "int smb2_open(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_tree_connect *tcon = work->tcon;\n\tstruct smb2_create_req *req;\n\tstruct smb2_create_rsp *rsp;\n\tstruct path path;\n\tstruct ksmbd_share_config *share = tcon->share_conf;\n\tstruct ksmbd_file *fp = NULL;\n\tstruct file *filp = NULL;\n\tstruct mnt_idmap *idmap = NULL;\n\tstruct kstat stat;\n\tstruct create_context *context;\n\tstruct lease_ctx_info *lc = NULL;\n\tstruct create_ea_buf_req *ea_buf = NULL;\n\tstruct oplock_info *opinfo;\n\t__le32 *next_ptr = NULL;\n\tint req_op_level = 0, open_flags = 0, may_flags = 0, file_info = 0;\n\tint rc = 0;\n\tint contxt_cnt = 0, query_disk_id = 0;\n\tint maximal_access_ctxt = 0, posix_ctxt = 0;\n\tint s_type = 0;\n\tint next_off = 0;\n\tchar *name = NULL;\n\tchar *stream_name = NULL;\n\tbool file_present = false, created = false, already_permitted = false;\n\tint share_ret, need_truncate = 0;\n\tu64 time;\n\tumode_t posix_mode = 0;\n\t__le32 daccess, maximal_access = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (req->hdr.NextCommand && !work->next_smb2_rcv_hdr_off &&\n\t    (req->hdr.Flags & SMB2_FLAGS_RELATED_OPERATIONS)) {\n\t\tksmbd_debug(SMB, \"invalid flag in chained command\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\tsmb2_set_err_rsp(work);\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_share_config_flag(share, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe create request\\n\");\n\t\treturn create_smb2_pipe(work);\n\t}\n\n\tif (req->NameLength) {\n\t\tif ((req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t\t    *(char *)req->Buffer == '\\\\') {\n\t\t\tpr_err(\"not allow directory name included leading slash\\n\");\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tname = smb2_get_name(req->Buffer,\n\t\t\t\t     le16_to_cpu(req->NameLength),\n\t\t\t\t     work->conn->local_nls);\n\t\tif (IS_ERR(name)) {\n\t\t\trc = PTR_ERR(name);\n\t\t\tif (rc != -ENOMEM)\n\t\t\t\trc = -ENOENT;\n\t\t\tname = NULL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tksmbd_debug(SMB, \"converted name = %s\\n\", name);\n\t\tif (strchr(name, ':')) {\n\t\t\tif (!test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t    KSMBD_SHARE_FLAG_STREAMS)) {\n\t\t\t\trc = -EBADF;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\trc = parse_stream_name(name, &stream_name, &s_type);\n\t\t\tif (rc < 0)\n\t\t\t\tgoto err_out1;\n\t\t}\n\n\t\trc = ksmbd_validate_filename(name);\n\t\tif (rc < 0)\n\t\t\tgoto err_out1;\n\n\t\tif (ksmbd_share_veto_filename(share, name)) {\n\t\t\trc = -ENOENT;\n\t\t\tksmbd_debug(SMB, \"Reject open(), vetoed file: %s\\n\",\n\t\t\t\t    name);\n\t\t\tgoto err_out1;\n\t\t}\n\t} else {\n\t\tname = kstrdup(\"\", GFP_KERNEL);\n\t\tif (!name) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_out1;\n\t\t}\n\t}\n\n\treq_op_level = req->RequestedOplockLevel;\n\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE)\n\t\tlc = parse_lease_state(req);\n\n\tif (le32_to_cpu(req->ImpersonationLevel) > le32_to_cpu(IL_DELEGATE)) {\n\t\tpr_err(\"Invalid impersonationlevel : 0x%x\\n\",\n\t\t       le32_to_cpu(req->ImpersonationLevel));\n\t\trc = -EIO;\n\t\trsp->hdr.Status = STATUS_BAD_IMPERSONATION_LEVEL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateOptions && !(req->CreateOptions & CREATE_OPTIONS_MASK_LE)) {\n\t\tpr_err(\"Invalid create options : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateOptions));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t} else {\n\t\tif (req->CreateOptions & FILE_SEQUENTIAL_ONLY_LE &&\n\t\t    req->CreateOptions & FILE_RANDOM_ACCESS_LE)\n\t\t\treq->CreateOptions = ~(FILE_SEQUENTIAL_ONLY_LE);\n\n\t\tif (req->CreateOptions &\n\t\t    (FILE_OPEN_BY_FILE_ID_LE | CREATE_TREE_CONNECTION |\n\t\t     FILE_RESERVE_OPFILTER_LE)) {\n\t\t\trc = -EOPNOTSUPP;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (req->CreateOptions & FILE_NO_COMPRESSION_LE) {\n\t\t\t\treq->CreateOptions = ~(FILE_NO_COMPRESSION_LE);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (le32_to_cpu(req->CreateDisposition) >\n\t    le32_to_cpu(FILE_OVERWRITE_IF_LE)) {\n\t\tpr_err(\"Invalid create disposition : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateDisposition));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (!(req->DesiredAccess & DESIRED_ACCESS_MASK)) {\n\t\tpr_err(\"Invalid desired access : 0x%x\\n\",\n\t\t       le32_to_cpu(req->DesiredAccess));\n\t\trc = -EACCES;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->FileAttributes && !(req->FileAttributes & FILE_ATTRIBUTE_MASK_LE)) {\n\t\tpr_err(\"Invalid file attribute : 0x%x\\n\",\n\t\t       le32_to_cpu(req->FileAttributes));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\t/* Parse non-durable handle create contexts */\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tea_buf = (struct create_ea_buf_req *)context;\n\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t    sizeof(struct create_ea_buf_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\tif (req->CreateOptions & FILE_NO_EA_KNOWLEDGE_LE) {\n\t\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"get query maximal access context\\n\");\n\t\t\tmaximal_access_ctxt = 1;\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get timewarp context\\n\");\n\t\t\trc = -EBADF;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (tcon->posix_extensions) {\n\t\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX);\n\t\t\tif (IS_ERR(context)) {\n\t\t\t\trc = PTR_ERR(context);\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (context) {\n\t\t\t\tstruct create_posix *posix =\n\t\t\t\t\t(struct create_posix *)context;\n\t\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t\t    sizeof(struct create_posix) - 4) {\n\t\t\t\t\trc = -EINVAL;\n\t\t\t\t\tgoto err_out1;\n\t\t\t\t}\n\t\t\t\tksmbd_debug(SMB, \"get posix context\\n\");\n\n\t\t\t\tposix_mode = le32_to_cpu(posix->Mode);\n\t\t\t\tposix_ctxt = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ksmbd_override_fsids(work)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out1;\n\t}\n\n\trc = ksmbd_vfs_kern_path_locked(work, name, LOOKUP_NO_SYMLINKS, &path, 1);\n\tif (!rc) {\n\t\tfile_present = true;\n\n\t\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE) {\n\t\t\t/*\n\t\t\t * If file exists with under flags, return access\n\t\t\t * denied error.\n\t\t\t */\n\t\t\tif (req->CreateDisposition == FILE_OVERWRITE_IF_LE ||\n\t\t\t    req->CreateDisposition == FILE_OPEN_IF_LE) {\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t} else if (d_is_symlink(path.dentry)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tfile_present = true;\n\t\tidmap = mnt_idmap(path.mnt);\n\t} else {\n\t\tif (rc != -ENOENT)\n\t\t\tgoto err_out;\n\t\tksmbd_debug(SMB, \"can not get linux path for %s, rc = %d\\n\",\n\t\t\t    name, rc);\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\t}\n\t\t} else {\n\t\t\tif (file_present && S_ISDIR(d_inode(path.dentry)->i_mode) &&\n\t\t\t    s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\t\t}\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE &&\n\t\t    req->FileAttributes & FILE_ATTRIBUTE_NORMAL_LE) {\n\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\trc = -EIO;\n\t\t}\n\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (file_present && req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE &&\n\t    S_ISDIR(d_inode(path.dentry)->i_mode) &&\n\t    !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\tksmbd_debug(SMB, \"open() argument is a directory: %s, %x\\n\",\n\t\t\t    name, req->CreateOptions);\n\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (file_present && (req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t    !(req->CreateDisposition == FILE_CREATE_LE) &&\n\t    !S_ISDIR(d_inode(path.dentry)->i_mode)) {\n\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (!stream_name && file_present &&\n\t    req->CreateDisposition == FILE_CREATE_LE) {\n\t\trc = -EEXIST;\n\t\tgoto err_out;\n\t}\n\n\tdaccess = smb_map_generic_desired_access(req->DesiredAccess);\n\n\tif (file_present && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\trc = smb_check_perm_dacl(conn, &path, &daccess,\n\t\t\t\t\t sess->user->uid);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (daccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tif (!file_present) {\n\t\t\tdaccess = cpu_to_le32(GENERIC_ALL_FLAGS);\n\t\t} else {\n\t\t\trc = ksmbd_vfs_query_maximal_access(idmap,\n\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t    &daccess);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\talready_permitted = true;\n\t\t}\n\t\tmaximal_access = daccess;\n\t}\n\n\topen_flags = smb2_create_open_flags(file_present, daccess,\n\t\t\t\t\t    req->CreateDisposition,\n\t\t\t\t\t    &may_flags);\n\n\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tif (open_flags & O_CREAT) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t/*create file if not present */\n\tif (!file_present) {\n\t\trc = smb2_creat(work, &path, name, open_flags, posix_mode,\n\t\t\t\treq->CreateOptions & FILE_DIRECTORY_FILE_LE);\n\t\tif (rc) {\n\t\t\tif (rc == -ENOENT) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_OBJECT_PATH_NOT_FOUND;\n\t\t\t}\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tcreated = true;\n\t\tidmap = mnt_idmap(path.mnt);\n\t\tif (ea_buf) {\n\t\t\tif (le32_to_cpu(ea_buf->ccontext.DataLength) <\n\t\t\t    sizeof(struct smb2_ea_info)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\trc = smb2_set_ea(&ea_buf->ea,\n\t\t\t\t\t le32_to_cpu(ea_buf->ccontext.DataLength),\n\t\t\t\t\t &path);\n\t\t\tif (rc == -EOPNOTSUPP)\n\t\t\t\trc = 0;\n\t\t\telse if (rc)\n\t\t\t\tgoto err_out;\n\t\t}\n\t} else if (!already_permitted) {\n\t\t/* FILE_READ_ATTRIBUTE is allowed without inode_permission,\n\t\t * because execute(search) permission on a parent directory,\n\t\t * is already granted.\n\t\t */\n\t\tif (daccess & ~(FILE_READ_ATTRIBUTES_LE | FILE_READ_CONTROL_LE)) {\n\t\t\trc = inode_permission(idmap,\n\t\t\t\t\t      d_inode(path.dentry),\n\t\t\t\t\t      may_flags);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\n\t\t\tif ((daccess & FILE_DELETE_LE) ||\n\t\t\t    (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\t\t\trc = inode_permission(idmap,\n\t\t\t\t\t\t      d_inode(path.dentry->d_parent),\n\t\t\t\t\t\t      MAY_EXEC | MAY_WRITE);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\t}\n\n\trc = ksmbd_query_inode_status(d_inode(path.dentry->d_parent));\n\tif (rc == KSMBD_INODE_STATUS_PENDING_DELETE) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\trc = 0;\n\tfilp = dentry_open(&path, open_flags, current_cred());\n\tif (IS_ERR(filp)) {\n\t\trc = PTR_ERR(filp);\n\t\tpr_err(\"dentry open for dir failed, rc %d\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\tif (file_present) {\n\t\tif (!(open_flags & O_TRUNC))\n\t\t\tfile_info = FILE_OPENED;\n\t\telse\n\t\t\tfile_info = FILE_OVERWRITTEN;\n\n\t\tif ((req->CreateDisposition & FILE_CREATE_MASK_LE) ==\n\t\t    FILE_SUPERSEDE_LE)\n\t\t\tfile_info = FILE_SUPERSEDED;\n\t} else if (open_flags & O_CREAT) {\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tksmbd_vfs_set_fadvise(filp, req->CreateOptions);\n\n\t/* Obtain Volatile-ID */\n\tfp = ksmbd_open_fd(work, filp);\n\tif (IS_ERR(fp)) {\n\t\tfput(filp);\n\t\trc = PTR_ERR(fp);\n\t\tfp = NULL;\n\t\tgoto err_out;\n\t}\n\n\t/* Get Persistent-ID */\n\tksmbd_open_durable_fd(fp);\n\tif (!has_file_id(fp->persistent_id)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tfp->cdoption = req->CreateDisposition;\n\tfp->daccess = daccess;\n\tfp->saccess = req->ShareAccess;\n\tfp->coption = req->CreateOptions;\n\n\t/* Set default windows and posix acls if creating new file */\n\tif (created) {\n\t\tint posix_acl_rc;\n\t\tstruct inode *inode = d_inode(path.dentry);\n\n\t\tposix_acl_rc = ksmbd_vfs_inherit_posix_acl(idmap,\n\t\t\t\t\t\t\t   path.dentry,\n\t\t\t\t\t\t\t   d_inode(path.dentry->d_parent));\n\t\tif (posix_acl_rc)\n\t\t\tksmbd_debug(SMB, \"inherit posix acl failed : %d\\n\", posix_acl_rc);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\trc = smb_inherit_dacl(conn, &path, sess->user->uid,\n\t\t\t\t\t      sess->user->gid);\n\t\t}\n\n\t\tif (rc) {\n\t\t\trc = smb2_create_sd_buffer(work, req, &path);\n\t\t\tif (rc) {\n\t\t\t\tif (posix_acl_rc)\n\t\t\t\t\tksmbd_vfs_set_init_posix_acl(idmap,\n\t\t\t\t\t\t\t\t     path.dentry);\n\n\t\t\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\t\t\tstruct smb_fattr fattr;\n\t\t\t\t\tstruct smb_ntsd *pntsd;\n\t\t\t\t\tint pntsd_size, ace_num = 0;\n\n\t\t\t\t\tksmbd_acls_fattr(&fattr, idmap, inode);\n\t\t\t\t\tif (fattr.cf_acls)\n\t\t\t\t\t\tace_num = fattr.cf_acls->a_count;\n\t\t\t\t\tif (fattr.cf_dacls)\n\t\t\t\t\t\tace_num += fattr.cf_dacls->a_count;\n\n\t\t\t\t\tpntsd = kmalloc(sizeof(struct smb_ntsd) +\n\t\t\t\t\t\t\tsizeof(struct smb_sid) * 3 +\n\t\t\t\t\t\t\tsizeof(struct smb_acl) +\n\t\t\t\t\t\t\tsizeof(struct smb_ace) * ace_num * 2,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\t\tif (!pntsd) {\n\t\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = build_sec_desc(idmap,\n\t\t\t\t\t\t\t    pntsd, NULL, 0,\n\t\t\t\t\t\t\t    OWNER_SECINFO |\n\t\t\t\t\t\t\t    GROUP_SECINFO |\n\t\t\t\t\t\t\t    DACL_SECINFO,\n\t\t\t\t\t\t\t    &pntsd_size, &fattr);\n\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\tif (rc) {\n\t\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = ksmbd_vfs_set_sd_xattr(conn,\n\t\t\t\t\t\t\t\t    idmap,\n\t\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t\t    pntsd,\n\t\t\t\t\t\t\t\t    pntsd_size);\n\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\tif (rc)\n\t\t\t\t\t\tpr_err(\"failed to store ntacl in xattr : %d\\n\",\n\t\t\t\t\t\t       rc);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\trc = smb2_set_stream_name_xattr(&path,\n\t\t\t\t\t\tfp,\n\t\t\t\t\t\tstream_name,\n\t\t\t\t\t\ts_type);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tfp->attrib_only = !(req->DesiredAccess & ~(FILE_READ_ATTRIBUTES_LE |\n\t\t\tFILE_WRITE_ATTRIBUTES_LE | FILE_SYNCHRONIZE_LE));\n\tif (!S_ISDIR(file_inode(filp)->i_mode) && open_flags & O_TRUNC &&\n\t    !fp->attrib_only && !stream_name) {\n\t\tsmb_break_all_oplock(work, fp);\n\t\tneed_truncate = 1;\n\t}\n\n\t/* fp should be searchable through ksmbd_inode.m_fp_list\n\t * after daccess, saccess, attrib_only, and stream are\n\t * initialized.\n\t */\n\twrite_lock(&fp->f_ci->m_lock);\n\tlist_add(&fp->node, &fp->f_ci->m_fp_list);\n\twrite_unlock(&fp->f_ci->m_lock);\n\n\t/* Check delete pending among previous fp before oplock break */\n\tif (ksmbd_inode_pending_delete(fp)) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\tshare_ret = ksmbd_smb_check_shared_mode(fp->filp, fp);\n\tif (!test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_OPLOCKS) ||\n\t    (req_op_level == SMB2_OPLOCK_LEVEL_LEASE &&\n\t     !(conn->vals->capabilities & SMB2_GLOBAL_CAP_LEASING))) {\n\t\tif (share_ret < 0 && !S_ISDIR(file_inode(fp->filp)->i_mode)) {\n\t\t\trc = share_ret;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE) {\n\t\t\treq_op_level = smb2_map_lease_to_oplock(lc->req_state);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"lease req for(%s) req oplock state 0x%x, lease state 0x%x\\n\",\n\t\t\t\t    name, req_op_level, lc->req_state);\n\t\t\trc = find_same_lease_key(sess, fp->f_ci, lc);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t} else if (open_flags == O_RDONLY &&\n\t\t\t   (req_op_level == SMB2_OPLOCK_LEVEL_BATCH ||\n\t\t\t    req_op_level == SMB2_OPLOCK_LEVEL_EXCLUSIVE))\n\t\t\treq_op_level = SMB2_OPLOCK_LEVEL_II;\n\n\t\trc = smb_grant_oplock(work, req_op_level,\n\t\t\t\t      fp->persistent_id, fp,\n\t\t\t\t      le32_to_cpu(req->hdr.Id.SyncId.TreeId),\n\t\t\t\t      lc, share_ret);\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)\n\t\tksmbd_fd_set_delete_on_close(fp, file_info);\n\n\tif (need_truncate) {\n\t\trc = smb2_create_truncate(&path);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\tstruct create_alloc_size_req *az_req;\n\n\t\taz_req = (struct create_alloc_size_req *)smb2_find_context_vals(req,\n\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE);\n\t\tif (IS_ERR(az_req)) {\n\t\t\trc = PTR_ERR(az_req);\n\t\t\tgoto err_out;\n\t\t} else if (az_req) {\n\t\t\tloff_t alloc_size;\n\t\t\tint err;\n\n\t\t\tif (le16_to_cpu(az_req->ccontext.DataOffset) +\n\t\t\t    le32_to_cpu(az_req->ccontext.DataLength) <\n\t\t\t    sizeof(struct create_alloc_size_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\talloc_size = le64_to_cpu(az_req->AllocationSize);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"request smb2 create allocate size : %llu\\n\",\n\t\t\t\t    alloc_size);\n\t\t\tsmb_break_all_levII_oplock(work, fp, 1);\n\t\t\terr = vfs_fallocate(fp->filp, FALLOC_FL_KEEP_SIZE, 0,\n\t\t\t\t\t    alloc_size);\n\t\t\tif (err < 0)\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"vfs_fallocate is failed : %d\\n\",\n\t\t\t\t\t    err);\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get query on disk id context\\n\");\n\t\t\tquery_disk_id = 1;\n\t\t}\n\t}\n\n\trc = ksmbd_vfs_getattr(&path, &stat);\n\tif (rc)\n\t\tgoto err_out;\n\n\tif (stat.result_mask & STATX_BTIME)\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.btime);\n\telse\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.ctime);\n\tif (req->FileAttributes || fp->f_ci->m_fattr == 0)\n\t\tfp->f_ci->m_fattr =\n\t\t\tcpu_to_le32(smb2_get_dos_mode(&stat, le32_to_cpu(req->FileAttributes)));\n\n\tif (!created)\n\t\tsmb2_update_xattrs(tcon, &path, fp);\n\telse\n\t\tsmb2_new_xattrs(tcon, &path, fp);\n\n\tmemcpy(fp->client_guid, conn->ClientGUID, SMB2_CLIENT_GUID_SIZE);\n\n\trsp->StructureSize = cpu_to_le16(89);\n\trcu_read_lock();\n\topinfo = rcu_dereference(fp->f_opinfo);\n\trsp->OplockLevel = opinfo != NULL ? opinfo->level : 0;\n\trcu_read_unlock();\n\trsp->Flags = 0;\n\trsp->CreateAction = cpu_to_le32(file_info);\n\trsp->CreationTime = cpu_to_le64(fp->create_time);\n\ttime = ksmbd_UnixTimeToNT(stat.atime);\n\trsp->LastAccessTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.mtime);\n\trsp->LastWriteTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.ctime);\n\trsp->ChangeTime = cpu_to_le64(time);\n\trsp->AllocationSize = S_ISDIR(stat.mode) ? 0 :\n\t\tcpu_to_le64(stat.blocks << 9);\n\trsp->EndofFile = S_ISDIR(stat.mode) ? 0 : cpu_to_le64(stat.size);\n\trsp->FileAttributes = fp->f_ci->m_fattr;\n\n\trsp->Reserved2 = 0;\n\n\trsp->PersistentFileId = fp->persistent_id;\n\trsp->VolatileFileId = fp->volatile_id;\n\n\trsp->CreateContextsOffset = 0;\n\trsp->CreateContextsLength = 0;\n\tinc_rfc1001_len(work->response_buf, 88); /* StructureSize - 1*/\n\n\t/* If lease is request send lease context response */\n\tif (opinfo && opinfo->is_lease) {\n\t\tstruct create_context *lease_ccontext;\n\n\t\tksmbd_debug(SMB, \"lease granted on(%s) lease state 0x%x\\n\",\n\t\t\t    name, opinfo->o_lease->state);\n\t\trsp->OplockLevel = SMB2_OPLOCK_LEVEL_LEASE;\n\n\t\tlease_ccontext = (struct create_context *)rsp->Buffer;\n\t\tcontxt_cnt++;\n\t\tcreate_lease_buf(rsp->Buffer, opinfo->o_lease);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_lease_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_lease_size);\n\t\tnext_ptr = &lease_ccontext->Next;\n\t\tnext_off = conn->vals->create_lease_size;\n\t}\n\n\tif (maximal_access_ctxt) {\n\t\tstruct create_context *mxac_ccontext;\n\n\t\tif (maximal_access == 0)\n\t\t\tksmbd_vfs_query_maximal_access(idmap,\n\t\t\t\t\t\t       path.dentry,\n\t\t\t\t\t\t       &maximal_access);\n\t\tmxac_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_mxac_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tle32_to_cpu(maximal_access));\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_mxac_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_mxac_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &mxac_ccontext->Next;\n\t\tnext_off = conn->vals->create_mxac_size;\n\t}\n\n\tif (query_disk_id) {\n\t\tstruct create_context *disk_id_ccontext;\n\n\t\tdisk_id_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_disk_id_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tstat.ino, tcon->id);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_disk_id_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_disk_id_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &disk_id_ccontext->Next;\n\t\tnext_off = conn->vals->create_disk_id_size;\n\t}\n\n\tif (posix_ctxt) {\n\t\tcontxt_cnt++;\n\t\tcreate_posix_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tfp);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_posix_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_posix_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t}\n\n\tif (contxt_cnt > 0) {\n\t\trsp->CreateContextsOffset =\n\t\t\tcpu_to_le32(offsetof(struct smb2_create_rsp, Buffer));\n\t}\n\nerr_out:\n\tif (file_present || created) {\n\t\tinode_unlock(d_inode(path.dentry->d_parent));\n\t\tdput(path.dentry);\n\t}\n\tksmbd_revert_fsids(work);\nerr_out1:\n\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\telse if (rc == -EOPNOTSUPP)\n\t\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\telse if (rc == -EACCES || rc == -ESTALE || rc == -EXDEV)\n\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\telse if (rc == -ENOENT)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_INVALID;\n\t\telse if (rc == -EPERM)\n\t\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\t\telse if (rc == -EBUSY)\n\t\t\trsp->hdr.Status = STATUS_DELETE_PENDING;\n\t\telse if (rc == -EBADF)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_NOT_FOUND;\n\t\telse if (rc == -ENOEXEC)\n\t\t\trsp->hdr.Status = STATUS_DUPLICATE_OBJECTID;\n\t\telse if (rc == -ENXIO)\n\t\t\trsp->hdr.Status = STATUS_NO_SUCH_DEVICE;\n\t\telse if (rc == -EEXIST)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_COLLISION;\n\t\telse if (rc == -EMFILE)\n\t\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\t\tif (!rsp->hdr.Status)\n\t\t\trsp->hdr.Status = STATUS_UNEXPECTED_IO_ERROR;\n\n\t\tif (fp)\n\t\t\tksmbd_fd_put(work, fp);\n\t\tsmb2_set_err_rsp(work);\n\t\tksmbd_debug(SMB, \"Error response: %x\\n\", rsp->hdr.Status);\n\t}\n\n\tkfree(name);\n\tkfree(lc);\n\n\treturn 0;\n}",
        "code_after_change": "int smb2_open(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_tree_connect *tcon = work->tcon;\n\tstruct smb2_create_req *req;\n\tstruct smb2_create_rsp *rsp;\n\tstruct path path;\n\tstruct ksmbd_share_config *share = tcon->share_conf;\n\tstruct ksmbd_file *fp = NULL;\n\tstruct file *filp = NULL;\n\tstruct mnt_idmap *idmap = NULL;\n\tstruct kstat stat;\n\tstruct create_context *context;\n\tstruct lease_ctx_info *lc = NULL;\n\tstruct create_ea_buf_req *ea_buf = NULL;\n\tstruct oplock_info *opinfo;\n\t__le32 *next_ptr = NULL;\n\tint req_op_level = 0, open_flags = 0, may_flags = 0, file_info = 0;\n\tint rc = 0;\n\tint contxt_cnt = 0, query_disk_id = 0;\n\tint maximal_access_ctxt = 0, posix_ctxt = 0;\n\tint s_type = 0;\n\tint next_off = 0;\n\tchar *name = NULL;\n\tchar *stream_name = NULL;\n\tbool file_present = false, created = false, already_permitted = false;\n\tint share_ret, need_truncate = 0;\n\tu64 time;\n\tumode_t posix_mode = 0;\n\t__le32 daccess, maximal_access = 0;\n\n\tWORK_BUFFERS(work, req, rsp);\n\n\tif (req->hdr.NextCommand && !work->next_smb2_rcv_hdr_off &&\n\t    (req->hdr.Flags & SMB2_FLAGS_RELATED_OPERATIONS)) {\n\t\tksmbd_debug(SMB, \"invalid flag in chained command\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\tsmb2_set_err_rsp(work);\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_share_config_flag(share, KSMBD_SHARE_FLAG_PIPE)) {\n\t\tksmbd_debug(SMB, \"IPC pipe create request\\n\");\n\t\treturn create_smb2_pipe(work);\n\t}\n\n\tif (req->NameLength) {\n\t\tif ((req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t\t    *(char *)req->Buffer == '\\\\') {\n\t\t\tpr_err(\"not allow directory name included leading slash\\n\");\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tname = smb2_get_name(req->Buffer,\n\t\t\t\t     le16_to_cpu(req->NameLength),\n\t\t\t\t     work->conn->local_nls);\n\t\tif (IS_ERR(name)) {\n\t\t\trc = PTR_ERR(name);\n\t\t\tif (rc != -ENOMEM)\n\t\t\t\trc = -ENOENT;\n\t\t\tname = NULL;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tksmbd_debug(SMB, \"converted name = %s\\n\", name);\n\t\tif (strchr(name, ':')) {\n\t\t\tif (!test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t    KSMBD_SHARE_FLAG_STREAMS)) {\n\t\t\t\trc = -EBADF;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\trc = parse_stream_name(name, &stream_name, &s_type);\n\t\t\tif (rc < 0)\n\t\t\t\tgoto err_out1;\n\t\t}\n\n\t\trc = ksmbd_validate_filename(name);\n\t\tif (rc < 0)\n\t\t\tgoto err_out1;\n\n\t\tif (ksmbd_share_veto_filename(share, name)) {\n\t\t\trc = -ENOENT;\n\t\t\tksmbd_debug(SMB, \"Reject open(), vetoed file: %s\\n\",\n\t\t\t\t    name);\n\t\t\tgoto err_out1;\n\t\t}\n\t} else {\n\t\tname = kstrdup(\"\", GFP_KERNEL);\n\t\tif (!name) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto err_out1;\n\t\t}\n\t}\n\n\treq_op_level = req->RequestedOplockLevel;\n\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE)\n\t\tlc = parse_lease_state(req);\n\n\tif (le32_to_cpu(req->ImpersonationLevel) > le32_to_cpu(IL_DELEGATE)) {\n\t\tpr_err(\"Invalid impersonationlevel : 0x%x\\n\",\n\t\t       le32_to_cpu(req->ImpersonationLevel));\n\t\trc = -EIO;\n\t\trsp->hdr.Status = STATUS_BAD_IMPERSONATION_LEVEL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateOptions && !(req->CreateOptions & CREATE_OPTIONS_MASK_LE)) {\n\t\tpr_err(\"Invalid create options : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateOptions));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t} else {\n\t\tif (req->CreateOptions & FILE_SEQUENTIAL_ONLY_LE &&\n\t\t    req->CreateOptions & FILE_RANDOM_ACCESS_LE)\n\t\t\treq->CreateOptions = ~(FILE_SEQUENTIAL_ONLY_LE);\n\n\t\tif (req->CreateOptions &\n\t\t    (FILE_OPEN_BY_FILE_ID_LE | CREATE_TREE_CONNECTION |\n\t\t     FILE_RESERVE_OPFILTER_LE)) {\n\t\t\trc = -EOPNOTSUPP;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (req->CreateOptions & FILE_NO_COMPRESSION_LE) {\n\t\t\t\treq->CreateOptions = ~(FILE_NO_COMPRESSION_LE);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (le32_to_cpu(req->CreateDisposition) >\n\t    le32_to_cpu(FILE_OVERWRITE_IF_LE)) {\n\t\tpr_err(\"Invalid create disposition : 0x%x\\n\",\n\t\t       le32_to_cpu(req->CreateDisposition));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (!(req->DesiredAccess & DESIRED_ACCESS_MASK)) {\n\t\tpr_err(\"Invalid desired access : 0x%x\\n\",\n\t\t       le32_to_cpu(req->DesiredAccess));\n\t\trc = -EACCES;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->FileAttributes && !(req->FileAttributes & FILE_ATTRIBUTE_MASK_LE)) {\n\t\tpr_err(\"Invalid file attribute : 0x%x\\n\",\n\t\t       le32_to_cpu(req->FileAttributes));\n\t\trc = -EINVAL;\n\t\tgoto err_out1;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\t/* Parse non-durable handle create contexts */\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER, 4);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tea_buf = (struct create_ea_buf_req *)context;\n\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t    sizeof(struct create_ea_buf_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t\tif (req->CreateOptions & FILE_NO_EA_KNOWLEDGE_LE) {\n\t\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out1;\n\t\t\t}\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST, 4);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"get query maximal access context\\n\");\n\t\t\tmaximal_access_ctxt = 1;\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST, 4);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out1;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get timewarp context\\n\");\n\t\t\trc = -EBADF;\n\t\t\tgoto err_out1;\n\t\t}\n\n\t\tif (tcon->posix_extensions) {\n\t\t\tcontext = smb2_find_context_vals(req,\n\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX, 16);\n\t\t\tif (IS_ERR(context)) {\n\t\t\t\trc = PTR_ERR(context);\n\t\t\t\tgoto err_out1;\n\t\t\t} else if (context) {\n\t\t\t\tstruct create_posix *posix =\n\t\t\t\t\t(struct create_posix *)context;\n\t\t\t\tif (le16_to_cpu(context->DataOffset) +\n\t\t\t\t    le32_to_cpu(context->DataLength) <\n\t\t\t\t    sizeof(struct create_posix) - 4) {\n\t\t\t\t\trc = -EINVAL;\n\t\t\t\t\tgoto err_out1;\n\t\t\t\t}\n\t\t\t\tksmbd_debug(SMB, \"get posix context\\n\");\n\n\t\t\t\tposix_mode = le32_to_cpu(posix->Mode);\n\t\t\t\tposix_ctxt = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ksmbd_override_fsids(work)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out1;\n\t}\n\n\trc = ksmbd_vfs_kern_path_locked(work, name, LOOKUP_NO_SYMLINKS, &path, 1);\n\tif (!rc) {\n\t\tfile_present = true;\n\n\t\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE) {\n\t\t\t/*\n\t\t\t * If file exists with under flags, return access\n\t\t\t * denied error.\n\t\t\t */\n\t\t\tif (req->CreateDisposition == FILE_OVERWRITE_IF_LE ||\n\t\t\t    req->CreateDisposition == FILE_OPEN_IF_LE) {\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\t\trc = -EACCES;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t} else if (d_is_symlink(path.dentry)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tfile_present = true;\n\t\tidmap = mnt_idmap(path.mnt);\n\t} else {\n\t\tif (rc != -ENOENT)\n\t\t\tgoto err_out;\n\t\tksmbd_debug(SMB, \"can not get linux path for %s, rc = %d\\n\",\n\t\t\t    name, rc);\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE) {\n\t\t\tif (s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\t}\n\t\t} else {\n\t\t\tif (file_present && S_ISDIR(d_inode(path.dentry)->i_mode) &&\n\t\t\t    s_type == DATA_STREAM) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\t\t}\n\t\t}\n\n\t\tif (req->CreateOptions & FILE_DIRECTORY_FILE_LE &&\n\t\t    req->FileAttributes & FILE_ATTRIBUTE_NORMAL_LE) {\n\t\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\t\trc = -EIO;\n\t\t}\n\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (file_present && req->CreateOptions & FILE_NON_DIRECTORY_FILE_LE &&\n\t    S_ISDIR(d_inode(path.dentry)->i_mode) &&\n\t    !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\tksmbd_debug(SMB, \"open() argument is a directory: %s, %x\\n\",\n\t\t\t    name, req->CreateOptions);\n\t\trsp->hdr.Status = STATUS_FILE_IS_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (file_present && (req->CreateOptions & FILE_DIRECTORY_FILE_LE) &&\n\t    !(req->CreateDisposition == FILE_CREATE_LE) &&\n\t    !S_ISDIR(d_inode(path.dentry)->i_mode)) {\n\t\trsp->hdr.Status = STATUS_NOT_A_DIRECTORY;\n\t\trc = -EIO;\n\t\tgoto err_out;\n\t}\n\n\tif (!stream_name && file_present &&\n\t    req->CreateDisposition == FILE_CREATE_LE) {\n\t\trc = -EEXIST;\n\t\tgoto err_out;\n\t}\n\n\tdaccess = smb_map_generic_desired_access(req->DesiredAccess);\n\n\tif (file_present && !(req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\trc = smb_check_perm_dacl(conn, &path, &daccess,\n\t\t\t\t\t sess->user->uid);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (daccess & FILE_MAXIMAL_ACCESS_LE) {\n\t\tif (!file_present) {\n\t\t\tdaccess = cpu_to_le32(GENERIC_ALL_FLAGS);\n\t\t} else {\n\t\t\trc = ksmbd_vfs_query_maximal_access(idmap,\n\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t    &daccess);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t\talready_permitted = true;\n\t\t}\n\t\tmaximal_access = daccess;\n\t}\n\n\topen_flags = smb2_create_open_flags(file_present, daccess,\n\t\t\t\t\t    req->CreateDisposition,\n\t\t\t\t\t    &may_flags);\n\n\tif (!test_tree_conn_flag(tcon, KSMBD_TREE_CONN_FLAG_WRITABLE)) {\n\t\tif (open_flags & O_CREAT) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"User does not have write permission\\n\");\n\t\t\trc = -EACCES;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\t/*create file if not present */\n\tif (!file_present) {\n\t\trc = smb2_creat(work, &path, name, open_flags, posix_mode,\n\t\t\t\treq->CreateOptions & FILE_DIRECTORY_FILE_LE);\n\t\tif (rc) {\n\t\t\tif (rc == -ENOENT) {\n\t\t\t\trc = -EIO;\n\t\t\t\trsp->hdr.Status = STATUS_OBJECT_PATH_NOT_FOUND;\n\t\t\t}\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tcreated = true;\n\t\tidmap = mnt_idmap(path.mnt);\n\t\tif (ea_buf) {\n\t\t\tif (le32_to_cpu(ea_buf->ccontext.DataLength) <\n\t\t\t    sizeof(struct smb2_ea_info)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\n\t\t\trc = smb2_set_ea(&ea_buf->ea,\n\t\t\t\t\t le32_to_cpu(ea_buf->ccontext.DataLength),\n\t\t\t\t\t &path);\n\t\t\tif (rc == -EOPNOTSUPP)\n\t\t\t\trc = 0;\n\t\t\telse if (rc)\n\t\t\t\tgoto err_out;\n\t\t}\n\t} else if (!already_permitted) {\n\t\t/* FILE_READ_ATTRIBUTE is allowed without inode_permission,\n\t\t * because execute(search) permission on a parent directory,\n\t\t * is already granted.\n\t\t */\n\t\tif (daccess & ~(FILE_READ_ATTRIBUTES_LE | FILE_READ_CONTROL_LE)) {\n\t\t\trc = inode_permission(idmap,\n\t\t\t\t\t      d_inode(path.dentry),\n\t\t\t\t\t      may_flags);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\n\t\t\tif ((daccess & FILE_DELETE_LE) ||\n\t\t\t    (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)) {\n\t\t\t\trc = inode_permission(idmap,\n\t\t\t\t\t\t      d_inode(path.dentry->d_parent),\n\t\t\t\t\t\t      MAY_EXEC | MAY_WRITE);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t}\n\t}\n\n\trc = ksmbd_query_inode_status(d_inode(path.dentry->d_parent));\n\tif (rc == KSMBD_INODE_STATUS_PENDING_DELETE) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\trc = 0;\n\tfilp = dentry_open(&path, open_flags, current_cred());\n\tif (IS_ERR(filp)) {\n\t\trc = PTR_ERR(filp);\n\t\tpr_err(\"dentry open for dir failed, rc %d\\n\", rc);\n\t\tgoto err_out;\n\t}\n\n\tif (file_present) {\n\t\tif (!(open_flags & O_TRUNC))\n\t\t\tfile_info = FILE_OPENED;\n\t\telse\n\t\t\tfile_info = FILE_OVERWRITTEN;\n\n\t\tif ((req->CreateDisposition & FILE_CREATE_MASK_LE) ==\n\t\t    FILE_SUPERSEDE_LE)\n\t\t\tfile_info = FILE_SUPERSEDED;\n\t} else if (open_flags & O_CREAT) {\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tksmbd_vfs_set_fadvise(filp, req->CreateOptions);\n\n\t/* Obtain Volatile-ID */\n\tfp = ksmbd_open_fd(work, filp);\n\tif (IS_ERR(fp)) {\n\t\tfput(filp);\n\t\trc = PTR_ERR(fp);\n\t\tfp = NULL;\n\t\tgoto err_out;\n\t}\n\n\t/* Get Persistent-ID */\n\tksmbd_open_durable_fd(fp);\n\tif (!has_file_id(fp->persistent_id)) {\n\t\trc = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tfp->cdoption = req->CreateDisposition;\n\tfp->daccess = daccess;\n\tfp->saccess = req->ShareAccess;\n\tfp->coption = req->CreateOptions;\n\n\t/* Set default windows and posix acls if creating new file */\n\tif (created) {\n\t\tint posix_acl_rc;\n\t\tstruct inode *inode = d_inode(path.dentry);\n\n\t\tposix_acl_rc = ksmbd_vfs_inherit_posix_acl(idmap,\n\t\t\t\t\t\t\t   path.dentry,\n\t\t\t\t\t\t\t   d_inode(path.dentry->d_parent));\n\t\tif (posix_acl_rc)\n\t\t\tksmbd_debug(SMB, \"inherit posix acl failed : %d\\n\", posix_acl_rc);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\trc = smb_inherit_dacl(conn, &path, sess->user->uid,\n\t\t\t\t\t      sess->user->gid);\n\t\t}\n\n\t\tif (rc) {\n\t\t\trc = smb2_create_sd_buffer(work, req, &path);\n\t\t\tif (rc) {\n\t\t\t\tif (posix_acl_rc)\n\t\t\t\t\tksmbd_vfs_set_init_posix_acl(idmap,\n\t\t\t\t\t\t\t\t     path.dentry);\n\n\t\t\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t\t\t\t\t\t   KSMBD_SHARE_FLAG_ACL_XATTR)) {\n\t\t\t\t\tstruct smb_fattr fattr;\n\t\t\t\t\tstruct smb_ntsd *pntsd;\n\t\t\t\t\tint pntsd_size, ace_num = 0;\n\n\t\t\t\t\tksmbd_acls_fattr(&fattr, idmap, inode);\n\t\t\t\t\tif (fattr.cf_acls)\n\t\t\t\t\t\tace_num = fattr.cf_acls->a_count;\n\t\t\t\t\tif (fattr.cf_dacls)\n\t\t\t\t\t\tace_num += fattr.cf_dacls->a_count;\n\n\t\t\t\t\tpntsd = kmalloc(sizeof(struct smb_ntsd) +\n\t\t\t\t\t\t\tsizeof(struct smb_sid) * 3 +\n\t\t\t\t\t\t\tsizeof(struct smb_acl) +\n\t\t\t\t\t\t\tsizeof(struct smb_ace) * ace_num * 2,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\t\t\tif (!pntsd) {\n\t\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = build_sec_desc(idmap,\n\t\t\t\t\t\t\t    pntsd, NULL, 0,\n\t\t\t\t\t\t\t    OWNER_SECINFO |\n\t\t\t\t\t\t\t    GROUP_SECINFO |\n\t\t\t\t\t\t\t    DACL_SECINFO,\n\t\t\t\t\t\t\t    &pntsd_size, &fattr);\n\t\t\t\t\tposix_acl_release(fattr.cf_acls);\n\t\t\t\t\tposix_acl_release(fattr.cf_dacls);\n\t\t\t\t\tif (rc) {\n\t\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\t\tgoto err_out;\n\t\t\t\t\t}\n\n\t\t\t\t\trc = ksmbd_vfs_set_sd_xattr(conn,\n\t\t\t\t\t\t\t\t    idmap,\n\t\t\t\t\t\t\t\t    path.dentry,\n\t\t\t\t\t\t\t\t    pntsd,\n\t\t\t\t\t\t\t\t    pntsd_size);\n\t\t\t\t\tkfree(pntsd);\n\t\t\t\t\tif (rc)\n\t\t\t\t\t\tpr_err(\"failed to store ntacl in xattr : %d\\n\",\n\t\t\t\t\t\t       rc);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\trc = 0;\n\t}\n\n\tif (stream_name) {\n\t\trc = smb2_set_stream_name_xattr(&path,\n\t\t\t\t\t\tfp,\n\t\t\t\t\t\tstream_name,\n\t\t\t\t\t\ts_type);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t\tfile_info = FILE_CREATED;\n\t}\n\n\tfp->attrib_only = !(req->DesiredAccess & ~(FILE_READ_ATTRIBUTES_LE |\n\t\t\tFILE_WRITE_ATTRIBUTES_LE | FILE_SYNCHRONIZE_LE));\n\tif (!S_ISDIR(file_inode(filp)->i_mode) && open_flags & O_TRUNC &&\n\t    !fp->attrib_only && !stream_name) {\n\t\tsmb_break_all_oplock(work, fp);\n\t\tneed_truncate = 1;\n\t}\n\n\t/* fp should be searchable through ksmbd_inode.m_fp_list\n\t * after daccess, saccess, attrib_only, and stream are\n\t * initialized.\n\t */\n\twrite_lock(&fp->f_ci->m_lock);\n\tlist_add(&fp->node, &fp->f_ci->m_fp_list);\n\twrite_unlock(&fp->f_ci->m_lock);\n\n\t/* Check delete pending among previous fp before oplock break */\n\tif (ksmbd_inode_pending_delete(fp)) {\n\t\trc = -EBUSY;\n\t\tgoto err_out;\n\t}\n\n\tshare_ret = ksmbd_smb_check_shared_mode(fp->filp, fp);\n\tif (!test_share_config_flag(work->tcon->share_conf, KSMBD_SHARE_FLAG_OPLOCKS) ||\n\t    (req_op_level == SMB2_OPLOCK_LEVEL_LEASE &&\n\t     !(conn->vals->capabilities & SMB2_GLOBAL_CAP_LEASING))) {\n\t\tif (share_ret < 0 && !S_ISDIR(file_inode(fp->filp)->i_mode)) {\n\t\t\trc = share_ret;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (req_op_level == SMB2_OPLOCK_LEVEL_LEASE) {\n\t\t\treq_op_level = smb2_map_lease_to_oplock(lc->req_state);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"lease req for(%s) req oplock state 0x%x, lease state 0x%x\\n\",\n\t\t\t\t    name, req_op_level, lc->req_state);\n\t\t\trc = find_same_lease_key(sess, fp->f_ci, lc);\n\t\t\tif (rc)\n\t\t\t\tgoto err_out;\n\t\t} else if (open_flags == O_RDONLY &&\n\t\t\t   (req_op_level == SMB2_OPLOCK_LEVEL_BATCH ||\n\t\t\t    req_op_level == SMB2_OPLOCK_LEVEL_EXCLUSIVE))\n\t\t\treq_op_level = SMB2_OPLOCK_LEVEL_II;\n\n\t\trc = smb_grant_oplock(work, req_op_level,\n\t\t\t\t      fp->persistent_id, fp,\n\t\t\t\t      le32_to_cpu(req->hdr.Id.SyncId.TreeId),\n\t\t\t\t      lc, share_ret);\n\t\tif (rc < 0)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateOptions & FILE_DELETE_ON_CLOSE_LE)\n\t\tksmbd_fd_set_delete_on_close(fp, file_info);\n\n\tif (need_truncate) {\n\t\trc = smb2_create_truncate(&path);\n\t\tif (rc)\n\t\t\tgoto err_out;\n\t}\n\n\tif (req->CreateContextsOffset) {\n\t\tstruct create_alloc_size_req *az_req;\n\n\t\taz_req = (struct create_alloc_size_req *)smb2_find_context_vals(req,\n\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE, 4);\n\t\tif (IS_ERR(az_req)) {\n\t\t\trc = PTR_ERR(az_req);\n\t\t\tgoto err_out;\n\t\t} else if (az_req) {\n\t\t\tloff_t alloc_size;\n\t\t\tint err;\n\n\t\t\tif (le16_to_cpu(az_req->ccontext.DataOffset) +\n\t\t\t    le32_to_cpu(az_req->ccontext.DataLength) <\n\t\t\t    sizeof(struct create_alloc_size_req)) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\talloc_size = le64_to_cpu(az_req->AllocationSize);\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"request smb2 create allocate size : %llu\\n\",\n\t\t\t\t    alloc_size);\n\t\t\tsmb_break_all_levII_oplock(work, fp, 1);\n\t\t\terr = vfs_fallocate(fp->filp, FALLOC_FL_KEEP_SIZE, 0,\n\t\t\t\t\t    alloc_size);\n\t\t\tif (err < 0)\n\t\t\t\tksmbd_debug(SMB,\n\t\t\t\t\t    \"vfs_fallocate is failed : %d\\n\",\n\t\t\t\t\t    err);\n\t\t}\n\n\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID, 4);\n\t\tif (IS_ERR(context)) {\n\t\t\trc = PTR_ERR(context);\n\t\t\tgoto err_out;\n\t\t} else if (context) {\n\t\t\tksmbd_debug(SMB, \"get query on disk id context\\n\");\n\t\t\tquery_disk_id = 1;\n\t\t}\n\t}\n\n\trc = ksmbd_vfs_getattr(&path, &stat);\n\tif (rc)\n\t\tgoto err_out;\n\n\tif (stat.result_mask & STATX_BTIME)\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.btime);\n\telse\n\t\tfp->create_time = ksmbd_UnixTimeToNT(stat.ctime);\n\tif (req->FileAttributes || fp->f_ci->m_fattr == 0)\n\t\tfp->f_ci->m_fattr =\n\t\t\tcpu_to_le32(smb2_get_dos_mode(&stat, le32_to_cpu(req->FileAttributes)));\n\n\tif (!created)\n\t\tsmb2_update_xattrs(tcon, &path, fp);\n\telse\n\t\tsmb2_new_xattrs(tcon, &path, fp);\n\n\tmemcpy(fp->client_guid, conn->ClientGUID, SMB2_CLIENT_GUID_SIZE);\n\n\trsp->StructureSize = cpu_to_le16(89);\n\trcu_read_lock();\n\topinfo = rcu_dereference(fp->f_opinfo);\n\trsp->OplockLevel = opinfo != NULL ? opinfo->level : 0;\n\trcu_read_unlock();\n\trsp->Flags = 0;\n\trsp->CreateAction = cpu_to_le32(file_info);\n\trsp->CreationTime = cpu_to_le64(fp->create_time);\n\ttime = ksmbd_UnixTimeToNT(stat.atime);\n\trsp->LastAccessTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.mtime);\n\trsp->LastWriteTime = cpu_to_le64(time);\n\ttime = ksmbd_UnixTimeToNT(stat.ctime);\n\trsp->ChangeTime = cpu_to_le64(time);\n\trsp->AllocationSize = S_ISDIR(stat.mode) ? 0 :\n\t\tcpu_to_le64(stat.blocks << 9);\n\trsp->EndofFile = S_ISDIR(stat.mode) ? 0 : cpu_to_le64(stat.size);\n\trsp->FileAttributes = fp->f_ci->m_fattr;\n\n\trsp->Reserved2 = 0;\n\n\trsp->PersistentFileId = fp->persistent_id;\n\trsp->VolatileFileId = fp->volatile_id;\n\n\trsp->CreateContextsOffset = 0;\n\trsp->CreateContextsLength = 0;\n\tinc_rfc1001_len(work->response_buf, 88); /* StructureSize - 1*/\n\n\t/* If lease is request send lease context response */\n\tif (opinfo && opinfo->is_lease) {\n\t\tstruct create_context *lease_ccontext;\n\n\t\tksmbd_debug(SMB, \"lease granted on(%s) lease state 0x%x\\n\",\n\t\t\t    name, opinfo->o_lease->state);\n\t\trsp->OplockLevel = SMB2_OPLOCK_LEVEL_LEASE;\n\n\t\tlease_ccontext = (struct create_context *)rsp->Buffer;\n\t\tcontxt_cnt++;\n\t\tcreate_lease_buf(rsp->Buffer, opinfo->o_lease);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_lease_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_lease_size);\n\t\tnext_ptr = &lease_ccontext->Next;\n\t\tnext_off = conn->vals->create_lease_size;\n\t}\n\n\tif (maximal_access_ctxt) {\n\t\tstruct create_context *mxac_ccontext;\n\n\t\tif (maximal_access == 0)\n\t\t\tksmbd_vfs_query_maximal_access(idmap,\n\t\t\t\t\t\t       path.dentry,\n\t\t\t\t\t\t       &maximal_access);\n\t\tmxac_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_mxac_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tle32_to_cpu(maximal_access));\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_mxac_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_mxac_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &mxac_ccontext->Next;\n\t\tnext_off = conn->vals->create_mxac_size;\n\t}\n\n\tif (query_disk_id) {\n\t\tstruct create_context *disk_id_ccontext;\n\n\t\tdisk_id_ccontext = (struct create_context *)(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength));\n\t\tcontxt_cnt++;\n\t\tcreate_disk_id_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tstat.ino, tcon->id);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_disk_id_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_disk_id_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t\tnext_ptr = &disk_id_ccontext->Next;\n\t\tnext_off = conn->vals->create_disk_id_size;\n\t}\n\n\tif (posix_ctxt) {\n\t\tcontxt_cnt++;\n\t\tcreate_posix_rsp_buf(rsp->Buffer +\n\t\t\t\tle32_to_cpu(rsp->CreateContextsLength),\n\t\t\t\tfp);\n\t\tle32_add_cpu(&rsp->CreateContextsLength,\n\t\t\t     conn->vals->create_posix_size);\n\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\tconn->vals->create_posix_size);\n\t\tif (next_ptr)\n\t\t\t*next_ptr = cpu_to_le32(next_off);\n\t}\n\n\tif (contxt_cnt > 0) {\n\t\trsp->CreateContextsOffset =\n\t\t\tcpu_to_le32(offsetof(struct smb2_create_rsp, Buffer));\n\t}\n\nerr_out:\n\tif (file_present || created) {\n\t\tinode_unlock(d_inode(path.dentry->d_parent));\n\t\tdput(path.dentry);\n\t}\n\tksmbd_revert_fsids(work);\nerr_out1:\n\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\telse if (rc == -EOPNOTSUPP)\n\t\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\telse if (rc == -EACCES || rc == -ESTALE || rc == -EXDEV)\n\t\t\trsp->hdr.Status = STATUS_ACCESS_DENIED;\n\t\telse if (rc == -ENOENT)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_INVALID;\n\t\telse if (rc == -EPERM)\n\t\t\trsp->hdr.Status = STATUS_SHARING_VIOLATION;\n\t\telse if (rc == -EBUSY)\n\t\t\trsp->hdr.Status = STATUS_DELETE_PENDING;\n\t\telse if (rc == -EBADF)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_NOT_FOUND;\n\t\telse if (rc == -ENOEXEC)\n\t\t\trsp->hdr.Status = STATUS_DUPLICATE_OBJECTID;\n\t\telse if (rc == -ENXIO)\n\t\t\trsp->hdr.Status = STATUS_NO_SUCH_DEVICE;\n\t\telse if (rc == -EEXIST)\n\t\t\trsp->hdr.Status = STATUS_OBJECT_NAME_COLLISION;\n\t\telse if (rc == -EMFILE)\n\t\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\t\tif (!rsp->hdr.Status)\n\t\t\trsp->hdr.Status = STATUS_UNEXPECTED_IO_ERROR;\n\n\t\tif (fp)\n\t\t\tksmbd_fd_put(work, fp);\n\t\tsmb2_set_err_rsp(work);\n\t\tksmbd_debug(SMB, \"Error response: %x\\n\", rsp->hdr.Status);\n\t}\n\n\tkfree(name);\n\tkfree(lc);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -157,7 +157,7 @@\n \n \tif (req->CreateContextsOffset) {\n \t\t/* Parse non-durable handle create contexts */\n-\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER);\n+\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER, 4);\n \t\tif (IS_ERR(context)) {\n \t\t\trc = PTR_ERR(context);\n \t\t\tgoto err_out1;\n@@ -177,7 +177,7 @@\n \t\t}\n \n \t\tcontext = smb2_find_context_vals(req,\n-\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST);\n+\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST, 4);\n \t\tif (IS_ERR(context)) {\n \t\t\trc = PTR_ERR(context);\n \t\t\tgoto err_out1;\n@@ -188,7 +188,7 @@\n \t\t}\n \n \t\tcontext = smb2_find_context_vals(req,\n-\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST);\n+\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST, 4);\n \t\tif (IS_ERR(context)) {\n \t\t\trc = PTR_ERR(context);\n \t\t\tgoto err_out1;\n@@ -200,7 +200,7 @@\n \n \t\tif (tcon->posix_extensions) {\n \t\t\tcontext = smb2_find_context_vals(req,\n-\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX);\n+\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX, 16);\n \t\t\tif (IS_ERR(context)) {\n \t\t\t\trc = PTR_ERR(context);\n \t\t\t\tgoto err_out1;\n@@ -598,7 +598,7 @@\n \t\tstruct create_alloc_size_req *az_req;\n \n \t\taz_req = (struct create_alloc_size_req *)smb2_find_context_vals(req,\n-\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE);\n+\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE, 4);\n \t\tif (IS_ERR(az_req)) {\n \t\t\trc = PTR_ERR(az_req);\n \t\t\tgoto err_out;\n@@ -625,7 +625,7 @@\n \t\t\t\t\t    err);\n \t\t}\n \n-\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID);\n+\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID, 4);\n \t\tif (IS_ERR(context)) {\n \t\t\trc = PTR_ERR(context);\n \t\t\tgoto err_out;",
        "function_modified_lines": {
            "added": [
                "\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER, 4);",
                "\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST, 4);",
                "\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST, 4);",
                "\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX, 16);",
                "\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE, 4);",
                "\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID, 4);"
            ],
            "deleted": [
                "\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_EA_BUFFER);",
                "\t\t\t\t\t\t SMB2_CREATE_QUERY_MAXIMAL_ACCESS_REQUEST);",
                "\t\t\t\t\t\t SMB2_CREATE_TIMEWARP_REQUEST);",
                "\t\t\t\t\t\t\t SMB2_CREATE_TAG_POSIX);",
                "\t\t\t\t\tSMB2_CREATE_ALLOCATION_SIZE);",
                "\t\tcontext = smb2_find_context_vals(req, SMB2_CREATE_QUERY_ON_DISK_ID);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.4. ksmbd has an out-of-bounds read in smb2_find_context_vals when create_context's name_len is larger than the tag length.",
        "id": 4138
    },
    {
        "cve_id": "CVE-2017-7277",
        "code_before_change": "void __sock_recv_timestamp(struct msghdr *msg, struct sock *sk,\n\tstruct sk_buff *skb)\n{\n\tint need_software_tstamp = sock_flag(sk, SOCK_RCVTSTAMP);\n\tstruct scm_timestamping tss;\n\tint empty = 1;\n\tstruct skb_shared_hwtstamps *shhwtstamps =\n\t\tskb_hwtstamps(skb);\n\n\t/* Race occurred between timestamp enabling and packet\n\t   receiving.  Fill in the current time for now. */\n\tif (need_software_tstamp && skb->tstamp == 0)\n\t\t__net_timestamp(skb);\n\n\tif (need_software_tstamp) {\n\t\tif (!sock_flag(sk, SOCK_RCVTSTAMPNS)) {\n\t\t\tstruct timeval tv;\n\t\t\tskb_get_timestamp(skb, &tv);\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMP,\n\t\t\t\t sizeof(tv), &tv);\n\t\t} else {\n\t\t\tstruct timespec ts;\n\t\t\tskb_get_timestampns(skb, &ts);\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPNS,\n\t\t\t\t sizeof(ts), &ts);\n\t\t}\n\t}\n\n\tmemset(&tss, 0, sizeof(tss));\n\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_SOFTWARE) &&\n\t    ktime_to_timespec_cond(skb->tstamp, tss.ts + 0))\n\t\tempty = 0;\n\tif (shhwtstamps &&\n\t    (sk->sk_tsflags & SOF_TIMESTAMPING_RAW_HARDWARE) &&\n\t    ktime_to_timespec_cond(shhwtstamps->hwtstamp, tss.ts + 2))\n\t\tempty = 0;\n\tif (!empty) {\n\t\tput_cmsg(msg, SOL_SOCKET,\n\t\t\t SCM_TIMESTAMPING, sizeof(tss), &tss);\n\n\t\tif (skb_is_err_queue(skb) && skb->len &&\n\t\t    (sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS))\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPING_OPT_STATS,\n\t\t\t\t skb->len, skb->data);\n\t}\n}",
        "code_after_change": "void __sock_recv_timestamp(struct msghdr *msg, struct sock *sk,\n\tstruct sk_buff *skb)\n{\n\tint need_software_tstamp = sock_flag(sk, SOCK_RCVTSTAMP);\n\tstruct scm_timestamping tss;\n\tint empty = 1;\n\tstruct skb_shared_hwtstamps *shhwtstamps =\n\t\tskb_hwtstamps(skb);\n\n\t/* Race occurred between timestamp enabling and packet\n\t   receiving.  Fill in the current time for now. */\n\tif (need_software_tstamp && skb->tstamp == 0)\n\t\t__net_timestamp(skb);\n\n\tif (need_software_tstamp) {\n\t\tif (!sock_flag(sk, SOCK_RCVTSTAMPNS)) {\n\t\t\tstruct timeval tv;\n\t\t\tskb_get_timestamp(skb, &tv);\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMP,\n\t\t\t\t sizeof(tv), &tv);\n\t\t} else {\n\t\t\tstruct timespec ts;\n\t\t\tskb_get_timestampns(skb, &ts);\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPNS,\n\t\t\t\t sizeof(ts), &ts);\n\t\t}\n\t}\n\n\tmemset(&tss, 0, sizeof(tss));\n\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_SOFTWARE) &&\n\t    ktime_to_timespec_cond(skb->tstamp, tss.ts + 0))\n\t\tempty = 0;\n\tif (shhwtstamps &&\n\t    (sk->sk_tsflags & SOF_TIMESTAMPING_RAW_HARDWARE) &&\n\t    ktime_to_timespec_cond(shhwtstamps->hwtstamp, tss.ts + 2))\n\t\tempty = 0;\n\tif (!empty) {\n\t\tput_cmsg(msg, SOL_SOCKET,\n\t\t\t SCM_TIMESTAMPING, sizeof(tss), &tss);\n\n\t\tif (skb_is_err_queue(skb) && skb->len &&\n\t\t    SKB_EXT_ERR(skb)->opt_stats)\n\t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPING_OPT_STATS,\n\t\t\t\t skb->len, skb->data);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,7 +39,7 @@\n \t\t\t SCM_TIMESTAMPING, sizeof(tss), &tss);\n \n \t\tif (skb_is_err_queue(skb) && skb->len &&\n-\t\t    (sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS))\n+\t\t    SKB_EXT_ERR(skb)->opt_stats)\n \t\t\tput_cmsg(msg, SOL_SOCKET, SCM_TIMESTAMPING_OPT_STATS,\n \t\t\t\t skb->len, skb->data);\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t    SKB_EXT_ERR(skb)->opt_stats)"
            ],
            "deleted": [
                "\t\t    (sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS))"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The TCP stack in the Linux kernel through 4.10.6 mishandles the SCM_TIMESTAMPING_OPT_STATS feature, which allows local users to obtain sensitive information from the kernel's internal socket data structures or cause a denial of service (out-of-bounds read) via crafted system calls, related to net/core/skbuff.c and net/socket.c.",
        "id": 1494
    },
    {
        "cve_id": "CVE-2022-20132",
        "code_before_change": "int uclogic_params_init(struct uclogic_params *params,\n\t\t\tstruct hid_device *hdev)\n{\n\tint rc;\n\tstruct usb_device *udev = hid_to_usb_dev(hdev);\n\t__u8  bNumInterfaces = udev->config->desc.bNumInterfaces;\n\tstruct usb_interface *iface = to_usb_interface(hdev->dev.parent);\n\t__u8 bInterfaceNumber = iface->cur_altsetting->desc.bInterfaceNumber;\n\tbool found;\n\t/* The resulting parameters (noop) */\n\tstruct uclogic_params p = {0, };\n\n\t/* Check arguments */\n\tif (params == NULL || hdev == NULL ||\n\t    !hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\trc = -EINVAL;\n\t\tgoto cleanup;\n\t}\n\n\t/*\n\t * Set replacement report descriptor if the original matches the\n\t * specified size. Otherwise keep interface unchanged.\n\t */\n#define WITH_OPT_DESC(_orig_desc_token, _new_desc_token) \\\n\tuclogic_params_init_with_opt_desc(                  \\\n\t\t&p, hdev,                                   \\\n\t\tUCLOGIC_RDESC_##_orig_desc_token##_SIZE,    \\\n\t\tuclogic_rdesc_##_new_desc_token##_arr,      \\\n\t\tuclogic_rdesc_##_new_desc_token##_size)\n\n#define VID_PID(_vid, _pid) \\\n\t(((__u32)(_vid) << 16) | ((__u32)(_pid) & U16_MAX))\n\n\t/*\n\t * Handle specific interfaces for specific tablets.\n\t *\n\t * Observe the following logic:\n\t *\n\t * If the interface is recognized as producing certain useful input:\n\t *\tMark interface as valid.\n\t *\tOutput interface parameters.\n\t * Else, if the interface is recognized as *not* producing any useful\n\t * input:\n\t *\tMark interface as invalid.\n\t * Else:\n\t *\tMark interface as valid.\n\t *\tOutput noop parameters.\n\t *\n\t * Rule of thumb: it is better to disable a broken interface than let\n\t *\t\t  it spew garbage input.\n\t */\n\n\tswitch (VID_PID(hdev->vendor, hdev->product)) {\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_PF1209):\n\t\trc = WITH_OPT_DESC(PF1209_ORIG, pf1209_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP4030U):\n\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp4030u_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP5540U):\n\t\tif (hdev->dev_rsize == UCLOGIC_RDESC_WP5540U_V2_ORIG_SIZE) {\n\t\t\tif (bInterfaceNumber == 0) {\n\t\t\t\t/* Try to probe v1 pen parameters */\n\t\t\t\trc = uclogic_params_pen_init_v1(&p.pen,\n\t\t\t\t\t\t\t\t&found, hdev);\n\t\t\t\tif (rc != 0) {\n\t\t\t\t\thid_err(hdev,\n\t\t\t\t\t\t\"pen probing failed: %d\\n\",\n\t\t\t\t\t\trc);\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\t\t\t\tif (!found) {\n\t\t\t\t\thid_warn(hdev,\n\t\t\t\t\t\t \"pen parameters not found\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tuclogic_params_init_invalid(&p);\n\t\t\t}\n\t\t} else {\n\t\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp5540u_fixed);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP8060U):\n\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp8060u_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP1062):\n\t\trc = WITH_OPT_DESC(WP1062_ORIG, wp1062_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_WIRELESS_TABLET_TWHL850):\n\t\tswitch (bInterfaceNumber) {\n\t\tcase 0:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG0, twhl850_fixed0);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG1, twhl850_fixed1);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG2, twhl850_fixed2);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_TWHA60):\n\t\t/*\n\t\t * If it is not a three-interface version, which is known to\n\t\t * respond to initialization.\n\t\t */\n\t\tif (bNumInterfaces != 3) {\n\t\t\tswitch (bInterfaceNumber) {\n\t\t\tcase 0:\n\t\t\t\trc = WITH_OPT_DESC(TWHA60_ORIG0,\n\t\t\t\t\t\t\ttwha60_fixed0);\n\t\t\t\tif (rc != 0)\n\t\t\t\t\tgoto cleanup;\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\trc = WITH_OPT_DESC(TWHA60_ORIG1,\n\t\t\t\t\t\t\ttwha60_fixed1);\n\t\t\t\tif (rc != 0)\n\t\t\t\t\tgoto cleanup;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tcase VID_PID(USB_VENDOR_ID_HUION,\n\t\t     USB_DEVICE_ID_HUION_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_HUION,\n\t\t     USB_DEVICE_ID_HUION_HS64):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_HUION_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_YIYNOVA_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_81):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_DRAWIMAGE_G3):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_45):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_47):\n\t\trc = uclogic_params_huion_init(&p, hdev);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGTIZER,\n\t\t     USB_DEVICE_ID_UGTIZER_TABLET_GP0610):\n\tcase VID_PID(USB_VENDOR_ID_UGTIZER,\n\t\t     USB_DEVICE_ID_UGTIZER_TABLET_GT5040):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_G540):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_G640):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_RAINBOW_CV720):\n\t\t/* If this is the pen interface */\n\t\tif (bInterfaceNumber == 1) {\n\t\t\t/* Probe v1 pen parameters */\n\t\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tif (!found) {\n\t\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\t\tuclogic_params_init_invalid(&p);\n\t\t\t}\n\t\t} else {\n\t\t\t/* TODO: Consider marking the interface invalid */\n\t\t\tuclogic_params_init_with_pen_unused(&p);\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_DECO01):\n\t\t/* If this is the pen and frame interface */\n\t\tif (bInterfaceNumber == 1) {\n\t\t\t/* Probe v1 pen parameters */\n\t\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\t/* Initialize frame parameters */\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_xppen_deco01_frame_arr,\n\t\t\t\tuclogic_rdesc_xppen_deco01_frame_size,\n\t\t\t\t0);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t} else {\n\t\t\t/* TODO: Consider marking the interface invalid */\n\t\t\tuclogic_params_init_with_pen_unused(&p);\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_TRUST,\n\t\t     USB_DEVICE_ID_TRUST_PANORA_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_G5):\n\t\t/* Ignore non-pen interfaces */\n\t\tif (bInterfaceNumber != 1) {\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t\tbreak;\n\t\t}\n\n\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\tif (rc != 0) {\n\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\tgoto cleanup;\n\t\t} else if (found) {\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_ugee_g5_frame_arr,\n\t\t\t\tuclogic_rdesc_ugee_g5_frame_size,\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_ID);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev,\n\t\t\t\t\t\"failed creating buttonpad parameters: %d\\n\",\n\t\t\t\t\trc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tp.frame.re_lsb =\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_RE_LSB;\n\t\t\tp.frame.dev_id_byte =\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_DEV_ID_BYTE;\n\t\t} else {\n\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t}\n\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_EX07S):\n\t\t/* Ignore non-pen interfaces */\n\t\tif (bInterfaceNumber != 1) {\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t\tbreak;\n\t\t}\n\n\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\tif (rc != 0) {\n\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\tgoto cleanup;\n\t\t} else if (found) {\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_ugee_ex07_buttonpad_arr,\n\t\t\t\tuclogic_rdesc_ugee_ex07_buttonpad_size,\n\t\t\t\t0);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev,\n\t\t\t\t\t\"failed creating buttonpad parameters: %d\\n\",\n\t\t\t\t\trc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t} else {\n\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t}\n\n\t\tbreak;\n\t}\n\n#undef VID_PID\n#undef WITH_OPT_DESC\n\n\t/* Output parameters */\n\tmemcpy(params, &p, sizeof(*params));\n\tmemset(&p, 0, sizeof(p));\n\trc = 0;\ncleanup:\n\tuclogic_params_cleanup(&p);\n\treturn rc;\n}",
        "code_after_change": "int uclogic_params_init(struct uclogic_params *params,\n\t\t\tstruct hid_device *hdev)\n{\n\tint rc;\n\tstruct usb_device *udev = hid_to_usb_dev(hdev);\n\t__u8  bNumInterfaces = udev->config->desc.bNumInterfaces;\n\tstruct usb_interface *iface = to_usb_interface(hdev->dev.parent);\n\t__u8 bInterfaceNumber = iface->cur_altsetting->desc.bInterfaceNumber;\n\tbool found;\n\t/* The resulting parameters (noop) */\n\tstruct uclogic_params p = {0, };\n\n\t/* Check arguments */\n\tif (params == NULL || hdev == NULL || !hid_is_usb(hdev)) {\n\t\trc = -EINVAL;\n\t\tgoto cleanup;\n\t}\n\n\t/*\n\t * Set replacement report descriptor if the original matches the\n\t * specified size. Otherwise keep interface unchanged.\n\t */\n#define WITH_OPT_DESC(_orig_desc_token, _new_desc_token) \\\n\tuclogic_params_init_with_opt_desc(                  \\\n\t\t&p, hdev,                                   \\\n\t\tUCLOGIC_RDESC_##_orig_desc_token##_SIZE,    \\\n\t\tuclogic_rdesc_##_new_desc_token##_arr,      \\\n\t\tuclogic_rdesc_##_new_desc_token##_size)\n\n#define VID_PID(_vid, _pid) \\\n\t(((__u32)(_vid) << 16) | ((__u32)(_pid) & U16_MAX))\n\n\t/*\n\t * Handle specific interfaces for specific tablets.\n\t *\n\t * Observe the following logic:\n\t *\n\t * If the interface is recognized as producing certain useful input:\n\t *\tMark interface as valid.\n\t *\tOutput interface parameters.\n\t * Else, if the interface is recognized as *not* producing any useful\n\t * input:\n\t *\tMark interface as invalid.\n\t * Else:\n\t *\tMark interface as valid.\n\t *\tOutput noop parameters.\n\t *\n\t * Rule of thumb: it is better to disable a broken interface than let\n\t *\t\t  it spew garbage input.\n\t */\n\n\tswitch (VID_PID(hdev->vendor, hdev->product)) {\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_PF1209):\n\t\trc = WITH_OPT_DESC(PF1209_ORIG, pf1209_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP4030U):\n\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp4030u_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP5540U):\n\t\tif (hdev->dev_rsize == UCLOGIC_RDESC_WP5540U_V2_ORIG_SIZE) {\n\t\t\tif (bInterfaceNumber == 0) {\n\t\t\t\t/* Try to probe v1 pen parameters */\n\t\t\t\trc = uclogic_params_pen_init_v1(&p.pen,\n\t\t\t\t\t\t\t\t&found, hdev);\n\t\t\t\tif (rc != 0) {\n\t\t\t\t\thid_err(hdev,\n\t\t\t\t\t\t\"pen probing failed: %d\\n\",\n\t\t\t\t\t\trc);\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\t\t\t\tif (!found) {\n\t\t\t\t\thid_warn(hdev,\n\t\t\t\t\t\t \"pen parameters not found\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tuclogic_params_init_invalid(&p);\n\t\t\t}\n\t\t} else {\n\t\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp5540u_fixed);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP8060U):\n\t\trc = WITH_OPT_DESC(WPXXXXU_ORIG, wp8060u_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_WP1062):\n\t\trc = WITH_OPT_DESC(WP1062_ORIG, wp1062_fixed);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_WIRELESS_TABLET_TWHL850):\n\t\tswitch (bInterfaceNumber) {\n\t\tcase 0:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG0, twhl850_fixed0);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG1, twhl850_fixed1);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\trc = WITH_OPT_DESC(TWHL850_ORIG2, twhl850_fixed2);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_TABLET_TWHA60):\n\t\t/*\n\t\t * If it is not a three-interface version, which is known to\n\t\t * respond to initialization.\n\t\t */\n\t\tif (bNumInterfaces != 3) {\n\t\t\tswitch (bInterfaceNumber) {\n\t\t\tcase 0:\n\t\t\t\trc = WITH_OPT_DESC(TWHA60_ORIG0,\n\t\t\t\t\t\t\ttwha60_fixed0);\n\t\t\t\tif (rc != 0)\n\t\t\t\t\tgoto cleanup;\n\t\t\t\tbreak;\n\t\t\tcase 1:\n\t\t\t\trc = WITH_OPT_DESC(TWHA60_ORIG1,\n\t\t\t\t\t\t\ttwha60_fixed1);\n\t\t\t\tif (rc != 0)\n\t\t\t\t\tgoto cleanup;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tcase VID_PID(USB_VENDOR_ID_HUION,\n\t\t     USB_DEVICE_ID_HUION_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_HUION,\n\t\t     USB_DEVICE_ID_HUION_HS64):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_HUION_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_YIYNOVA_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_81):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_DRAWIMAGE_G3):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_45):\n\tcase VID_PID(USB_VENDOR_ID_UCLOGIC,\n\t\t     USB_DEVICE_ID_UCLOGIC_UGEE_TABLET_47):\n\t\trc = uclogic_params_huion_init(&p, hdev);\n\t\tif (rc != 0)\n\t\t\tgoto cleanup;\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGTIZER,\n\t\t     USB_DEVICE_ID_UGTIZER_TABLET_GP0610):\n\tcase VID_PID(USB_VENDOR_ID_UGTIZER,\n\t\t     USB_DEVICE_ID_UGTIZER_TABLET_GT5040):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_G540):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_G640):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_RAINBOW_CV720):\n\t\t/* If this is the pen interface */\n\t\tif (bInterfaceNumber == 1) {\n\t\t\t/* Probe v1 pen parameters */\n\t\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tif (!found) {\n\t\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\t\tuclogic_params_init_invalid(&p);\n\t\t\t}\n\t\t} else {\n\t\t\t/* TODO: Consider marking the interface invalid */\n\t\t\tuclogic_params_init_with_pen_unused(&p);\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_XPPEN_TABLET_DECO01):\n\t\t/* If this is the pen and frame interface */\n\t\tif (bInterfaceNumber == 1) {\n\t\t\t/* Probe v1 pen parameters */\n\t\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\t/* Initialize frame parameters */\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_xppen_deco01_frame_arr,\n\t\t\t\tuclogic_rdesc_xppen_deco01_frame_size,\n\t\t\t\t0);\n\t\t\tif (rc != 0)\n\t\t\t\tgoto cleanup;\n\t\t} else {\n\t\t\t/* TODO: Consider marking the interface invalid */\n\t\t\tuclogic_params_init_with_pen_unused(&p);\n\t\t}\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_TRUST,\n\t\t     USB_DEVICE_ID_TRUST_PANORA_TABLET):\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_G5):\n\t\t/* Ignore non-pen interfaces */\n\t\tif (bInterfaceNumber != 1) {\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t\tbreak;\n\t\t}\n\n\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\tif (rc != 0) {\n\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\tgoto cleanup;\n\t\t} else if (found) {\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_ugee_g5_frame_arr,\n\t\t\t\tuclogic_rdesc_ugee_g5_frame_size,\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_ID);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev,\n\t\t\t\t\t\"failed creating buttonpad parameters: %d\\n\",\n\t\t\t\t\trc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t\tp.frame.re_lsb =\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_RE_LSB;\n\t\t\tp.frame.dev_id_byte =\n\t\t\t\tUCLOGIC_RDESC_UGEE_G5_FRAME_DEV_ID_BYTE;\n\t\t} else {\n\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t}\n\n\t\tbreak;\n\tcase VID_PID(USB_VENDOR_ID_UGEE,\n\t\t     USB_DEVICE_ID_UGEE_TABLET_EX07S):\n\t\t/* Ignore non-pen interfaces */\n\t\tif (bInterfaceNumber != 1) {\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t\tbreak;\n\t\t}\n\n\t\trc = uclogic_params_pen_init_v1(&p.pen, &found, hdev);\n\t\tif (rc != 0) {\n\t\t\thid_err(hdev, \"pen probing failed: %d\\n\", rc);\n\t\t\tgoto cleanup;\n\t\t} else if (found) {\n\t\t\trc = uclogic_params_frame_init_with_desc(\n\t\t\t\t&p.frame,\n\t\t\t\tuclogic_rdesc_ugee_ex07_buttonpad_arr,\n\t\t\t\tuclogic_rdesc_ugee_ex07_buttonpad_size,\n\t\t\t\t0);\n\t\t\tif (rc != 0) {\n\t\t\t\thid_err(hdev,\n\t\t\t\t\t\"failed creating buttonpad parameters: %d\\n\",\n\t\t\t\t\trc);\n\t\t\t\tgoto cleanup;\n\t\t\t}\n\t\t} else {\n\t\t\thid_warn(hdev, \"pen parameters not found\");\n\t\t\tuclogic_params_init_invalid(&p);\n\t\t}\n\n\t\tbreak;\n\t}\n\n#undef VID_PID\n#undef WITH_OPT_DESC\n\n\t/* Output parameters */\n\tmemcpy(params, &p, sizeof(*params));\n\tmemset(&p, 0, sizeof(p));\n\trc = 0;\ncleanup:\n\tuclogic_params_cleanup(&p);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,8 +11,7 @@\n \tstruct uclogic_params p = {0, };\n \n \t/* Check arguments */\n-\tif (params == NULL || hdev == NULL ||\n-\t    !hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif (params == NULL || hdev == NULL || !hid_is_usb(hdev)) {\n \t\trc = -EINVAL;\n \t\tgoto cleanup;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (params == NULL || hdev == NULL || !hid_is_usb(hdev)) {"
            ],
            "deleted": [
                "\tif (params == NULL || hdev == NULL ||",
                "\t    !hid_is_using_ll_driver(hdev, &usb_hid_driver)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In lg_probe and related functions of hid-lg.c and other USB HID files, there is a possible out of bounds read due to improper input validation. This could lead to local information disclosure if a malicious USB HID device were plugged in, with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-188677105References: Upstream kernel",
        "id": 3335
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t  void *val, int bytes)\n{\n\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);\n\treturn X86EMUL_IO_NEEDED;\n}",
        "code_after_change": "static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t  void *val, int bytes)\n{\n\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);\n\treturn X86EMUL_IO_NEEDED;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n \t\t\t  void *val, int bytes)\n {\n-\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);\n+\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);\n \treturn X86EMUL_IO_NEEDED;\n }",
        "function_modified_lines": {
            "added": [
                "\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);"
            ],
            "deleted": [
                "\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1367
    },
    {
        "cve_id": "CVE-2023-38426",
        "code_before_change": "static int smb2_create_sd_buffer(struct ksmbd_work *work,\n\t\t\t\t struct smb2_create_req *req,\n\t\t\t\t const struct path *path)\n{\n\tstruct create_context *context;\n\tstruct create_sd_buf_req *sd_buf;\n\n\tif (!req->CreateContextsOffset)\n\t\treturn -ENOENT;\n\n\t/* Parse SD BUFFER create contexts */\n\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);\n\tif (!context)\n\t\treturn -ENOENT;\n\telse if (IS_ERR(context))\n\t\treturn PTR_ERR(context);\n\n\tksmbd_debug(SMB,\n\t\t    \"Set ACLs using SMB2_CREATE_SD_BUFFER context\\n\");\n\tsd_buf = (struct create_sd_buf_req *)context;\n\tif (le16_to_cpu(context->DataOffset) +\n\t    le32_to_cpu(context->DataLength) <\n\t    sizeof(struct create_sd_buf_req))\n\t\treturn -EINVAL;\n\treturn set_info_sec(work->conn, work->tcon, path, &sd_buf->ntsd,\n\t\t\t    le32_to_cpu(sd_buf->ccontext.DataLength), true);\n}",
        "code_after_change": "static int smb2_create_sd_buffer(struct ksmbd_work *work,\n\t\t\t\t struct smb2_create_req *req,\n\t\t\t\t const struct path *path)\n{\n\tstruct create_context *context;\n\tstruct create_sd_buf_req *sd_buf;\n\n\tif (!req->CreateContextsOffset)\n\t\treturn -ENOENT;\n\n\t/* Parse SD BUFFER create contexts */\n\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);\n\tif (!context)\n\t\treturn -ENOENT;\n\telse if (IS_ERR(context))\n\t\treturn PTR_ERR(context);\n\n\tksmbd_debug(SMB,\n\t\t    \"Set ACLs using SMB2_CREATE_SD_BUFFER context\\n\");\n\tsd_buf = (struct create_sd_buf_req *)context;\n\tif (le16_to_cpu(context->DataOffset) +\n\t    le32_to_cpu(context->DataLength) <\n\t    sizeof(struct create_sd_buf_req))\n\t\treturn -EINVAL;\n\treturn set_info_sec(work->conn, work->tcon, path, &sd_buf->ntsd,\n\t\t\t    le32_to_cpu(sd_buf->ccontext.DataLength), true);\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,7 @@\n \t\treturn -ENOENT;\n \n \t/* Parse SD BUFFER create contexts */\n-\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);\n+\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);\n \tif (!context)\n \t\treturn -ENOENT;\n \telse if (IS_ERR(context))",
        "function_modified_lines": {
            "added": [
                "\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);"
            ],
            "deleted": [
                "\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.4. ksmbd has an out-of-bounds read in smb2_find_context_vals when create_context's name_len is larger than the tag length.",
        "id": 4139
    },
    {
        "cve_id": "CVE-2016-7917",
        "code_before_change": "static void nfnetlink_rcv_batch(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t\tu_int16_t subsys_id)\n{\n\tstruct sk_buff *oskb = skb;\n\tstruct net *net = sock_net(skb->sk);\n\tconst struct nfnetlink_subsystem *ss;\n\tconst struct nfnl_callback *nc;\n\tstatic LIST_HEAD(err_list);\n\tu32 status;\n\tint err;\n\n\tif (subsys_id >= NFNL_SUBSYS_COUNT)\n\t\treturn netlink_ack(skb, nlh, -EINVAL);\nreplay:\n\tstatus = 0;\n\n\tskb = netlink_skb_clone(oskb, GFP_KERNEL);\n\tif (!skb)\n\t\treturn netlink_ack(oskb, nlh, -ENOMEM);\n\n\tnfnl_lock(subsys_id);\n\tss = nfnl_dereference_protected(subsys_id);\n\tif (!ss) {\n#ifdef CONFIG_MODULES\n\t\tnfnl_unlock(subsys_id);\n\t\trequest_module(\"nfnetlink-subsys-%d\", subsys_id);\n\t\tnfnl_lock(subsys_id);\n\t\tss = nfnl_dereference_protected(subsys_id);\n\t\tif (!ss)\n#endif\n\t\t{\n\t\t\tnfnl_unlock(subsys_id);\n\t\t\tnetlink_ack(oskb, nlh, -EOPNOTSUPP);\n\t\t\treturn kfree_skb(skb);\n\t\t}\n\t}\n\n\tif (!ss->commit || !ss->abort) {\n\t\tnfnl_unlock(subsys_id);\n\t\tnetlink_ack(oskb, nlh, -EOPNOTSUPP);\n\t\treturn kfree_skb(skb);\n\t}\n\n\twhile (skb->len >= nlmsg_total_size(0)) {\n\t\tint msglen, type;\n\n\t\tnlh = nlmsg_hdr(skb);\n\t\terr = 0;\n\n\t\tif (nlmsg_len(nlh) < sizeof(struct nfgenmsg) ||\n\t\t    skb->len < nlh->nlmsg_len) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\t/* Only requests are handled by the kernel */\n\t\tif (!(nlh->nlmsg_flags & NLM_F_REQUEST)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\ttype = nlh->nlmsg_type;\n\t\tif (type == NFNL_MSG_BATCH_BEGIN) {\n\t\t\t/* Malformed: Batch begin twice */\n\t\t\tnfnl_err_reset(&err_list);\n\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t\tgoto done;\n\t\t} else if (type == NFNL_MSG_BATCH_END) {\n\t\t\tstatus |= NFNL_BATCH_DONE;\n\t\t\tgoto done;\n\t\t} else if (type < NLMSG_MIN_TYPE) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\t/* We only accept a batch with messages for the same\n\t\t * subsystem.\n\t\t */\n\t\tif (NFNL_SUBSYS_ID(type) != subsys_id) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\tnc = nfnetlink_find_client(type, ss);\n\t\tif (!nc) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\t{\n\t\t\tint min_len = nlmsg_total_size(sizeof(struct nfgenmsg));\n\t\t\tu_int8_t cb_id = NFNL_MSG_TYPE(nlh->nlmsg_type);\n\t\t\tstruct nlattr *cda[ss->cb[cb_id].attr_count + 1];\n\t\t\tstruct nlattr *attr = (void *)nlh + min_len;\n\t\t\tint attrlen = nlh->nlmsg_len - min_len;\n\n\t\t\terr = nla_parse(cda, ss->cb[cb_id].attr_count,\n\t\t\t\t\tattr, attrlen, ss->cb[cb_id].policy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto ack;\n\n\t\t\tif (nc->call_batch) {\n\t\t\t\terr = nc->call_batch(net, net->nfnl, skb, nlh,\n\t\t\t\t\t\t     (const struct nlattr **)cda);\n\t\t\t}\n\n\t\t\t/* The lock was released to autoload some module, we\n\t\t\t * have to abort and start from scratch using the\n\t\t\t * original skb.\n\t\t\t */\n\t\t\tif (err == -EAGAIN) {\n\t\t\t\tstatus |= NFNL_BATCH_REPLAY;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t}\nack:\n\t\tif (nlh->nlmsg_flags & NLM_F_ACK || err) {\n\t\t\t/* Errors are delivered once the full batch has been\n\t\t\t * processed, this avoids that the same error is\n\t\t\t * reported several times when replaying the batch.\n\t\t\t */\n\t\t\tif (nfnl_err_add(&err_list, nlh, err) < 0) {\n\t\t\t\t/* We failed to enqueue an error, reset the\n\t\t\t\t * list of errors and send OOM to userspace\n\t\t\t\t * pointing to the batch header.\n\t\t\t\t */\n\t\t\t\tnfnl_err_reset(&err_list);\n\t\t\t\tnetlink_ack(oskb, nlmsg_hdr(oskb), -ENOMEM);\n\t\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\t/* We don't stop processing the batch on errors, thus,\n\t\t\t * userspace gets all the errors that the batch\n\t\t\t * triggers.\n\t\t\t */\n\t\t\tif (err)\n\t\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t}\nnext:\n\t\tmsglen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (msglen > skb->len)\n\t\t\tmsglen = skb->len;\n\t\tskb_pull(skb, msglen);\n\t}\ndone:\n\tif (status & NFNL_BATCH_REPLAY) {\n\t\tss->abort(net, oskb);\n\t\tnfnl_err_reset(&err_list);\n\t\tnfnl_unlock(subsys_id);\n\t\tkfree_skb(skb);\n\t\tgoto replay;\n\t} else if (status == NFNL_BATCH_DONE) {\n\t\tss->commit(net, oskb);\n\t} else {\n\t\tss->abort(net, oskb);\n\t}\n\n\tnfnl_err_deliver(&err_list, oskb);\n\tnfnl_unlock(subsys_id);\n\tkfree_skb(skb);\n}",
        "code_after_change": "static void nfnetlink_rcv_batch(struct sk_buff *skb, struct nlmsghdr *nlh,\n\t\t\t\tu_int16_t subsys_id)\n{\n\tstruct sk_buff *oskb = skb;\n\tstruct net *net = sock_net(skb->sk);\n\tconst struct nfnetlink_subsystem *ss;\n\tconst struct nfnl_callback *nc;\n\tstatic LIST_HEAD(err_list);\n\tu32 status;\n\tint err;\n\n\tif (subsys_id >= NFNL_SUBSYS_COUNT)\n\t\treturn netlink_ack(skb, nlh, -EINVAL);\nreplay:\n\tstatus = 0;\n\n\tskb = netlink_skb_clone(oskb, GFP_KERNEL);\n\tif (!skb)\n\t\treturn netlink_ack(oskb, nlh, -ENOMEM);\n\n\tnfnl_lock(subsys_id);\n\tss = nfnl_dereference_protected(subsys_id);\n\tif (!ss) {\n#ifdef CONFIG_MODULES\n\t\tnfnl_unlock(subsys_id);\n\t\trequest_module(\"nfnetlink-subsys-%d\", subsys_id);\n\t\tnfnl_lock(subsys_id);\n\t\tss = nfnl_dereference_protected(subsys_id);\n\t\tif (!ss)\n#endif\n\t\t{\n\t\t\tnfnl_unlock(subsys_id);\n\t\t\tnetlink_ack(oskb, nlh, -EOPNOTSUPP);\n\t\t\treturn kfree_skb(skb);\n\t\t}\n\t}\n\n\tif (!ss->commit || !ss->abort) {\n\t\tnfnl_unlock(subsys_id);\n\t\tnetlink_ack(oskb, nlh, -EOPNOTSUPP);\n\t\treturn kfree_skb(skb);\n\t}\n\n\twhile (skb->len >= nlmsg_total_size(0)) {\n\t\tint msglen, type;\n\n\t\tnlh = nlmsg_hdr(skb);\n\t\terr = 0;\n\n\t\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n\t\t    skb->len < nlh->nlmsg_len ||\n\t\t    nlmsg_len(nlh) < sizeof(struct nfgenmsg)) {\n\t\t\tnfnl_err_reset(&err_list);\n\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Only requests are handled by the kernel */\n\t\tif (!(nlh->nlmsg_flags & NLM_F_REQUEST)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\ttype = nlh->nlmsg_type;\n\t\tif (type == NFNL_MSG_BATCH_BEGIN) {\n\t\t\t/* Malformed: Batch begin twice */\n\t\t\tnfnl_err_reset(&err_list);\n\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t\tgoto done;\n\t\t} else if (type == NFNL_MSG_BATCH_END) {\n\t\t\tstatus |= NFNL_BATCH_DONE;\n\t\t\tgoto done;\n\t\t} else if (type < NLMSG_MIN_TYPE) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\t/* We only accept a batch with messages for the same\n\t\t * subsystem.\n\t\t */\n\t\tif (NFNL_SUBSYS_ID(type) != subsys_id) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\tnc = nfnetlink_find_client(type, ss);\n\t\tif (!nc) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto ack;\n\t\t}\n\n\t\t{\n\t\t\tint min_len = nlmsg_total_size(sizeof(struct nfgenmsg));\n\t\t\tu_int8_t cb_id = NFNL_MSG_TYPE(nlh->nlmsg_type);\n\t\t\tstruct nlattr *cda[ss->cb[cb_id].attr_count + 1];\n\t\t\tstruct nlattr *attr = (void *)nlh + min_len;\n\t\t\tint attrlen = nlh->nlmsg_len - min_len;\n\n\t\t\terr = nla_parse(cda, ss->cb[cb_id].attr_count,\n\t\t\t\t\tattr, attrlen, ss->cb[cb_id].policy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto ack;\n\n\t\t\tif (nc->call_batch) {\n\t\t\t\terr = nc->call_batch(net, net->nfnl, skb, nlh,\n\t\t\t\t\t\t     (const struct nlattr **)cda);\n\t\t\t}\n\n\t\t\t/* The lock was released to autoload some module, we\n\t\t\t * have to abort and start from scratch using the\n\t\t\t * original skb.\n\t\t\t */\n\t\t\tif (err == -EAGAIN) {\n\t\t\t\tstatus |= NFNL_BATCH_REPLAY;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t}\nack:\n\t\tif (nlh->nlmsg_flags & NLM_F_ACK || err) {\n\t\t\t/* Errors are delivered once the full batch has been\n\t\t\t * processed, this avoids that the same error is\n\t\t\t * reported several times when replaying the batch.\n\t\t\t */\n\t\t\tif (nfnl_err_add(&err_list, nlh, err) < 0) {\n\t\t\t\t/* We failed to enqueue an error, reset the\n\t\t\t\t * list of errors and send OOM to userspace\n\t\t\t\t * pointing to the batch header.\n\t\t\t\t */\n\t\t\t\tnfnl_err_reset(&err_list);\n\t\t\t\tnetlink_ack(oskb, nlmsg_hdr(oskb), -ENOMEM);\n\t\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\t/* We don't stop processing the batch on errors, thus,\n\t\t\t * userspace gets all the errors that the batch\n\t\t\t * triggers.\n\t\t\t */\n\t\t\tif (err)\n\t\t\t\tstatus |= NFNL_BATCH_FAILURE;\n\t\t}\nnext:\n\t\tmsglen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (msglen > skb->len)\n\t\t\tmsglen = skb->len;\n\t\tskb_pull(skb, msglen);\n\t}\ndone:\n\tif (status & NFNL_BATCH_REPLAY) {\n\t\tss->abort(net, oskb);\n\t\tnfnl_err_reset(&err_list);\n\t\tnfnl_unlock(subsys_id);\n\t\tkfree_skb(skb);\n\t\tgoto replay;\n\t} else if (status == NFNL_BATCH_DONE) {\n\t\tss->commit(net, oskb);\n\t} else {\n\t\tss->abort(net, oskb);\n\t}\n\n\tnfnl_err_deliver(&err_list, oskb);\n\tnfnl_unlock(subsys_id);\n\tkfree_skb(skb);\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,10 +47,12 @@\n \t\tnlh = nlmsg_hdr(skb);\n \t\terr = 0;\n \n-\t\tif (nlmsg_len(nlh) < sizeof(struct nfgenmsg) ||\n-\t\t    skb->len < nlh->nlmsg_len) {\n-\t\t\terr = -EINVAL;\n-\t\t\tgoto ack;\n+\t\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n+\t\t    skb->len < nlh->nlmsg_len ||\n+\t\t    nlmsg_len(nlh) < sizeof(struct nfgenmsg)) {\n+\t\t\tnfnl_err_reset(&err_list);\n+\t\t\tstatus |= NFNL_BATCH_FAILURE;\n+\t\t\tgoto done;\n \t\t}\n \n \t\t/* Only requests are handled by the kernel */",
        "function_modified_lines": {
            "added": [
                "\t\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||",
                "\t\t    skb->len < nlh->nlmsg_len ||",
                "\t\t    nlmsg_len(nlh) < sizeof(struct nfgenmsg)) {",
                "\t\t\tnfnl_err_reset(&err_list);",
                "\t\t\tstatus |= NFNL_BATCH_FAILURE;",
                "\t\t\tgoto done;"
            ],
            "deleted": [
                "\t\tif (nlmsg_len(nlh) < sizeof(struct nfgenmsg) ||",
                "\t\t    skb->len < nlh->nlmsg_len) {",
                "\t\t\terr = -EINVAL;",
                "\t\t\tgoto ack;"
            ]
        },
        "cwe": [
            "CWE-200",
            "CWE-125"
        ],
        "cve_description": "The nfnetlink_rcv_batch function in net/netfilter/nfnetlink.c in the Linux kernel before 4.5 does not check whether a batch message's length field is large enough, which allows local users to obtain sensitive information from kernel memory or cause a denial of service (infinite loop or out-of-bounds read) by leveraging the CAP_NET_ADMIN capability.",
        "id": 1115
    },
    {
        "cve_id": "CVE-2017-9984",
        "code_before_change": "void snd_msndmidi_input_read(void *mpuv)\n{\n\tunsigned long flags;\n\tstruct snd_msndmidi *mpu = mpuv;\n\tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n\n\tspin_lock_irqsave(&mpu->input_lock, flags);\n\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=\n\t       readw(mpu->dev->MIDQ + JQS_wHead)) {\n\t\tu16 wTmp, val;\n\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));\n\n\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,\n\t\t\t\t     &mpu->mode))\n\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,\n\t\t\t\t\t\t    (unsigned char *)&val, 1);\n\n\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;\n\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))\n\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);\n\t\telse\n\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);\n\t}\n\tspin_unlock_irqrestore(&mpu->input_lock, flags);\n}",
        "code_after_change": "void snd_msndmidi_input_read(void *mpuv)\n{\n\tunsigned long flags;\n\tstruct snd_msndmidi *mpu = mpuv;\n\tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n\tu16 head, tail, size;\n\n\tspin_lock_irqsave(&mpu->input_lock, flags);\n\thead = readw(mpu->dev->MIDQ + JQS_wHead);\n\ttail = readw(mpu->dev->MIDQ + JQS_wTail);\n\tsize = readw(mpu->dev->MIDQ + JQS_wSize);\n\tif (head > size || tail > size)\n\t\tgoto out;\n\twhile (head != tail) {\n\t\tunsigned char val = readw(pwMIDQData + 2 * head);\n\n\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))\n\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);\n\t\tif (++head > size)\n\t\t\thead = 0;\n\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);\n\t}\n out:\n\tspin_unlock_irqrestore(&mpu->input_lock, flags);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,23 +3,23 @@\n \tunsigned long flags;\n \tstruct snd_msndmidi *mpu = mpuv;\n \tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n+\tu16 head, tail, size;\n \n \tspin_lock_irqsave(&mpu->input_lock, flags);\n-\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=\n-\t       readw(mpu->dev->MIDQ + JQS_wHead)) {\n-\t\tu16 wTmp, val;\n-\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));\n+\thead = readw(mpu->dev->MIDQ + JQS_wHead);\n+\ttail = readw(mpu->dev->MIDQ + JQS_wTail);\n+\tsize = readw(mpu->dev->MIDQ + JQS_wSize);\n+\tif (head > size || tail > size)\n+\t\tgoto out;\n+\twhile (head != tail) {\n+\t\tunsigned char val = readw(pwMIDQData + 2 * head);\n \n-\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,\n-\t\t\t\t     &mpu->mode))\n-\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,\n-\t\t\t\t\t\t    (unsigned char *)&val, 1);\n-\n-\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;\n-\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))\n-\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);\n-\t\telse\n-\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);\n+\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))\n+\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);\n+\t\tif (++head > size)\n+\t\t\thead = 0;\n+\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);\n \t}\n+ out:\n \tspin_unlock_irqrestore(&mpu->input_lock, flags);\n }",
        "function_modified_lines": {
            "added": [
                "\tu16 head, tail, size;",
                "\thead = readw(mpu->dev->MIDQ + JQS_wHead);",
                "\ttail = readw(mpu->dev->MIDQ + JQS_wTail);",
                "\tsize = readw(mpu->dev->MIDQ + JQS_wSize);",
                "\tif (head > size || tail > size)",
                "\t\tgoto out;",
                "\twhile (head != tail) {",
                "\t\tunsigned char val = readw(pwMIDQData + 2 * head);",
                "\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))",
                "\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);",
                "\t\tif (++head > size)",
                "\t\t\thead = 0;",
                "\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);",
                " out:"
            ],
            "deleted": [
                "\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=",
                "\t       readw(mpu->dev->MIDQ + JQS_wHead)) {",
                "\t\tu16 wTmp, val;",
                "\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));",
                "\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,",
                "\t\t\t\t     &mpu->mode))",
                "\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,",
                "\t\t\t\t\t\t    (unsigned char *)&val, 1);",
                "",
                "\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;",
                "\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))",
                "\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);",
                "\t\telse",
                "\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The snd_msnd_interrupt function in sound/isa/msnd/msnd_pinnacle.c in the Linux kernel through 4.11.7 allows local users to cause a denial of service (over-boundary access) or possibly have unspecified other impact by changing the value of a message queue head pointer between two kernel reads of that value, aka a \"double fetch\" vulnerability.",
        "id": 1571
    },
    {
        "cve_id": "CVE-2021-39657",
        "code_before_change": "static int ufshcd_eh_device_reset_handler(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host;\n\tstruct ufs_hba *hba;\n\tunsigned int tag;\n\tu32 pos;\n\tint err;\n\tu8 resp = 0xF;\n\tstruct ufshcd_lrb *lrbp;\n\tunsigned long flags;\n\n\thost = cmd->device->host;\n\thba = shost_priv(host);\n\ttag = cmd->request->tag;\n\n\tlrbp = &hba->lrb[tag];\n\terr = ufshcd_issue_tm_cmd(hba, lrbp->lun, 0, UFS_LOGICAL_RESET, &resp);\n\tif (err || resp != UPIU_TASK_MANAGEMENT_FUNC_COMPL) {\n\t\tif (!err)\n\t\t\terr = resp;\n\t\tgoto out;\n\t}\n\n\t/* clear the commands that were pending for corresponding LUN */\n\tfor_each_set_bit(pos, &hba->outstanding_reqs, hba->nutrs) {\n\t\tif (hba->lrb[pos].lun == lrbp->lun) {\n\t\t\terr = ufshcd_clear_cmd(hba, pos);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_lock_irqsave(host->host_lock, flags);\n\tufshcd_transfer_req_compl(hba);\n\tspin_unlock_irqrestore(host->host_lock, flags);\n\nout:\n\thba->req_abort_count = 0;\n\tufshcd_update_evt_hist(hba, UFS_EVT_DEV_RESET, (u32)err);\n\tif (!err) {\n\t\terr = SUCCESS;\n\t} else {\n\t\tdev_err(hba->dev, \"%s: failed with err %d\\n\", __func__, err);\n\t\terr = FAILED;\n\t}\n\treturn err;\n}",
        "code_after_change": "static int ufshcd_eh_device_reset_handler(struct scsi_cmnd *cmd)\n{\n\tstruct Scsi_Host *host;\n\tstruct ufs_hba *hba;\n\tu32 pos;\n\tint err;\n\tu8 resp = 0xF, lun;\n\tunsigned long flags;\n\n\thost = cmd->device->host;\n\thba = shost_priv(host);\n\n\tlun = ufshcd_scsi_to_upiu_lun(cmd->device->lun);\n\terr = ufshcd_issue_tm_cmd(hba, lun, 0, UFS_LOGICAL_RESET, &resp);\n\tif (err || resp != UPIU_TASK_MANAGEMENT_FUNC_COMPL) {\n\t\tif (!err)\n\t\t\terr = resp;\n\t\tgoto out;\n\t}\n\n\t/* clear the commands that were pending for corresponding LUN */\n\tfor_each_set_bit(pos, &hba->outstanding_reqs, hba->nutrs) {\n\t\tif (hba->lrb[pos].lun == lun) {\n\t\t\terr = ufshcd_clear_cmd(hba, pos);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_lock_irqsave(host->host_lock, flags);\n\tufshcd_transfer_req_compl(hba);\n\tspin_unlock_irqrestore(host->host_lock, flags);\n\nout:\n\thba->req_abort_count = 0;\n\tufshcd_update_evt_hist(hba, UFS_EVT_DEV_RESET, (u32)err);\n\tif (!err) {\n\t\terr = SUCCESS;\n\t} else {\n\t\tdev_err(hba->dev, \"%s: failed with err %d\\n\", __func__, err);\n\t\terr = FAILED;\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,19 +2,16 @@\n {\n \tstruct Scsi_Host *host;\n \tstruct ufs_hba *hba;\n-\tunsigned int tag;\n \tu32 pos;\n \tint err;\n-\tu8 resp = 0xF;\n-\tstruct ufshcd_lrb *lrbp;\n+\tu8 resp = 0xF, lun;\n \tunsigned long flags;\n \n \thost = cmd->device->host;\n \thba = shost_priv(host);\n-\ttag = cmd->request->tag;\n \n-\tlrbp = &hba->lrb[tag];\n-\terr = ufshcd_issue_tm_cmd(hba, lrbp->lun, 0, UFS_LOGICAL_RESET, &resp);\n+\tlun = ufshcd_scsi_to_upiu_lun(cmd->device->lun);\n+\terr = ufshcd_issue_tm_cmd(hba, lun, 0, UFS_LOGICAL_RESET, &resp);\n \tif (err || resp != UPIU_TASK_MANAGEMENT_FUNC_COMPL) {\n \t\tif (!err)\n \t\t\terr = resp;\n@@ -23,7 +20,7 @@\n \n \t/* clear the commands that were pending for corresponding LUN */\n \tfor_each_set_bit(pos, &hba->outstanding_reqs, hba->nutrs) {\n-\t\tif (hba->lrb[pos].lun == lrbp->lun) {\n+\t\tif (hba->lrb[pos].lun == lun) {\n \t\t\terr = ufshcd_clear_cmd(hba, pos);\n \t\t\tif (err)\n \t\t\t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\tu8 resp = 0xF, lun;",
                "\tlun = ufshcd_scsi_to_upiu_lun(cmd->device->lun);",
                "\terr = ufshcd_issue_tm_cmd(hba, lun, 0, UFS_LOGICAL_RESET, &resp);",
                "\t\tif (hba->lrb[pos].lun == lun) {"
            ],
            "deleted": [
                "\tunsigned int tag;",
                "\tu8 resp = 0xF;",
                "\tstruct ufshcd_lrb *lrbp;",
                "\ttag = cmd->request->tag;",
                "\tlrbp = &hba->lrb[tag];",
                "\terr = ufshcd_issue_tm_cmd(hba, lrbp->lun, 0, UFS_LOGICAL_RESET, &resp);",
                "\t\tif (hba->lrb[pos].lun == lrbp->lun) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In ufshcd_eh_device_reset_handler of ufshcd.c, there is a possible out of bounds read due to a missing bounds check. This could lead to local information disclosure with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-194696049References: Upstream kernel",
        "id": 3095
    },
    {
        "cve_id": "CVE-2019-15090",
        "code_before_change": "void\nqedi_dbg_warn(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\tchar nfunc[32];\n\n\tmemset(nfunc, 0, sizeof(nfunc));\n\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & QEDI_LOG_WARN))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tnfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "code_after_change": "void\nqedi_dbg_warn(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & QEDI_LOG_WARN))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,6 @@\n {\n \tva_list va;\n \tstruct va_format vaf;\n-\tchar nfunc[32];\n-\n-\tmemset(nfunc, 0, sizeof(nfunc));\n-\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n \n \tva_start(va, fmt);\n \n@@ -19,9 +15,9 @@\n \n \tif (likely(qedi) && likely(qedi->pdev))\n \t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n-\t\t\tnfunc, line, qedi->host_no, &vaf);\n+\t\t\tfunc, line, qedi->host_no, &vaf);\n \telse\n-\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n+\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n \n ret:\n \tva_end(va);",
        "function_modified_lines": {
            "added": [
                "\t\t\tfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);"
            ],
            "deleted": [
                "\tchar nfunc[32];",
                "",
                "\tmemset(nfunc, 0, sizeof(nfunc));",
                "\tmemcpy(nfunc, func, sizeof(nfunc) - 1);",
                "\t\t\tnfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in drivers/scsi/qedi/qedi_dbg.c in the Linux kernel before 5.1.12. In the qedi_dbg_* family of functions, there is an out-of-bounds read.",
        "id": 1986
    },
    {
        "cve_id": "CVE-2014-7825",
        "code_before_change": "static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}",
        "code_after_change": "static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \n \t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the perf subsystem, which allows local users to cause a denial of service (out-of-bounds read and OOPS) or bypass the ASLR protection mechanism via a crafted application.",
        "id": 591
    },
    {
        "cve_id": "CVE-2014-7825",
        "code_before_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "code_after_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n \t\treturn;",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the perf subsystem, which allows local users to cause a denial of service (out-of-bounds read and OOPS) or bypass the ASLR protection mechanism via a crafted application.",
        "id": 592
    },
    {
        "cve_id": "CVE-2019-19252",
        "code_before_change": "static ssize_t\nvcs_write(struct file *file, const char __user *buf, size_t count, loff_t *ppos)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct vc_data *vc;\n\tlong pos;\n\tlong attr, size, written;\n\tchar *con_buf0;\n\tint col, maxcol, viewed;\n\tu16 *org0 = NULL, *org = NULL;\n\tsize_t ret;\n\tchar *con_buf;\n\n\tcon_buf = (char *) __get_free_page(GFP_KERNEL);\n\tif (!con_buf)\n\t\treturn -ENOMEM;\n\n\tpos = *ppos;\n\n\t/* Select the proper current console and verify\n\t * sanity of the situation under the console lock.\n\t */\n\tconsole_lock();\n\n\tattr = use_attributes(inode);\n\tret = -ENXIO;\n\tvc = vcs_vc(inode, &viewed);\n\tif (!vc)\n\t\tgoto unlock_out;\n\n\tsize = vcs_size(inode);\n\tret = -EINVAL;\n\tif (pos < 0 || pos > size)\n\t\tgoto unlock_out;\n\tif (count > size - pos)\n\t\tcount = size - pos;\n\twritten = 0;\n\twhile (count) {\n\t\tlong this_round = count;\n\t\tsize_t orig_count;\n\t\tlong p;\n\n\t\tif (this_round > CON_BUF_SIZE)\n\t\t\tthis_round = CON_BUF_SIZE;\n\n\t\t/* Temporarily drop the console lock so that we can read\n\t\t * in the write data from userspace safely.\n\t\t */\n\t\tconsole_unlock();\n\t\tret = copy_from_user(con_buf, buf, this_round);\n\t\tconsole_lock();\n\n\t\tif (ret) {\n\t\t\tthis_round -= ret;\n\t\t\tif (!this_round) {\n\t\t\t\t/* Abort loop if no data were copied. Otherwise\n\t\t\t\t * fail with -EFAULT.\n\t\t\t\t */\n\t\t\t\tif (written)\n\t\t\t\t\tbreak;\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto unlock_out;\n\t\t\t}\n\t\t}\n\n\t\t/* The vcs_size might have changed while we slept to grab\n\t\t * the user buffer, so recheck.\n\t\t * Return data written up to now on failure.\n\t\t */\n\t\tsize = vcs_size(inode);\n\t\tif (size < 0) {\n\t\t\tif (written)\n\t\t\t\tbreak;\n\t\t\tret = size;\n\t\t\tgoto unlock_out;\n\t\t}\n\t\tif (pos >= size)\n\t\t\tbreak;\n\t\tif (this_round > size - pos)\n\t\t\tthis_round = size - pos;\n\n\t\t/* OK, now actually push the write to the console\n\t\t * under the lock using the local kernel buffer.\n\t\t */\n\n\t\tcon_buf0 = con_buf;\n\t\torig_count = this_round;\n\t\tmaxcol = vc->vc_cols;\n\t\tp = pos;\n\t\tif (!attr) {\n\t\t\torg0 = org = screen_pos(vc, p, viewed);\n\t\t\tcol = p % maxcol;\n\t\t\tp += maxcol - col;\n\n\t\t\twhile (this_round > 0) {\n\t\t\t\tunsigned char c = *con_buf0++;\n\n\t\t\t\tthis_round--;\n\t\t\t\tvcs_scr_writew(vc,\n\t\t\t\t\t       (vcs_scr_readw(vc, org) & 0xff00) | c, org);\n\t\t\t\torg++;\n\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\torg = screen_pos(vc, p, viewed);\n\t\t\t\t\tcol = 0;\n\t\t\t\t\tp += maxcol;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (p < HEADER_SIZE) {\n\t\t\t\tchar header[HEADER_SIZE];\n\n\t\t\t\tgetconsxy(vc, header + 2);\n\t\t\t\twhile (p < HEADER_SIZE && this_round > 0) {\n\t\t\t\t\tthis_round--;\n\t\t\t\t\theader[p++] = *con_buf0++;\n\t\t\t\t}\n\t\t\t\tif (!viewed)\n\t\t\t\t\tputconsxy(vc, header + 2);\n\t\t\t}\n\t\t\tp -= HEADER_SIZE;\n\t\t\tcol = (p/2) % maxcol;\n\t\t\tif (this_round > 0) {\n\t\t\t\torg0 = org = screen_pos(vc, p/2, viewed);\n\t\t\t\tif ((p & 1) && this_round > 0) {\n\t\t\t\t\tchar c;\n\n\t\t\t\t\tthis_round--;\n\t\t\t\t\tc = *con_buf0++;\n#ifdef __BIG_ENDIAN\n\t\t\t\t\tvcs_scr_writew(vc, c |\n\t\t\t\t\t     (vcs_scr_readw(vc, org) & 0xff00), org);\n#else\n\t\t\t\t\tvcs_scr_writew(vc, (c << 8) |\n\t\t\t\t\t     (vcs_scr_readw(vc, org) & 0xff), org);\n#endif\n\t\t\t\t\torg++;\n\t\t\t\t\tp++;\n\t\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\t\torg = screen_pos(vc, p/2, viewed);\n\t\t\t\t\t\tcol = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tp /= 2;\n\t\t\t\tp += maxcol - col;\n\t\t\t}\n\t\t\twhile (this_round > 1) {\n\t\t\t\tunsigned short w;\n\n\t\t\t\tw = get_unaligned(((unsigned short *)con_buf0));\n\t\t\t\tvcs_scr_writew(vc, w, org++);\n\t\t\t\tcon_buf0 += 2;\n\t\t\t\tthis_round -= 2;\n\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\torg = screen_pos(vc, p, viewed);\n\t\t\t\t\tcol = 0;\n\t\t\t\t\tp += maxcol;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (this_round > 0) {\n\t\t\t\tunsigned char c;\n\n\t\t\t\tc = *con_buf0++;\n#ifdef __BIG_ENDIAN\n\t\t\t\tvcs_scr_writew(vc, (vcs_scr_readw(vc, org) & 0xff) | (c << 8), org);\n#else\n\t\t\t\tvcs_scr_writew(vc, (vcs_scr_readw(vc, org) & 0xff00) | c, org);\n#endif\n\t\t\t}\n\t\t}\n\t\tcount -= orig_count;\n\t\twritten += orig_count;\n\t\tbuf += orig_count;\n\t\tpos += orig_count;\n\t\tif (org0)\n\t\t\tupdate_region(vc, (unsigned long)(org0), org - org0);\n\t}\n\t*ppos += written;\n\tret = written;\n\tif (written)\n\t\tvcs_scr_updated(vc);\n\nunlock_out:\n\tconsole_unlock();\n\tfree_page((unsigned long) con_buf);\n\treturn ret;\n}",
        "code_after_change": "static ssize_t\nvcs_write(struct file *file, const char __user *buf, size_t count, loff_t *ppos)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct vc_data *vc;\n\tlong pos;\n\tlong attr, size, written;\n\tchar *con_buf0;\n\tint col, maxcol, viewed;\n\tu16 *org0 = NULL, *org = NULL;\n\tsize_t ret;\n\tchar *con_buf;\n\n\tif (use_unicode(inode))\n\t\treturn -EOPNOTSUPP;\n\n\tcon_buf = (char *) __get_free_page(GFP_KERNEL);\n\tif (!con_buf)\n\t\treturn -ENOMEM;\n\n\tpos = *ppos;\n\n\t/* Select the proper current console and verify\n\t * sanity of the situation under the console lock.\n\t */\n\tconsole_lock();\n\n\tattr = use_attributes(inode);\n\tret = -ENXIO;\n\tvc = vcs_vc(inode, &viewed);\n\tif (!vc)\n\t\tgoto unlock_out;\n\n\tsize = vcs_size(inode);\n\tret = -EINVAL;\n\tif (pos < 0 || pos > size)\n\t\tgoto unlock_out;\n\tif (count > size - pos)\n\t\tcount = size - pos;\n\twritten = 0;\n\twhile (count) {\n\t\tlong this_round = count;\n\t\tsize_t orig_count;\n\t\tlong p;\n\n\t\tif (this_round > CON_BUF_SIZE)\n\t\t\tthis_round = CON_BUF_SIZE;\n\n\t\t/* Temporarily drop the console lock so that we can read\n\t\t * in the write data from userspace safely.\n\t\t */\n\t\tconsole_unlock();\n\t\tret = copy_from_user(con_buf, buf, this_round);\n\t\tconsole_lock();\n\n\t\tif (ret) {\n\t\t\tthis_round -= ret;\n\t\t\tif (!this_round) {\n\t\t\t\t/* Abort loop if no data were copied. Otherwise\n\t\t\t\t * fail with -EFAULT.\n\t\t\t\t */\n\t\t\t\tif (written)\n\t\t\t\t\tbreak;\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto unlock_out;\n\t\t\t}\n\t\t}\n\n\t\t/* The vcs_size might have changed while we slept to grab\n\t\t * the user buffer, so recheck.\n\t\t * Return data written up to now on failure.\n\t\t */\n\t\tsize = vcs_size(inode);\n\t\tif (size < 0) {\n\t\t\tif (written)\n\t\t\t\tbreak;\n\t\t\tret = size;\n\t\t\tgoto unlock_out;\n\t\t}\n\t\tif (pos >= size)\n\t\t\tbreak;\n\t\tif (this_round > size - pos)\n\t\t\tthis_round = size - pos;\n\n\t\t/* OK, now actually push the write to the console\n\t\t * under the lock using the local kernel buffer.\n\t\t */\n\n\t\tcon_buf0 = con_buf;\n\t\torig_count = this_round;\n\t\tmaxcol = vc->vc_cols;\n\t\tp = pos;\n\t\tif (!attr) {\n\t\t\torg0 = org = screen_pos(vc, p, viewed);\n\t\t\tcol = p % maxcol;\n\t\t\tp += maxcol - col;\n\n\t\t\twhile (this_round > 0) {\n\t\t\t\tunsigned char c = *con_buf0++;\n\n\t\t\t\tthis_round--;\n\t\t\t\tvcs_scr_writew(vc,\n\t\t\t\t\t       (vcs_scr_readw(vc, org) & 0xff00) | c, org);\n\t\t\t\torg++;\n\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\torg = screen_pos(vc, p, viewed);\n\t\t\t\t\tcol = 0;\n\t\t\t\t\tp += maxcol;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (p < HEADER_SIZE) {\n\t\t\t\tchar header[HEADER_SIZE];\n\n\t\t\t\tgetconsxy(vc, header + 2);\n\t\t\t\twhile (p < HEADER_SIZE && this_round > 0) {\n\t\t\t\t\tthis_round--;\n\t\t\t\t\theader[p++] = *con_buf0++;\n\t\t\t\t}\n\t\t\t\tif (!viewed)\n\t\t\t\t\tputconsxy(vc, header + 2);\n\t\t\t}\n\t\t\tp -= HEADER_SIZE;\n\t\t\tcol = (p/2) % maxcol;\n\t\t\tif (this_round > 0) {\n\t\t\t\torg0 = org = screen_pos(vc, p/2, viewed);\n\t\t\t\tif ((p & 1) && this_round > 0) {\n\t\t\t\t\tchar c;\n\n\t\t\t\t\tthis_round--;\n\t\t\t\t\tc = *con_buf0++;\n#ifdef __BIG_ENDIAN\n\t\t\t\t\tvcs_scr_writew(vc, c |\n\t\t\t\t\t     (vcs_scr_readw(vc, org) & 0xff00), org);\n#else\n\t\t\t\t\tvcs_scr_writew(vc, (c << 8) |\n\t\t\t\t\t     (vcs_scr_readw(vc, org) & 0xff), org);\n#endif\n\t\t\t\t\torg++;\n\t\t\t\t\tp++;\n\t\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\t\torg = screen_pos(vc, p/2, viewed);\n\t\t\t\t\t\tcol = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tp /= 2;\n\t\t\t\tp += maxcol - col;\n\t\t\t}\n\t\t\twhile (this_round > 1) {\n\t\t\t\tunsigned short w;\n\n\t\t\t\tw = get_unaligned(((unsigned short *)con_buf0));\n\t\t\t\tvcs_scr_writew(vc, w, org++);\n\t\t\t\tcon_buf0 += 2;\n\t\t\t\tthis_round -= 2;\n\t\t\t\tif (++col == maxcol) {\n\t\t\t\t\torg = screen_pos(vc, p, viewed);\n\t\t\t\t\tcol = 0;\n\t\t\t\t\tp += maxcol;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (this_round > 0) {\n\t\t\t\tunsigned char c;\n\n\t\t\t\tc = *con_buf0++;\n#ifdef __BIG_ENDIAN\n\t\t\t\tvcs_scr_writew(vc, (vcs_scr_readw(vc, org) & 0xff) | (c << 8), org);\n#else\n\t\t\t\tvcs_scr_writew(vc, (vcs_scr_readw(vc, org) & 0xff00) | c, org);\n#endif\n\t\t\t}\n\t\t}\n\t\tcount -= orig_count;\n\t\twritten += orig_count;\n\t\tbuf += orig_count;\n\t\tpos += orig_count;\n\t\tif (org0)\n\t\t\tupdate_region(vc, (unsigned long)(org0), org - org0);\n\t}\n\t*ppos += written;\n\tret = written;\n\tif (written)\n\t\tvcs_scr_updated(vc);\n\nunlock_out:\n\tconsole_unlock();\n\tfree_page((unsigned long) con_buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,9 @@\n \tu16 *org0 = NULL, *org = NULL;\n \tsize_t ret;\n \tchar *con_buf;\n+\n+\tif (use_unicode(inode))\n+\t\treturn -EOPNOTSUPP;\n \n \tcon_buf = (char *) __get_free_page(GFP_KERNEL);\n \tif (!con_buf)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (use_unicode(inode))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "vcs_write in drivers/tty/vt/vc_screen.c in the Linux kernel through 5.3.13 does not prevent write access to vcsu devices, aka CID-0c9acb1af77a.",
        "id": 2186
    },
    {
        "cve_id": "CVE-2016-9555",
        "code_before_change": "sctp_disposition_t sctp_sf_ootb(struct net *net,\n\t\t\t\tconst struct sctp_endpoint *ep,\n\t\t\t\tconst struct sctp_association *asoc,\n\t\t\t\tconst sctp_subtype_t type,\n\t\t\t\tvoid *arg,\n\t\t\t\tsctp_cmd_seq_t *commands)\n{\n\tstruct sctp_chunk *chunk = arg;\n\tstruct sk_buff *skb = chunk->skb;\n\tsctp_chunkhdr_t *ch;\n\tsctp_errhdr_t *err;\n\t__u8 *ch_end;\n\tint ootb_shut_ack = 0;\n\tint ootb_cookie_ack = 0;\n\n\tSCTP_INC_STATS(net, SCTP_MIB_OUTOFBLUES);\n\n\tch = (sctp_chunkhdr_t *) chunk->chunk_hdr;\n\tdo {\n\t\t/* Report violation if the chunk is less then minimal */\n\t\tif (ntohs(ch->length) < sizeof(sctp_chunkhdr_t))\n\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n\t\t\t\t\t\t  commands);\n\n\t\t/* Now that we know we at least have a chunk header,\n\t\t * do things that are type appropriate.\n\t\t */\n\t\tif (SCTP_CID_SHUTDOWN_ACK == ch->type)\n\t\t\tootb_shut_ack = 1;\n\n\t\t/* RFC 2960, Section 3.3.7\n\t\t *   Moreover, under any circumstances, an endpoint that\n\t\t *   receives an ABORT  MUST NOT respond to that ABORT by\n\t\t *   sending an ABORT of its own.\n\t\t */\n\t\tif (SCTP_CID_ABORT == ch->type)\n\t\t\treturn sctp_sf_pdiscard(net, ep, asoc, type, arg, commands);\n\n\t\t/* RFC 8.4, 7) If the packet contains a \"Stale cookie\" ERROR\n\t\t * or a COOKIE ACK the SCTP Packet should be silently\n\t\t * discarded.\n\t\t */\n\n\t\tif (SCTP_CID_COOKIE_ACK == ch->type)\n\t\t\tootb_cookie_ack = 1;\n\n\t\tif (SCTP_CID_ERROR == ch->type) {\n\t\t\tsctp_walk_errors(err, ch) {\n\t\t\t\tif (SCTP_ERROR_STALE_COOKIE == err->cause) {\n\t\t\t\t\tootb_cookie_ack = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Report violation if chunk len overflows */\n\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));\n\t\tif (ch_end > skb_tail_pointer(skb))\n\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n\t\t\t\t\t\t  commands);\n\n\t\tch = (sctp_chunkhdr_t *) ch_end;\n\t} while (ch_end < skb_tail_pointer(skb));\n\n\tif (ootb_shut_ack)\n\t\treturn sctp_sf_shut_8_4_5(net, ep, asoc, type, arg, commands);\n\telse if (ootb_cookie_ack)\n\t\treturn sctp_sf_pdiscard(net, ep, asoc, type, arg, commands);\n\telse\n\t\treturn sctp_sf_tabort_8_4_8(net, ep, asoc, type, arg, commands);\n}",
        "code_after_change": "sctp_disposition_t sctp_sf_ootb(struct net *net,\n\t\t\t\tconst struct sctp_endpoint *ep,\n\t\t\t\tconst struct sctp_association *asoc,\n\t\t\t\tconst sctp_subtype_t type,\n\t\t\t\tvoid *arg,\n\t\t\t\tsctp_cmd_seq_t *commands)\n{\n\tstruct sctp_chunk *chunk = arg;\n\tstruct sk_buff *skb = chunk->skb;\n\tsctp_chunkhdr_t *ch;\n\tsctp_errhdr_t *err;\n\t__u8 *ch_end;\n\tint ootb_shut_ack = 0;\n\tint ootb_cookie_ack = 0;\n\n\tSCTP_INC_STATS(net, SCTP_MIB_OUTOFBLUES);\n\n\tch = (sctp_chunkhdr_t *) chunk->chunk_hdr;\n\tdo {\n\t\t/* Report violation if the chunk is less then minimal */\n\t\tif (ntohs(ch->length) < sizeof(sctp_chunkhdr_t))\n\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n\t\t\t\t\t\t  commands);\n\n\t\t/* Report violation if chunk len overflows */\n\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));\n\t\tif (ch_end > skb_tail_pointer(skb))\n\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n\t\t\t\t\t\t  commands);\n\n\t\t/* Now that we know we at least have a chunk header,\n\t\t * do things that are type appropriate.\n\t\t */\n\t\tif (SCTP_CID_SHUTDOWN_ACK == ch->type)\n\t\t\tootb_shut_ack = 1;\n\n\t\t/* RFC 2960, Section 3.3.7\n\t\t *   Moreover, under any circumstances, an endpoint that\n\t\t *   receives an ABORT  MUST NOT respond to that ABORT by\n\t\t *   sending an ABORT of its own.\n\t\t */\n\t\tif (SCTP_CID_ABORT == ch->type)\n\t\t\treturn sctp_sf_pdiscard(net, ep, asoc, type, arg, commands);\n\n\t\t/* RFC 8.4, 7) If the packet contains a \"Stale cookie\" ERROR\n\t\t * or a COOKIE ACK the SCTP Packet should be silently\n\t\t * discarded.\n\t\t */\n\n\t\tif (SCTP_CID_COOKIE_ACK == ch->type)\n\t\t\tootb_cookie_ack = 1;\n\n\t\tif (SCTP_CID_ERROR == ch->type) {\n\t\t\tsctp_walk_errors(err, ch) {\n\t\t\t\tif (SCTP_ERROR_STALE_COOKIE == err->cause) {\n\t\t\t\t\tootb_cookie_ack = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tch = (sctp_chunkhdr_t *) ch_end;\n\t} while (ch_end < skb_tail_pointer(skb));\n\n\tif (ootb_shut_ack)\n\t\treturn sctp_sf_shut_8_4_5(net, ep, asoc, type, arg, commands);\n\telse if (ootb_cookie_ack)\n\t\treturn sctp_sf_pdiscard(net, ep, asoc, type, arg, commands);\n\telse\n\t\treturn sctp_sf_tabort_8_4_8(net, ep, asoc, type, arg, commands);\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,12 @@\n \tdo {\n \t\t/* Report violation if the chunk is less then minimal */\n \t\tif (ntohs(ch->length) < sizeof(sctp_chunkhdr_t))\n+\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n+\t\t\t\t\t\t  commands);\n+\n+\t\t/* Report violation if chunk len overflows */\n+\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));\n+\t\tif (ch_end > skb_tail_pointer(skb))\n \t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n \t\t\t\t\t\t  commands);\n \n@@ -53,12 +59,6 @@\n \t\t\t}\n \t\t}\n \n-\t\t/* Report violation if chunk len overflows */\n-\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));\n-\t\tif (ch_end > skb_tail_pointer(skb))\n-\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,\n-\t\t\t\t\t\t  commands);\n-\n \t\tch = (sctp_chunkhdr_t *) ch_end;\n \t} while (ch_end < skb_tail_pointer(skb));\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,",
                "\t\t\t\t\t\t  commands);",
                "",
                "\t\t/* Report violation if chunk len overflows */",
                "\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));",
                "\t\tif (ch_end > skb_tail_pointer(skb))"
            ],
            "deleted": [
                "\t\t/* Report violation if chunk len overflows */",
                "\t\tch_end = ((__u8 *)ch) + SCTP_PAD4(ntohs(ch->length));",
                "\t\tif (ch_end > skb_tail_pointer(skb))",
                "\t\t\treturn sctp_sf_violation_chunklen(net, ep, asoc, type, arg,",
                "\t\t\t\t\t\t  commands);",
                ""
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The sctp_sf_ootb function in net/sctp/sm_statefuns.c in the Linux kernel before 4.8.8 lacks chunk-length checking for the first chunk, which allows remote attackers to cause a denial of service (out-of-bounds slab access) or possibly have unspecified other impact via crafted SCTP data.",
        "id": 1145
    },
    {
        "cve_id": "CVE-2022-20132",
        "code_before_change": "static int asus_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tint ret;\n\tstruct asus_drvdata *drvdata;\n\n\tdrvdata = devm_kzalloc(&hdev->dev, sizeof(*drvdata), GFP_KERNEL);\n\tif (drvdata == NULL) {\n\t\thid_err(hdev, \"Can't alloc Asus descriptor\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drvdata);\n\n\tdrvdata->quirks = id->driver_data;\n\n\t/*\n\t * T90CHI's keyboard dock returns same ID values as T100CHI's dock.\n\t * Thus, identify T90CHI dock with product name string.\n\t */\n\tif (strstr(hdev->name, \"T90CHI\")) {\n\t\tdrvdata->quirks &= ~QUIRK_T100CHI;\n\t\tdrvdata->quirks |= QUIRK_T90CHI;\n\t}\n\n\tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n\t\tdrvdata->tp = &asus_i2c_tp;\n\n\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&\n\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\n\t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n\t\t\tdrvdata->quirks = QUIRK_SKIP_INPUT_MAPPING;\n\t\t\t/*\n\t\t\t * The T100HA uses the same USB-ids as the T100TAF and\n\t\t\t * the T200TA uses the same USB-ids as the T100TA, while\n\t\t\t * both have different max x/y values as the T100TA[F].\n\t\t\t */\n\t\t\tif (dmi_match(DMI_PRODUCT_NAME, \"T100HAN\"))\n\t\t\t\tdrvdata->tp = &asus_t100ha_tp;\n\t\t\telse if (dmi_match(DMI_PRODUCT_NAME, \"T200TA\"))\n\t\t\t\tdrvdata->tp = &asus_t200ta_tp;\n\t\t\telse\n\t\t\t\tdrvdata->tp = &asus_t100ta_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_T100CHI) {\n\t\t/*\n\t\t * All functionality is on a single HID interface and for\n\t\t * userspace the touchpad must be a separate input_dev.\n\t\t */\n\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\tdrvdata->tp = &asus_t100chi_tp;\n\t}\n\n\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&\n\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\tstruct usb_host_interface *alt =\n\t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n\n\t\tif (alt->desc.bInterfaceNumber == MEDION_E1239T_TPAD_INTF) {\n\t\t\t/* For separate input-devs for tp and tp toggle key */\n\t\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\t\tdrvdata->quirks |= QUIRK_SKIP_INPUT_MAPPING;\n\t\t\tdrvdata->tp = &medion_e1239t_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_NO_INIT_REPORTS)\n\t\thdev->quirks |= HID_QUIRK_NO_INIT_REPORTS;\n\n\tdrvdata->hdev = hdev;\n\n\tif (drvdata->quirks & (QUIRK_T100CHI | QUIRK_T90CHI)) {\n\t\tret = asus_battery_probe(hdev);\n\t\tif (ret) {\n\t\t\thid_err(hdev,\n\t\t\t    \"Asus hid battery_probe failed: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hid parse failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hw start failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!drvdata->input) {\n\t\thid_err(hdev, \"Asus input not registered\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_stop_hw;\n\t}\n\n\tif (drvdata->tp) {\n\t\tdrvdata->input->name = \"Asus TouchPad\";\n\t} else {\n\t\tdrvdata->input->name = \"Asus Keyboard\";\n\t}\n\n\tif (drvdata->tp) {\n\t\tret = asus_start_multitouch(hdev);\n\t\tif (ret)\n\t\t\tgoto err_stop_hw;\n\t}\n\n\treturn 0;\nerr_stop_hw:\n\thid_hw_stop(hdev);\n\treturn ret;\n}",
        "code_after_change": "static int asus_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tint ret;\n\tstruct asus_drvdata *drvdata;\n\n\tdrvdata = devm_kzalloc(&hdev->dev, sizeof(*drvdata), GFP_KERNEL);\n\tif (drvdata == NULL) {\n\t\thid_err(hdev, \"Can't alloc Asus descriptor\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drvdata);\n\n\tdrvdata->quirks = id->driver_data;\n\n\t/*\n\t * T90CHI's keyboard dock returns same ID values as T100CHI's dock.\n\t * Thus, identify T90CHI dock with product name string.\n\t */\n\tif (strstr(hdev->name, \"T90CHI\")) {\n\t\tdrvdata->quirks &= ~QUIRK_T100CHI;\n\t\tdrvdata->quirks |= QUIRK_T90CHI;\n\t}\n\n\tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n\t\tdrvdata->tp = &asus_i2c_tp;\n\n\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {\n\t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\n\t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n\t\t\tdrvdata->quirks = QUIRK_SKIP_INPUT_MAPPING;\n\t\t\t/*\n\t\t\t * The T100HA uses the same USB-ids as the T100TAF and\n\t\t\t * the T200TA uses the same USB-ids as the T100TA, while\n\t\t\t * both have different max x/y values as the T100TA[F].\n\t\t\t */\n\t\t\tif (dmi_match(DMI_PRODUCT_NAME, \"T100HAN\"))\n\t\t\t\tdrvdata->tp = &asus_t100ha_tp;\n\t\t\telse if (dmi_match(DMI_PRODUCT_NAME, \"T200TA\"))\n\t\t\t\tdrvdata->tp = &asus_t200ta_tp;\n\t\t\telse\n\t\t\t\tdrvdata->tp = &asus_t100ta_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_T100CHI) {\n\t\t/*\n\t\t * All functionality is on a single HID interface and for\n\t\t * userspace the touchpad must be a separate input_dev.\n\t\t */\n\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\tdrvdata->tp = &asus_t100chi_tp;\n\t}\n\n\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {\n\t\tstruct usb_host_interface *alt =\n\t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n\n\t\tif (alt->desc.bInterfaceNumber == MEDION_E1239T_TPAD_INTF) {\n\t\t\t/* For separate input-devs for tp and tp toggle key */\n\t\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\t\tdrvdata->quirks |= QUIRK_SKIP_INPUT_MAPPING;\n\t\t\tdrvdata->tp = &medion_e1239t_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_NO_INIT_REPORTS)\n\t\thdev->quirks |= HID_QUIRK_NO_INIT_REPORTS;\n\n\tdrvdata->hdev = hdev;\n\n\tif (drvdata->quirks & (QUIRK_T100CHI | QUIRK_T90CHI)) {\n\t\tret = asus_battery_probe(hdev);\n\t\tif (ret) {\n\t\t\thid_err(hdev,\n\t\t\t    \"Asus hid battery_probe failed: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hid parse failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hw start failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!drvdata->input) {\n\t\thid_err(hdev, \"Asus input not registered\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_stop_hw;\n\t}\n\n\tif (drvdata->tp) {\n\t\tdrvdata->input->name = \"Asus TouchPad\";\n\t} else {\n\t\tdrvdata->input->name = \"Asus Keyboard\";\n\t}\n\n\tif (drvdata->tp) {\n\t\tret = asus_start_multitouch(hdev);\n\t\tif (ret)\n\t\t\tgoto err_stop_hw;\n\t}\n\n\treturn 0;\nerr_stop_hw:\n\thid_hw_stop(hdev);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,7 @@\n \tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n \t\tdrvdata->tp = &asus_i2c_tp;\n \n-\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&\n-\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {\n \t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n \n \t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n@@ -54,8 +53,7 @@\n \t\tdrvdata->tp = &asus_t100chi_tp;\n \t}\n \n-\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&\n-\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {\n \t\tstruct usb_host_interface *alt =\n \t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n ",
        "function_modified_lines": {
            "added": [
                "\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {",
                "\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {"
            ],
            "deleted": [
                "\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&",
                "\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {",
                "\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&",
                "\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In lg_probe and related functions of hid-lg.c and other USB HID files, there is a possible out of bounds read due to improper input validation. This could lead to local information disclosure if a malicious USB HID device were plugged in, with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-188677105References: Upstream kernel",
        "id": 3332
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "struct inode *ntfs_create_inode(struct user_namespace *mnt_userns,\n\t\t\t\tstruct inode *dir, struct dentry *dentry,\n\t\t\t\tconst struct cpu_str *uni, umode_t mode,\n\t\t\t\tdev_t dev, const char *symname, u32 size,\n\t\t\t\tstruct ntfs_fnd *fnd)\n{\n\tint err;\n\tstruct super_block *sb = dir->i_sb;\n\tstruct ntfs_sb_info *sbi = sb->s_fs_info;\n\tconst struct qstr *name = &dentry->d_name;\n\tCLST ino = 0;\n\tstruct ntfs_inode *dir_ni = ntfs_i(dir);\n\tstruct ntfs_inode *ni = NULL;\n\tstruct inode *inode = NULL;\n\tstruct ATTRIB *attr;\n\tstruct ATTR_STD_INFO5 *std5;\n\tstruct ATTR_FILE_NAME *fname;\n\tstruct MFT_REC *rec;\n\tu32 asize, dsize, sd_size;\n\tenum FILE_ATTRIBUTE fa;\n\t__le32 security_id = SECURITY_ID_INVALID;\n\tCLST vcn;\n\tconst void *sd;\n\tu16 t16, nsize = 0, aid = 0;\n\tstruct INDEX_ROOT *root, *dir_root;\n\tstruct NTFS_DE *e, *new_de = NULL;\n\tstruct REPARSE_DATA_BUFFER *rp = NULL;\n\tbool rp_inserted = false;\n\n\tif (!fnd)\n\t\tni_lock_dir(dir_ni);\n\n\tdir_root = indx_get_root(&dir_ni->dir, dir_ni, NULL, NULL);\n\tif (!dir_root) {\n\t\terr = -EINVAL;\n\t\tgoto out1;\n\t}\n\n\tif (S_ISDIR(mode)) {\n\t\t/* Use parent's directory attributes. */\n\t\tfa = dir_ni->std_fa | FILE_ATTRIBUTE_DIRECTORY |\n\t\t     FILE_ATTRIBUTE_ARCHIVE;\n\t\t/*\n\t\t * By default child directory inherits parent attributes.\n\t\t * Root directory is hidden + system.\n\t\t * Make an exception for children in root.\n\t\t */\n\t\tif (dir->i_ino == MFT_REC_ROOT)\n\t\t\tfa &= ~(FILE_ATTRIBUTE_HIDDEN | FILE_ATTRIBUTE_SYSTEM);\n\t} else if (S_ISLNK(mode)) {\n\t\t/* It is good idea that link should be the same type (file/dir) as target */\n\t\tfa = FILE_ATTRIBUTE_REPARSE_POINT;\n\n\t\t/*\n\t\t * Linux: there are dir/file/symlink and so on.\n\t\t * NTFS: symlinks are \"dir + reparse\" or \"file + reparse\"\n\t\t * It is good idea to create:\n\t\t * dir + reparse if 'symname' points to directory\n\t\t * or\n\t\t * file + reparse if 'symname' points to file\n\t\t * Unfortunately kern_path hangs if symname contains 'dir'.\n\t\t */\n\n\t\t/*\n\t\t *\tstruct path path;\n\t\t *\n\t\t *\tif (!kern_path(symname, LOOKUP_FOLLOW, &path)){\n\t\t *\t\tstruct inode *target = d_inode(path.dentry);\n\t\t *\n\t\t *\t\tif (S_ISDIR(target->i_mode))\n\t\t *\t\t\tfa |= FILE_ATTRIBUTE_DIRECTORY;\n\t\t *\t\t// if ( target->i_sb == sb ){\n\t\t *\t\t//\tuse relative path?\n\t\t *\t\t// }\n\t\t *\t\tpath_put(&path);\n\t\t *\t}\n\t\t */\n\t} else if (S_ISREG(mode)) {\n\t\tif (sbi->options->sparse) {\n\t\t\t/* Sparsed regular file, cause option 'sparse'. */\n\t\t\tfa = FILE_ATTRIBUTE_SPARSE_FILE |\n\t\t\t     FILE_ATTRIBUTE_ARCHIVE;\n\t\t} else if (dir_ni->std_fa & FILE_ATTRIBUTE_COMPRESSED) {\n\t\t\t/* Compressed regular file, if parent is compressed. */\n\t\t\tfa = FILE_ATTRIBUTE_COMPRESSED | FILE_ATTRIBUTE_ARCHIVE;\n\t\t} else {\n\t\t\t/* Regular file, default attributes. */\n\t\t\tfa = FILE_ATTRIBUTE_ARCHIVE;\n\t\t}\n\t} else {\n\t\tfa = FILE_ATTRIBUTE_ARCHIVE;\n\t}\n\n\t/* If option \"hide_dot_files\" then set hidden attribute for dot files. */\n\tif (sbi->options->hide_dot_files && name->name[0] == '.')\n\t\tfa |= FILE_ATTRIBUTE_HIDDEN;\n\n\tif (!(mode & 0222))\n\t\tfa |= FILE_ATTRIBUTE_READONLY;\n\n\t/* Allocate PATH_MAX bytes. */\n\tnew_de = __getname();\n\tif (!new_de) {\n\t\terr = -ENOMEM;\n\t\tgoto out1;\n\t}\n\n\t/* Mark rw ntfs as dirty. it will be cleared at umount. */\n\tntfs_set_state(sbi, NTFS_DIRTY_DIRTY);\n\n\t/* Step 1: allocate and fill new mft record. */\n\terr = ntfs_look_free_mft(sbi, &ino, false, NULL, NULL);\n\tif (err)\n\t\tgoto out2;\n\n\tni = ntfs_new_inode(sbi, ino, fa & FILE_ATTRIBUTE_DIRECTORY);\n\tif (IS_ERR(ni)) {\n\t\terr = PTR_ERR(ni);\n\t\tni = NULL;\n\t\tgoto out3;\n\t}\n\tinode = &ni->vfs_inode;\n\tinode_init_owner(mnt_userns, inode, dir, mode);\n\tmode = inode->i_mode;\n\n\tinode->i_atime = inode->i_mtime = inode->i_ctime = ni->i_crtime =\n\t\tcurrent_time(inode);\n\n\trec = ni->mi.mrec;\n\trec->hard_links = cpu_to_le16(1);\n\tattr = Add2Ptr(rec, le16_to_cpu(rec->attr_off));\n\n\t/* Get default security id. */\n\tsd = s_default_security;\n\tsd_size = sizeof(s_default_security);\n\n\tif (is_ntfs3(sbi)) {\n\t\tsecurity_id = dir_ni->std_security_id;\n\t\tif (le32_to_cpu(security_id) < SECURITY_ID_FIRST) {\n\t\t\tsecurity_id = sbi->security.def_security_id;\n\n\t\t\tif (security_id == SECURITY_ID_INVALID &&\n\t\t\t    !ntfs_insert_security(sbi, sd, sd_size,\n\t\t\t\t\t\t  &security_id, NULL))\n\t\t\t\tsbi->security.def_security_id = security_id;\n\t\t}\n\t}\n\n\t/* Insert standard info. */\n\tstd5 = Add2Ptr(attr, SIZEOF_RESIDENT);\n\n\tif (security_id == SECURITY_ID_INVALID) {\n\t\tdsize = sizeof(struct ATTR_STD_INFO);\n\t} else {\n\t\tdsize = sizeof(struct ATTR_STD_INFO5);\n\t\tstd5->security_id = security_id;\n\t\tni->std_security_id = security_id;\n\t}\n\tasize = SIZEOF_RESIDENT + dsize;\n\n\tattr->type = ATTR_STD;\n\tattr->size = cpu_to_le32(asize);\n\tattr->id = cpu_to_le16(aid++);\n\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\tattr->res.data_size = cpu_to_le32(dsize);\n\n\tstd5->cr_time = std5->m_time = std5->c_time = std5->a_time =\n\t\tkernel2nt(&inode->i_atime);\n\n\tni->std_fa = fa;\n\tstd5->fa = fa;\n\n\tattr = Add2Ptr(attr, asize);\n\n\t/* Insert file name. */\n\terr = fill_name_de(sbi, new_de, name, uni);\n\tif (err)\n\t\tgoto out4;\n\n\tmi_get_ref(&ni->mi, &new_de->ref);\n\n\tfname = (struct ATTR_FILE_NAME *)(new_de + 1);\n\n\tif (sbi->options->windows_names &&\n\t    !valid_windows_name(sbi, (struct le_str *)&fname->name_len)) {\n\t\terr = -EINVAL;\n\t\tgoto out4;\n\t}\n\n\tmi_get_ref(&dir_ni->mi, &fname->home);\n\tfname->dup.cr_time = fname->dup.m_time = fname->dup.c_time =\n\t\tfname->dup.a_time = std5->cr_time;\n\tfname->dup.alloc_size = fname->dup.data_size = 0;\n\tfname->dup.fa = std5->fa;\n\tfname->dup.ea_size = fname->dup.reparse = 0;\n\n\tdsize = le16_to_cpu(new_de->key_size);\n\tasize = ALIGN(SIZEOF_RESIDENT + dsize, 8);\n\n\tattr->type = ATTR_NAME;\n\tattr->size = cpu_to_le32(asize);\n\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\tattr->res.flags = RESIDENT_FLAG_INDEXED;\n\tattr->id = cpu_to_le16(aid++);\n\tattr->res.data_size = cpu_to_le32(dsize);\n\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), fname, dsize);\n\n\tattr = Add2Ptr(attr, asize);\n\n\tif (security_id == SECURITY_ID_INVALID) {\n\t\t/* Insert security attribute. */\n\t\tasize = SIZEOF_RESIDENT + ALIGN(sd_size, 8);\n\n\t\tattr->type = ATTR_SECURE;\n\t\tattr->size = cpu_to_le32(asize);\n\t\tattr->id = cpu_to_le16(aid++);\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_size = cpu_to_le32(sd_size);\n\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), sd, sd_size);\n\n\t\tattr = Add2Ptr(attr, asize);\n\t}\n\n\tattr->id = cpu_to_le16(aid++);\n\tif (fa & FILE_ATTRIBUTE_DIRECTORY) {\n\t\t/*\n\t\t * Regular directory or symlink to directory.\n\t\t * Create root attribute.\n\t\t */\n\t\tdsize = sizeof(struct INDEX_ROOT) + sizeof(struct NTFS_DE);\n\t\tasize = sizeof(I30_NAME) + SIZEOF_RESIDENT + dsize;\n\n\t\tattr->type = ATTR_ROOT;\n\t\tattr->size = cpu_to_le32(asize);\n\n\t\tattr->name_len = ARRAY_SIZE(I30_NAME);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_off =\n\t\t\tcpu_to_le16(sizeof(I30_NAME) + SIZEOF_RESIDENT);\n\t\tattr->res.data_size = cpu_to_le32(dsize);\n\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), I30_NAME,\n\t\t       sizeof(I30_NAME));\n\n\t\troot = Add2Ptr(attr, sizeof(I30_NAME) + SIZEOF_RESIDENT);\n\t\tmemcpy(root, dir_root, offsetof(struct INDEX_ROOT, ihdr));\n\t\troot->ihdr.de_off =\n\t\t\tcpu_to_le32(sizeof(struct INDEX_HDR)); // 0x10\n\t\troot->ihdr.used = cpu_to_le32(sizeof(struct INDEX_HDR) +\n\t\t\t\t\t      sizeof(struct NTFS_DE));\n\t\troot->ihdr.total = root->ihdr.used;\n\n\t\te = Add2Ptr(root, sizeof(struct INDEX_ROOT));\n\t\te->size = cpu_to_le16(sizeof(struct NTFS_DE));\n\t\te->flags = NTFS_IE_LAST;\n\t} else if (S_ISLNK(mode)) {\n\t\t/*\n\t\t * Symlink to file.\n\t\t * Create empty resident data attribute.\n\t\t */\n\t\tasize = SIZEOF_RESIDENT;\n\n\t\t/* Insert empty ATTR_DATA */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->size = cpu_to_le32(SIZEOF_RESIDENT);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t} else if (S_ISREG(mode)) {\n\t\t/*\n\t\t * Regular file. Create empty non resident data attribute.\n\t\t */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->non_res = 1;\n\t\tattr->nres.evcn = cpu_to_le64(-1ll);\n\t\tif (fa & FILE_ATTRIBUTE_SPARSE_FILE) {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT_EX + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_EX_LE;\n\t\t\tattr->flags = ATTR_FLAG_SPARSED;\n\t\t\tasize = SIZEOF_NONRESIDENT_EX + 8;\n\t\t} else if (fa & FILE_ATTRIBUTE_COMPRESSED) {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT_EX + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_EX_LE;\n\t\t\tattr->flags = ATTR_FLAG_COMPRESSED;\n\t\t\tattr->nres.c_unit = COMPRESSION_UNIT;\n\t\t\tasize = SIZEOF_NONRESIDENT_EX + 8;\n\t\t} else {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_LE;\n\t\t\tasize = SIZEOF_NONRESIDENT + 8;\n\t\t}\n\t\tattr->nres.run_off = attr->name_off;\n\t} else {\n\t\t/*\n\t\t * Node. Create empty resident data attribute.\n\t\t */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->size = cpu_to_le32(SIZEOF_RESIDENT);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tif (fa & FILE_ATTRIBUTE_SPARSE_FILE)\n\t\t\tattr->flags = ATTR_FLAG_SPARSED;\n\t\telse if (fa & FILE_ATTRIBUTE_COMPRESSED)\n\t\t\tattr->flags = ATTR_FLAG_COMPRESSED;\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\tasize = SIZEOF_RESIDENT;\n\t\tni->ni_flags |= NI_FLAG_RESIDENT;\n\t}\n\n\tif (S_ISDIR(mode)) {\n\t\tni->ni_flags |= NI_FLAG_DIR;\n\t\terr = indx_init(&ni->dir, sbi, attr, INDEX_MUTEX_I30);\n\t\tif (err)\n\t\t\tgoto out4;\n\t} else if (S_ISLNK(mode)) {\n\t\trp = ntfs_create_reparse_buffer(sbi, symname, size, &nsize);\n\n\t\tif (IS_ERR(rp)) {\n\t\t\terr = PTR_ERR(rp);\n\t\t\trp = NULL;\n\t\t\tgoto out4;\n\t\t}\n\n\t\t/*\n\t\t * Insert ATTR_REPARSE.\n\t\t */\n\t\tattr = Add2Ptr(attr, asize);\n\t\tattr->type = ATTR_REPARSE;\n\t\tattr->id = cpu_to_le16(aid++);\n\n\t\t/* Resident or non resident? */\n\t\tasize = ALIGN(SIZEOF_RESIDENT + nsize, 8);\n\t\tt16 = PtrOffset(rec, attr);\n\n\t\t/*\n\t\t * Below function 'ntfs_save_wsl_perm' requires 0x78 bytes.\n\t\t * It is good idea to keep extened attributes resident.\n\t\t */\n\t\tif (asize + t16 + 0x78 + 8 > sbi->record_size) {\n\t\t\tCLST alen;\n\t\t\tCLST clst = bytes_to_cluster(sbi, nsize);\n\n\t\t\t/* Bytes per runs. */\n\t\t\tt16 = sbi->record_size - t16 - SIZEOF_NONRESIDENT;\n\n\t\t\tattr->non_res = 1;\n\t\t\tattr->nres.evcn = cpu_to_le64(clst - 1);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_LE;\n\t\t\tattr->nres.run_off = attr->name_off;\n\t\t\tattr->nres.data_size = cpu_to_le64(nsize);\n\t\t\tattr->nres.valid_size = attr->nres.data_size;\n\t\t\tattr->nres.alloc_size =\n\t\t\t\tcpu_to_le64(ntfs_up_cluster(sbi, nsize));\n\n\t\t\terr = attr_allocate_clusters(sbi, &ni->file.run, 0, 0,\n\t\t\t\t\t\t     clst, NULL, ALLOCATE_DEF,\n\t\t\t\t\t\t     &alen, 0, NULL, NULL);\n\t\t\tif (err)\n\t\t\t\tgoto out5;\n\n\t\t\terr = run_pack(&ni->file.run, 0, clst,\n\t\t\t\t       Add2Ptr(attr, SIZEOF_NONRESIDENT), t16,\n\t\t\t\t       &vcn);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out5;\n\n\t\t\tif (vcn != clst) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out5;\n\t\t\t}\n\n\t\t\tasize = SIZEOF_NONRESIDENT + ALIGN(err, 8);\n\t\t} else {\n\t\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\t\tattr->res.data_size = cpu_to_le32(nsize);\n\t\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), rp, nsize);\n\t\t\tnsize = 0;\n\t\t}\n\t\t/* Size of symlink equals the length of input string. */\n\t\tinode->i_size = size;\n\n\t\tattr->size = cpu_to_le32(asize);\n\n\t\terr = ntfs_insert_reparse(sbi, IO_REPARSE_TAG_SYMLINK,\n\t\t\t\t\t  &new_de->ref);\n\t\tif (err)\n\t\t\tgoto out5;\n\n\t\trp_inserted = true;\n\t}\n\n\tattr = Add2Ptr(attr, asize);\n\tattr->type = ATTR_END;\n\n\trec->used = cpu_to_le32(PtrOffset(rec, attr) + 8);\n\trec->next_attr_id = cpu_to_le16(aid);\n\n\t/* Step 2: Add new name in index. */\n\terr = indx_insert_entry(&dir_ni->dir, dir_ni, new_de, sbi, fnd, 0);\n\tif (err)\n\t\tgoto out6;\n\n\t/* Unlock parent directory before ntfs_init_acl. */\n\tif (!fnd)\n\t\tni_unlock(dir_ni);\n\n\tinode->i_generation = le16_to_cpu(rec->seq);\n\n\tdir->i_mtime = dir->i_ctime = inode->i_atime;\n\n\tif (S_ISDIR(mode)) {\n\t\tinode->i_op = &ntfs_dir_inode_operations;\n\t\tinode->i_fop = &ntfs_dir_operations;\n\t} else if (S_ISLNK(mode)) {\n\t\tinode->i_op = &ntfs_link_inode_operations;\n\t\tinode->i_fop = NULL;\n\t\tinode->i_mapping->a_ops = &ntfs_aops;\n\t\tinode->i_size = size;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISREG(mode)) {\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t\tinode->i_fop = &ntfs_file_operations;\n\t\tinode->i_mapping->a_ops =\n\t\t\tis_compressed(ni) ? &ntfs_aops_cmpr : &ntfs_aops;\n\t\tinit_rwsem(&ni->file.run_lock);\n\t} else {\n\t\tinode->i_op = &ntfs_special_inode_operations;\n\t\tinit_special_inode(inode, mode, dev);\n\t}\n\n#ifdef CONFIG_NTFS3_FS_POSIX_ACL\n\tif (!S_ISLNK(mode) && (sb->s_flags & SB_POSIXACL)) {\n\t\terr = ntfs_init_acl(mnt_userns, inode, dir);\n\t\tif (err)\n\t\t\tgoto out7;\n\t} else\n#endif\n\t{\n\t\tinode->i_flags |= S_NOSEC;\n\t}\n\n\t/* Write non resident data. */\n\tif (nsize) {\n\t\terr = ntfs_sb_write_run(sbi, &ni->file.run, 0, rp, nsize, 0);\n\t\tif (err)\n\t\t\tgoto out7;\n\t}\n\n\t/*\n\t * Call 'd_instantiate' after inode->i_op is set\n\t * but before finish_open.\n\t */\n\td_instantiate(dentry, inode);\n\n\tntfs_save_wsl_perm(inode);\n\tmark_inode_dirty(dir);\n\tmark_inode_dirty(inode);\n\n\t/* Normal exit. */\n\tgoto out2;\n\nout7:\n\n\t/* Undo 'indx_insert_entry'. */\n\tif (!fnd)\n\t\tni_lock_dir(dir_ni);\n\tindx_delete_entry(&dir_ni->dir, dir_ni, new_de + 1,\n\t\t\t  le16_to_cpu(new_de->key_size), sbi);\n\t/* ni_unlock(dir_ni); will be called later. */\nout6:\n\tif (rp_inserted)\n\t\tntfs_remove_reparse(sbi, IO_REPARSE_TAG_SYMLINK, &new_de->ref);\n\nout5:\n\tif (S_ISDIR(mode) || run_is_empty(&ni->file.run))\n\t\tgoto out4;\n\n\trun_deallocate(sbi, &ni->file.run, false);\n\nout4:\n\tclear_rec_inuse(rec);\n\tclear_nlink(inode);\n\tni->mi.dirty = false;\n\tdiscard_new_inode(inode);\nout3:\n\tntfs_mark_rec_free(sbi, ino, false);\n\nout2:\n\t__putname(new_de);\n\tkfree(rp);\n\nout1:\n\tif (err) {\n\t\tif (!fnd)\n\t\t\tni_unlock(dir_ni);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tunlock_new_inode(inode);\n\n\treturn inode;\n}",
        "code_after_change": "struct inode *ntfs_create_inode(struct user_namespace *mnt_userns,\n\t\t\t\tstruct inode *dir, struct dentry *dentry,\n\t\t\t\tconst struct cpu_str *uni, umode_t mode,\n\t\t\t\tdev_t dev, const char *symname, u32 size,\n\t\t\t\tstruct ntfs_fnd *fnd)\n{\n\tint err;\n\tstruct super_block *sb = dir->i_sb;\n\tstruct ntfs_sb_info *sbi = sb->s_fs_info;\n\tconst struct qstr *name = &dentry->d_name;\n\tCLST ino = 0;\n\tstruct ntfs_inode *dir_ni = ntfs_i(dir);\n\tstruct ntfs_inode *ni = NULL;\n\tstruct inode *inode = NULL;\n\tstruct ATTRIB *attr;\n\tstruct ATTR_STD_INFO5 *std5;\n\tstruct ATTR_FILE_NAME *fname;\n\tstruct MFT_REC *rec;\n\tu32 asize, dsize, sd_size;\n\tenum FILE_ATTRIBUTE fa;\n\t__le32 security_id = SECURITY_ID_INVALID;\n\tCLST vcn;\n\tconst void *sd;\n\tu16 t16, nsize = 0, aid = 0;\n\tstruct INDEX_ROOT *root, *dir_root;\n\tstruct NTFS_DE *e, *new_de = NULL;\n\tstruct REPARSE_DATA_BUFFER *rp = NULL;\n\tbool rp_inserted = false;\n\n\tif (!fnd)\n\t\tni_lock_dir(dir_ni);\n\n\tdir_root = indx_get_root(&dir_ni->dir, dir_ni, NULL, NULL);\n\tif (!dir_root) {\n\t\terr = -EINVAL;\n\t\tgoto out1;\n\t}\n\n\tif (S_ISDIR(mode)) {\n\t\t/* Use parent's directory attributes. */\n\t\tfa = dir_ni->std_fa | FILE_ATTRIBUTE_DIRECTORY |\n\t\t     FILE_ATTRIBUTE_ARCHIVE;\n\t\t/*\n\t\t * By default child directory inherits parent attributes.\n\t\t * Root directory is hidden + system.\n\t\t * Make an exception for children in root.\n\t\t */\n\t\tif (dir->i_ino == MFT_REC_ROOT)\n\t\t\tfa &= ~(FILE_ATTRIBUTE_HIDDEN | FILE_ATTRIBUTE_SYSTEM);\n\t} else if (S_ISLNK(mode)) {\n\t\t/* It is good idea that link should be the same type (file/dir) as target */\n\t\tfa = FILE_ATTRIBUTE_REPARSE_POINT;\n\n\t\t/*\n\t\t * Linux: there are dir/file/symlink and so on.\n\t\t * NTFS: symlinks are \"dir + reparse\" or \"file + reparse\"\n\t\t * It is good idea to create:\n\t\t * dir + reparse if 'symname' points to directory\n\t\t * or\n\t\t * file + reparse if 'symname' points to file\n\t\t * Unfortunately kern_path hangs if symname contains 'dir'.\n\t\t */\n\n\t\t/*\n\t\t *\tstruct path path;\n\t\t *\n\t\t *\tif (!kern_path(symname, LOOKUP_FOLLOW, &path)){\n\t\t *\t\tstruct inode *target = d_inode(path.dentry);\n\t\t *\n\t\t *\t\tif (S_ISDIR(target->i_mode))\n\t\t *\t\t\tfa |= FILE_ATTRIBUTE_DIRECTORY;\n\t\t *\t\t// if ( target->i_sb == sb ){\n\t\t *\t\t//\tuse relative path?\n\t\t *\t\t// }\n\t\t *\t\tpath_put(&path);\n\t\t *\t}\n\t\t */\n\t} else if (S_ISREG(mode)) {\n\t\tif (sbi->options->sparse) {\n\t\t\t/* Sparsed regular file, cause option 'sparse'. */\n\t\t\tfa = FILE_ATTRIBUTE_SPARSE_FILE |\n\t\t\t     FILE_ATTRIBUTE_ARCHIVE;\n\t\t} else if (dir_ni->std_fa & FILE_ATTRIBUTE_COMPRESSED) {\n\t\t\t/* Compressed regular file, if parent is compressed. */\n\t\t\tfa = FILE_ATTRIBUTE_COMPRESSED | FILE_ATTRIBUTE_ARCHIVE;\n\t\t} else {\n\t\t\t/* Regular file, default attributes. */\n\t\t\tfa = FILE_ATTRIBUTE_ARCHIVE;\n\t\t}\n\t} else {\n\t\tfa = FILE_ATTRIBUTE_ARCHIVE;\n\t}\n\n\t/* If option \"hide_dot_files\" then set hidden attribute for dot files. */\n\tif (sbi->options->hide_dot_files && name->name[0] == '.')\n\t\tfa |= FILE_ATTRIBUTE_HIDDEN;\n\n\tif (!(mode & 0222))\n\t\tfa |= FILE_ATTRIBUTE_READONLY;\n\n\t/* Allocate PATH_MAX bytes. */\n\tnew_de = __getname();\n\tif (!new_de) {\n\t\terr = -ENOMEM;\n\t\tgoto out1;\n\t}\n\n\t/* Mark rw ntfs as dirty. it will be cleared at umount. */\n\tntfs_set_state(sbi, NTFS_DIRTY_DIRTY);\n\n\t/* Step 1: allocate and fill new mft record. */\n\terr = ntfs_look_free_mft(sbi, &ino, false, NULL, NULL);\n\tif (err)\n\t\tgoto out2;\n\n\tni = ntfs_new_inode(sbi, ino, fa & FILE_ATTRIBUTE_DIRECTORY);\n\tif (IS_ERR(ni)) {\n\t\terr = PTR_ERR(ni);\n\t\tni = NULL;\n\t\tgoto out3;\n\t}\n\tinode = &ni->vfs_inode;\n\tinode_init_owner(mnt_userns, inode, dir, mode);\n\tmode = inode->i_mode;\n\n\tinode->i_atime = inode->i_mtime = inode->i_ctime = ni->i_crtime =\n\t\tcurrent_time(inode);\n\n\trec = ni->mi.mrec;\n\trec->hard_links = cpu_to_le16(1);\n\tattr = Add2Ptr(rec, le16_to_cpu(rec->attr_off));\n\n\t/* Get default security id. */\n\tsd = s_default_security;\n\tsd_size = sizeof(s_default_security);\n\n\tif (is_ntfs3(sbi)) {\n\t\tsecurity_id = dir_ni->std_security_id;\n\t\tif (le32_to_cpu(security_id) < SECURITY_ID_FIRST) {\n\t\t\tsecurity_id = sbi->security.def_security_id;\n\n\t\t\tif (security_id == SECURITY_ID_INVALID &&\n\t\t\t    !ntfs_insert_security(sbi, sd, sd_size,\n\t\t\t\t\t\t  &security_id, NULL))\n\t\t\t\tsbi->security.def_security_id = security_id;\n\t\t}\n\t}\n\n\t/* Insert standard info. */\n\tstd5 = Add2Ptr(attr, SIZEOF_RESIDENT);\n\n\tif (security_id == SECURITY_ID_INVALID) {\n\t\tdsize = sizeof(struct ATTR_STD_INFO);\n\t} else {\n\t\tdsize = sizeof(struct ATTR_STD_INFO5);\n\t\tstd5->security_id = security_id;\n\t\tni->std_security_id = security_id;\n\t}\n\tasize = SIZEOF_RESIDENT + dsize;\n\n\tattr->type = ATTR_STD;\n\tattr->size = cpu_to_le32(asize);\n\tattr->id = cpu_to_le16(aid++);\n\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\tattr->res.data_size = cpu_to_le32(dsize);\n\n\tstd5->cr_time = std5->m_time = std5->c_time = std5->a_time =\n\t\tkernel2nt(&inode->i_atime);\n\n\tni->std_fa = fa;\n\tstd5->fa = fa;\n\n\tattr = Add2Ptr(attr, asize);\n\n\t/* Insert file name. */\n\terr = fill_name_de(sbi, new_de, name, uni);\n\tif (err)\n\t\tgoto out4;\n\n\tmi_get_ref(&ni->mi, &new_de->ref);\n\n\tfname = (struct ATTR_FILE_NAME *)(new_de + 1);\n\n\tif (sbi->options->windows_names &&\n\t    !valid_windows_name(sbi, (struct le_str *)&fname->name_len)) {\n\t\terr = -EINVAL;\n\t\tgoto out4;\n\t}\n\n\tmi_get_ref(&dir_ni->mi, &fname->home);\n\tfname->dup.cr_time = fname->dup.m_time = fname->dup.c_time =\n\t\tfname->dup.a_time = std5->cr_time;\n\tfname->dup.alloc_size = fname->dup.data_size = 0;\n\tfname->dup.fa = std5->fa;\n\tfname->dup.ea_size = fname->dup.reparse = 0;\n\n\tdsize = le16_to_cpu(new_de->key_size);\n\tasize = ALIGN(SIZEOF_RESIDENT + dsize, 8);\n\n\tattr->type = ATTR_NAME;\n\tattr->size = cpu_to_le32(asize);\n\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\tattr->res.flags = RESIDENT_FLAG_INDEXED;\n\tattr->id = cpu_to_le16(aid++);\n\tattr->res.data_size = cpu_to_le32(dsize);\n\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), fname, dsize);\n\n\tattr = Add2Ptr(attr, asize);\n\n\tif (security_id == SECURITY_ID_INVALID) {\n\t\t/* Insert security attribute. */\n\t\tasize = SIZEOF_RESIDENT + ALIGN(sd_size, 8);\n\n\t\tattr->type = ATTR_SECURE;\n\t\tattr->size = cpu_to_le32(asize);\n\t\tattr->id = cpu_to_le16(aid++);\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_size = cpu_to_le32(sd_size);\n\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), sd, sd_size);\n\n\t\tattr = Add2Ptr(attr, asize);\n\t}\n\n\tattr->id = cpu_to_le16(aid++);\n\tif (fa & FILE_ATTRIBUTE_DIRECTORY) {\n\t\t/*\n\t\t * Regular directory or symlink to directory.\n\t\t * Create root attribute.\n\t\t */\n\t\tdsize = sizeof(struct INDEX_ROOT) + sizeof(struct NTFS_DE);\n\t\tasize = sizeof(I30_NAME) + SIZEOF_RESIDENT + dsize;\n\n\t\tattr->type = ATTR_ROOT;\n\t\tattr->size = cpu_to_le32(asize);\n\n\t\tattr->name_len = ARRAY_SIZE(I30_NAME);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_off =\n\t\t\tcpu_to_le16(sizeof(I30_NAME) + SIZEOF_RESIDENT);\n\t\tattr->res.data_size = cpu_to_le32(dsize);\n\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), I30_NAME,\n\t\t       sizeof(I30_NAME));\n\n\t\troot = Add2Ptr(attr, sizeof(I30_NAME) + SIZEOF_RESIDENT);\n\t\tmemcpy(root, dir_root, offsetof(struct INDEX_ROOT, ihdr));\n\t\troot->ihdr.de_off =\n\t\t\tcpu_to_le32(sizeof(struct INDEX_HDR)); // 0x10\n\t\troot->ihdr.used = cpu_to_le32(sizeof(struct INDEX_HDR) +\n\t\t\t\t\t      sizeof(struct NTFS_DE));\n\t\troot->ihdr.total = root->ihdr.used;\n\n\t\te = Add2Ptr(root, sizeof(struct INDEX_ROOT));\n\t\te->size = cpu_to_le16(sizeof(struct NTFS_DE));\n\t\te->flags = NTFS_IE_LAST;\n\t} else if (S_ISLNK(mode)) {\n\t\t/*\n\t\t * Symlink to file.\n\t\t * Create empty resident data attribute.\n\t\t */\n\t\tasize = SIZEOF_RESIDENT;\n\n\t\t/* Insert empty ATTR_DATA */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->size = cpu_to_le32(SIZEOF_RESIDENT);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t} else if (S_ISREG(mode)) {\n\t\t/*\n\t\t * Regular file. Create empty non resident data attribute.\n\t\t */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->non_res = 1;\n\t\tattr->nres.evcn = cpu_to_le64(-1ll);\n\t\tif (fa & FILE_ATTRIBUTE_SPARSE_FILE) {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT_EX + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_EX_LE;\n\t\t\tattr->flags = ATTR_FLAG_SPARSED;\n\t\t\tasize = SIZEOF_NONRESIDENT_EX + 8;\n\t\t} else if (fa & FILE_ATTRIBUTE_COMPRESSED) {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT_EX + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_EX_LE;\n\t\t\tattr->flags = ATTR_FLAG_COMPRESSED;\n\t\t\tattr->nres.c_unit = COMPRESSION_UNIT;\n\t\t\tasize = SIZEOF_NONRESIDENT_EX + 8;\n\t\t} else {\n\t\t\tattr->size = cpu_to_le32(SIZEOF_NONRESIDENT + 8);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_LE;\n\t\t\tasize = SIZEOF_NONRESIDENT + 8;\n\t\t}\n\t\tattr->nres.run_off = attr->name_off;\n\t} else {\n\t\t/*\n\t\t * Node. Create empty resident data attribute.\n\t\t */\n\t\tattr->type = ATTR_DATA;\n\t\tattr->size = cpu_to_le32(SIZEOF_RESIDENT);\n\t\tattr->name_off = SIZEOF_RESIDENT_LE;\n\t\tif (fa & FILE_ATTRIBUTE_SPARSE_FILE)\n\t\t\tattr->flags = ATTR_FLAG_SPARSED;\n\t\telse if (fa & FILE_ATTRIBUTE_COMPRESSED)\n\t\t\tattr->flags = ATTR_FLAG_COMPRESSED;\n\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\tasize = SIZEOF_RESIDENT;\n\t\tni->ni_flags |= NI_FLAG_RESIDENT;\n\t}\n\n\tif (S_ISDIR(mode)) {\n\t\tni->ni_flags |= NI_FLAG_DIR;\n\t\terr = indx_init(&ni->dir, sbi, attr, INDEX_MUTEX_I30);\n\t\tif (err)\n\t\t\tgoto out4;\n\t} else if (S_ISLNK(mode)) {\n\t\trp = ntfs_create_reparse_buffer(sbi, symname, size, &nsize);\n\n\t\tif (IS_ERR(rp)) {\n\t\t\terr = PTR_ERR(rp);\n\t\t\trp = NULL;\n\t\t\tgoto out4;\n\t\t}\n\n\t\t/*\n\t\t * Insert ATTR_REPARSE.\n\t\t */\n\t\tattr = Add2Ptr(attr, asize);\n\t\tattr->type = ATTR_REPARSE;\n\t\tattr->id = cpu_to_le16(aid++);\n\n\t\t/* Resident or non resident? */\n\t\tasize = ALIGN(SIZEOF_RESIDENT + nsize, 8);\n\t\tt16 = PtrOffset(rec, attr);\n\n\t\t/*\n\t\t * Below function 'ntfs_save_wsl_perm' requires 0x78 bytes.\n\t\t * It is good idea to keep extened attributes resident.\n\t\t */\n\t\tif (asize + t16 + 0x78 + 8 > sbi->record_size) {\n\t\t\tCLST alen;\n\t\t\tCLST clst = bytes_to_cluster(sbi, nsize);\n\n\t\t\t/* Bytes per runs. */\n\t\t\tt16 = sbi->record_size - t16 - SIZEOF_NONRESIDENT;\n\n\t\t\tattr->non_res = 1;\n\t\t\tattr->nres.evcn = cpu_to_le64(clst - 1);\n\t\t\tattr->name_off = SIZEOF_NONRESIDENT_LE;\n\t\t\tattr->nres.run_off = attr->name_off;\n\t\t\tattr->nres.data_size = cpu_to_le64(nsize);\n\t\t\tattr->nres.valid_size = attr->nres.data_size;\n\t\t\tattr->nres.alloc_size =\n\t\t\t\tcpu_to_le64(ntfs_up_cluster(sbi, nsize));\n\n\t\t\terr = attr_allocate_clusters(sbi, &ni->file.run, 0, 0,\n\t\t\t\t\t\t     clst, NULL, ALLOCATE_DEF,\n\t\t\t\t\t\t     &alen, 0, NULL, NULL);\n\t\t\tif (err)\n\t\t\t\tgoto out5;\n\n\t\t\terr = run_pack(&ni->file.run, 0, clst,\n\t\t\t\t       Add2Ptr(attr, SIZEOF_NONRESIDENT), t16,\n\t\t\t\t       &vcn);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out5;\n\n\t\t\tif (vcn != clst) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out5;\n\t\t\t}\n\n\t\t\tasize = SIZEOF_NONRESIDENT + ALIGN(err, 8);\n\t\t} else {\n\t\t\tattr->res.data_off = SIZEOF_RESIDENT_LE;\n\t\t\tattr->res.data_size = cpu_to_le32(nsize);\n\t\t\tmemcpy(Add2Ptr(attr, SIZEOF_RESIDENT), rp, nsize);\n\t\t\tnsize = 0;\n\t\t}\n\t\t/* Size of symlink equals the length of input string. */\n\t\tinode->i_size = size;\n\n\t\tattr->size = cpu_to_le32(asize);\n\n\t\terr = ntfs_insert_reparse(sbi, IO_REPARSE_TAG_SYMLINK,\n\t\t\t\t\t  &new_de->ref);\n\t\tif (err)\n\t\t\tgoto out5;\n\n\t\trp_inserted = true;\n\t}\n\n\tattr = Add2Ptr(attr, asize);\n\tattr->type = ATTR_END;\n\n\trec->used = cpu_to_le32(PtrOffset(rec, attr) + 8);\n\trec->next_attr_id = cpu_to_le16(aid);\n\n\t/* Step 2: Add new name in index. */\n\terr = indx_insert_entry(&dir_ni->dir, dir_ni, new_de, sbi, fnd, 0);\n\tif (err)\n\t\tgoto out6;\n\n\t/* Unlock parent directory before ntfs_init_acl. */\n\tif (!fnd)\n\t\tni_unlock(dir_ni);\n\n\tinode->i_generation = le16_to_cpu(rec->seq);\n\n\tdir->i_mtime = dir->i_ctime = inode->i_atime;\n\n\tif (S_ISDIR(mode)) {\n\t\tinode->i_op = &ntfs_dir_inode_operations;\n\t\tinode->i_fop = &ntfs_dir_operations;\n\t} else if (S_ISLNK(mode)) {\n\t\tinode->i_op = &ntfs_link_inode_operations;\n\t\tinode->i_fop = NULL;\n\t\tinode->i_mapping->a_ops = &ntfs_aops;\n\t\tinode->i_size = size;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISREG(mode)) {\n\t\tinode->i_op = &ntfs_file_inode_operations;\n\t\tinode->i_fop = &ntfs_file_operations;\n\t\tinode->i_mapping->a_ops =\n\t\t\tis_compressed(ni) ? &ntfs_aops_cmpr : &ntfs_aops;\n\t\tinit_rwsem(&ni->file.run_lock);\n\t} else {\n\t\tinode->i_op = &ntfs_special_inode_operations;\n\t\tinit_special_inode(inode, mode, dev);\n\t}\n\n#ifdef CONFIG_NTFS3_FS_POSIX_ACL\n\tif (!S_ISLNK(mode) && (sb->s_flags & SB_POSIXACL)) {\n\t\terr = ntfs_init_acl(mnt_userns, inode, dir);\n\t\tif (err)\n\t\t\tgoto out7;\n\t} else\n#endif\n\t{\n\t\tinode->i_flags |= S_NOSEC;\n\t}\n\n\t/* Write non resident data. */\n\tif (nsize) {\n\t\terr = ntfs_sb_write_run(sbi, &ni->file.run, 0, rp, nsize, 0);\n\t\tif (err)\n\t\t\tgoto out7;\n\t}\n\n\t/*\n\t * Call 'd_instantiate' after inode->i_op is set\n\t * but before finish_open.\n\t */\n\td_instantiate(dentry, inode);\n\n\tntfs_save_wsl_perm(inode);\n\tmark_inode_dirty(dir);\n\tmark_inode_dirty(inode);\n\n\t/* Normal exit. */\n\tgoto out2;\n\nout7:\n\n\t/* Undo 'indx_insert_entry'. */\n\tif (!fnd)\n\t\tni_lock_dir(dir_ni);\n\tindx_delete_entry(&dir_ni->dir, dir_ni, new_de + 1,\n\t\t\t  le16_to_cpu(new_de->key_size), sbi);\n\t/* ni_unlock(dir_ni); will be called later. */\nout6:\n\tif (rp_inserted)\n\t\tntfs_remove_reparse(sbi, IO_REPARSE_TAG_SYMLINK, &new_de->ref);\n\nout5:\n\tif (!S_ISDIR(mode))\n\t\trun_deallocate(sbi, &ni->file.run, false);\n\nout4:\n\tclear_rec_inuse(rec);\n\tclear_nlink(inode);\n\tni->mi.dirty = false;\n\tdiscard_new_inode(inode);\nout3:\n\tntfs_mark_rec_free(sbi, ino, false);\n\nout2:\n\t__putname(new_de);\n\tkfree(rp);\n\nout1:\n\tif (err) {\n\t\tif (!fnd)\n\t\t\tni_unlock(dir_ni);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tunlock_new_inode(inode);\n\n\treturn inode;\n}",
        "patch": "--- code before\n+++ code after\n@@ -469,10 +469,8 @@\n \t\tntfs_remove_reparse(sbi, IO_REPARSE_TAG_SYMLINK, &new_de->ref);\n \n out5:\n-\tif (S_ISDIR(mode) || run_is_empty(&ni->file.run))\n-\t\tgoto out4;\n-\n-\trun_deallocate(sbi, &ni->file.run, false);\n+\tif (!S_ISDIR(mode))\n+\t\trun_deallocate(sbi, &ni->file.run, false);\n \n out4:\n \tclear_rec_inuse(rec);",
        "function_modified_lines": {
            "added": [
                "\tif (!S_ISDIR(mode))",
                "\t\trun_deallocate(sbi, &ni->file.run, false);"
            ],
            "deleted": [
                "\tif (S_ISDIR(mode) || run_is_empty(&ni->file.run))",
                "\t\tgoto out4;",
                "",
                "\trun_deallocate(sbi, &ni->file.run, false);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3797
    },
    {
        "cve_id": "CVE-2023-37453",
        "code_before_change": "static void hub_port_connect(struct usb_hub *hub, int port1, u16 portstatus,\n\t\tu16 portchange)\n{\n\tint status = -ENODEV;\n\tint i;\n\tunsigned unit_load;\n\tstruct usb_device *hdev = hub->hdev;\n\tstruct usb_hcd *hcd = bus_to_hcd(hdev->bus);\n\tstruct usb_port *port_dev = hub->ports[port1 - 1];\n\tstruct usb_device *udev = port_dev->child;\n\tstatic int unreliable_port = -1;\n\tbool retry_locked;\n\n\t/* Disconnect any existing devices under this port */\n\tif (udev) {\n\t\tif (hcd->usb_phy && !hdev->parent)\n\t\t\tusb_phy_notify_disconnect(hcd->usb_phy, udev->speed);\n\t\tusb_disconnect(&port_dev->child);\n\t}\n\n\t/* We can forget about a \"removed\" device when there's a physical\n\t * disconnect or the connect status changes.\n\t */\n\tif (!(portstatus & USB_PORT_STAT_CONNECTION) ||\n\t\t\t(portchange & USB_PORT_STAT_C_CONNECTION))\n\t\tclear_bit(port1, hub->removed_bits);\n\n\tif (portchange & (USB_PORT_STAT_C_CONNECTION |\n\t\t\t\tUSB_PORT_STAT_C_ENABLE)) {\n\t\tstatus = hub_port_debounce_be_stable(hub, port1);\n\t\tif (status < 0) {\n\t\t\tif (status != -ENODEV &&\n\t\t\t\tport1 != unreliable_port &&\n\t\t\t\tprintk_ratelimit())\n\t\t\t\tdev_err(&port_dev->dev, \"connect-debounce failed\\n\");\n\t\t\tportstatus &= ~USB_PORT_STAT_CONNECTION;\n\t\t\tunreliable_port = port1;\n\t\t} else {\n\t\t\tportstatus = status;\n\t\t}\n\t}\n\n\t/* Return now if debouncing failed or nothing is connected or\n\t * the device was \"removed\".\n\t */\n\tif (!(portstatus & USB_PORT_STAT_CONNECTION) ||\n\t\t\ttest_bit(port1, hub->removed_bits)) {\n\n\t\t/*\n\t\t * maybe switch power back on (e.g. root hub was reset)\n\t\t * but only if the port isn't owned by someone else.\n\t\t */\n\t\tif (hub_is_port_power_switchable(hub)\n\t\t\t\t&& !usb_port_is_power_on(hub, portstatus)\n\t\t\t\t&& !port_dev->port_owner)\n\t\t\tset_port_feature(hdev, port1, USB_PORT_FEAT_POWER);\n\n\t\tif (portstatus & USB_PORT_STAT_ENABLE)\n\t\t\tgoto done;\n\t\treturn;\n\t}\n\tif (hub_is_superspeed(hub->hdev))\n\t\tunit_load = 150;\n\telse\n\t\tunit_load = 100;\n\n\tstatus = 0;\n\n\tfor (i = 0; i < PORT_INIT_TRIES; i++) {\n\t\tif (hub_port_stop_enumerate(hub, port1, i)) {\n\t\t\tstatus = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\tusb_lock_port(port_dev);\n\t\tmutex_lock(hcd->address0_mutex);\n\t\tretry_locked = true;\n\t\t/* reallocate for each attempt, since references\n\t\t * to the previous one can escape in various ways\n\t\t */\n\t\tudev = usb_alloc_dev(hdev, hdev->bus, port1);\n\t\tif (!udev) {\n\t\t\tdev_err(&port_dev->dev,\n\t\t\t\t\t\"couldn't allocate usb_device\\n\");\n\t\t\tmutex_unlock(hcd->address0_mutex);\n\t\t\tusb_unlock_port(port_dev);\n\t\t\tgoto done;\n\t\t}\n\n\t\tusb_set_device_state(udev, USB_STATE_POWERED);\n\t\tudev->bus_mA = hub->mA_per_port;\n\t\tudev->level = hdev->level + 1;\n\t\tudev->wusb = hub_is_wusb(hub);\n\n\t\t/* Devices connected to SuperSpeed hubs are USB 3.0 or later */\n\t\tif (hub_is_superspeed(hub->hdev))\n\t\t\tudev->speed = USB_SPEED_SUPER;\n\t\telse\n\t\t\tudev->speed = USB_SPEED_UNKNOWN;\n\n\t\tchoose_devnum(udev);\n\t\tif (udev->devnum <= 0) {\n\t\t\tstatus = -ENOTCONN;\t/* Don't retry */\n\t\t\tgoto loop;\n\t\t}\n\n\t\t/* reset (non-USB 3.0 devices) and get descriptor */\n\t\tstatus = hub_port_init(hub, udev, port1, i);\n\t\tif (status < 0)\n\t\t\tgoto loop;\n\n\t\tmutex_unlock(hcd->address0_mutex);\n\t\tusb_unlock_port(port_dev);\n\t\tretry_locked = false;\n\n\t\tif (udev->quirks & USB_QUIRK_DELAY_INIT)\n\t\t\tmsleep(2000);\n\n\t\t/* consecutive bus-powered hubs aren't reliable; they can\n\t\t * violate the voltage drop budget.  if the new child has\n\t\t * a \"powered\" LED, users should notice we didn't enable it\n\t\t * (without reading syslog), even without per-port LEDs\n\t\t * on the parent.\n\t\t */\n\t\tif (udev->descriptor.bDeviceClass == USB_CLASS_HUB\n\t\t\t\t&& udev->bus_mA <= unit_load) {\n\t\t\tu16\tdevstat;\n\n\t\t\tstatus = usb_get_std_status(udev, USB_RECIP_DEVICE, 0,\n\t\t\t\t\t&devstat);\n\t\t\tif (status) {\n\t\t\t\tdev_dbg(&udev->dev, \"get status %d ?\\n\", status);\n\t\t\t\tgoto loop_disable;\n\t\t\t}\n\t\t\tif ((devstat & (1 << USB_DEVICE_SELF_POWERED)) == 0) {\n\t\t\t\tdev_err(&udev->dev,\n\t\t\t\t\t\"can't connect bus-powered hub \"\n\t\t\t\t\t\"to this port\\n\");\n\t\t\t\tif (hub->has_indicators) {\n\t\t\t\t\thub->indicator[port1-1] =\n\t\t\t\t\t\tINDICATOR_AMBER_BLINK;\n\t\t\t\t\tqueue_delayed_work(\n\t\t\t\t\t\tsystem_power_efficient_wq,\n\t\t\t\t\t\t&hub->leds, 0);\n\t\t\t\t}\n\t\t\t\tstatus = -ENOTCONN;\t/* Don't retry */\n\t\t\t\tgoto loop_disable;\n\t\t\t}\n\t\t}\n\n\t\t/* check for devices running slower than they could */\n\t\tif (le16_to_cpu(udev->descriptor.bcdUSB) >= 0x0200\n\t\t\t\t&& udev->speed == USB_SPEED_FULL\n\t\t\t\t&& highspeed_hubs != 0)\n\t\t\tcheck_highspeed(hub, udev, port1);\n\n\t\t/* Store the parent's children[] pointer.  At this point\n\t\t * udev becomes globally accessible, although presumably\n\t\t * no one will look at it until hdev is unlocked.\n\t\t */\n\t\tstatus = 0;\n\n\t\tmutex_lock(&usb_port_peer_mutex);\n\n\t\t/* We mustn't add new devices if the parent hub has\n\t\t * been disconnected; we would race with the\n\t\t * recursively_mark_NOTATTACHED() routine.\n\t\t */\n\t\tspin_lock_irq(&device_state_lock);\n\t\tif (hdev->state == USB_STATE_NOTATTACHED)\n\t\t\tstatus = -ENOTCONN;\n\t\telse\n\t\t\tport_dev->child = udev;\n\t\tspin_unlock_irq(&device_state_lock);\n\t\tmutex_unlock(&usb_port_peer_mutex);\n\n\t\t/* Run it through the hoops (find a driver, etc) */\n\t\tif (!status) {\n\t\t\tstatus = usb_new_device(udev);\n\t\t\tif (status) {\n\t\t\t\tmutex_lock(&usb_port_peer_mutex);\n\t\t\t\tspin_lock_irq(&device_state_lock);\n\t\t\t\tport_dev->child = NULL;\n\t\t\t\tspin_unlock_irq(&device_state_lock);\n\t\t\t\tmutex_unlock(&usb_port_peer_mutex);\n\t\t\t} else {\n\t\t\t\tif (hcd->usb_phy && !hdev->parent)\n\t\t\t\t\tusb_phy_notify_connect(hcd->usb_phy,\n\t\t\t\t\t\t\tudev->speed);\n\t\t\t}\n\t\t}\n\n\t\tif (status)\n\t\t\tgoto loop_disable;\n\n\t\tstatus = hub_power_remaining(hub);\n\t\tif (status)\n\t\t\tdev_dbg(hub->intfdev, \"%dmA power budget left\\n\", status);\n\n\t\treturn;\n\nloop_disable:\n\t\thub_port_disable(hub, port1, 1);\nloop:\n\t\tusb_ep0_reinit(udev);\n\t\trelease_devnum(udev);\n\t\thub_free_dev(udev);\n\t\tif (retry_locked) {\n\t\t\tmutex_unlock(hcd->address0_mutex);\n\t\t\tusb_unlock_port(port_dev);\n\t\t}\n\t\tusb_put_dev(udev);\n\t\tif ((status == -ENOTCONN) || (status == -ENOTSUPP))\n\t\t\tbreak;\n\n\t\t/* When halfway through our retry count, power-cycle the port */\n\t\tif (i == (PORT_INIT_TRIES - 1) / 2) {\n\t\t\tdev_info(&port_dev->dev, \"attempt power cycle\\n\");\n\t\t\tusb_hub_set_port_power(hdev, hub, port1, false);\n\t\t\tmsleep(2 * hub_power_on_good_delay(hub));\n\t\t\tusb_hub_set_port_power(hdev, hub, port1, true);\n\t\t\tmsleep(hub_power_on_good_delay(hub));\n\t\t}\n\t}\n\tif (hub->hdev->parent ||\n\t\t\t!hcd->driver->port_handed_over ||\n\t\t\t!(hcd->driver->port_handed_over)(hcd, port1)) {\n\t\tif (status != -ENOTCONN && status != -ENODEV)\n\t\t\tdev_err(&port_dev->dev,\n\t\t\t\t\t\"unable to enumerate USB device\\n\");\n\t}\n\ndone:\n\thub_port_disable(hub, port1, 1);\n\tif (hcd->driver->relinquish_port && !hub->hdev->parent) {\n\t\tif (status != -ENOTCONN && status != -ENODEV)\n\t\t\thcd->driver->relinquish_port(hcd, port1);\n\t}\n}",
        "code_after_change": "static void hub_port_connect(struct usb_hub *hub, int port1, u16 portstatus,\n\t\tu16 portchange)\n{\n\tint status = -ENODEV;\n\tint i;\n\tunsigned unit_load;\n\tstruct usb_device *hdev = hub->hdev;\n\tstruct usb_hcd *hcd = bus_to_hcd(hdev->bus);\n\tstruct usb_port *port_dev = hub->ports[port1 - 1];\n\tstruct usb_device *udev = port_dev->child;\n\tstatic int unreliable_port = -1;\n\tbool retry_locked;\n\n\t/* Disconnect any existing devices under this port */\n\tif (udev) {\n\t\tif (hcd->usb_phy && !hdev->parent)\n\t\t\tusb_phy_notify_disconnect(hcd->usb_phy, udev->speed);\n\t\tusb_disconnect(&port_dev->child);\n\t}\n\n\t/* We can forget about a \"removed\" device when there's a physical\n\t * disconnect or the connect status changes.\n\t */\n\tif (!(portstatus & USB_PORT_STAT_CONNECTION) ||\n\t\t\t(portchange & USB_PORT_STAT_C_CONNECTION))\n\t\tclear_bit(port1, hub->removed_bits);\n\n\tif (portchange & (USB_PORT_STAT_C_CONNECTION |\n\t\t\t\tUSB_PORT_STAT_C_ENABLE)) {\n\t\tstatus = hub_port_debounce_be_stable(hub, port1);\n\t\tif (status < 0) {\n\t\t\tif (status != -ENODEV &&\n\t\t\t\tport1 != unreliable_port &&\n\t\t\t\tprintk_ratelimit())\n\t\t\t\tdev_err(&port_dev->dev, \"connect-debounce failed\\n\");\n\t\t\tportstatus &= ~USB_PORT_STAT_CONNECTION;\n\t\t\tunreliable_port = port1;\n\t\t} else {\n\t\t\tportstatus = status;\n\t\t}\n\t}\n\n\t/* Return now if debouncing failed or nothing is connected or\n\t * the device was \"removed\".\n\t */\n\tif (!(portstatus & USB_PORT_STAT_CONNECTION) ||\n\t\t\ttest_bit(port1, hub->removed_bits)) {\n\n\t\t/*\n\t\t * maybe switch power back on (e.g. root hub was reset)\n\t\t * but only if the port isn't owned by someone else.\n\t\t */\n\t\tif (hub_is_port_power_switchable(hub)\n\t\t\t\t&& !usb_port_is_power_on(hub, portstatus)\n\t\t\t\t&& !port_dev->port_owner)\n\t\t\tset_port_feature(hdev, port1, USB_PORT_FEAT_POWER);\n\n\t\tif (portstatus & USB_PORT_STAT_ENABLE)\n\t\t\tgoto done;\n\t\treturn;\n\t}\n\tif (hub_is_superspeed(hub->hdev))\n\t\tunit_load = 150;\n\telse\n\t\tunit_load = 100;\n\n\tstatus = 0;\n\n\tfor (i = 0; i < PORT_INIT_TRIES; i++) {\n\t\tif (hub_port_stop_enumerate(hub, port1, i)) {\n\t\t\tstatus = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\tusb_lock_port(port_dev);\n\t\tmutex_lock(hcd->address0_mutex);\n\t\tretry_locked = true;\n\t\t/* reallocate for each attempt, since references\n\t\t * to the previous one can escape in various ways\n\t\t */\n\t\tudev = usb_alloc_dev(hdev, hdev->bus, port1);\n\t\tif (!udev) {\n\t\t\tdev_err(&port_dev->dev,\n\t\t\t\t\t\"couldn't allocate usb_device\\n\");\n\t\t\tmutex_unlock(hcd->address0_mutex);\n\t\t\tusb_unlock_port(port_dev);\n\t\t\tgoto done;\n\t\t}\n\n\t\tusb_set_device_state(udev, USB_STATE_POWERED);\n\t\tudev->bus_mA = hub->mA_per_port;\n\t\tudev->level = hdev->level + 1;\n\t\tudev->wusb = hub_is_wusb(hub);\n\n\t\t/* Devices connected to SuperSpeed hubs are USB 3.0 or later */\n\t\tif (hub_is_superspeed(hub->hdev))\n\t\t\tudev->speed = USB_SPEED_SUPER;\n\t\telse\n\t\t\tudev->speed = USB_SPEED_UNKNOWN;\n\n\t\tchoose_devnum(udev);\n\t\tif (udev->devnum <= 0) {\n\t\t\tstatus = -ENOTCONN;\t/* Don't retry */\n\t\t\tgoto loop;\n\t\t}\n\n\t\t/* reset (non-USB 3.0 devices) and get descriptor */\n\t\tstatus = hub_port_init(hub, udev, port1, i, NULL);\n\t\tif (status < 0)\n\t\t\tgoto loop;\n\n\t\tmutex_unlock(hcd->address0_mutex);\n\t\tusb_unlock_port(port_dev);\n\t\tretry_locked = false;\n\n\t\tif (udev->quirks & USB_QUIRK_DELAY_INIT)\n\t\t\tmsleep(2000);\n\n\t\t/* consecutive bus-powered hubs aren't reliable; they can\n\t\t * violate the voltage drop budget.  if the new child has\n\t\t * a \"powered\" LED, users should notice we didn't enable it\n\t\t * (without reading syslog), even without per-port LEDs\n\t\t * on the parent.\n\t\t */\n\t\tif (udev->descriptor.bDeviceClass == USB_CLASS_HUB\n\t\t\t\t&& udev->bus_mA <= unit_load) {\n\t\t\tu16\tdevstat;\n\n\t\t\tstatus = usb_get_std_status(udev, USB_RECIP_DEVICE, 0,\n\t\t\t\t\t&devstat);\n\t\t\tif (status) {\n\t\t\t\tdev_dbg(&udev->dev, \"get status %d ?\\n\", status);\n\t\t\t\tgoto loop_disable;\n\t\t\t}\n\t\t\tif ((devstat & (1 << USB_DEVICE_SELF_POWERED)) == 0) {\n\t\t\t\tdev_err(&udev->dev,\n\t\t\t\t\t\"can't connect bus-powered hub \"\n\t\t\t\t\t\"to this port\\n\");\n\t\t\t\tif (hub->has_indicators) {\n\t\t\t\t\thub->indicator[port1-1] =\n\t\t\t\t\t\tINDICATOR_AMBER_BLINK;\n\t\t\t\t\tqueue_delayed_work(\n\t\t\t\t\t\tsystem_power_efficient_wq,\n\t\t\t\t\t\t&hub->leds, 0);\n\t\t\t\t}\n\t\t\t\tstatus = -ENOTCONN;\t/* Don't retry */\n\t\t\t\tgoto loop_disable;\n\t\t\t}\n\t\t}\n\n\t\t/* check for devices running slower than they could */\n\t\tif (le16_to_cpu(udev->descriptor.bcdUSB) >= 0x0200\n\t\t\t\t&& udev->speed == USB_SPEED_FULL\n\t\t\t\t&& highspeed_hubs != 0)\n\t\t\tcheck_highspeed(hub, udev, port1);\n\n\t\t/* Store the parent's children[] pointer.  At this point\n\t\t * udev becomes globally accessible, although presumably\n\t\t * no one will look at it until hdev is unlocked.\n\t\t */\n\t\tstatus = 0;\n\n\t\tmutex_lock(&usb_port_peer_mutex);\n\n\t\t/* We mustn't add new devices if the parent hub has\n\t\t * been disconnected; we would race with the\n\t\t * recursively_mark_NOTATTACHED() routine.\n\t\t */\n\t\tspin_lock_irq(&device_state_lock);\n\t\tif (hdev->state == USB_STATE_NOTATTACHED)\n\t\t\tstatus = -ENOTCONN;\n\t\telse\n\t\t\tport_dev->child = udev;\n\t\tspin_unlock_irq(&device_state_lock);\n\t\tmutex_unlock(&usb_port_peer_mutex);\n\n\t\t/* Run it through the hoops (find a driver, etc) */\n\t\tif (!status) {\n\t\t\tstatus = usb_new_device(udev);\n\t\t\tif (status) {\n\t\t\t\tmutex_lock(&usb_port_peer_mutex);\n\t\t\t\tspin_lock_irq(&device_state_lock);\n\t\t\t\tport_dev->child = NULL;\n\t\t\t\tspin_unlock_irq(&device_state_lock);\n\t\t\t\tmutex_unlock(&usb_port_peer_mutex);\n\t\t\t} else {\n\t\t\t\tif (hcd->usb_phy && !hdev->parent)\n\t\t\t\t\tusb_phy_notify_connect(hcd->usb_phy,\n\t\t\t\t\t\t\tudev->speed);\n\t\t\t}\n\t\t}\n\n\t\tif (status)\n\t\t\tgoto loop_disable;\n\n\t\tstatus = hub_power_remaining(hub);\n\t\tif (status)\n\t\t\tdev_dbg(hub->intfdev, \"%dmA power budget left\\n\", status);\n\n\t\treturn;\n\nloop_disable:\n\t\thub_port_disable(hub, port1, 1);\nloop:\n\t\tusb_ep0_reinit(udev);\n\t\trelease_devnum(udev);\n\t\thub_free_dev(udev);\n\t\tif (retry_locked) {\n\t\t\tmutex_unlock(hcd->address0_mutex);\n\t\t\tusb_unlock_port(port_dev);\n\t\t}\n\t\tusb_put_dev(udev);\n\t\tif ((status == -ENOTCONN) || (status == -ENOTSUPP))\n\t\t\tbreak;\n\n\t\t/* When halfway through our retry count, power-cycle the port */\n\t\tif (i == (PORT_INIT_TRIES - 1) / 2) {\n\t\t\tdev_info(&port_dev->dev, \"attempt power cycle\\n\");\n\t\t\tusb_hub_set_port_power(hdev, hub, port1, false);\n\t\t\tmsleep(2 * hub_power_on_good_delay(hub));\n\t\t\tusb_hub_set_port_power(hdev, hub, port1, true);\n\t\t\tmsleep(hub_power_on_good_delay(hub));\n\t\t}\n\t}\n\tif (hub->hdev->parent ||\n\t\t\t!hcd->driver->port_handed_over ||\n\t\t\t!(hcd->driver->port_handed_over)(hcd, port1)) {\n\t\tif (status != -ENOTCONN && status != -ENODEV)\n\t\t\tdev_err(&port_dev->dev,\n\t\t\t\t\t\"unable to enumerate USB device\\n\");\n\t}\n\ndone:\n\thub_port_disable(hub, port1, 1);\n\tif (hcd->driver->relinquish_port && !hub->hdev->parent) {\n\t\tif (status != -ENOTCONN && status != -ENODEV)\n\t\t\thcd->driver->relinquish_port(hcd, port1);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -105,7 +105,7 @@\n \t\t}\n \n \t\t/* reset (non-USB 3.0 devices) and get descriptor */\n-\t\tstatus = hub_port_init(hub, udev, port1, i);\n+\t\tstatus = hub_port_init(hub, udev, port1, i, NULL);\n \t\tif (status < 0)\n \t\t\tgoto loop;\n ",
        "function_modified_lines": {
            "added": [
                "\t\tstatus = hub_port_init(hub, udev, port1, i, NULL);"
            ],
            "deleted": [
                "\t\tstatus = hub_port_init(hub, udev, port1, i);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the USB subsystem in the Linux kernel through 6.4.2. There is an out-of-bounds and crash in read_descriptors in drivers/usb/core/sysfs.c.",
        "id": 4133
    },
    {
        "cve_id": "CVE-2020-8835",
        "code_before_change": "static void reg_set_min_max(struct bpf_reg_state *true_reg,\n\t\t\t    struct bpf_reg_state *false_reg, u64 val,\n\t\t\t    u8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\t/* If the dst_reg is a pointer, we can't learn anything about its\n\t * variable offset from the compare (unless src_reg were a pointer into\n\t * the same object, but we don't bother with that.\n\t * Since false_reg and true_reg have the same type by construction, we\n\t * only need to check one of them for pointerness.\n\t */\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\t/* For BPF_JEQ, if this is false we know nothing Jon Snow, but\n\t\t * if it is true we know the value for sure. Likewise for\n\t\t * BPF_JNE.\n\t\t */\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JGT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JGT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSGT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSGT ? sval + 1 : sval;\n\n\t\t/* If the full s64 was not sign-extended from s32 then don't\n\t\t * deduct further info.\n\t\t */\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JLT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JLT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSLT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSLT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\tif (is_jmp32) {\n\t\t__reg_bound_offset32(false_reg);\n\t\t__reg_bound_offset32(true_reg);\n\t}\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "code_after_change": "static void reg_set_min_max(struct bpf_reg_state *true_reg,\n\t\t\t    struct bpf_reg_state *false_reg, u64 val,\n\t\t\t    u8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\t/* If the dst_reg is a pointer, we can't learn anything about its\n\t * variable offset from the compare (unless src_reg were a pointer into\n\t * the same object, but we don't bother with that.\n\t * Since false_reg and true_reg have the same type by construction, we\n\t * only need to check one of them for pointerness.\n\t */\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\t/* For BPF_JEQ, if this is false we know nothing Jon Snow, but\n\t\t * if it is true we know the value for sure. Likewise for\n\t\t * BPF_JNE.\n\t\t */\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JGT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JGT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSGT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSGT ? sval + 1 : sval;\n\n\t\t/* If the full s64 was not sign-extended from s32 then don't\n\t\t * deduct further info.\n\t\t */\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JLT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JLT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSLT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSLT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "patch": "--- code before\n+++ code after\n@@ -109,10 +109,6 @@\n \t/* We might have learned some bits from the bounds. */\n \t__reg_bound_offset(false_reg);\n \t__reg_bound_offset(true_reg);\n-\tif (is_jmp32) {\n-\t\t__reg_bound_offset32(false_reg);\n-\t\t__reg_bound_offset32(true_reg);\n-\t}\n \t/* Intersecting with the old var_off might have improved our bounds\n \t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n \t * then new var_off is (0; 0x7f...fc) which improves our umax.",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (is_jmp32) {",
                "\t\t__reg_bound_offset32(false_reg);",
                "\t\t__reg_bound_offset32(true_reg);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.5.0 and newer, the bpf verifier (kernel/bpf/verifier.c) did not properly restrict the register bounds for 32-bit operations, leading to out-of-bounds reads and writes in kernel memory. The vulnerability also affects the Linux 5.4 stable series, starting with v5.4.7, as the introducing commit was backported to that branch. This vulnerability was fixed in 5.6.1, 5.5.14, and 5.4.29. (issue is aka ZDI-CAN-10780)",
        "id": 2809
    },
    {
        "cve_id": "CVE-2017-7558",
        "code_before_change": "static int inet_diag_msg_sctpaddrs_fill(struct sk_buff *skb,\n\t\t\t\t\tstruct sctp_association *asoc)\n{\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tstruct sctp_transport *from;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tattr = nla_reserve(skb, INET_DIAG_PEERS,\n\t\t\t   addrlen * asoc->peer.transport_count);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry(from, &asoc->peer.transport_addr_list,\n\t\t\t    transports) {\n\t\tmemcpy(info, &from->ipaddr, addrlen);\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int inet_diag_msg_sctpaddrs_fill(struct sk_buff *skb,\n\t\t\t\t\tstruct sctp_association *asoc)\n{\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tstruct sctp_transport *from;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tattr = nla_reserve(skb, INET_DIAG_PEERS,\n\t\t\t   addrlen * asoc->peer.transport_count);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry(from, &asoc->peer.transport_addr_list,\n\t\t\t    transports) {\n\t\tmemcpy(info, &from->ipaddr, sizeof(from->ipaddr));\n\t\tmemset(info + sizeof(from->ipaddr), 0,\n\t\t       addrlen - sizeof(from->ipaddr));\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,9 @@\n \tinfo = nla_data(attr);\n \tlist_for_each_entry(from, &asoc->peer.transport_addr_list,\n \t\t\t    transports) {\n-\t\tmemcpy(info, &from->ipaddr, addrlen);\n+\t\tmemcpy(info, &from->ipaddr, sizeof(from->ipaddr));\n+\t\tmemset(info + sizeof(from->ipaddr), 0,\n+\t\t       addrlen - sizeof(from->ipaddr));\n \t\tinfo += addrlen;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tmemcpy(info, &from->ipaddr, sizeof(from->ipaddr));",
                "\t\tmemset(info + sizeof(from->ipaddr), 0,",
                "\t\t       addrlen - sizeof(from->ipaddr));"
            ],
            "deleted": [
                "\t\tmemcpy(info, &from->ipaddr, addrlen);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A kernel data leak due to an out-of-bound read was found in the Linux kernel in inet_diag_msg_sctp{,l}addr_fill() and sctp_get_sctp_info() functions present since version 4.7-rc1 through version 4.13. A data leak happens when these functions fill in sockaddr data structures used to export socket's diagnostic information. As a result, up to 100 bytes of the slab data could be leaked to a userspace.",
        "id": 1516
    },
    {
        "cve_id": "CVE-2018-14610",
        "code_before_change": "static int find_first_block_group(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_path *path,\n\t\t\t\t  struct btrfs_key *key)\n{\n\tstruct btrfs_root *root = fs_info->extent_root;\n\tint ret = 0;\n\tstruct btrfs_key found_key;\n\tstruct extent_buffer *leaf;\n\tint slot;\n\n\tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret == 0)\n\t\t\t\tcontinue;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.objectid >= key->objectid &&\n\t\t    found_key.type == BTRFS_BLOCK_GROUP_ITEM_KEY) {\n\t\t\tstruct extent_map_tree *em_tree;\n\t\t\tstruct extent_map *em;\n\n\t\t\tem_tree = &root->fs_info->mapping_tree.map_tree;\n\t\t\tread_lock(&em_tree->lock);\n\t\t\tem = lookup_extent_mapping(em_tree, found_key.objectid,\n\t\t\t\t\t\t   found_key.offset);\n\t\t\tread_unlock(&em_tree->lock);\n\t\t\tif (!em) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\"logical %llu len %llu found bg but no related chunk\",\n\t\t\t\t\t  found_key.objectid, found_key.offset);\n\t\t\t\tret = -ENOENT;\n\t\t\t} else {\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t\tfree_extent_map(em);\n\t\t\tgoto out;\n\t\t}\n\t\tpath->slots[0]++;\n\t}\nout:\n\treturn ret;\n}",
        "code_after_change": "static int find_first_block_group(struct btrfs_fs_info *fs_info,\n\t\t\t\t  struct btrfs_path *path,\n\t\t\t\t  struct btrfs_key *key)\n{\n\tstruct btrfs_root *root = fs_info->extent_root;\n\tint ret = 0;\n\tstruct btrfs_key found_key;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_block_group_item bg;\n\tu64 flags;\n\tint slot;\n\n\tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\n\twhile (1) {\n\t\tslot = path->slots[0];\n\t\tleaf = path->nodes[0];\n\t\tif (slot >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret == 0)\n\t\t\t\tcontinue;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\t}\n\t\tbtrfs_item_key_to_cpu(leaf, &found_key, slot);\n\n\t\tif (found_key.objectid >= key->objectid &&\n\t\t    found_key.type == BTRFS_BLOCK_GROUP_ITEM_KEY) {\n\t\t\tstruct extent_map_tree *em_tree;\n\t\t\tstruct extent_map *em;\n\n\t\t\tem_tree = &root->fs_info->mapping_tree.map_tree;\n\t\t\tread_lock(&em_tree->lock);\n\t\t\tem = lookup_extent_mapping(em_tree, found_key.objectid,\n\t\t\t\t\t\t   found_key.offset);\n\t\t\tread_unlock(&em_tree->lock);\n\t\t\tif (!em) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\"logical %llu len %llu found bg but no related chunk\",\n\t\t\t\t\t  found_key.objectid, found_key.offset);\n\t\t\t\tret = -ENOENT;\n\t\t\t} else if (em->start != found_key.objectid ||\n\t\t\t\t   em->len != found_key.offset) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",\n\t\t\t\t\t  found_key.objectid, found_key.offset,\n\t\t\t\t\t  em->start, em->len);\n\t\t\t\tret = -EUCLEAN;\n\t\t\t} else {\n\t\t\t\tread_extent_buffer(leaf, &bg,\n\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),\n\t\t\t\t\tsizeof(bg));\n\t\t\t\tflags = btrfs_block_group_flags(&bg) &\n\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;\n\n\t\t\t\tif (flags != (em->map_lookup->type &\n\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {\n\t\t\t\t\tbtrfs_err(fs_info,\n\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",\n\t\t\t\t\t\tfound_key.objectid,\n\t\t\t\t\t\tfound_key.offset, flags,\n\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &\n\t\t\t\t\t\t em->map_lookup->type));\n\t\t\t\t\tret = -EUCLEAN;\n\t\t\t\t} else {\n\t\t\t\t\tret = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfree_extent_map(em);\n\t\t\tgoto out;\n\t\t}\n\t\tpath->slots[0]++;\n\t}\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,8 @@\n \tint ret = 0;\n \tstruct btrfs_key found_key;\n \tstruct extent_buffer *leaf;\n+\tstruct btrfs_block_group_item bg;\n+\tu64 flags;\n \tint slot;\n \n \tret = btrfs_search_slot(NULL, root, key, path, 0, 0);\n@@ -40,8 +42,32 @@\n \t\t\t\"logical %llu len %llu found bg but no related chunk\",\n \t\t\t\t\t  found_key.objectid, found_key.offset);\n \t\t\t\tret = -ENOENT;\n+\t\t\t} else if (em->start != found_key.objectid ||\n+\t\t\t\t   em->len != found_key.offset) {\n+\t\t\t\tbtrfs_err(fs_info,\n+\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",\n+\t\t\t\t\t  found_key.objectid, found_key.offset,\n+\t\t\t\t\t  em->start, em->len);\n+\t\t\t\tret = -EUCLEAN;\n \t\t\t} else {\n-\t\t\t\tret = 0;\n+\t\t\t\tread_extent_buffer(leaf, &bg,\n+\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),\n+\t\t\t\t\tsizeof(bg));\n+\t\t\t\tflags = btrfs_block_group_flags(&bg) &\n+\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;\n+\n+\t\t\t\tif (flags != (em->map_lookup->type &\n+\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {\n+\t\t\t\t\tbtrfs_err(fs_info,\n+\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",\n+\t\t\t\t\t\tfound_key.objectid,\n+\t\t\t\t\t\tfound_key.offset, flags,\n+\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &\n+\t\t\t\t\t\t em->map_lookup->type));\n+\t\t\t\t\tret = -EUCLEAN;\n+\t\t\t\t} else {\n+\t\t\t\t\tret = 0;\n+\t\t\t\t}\n \t\t\t}\n \t\t\tfree_extent_map(em);\n \t\t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "\tstruct btrfs_block_group_item bg;",
                "\tu64 flags;",
                "\t\t\t} else if (em->start != found_key.objectid ||",
                "\t\t\t\t   em->len != found_key.offset) {",
                "\t\t\t\tbtrfs_err(fs_info,",
                "\t\t\"block group %llu len %llu mismatch with chunk %llu len %llu\",",
                "\t\t\t\t\t  found_key.objectid, found_key.offset,",
                "\t\t\t\t\t  em->start, em->len);",
                "\t\t\t\tret = -EUCLEAN;",
                "\t\t\t\tread_extent_buffer(leaf, &bg,",
                "\t\t\t\t\tbtrfs_item_ptr_offset(leaf, slot),",
                "\t\t\t\t\tsizeof(bg));",
                "\t\t\t\tflags = btrfs_block_group_flags(&bg) &",
                "\t\t\t\t\tBTRFS_BLOCK_GROUP_TYPE_MASK;",
                "",
                "\t\t\t\tif (flags != (em->map_lookup->type &",
                "\t\t\t\t\t      BTRFS_BLOCK_GROUP_TYPE_MASK)) {",
                "\t\t\t\t\tbtrfs_err(fs_info,",
                "\"block group %llu len %llu type flags 0x%llx mismatch with chunk type flags 0x%llx\",",
                "\t\t\t\t\t\tfound_key.objectid,",
                "\t\t\t\t\t\tfound_key.offset, flags,",
                "\t\t\t\t\t\t(BTRFS_BLOCK_GROUP_TYPE_MASK &",
                "\t\t\t\t\t\t em->map_lookup->type));",
                "\t\t\t\t\tret = -EUCLEAN;",
                "\t\t\t\t} else {",
                "\t\t\t\t\tret = 0;",
                "\t\t\t\t}"
            ],
            "deleted": [
                "\t\t\t\tret = 0;"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is out-of-bounds access in write_extent_buffer() when mounting and operating a crafted btrfs image, because of a lack of verification that each block group has a corresponding chunk at mount time, within btrfs_read_block_groups in fs/btrfs/extent-tree.c.",
        "id": 1679
    },
    {
        "cve_id": "CVE-2017-16645",
        "code_before_change": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen > 0) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\t\t\treturn union_desc;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;\n}",
        "code_after_change": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen >= sizeof(*union_desc)) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bLength > buflen) {\n\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\n\t\t\tif (union_desc->bLength >= sizeof(*union_desc))\n\t\t\t\treturn union_desc;\n\n\t\t\tdev_err(&intf->dev,\n\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",\n\t\t\t\tunion_desc->bLength, sizeof(*union_desc));\n\t\t\treturn NULL;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,13 +15,25 @@\n \t\treturn NULL;\n \t}\n \n-\twhile (buflen > 0) {\n+\twhile (buflen >= sizeof(*union_desc)) {\n \t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n+\n+\t\tif (union_desc->bLength > buflen) {\n+\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");\n+\t\t\treturn NULL;\n+\t\t}\n \n \t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n \t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n \t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n-\t\t\treturn union_desc;\n+\n+\t\t\tif (union_desc->bLength >= sizeof(*union_desc))\n+\t\t\t\treturn union_desc;\n+\n+\t\t\tdev_err(&intf->dev,\n+\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",\n+\t\t\t\tunion_desc->bLength, sizeof(*union_desc));\n+\t\t\treturn NULL;\n \t\t}\n \n \t\tbuflen -= union_desc->bLength;",
        "function_modified_lines": {
            "added": [
                "\twhile (buflen >= sizeof(*union_desc)) {",
                "",
                "\t\tif (union_desc->bLength > buflen) {",
                "\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");",
                "\t\t\treturn NULL;",
                "\t\t}",
                "",
                "\t\t\tif (union_desc->bLength >= sizeof(*union_desc))",
                "\t\t\t\treturn union_desc;",
                "",
                "\t\t\tdev_err(&intf->dev,",
                "\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",",
                "\t\t\t\tunion_desc->bLength, sizeof(*union_desc));",
                "\t\t\treturn NULL;"
            ],
            "deleted": [
                "\twhile (buflen > 0) {",
                "\t\t\treturn union_desc;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ims_pcu_get_cdc_union_desc function in drivers/input/misc/ims-pcu.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (ims_pcu_parse_cdc_data out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1327
    },
    {
        "cve_id": "CVE-2022-2785",
        "code_before_change": "\nBPF_CALL_3(bpf_sys_bpf, int, cmd, union bpf_attr *, attr, u32, attr_size)\n{\n\tstruct bpf_prog * __maybe_unused prog;\n\tstruct bpf_tramp_run_ctx __maybe_unused run_ctx;\n\n\tswitch (cmd) {\n\tcase BPF_MAP_CREATE:\n\tcase BPF_MAP_UPDATE_ELEM:\n\tcase BPF_MAP_FREEZE:\n\tcase BPF_PROG_LOAD:\n\tcase BPF_BTF_LOAD:\n\tcase BPF_LINK_CREATE:\n\tcase BPF_RAW_TRACEPOINT_OPEN:\n\t\tbreak;\n#ifdef CONFIG_BPF_JIT /* __bpf_prog_enter_sleepable used by trampoline and JIT */\n\tcase BPF_PROG_TEST_RUN:\n\t\tif (attr->test.data_in || attr->test.data_out ||\n\t\t    attr->test.ctx_out || attr->test.duration ||\n\t\t    attr->test.repeat || attr->test.flags)\n\t\t\treturn -EINVAL;\n\n\t\tprog = bpf_prog_get_type(attr->test.prog_fd, BPF_PROG_TYPE_SYSCALL);\n\t\tif (IS_ERR(prog))\n\t\t\treturn PTR_ERR(prog);\n\n\t\tif (attr->test.ctx_size_in < prog->aux->max_ctx_offset ||\n\t\t    attr->test.ctx_size_in > U16_MAX) {\n\t\t\tbpf_prog_put(prog);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\trun_ctx.bpf_cookie = 0;\n\t\trun_ctx.saved_run_ctx = NULL;\n\t\tif (!__bpf_prog_enter_sleepable(prog, &run_ctx)) {\n\t\t\t/* recursion detected */\n\t\t\tbpf_prog_put(prog);\n\t\t\treturn -EBUSY;\n\t\t}\n\t\tattr->test.retval = bpf_prog_run(prog, (void *) (long) attr->test.ctx_in);\n\t\t__bpf_prog_exit_sleepable(prog, 0 /* bpf_prog_run does runtime stats */, &run_ctx);\n\t\tbpf_prog_put(prog);\n\t\treturn 0;\n#endif\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn __sys_bpf(cmd, KERNEL_BPFPTR(attr), attr_size);\n}",
        "code_after_change": "\nBPF_CALL_3(bpf_sys_bpf, int, cmd, union bpf_attr *, attr, u32, attr_size)\n{\n\tswitch (cmd) {\n\tcase BPF_MAP_CREATE:\n\tcase BPF_MAP_UPDATE_ELEM:\n\tcase BPF_MAP_FREEZE:\n\tcase BPF_PROG_LOAD:\n\tcase BPF_BTF_LOAD:\n\tcase BPF_LINK_CREATE:\n\tcase BPF_RAW_TRACEPOINT_OPEN:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn __sys_bpf(cmd, KERNEL_BPFPTR(attr), attr_size);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,6 @@\n \n BPF_CALL_3(bpf_sys_bpf, int, cmd, union bpf_attr *, attr, u32, attr_size)\n {\n-\tstruct bpf_prog * __maybe_unused prog;\n-\tstruct bpf_tramp_run_ctx __maybe_unused run_ctx;\n-\n \tswitch (cmd) {\n \tcase BPF_MAP_CREATE:\n \tcase BPF_MAP_UPDATE_ELEM:\n@@ -13,35 +10,6 @@\n \tcase BPF_LINK_CREATE:\n \tcase BPF_RAW_TRACEPOINT_OPEN:\n \t\tbreak;\n-#ifdef CONFIG_BPF_JIT /* __bpf_prog_enter_sleepable used by trampoline and JIT */\n-\tcase BPF_PROG_TEST_RUN:\n-\t\tif (attr->test.data_in || attr->test.data_out ||\n-\t\t    attr->test.ctx_out || attr->test.duration ||\n-\t\t    attr->test.repeat || attr->test.flags)\n-\t\t\treturn -EINVAL;\n-\n-\t\tprog = bpf_prog_get_type(attr->test.prog_fd, BPF_PROG_TYPE_SYSCALL);\n-\t\tif (IS_ERR(prog))\n-\t\t\treturn PTR_ERR(prog);\n-\n-\t\tif (attr->test.ctx_size_in < prog->aux->max_ctx_offset ||\n-\t\t    attr->test.ctx_size_in > U16_MAX) {\n-\t\t\tbpf_prog_put(prog);\n-\t\t\treturn -EINVAL;\n-\t\t}\n-\n-\t\trun_ctx.bpf_cookie = 0;\n-\t\trun_ctx.saved_run_ctx = NULL;\n-\t\tif (!__bpf_prog_enter_sleepable(prog, &run_ctx)) {\n-\t\t\t/* recursion detected */\n-\t\t\tbpf_prog_put(prog);\n-\t\t\treturn -EBUSY;\n-\t\t}\n-\t\tattr->test.retval = bpf_prog_run(prog, (void *) (long) attr->test.ctx_in);\n-\t\t__bpf_prog_exit_sleepable(prog, 0 /* bpf_prog_run does runtime stats */, &run_ctx);\n-\t\tbpf_prog_put(prog);\n-\t\treturn 0;\n-#endif\n \tdefault:\n \t\treturn -EINVAL;\n \t}",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tstruct bpf_prog * __maybe_unused prog;",
                "\tstruct bpf_tramp_run_ctx __maybe_unused run_ctx;",
                "",
                "#ifdef CONFIG_BPF_JIT /* __bpf_prog_enter_sleepable used by trampoline and JIT */",
                "\tcase BPF_PROG_TEST_RUN:",
                "\t\tif (attr->test.data_in || attr->test.data_out ||",
                "\t\t    attr->test.ctx_out || attr->test.duration ||",
                "\t\t    attr->test.repeat || attr->test.flags)",
                "\t\t\treturn -EINVAL;",
                "",
                "\t\tprog = bpf_prog_get_type(attr->test.prog_fd, BPF_PROG_TYPE_SYSCALL);",
                "\t\tif (IS_ERR(prog))",
                "\t\t\treturn PTR_ERR(prog);",
                "",
                "\t\tif (attr->test.ctx_size_in < prog->aux->max_ctx_offset ||",
                "\t\t    attr->test.ctx_size_in > U16_MAX) {",
                "\t\t\tbpf_prog_put(prog);",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                "",
                "\t\trun_ctx.bpf_cookie = 0;",
                "\t\trun_ctx.saved_run_ctx = NULL;",
                "\t\tif (!__bpf_prog_enter_sleepable(prog, &run_ctx)) {",
                "\t\t\t/* recursion detected */",
                "\t\t\tbpf_prog_put(prog);",
                "\t\t\treturn -EBUSY;",
                "\t\t}",
                "\t\tattr->test.retval = bpf_prog_run(prog, (void *) (long) attr->test.ctx_in);",
                "\t\t__bpf_prog_exit_sleepable(prog, 0 /* bpf_prog_run does runtime stats */, &run_ctx);",
                "\t\tbpf_prog_put(prog);",
                "\t\treturn 0;",
                "#endif"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "There exists an arbitrary memory read within the Linux Kernel BPF - Constants provided to fill pointers in structs passed in to bpf_sys_bpf are not verified and can point anywhere, including memory not owned by BPF. An attacker with CAP_BPF can arbitrarily read memory from anywhere on the system. We recommend upgrading past commit 86f44fcec22c",
        "id": 3496
    },
    {
        "cve_id": "CVE-2023-6610",
        "code_before_change": "int\nsmb2_check_message(char *buf, unsigned int len, struct TCP_Server_Info *server)\n{\n\tstruct TCP_Server_Info *pserver;\n\tstruct smb2_hdr *shdr = (struct smb2_hdr *)buf;\n\tstruct smb2_pdu *pdu = (struct smb2_pdu *)shdr;\n\tint hdr_size = sizeof(struct smb2_hdr);\n\tint pdu_size = sizeof(struct smb2_pdu);\n\tint command;\n\t__u32 calc_len; /* calculated length */\n\t__u64 mid;\n\n\t/* If server is a channel, select the primary channel */\n\tpserver = SERVER_IS_CHAN(server) ? server->primary_server : server;\n\n\t/*\n\t * Add function to do table lookup of StructureSize by command\n\t * ie Validate the wct via smb2_struct_sizes table above\n\t */\n\tif (shdr->ProtocolId == SMB2_TRANSFORM_PROTO_NUM) {\n\t\tstruct smb2_transform_hdr *thdr =\n\t\t\t(struct smb2_transform_hdr *)buf;\n\t\tstruct cifs_ses *ses = NULL;\n\t\tstruct cifs_ses *iter;\n\n\t\t/* decrypt frame now that it is completely read in */\n\t\tspin_lock(&cifs_tcp_ses_lock);\n\t\tlist_for_each_entry(iter, &pserver->smb_ses_list, smb_ses_list) {\n\t\t\tif (iter->Suid == le64_to_cpu(thdr->SessionId)) {\n\t\t\t\tses = iter;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&cifs_tcp_ses_lock);\n\t\tif (!ses) {\n\t\t\tcifs_dbg(VFS, \"no decryption - session id not found\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tmid = le64_to_cpu(shdr->MessageId);\n\tif (len < pdu_size) {\n\t\tif ((len >= hdr_size)\n\t\t    && (shdr->Status != 0)) {\n\t\t\tpdu->StructureSize2 = 0;\n\t\t\t/*\n\t\t\t * As with SMB/CIFS, on some error cases servers may\n\t\t\t * not return wct properly\n\t\t\t */\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than SMB header size\\n\");\n\t\t}\n\t\treturn 1;\n\t}\n\tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n\t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n\t\t\t mid);\n\t\treturn 1;\n\t}\n\n\tif (check_smb2_hdr(shdr, mid))\n\t\treturn 1;\n\n\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n\t\t\t le16_to_cpu(shdr->StructureSize));\n\t\treturn 1;\n\t}\n\n\tcommand = le16_to_cpu(shdr->Command);\n\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n\t\treturn 1;\n\t}\n\n\tif (smb2_rsp_struct_sizes[command] != pdu->StructureSize2) {\n\t\tif (command != SMB2_OPLOCK_BREAK_HE && (shdr->Status == 0 ||\n\t\t    pdu->StructureSize2 != SMB2_ERROR_STRUCTURE_SIZE2_LE)) {\n\t\t\t/* error packets have 9 byte structure size */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %u for command %d\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2), command);\n\t\t\treturn 1;\n\t\t} else if (command == SMB2_OPLOCK_BREAK_HE\n\t\t\t   && (shdr->Status == 0)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 44)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 36)) {\n\t\t\t/* special case for SMB2.1 lease break message */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %d for oplock break\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2));\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tcalc_len = smb2_calc_size(buf);\n\n\t/* For SMB2_IOCTL, OutputOffset and OutputLength are optional, so might\n\t * be 0, and not a real miscalculation */\n\tif (command == SMB2_IOCTL_HE && calc_len == 0)\n\t\treturn 0;\n\n\tif (command == SMB2_NEGOTIATE_HE)\n\t\tcalc_len += get_neg_ctxt_len(shdr, len, calc_len);\n\n\tif (len != calc_len) {\n\t\t/* create failed on symlink */\n\t\tif (command == SMB2_CREATE_HE &&\n\t\t    shdr->Status == STATUS_STOPPED_ON_SYMLINK)\n\t\t\treturn 0;\n\t\t/* Windows 7 server returns 24 bytes more */\n\t\tif (calc_len + 24 == len && command == SMB2_OPLOCK_BREAK_HE)\n\t\t\treturn 0;\n\t\t/* server can return one byte more due to implied bcc[0] */\n\t\tif (calc_len == len + 1)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Some windows servers (win2016) will pad also the final\n\t\t * PDU in a compound to 8 bytes.\n\t\t */\n\t\tif (ALIGN(calc_len, 8) == len)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * MacOS server pads after SMB2.1 write response with 3 bytes\n\t\t * of junk. Other servers match RFC1001 len to actual\n\t\t * SMB2/SMB3 frame length (header + smb2 response specific data)\n\t\t * Some windows servers also pad up to 8 bytes when compounding.\n\t\t */\n\t\tif (calc_len < len)\n\t\t\treturn 0;\n\n\t\t/* Only log a message if len was really miscalculated */\n\t\tif (unlikely(cifsFYI))\n\t\t\tcifs_dbg(FYI, \"Server response too short: calculated \"\n\t\t\t\t \"length %u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\t calc_len, len, command, mid);\n\t\telse\n\t\t\tpr_warn(\"Server response too short: calculated length \"\n\t\t\t\t\"%u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\tcalc_len, len, command, mid);\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "code_after_change": "int\nsmb2_check_message(char *buf, unsigned int len, struct TCP_Server_Info *server)\n{\n\tstruct TCP_Server_Info *pserver;\n\tstruct smb2_hdr *shdr = (struct smb2_hdr *)buf;\n\tstruct smb2_pdu *pdu = (struct smb2_pdu *)shdr;\n\tint hdr_size = sizeof(struct smb2_hdr);\n\tint pdu_size = sizeof(struct smb2_pdu);\n\tint command;\n\t__u32 calc_len; /* calculated length */\n\t__u64 mid;\n\n\t/* If server is a channel, select the primary channel */\n\tpserver = SERVER_IS_CHAN(server) ? server->primary_server : server;\n\n\t/*\n\t * Add function to do table lookup of StructureSize by command\n\t * ie Validate the wct via smb2_struct_sizes table above\n\t */\n\tif (shdr->ProtocolId == SMB2_TRANSFORM_PROTO_NUM) {\n\t\tstruct smb2_transform_hdr *thdr =\n\t\t\t(struct smb2_transform_hdr *)buf;\n\t\tstruct cifs_ses *ses = NULL;\n\t\tstruct cifs_ses *iter;\n\n\t\t/* decrypt frame now that it is completely read in */\n\t\tspin_lock(&cifs_tcp_ses_lock);\n\t\tlist_for_each_entry(iter, &pserver->smb_ses_list, smb_ses_list) {\n\t\t\tif (iter->Suid == le64_to_cpu(thdr->SessionId)) {\n\t\t\t\tses = iter;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&cifs_tcp_ses_lock);\n\t\tif (!ses) {\n\t\t\tcifs_dbg(VFS, \"no decryption - session id not found\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tmid = le64_to_cpu(shdr->MessageId);\n\tif (check_smb2_hdr(shdr, mid))\n\t\treturn 1;\n\n\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n\t\t\t le16_to_cpu(shdr->StructureSize));\n\t\treturn 1;\n\t}\n\n\tcommand = le16_to_cpu(shdr->Command);\n\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n\t\treturn 1;\n\t}\n\n\tif (len < pdu_size) {\n\t\tif ((len >= hdr_size)\n\t\t    && (shdr->Status != 0)) {\n\t\t\tpdu->StructureSize2 = 0;\n\t\t\t/*\n\t\t\t * As with SMB/CIFS, on some error cases servers may\n\t\t\t * not return wct properly\n\t\t\t */\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than SMB header size\\n\");\n\t\t}\n\t\treturn 1;\n\t}\n\tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n\t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n\t\t\t mid);\n\t\treturn 1;\n\t}\n\n\tif (smb2_rsp_struct_sizes[command] != pdu->StructureSize2) {\n\t\tif (command != SMB2_OPLOCK_BREAK_HE && (shdr->Status == 0 ||\n\t\t    pdu->StructureSize2 != SMB2_ERROR_STRUCTURE_SIZE2_LE)) {\n\t\t\t/* error packets have 9 byte structure size */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %u for command %d\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2), command);\n\t\t\treturn 1;\n\t\t} else if (command == SMB2_OPLOCK_BREAK_HE\n\t\t\t   && (shdr->Status == 0)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 44)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 36)) {\n\t\t\t/* special case for SMB2.1 lease break message */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %d for oplock break\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2));\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tcalc_len = smb2_calc_size(buf);\n\n\t/* For SMB2_IOCTL, OutputOffset and OutputLength are optional, so might\n\t * be 0, and not a real miscalculation */\n\tif (command == SMB2_IOCTL_HE && calc_len == 0)\n\t\treturn 0;\n\n\tif (command == SMB2_NEGOTIATE_HE)\n\t\tcalc_len += get_neg_ctxt_len(shdr, len, calc_len);\n\n\tif (len != calc_len) {\n\t\t/* create failed on symlink */\n\t\tif (command == SMB2_CREATE_HE &&\n\t\t    shdr->Status == STATUS_STOPPED_ON_SYMLINK)\n\t\t\treturn 0;\n\t\t/* Windows 7 server returns 24 bytes more */\n\t\tif (calc_len + 24 == len && command == SMB2_OPLOCK_BREAK_HE)\n\t\t\treturn 0;\n\t\t/* server can return one byte more due to implied bcc[0] */\n\t\tif (calc_len == len + 1)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Some windows servers (win2016) will pad also the final\n\t\t * PDU in a compound to 8 bytes.\n\t\t */\n\t\tif (ALIGN(calc_len, 8) == len)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * MacOS server pads after SMB2.1 write response with 3 bytes\n\t\t * of junk. Other servers match RFC1001 len to actual\n\t\t * SMB2/SMB3 frame length (header + smb2 response specific data)\n\t\t * Some windows servers also pad up to 8 bytes when compounding.\n\t\t */\n\t\tif (calc_len < len)\n\t\t\treturn 0;\n\n\t\t/* Only log a message if len was really miscalculated */\n\t\tif (unlikely(cifsFYI))\n\t\t\tcifs_dbg(FYI, \"Server response too short: calculated \"\n\t\t\t\t \"length %u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\t calc_len, len, command, mid);\n\t\telse\n\t\t\tpr_warn(\"Server response too short: calculated length \"\n\t\t\t\t\"%u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\tcalc_len, len, command, mid);\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,6 +39,21 @@\n \t}\n \n \tmid = le64_to_cpu(shdr->MessageId);\n+\tif (check_smb2_hdr(shdr, mid))\n+\t\treturn 1;\n+\n+\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n+\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n+\t\t\t le16_to_cpu(shdr->StructureSize));\n+\t\treturn 1;\n+\t}\n+\n+\tcommand = le16_to_cpu(shdr->Command);\n+\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n+\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n+\t\treturn 1;\n+\t}\n+\n \tif (len < pdu_size) {\n \t\tif ((len >= hdr_size)\n \t\t    && (shdr->Status != 0)) {\n@@ -56,21 +71,6 @@\n \tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n \t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n \t\t\t mid);\n-\t\treturn 1;\n-\t}\n-\n-\tif (check_smb2_hdr(shdr, mid))\n-\t\treturn 1;\n-\n-\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n-\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n-\t\t\t le16_to_cpu(shdr->StructureSize));\n-\t\treturn 1;\n-\t}\n-\n-\tcommand = le16_to_cpu(shdr->Command);\n-\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n-\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n \t\treturn 1;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tif (check_smb2_hdr(shdr, mid))",
                "\t\treturn 1;",
                "",
                "\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {",
                "\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",",
                "\t\t\t le16_to_cpu(shdr->StructureSize));",
                "\t\treturn 1;",
                "\t}",
                "",
                "\tcommand = le16_to_cpu(shdr->Command);",
                "\tif (command >= NUMBER_OF_SMB2_COMMANDS) {",
                "\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);",
                "\t\treturn 1;",
                "\t}",
                ""
            ],
            "deleted": [
                "\t\treturn 1;",
                "\t}",
                "",
                "\tif (check_smb2_hdr(shdr, mid))",
                "\t\treturn 1;",
                "",
                "\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {",
                "\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",",
                "\t\t\t le16_to_cpu(shdr->StructureSize));",
                "\t\treturn 1;",
                "\t}",
                "",
                "\tcommand = le16_to_cpu(shdr->Command);",
                "\tif (command >= NUMBER_OF_SMB2_COMMANDS) {",
                "\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in smb2_dump_detail in fs/smb/client/smb2ops.c in the Linux Kernel. This issue could allow a local attacker to crash the system or leak internal kernel information.",
        "id": 4305
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "void fnd_clear(struct ntfs_fnd *fnd)\n{\n\tint i;\n\n\tfor (i = 0; i < fnd->level; i++) {\n\t\tstruct indx_node *n = fnd->nodes[i];\n\n\t\tif (!n)\n\t\t\tcontinue;\n\n\t\tput_indx_node(n);\n\t\tfnd->nodes[i] = NULL;\n\t}\n\tfnd->level = 0;\n\tfnd->root_de = NULL;\n}",
        "code_after_change": "void fnd_clear(struct ntfs_fnd *fnd)\n{\n\tint i;\n\n\tfor (i = fnd->level - 1; i >= 0; i--) {\n\t\tstruct indx_node *n = fnd->nodes[i];\n\n\t\tif (!n)\n\t\t\tcontinue;\n\n\t\tput_indx_node(n);\n\t\tfnd->nodes[i] = NULL;\n\t}\n\tfnd->level = 0;\n\tfnd->root_de = NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n {\n \tint i;\n \n-\tfor (i = 0; i < fnd->level; i++) {\n+\tfor (i = fnd->level - 1; i >= 0; i--) {\n \t\tstruct indx_node *n = fnd->nodes[i];\n \n \t\tif (!n)",
        "function_modified_lines": {
            "added": [
                "\tfor (i = fnd->level - 1; i >= 0; i--) {"
            ],
            "deleted": [
                "\tfor (i = 0; i < fnd->level; i++) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3791
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_and(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umax_val = src_reg->u32_max_value;\n\n\t/* Assuming scalar64_min_max_and will be called so its safe\n\t * to skip updating register for known 32-bit case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get our minimum from the var_off, since that's inherently\n\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = min(dst_reg->u32_max_value, umax_val);\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ANDing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n\n}",
        "code_after_change": "static void scalar32_min_max_and(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\tu32 umax_val = src_reg->u32_max_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get our minimum from the var_off, since that's inherently\n\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = min(dst_reg->u32_max_value, umax_val);\n\tif (dst_reg->s32_min_value < 0 || smin_val < 0) {\n\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t * ain't nobody got time for that.\n\t\t */\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t} else {\n\t\t/* ANDing two positives gives a positive, so safe to\n\t\t * cast result into s64.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,11 +7,10 @@\n \ts32 smin_val = src_reg->s32_min_value;\n \tu32 umax_val = src_reg->u32_max_value;\n \n-\t/* Assuming scalar64_min_max_and will be called so its safe\n-\t * to skip updating register for known 32-bit case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get our minimum from the var_off, since that's inherently\n \t * bitwise.  Our maximum is the minimum of the operands' maxima.\n@@ -31,5 +30,4 @@\n \t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n \t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n \t}\n-\n }",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_and will be called so its safe",
                "\t * to skip updating register for known 32-bit case.",
                "\t */",
                "\tif (src_known && dst_known)",
                ""
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1).",
        "id": 3011
    },
    {
        "cve_id": "CVE-2023-37453",
        "code_before_change": "static int usb_reset_and_verify_device(struct usb_device *udev)\n{\n\tstruct usb_device\t\t*parent_hdev = udev->parent;\n\tstruct usb_hub\t\t\t*parent_hub;\n\tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;\n\tstruct usb_host_bos\t\t*bos;\n\tint\t\t\t\ti, j, ret = 0;\n\tint\t\t\t\tport1 = udev->portnum;\n\n\tif (udev->state == USB_STATE_NOTATTACHED ||\n\t\t\tudev->state == USB_STATE_SUSPENDED) {\n\t\tdev_dbg(&udev->dev, \"device reset not allowed in state %d\\n\",\n\t\t\t\tudev->state);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!parent_hdev)\n\t\treturn -EISDIR;\n\n\tparent_hub = usb_hub_to_struct_hub(parent_hdev);\n\n\t/* Disable USB2 hardware LPM.\n\t * It will be re-enabled by the enumeration process.\n\t */\n\tusb_disable_usb2_hardware_lpm(udev);\n\n\tbos = udev->bos;\n\tudev->bos = NULL;\n\n\tmutex_lock(hcd->address0_mutex);\n\n\tfor (i = 0; i < PORT_INIT_TRIES; ++i) {\n\t\tif (hub_port_stop_enumerate(parent_hub, port1, i)) {\n\t\t\tret = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ep0 maxpacket size may change; let the HCD know about it.\n\t\t * Other endpoints will be handled by re-enumeration. */\n\t\tusb_ep0_reinit(udev);\n\t\tret = hub_port_init(parent_hub, udev, port1, i);\n\t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(hcd->address0_mutex);\n\n\tif (ret < 0)\n\t\tgoto re_enumerate;\n\n\t/* Device might have changed firmware (DFU or similar) */\n\tif (descriptors_changed(udev, &descriptor, bos)) {\n\t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */\n\t\tgoto re_enumerate;\n\t}\n\n\t/* Restore the device's previous configuration */\n\tif (!udev->actconfig)\n\t\tgoto done;\n\n\tmutex_lock(hcd->bandwidth_mutex);\n\tret = usb_hcd_alloc_bandwidth(udev, udev->actconfig, NULL, NULL);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\t\"Busted HC?  Not enough HCD resources for \"\n\t\t\t\t\"old configuration.\\n\");\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tret = usb_control_msg(udev, usb_sndctrlpipe(udev, 0),\n\t\t\tUSB_REQ_SET_CONFIGURATION, 0,\n\t\t\tudev->actconfig->desc.bConfigurationValue, 0,\n\t\t\tNULL, 0, USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_err(&udev->dev,\n\t\t\t\"can't restore configuration #%d (error=%d)\\n\",\n\t\t\tudev->actconfig->desc.bConfigurationValue, ret);\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tmutex_unlock(hcd->bandwidth_mutex);\n\tusb_set_device_state(udev, USB_STATE_CONFIGURED);\n\n\t/* Put interfaces back into the same altsettings as before.\n\t * Don't bother to send the Set-Interface request for interfaces\n\t * that were already in altsetting 0; besides being unnecessary,\n\t * many devices can't handle it.  Instead just reset the host-side\n\t * endpoint state.\n\t */\n\tfor (i = 0; i < udev->actconfig->desc.bNumInterfaces; i++) {\n\t\tstruct usb_host_config *config = udev->actconfig;\n\t\tstruct usb_interface *intf = config->interface[i];\n\t\tstruct usb_interface_descriptor *desc;\n\n\t\tdesc = &intf->cur_altsetting->desc;\n\t\tif (desc->bAlternateSetting == 0) {\n\t\t\tusb_disable_interface(udev, intf, true);\n\t\t\tusb_enable_interface(udev, intf, true);\n\t\t\tret = 0;\n\t\t} else {\n\t\t\t/* Let the bandwidth allocation function know that this\n\t\t\t * device has been reset, and it will have to use\n\t\t\t * alternate setting 0 as the current alternate setting.\n\t\t\t */\n\t\t\tintf->resetting_device = 1;\n\t\t\tret = usb_set_interface(udev, desc->bInterfaceNumber,\n\t\t\t\t\tdesc->bAlternateSetting);\n\t\t\tintf->resetting_device = 0;\n\t\t}\n\t\tif (ret < 0) {\n\t\t\tdev_err(&udev->dev, \"failed to restore interface %d \"\n\t\t\t\t\"altsetting %d (error=%d)\\n\",\n\t\t\t\tdesc->bInterfaceNumber,\n\t\t\t\tdesc->bAlternateSetting,\n\t\t\t\tret);\n\t\t\tgoto re_enumerate;\n\t\t}\n\t\t/* Resetting also frees any allocated streams */\n\t\tfor (j = 0; j < intf->cur_altsetting->desc.bNumEndpoints; j++)\n\t\t\tintf->cur_altsetting->endpoint[j].streams = 0;\n\t}\n\ndone:\n\t/* Now that the alt settings are re-installed, enable LTM and LPM. */\n\tusb_enable_usb2_hardware_lpm(udev);\n\tusb_unlocked_enable_lpm(udev);\n\tusb_enable_ltm(udev);\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\treturn 0;\n\nre_enumerate:\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\thub_port_logical_disconnect(parent_hub, port1);\n\treturn -ENODEV;\n}",
        "code_after_change": "static int usb_reset_and_verify_device(struct usb_device *udev)\n{\n\tstruct usb_device\t\t*parent_hdev = udev->parent;\n\tstruct usb_hub\t\t\t*parent_hub;\n\tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n\tstruct usb_device_descriptor\tdescriptor;\n\tstruct usb_host_bos\t\t*bos;\n\tint\t\t\t\ti, j, ret = 0;\n\tint\t\t\t\tport1 = udev->portnum;\n\n\tif (udev->state == USB_STATE_NOTATTACHED ||\n\t\t\tudev->state == USB_STATE_SUSPENDED) {\n\t\tdev_dbg(&udev->dev, \"device reset not allowed in state %d\\n\",\n\t\t\t\tudev->state);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!parent_hdev)\n\t\treturn -EISDIR;\n\n\tparent_hub = usb_hub_to_struct_hub(parent_hdev);\n\n\t/* Disable USB2 hardware LPM.\n\t * It will be re-enabled by the enumeration process.\n\t */\n\tusb_disable_usb2_hardware_lpm(udev);\n\n\tbos = udev->bos;\n\tudev->bos = NULL;\n\n\tmutex_lock(hcd->address0_mutex);\n\n\tfor (i = 0; i < PORT_INIT_TRIES; ++i) {\n\t\tif (hub_port_stop_enumerate(parent_hub, port1, i)) {\n\t\t\tret = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ep0 maxpacket size may change; let the HCD know about it.\n\t\t * Other endpoints will be handled by re-enumeration. */\n\t\tusb_ep0_reinit(udev);\n\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);\n\t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(hcd->address0_mutex);\n\n\tif (ret < 0)\n\t\tgoto re_enumerate;\n\n\t/* Device might have changed firmware (DFU or similar) */\n\tif (descriptors_changed(udev, &descriptor, bos)) {\n\t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n\t\tgoto re_enumerate;\n\t}\n\n\t/* Restore the device's previous configuration */\n\tif (!udev->actconfig)\n\t\tgoto done;\n\n\tmutex_lock(hcd->bandwidth_mutex);\n\tret = usb_hcd_alloc_bandwidth(udev, udev->actconfig, NULL, NULL);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\t\"Busted HC?  Not enough HCD resources for \"\n\t\t\t\t\"old configuration.\\n\");\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tret = usb_control_msg(udev, usb_sndctrlpipe(udev, 0),\n\t\t\tUSB_REQ_SET_CONFIGURATION, 0,\n\t\t\tudev->actconfig->desc.bConfigurationValue, 0,\n\t\t\tNULL, 0, USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_err(&udev->dev,\n\t\t\t\"can't restore configuration #%d (error=%d)\\n\",\n\t\t\tudev->actconfig->desc.bConfigurationValue, ret);\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tmutex_unlock(hcd->bandwidth_mutex);\n\tusb_set_device_state(udev, USB_STATE_CONFIGURED);\n\n\t/* Put interfaces back into the same altsettings as before.\n\t * Don't bother to send the Set-Interface request for interfaces\n\t * that were already in altsetting 0; besides being unnecessary,\n\t * many devices can't handle it.  Instead just reset the host-side\n\t * endpoint state.\n\t */\n\tfor (i = 0; i < udev->actconfig->desc.bNumInterfaces; i++) {\n\t\tstruct usb_host_config *config = udev->actconfig;\n\t\tstruct usb_interface *intf = config->interface[i];\n\t\tstruct usb_interface_descriptor *desc;\n\n\t\tdesc = &intf->cur_altsetting->desc;\n\t\tif (desc->bAlternateSetting == 0) {\n\t\t\tusb_disable_interface(udev, intf, true);\n\t\t\tusb_enable_interface(udev, intf, true);\n\t\t\tret = 0;\n\t\t} else {\n\t\t\t/* Let the bandwidth allocation function know that this\n\t\t\t * device has been reset, and it will have to use\n\t\t\t * alternate setting 0 as the current alternate setting.\n\t\t\t */\n\t\t\tintf->resetting_device = 1;\n\t\t\tret = usb_set_interface(udev, desc->bInterfaceNumber,\n\t\t\t\t\tdesc->bAlternateSetting);\n\t\t\tintf->resetting_device = 0;\n\t\t}\n\t\tif (ret < 0) {\n\t\t\tdev_err(&udev->dev, \"failed to restore interface %d \"\n\t\t\t\t\"altsetting %d (error=%d)\\n\",\n\t\t\t\tdesc->bInterfaceNumber,\n\t\t\t\tdesc->bAlternateSetting,\n\t\t\t\tret);\n\t\t\tgoto re_enumerate;\n\t\t}\n\t\t/* Resetting also frees any allocated streams */\n\t\tfor (j = 0; j < intf->cur_altsetting->desc.bNumEndpoints; j++)\n\t\t\tintf->cur_altsetting->endpoint[j].streams = 0;\n\t}\n\ndone:\n\t/* Now that the alt settings are re-installed, enable LTM and LPM. */\n\tusb_enable_usb2_hardware_lpm(udev);\n\tusb_unlocked_enable_lpm(udev);\n\tusb_enable_ltm(udev);\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\treturn 0;\n\nre_enumerate:\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\thub_port_logical_disconnect(parent_hub, port1);\n\treturn -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct usb_device\t\t*parent_hdev = udev->parent;\n \tstruct usb_hub\t\t\t*parent_hub;\n \tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n-\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;\n+\tstruct usb_device_descriptor\tdescriptor;\n \tstruct usb_host_bos\t\t*bos;\n \tint\t\t\t\ti, j, ret = 0;\n \tint\t\t\t\tport1 = udev->portnum;\n@@ -39,7 +39,7 @@\n \t\t/* ep0 maxpacket size may change; let the HCD know about it.\n \t\t * Other endpoints will be handled by re-enumeration. */\n \t\tusb_ep0_reinit(udev);\n-\t\tret = hub_port_init(parent_hub, udev, port1, i);\n+\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);\n \t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n \t\t\tbreak;\n \t}\n@@ -51,7 +51,6 @@\n \t/* Device might have changed firmware (DFU or similar) */\n \tif (descriptors_changed(udev, &descriptor, bos)) {\n \t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n-\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */\n \t\tgoto re_enumerate;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_device_descriptor\tdescriptor;",
                "\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);"
            ],
            "deleted": [
                "\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;",
                "\t\tret = hub_port_init(parent_hub, udev, port1, i);",
                "\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the USB subsystem in the Linux kernel through 6.4.2. There is an out-of-bounds and crash in read_descriptors in drivers/usb/core/sysfs.c.",
        "id": 4132
    },
    {
        "cve_id": "CVE-2021-3753",
        "code_before_change": "static int vt_k_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\tunsigned long arg, bool perm)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tvoid __user *up = (void __user *)arg;\n\tunsigned int console = vc->vc_num;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is nave.\n\t\t */\n\t\treturn put_user(KB_101, (char __user *)arg);\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST)\n\t\t\treturn -EINVAL;\n\n\t\treturn ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\treturn ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\treturn vt_kdsetmode(vc, arg);\n\n\tcase KDGETMODE:\n\t\treturn put_user(vc->vc_mode, (int __user *)arg);\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\treturn -EINVAL;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\treturn put_user(vt_do_kdgkbmode(console), (int __user *)arg);\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\treturn vt_do_kdskbmeta(console, arg);\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\treturn put_user(vt_do_kdgkbmeta(console), (int __user *)arg);\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\treturn vt_do_kbkeycode_ioctl(cmd, up, perm);\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\treturn vt_do_kdsk_ioctl(cmd, up, perm, console);\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\treturn vt_do_kdgkb_ioctl(cmd, up, perm);\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\treturn vt_do_diacrit(cmd, up, perm);\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\treturn vt_do_kdskled(console, cmd, arg, perm);\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\tput_pid(vt_spawn_con.pid);\n\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\tvt_spawn_con.sig = arg;\n\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\tbreak;\n\n\tcase KDFONTOP: {\n\t\tstruct console_font_op op;\n\n\t\tif (copy_from_user(&op, up, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int vt_k_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\tunsigned long arg, bool perm)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tvoid __user *up = (void __user *)arg;\n\tunsigned int console = vc->vc_num;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is nave.\n\t\t */\n\t\treturn put_user(KB_101, (char __user *)arg);\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST)\n\t\t\treturn -EINVAL;\n\n\t\treturn ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\treturn ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tconsole_lock();\n\t\tret = vt_kdsetmode(vc, arg);\n\t\tconsole_unlock();\n\t\treturn ret;\n\n\tcase KDGETMODE:\n\t\treturn put_user(vc->vc_mode, (int __user *)arg);\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\treturn -EINVAL;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\treturn put_user(vt_do_kdgkbmode(console), (int __user *)arg);\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\treturn vt_do_kdskbmeta(console, arg);\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\treturn put_user(vt_do_kdgkbmeta(console), (int __user *)arg);\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\treturn vt_do_kbkeycode_ioctl(cmd, up, perm);\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\treturn vt_do_kdsk_ioctl(cmd, up, perm, console);\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\treturn vt_do_kdgkb_ioctl(cmd, up, perm);\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\treturn vt_do_diacrit(cmd, up, perm);\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\treturn vt_do_kdskled(console, cmd, arg, perm);\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\tput_pid(vt_spawn_con.pid);\n\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\tvt_spawn_con.sig = arg;\n\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\tbreak;\n\n\tcase KDFONTOP: {\n\t\tstruct console_font_op op;\n\n\t\tif (copy_from_user(&op, up, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -95,7 +95,10 @@\n \t\tif (!perm)\n \t\t\treturn -EPERM;\n \n-\t\treturn vt_kdsetmode(vc, arg);\n+\t\tconsole_lock();\n+\t\tret = vt_kdsetmode(vc, arg);\n+\t\tconsole_unlock();\n+\t\treturn ret;\n \n \tcase KDGETMODE:\n \t\treturn put_user(vc->vc_mode, (int __user *)arg);",
        "function_modified_lines": {
            "added": [
                "\t\tconsole_lock();",
                "\t\tret = vt_kdsetmode(vc, arg);",
                "\t\tconsole_unlock();",
                "\t\treturn ret;"
            ],
            "deleted": [
                "\t\treturn vt_kdsetmode(vc, arg);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A race problem was seen in the vt_k_ioctl in drivers/tty/vt/vt_ioctl.c in the Linux kernel, which may cause an out of bounds read in vt as the write access to vc_mode is not protected by lock-in vt_ioctl (KDSETMDE). The highest threat from this vulnerability is to data confidentiality.",
        "id": 3057
    },
    {
        "cve_id": "CVE-2021-0941",
        "code_before_change": "\nBPF_CALL_4(bpf_skb_adjust_room, struct sk_buff *, skb, s32, len_diff,\n\t   u32, mode, u64, flags)\n{\n\tu32 len_cur, len_diff_abs = abs(len_diff);\n\tu32 len_min = bpf_skb_net_base_len(skb);\n\tu32 len_max = __bpf_skb_max_len(skb);\n\t__be16 proto = skb->protocol;\n\tbool shrink = len_diff < 0;\n\tu32 off;\n\tint ret;\n\n\tif (unlikely(flags & ~(BPF_F_ADJ_ROOM_MASK |\n\t\t\t       BPF_F_ADJ_ROOM_NO_CSUM_RESET)))\n\t\treturn -EINVAL;\n\tif (unlikely(len_diff_abs > 0xfffU))\n\t\treturn -EFAULT;\n\tif (unlikely(proto != htons(ETH_P_IP) &&\n\t\t     proto != htons(ETH_P_IPV6)))\n\t\treturn -ENOTSUPP;\n\n\toff = skb_mac_header_len(skb);\n\tswitch (mode) {\n\tcase BPF_ADJ_ROOM_NET:\n\t\toff += bpf_skb_net_base_len(skb);\n\t\tbreak;\n\tcase BPF_ADJ_ROOM_MAC:\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTSUPP;\n\t}\n\n\tlen_cur = skb->len - skb_network_offset(skb);\n\tif ((shrink && (len_diff_abs >= len_cur ||\n\t\t\tlen_cur - len_diff_abs < len_min)) ||\n\t    (!shrink && (skb->len + len_diff_abs > len_max &&\n\t\t\t !skb_is_gso(skb))))\n\t\treturn -ENOTSUPP;\n\n\tret = shrink ? bpf_skb_net_shrink(skb, off, len_diff_abs, flags) :\n\t\t       bpf_skb_net_grow(skb, off, len_diff_abs, flags);\n\tif (!ret && !(flags & BPF_F_ADJ_ROOM_NO_CSUM_RESET))\n\t\t__skb_reset_checksum_unnecessary(skb);\n\n\tbpf_compute_data_pointers(skb);\n\treturn ret;\n}",
        "code_after_change": "\nBPF_CALL_4(bpf_skb_adjust_room, struct sk_buff *, skb, s32, len_diff,\n\t   u32, mode, u64, flags)\n{\n\tu32 len_cur, len_diff_abs = abs(len_diff);\n\tu32 len_min = bpf_skb_net_base_len(skb);\n\tu32 len_max = BPF_SKB_MAX_LEN;\n\t__be16 proto = skb->protocol;\n\tbool shrink = len_diff < 0;\n\tu32 off;\n\tint ret;\n\n\tif (unlikely(flags & ~(BPF_F_ADJ_ROOM_MASK |\n\t\t\t       BPF_F_ADJ_ROOM_NO_CSUM_RESET)))\n\t\treturn -EINVAL;\n\tif (unlikely(len_diff_abs > 0xfffU))\n\t\treturn -EFAULT;\n\tif (unlikely(proto != htons(ETH_P_IP) &&\n\t\t     proto != htons(ETH_P_IPV6)))\n\t\treturn -ENOTSUPP;\n\n\toff = skb_mac_header_len(skb);\n\tswitch (mode) {\n\tcase BPF_ADJ_ROOM_NET:\n\t\toff += bpf_skb_net_base_len(skb);\n\t\tbreak;\n\tcase BPF_ADJ_ROOM_MAC:\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTSUPP;\n\t}\n\n\tlen_cur = skb->len - skb_network_offset(skb);\n\tif ((shrink && (len_diff_abs >= len_cur ||\n\t\t\tlen_cur - len_diff_abs < len_min)) ||\n\t    (!shrink && (skb->len + len_diff_abs > len_max &&\n\t\t\t !skb_is_gso(skb))))\n\t\treturn -ENOTSUPP;\n\n\tret = shrink ? bpf_skb_net_shrink(skb, off, len_diff_abs, flags) :\n\t\t       bpf_skb_net_grow(skb, off, len_diff_abs, flags);\n\tif (!ret && !(flags & BPF_F_ADJ_ROOM_NO_CSUM_RESET))\n\t\t__skb_reset_checksum_unnecessary(skb);\n\n\tbpf_compute_data_pointers(skb);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n {\n \tu32 len_cur, len_diff_abs = abs(len_diff);\n \tu32 len_min = bpf_skb_net_base_len(skb);\n-\tu32 len_max = __bpf_skb_max_len(skb);\n+\tu32 len_max = BPF_SKB_MAX_LEN;\n \t__be16 proto = skb->protocol;\n \tbool shrink = len_diff < 0;\n \tu32 off;",
        "function_modified_lines": {
            "added": [
                "\tu32 len_max = BPF_SKB_MAX_LEN;"
            ],
            "deleted": [
                "\tu32 len_max = __bpf_skb_max_len(skb);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-416"
        ],
        "cve_description": "In bpf_skb_change_head of filter.c, there is a possible out of bounds read due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-154177719References: Upstream kernel",
        "id": 2838
    },
    {
        "cve_id": "CVE-2019-14283",
        "code_before_change": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif ((int)g->sect <= 0 ||\n\t    (int)g->head <= 0 ||\n\t    /* check for overflow in max_sector */\n\t    (int)(g->sect * g->head) <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,8 +4,10 @@\n \tint cnt;\n \n \t/* sanity checking for parameters. */\n-\tif (g->sect <= 0 ||\n-\t    g->head <= 0 ||\n+\tif ((int)g->sect <= 0 ||\n+\t    (int)g->head <= 0 ||\n+\t    /* check for overflow in max_sector */\n+\t    (int)(g->sect * g->head) <= 0 ||\n \t    /* check for zero in F_SECT_PER_TRACK */\n \t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n \t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||",
        "function_modified_lines": {
            "added": [
                "\tif ((int)g->sect <= 0 ||",
                "\t    (int)g->head <= 0 ||",
                "\t    /* check for overflow in max_sector */",
                "\t    (int)(g->sect * g->head) <= 0 ||"
            ],
            "deleted": [
                "\tif (g->sect <= 0 ||",
                "\t    g->head <= 0 ||"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-190"
        ],
        "cve_description": "In the Linux kernel before 5.2.3, set_geometry in drivers/block/floppy.c does not validate the sect and head fields, as demonstrated by an integer overflow and out-of-bounds read. It can be triggered by an unprivileged local user when a floppy disk has been inserted. NOTE: QEMU creates the floppy device by default.",
        "id": 1964
    },
    {
        "cve_id": "CVE-2023-38430",
        "code_before_change": "int ksmbd_conn_handler_loop(void *p)\n{\n\tstruct ksmbd_conn *conn = (struct ksmbd_conn *)p;\n\tstruct ksmbd_transport *t = conn->transport;\n\tunsigned int pdu_size, max_allowed_pdu_size;\n\tchar hdr_buf[4] = {0,};\n\tint size;\n\n\tmutex_init(&conn->srv_mutex);\n\t__module_get(THIS_MODULE);\n\n\tif (t->ops->prepare && t->ops->prepare(t))\n\t\tgoto out;\n\n\tconn->last_active = jiffies;\n\twhile (ksmbd_conn_alive(conn)) {\n\t\tif (try_to_freeze())\n\t\t\tcontinue;\n\n\t\tkvfree(conn->request_buf);\n\t\tconn->request_buf = NULL;\n\n\t\tsize = t->ops->read(t, hdr_buf, sizeof(hdr_buf), -1);\n\t\tif (size != sizeof(hdr_buf))\n\t\t\tbreak;\n\n\t\tpdu_size = get_rfc1002_len(hdr_buf);\n\t\tksmbd_debug(CONN, \"RFC1002 header %u bytes\\n\", pdu_size);\n\n\t\tif (ksmbd_conn_good(conn))\n\t\t\tmax_allowed_pdu_size =\n\t\t\t\tSMB3_MAX_MSGSIZE + conn->vals->max_write_size;\n\t\telse\n\t\t\tmax_allowed_pdu_size = SMB3_MAX_MSGSIZE;\n\n\t\tif (pdu_size > max_allowed_pdu_size) {\n\t\t\tpr_err_ratelimited(\"PDU length(%u) exceeded maximum allowed pdu size(%u) on connection(%d)\\n\",\n\t\t\t\t\tpdu_size, max_allowed_pdu_size,\n\t\t\t\t\tREAD_ONCE(conn->status));\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Check maximum pdu size(0x00FFFFFF).\n\t\t */\n\t\tif (pdu_size > MAX_STREAM_PROT_LEN)\n\t\t\tbreak;\n\n\t\tif (pdu_size < SMB1_MIN_SUPPORTED_HEADER_SIZE)\n\t\t\tbreak;\n\n\t\t/* 4 for rfc1002 length field */\n\t\t/* 1 for implied bcc[0] */\n\t\tsize = pdu_size + 4 + 1;\n\t\tconn->request_buf = kvmalloc(size, GFP_KERNEL);\n\t\tif (!conn->request_buf)\n\t\t\tbreak;\n\n\t\tmemcpy(conn->request_buf, hdr_buf, sizeof(hdr_buf));\n\t\tif (!ksmbd_smb_request(conn))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We already read 4 bytes to find out PDU size, now\n\t\t * read in PDU\n\t\t */\n\t\tsize = t->ops->read(t, conn->request_buf + 4, pdu_size, 2);\n\t\tif (size < 0) {\n\t\t\tpr_err(\"sock_read failed: %d\\n\", size);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (size != pdu_size) {\n\t\t\tpr_err(\"PDU error. Read: %d, Expected: %d\\n\",\n\t\t\t       size, pdu_size);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (((struct smb2_hdr *)smb2_get_msg(conn->request_buf))->ProtocolId ==\n\t\t    SMB2_PROTO_NUMBER) {\n\t\t\tif (pdu_size < SMB2_MIN_SUPPORTED_HEADER_SIZE)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!default_conn_ops.process_fn) {\n\t\t\tpr_err(\"No connection request callback\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (default_conn_ops.process_fn(conn)) {\n\t\t\tpr_err(\"Cannot handle request\\n\");\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tksmbd_conn_set_releasing(conn);\n\t/* Wait till all reference dropped to the Server object*/\n\twait_event(conn->r_count_q, atomic_read(&conn->r_count) == 0);\n\n\tif (IS_ENABLED(CONFIG_UNICODE))\n\t\tutf8_unload(conn->um);\n\tunload_nls(conn->local_nls);\n\tif (default_conn_ops.terminate_fn)\n\t\tdefault_conn_ops.terminate_fn(conn);\n\tt->ops->disconnect(t);\n\tmodule_put(THIS_MODULE);\n\treturn 0;\n}",
        "code_after_change": "int ksmbd_conn_handler_loop(void *p)\n{\n\tstruct ksmbd_conn *conn = (struct ksmbd_conn *)p;\n\tstruct ksmbd_transport *t = conn->transport;\n\tunsigned int pdu_size, max_allowed_pdu_size;\n\tchar hdr_buf[4] = {0,};\n\tint size;\n\n\tmutex_init(&conn->srv_mutex);\n\t__module_get(THIS_MODULE);\n\n\tif (t->ops->prepare && t->ops->prepare(t))\n\t\tgoto out;\n\n\tconn->last_active = jiffies;\n\twhile (ksmbd_conn_alive(conn)) {\n\t\tif (try_to_freeze())\n\t\t\tcontinue;\n\n\t\tkvfree(conn->request_buf);\n\t\tconn->request_buf = NULL;\n\n\t\tsize = t->ops->read(t, hdr_buf, sizeof(hdr_buf), -1);\n\t\tif (size != sizeof(hdr_buf))\n\t\t\tbreak;\n\n\t\tpdu_size = get_rfc1002_len(hdr_buf);\n\t\tksmbd_debug(CONN, \"RFC1002 header %u bytes\\n\", pdu_size);\n\n\t\tif (ksmbd_conn_good(conn))\n\t\t\tmax_allowed_pdu_size =\n\t\t\t\tSMB3_MAX_MSGSIZE + conn->vals->max_write_size;\n\t\telse\n\t\t\tmax_allowed_pdu_size = SMB3_MAX_MSGSIZE;\n\n\t\tif (pdu_size > max_allowed_pdu_size) {\n\t\t\tpr_err_ratelimited(\"PDU length(%u) exceeded maximum allowed pdu size(%u) on connection(%d)\\n\",\n\t\t\t\t\tpdu_size, max_allowed_pdu_size,\n\t\t\t\t\tREAD_ONCE(conn->status));\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Check maximum pdu size(0x00FFFFFF).\n\t\t */\n\t\tif (pdu_size > MAX_STREAM_PROT_LEN)\n\t\t\tbreak;\n\n\t\tif (pdu_size < SMB1_MIN_SUPPORTED_HEADER_SIZE)\n\t\t\tbreak;\n\n\t\t/* 4 for rfc1002 length field */\n\t\t/* 1 for implied bcc[0] */\n\t\tsize = pdu_size + 4 + 1;\n\t\tconn->request_buf = kvmalloc(size, GFP_KERNEL);\n\t\tif (!conn->request_buf)\n\t\t\tbreak;\n\n\t\tmemcpy(conn->request_buf, hdr_buf, sizeof(hdr_buf));\n\n\t\t/*\n\t\t * We already read 4 bytes to find out PDU size, now\n\t\t * read in PDU\n\t\t */\n\t\tsize = t->ops->read(t, conn->request_buf + 4, pdu_size, 2);\n\t\tif (size < 0) {\n\t\t\tpr_err(\"sock_read failed: %d\\n\", size);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (size != pdu_size) {\n\t\t\tpr_err(\"PDU error. Read: %d, Expected: %d\\n\",\n\t\t\t       size, pdu_size);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ksmbd_smb_request(conn))\n\t\t\tbreak;\n\n\t\tif (((struct smb2_hdr *)smb2_get_msg(conn->request_buf))->ProtocolId ==\n\t\t    SMB2_PROTO_NUMBER) {\n\t\t\tif (pdu_size < SMB2_MIN_SUPPORTED_HEADER_SIZE)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (!default_conn_ops.process_fn) {\n\t\t\tpr_err(\"No connection request callback\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tif (default_conn_ops.process_fn(conn)) {\n\t\t\tpr_err(\"Cannot handle request\\n\");\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tksmbd_conn_set_releasing(conn);\n\t/* Wait till all reference dropped to the Server object*/\n\twait_event(conn->r_count_q, atomic_read(&conn->r_count) == 0);\n\n\tif (IS_ENABLED(CONFIG_UNICODE))\n\t\tutf8_unload(conn->um);\n\tunload_nls(conn->local_nls);\n\tif (default_conn_ops.terminate_fn)\n\t\tdefault_conn_ops.terminate_fn(conn);\n\tt->ops->disconnect(t);\n\tmodule_put(THIS_MODULE);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -57,8 +57,6 @@\n \t\t\tbreak;\n \n \t\tmemcpy(conn->request_buf, hdr_buf, sizeof(hdr_buf));\n-\t\tif (!ksmbd_smb_request(conn))\n-\t\t\tbreak;\n \n \t\t/*\n \t\t * We already read 4 bytes to find out PDU size, now\n@@ -75,6 +73,9 @@\n \t\t\t       size, pdu_size);\n \t\t\tcontinue;\n \t\t}\n+\n+\t\tif (!ksmbd_smb_request(conn))\n+\t\t\tbreak;\n \n \t\tif (((struct smb2_hdr *)smb2_get_msg(conn->request_buf))->ProtocolId ==\n \t\t    SMB2_PROTO_NUMBER) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t\tif (!ksmbd_smb_request(conn))",
                "\t\t\tbreak;"
            ],
            "deleted": [
                "\t\tif (!ksmbd_smb_request(conn))",
                "\t\t\tbreak;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.9. ksmbd does not validate the SMB request protocol ID, leading to an out-of-bounds read.",
        "id": 4141
    }
]