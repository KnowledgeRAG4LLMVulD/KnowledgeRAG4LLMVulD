[
    {
        "cve_id": "CVE-2014-3182",
        "code_before_change": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t\t  struct dj_report *dj_report)\n{\n\t/* Called in delayed work context */\n\tstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\n\tstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct hid_device *dj_hiddev;\n\tstruct dj_device *dj_dev;\n\n\t/* Device index goes from 1 to 6, we need 3 bytes to store the\n\t * semicolon, the index, and a null terminator\n\t */\n\tunsigned char tmpstr[3];\n\n\tif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\n\t    SPFUNCTION_DEVICE_LIST_EMPTY) {\n\t\tdbg_hid(\"%s: device list is empty\\n\", __func__);\n\t\tdjrcv_dev->querying_devices = false;\n\t\treturn;\n\t}\n\n\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",\n\t\t\t__func__, dj_report->device_index);\n\t\treturn;\n\t}\n\n\tif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\n\t\t/* The device is already known. No need to reallocate it. */\n\t\tdbg_hid(\"%s: device is already known\\n\", __func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev = hid_allocate_device();\n\tif (IS_ERR(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev->ll_driver = &logi_dj_ll_driver;\n\n\tdj_hiddev->dev.parent = &djrcv_hdev->dev;\n\tdj_hiddev->bus = BUS_USB;\n\tdj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\n\tdj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\n\tsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\t\t\"Logitech Unifying Device. Wireless PID:%02x%02x\",\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\n\n\tusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\n\tsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\n\tstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\n\n\tdj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\n\n\tif (!dj_dev) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto dj_device_allocate_fail;\n\t}\n\n\tdj_dev->reports_supported = get_unaligned_le32(\n\t\tdj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\n\tdj_dev->hdev = dj_hiddev;\n\tdj_dev->dj_receiver_dev = djrcv_dev;\n\tdj_dev->device_index = dj_report->device_index;\n\tdj_hiddev->driver_data = dj_dev;\n\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\n\n\tif (hid_add_device(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto hid_add_device_fail;\n\t}\n\n\treturn;\n\nhid_add_device_fail:\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\n\tkfree(dj_dev);\ndj_device_allocate_fail:\n\thid_destroy_device(dj_hiddev);\n}",
        "code_after_change": "static void logi_dj_recv_add_djhid_device(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t\t  struct dj_report *dj_report)\n{\n\t/* Called in delayed work context */\n\tstruct hid_device *djrcv_hdev = djrcv_dev->hdev;\n\tstruct usb_interface *intf = to_usb_interface(djrcv_hdev->dev.parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct hid_device *dj_hiddev;\n\tstruct dj_device *dj_dev;\n\n\t/* Device index goes from 1 to 6, we need 3 bytes to store the\n\t * semicolon, the index, and a null terminator\n\t */\n\tunsigned char tmpstr[3];\n\n\tif (dj_report->report_params[DEVICE_PAIRED_PARAM_SPFUNCTION] &\n\t    SPFUNCTION_DEVICE_LIST_EMPTY) {\n\t\tdbg_hid(\"%s: device list is empty\\n\", __func__);\n\t\tdjrcv_dev->querying_devices = false;\n\t\treturn;\n\t}\n\n\tif (djrcv_dev->paired_dj_devices[dj_report->device_index]) {\n\t\t/* The device is already known. No need to reallocate it. */\n\t\tdbg_hid(\"%s: device is already known\\n\", __func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev = hid_allocate_device();\n\tif (IS_ERR(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: hid_allocate_device failed\\n\",\n\t\t\t__func__);\n\t\treturn;\n\t}\n\n\tdj_hiddev->ll_driver = &logi_dj_ll_driver;\n\n\tdj_hiddev->dev.parent = &djrcv_hdev->dev;\n\tdj_hiddev->bus = BUS_USB;\n\tdj_hiddev->vendor = le16_to_cpu(usbdev->descriptor.idVendor);\n\tdj_hiddev->product = le16_to_cpu(usbdev->descriptor.idProduct);\n\tsnprintf(dj_hiddev->name, sizeof(dj_hiddev->name),\n\t\t\"Logitech Unifying Device. Wireless PID:%02x%02x\",\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_MSB],\n\t\tdj_report->report_params[DEVICE_PAIRED_PARAM_EQUAD_ID_LSB]);\n\n\tusb_make_path(usbdev, dj_hiddev->phys, sizeof(dj_hiddev->phys));\n\tsnprintf(tmpstr, sizeof(tmpstr), \":%d\", dj_report->device_index);\n\tstrlcat(dj_hiddev->phys, tmpstr, sizeof(dj_hiddev->phys));\n\n\tdj_dev = kzalloc(sizeof(struct dj_device), GFP_KERNEL);\n\n\tif (!dj_dev) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed allocating dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto dj_device_allocate_fail;\n\t}\n\n\tdj_dev->reports_supported = get_unaligned_le32(\n\t\tdj_report->report_params + DEVICE_PAIRED_RF_REPORT_TYPE);\n\tdj_dev->hdev = dj_hiddev;\n\tdj_dev->dj_receiver_dev = djrcv_dev;\n\tdj_dev->device_index = dj_report->device_index;\n\tdj_hiddev->driver_data = dj_dev;\n\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = dj_dev;\n\n\tif (hid_add_device(dj_hiddev)) {\n\t\tdev_err(&djrcv_hdev->dev, \"%s: failed adding dj_device\\n\",\n\t\t\t__func__);\n\t\tgoto hid_add_device_fail;\n\t}\n\n\treturn;\n\nhid_add_device_fail:\n\tdjrcv_dev->paired_dj_devices[dj_report->device_index] = NULL;\n\tkfree(dj_dev);\ndj_device_allocate_fail:\n\thid_destroy_device(dj_hiddev);\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,13 +17,6 @@\n \t    SPFUNCTION_DEVICE_LIST_EMPTY) {\n \t\tdbg_hid(\"%s: device list is empty\\n\", __func__);\n \t\tdjrcv_dev->querying_devices = false;\n-\t\treturn;\n-\t}\n-\n-\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n-\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\n-\t\tdev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",\n-\t\t\t__func__, dj_report->device_index);\n \t\treturn;\n \t}\n ",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\treturn;",
                "\t}",
                "",
                "\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||",
                "\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {",
                "\t\tdev_err(&djrcv_hdev->dev, \"%s: invalid device index:%d\\n\",",
                "\t\t\t__func__, dj_report->device_index);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Array index error in the logi_dj_raw_event function in drivers/hid/hid-logitech-dj.c in the Linux kernel before 3.16.2 allows physically proximate attackers to execute arbitrary code or cause a denial of service (invalid kfree) via a crafted device that provides a malformed REPORT_TYPE_NOTIF_DEVICE_UNPAIRED value.",
        "id": 512
    },
    {
        "cve_id": "CVE-2013-7027",
        "code_before_change": "int ieee80211_radiotap_iterator_init(\n\tstruct ieee80211_radiotap_iterator *iterator,\n\tstruct ieee80211_radiotap_header *radiotap_header,\n\tint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\n\t/* Linux only supports version 0 radiotap format */\n\tif (radiotap_header->it_version)\n\t\treturn -EINVAL;\n\n\t/* sanity check for allowed length and radiotap length field */\n\tif (max_length < get_unaligned_le16(&radiotap_header->it_len))\n\t\treturn -EINVAL;\n\n\titerator->_rtheader = radiotap_header;\n\titerator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\n\titerator->_arg_index = 0;\n\titerator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\n\titerator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\n\titerator->_reset_on_ext = 0;\n\titerator->_next_bitmap = &radiotap_header->it_present;\n\titerator->_next_bitmap++;\n\titerator->_vns = vns;\n\titerator->current_namespace = &radiotap_ns;\n\titerator->is_radiotap_ns = 1;\n\n\t/* find payload start allowing for extended bitmap(s) */\n\n\tif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\n\t\twhile (get_unaligned_le32(iterator->_arg) &\n\t\t\t\t\t(1 << IEEE80211_RADIOTAP_EXT)) {\n\t\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t\t/*\n\t\t\t * check for insanity where the present bitmaps\n\t\t\t * keep claiming to extend up to or even beyond the\n\t\t\t * stated radiotap header length\n\t\t\t */\n\n\t\t\tif ((unsigned long)iterator->_arg -\n\t\t\t    (unsigned long)iterator->_rtheader >\n\t\t\t    (unsigned long)iterator->_max_length)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t/*\n\t\t * no need to check again for blowing past stated radiotap\n\t\t * header length, because ieee80211_radiotap_iterator_next\n\t\t * checks it before it is dereferenced\n\t\t */\n\t}\n\n\titerator->this_arg = iterator->_arg;\n\n\t/* we are all initialized happily */\n\n\treturn 0;\n}",
        "code_after_change": "int ieee80211_radiotap_iterator_init(\n\tstruct ieee80211_radiotap_iterator *iterator,\n\tstruct ieee80211_radiotap_header *radiotap_header,\n\tint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n{\n\t/* check the radiotap header can actually be present */\n\tif (max_length < sizeof(struct ieee80211_radiotap_header))\n\t\treturn -EINVAL;\n\n\t/* Linux only supports version 0 radiotap format */\n\tif (radiotap_header->it_version)\n\t\treturn -EINVAL;\n\n\t/* sanity check for allowed length and radiotap length field */\n\tif (max_length < get_unaligned_le16(&radiotap_header->it_len))\n\t\treturn -EINVAL;\n\n\titerator->_rtheader = radiotap_header;\n\titerator->_max_length = get_unaligned_le16(&radiotap_header->it_len);\n\titerator->_arg_index = 0;\n\titerator->_bitmap_shifter = get_unaligned_le32(&radiotap_header->it_present);\n\titerator->_arg = (uint8_t *)radiotap_header + sizeof(*radiotap_header);\n\titerator->_reset_on_ext = 0;\n\titerator->_next_bitmap = &radiotap_header->it_present;\n\titerator->_next_bitmap++;\n\titerator->_vns = vns;\n\titerator->current_namespace = &radiotap_ns;\n\titerator->is_radiotap_ns = 1;\n\n\t/* find payload start allowing for extended bitmap(s) */\n\n\tif (iterator->_bitmap_shifter & (1<<IEEE80211_RADIOTAP_EXT)) {\n\t\twhile (get_unaligned_le32(iterator->_arg) &\n\t\t\t\t\t(1 << IEEE80211_RADIOTAP_EXT)) {\n\t\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t\t/*\n\t\t\t * check for insanity where the present bitmaps\n\t\t\t * keep claiming to extend up to or even beyond the\n\t\t\t * stated radiotap header length\n\t\t\t */\n\n\t\t\tif ((unsigned long)iterator->_arg -\n\t\t\t    (unsigned long)iterator->_rtheader +\n\t\t\t    sizeof(uint32_t) >\n\t\t\t    (unsigned long)iterator->_max_length)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\titerator->_arg += sizeof(uint32_t);\n\n\t\t/*\n\t\t * no need to check again for blowing past stated radiotap\n\t\t * header length, because ieee80211_radiotap_iterator_next\n\t\t * checks it before it is dereferenced\n\t\t */\n\t}\n\n\titerator->this_arg = iterator->_arg;\n\n\t/* we are all initialized happily */\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,10 @@\n \tstruct ieee80211_radiotap_header *radiotap_header,\n \tint max_length, const struct ieee80211_radiotap_vendor_namespaces *vns)\n {\n+\t/* check the radiotap header can actually be present */\n+\tif (max_length < sizeof(struct ieee80211_radiotap_header))\n+\t\treturn -EINVAL;\n+\n \t/* Linux only supports version 0 radiotap format */\n \tif (radiotap_header->it_version)\n \t\treturn -EINVAL;\n@@ -37,7 +41,8 @@\n \t\t\t */\n \n \t\t\tif ((unsigned long)iterator->_arg -\n-\t\t\t    (unsigned long)iterator->_rtheader >\n+\t\t\t    (unsigned long)iterator->_rtheader +\n+\t\t\t    sizeof(uint32_t) >\n \t\t\t    (unsigned long)iterator->_max_length)\n \t\t\t\treturn -EINVAL;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t/* check the radiotap header can actually be present */",
                "\tif (max_length < sizeof(struct ieee80211_radiotap_header))",
                "\t\treturn -EINVAL;",
                "",
                "\t\t\t    (unsigned long)iterator->_rtheader +",
                "\t\t\t    sizeof(uint32_t) >"
            ],
            "deleted": [
                "\t\t\t    (unsigned long)iterator->_rtheader >"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The ieee80211_radiotap_iterator_init function in net/wireless/radiotap.c in the Linux kernel before 3.11.7 does not check whether a frame contains any data outside of the header, which might allow attackers to cause a denial of service (buffer over-read) via a crafted header.",
        "id": 358
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((e->target_offset == sizeof(struct ip6t_entry) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0 &&\n\t\t\t     unconditional(&e->ipv6)) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,11 +29,10 @@\n \t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n \n \t\t\t/* Unconditional return/END. */\n-\t\t\tif ((e->target_offset == sizeof(struct ip6t_entry) &&\n+\t\t\tif ((unconditional(e) &&\n \t\t\t     (strcmp(t->target.u.user.name,\n \t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n-\t\t\t     t->verdict < 0 &&\n-\t\t\t     unconditional(&e->ipv6)) || visited) {\n+\t\t\t     t->verdict < 0) || visited) {\n \t\t\t\tunsigned int oldpos, size;\n \n \t\t\t\tif ((strcmp(t->target.u.user.name,",
        "function_modified_lines": {
            "added": [
                "\t\t\tif ((unconditional(e) &&",
                "\t\t\t     t->verdict < 0) || visited) {"
            ],
            "deleted": [
                "\t\t\tif ((e->target_offset == sizeof(struct ip6t_entry) &&",
                "\t\t\t     t->verdict < 0 &&",
                "\t\t\t     unconditional(&e->ipv6)) || visited) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 972
    },
    {
        "cve_id": "CVE-2013-1929",
        "code_before_change": "static void tg3_read_vpd(struct tg3 *tp)\n{\n\tu8 *vpd_data;\n\tunsigned int block_end, rosize, len;\n\tu32 vpdlen;\n\tint j, i = 0;\n\n\tvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\n\tif (!vpd_data)\n\t\tgoto out_no_vpd;\n\n\ti = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\trosize = pci_vpd_lrdt_size(&vpd_data[i]);\n\tblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\n\ti += PCI_VPD_LRDT_TAG_SIZE;\n\n\tif (block_end > vpdlen)\n\t\tgoto out_not_found;\n\n\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_MFR_ID);\n\tif (j > 0) {\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end || len != 4 ||\n\t\t    memcmp(&vpd_data[j], \"1028\", 4))\n\t\t\tgoto partno;\n\n\t\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t\t      PCI_VPD_RO_KEYWORD_VENDOR0);\n\t\tif (j < 0)\n\t\t\tgoto partno;\n\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end)\n\t\t\tgoto partno;\n\n\t\tmemcpy(tp->fw_ver, &vpd_data[j], len);\n\t\tstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);\n\t}\n\npartno:\n\ti = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_PARTNO);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[i]);\n\n\ti += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len > TG3_BPN_SIZE ||\n\t    (len + i) > vpdlen)\n\t\tgoto out_not_found;\n\n\tmemcpy(tp->board_part_number, &vpd_data[i], len);\n\nout_not_found:\n\tkfree(vpd_data);\n\tif (tp->board_part_number[0])\n\t\treturn;\n\nout_no_vpd:\n\tif (tg3_asic_rev(tp) == ASIC_REV_5717) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\n\t\t    tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5717\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5718\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57780\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57760\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57790\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57788\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57761\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57765\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57781\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57785\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57791\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57795\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57762\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57766\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57782\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57786\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\n\t\tstrcpy(tp->board_part_number, \"BCM95906\");\n\t} else {\nnomatch:\n\t\tstrcpy(tp->board_part_number, \"none\");\n\t}\n}",
        "code_after_change": "static void tg3_read_vpd(struct tg3 *tp)\n{\n\tu8 *vpd_data;\n\tunsigned int block_end, rosize, len;\n\tu32 vpdlen;\n\tint j, i = 0;\n\n\tvpd_data = (u8 *)tg3_vpd_readblock(tp, &vpdlen);\n\tif (!vpd_data)\n\t\tgoto out_no_vpd;\n\n\ti = pci_vpd_find_tag(vpd_data, 0, vpdlen, PCI_VPD_LRDT_RO_DATA);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\trosize = pci_vpd_lrdt_size(&vpd_data[i]);\n\tblock_end = i + PCI_VPD_LRDT_TAG_SIZE + rosize;\n\ti += PCI_VPD_LRDT_TAG_SIZE;\n\n\tif (block_end > vpdlen)\n\t\tgoto out_not_found;\n\n\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_MFR_ID);\n\tif (j > 0) {\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end || len != 4 ||\n\t\t    memcmp(&vpd_data[j], \"1028\", 4))\n\t\t\tgoto partno;\n\n\t\tj = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t\t      PCI_VPD_RO_KEYWORD_VENDOR0);\n\t\tif (j < 0)\n\t\t\tgoto partno;\n\n\t\tlen = pci_vpd_info_field_size(&vpd_data[j]);\n\n\t\tj += PCI_VPD_INFO_FLD_HDR_SIZE;\n\t\tif (j + len > block_end)\n\t\t\tgoto partno;\n\n\t\tif (len >= sizeof(tp->fw_ver))\n\t\t\tlen = sizeof(tp->fw_ver) - 1;\n\t\tmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));\n\t\tsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,\n\t\t\t &vpd_data[j]);\n\t}\n\npartno:\n\ti = pci_vpd_find_info_keyword(vpd_data, i, rosize,\n\t\t\t\t      PCI_VPD_RO_KEYWORD_PARTNO);\n\tif (i < 0)\n\t\tgoto out_not_found;\n\n\tlen = pci_vpd_info_field_size(&vpd_data[i]);\n\n\ti += PCI_VPD_INFO_FLD_HDR_SIZE;\n\tif (len > TG3_BPN_SIZE ||\n\t    (len + i) > vpdlen)\n\t\tgoto out_not_found;\n\n\tmemcpy(tp->board_part_number, &vpd_data[i], len);\n\nout_not_found:\n\tkfree(vpd_data);\n\tif (tp->board_part_number[0])\n\t\treturn;\n\nout_no_vpd:\n\tif (tg3_asic_rev(tp) == ASIC_REV_5717) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717 ||\n\t\t    tp->pdev->device == TG3PCI_DEVICE_TIGON3_5717_C)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5717\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_5718)\n\t\t\tstrcpy(tp->board_part_number, \"BCM5718\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57780) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57780)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57780\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57760)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57760\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57790)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57790\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57788)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57788\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57765) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57761)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57761\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57765)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57765\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57781)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57781\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57785)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57785\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57791)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57791\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57795)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57795\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_57766) {\n\t\tif (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57762)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57762\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57766)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57766\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57782)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57782\");\n\t\telse if (tp->pdev->device == TG3PCI_DEVICE_TIGON3_57786)\n\t\t\tstrcpy(tp->board_part_number, \"BCM57786\");\n\t\telse\n\t\t\tgoto nomatch;\n\t} else if (tg3_asic_rev(tp) == ASIC_REV_5906) {\n\t\tstrcpy(tp->board_part_number, \"BCM95906\");\n\t} else {\nnomatch:\n\t\tstrcpy(tp->board_part_number, \"none\");\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -41,8 +41,11 @@\n \t\tif (j + len > block_end)\n \t\t\tgoto partno;\n \n-\t\tmemcpy(tp->fw_ver, &vpd_data[j], len);\n-\t\tstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);\n+\t\tif (len >= sizeof(tp->fw_ver))\n+\t\t\tlen = sizeof(tp->fw_ver) - 1;\n+\t\tmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));\n+\t\tsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,\n+\t\t\t &vpd_data[j]);\n \t}\n \n partno:",
        "function_modified_lines": {
            "added": [
                "\t\tif (len >= sizeof(tp->fw_ver))",
                "\t\t\tlen = sizeof(tp->fw_ver) - 1;",
                "\t\tmemset(tp->fw_ver, 0, sizeof(tp->fw_ver));",
                "\t\tsnprintf(tp->fw_ver, sizeof(tp->fw_ver), \"%.*s bc \", len,",
                "\t\t\t &vpd_data[j]);"
            ],
            "deleted": [
                "\t\tmemcpy(tp->fw_ver, &vpd_data[j], len);",
                "\t\tstrncat(tp->fw_ver, \" bc \", vpdlen - len - 1);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the tg3_read_vpd function in drivers/net/ethernet/broadcom/tg3.c in the Linux kernel before 3.8.6 allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via crafted firmware that specifies a long string in the Vital Product Data (VPD) data structure.",
        "id": 205
    },
    {
        "cve_id": "CVE-2012-3364",
        "code_before_change": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\n\tdata += 2;\n\n\tnfca_poll->nfcid1_len = *data++;\n\n\tpr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\n\t\t nfca_poll->sens_res, nfca_poll->nfcid1_len);\n\n\tmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\n\tdata += nfca_poll->nfcid1_len;\n\n\tnfca_poll->sel_res_len = *data++;\n\n\tif (nfca_poll->sel_res_len != 0)\n\t\tnfca_poll->sel_res = *data++;\n\n\tpr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\n\t\t nfca_poll->sel_res_len,\n\t\t nfca_poll->sel_res);\n\n\treturn data;\n}",
        "code_after_change": "static __u8 *nci_extract_rf_params_nfca_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfca_poll *nfca_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\n\tdata += 2;\n\n\tnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);\n\n\tpr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\n\t\t nfca_poll->sens_res, nfca_poll->nfcid1_len);\n\n\tmemcpy(nfca_poll->nfcid1, data, nfca_poll->nfcid1_len);\n\tdata += nfca_poll->nfcid1_len;\n\n\tnfca_poll->sel_res_len = *data++;\n\n\tif (nfca_poll->sel_res_len != 0)\n\t\tnfca_poll->sel_res = *data++;\n\n\tpr_debug(\"sel_res_len %d, sel_res 0x%x\\n\",\n\t\t nfca_poll->sel_res_len,\n\t\t nfca_poll->sel_res);\n\n\treturn data;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tnfca_poll->sens_res = __le16_to_cpu(*((__u16 *)data));\n \tdata += 2;\n \n-\tnfca_poll->nfcid1_len = *data++;\n+\tnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);\n \n \tpr_debug(\"sens_res 0x%x, nfcid1_len %d\\n\",\n \t\t nfca_poll->sens_res, nfca_poll->nfcid1_len);",
        "function_modified_lines": {
            "added": [
                "\tnfca_poll->nfcid1_len = min_t(__u8, *data++, NFC_NFCID1_MAXSIZE);"
            ],
            "deleted": [
                "\tnfca_poll->nfcid1_len = *data++;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple stack-based buffer overflows in the Near Field Communication Controller Interface (NCI) in the Linux kernel before 3.4.5 allow remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via incoming frames with crafted length fields.",
        "id": 56
    },
    {
        "cve_id": "CVE-2018-10124",
        "code_before_change": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
        "code_after_change": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\t/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */\n\tif (pid == INT_MIN)\n\t\treturn -ESRCH;\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,10 @@\n \t\trcu_read_unlock();\n \t\treturn ret;\n \t}\n+\n+\t/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */\n+\tif (pid == INT_MIN)\n+\t\treturn -ESRCH;\n \n \tread_lock(&tasklist_lock);\n \tif (pid != -1) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* -INT_MIN is undefined.  Exclude this case to avoid a UBSAN warning */",
                "\tif (pid == INT_MIN)",
                "\t\treturn -ESRCH;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The kill_something_info function in kernel/signal.c in the Linux kernel before 4.13, when an unspecified architecture and compiler is used, might allow local users to cause a denial of service via an INT_MIN argument.",
        "id": 1586
    },
    {
        "cve_id": "CVE-2017-15126",
        "code_before_change": "static ssize_t userfaultfd_ctx_read(struct userfaultfd_ctx *ctx, int no_wait,\n\t\t\t\t    struct uffd_msg *msg)\n{\n\tssize_t ret;\n\tDECLARE_WAITQUEUE(wait, current);\n\tstruct userfaultfd_wait_queue *uwq;\n\t/*\n\t * Handling fork event requires sleeping operations, so\n\t * we drop the event_wqh lock, then do these ops, then\n\t * lock it back and wake up the waiter. While the lock is\n\t * dropped the ewq may go away so we keep track of it\n\t * carefully.\n\t */\n\tLIST_HEAD(fork_event);\n\tstruct userfaultfd_ctx *fork_nctx = NULL;\n\n\t/* always take the fd_wqh lock before the fault_pending_wqh lock */\n\tspin_lock(&ctx->fd_wqh.lock);\n\t__add_wait_queue(&ctx->fd_wqh, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tspin_lock(&ctx->fault_pending_wqh.lock);\n\t\tuwq = find_userfault(ctx);\n\t\tif (uwq) {\n\t\t\t/*\n\t\t\t * Use a seqcount to repeat the lockless check\n\t\t\t * in wake_userfault() to avoid missing\n\t\t\t * wakeups because during the refile both\n\t\t\t * waitqueue could become empty if this is the\n\t\t\t * only userfault.\n\t\t\t */\n\t\t\twrite_seqcount_begin(&ctx->refile_seq);\n\n\t\t\t/*\n\t\t\t * The fault_pending_wqh.lock prevents the uwq\n\t\t\t * to disappear from under us.\n\t\t\t *\n\t\t\t * Refile this userfault from\n\t\t\t * fault_pending_wqh to fault_wqh, it's not\n\t\t\t * pending anymore after we read it.\n\t\t\t *\n\t\t\t * Use list_del() by hand (as\n\t\t\t * userfaultfd_wake_function also uses\n\t\t\t * list_del_init() by hand) to be sure nobody\n\t\t\t * changes __remove_wait_queue() to use\n\t\t\t * list_del_init() in turn breaking the\n\t\t\t * !list_empty_careful() check in\n\t\t\t * handle_userfault(). The uwq->wq.head list\n\t\t\t * must never be empty at any time during the\n\t\t\t * refile, or the waitqueue could disappear\n\t\t\t * from under us. The \"wait_queue_head_t\"\n\t\t\t * parameter of __remove_wait_queue() is unused\n\t\t\t * anyway.\n\t\t\t */\n\t\t\tlist_del(&uwq->wq.entry);\n\t\t\t__add_wait_queue(&ctx->fault_wqh, &uwq->wq);\n\n\t\t\twrite_seqcount_end(&ctx->refile_seq);\n\n\t\t\t/* careful to always initialize msg if ret == 0 */\n\t\t\t*msg = uwq->msg;\n\t\t\tspin_unlock(&ctx->fault_pending_wqh.lock);\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->fault_pending_wqh.lock);\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t\tuwq = find_userfault_evt(ctx);\n\t\tif (uwq) {\n\t\t\t*msg = uwq->msg;\n\n\t\t\tif (uwq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tfork_nctx = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tuwq->msg.arg.reserved.reserved1;\n\t\t\t\tlist_move(&uwq->wq.entry, &fork_event);\n\t\t\t\tspin_unlock(&ctx->event_wqh.lock);\n\t\t\t\tret = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tuserfaultfd_event_complete(ctx, uwq);\n\t\t\tspin_unlock(&ctx->event_wqh.lock);\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\tif (signal_pending(current)) {\n\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (no_wait) {\n\t\t\tret = -EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->fd_wqh.lock);\n\t\tschedule();\n\t\tspin_lock(&ctx->fd_wqh.lock);\n\t}\n\t__remove_wait_queue(&ctx->fd_wqh, &wait);\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->fd_wqh.lock);\n\n\tif (!ret && msg->event == UFFD_EVENT_FORK) {\n\t\tret = resolve_userfault_fork(ctx, fork_nctx, msg);\n\n\t\tif (!ret) {\n\t\t\tspin_lock(&ctx->event_wqh.lock);\n\t\t\tif (!list_empty(&fork_event)) {\n\t\t\t\tuwq = list_first_entry(&fork_event,\n\t\t\t\t\t\t       typeof(*uwq),\n\t\t\t\t\t\t       wq.entry);\n\t\t\t\tlist_del(&uwq->wq.entry);\n\t\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);\n\t\t\t\tuserfaultfd_event_complete(ctx, uwq);\n\t\t\t}\n\t\t\tspin_unlock(&ctx->event_wqh.lock);\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static ssize_t userfaultfd_ctx_read(struct userfaultfd_ctx *ctx, int no_wait,\n\t\t\t\t    struct uffd_msg *msg)\n{\n\tssize_t ret;\n\tDECLARE_WAITQUEUE(wait, current);\n\tstruct userfaultfd_wait_queue *uwq;\n\t/*\n\t * Handling fork event requires sleeping operations, so\n\t * we drop the event_wqh lock, then do these ops, then\n\t * lock it back and wake up the waiter. While the lock is\n\t * dropped the ewq may go away so we keep track of it\n\t * carefully.\n\t */\n\tLIST_HEAD(fork_event);\n\tstruct userfaultfd_ctx *fork_nctx = NULL;\n\n\t/* always take the fd_wqh lock before the fault_pending_wqh lock */\n\tspin_lock(&ctx->fd_wqh.lock);\n\t__add_wait_queue(&ctx->fd_wqh, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tspin_lock(&ctx->fault_pending_wqh.lock);\n\t\tuwq = find_userfault(ctx);\n\t\tif (uwq) {\n\t\t\t/*\n\t\t\t * Use a seqcount to repeat the lockless check\n\t\t\t * in wake_userfault() to avoid missing\n\t\t\t * wakeups because during the refile both\n\t\t\t * waitqueue could become empty if this is the\n\t\t\t * only userfault.\n\t\t\t */\n\t\t\twrite_seqcount_begin(&ctx->refile_seq);\n\n\t\t\t/*\n\t\t\t * The fault_pending_wqh.lock prevents the uwq\n\t\t\t * to disappear from under us.\n\t\t\t *\n\t\t\t * Refile this userfault from\n\t\t\t * fault_pending_wqh to fault_wqh, it's not\n\t\t\t * pending anymore after we read it.\n\t\t\t *\n\t\t\t * Use list_del() by hand (as\n\t\t\t * userfaultfd_wake_function also uses\n\t\t\t * list_del_init() by hand) to be sure nobody\n\t\t\t * changes __remove_wait_queue() to use\n\t\t\t * list_del_init() in turn breaking the\n\t\t\t * !list_empty_careful() check in\n\t\t\t * handle_userfault(). The uwq->wq.head list\n\t\t\t * must never be empty at any time during the\n\t\t\t * refile, or the waitqueue could disappear\n\t\t\t * from under us. The \"wait_queue_head_t\"\n\t\t\t * parameter of __remove_wait_queue() is unused\n\t\t\t * anyway.\n\t\t\t */\n\t\t\tlist_del(&uwq->wq.entry);\n\t\t\t__add_wait_queue(&ctx->fault_wqh, &uwq->wq);\n\n\t\t\twrite_seqcount_end(&ctx->refile_seq);\n\n\t\t\t/* careful to always initialize msg if ret == 0 */\n\t\t\t*msg = uwq->msg;\n\t\t\tspin_unlock(&ctx->fault_pending_wqh.lock);\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->fault_pending_wqh.lock);\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t\tuwq = find_userfault_evt(ctx);\n\t\tif (uwq) {\n\t\t\t*msg = uwq->msg;\n\n\t\t\tif (uwq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tfork_nctx = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tuwq->msg.arg.reserved.reserved1;\n\t\t\t\tlist_move(&uwq->wq.entry, &fork_event);\n\t\t\t\t/*\n\t\t\t\t * fork_nctx can be freed as soon as\n\t\t\t\t * we drop the lock, unless we take a\n\t\t\t\t * reference on it.\n\t\t\t\t */\n\t\t\t\tuserfaultfd_ctx_get(fork_nctx);\n\t\t\t\tspin_unlock(&ctx->event_wqh.lock);\n\t\t\t\tret = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tuserfaultfd_event_complete(ctx, uwq);\n\t\t\tspin_unlock(&ctx->event_wqh.lock);\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\tif (signal_pending(current)) {\n\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (no_wait) {\n\t\t\tret = -EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&ctx->fd_wqh.lock);\n\t\tschedule();\n\t\tspin_lock(&ctx->fd_wqh.lock);\n\t}\n\t__remove_wait_queue(&ctx->fd_wqh, &wait);\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->fd_wqh.lock);\n\n\tif (!ret && msg->event == UFFD_EVENT_FORK) {\n\t\tret = resolve_userfault_fork(ctx, fork_nctx, msg);\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t\tif (!list_empty(&fork_event)) {\n\t\t\t/*\n\t\t\t * The fork thread didn't abort, so we can\n\t\t\t * drop the temporary refcount.\n\t\t\t */\n\t\t\tuserfaultfd_ctx_put(fork_nctx);\n\n\t\t\tuwq = list_first_entry(&fork_event,\n\t\t\t\t\t       typeof(*uwq),\n\t\t\t\t\t       wq.entry);\n\t\t\t/*\n\t\t\t * If fork_event list wasn't empty and in turn\n\t\t\t * the event wasn't already released by fork\n\t\t\t * (the event is allocated on fork kernel\n\t\t\t * stack), put the event back to its place in\n\t\t\t * the event_wq. fork_event head will be freed\n\t\t\t * as soon as we return so the event cannot\n\t\t\t * stay queued there no matter the current\n\t\t\t * \"ret\" value.\n\t\t\t */\n\t\t\tlist_del(&uwq->wq.entry);\n\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);\n\n\t\t\t/*\n\t\t\t * Leave the event in the waitqueue and report\n\t\t\t * error to userland if we failed to resolve\n\t\t\t * the userfault fork.\n\t\t\t */\n\t\t\tif (likely(!ret))\n\t\t\t\tuserfaultfd_event_complete(ctx, uwq);\n\t\t} else {\n\t\t\t/*\n\t\t\t * Here the fork thread aborted and the\n\t\t\t * refcount from the fork thread on fork_nctx\n\t\t\t * has already been released. We still hold\n\t\t\t * the reference we took before releasing the\n\t\t\t * lock above. If resolve_userfault_fork\n\t\t\t * failed we've to drop it because the\n\t\t\t * fork_nctx has to be freed in such case. If\n\t\t\t * it succeeded we'll hold it because the new\n\t\t\t * uffd references it.\n\t\t\t */\n\t\t\tif (ret)\n\t\t\t\tuserfaultfd_ctx_put(fork_nctx);\n\t\t}\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -75,6 +75,12 @@\n \t\t\t\t\t(unsigned long)\n \t\t\t\t\tuwq->msg.arg.reserved.reserved1;\n \t\t\t\tlist_move(&uwq->wq.entry, &fork_event);\n+\t\t\t\t/*\n+\t\t\t\t * fork_nctx can be freed as soon as\n+\t\t\t\t * we drop the lock, unless we take a\n+\t\t\t\t * reference on it.\n+\t\t\t\t */\n+\t\t\t\tuserfaultfd_ctx_get(fork_nctx);\n \t\t\t\tspin_unlock(&ctx->event_wqh.lock);\n \t\t\t\tret = 0;\n \t\t\t\tbreak;\n@@ -105,19 +111,53 @@\n \n \tif (!ret && msg->event == UFFD_EVENT_FORK) {\n \t\tret = resolve_userfault_fork(ctx, fork_nctx, msg);\n+\t\tspin_lock(&ctx->event_wqh.lock);\n+\t\tif (!list_empty(&fork_event)) {\n+\t\t\t/*\n+\t\t\t * The fork thread didn't abort, so we can\n+\t\t\t * drop the temporary refcount.\n+\t\t\t */\n+\t\t\tuserfaultfd_ctx_put(fork_nctx);\n \n-\t\tif (!ret) {\n-\t\t\tspin_lock(&ctx->event_wqh.lock);\n-\t\t\tif (!list_empty(&fork_event)) {\n-\t\t\t\tuwq = list_first_entry(&fork_event,\n-\t\t\t\t\t\t       typeof(*uwq),\n-\t\t\t\t\t\t       wq.entry);\n-\t\t\t\tlist_del(&uwq->wq.entry);\n-\t\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);\n+\t\t\tuwq = list_first_entry(&fork_event,\n+\t\t\t\t\t       typeof(*uwq),\n+\t\t\t\t\t       wq.entry);\n+\t\t\t/*\n+\t\t\t * If fork_event list wasn't empty and in turn\n+\t\t\t * the event wasn't already released by fork\n+\t\t\t * (the event is allocated on fork kernel\n+\t\t\t * stack), put the event back to its place in\n+\t\t\t * the event_wq. fork_event head will be freed\n+\t\t\t * as soon as we return so the event cannot\n+\t\t\t * stay queued there no matter the current\n+\t\t\t * \"ret\" value.\n+\t\t\t */\n+\t\t\tlist_del(&uwq->wq.entry);\n+\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);\n+\n+\t\t\t/*\n+\t\t\t * Leave the event in the waitqueue and report\n+\t\t\t * error to userland if we failed to resolve\n+\t\t\t * the userfault fork.\n+\t\t\t */\n+\t\t\tif (likely(!ret))\n \t\t\t\tuserfaultfd_event_complete(ctx, uwq);\n-\t\t\t}\n-\t\t\tspin_unlock(&ctx->event_wqh.lock);\n+\t\t} else {\n+\t\t\t/*\n+\t\t\t * Here the fork thread aborted and the\n+\t\t\t * refcount from the fork thread on fork_nctx\n+\t\t\t * has already been released. We still hold\n+\t\t\t * the reference we took before releasing the\n+\t\t\t * lock above. If resolve_userfault_fork\n+\t\t\t * failed we've to drop it because the\n+\t\t\t * fork_nctx has to be freed in such case. If\n+\t\t\t * it succeeded we'll hold it because the new\n+\t\t\t * uffd references it.\n+\t\t\t */\n+\t\t\tif (ret)\n+\t\t\t\tuserfaultfd_ctx_put(fork_nctx);\n \t\t}\n+\t\tspin_unlock(&ctx->event_wqh.lock);\n \t}\n \n \treturn ret;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t/*",
                "\t\t\t\t * fork_nctx can be freed as soon as",
                "\t\t\t\t * we drop the lock, unless we take a",
                "\t\t\t\t * reference on it.",
                "\t\t\t\t */",
                "\t\t\t\tuserfaultfd_ctx_get(fork_nctx);",
                "\t\tspin_lock(&ctx->event_wqh.lock);",
                "\t\tif (!list_empty(&fork_event)) {",
                "\t\t\t/*",
                "\t\t\t * The fork thread didn't abort, so we can",
                "\t\t\t * drop the temporary refcount.",
                "\t\t\t */",
                "\t\t\tuserfaultfd_ctx_put(fork_nctx);",
                "\t\t\tuwq = list_first_entry(&fork_event,",
                "\t\t\t\t\t       typeof(*uwq),",
                "\t\t\t\t\t       wq.entry);",
                "\t\t\t/*",
                "\t\t\t * If fork_event list wasn't empty and in turn",
                "\t\t\t * the event wasn't already released by fork",
                "\t\t\t * (the event is allocated on fork kernel",
                "\t\t\t * stack), put the event back to its place in",
                "\t\t\t * the event_wq. fork_event head will be freed",
                "\t\t\t * as soon as we return so the event cannot",
                "\t\t\t * stay queued there no matter the current",
                "\t\t\t * \"ret\" value.",
                "\t\t\t */",
                "\t\t\tlist_del(&uwq->wq.entry);",
                "\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);",
                "",
                "\t\t\t/*",
                "\t\t\t * Leave the event in the waitqueue and report",
                "\t\t\t * error to userland if we failed to resolve",
                "\t\t\t * the userfault fork.",
                "\t\t\t */",
                "\t\t\tif (likely(!ret))",
                "\t\t} else {",
                "\t\t\t/*",
                "\t\t\t * Here the fork thread aborted and the",
                "\t\t\t * refcount from the fork thread on fork_nctx",
                "\t\t\t * has already been released. We still hold",
                "\t\t\t * the reference we took before releasing the",
                "\t\t\t * lock above. If resolve_userfault_fork",
                "\t\t\t * failed we've to drop it because the",
                "\t\t\t * fork_nctx has to be freed in such case. If",
                "\t\t\t * it succeeded we'll hold it because the new",
                "\t\t\t * uffd references it.",
                "\t\t\t */",
                "\t\t\tif (ret)",
                "\t\t\t\tuserfaultfd_ctx_put(fork_nctx);",
                "\t\tspin_unlock(&ctx->event_wqh.lock);"
            ],
            "deleted": [
                "\t\tif (!ret) {",
                "\t\t\tspin_lock(&ctx->event_wqh.lock);",
                "\t\t\tif (!list_empty(&fork_event)) {",
                "\t\t\t\tuwq = list_first_entry(&fork_event,",
                "\t\t\t\t\t\t       typeof(*uwq),",
                "\t\t\t\t\t\t       wq.entry);",
                "\t\t\t\tlist_del(&uwq->wq.entry);",
                "\t\t\t\t__add_wait_queue(&ctx->event_wqh, &uwq->wq);",
                "\t\t\t}",
                "\t\t\tspin_unlock(&ctx->event_wqh.lock);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A use-after-free flaw was found in fs/userfaultfd.c in the Linux kernel before 4.13.6. The issue is related to the handling of fork failure when dealing with event messages. Failure to fork correctly can lead to a situation where a fork event will be removed from an already freed list of events with userfaultfd_ctx_put().",
        "id": 1298
    },
    {
        "cve_id": "CVE-2016-7425",
        "code_before_change": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\n\t\tstruct scsi_cmnd *cmd)\n{\n\tchar *buffer;\n\tunsigned short use_sg;\n\tint retvalue = 0, transfer_len = 0;\n\tunsigned long flags;\n\tstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\n\tuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n\t\t(uint32_t)cmd->cmnd[6] << 16 |\n\t\t(uint32_t)cmd->cmnd[7] << 8 |\n\t\t(uint32_t)cmd->cmnd[8];\n\tstruct scatterlist *sg;\n\n\tuse_sg = scsi_sg_count(cmd);\n\tsg = scsi_sglist(cmd);\n\tbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\n\tif (use_sg > 1) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tgoto message_out;\n\t}\n\ttransfer_len += sg->length;\n\tif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\n\t\tgoto message_out;\n\t}\n\tpcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\n\tswitch (controlcode) {\n\tcase ARCMSR_MESSAGE_READ_RQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint8_t *ptmpQbuffer;\n\t\tuint32_t allxfer_len = 0;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tpr_info(\"%s: memory not enough!\\n\", __func__);\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpQbuffer = ver_addr;\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\n\t\t\tunsigned int tail = acb->rqbuf_getIndex;\n\t\t\tunsigned int head = acb->rqbuf_putIndex;\n\t\t\tunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\n\n\t\t\tallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\n\t\t\tif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\n\t\t\t\tallxfer_len = ARCMSR_API_DATA_BUFLEN;\n\n\t\t\tif (allxfer_len <= cnt_to_end)\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\n\t\t\telse {\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\n\t\t\t\tmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n\t\t\t}\n\t\t\tacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n\t\t}\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\n\t\t\tallxfer_len);\n\t\tif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\n\t\t\tstruct QBUFFER __iomem *prbuffer;\n\t\t\tacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\n\t\t\tprbuffer = arcmsr_get_iop_rqbuffer(acb);\n\t\t\tif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\n\t\t\t\tacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tpcmdmessagefld->cmdmessage.Length = allxfer_len;\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tint32_t user_len, cnt2end;\n\t\tuint8_t *pQbuffer, *ptmpuserbuffer;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpuserbuffer = ver_addr;\n\t\tuser_len = pcmdmessagefld->cmdmessage.Length;\n\t\tmemcpy(ptmpuserbuffer,\n\t\t\tpcmdmessagefld->messagedatabuffer, user_len);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\n\t\t\tstruct SENSE_DATA *sensebuffer =\n\t\t\t\t(struct SENSE_DATA *)cmd->sense_buffer;\n\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t/* has error report sensedata */\n\t\t\tsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\n\t\t\tsensebuffer->SenseKey = ILLEGAL_REQUEST;\n\t\t\tsensebuffer->AdditionalSenseLength = 0x0A;\n\t\t\tsensebuffer->AdditionalSenseCode = 0x20;\n\t\t\tsensebuffer->Valid = 1;\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t} else {\n\t\t\tpQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\n\t\t\tcnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\n\t\t\tif (user_len > cnt2end) {\n\t\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\n\t\t\t\tptmpuserbuffer += cnt2end;\n\t\t\t\tuser_len -= cnt2end;\n\t\t\t\tacb->wqbuf_putIndex = 0;\n\t\t\t\tpQbuffer = acb->wqbuffer;\n\t\t\t}\n\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, user_len);\n\t\t\tacb->wqbuf_putIndex += user_len;\n\t\t\tacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\n\t\t\tif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\n\t\t\t\tacb->acb_flags &=\n\t\t\t\t\t\t~ACB_F_MESSAGE_WQBUFFER_CLEARED;\n\t\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->rqbuffer;\n\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->wqbuffer;\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\n\t\tuint8_t *pQbuffer;\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tpQbuffer = acb->rqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tpQbuffer = acb->wqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_RETURN_CODE_3F: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_3F;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_HELLO: {\n\t\tint8_t *hello_string = \"Hello! I am ARCMSR\";\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer,\n\t\t\thello_string, (int16_t)strlen(hello_string));\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_GOODBYE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_iop_parking(acb);\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_flush_adapter_cache(acb);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: unknown controlcode!\\n\", __func__);\n\t}\nmessage_out:\n\tif (use_sg) {\n\t\tstruct scatterlist *sg = scsi_sglist(cmd);\n\t\tkunmap_atomic(buffer - sg->offset);\n\t}\n\treturn retvalue;\n}",
        "code_after_change": "static int arcmsr_iop_message_xfer(struct AdapterControlBlock *acb,\n\t\tstruct scsi_cmnd *cmd)\n{\n\tchar *buffer;\n\tunsigned short use_sg;\n\tint retvalue = 0, transfer_len = 0;\n\tunsigned long flags;\n\tstruct CMD_MESSAGE_FIELD *pcmdmessagefld;\n\tuint32_t controlcode = (uint32_t)cmd->cmnd[5] << 24 |\n\t\t(uint32_t)cmd->cmnd[6] << 16 |\n\t\t(uint32_t)cmd->cmnd[7] << 8 |\n\t\t(uint32_t)cmd->cmnd[8];\n\tstruct scatterlist *sg;\n\n\tuse_sg = scsi_sg_count(cmd);\n\tsg = scsi_sglist(cmd);\n\tbuffer = kmap_atomic(sg_page(sg)) + sg->offset;\n\tif (use_sg > 1) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tgoto message_out;\n\t}\n\ttransfer_len += sg->length;\n\tif (transfer_len > sizeof(struct CMD_MESSAGE_FIELD)) {\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: ARCMSR_MESSAGE_FAIL!\\n\", __func__);\n\t\tgoto message_out;\n\t}\n\tpcmdmessagefld = (struct CMD_MESSAGE_FIELD *)buffer;\n\tswitch (controlcode) {\n\tcase ARCMSR_MESSAGE_READ_RQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint8_t *ptmpQbuffer;\n\t\tuint32_t allxfer_len = 0;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tpr_info(\"%s: memory not enough!\\n\", __func__);\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpQbuffer = ver_addr;\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tif (acb->rqbuf_getIndex != acb->rqbuf_putIndex) {\n\t\t\tunsigned int tail = acb->rqbuf_getIndex;\n\t\t\tunsigned int head = acb->rqbuf_putIndex;\n\t\t\tunsigned int cnt_to_end = CIRC_CNT_TO_END(head, tail, ARCMSR_MAX_QBUFFER);\n\n\t\t\tallxfer_len = CIRC_CNT(head, tail, ARCMSR_MAX_QBUFFER);\n\t\t\tif (allxfer_len > ARCMSR_API_DATA_BUFLEN)\n\t\t\t\tallxfer_len = ARCMSR_API_DATA_BUFLEN;\n\n\t\t\tif (allxfer_len <= cnt_to_end)\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, allxfer_len);\n\t\t\telse {\n\t\t\t\tmemcpy(ptmpQbuffer, acb->rqbuffer + tail, cnt_to_end);\n\t\t\t\tmemcpy(ptmpQbuffer + cnt_to_end, acb->rqbuffer, allxfer_len - cnt_to_end);\n\t\t\t}\n\t\t\tacb->rqbuf_getIndex = (acb->rqbuf_getIndex + allxfer_len) % ARCMSR_MAX_QBUFFER;\n\t\t}\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer, ver_addr,\n\t\t\tallxfer_len);\n\t\tif (acb->acb_flags & ACB_F_IOPDATA_OVERFLOW) {\n\t\t\tstruct QBUFFER __iomem *prbuffer;\n\t\t\tacb->acb_flags &= ~ACB_F_IOPDATA_OVERFLOW;\n\t\t\tprbuffer = arcmsr_get_iop_rqbuffer(acb);\n\t\t\tif (arcmsr_Read_iop_rqbuffer_data(acb, prbuffer) == 0)\n\t\t\t\tacb->acb_flags |= ACB_F_IOPDATA_OVERFLOW;\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tpcmdmessagefld->cmdmessage.Length = allxfer_len;\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\n\t\tunsigned char *ver_addr;\n\t\tuint32_t user_len;\n\t\tint32_t cnt2end;\n\t\tuint8_t *pQbuffer, *ptmpuserbuffer;\n\t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n\t\tif (!ver_addr) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tgoto message_out;\n\t\t}\n\t\tptmpuserbuffer = ver_addr;\n\t\tuser_len = pcmdmessagefld->cmdmessage.Length;\n\t\tif (user_len > ARCMSR_API_DATA_BUFLEN) {\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t\tkfree(ver_addr);\n\t\t\tgoto message_out;\n\t\t}\n\t\tmemcpy(ptmpuserbuffer,\n\t\t\tpcmdmessagefld->messagedatabuffer, user_len);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tif (acb->wqbuf_putIndex != acb->wqbuf_getIndex) {\n\t\t\tstruct SENSE_DATA *sensebuffer =\n\t\t\t\t(struct SENSE_DATA *)cmd->sense_buffer;\n\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t/* has error report sensedata */\n\t\t\tsensebuffer->ErrorCode = SCSI_SENSE_CURRENT_ERRORS;\n\t\t\tsensebuffer->SenseKey = ILLEGAL_REQUEST;\n\t\t\tsensebuffer->AdditionalSenseLength = 0x0A;\n\t\t\tsensebuffer->AdditionalSenseCode = 0x20;\n\t\t\tsensebuffer->Valid = 1;\n\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\t} else {\n\t\t\tpQbuffer = &acb->wqbuffer[acb->wqbuf_putIndex];\n\t\t\tcnt2end = ARCMSR_MAX_QBUFFER - acb->wqbuf_putIndex;\n\t\t\tif (user_len > cnt2end) {\n\t\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, cnt2end);\n\t\t\t\tptmpuserbuffer += cnt2end;\n\t\t\t\tuser_len -= cnt2end;\n\t\t\t\tacb->wqbuf_putIndex = 0;\n\t\t\t\tpQbuffer = acb->wqbuffer;\n\t\t\t}\n\t\t\tmemcpy(pQbuffer, ptmpuserbuffer, user_len);\n\t\t\tacb->wqbuf_putIndex += user_len;\n\t\t\tacb->wqbuf_putIndex %= ARCMSR_MAX_QBUFFER;\n\t\t\tif (acb->acb_flags & ACB_F_MESSAGE_WQBUFFER_CLEARED) {\n\t\t\t\tacb->acb_flags &=\n\t\t\t\t\t\t~ACB_F_MESSAGE_WQBUFFER_CLEARED;\n\t\t\t\tarcmsr_write_ioctldata2iop(acb);\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tkfree(ver_addr);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_RQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->rqbuffer;\n\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_WQBUFFER: {\n\t\tuint8_t *pQbuffer = acb->wqbuffer;\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tmemset(pQbuffer, 0, ARCMSR_MAX_QBUFFER);\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_CLEAR_ALLQBUFFER: {\n\t\tuint8_t *pQbuffer;\n\t\tarcmsr_clear_iop2drv_rqueue_buffer(acb);\n\t\tspin_lock_irqsave(&acb->rqbuffer_lock, flags);\n\t\tacb->acb_flags |= ACB_F_MESSAGE_RQBUFFER_CLEARED;\n\t\tacb->rqbuf_getIndex = 0;\n\t\tacb->rqbuf_putIndex = 0;\n\t\tpQbuffer = acb->rqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->rqbuffer_lock, flags);\n\t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);\n\t\tacb->acb_flags |= (ACB_F_MESSAGE_WQBUFFER_CLEARED |\n\t\t\tACB_F_MESSAGE_WQBUFFER_READED);\n\t\tacb->wqbuf_getIndex = 0;\n\t\tacb->wqbuf_putIndex = 0;\n\t\tpQbuffer = acb->wqbuffer;\n\t\tmemset(pQbuffer, 0, sizeof(struct QBUFFER));\n\t\tspin_unlock_irqrestore(&acb->wqbuffer_lock, flags);\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_RETURN_CODE_3F: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_3F;\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_HELLO: {\n\t\tint8_t *hello_string = \"Hello! I am ARCMSR\";\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tmemcpy(pcmdmessagefld->messagedatabuffer,\n\t\t\thello_string, (int16_t)strlen(hello_string));\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_SAY_GOODBYE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_iop_parking(acb);\n\t\tbreak;\n\t}\n\tcase ARCMSR_MESSAGE_FLUSH_ADAPTER_CACHE: {\n\t\tif (acb->fw_flag == FW_DEADLOCK)\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_BUS_HANG_ON;\n\t\telse\n\t\t\tpcmdmessagefld->cmdmessage.ReturnCode =\n\t\t\t\tARCMSR_MESSAGE_RETURNCODE_OK;\n\t\tarcmsr_flush_adapter_cache(acb);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n\t\tpr_info(\"%s: unknown controlcode!\\n\", __func__);\n\t}\nmessage_out:\n\tif (use_sg) {\n\t\tstruct scatterlist *sg = scsi_sglist(cmd);\n\t\tkunmap_atomic(buffer - sg->offset);\n\t}\n\treturn retvalue;\n}",
        "patch": "--- code before\n+++ code after\n@@ -78,7 +78,8 @@\n \t}\n \tcase ARCMSR_MESSAGE_WRITE_WQBUFFER: {\n \t\tunsigned char *ver_addr;\n-\t\tint32_t user_len, cnt2end;\n+\t\tuint32_t user_len;\n+\t\tint32_t cnt2end;\n \t\tuint8_t *pQbuffer, *ptmpuserbuffer;\n \t\tver_addr = kmalloc(ARCMSR_API_DATA_BUFLEN, GFP_ATOMIC);\n \t\tif (!ver_addr) {\n@@ -87,6 +88,11 @@\n \t\t}\n \t\tptmpuserbuffer = ver_addr;\n \t\tuser_len = pcmdmessagefld->cmdmessage.Length;\n+\t\tif (user_len > ARCMSR_API_DATA_BUFLEN) {\n+\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;\n+\t\t\tkfree(ver_addr);\n+\t\t\tgoto message_out;\n+\t\t}\n \t\tmemcpy(ptmpuserbuffer,\n \t\t\tpcmdmessagefld->messagedatabuffer, user_len);\n \t\tspin_lock_irqsave(&acb->wqbuffer_lock, flags);",
        "function_modified_lines": {
            "added": [
                "\t\tuint32_t user_len;",
                "\t\tint32_t cnt2end;",
                "\t\tif (user_len > ARCMSR_API_DATA_BUFLEN) {",
                "\t\t\tretvalue = ARCMSR_MESSAGE_FAIL;",
                "\t\t\tkfree(ver_addr);",
                "\t\t\tgoto message_out;",
                "\t\t}"
            ],
            "deleted": [
                "\t\tint32_t user_len, cnt2end;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The arcmsr_iop_message_xfer function in drivers/scsi/arcmsr/arcmsr_hba.c in the Linux kernel through 4.8.2 does not restrict a certain length field, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) via an ARCMSR_MESSAGE_WRITE_WQBUFFER control code.",
        "id": 1108
    },
    {
        "cve_id": "CVE-2013-0310",
        "code_before_change": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\n\tunsigned char *opt = *option;\n\tunsigned char *tag;\n\tunsigned char opt_iter;\n\tunsigned char err_offset = 0;\n\tu8 opt_len;\n\tu8 tag_len;\n\tstruct cipso_v4_doi *doi_def = NULL;\n\tu32 tag_iter;\n\n\t/* caller already checks for length values that are too large */\n\topt_len = opt[1];\n\tif (opt_len < 8) {\n\t\terr_offset = 1;\n\t\tgoto validate_return;\n\t}\n\n\trcu_read_lock();\n\tdoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\n\tif (doi_def == NULL) {\n\t\terr_offset = 2;\n\t\tgoto validate_return_locked;\n\t}\n\n\topt_iter = CIPSO_V4_HDR_LEN;\n\ttag = opt + opt_iter;\n\twhile (opt_iter < opt_len) {\n\t\tfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\n\t\t\tif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n\t\t\t    ++tag_iter == CIPSO_V4_TAG_MAXCNT) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\ttag_len = tag[1];\n\t\tif (tag_len > (opt_len - opt_iter)) {\n\t\t\terr_offset = opt_iter + 1;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\tswitch (tag[0]) {\n\t\tcase CIPSO_V4_TAG_RBITMAP:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\t/* We are already going to do all the verification\n\t\t\t * necessary at the socket layer so from our point of\n\t\t\t * view it is safe to turn these checks off (and less\n\t\t\t * work), however, the CIPSO draft says we should do\n\t\t\t * all the CIPSO validations here but it doesn't\n\t\t\t * really specify _exactly_ what we need to validate\n\t\t\t * ... so, just make it a sysctl tunable. */\n\t\t\tif (cipso_v4_rbm_strictvalid) {\n\t\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t\tif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\n\t\t\t\t    cipso_v4_map_cat_rbm_valid(doi_def,\n\t\t\t\t\t\t\t    &tag[4],\n\t\t\t\t\t\t\t    tag_len - 4) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_ENUM:\n\t\t\tif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\n\t\t\t    cipso_v4_map_cat_enum_valid(doi_def,\n\t\t\t\t\t\t\t&tag[4],\n\t\t\t\t\t\t\ttag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_RANGE:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\n\t\t\t    cipso_v4_map_cat_rng_valid(doi_def,\n\t\t\t\t\t\t       &tag[4],\n\t\t\t\t\t\t       tag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_LOCAL:\n\t\t\t/* This is a non-standard tag that we only allow for\n\t\t\t * local connections, so if the incoming interface is\n\t\t\t * not the loopback device drop the packet. */\n\t\t\tif (!(skb->dev->flags & IFF_LOOPBACK)) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr_offset = opt_iter;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\ttag += tag_len;\n\t\topt_iter += tag_len;\n\t}\n\nvalidate_return_locked:\n\trcu_read_unlock();\nvalidate_return:\n\t*option = opt + err_offset;\n\treturn err_offset;\n}",
        "code_after_change": "int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)\n{\n\tunsigned char *opt = *option;\n\tunsigned char *tag;\n\tunsigned char opt_iter;\n\tunsigned char err_offset = 0;\n\tu8 opt_len;\n\tu8 tag_len;\n\tstruct cipso_v4_doi *doi_def = NULL;\n\tu32 tag_iter;\n\n\t/* caller already checks for length values that are too large */\n\topt_len = opt[1];\n\tif (opt_len < 8) {\n\t\terr_offset = 1;\n\t\tgoto validate_return;\n\t}\n\n\trcu_read_lock();\n\tdoi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));\n\tif (doi_def == NULL) {\n\t\terr_offset = 2;\n\t\tgoto validate_return_locked;\n\t}\n\n\topt_iter = CIPSO_V4_HDR_LEN;\n\ttag = opt + opt_iter;\n\twhile (opt_iter < opt_len) {\n\t\tfor (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];)\n\t\t\tif (doi_def->tags[tag_iter] == CIPSO_V4_TAG_INVALID ||\n\t\t\t    ++tag_iter == CIPSO_V4_TAG_MAXCNT) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\ttag_len = tag[1];\n\t\tif (tag_len > (opt_len - opt_iter)) {\n\t\t\terr_offset = opt_iter + 1;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\tswitch (tag[0]) {\n\t\tcase CIPSO_V4_TAG_RBITMAP:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RBM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\t/* We are already going to do all the verification\n\t\t\t * necessary at the socket layer so from our point of\n\t\t\t * view it is safe to turn these checks off (and less\n\t\t\t * work), however, the CIPSO draft says we should do\n\t\t\t * all the CIPSO validations here but it doesn't\n\t\t\t * really specify _exactly_ what we need to validate\n\t\t\t * ... so, just make it a sysctl tunable. */\n\t\t\tif (cipso_v4_rbm_strictvalid) {\n\t\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t\tif (tag_len > CIPSO_V4_TAG_RBM_BLEN &&\n\t\t\t\t    cipso_v4_map_cat_rbm_valid(doi_def,\n\t\t\t\t\t\t\t    &tag[4],\n\t\t\t\t\t\t\t    tag_len - 4) < 0) {\n\t\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\t\tgoto validate_return_locked;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_ENUM:\n\t\t\tif (tag_len < CIPSO_V4_TAG_ENUM_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_ENUM_BLEN &&\n\t\t\t    cipso_v4_map_cat_enum_valid(doi_def,\n\t\t\t\t\t\t\t&tag[4],\n\t\t\t\t\t\t\ttag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_RANGE:\n\t\t\tif (tag_len < CIPSO_V4_TAG_RNG_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\n\t\t\tif (cipso_v4_map_lvl_valid(doi_def,\n\t\t\t\t\t\t   tag[3]) < 0) {\n\t\t\t\terr_offset = opt_iter + 3;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len > CIPSO_V4_TAG_RNG_BLEN &&\n\t\t\t    cipso_v4_map_cat_rng_valid(doi_def,\n\t\t\t\t\t\t       &tag[4],\n\t\t\t\t\t\t       tag_len - 4) < 0) {\n\t\t\t\terr_offset = opt_iter + 4;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CIPSO_V4_TAG_LOCAL:\n\t\t\t/* This is a non-standard tag that we only allow for\n\t\t\t * local connections, so if the incoming interface is\n\t\t\t * not the loopback device drop the packet. Further,\n\t\t\t * there is no legitimate reason for setting this from\n\t\t\t * userspace so reject it if skb is NULL. */\n\t\t\tif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {\n\t\t\t\terr_offset = opt_iter;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tif (tag_len != CIPSO_V4_TAG_LOC_BLEN) {\n\t\t\t\terr_offset = opt_iter + 1;\n\t\t\t\tgoto validate_return_locked;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr_offset = opt_iter;\n\t\t\tgoto validate_return_locked;\n\t\t}\n\n\t\ttag += tag_len;\n\t\topt_iter += tag_len;\n\t}\n\nvalidate_return_locked:\n\trcu_read_unlock();\nvalidate_return:\n\t*option = opt + err_offset;\n\treturn err_offset;\n}",
        "patch": "--- code before\n+++ code after\n@@ -109,8 +109,10 @@\n \t\tcase CIPSO_V4_TAG_LOCAL:\n \t\t\t/* This is a non-standard tag that we only allow for\n \t\t\t * local connections, so if the incoming interface is\n-\t\t\t * not the loopback device drop the packet. */\n-\t\t\tif (!(skb->dev->flags & IFF_LOOPBACK)) {\n+\t\t\t * not the loopback device drop the packet. Further,\n+\t\t\t * there is no legitimate reason for setting this from\n+\t\t\t * userspace so reject it if skb is NULL. */\n+\t\t\tif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {\n \t\t\t\terr_offset = opt_iter;\n \t\t\t\tgoto validate_return_locked;\n \t\t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t * not the loopback device drop the packet. Further,",
                "\t\t\t * there is no legitimate reason for setting this from",
                "\t\t\t * userspace so reject it if skb is NULL. */",
                "\t\t\tif (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {"
            ],
            "deleted": [
                "\t\t\t * not the loopback device drop the packet. */",
                "\t\t\tif (!(skb->dev->flags & IFF_LOOPBACK)) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The cipso_v4_validate function in net/ipv4/cipso_ipv4.c in the Linux kernel before 3.4.8 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via an IPOPT_CIPSO IP_OPTIONS setsockopt system call.",
        "id": 157
    },
    {
        "cve_id": "CVE-2016-4998",
        "code_before_change": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "code_after_change": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -26,7 +26,8 @@\n \tif (!arp_checkentry(&e->arp))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "function_modified_lines": {
            "added": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ],
            "deleted": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The IPT_SO_SET_REPLACE setsockopt implementation in the netfilter subsystem in the Linux kernel before 4.6 allows local users to cause a denial of service (out-of-bounds read) or possibly obtain sensitive information from kernel heap memory by leveraging in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.",
        "id": 1046
    },
    {
        "cve_id": "CVE-2017-5548",
        "code_before_change": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tunsigned char buffer[3];\n\tint ret;\n\n\t/* Get a couple of the ATMega Firmware values */\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuffer, 3, 1000);\n\tif (ret >= 0) {\n\t\tatusb->fw_ver_maj = buffer[0];\n\t\tatusb->fw_ver_min = buffer[1];\n\t\tatusb->fw_hw_type = buffer[2];\n\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n\t}\n\tif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware version (%u.%u) predates our first public release.\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min);\n\t\tdev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static int atusb_get_and_show_revision(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tunsigned char *buffer;\n\tint ret;\n\n\tbuffer = kmalloc(3, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\t/* Get a couple of the ATMega Firmware values */\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_ID, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuffer, 3, 1000);\n\tif (ret >= 0) {\n\t\tatusb->fw_ver_maj = buffer[0];\n\t\tatusb->fw_ver_min = buffer[1];\n\t\tatusb->fw_hw_type = buffer[2];\n\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware: major: %u, minor: %u, hardware type: %u\\n\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min, atusb->fw_hw_type);\n\t}\n\tif (atusb->fw_ver_maj == 0 && atusb->fw_ver_min < 2) {\n\t\tdev_info(&usb_dev->dev,\n\t\t\t \"Firmware version (%u.%u) predates our first public release.\",\n\t\t\t atusb->fw_ver_maj, atusb->fw_ver_min);\n\t\tdev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n\t}\n\n\tkfree(buffer);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,12 @@\n static int atusb_get_and_show_revision(struct atusb *atusb)\n {\n \tstruct usb_device *usb_dev = atusb->usb_dev;\n-\tunsigned char buffer[3];\n+\tunsigned char *buffer;\n \tint ret;\n+\n+\tbuffer = kmalloc(3, GFP_KERNEL);\n+\tif (!buffer)\n+\t\treturn -ENOMEM;\n \n \t/* Get a couple of the ATMega Firmware values */\n \tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n@@ -24,5 +28,6 @@\n \t\tdev_info(&usb_dev->dev, \"Please update to version 0.2 or newer\");\n \t}\n \n+\tkfree(buffer);\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tunsigned char *buffer;",
                "",
                "\tbuffer = kmalloc(3, GFP_KERNEL);",
                "\tif (!buffer)",
                "\t\treturn -ENOMEM;",
                "\tkfree(buffer);"
            ],
            "deleted": [
                "\tunsigned char buffer[3];"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/ieee802154/atusb.c in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1463
    },
    {
        "cve_id": "CVE-2012-6712",
        "code_before_change": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\n\t\t\t\t    struct iwl_addsta_cmd *addsta,\n\t\t\t\t    struct iwl_rx_packet *pkt)\n{\n\tu8 sta_id = addsta->sta.sta_id;\n\tunsigned long flags;\n\tint ret = -EIO;\n\n\tif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\n\t\tIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\n\t\t\tpkt->hdr.flags);\n\t\treturn ret;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\n\t\t       sta_id);\n\n\tspin_lock_irqsave(&priv->shrd->sta_lock, flags);\n\n\tswitch (pkt->u.add_sta.status) {\n\tcase ADD_STA_SUCCESS_MSK:\n\t\tIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\n\t\tiwl_sta_ucode_activate(priv, sta_id);\n\t\tret = 0;\n\t\tbreak;\n\tcase ADD_STA_NO_ROOM_IN_TABLE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_BLOCK_ACK_RESOURCE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\t\t\t\"resource.\\n\", sta_id);\n\t\tbreak;\n\tcase ADD_STA_MODIFY_NON_EXIST_STA:\n\t\tIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tdefault:\n\t\tIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\n\t\t\t\tpkt->u.add_sta.status);\n\t\tbreak;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\n\t\t       sta_id, priv->stations[sta_id].sta.sta.addr);\n\n\t/*\n\t * XXX: The MAC address in the command buffer is often changed from\n\t * the original sent to the device. That is, the MAC address\n\t * written to the command buffer often is not the same MAC address\n\t * read from the command buffer when the command returns. This\n\t * issue has not yet been resolved and this debugging is left to\n\t * observe the problem.\n\t */\n\tIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\n\t\t       addsta->sta.addr);\n\tspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\n\n\treturn ret;\n}",
        "code_after_change": "static int iwl_process_add_sta_resp(struct iwl_priv *priv,\n\t\t\t\t    struct iwl_addsta_cmd *addsta,\n\t\t\t\t    struct iwl_rx_packet *pkt)\n{\n\tu8 sta_id = addsta->sta.sta_id;\n\tunsigned long flags;\n\tint ret = -EIO;\n\n\tif (pkt->hdr.flags & IWL_CMD_FAILED_MSK) {\n\t\tIWL_ERR(priv, \"Bad return from REPLY_ADD_STA (0x%08X)\\n\",\n\t\t\tpkt->hdr.flags);\n\t\treturn ret;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"Processing response for adding station %u\\n\",\n\t\t       sta_id);\n\n\tspin_lock_irqsave(&priv->shrd->sta_lock, flags);\n\n\tswitch (pkt->u.add_sta.status) {\n\tcase ADD_STA_SUCCESS_MSK:\n\t\tIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\n\t\tret = iwl_sta_ucode_activate(priv, sta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_ROOM_IN_TABLE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tcase ADD_STA_NO_BLOCK_ACK_RESOURCE:\n\t\tIWL_ERR(priv, \"Adding station %d failed, no block ack \"\n\t\t\t\"resource.\\n\", sta_id);\n\t\tbreak;\n\tcase ADD_STA_MODIFY_NON_EXIST_STA:\n\t\tIWL_ERR(priv, \"Attempting to modify non-existing station %d\\n\",\n\t\t\tsta_id);\n\t\tbreak;\n\tdefault:\n\t\tIWL_DEBUG_ASSOC(priv, \"Received REPLY_ADD_STA:(0x%08X)\\n\",\n\t\t\t\tpkt->u.add_sta.status);\n\t\tbreak;\n\t}\n\n\tIWL_DEBUG_INFO(priv, \"%s station id %u addr %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ?  \"Modified\" : \"Added\",\n\t\t       sta_id, priv->stations[sta_id].sta.sta.addr);\n\n\t/*\n\t * XXX: The MAC address in the command buffer is often changed from\n\t * the original sent to the device. That is, the MAC address\n\t * written to the command buffer often is not the same MAC address\n\t * read from the command buffer when the command returns. This\n\t * issue has not yet been resolved and this debugging is left to\n\t * observe the problem.\n\t */\n\tIWL_DEBUG_INFO(priv, \"%s station according to cmd buffer %pM\\n\",\n\t\t       priv->stations[sta_id].sta.mode ==\n\t\t       STA_CONTROL_MODIFY_MSK ? \"Modified\" : \"Added\",\n\t\t       addsta->sta.addr);\n\tspin_unlock_irqrestore(&priv->shrd->sta_lock, flags);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,8 +20,7 @@\n \tswitch (pkt->u.add_sta.status) {\n \tcase ADD_STA_SUCCESS_MSK:\n \t\tIWL_DEBUG_INFO(priv, \"REPLY_ADD_STA PASSED\\n\");\n-\t\tiwl_sta_ucode_activate(priv, sta_id);\n-\t\tret = 0;\n+\t\tret = iwl_sta_ucode_activate(priv, sta_id);\n \t\tbreak;\n \tcase ADD_STA_NO_ROOM_IN_TABLE:\n \t\tIWL_ERR(priv, \"Adding station %d failed, no room in table.\\n\",",
        "function_modified_lines": {
            "added": [
                "\t\tret = iwl_sta_ucode_activate(priv, sta_id);"
            ],
            "deleted": [
                "\t\tiwl_sta_ucode_activate(priv, sta_id);",
                "\t\tret = 0;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 3.4, a buffer overflow occurs in drivers/net/wireless/iwlwifi/iwl-agn-sta.c, which will cause at least memory corruption.",
        "id": 143
    },
    {
        "cve_id": "CVE-2017-16996",
        "code_before_change": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tint err;\n\n\tif (opcode == BPF_END || opcode == BPF_NEG) {\n\t\tif (opcode == BPF_NEG) {\n\t\t\tif (BPF_SRC(insn->code) != 0 ||\n\t\t\t    insn->src_reg != BPF_REG_0 ||\n\t\t\t    insn->off != 0 || insn->imm != 0) {\n\t\t\t\tverbose(env, \"BPF_NEG uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n\t\t\t    (insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\n\t\t\t    BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\tverbose(env, \"BPF_END uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->dst_reg)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic prohibited\\n\",\n\t\t\t\tinsn->dst_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t} else if (opcode == BPF_MOV) {\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/* check src operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t/* case: R1 = R2\n\t\t\t\t * copy register state to dest reg\n\t\t\t\t */\n\t\t\t\tregs[insn->dst_reg] = regs[insn->src_reg];\n\t\t\t\tregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n\t\t\t} else {\n\t\t\t\t/* R1 = (u32) R2 */\n\t\t\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\t\t\tverbose(env,\n\t\t\t\t\t\t\"R%d partial copy of pointer\\n\",\n\t\t\t\t\t\tinsn->src_reg);\n\t\t\t\t\treturn -EACCES;\n\t\t\t\t}\n\t\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\t\t/* high 32 bits are known zero. */\n\t\t\t\tregs[insn->dst_reg].var_off = tnum_cast(\n\t\t\t\t\t\tregs[insn->dst_reg].var_off, 4);\n\t\t\t\t__update_reg_bounds(&regs[insn->dst_reg]);\n\t\t\t}\n\t\t} else {\n\t\t\t/* case: R = imm\n\t\t\t * remember the value we stored into this reg\n\t\t\t */\n\t\t\tregs[insn->dst_reg].type = SCALAR_VALUE;\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t insn->imm);\n\t\t\t} else {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t (u32)insn->imm);\n\t\t\t}\n\t\t}\n\n\t} else if (opcode > BPF_END) {\n\t\tverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\n\t} else {\t/* all other ALU ops: and, sub, xor, add, ... */\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t/* check src1 operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src2 operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\n\t\t    BPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\n\t\t\tverbose(env, \"div by zero\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((opcode == BPF_LSH || opcode == BPF_RSH ||\n\t\t     opcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\n\t\t\tint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\n\n\t\t\tif (insn->imm < 0 || insn->imm >= size) {\n\t\t\t\tverbose(env, \"invalid shift %d\\n\", insn->imm);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\treturn adjust_reg_min_max_vals(env, insn);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tint err;\n\n\tif (opcode == BPF_END || opcode == BPF_NEG) {\n\t\tif (opcode == BPF_NEG) {\n\t\t\tif (BPF_SRC(insn->code) != 0 ||\n\t\t\t    insn->src_reg != BPF_REG_0 ||\n\t\t\t    insn->off != 0 || insn->imm != 0) {\n\t\t\t\tverbose(env, \"BPF_NEG uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n\t\t\t    (insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\n\t\t\t    BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\tverbose(env, \"BPF_END uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->dst_reg)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic prohibited\\n\",\n\t\t\t\tinsn->dst_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t} else if (opcode == BPF_MOV) {\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/* check src operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t/* case: R1 = R2\n\t\t\t\t * copy register state to dest reg\n\t\t\t\t */\n\t\t\t\tregs[insn->dst_reg] = regs[insn->src_reg];\n\t\t\t\tregs[insn->dst_reg].live |= REG_LIVE_WRITTEN;\n\t\t\t} else {\n\t\t\t\t/* R1 = (u32) R2 */\n\t\t\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\t\t\tverbose(env,\n\t\t\t\t\t\t\"R%d partial copy of pointer\\n\",\n\t\t\t\t\t\tinsn->src_reg);\n\t\t\t\t\treturn -EACCES;\n\t\t\t\t}\n\t\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\t\tcoerce_reg_to_size(&regs[insn->dst_reg], 4);\n\t\t\t}\n\t\t} else {\n\t\t\t/* case: R = imm\n\t\t\t * remember the value we stored into this reg\n\t\t\t */\n\t\t\tregs[insn->dst_reg].type = SCALAR_VALUE;\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t insn->imm);\n\t\t\t} else {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t (u32)insn->imm);\n\t\t\t}\n\t\t}\n\n\t} else if (opcode > BPF_END) {\n\t\tverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\n\t} else {\t/* all other ALU ops: and, sub, xor, add, ... */\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t/* check src1 operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src2 operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\n\t\t    BPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\n\t\t\tverbose(env, \"div by zero\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((opcode == BPF_LSH || opcode == BPF_RSH ||\n\t\t     opcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\n\t\t\tint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\n\n\t\t\tif (insn->imm < 0 || insn->imm >= size) {\n\t\t\t\tverbose(env, \"invalid shift %d\\n\", insn->imm);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\treturn adjust_reg_min_max_vals(env, insn);\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -77,10 +77,7 @@\n \t\t\t\t\treturn -EACCES;\n \t\t\t\t}\n \t\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n-\t\t\t\t/* high 32 bits are known zero. */\n-\t\t\t\tregs[insn->dst_reg].var_off = tnum_cast(\n-\t\t\t\t\t\tregs[insn->dst_reg].var_off, 4);\n-\t\t\t\t__update_reg_bounds(&regs[insn->dst_reg]);\n+\t\t\t\tcoerce_reg_to_size(&regs[insn->dst_reg], 4);\n \t\t\t}\n \t\t} else {\n \t\t\t/* case: R = imm",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tcoerce_reg_to_size(&regs[insn->dst_reg], 4);"
            ],
            "deleted": [
                "\t\t\t\t/* high 32 bits are known zero. */",
                "\t\t\t\tregs[insn->dst_reg].var_off = tnum_cast(",
                "\t\t\t\t\t\tregs[insn->dst_reg].var_off, 4);",
                "\t\t\t\t__update_reg_bounds(&regs[insn->dst_reg]);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 4.14.8 allows local users to cause a denial of service (memory corruption) or possibly have unspecified other impact by leveraging register truncation mishandling.",
        "id": 1355
    },
    {
        "cve_id": "CVE-2013-2850",
        "code_before_change": "int iscsi_decode_text_input(\n\tu8 phase,\n\tu8 sender,\n\tchar *textbuf,\n\tu32 length,\n\tstruct iscsi_conn *conn)\n{\n\tstruct iscsi_param_list *param_list = conn->param_list;\n\tchar *tmpbuf, *start = NULL, *end = NULL;\n\n\ttmpbuf = kzalloc(length + 1, GFP_KERNEL);\n\tif (!tmpbuf) {\n\t\tpr_err(\"Unable to allocate memory for tmpbuf.\\n\");\n\t\treturn -1;\n\t}\n\n\tmemcpy(tmpbuf, textbuf, length);\n\ttmpbuf[length] = '\\0';\n\tstart = tmpbuf;\n\tend = (start + length);\n\n\twhile (start < end) {\n\t\tchar *key, *value;\n\t\tstruct iscsi_param *param;\n\n\t\tif (iscsi_extract_key_value(start, &key, &value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tpr_debug(\"Got key: %s=%s\\n\", key, value);\n\n\t\tif (phase & PHASE_SECURITY) {\n\t\t\tif (iscsi_check_for_auth_key(key) > 0) {\n\t\t\t\tchar *tmpptr = key + strlen(key);\n\t\t\t\t*tmpptr = '=';\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tparam = iscsi_check_key(key, phase, sender, param_list);\n\t\tif (!param) {\n\t\t\tif (iscsi_add_notunderstood_response(key,\n\t\t\t\t\tvalue, param_list) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tstart += strlen(key) + strlen(value) + 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (iscsi_check_value(param, value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tstart += strlen(key) + strlen(value) + 2;\n\n\t\tif (IS_PSTATE_PROPOSER(param)) {\n\t\t\tif (iscsi_check_proposer_state(param, value) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_RESPONSE_GOT(param);\n\t\t} else {\n\t\t\tif (iscsi_check_acceptor_state(param, value, conn) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_ACCEPTOR(param);\n\t\t}\n\t}\n\n\tkfree(tmpbuf);\n\treturn 0;\n}",
        "code_after_change": "int iscsi_decode_text_input(\n\tu8 phase,\n\tu8 sender,\n\tchar *textbuf,\n\tu32 length,\n\tstruct iscsi_conn *conn)\n{\n\tstruct iscsi_param_list *param_list = conn->param_list;\n\tchar *tmpbuf, *start = NULL, *end = NULL;\n\n\ttmpbuf = kzalloc(length + 1, GFP_KERNEL);\n\tif (!tmpbuf) {\n\t\tpr_err(\"Unable to allocate memory for tmpbuf.\\n\");\n\t\treturn -1;\n\t}\n\n\tmemcpy(tmpbuf, textbuf, length);\n\ttmpbuf[length] = '\\0';\n\tstart = tmpbuf;\n\tend = (start + length);\n\n\twhile (start < end) {\n\t\tchar *key, *value;\n\t\tstruct iscsi_param *param;\n\n\t\tif (iscsi_extract_key_value(start, &key, &value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tpr_debug(\"Got key: %s=%s\\n\", key, value);\n\n\t\tif (phase & PHASE_SECURITY) {\n\t\t\tif (iscsi_check_for_auth_key(key) > 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\n\t\tparam = iscsi_check_key(key, phase, sender, param_list);\n\t\tif (!param) {\n\t\t\tif (iscsi_add_notunderstood_response(key,\n\t\t\t\t\tvalue, param_list) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tstart += strlen(key) + strlen(value) + 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (iscsi_check_value(param, value) < 0) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\tstart += strlen(key) + strlen(value) + 2;\n\n\t\tif (IS_PSTATE_PROPOSER(param)) {\n\t\t\tif (iscsi_check_proposer_state(param, value) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_RESPONSE_GOT(param);\n\t\t} else {\n\t\t\tif (iscsi_check_acceptor_state(param, value, conn) < 0) {\n\t\t\t\tkfree(tmpbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tSET_PSTATE_ACCEPTOR(param);\n\t\t}\n\t}\n\n\tkfree(tmpbuf);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,8 +32,6 @@\n \n \t\tif (phase & PHASE_SECURITY) {\n \t\t\tif (iscsi_check_for_auth_key(key) > 0) {\n-\t\t\t\tchar *tmpptr = key + strlen(key);\n-\t\t\t\t*tmpptr = '=';\n \t\t\t\tkfree(tmpbuf);\n \t\t\t\treturn 1;\n \t\t\t}",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\t\t\tchar *tmpptr = key + strlen(key);",
                "\t\t\t\t*tmpptr = '=';"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the iscsi_add_notunderstood_response function in drivers/target/iscsi/iscsi_target_parameters.c in the iSCSI target subsystem in the Linux kernel through 3.9.4 allows remote attackers to cause a denial of service (memory corruption and OOPS) or possibly execute arbitrary code via a long key that is not properly handled during construction of an error-response packet.",
        "id": 238
    },
    {
        "cve_id": "CVE-2014-3184",
        "code_before_change": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n\t\thid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\n\t\trdesc[30] = 0x0c;\n\t}\n\treturn rdesc;\n}",
        "code_after_change": "static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n\t\thid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\n\t\trdesc[30] = 0x0c;\n\t}\n\treturn rdesc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static __u8 *mr_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n \t\tunsigned int *rsize)\n {\n-\tif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n+\tif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {\n \t\thid_info(hdev, \"fixing up button/consumer in HID report descriptor\\n\");\n \t\trdesc[30] = 0x0c;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (*rsize >= 31 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {"
            ],
            "deleted": [
                "\tif (*rsize >= 30 && rdesc[29] == 0x05 && rdesc[30] == 0x09) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The report_fixup functions in the HID subsystem in the Linux kernel before 3.16.2 might allow physically proximate attackers to cause a denial of service (out-of-bounds write) via a crafted device that provides a small report descriptor, related to (1) drivers/hid/hid-cherry.c, (2) drivers/hid/hid-kye.c, (3) drivers/hid/hid-lg.c, (4) drivers/hid/hid-monterey.c, (5) drivers/hid/hid-petalynx.c, and (6) drivers/hid/hid-sunplus.c.",
        "id": 518
    },
    {
        "cve_id": "CVE-2019-19602",
        "code_before_change": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\n\treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}",
        "code_after_change": "static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n{\n\treturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n static inline int fpregs_state_valid(struct fpu *fpu, unsigned int cpu)\n {\n-\treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n+\treturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n }",
        "function_modified_lines": {
            "added": [
                "\treturn fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;"
            ],
            "deleted": [
                "\treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "fpregs_state_valid in arch/x86/include/asm/fpu/internal.h in the Linux kernel before 5.4.2, when GCC 9 is used, allows context-dependent attackers to cause a denial of service (memory corruption) or possibly have unspecified other impact because of incorrect fpu_fpregs_owner_ctx caching, as demonstrated by mishandling of signal-based non-cooperative preemption in Go 1.14 prereleases on amd64, aka CID-59c4bd853abc.",
        "id": 2222
    },
    {
        "cve_id": "CVE-2022-3636",
        "code_before_change": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\n\tstruct hlist_head *head = &ppe->foe_flow[hash / 2];\n\tstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\n\tstruct mtk_flow_entry *entry;\n\tstruct mtk_foe_bridge key = {};\n\tstruct ethhdr *eh;\n\tbool found = false;\n\tu8 *tag;\n\n\tspin_lock_bh(&ppe_lock);\n\n\tif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\n\t\tgoto out;\n\n\thlist_for_each_entry(entry, head, list) {\n\t\tif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\n\t\t\tif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\n\t\t\t\t     MTK_FOE_STATE_BIND))\n\t\t\t\tcontinue;\n\n\t\t\tentry->hash = 0xffff;\n\t\t\t__mtk_foe_entry_clear(ppe, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (found || !mtk_flow_entry_match(entry, hwe)) {\n\t\t\tif (entry->hash != 0xffff)\n\t\t\t\tentry->hash = 0xffff;\n\t\t\tcontinue;\n\t\t}\n\n\t\tentry->hash = hash;\n\t\t__mtk_foe_entry_commit(ppe, &entry->data, hash);\n\t\tfound = true;\n\t}\n\n\tif (found)\n\t\tgoto out;\n\n\teh = eth_hdr(skb);\n\tether_addr_copy(key.dest_mac, eh->h_dest);\n\tether_addr_copy(key.src_mac, eh->h_source);\n\ttag = skb->data - 2;\n\tkey.vlan = 0;\n\tswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\n\tcase htons(ETH_P_XDSA):\n\t\tif (!netdev_uses_dsa(skb->dev) ||\n\t\t    skb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\n\t\t\tgoto out;\n\n\t\ttag += 4;\n\t\tif (get_unaligned_be16(tag) != ETH_P_8021Q)\n\t\t\tbreak;\n\n\t\tfallthrough;\n#endif\n\tcase htons(ETH_P_8021Q):\n\t\tkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\n\tif (!entry)\n\t\tgoto out;\n\n\tmtk_foe_entry_commit_subflow(ppe, entry, hash);\n\nout:\n\tspin_unlock_bh(&ppe_lock);\n}",
        "code_after_change": "void __mtk_ppe_check_skb(struct mtk_ppe *ppe, struct sk_buff *skb, u16 hash)\n{\n\tstruct hlist_head *head = &ppe->foe_flow[hash / 2];\n\tstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\n\tstruct mtk_flow_entry *entry;\n\tstruct mtk_foe_bridge key = {};\n\tstruct hlist_node *n;\n\tstruct ethhdr *eh;\n\tbool found = false;\n\tu8 *tag;\n\n\tspin_lock_bh(&ppe_lock);\n\n\tif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\n\t\tgoto out;\n\n\thlist_for_each_entry_safe(entry, n, head, list) {\n\t\tif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\n\t\t\tif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\n\t\t\t\t     MTK_FOE_STATE_BIND))\n\t\t\t\tcontinue;\n\n\t\t\tentry->hash = 0xffff;\n\t\t\t__mtk_foe_entry_clear(ppe, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (found || !mtk_flow_entry_match(entry, hwe)) {\n\t\t\tif (entry->hash != 0xffff)\n\t\t\t\tentry->hash = 0xffff;\n\t\t\tcontinue;\n\t\t}\n\n\t\tentry->hash = hash;\n\t\t__mtk_foe_entry_commit(ppe, &entry->data, hash);\n\t\tfound = true;\n\t}\n\n\tif (found)\n\t\tgoto out;\n\n\teh = eth_hdr(skb);\n\tether_addr_copy(key.dest_mac, eh->h_dest);\n\tether_addr_copy(key.src_mac, eh->h_source);\n\ttag = skb->data - 2;\n\tkey.vlan = 0;\n\tswitch (skb->protocol) {\n#if IS_ENABLED(CONFIG_NET_DSA)\n\tcase htons(ETH_P_XDSA):\n\t\tif (!netdev_uses_dsa(skb->dev) ||\n\t\t    skb->dev->dsa_ptr->tag_ops->proto != DSA_TAG_PROTO_MTK)\n\t\t\tgoto out;\n\n\t\ttag += 4;\n\t\tif (get_unaligned_be16(tag) != ETH_P_8021Q)\n\t\t\tbreak;\n\n\t\tfallthrough;\n#endif\n\tcase htons(ETH_P_8021Q):\n\t\tkey.vlan = get_unaligned_be16(tag + 2) & VLAN_VID_MASK;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tentry = rhashtable_lookup_fast(&ppe->l2_flows, &key, mtk_flow_l2_ht_params);\n\tif (!entry)\n\t\tgoto out;\n\n\tmtk_foe_entry_commit_subflow(ppe, entry, hash);\n\nout:\n\tspin_unlock_bh(&ppe_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,7 @@\n \tstruct mtk_foe_entry *hwe = &ppe->foe_table[hash];\n \tstruct mtk_flow_entry *entry;\n \tstruct mtk_foe_bridge key = {};\n+\tstruct hlist_node *n;\n \tstruct ethhdr *eh;\n \tbool found = false;\n \tu8 *tag;\n@@ -13,7 +14,7 @@\n \tif (FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) == MTK_FOE_STATE_BIND)\n \t\tgoto out;\n \n-\thlist_for_each_entry(entry, head, list) {\n+\thlist_for_each_entry_safe(entry, n, head, list) {\n \t\tif (entry->type == MTK_FLOW_TYPE_L2_SUBFLOW) {\n \t\t\tif (unlikely(FIELD_GET(MTK_FOE_IB1_STATE, hwe->ib1) ==\n \t\t\t\t     MTK_FOE_STATE_BIND))",
        "function_modified_lines": {
            "added": [
                "\tstruct hlist_node *n;",
                "\thlist_for_each_entry_safe(entry, n, head, list) {"
            ],
            "deleted": [
                "\thlist_for_each_entry(entry, head, list) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability, which was classified as critical, was found in Linux Kernel. This affects the function __mtk_ppe_check_skb of the file drivers/net/ethernet/mediatek/mtk_ppe.c of the component Ethernet Handler. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The associated identifier of this vulnerability is VDB-211935.",
        "id": 3669
    },
    {
        "cve_id": "CVE-2014-3184",
        "code_before_change": "static __u8 *lg_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tstruct lg_drv_data *drv_data = hid_get_drvdata(hdev);\n\tstruct usb_device_descriptor *udesc;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 90 && rdesc[83] == 0x26 &&\n\t\t\trdesc[84] == 0x8c && rdesc[85] == 0x02) {\n\t\thid_info(hdev,\n\t\t\t \"fixing up Logitech keyboard report descriptor\\n\");\n\t\trdesc[84] = rdesc[89] = 0x4d;\n\t\trdesc[85] = rdesc[90] = 0x10;\n\t}\n\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 50 &&\n\t\t\trdesc[32] == 0x81 && rdesc[33] == 0x06 &&\n\t\t\trdesc[49] == 0x81 && rdesc[50] == 0x06) {\n\t\thid_info(hdev,\n\t\t\t \"fixing up rel/abs in Logitech report descriptor\\n\");\n\t\trdesc[33] = rdesc[50] = 0x02;\n\t}\n\n\tswitch (hdev->product) {\n\n\t/* Several wheels report as this id when operating in emulation mode. */\n\tcase USB_DEVICE_ID_LOGITECH_WHEEL:\n\t\tudesc = &(hid_to_usb_dev(hdev)->descriptor);\n\t\tif (!udesc) {\n\t\t\thid_err(hdev, \"NULL USB device descriptor\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\t\trev_maj = bcdDevice >> 8;\n\t\trev_min = bcdDevice & 0xff;\n\n\t\t/* Update the report descriptor for only the Driving Force wheel */\n\t\tif (rev_maj == 1 && rev_min == 2 &&\n\t\t\t\t*rsize == DF_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Driving Force report descriptor\\n\");\n\t\t\trdesc = df_rdesc_fixed;\n\t\t\t*rsize = sizeof(df_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_MOMO_WHEEL:\n\t\tif (*rsize == MOMO_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Momo Force (Red) report descriptor\\n\");\n\t\t\trdesc = momo_rdesc_fixed;\n\t\t\t*rsize = sizeof(momo_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_MOMO_WHEEL2:\n\t\tif (*rsize == MOMO2_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Momo Racing Force (Black) report descriptor\\n\");\n\t\t\trdesc = momo2_rdesc_fixed;\n\t\t\t*rsize = sizeof(momo2_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_VIBRATION_WHEEL:\n\t\tif (*rsize == FV_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Formula Vibration report descriptor\\n\");\n\t\t\trdesc = fv_rdesc_fixed;\n\t\t\t*rsize = sizeof(fv_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_DFP_WHEEL:\n\t\tif (*rsize == DFP_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Driving Force Pro report descriptor\\n\");\n\t\t\trdesc = dfp_rdesc_fixed;\n\t\t\t*rsize = sizeof(dfp_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_WII_WHEEL:\n\t\tif (*rsize >= 101 && rdesc[41] == 0x95 && rdesc[42] == 0x0B &&\n\t\t\t\trdesc[47] == 0x05 && rdesc[48] == 0x09) {\n\t\t\thid_info(hdev, \"fixing up Logitech Speed Force Wireless report descriptor\\n\");\n\t\t\trdesc[41] = 0x05;\n\t\t\trdesc[42] = 0x09;\n\t\t\trdesc[47] = 0x95;\n\t\t\trdesc[48] = 0x0B;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn rdesc;\n}",
        "code_after_change": "static __u8 *lg_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tstruct lg_drv_data *drv_data = hid_get_drvdata(hdev);\n\tstruct usb_device_descriptor *udesc;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 91 && rdesc[83] == 0x26 &&\n\t\t\trdesc[84] == 0x8c && rdesc[85] == 0x02) {\n\t\thid_info(hdev,\n\t\t\t \"fixing up Logitech keyboard report descriptor\\n\");\n\t\trdesc[84] = rdesc[89] = 0x4d;\n\t\trdesc[85] = rdesc[90] = 0x10;\n\t}\n\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 51 &&\n\t\t\trdesc[32] == 0x81 && rdesc[33] == 0x06 &&\n\t\t\trdesc[49] == 0x81 && rdesc[50] == 0x06) {\n\t\thid_info(hdev,\n\t\t\t \"fixing up rel/abs in Logitech report descriptor\\n\");\n\t\trdesc[33] = rdesc[50] = 0x02;\n\t}\n\n\tswitch (hdev->product) {\n\n\t/* Several wheels report as this id when operating in emulation mode. */\n\tcase USB_DEVICE_ID_LOGITECH_WHEEL:\n\t\tudesc = &(hid_to_usb_dev(hdev)->descriptor);\n\t\tif (!udesc) {\n\t\t\thid_err(hdev, \"NULL USB device descriptor\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\t\trev_maj = bcdDevice >> 8;\n\t\trev_min = bcdDevice & 0xff;\n\n\t\t/* Update the report descriptor for only the Driving Force wheel */\n\t\tif (rev_maj == 1 && rev_min == 2 &&\n\t\t\t\t*rsize == DF_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Driving Force report descriptor\\n\");\n\t\t\trdesc = df_rdesc_fixed;\n\t\t\t*rsize = sizeof(df_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_MOMO_WHEEL:\n\t\tif (*rsize == MOMO_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Momo Force (Red) report descriptor\\n\");\n\t\t\trdesc = momo_rdesc_fixed;\n\t\t\t*rsize = sizeof(momo_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_MOMO_WHEEL2:\n\t\tif (*rsize == MOMO2_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Momo Racing Force (Black) report descriptor\\n\");\n\t\t\trdesc = momo2_rdesc_fixed;\n\t\t\t*rsize = sizeof(momo2_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_VIBRATION_WHEEL:\n\t\tif (*rsize == FV_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Formula Vibration report descriptor\\n\");\n\t\t\trdesc = fv_rdesc_fixed;\n\t\t\t*rsize = sizeof(fv_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_DFP_WHEEL:\n\t\tif (*rsize == DFP_RDESC_ORIG_SIZE) {\n\t\t\thid_info(hdev,\n\t\t\t\t\"fixing up Logitech Driving Force Pro report descriptor\\n\");\n\t\t\trdesc = dfp_rdesc_fixed;\n\t\t\t*rsize = sizeof(dfp_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\n\tcase USB_DEVICE_ID_LOGITECH_WII_WHEEL:\n\t\tif (*rsize >= 101 && rdesc[41] == 0x95 && rdesc[42] == 0x0B &&\n\t\t\t\trdesc[47] == 0x05 && rdesc[48] == 0x09) {\n\t\t\thid_info(hdev, \"fixing up Logitech Speed Force Wireless report descriptor\\n\");\n\t\t\trdesc[41] = 0x05;\n\t\t\trdesc[42] = 0x09;\n\t\t\trdesc[47] = 0x95;\n\t\t\trdesc[48] = 0x0B;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn rdesc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,14 +5,14 @@\n \tstruct usb_device_descriptor *udesc;\n \t__u16 bcdDevice, rev_maj, rev_min;\n \n-\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 90 && rdesc[83] == 0x26 &&\n+\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 91 && rdesc[83] == 0x26 &&\n \t\t\trdesc[84] == 0x8c && rdesc[85] == 0x02) {\n \t\thid_info(hdev,\n \t\t\t \"fixing up Logitech keyboard report descriptor\\n\");\n \t\trdesc[84] = rdesc[89] = 0x4d;\n \t\trdesc[85] = rdesc[90] = 0x10;\n \t}\n-\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 50 &&\n+\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 51 &&\n \t\t\trdesc[32] == 0x81 && rdesc[33] == 0x06 &&\n \t\t\trdesc[49] == 0x81 && rdesc[50] == 0x06) {\n \t\thid_info(hdev,",
        "function_modified_lines": {
            "added": [
                "\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 91 && rdesc[83] == 0x26 &&",
                "\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 51 &&"
            ],
            "deleted": [
                "\tif ((drv_data->quirks & LG_RDESC) && *rsize >= 90 && rdesc[83] == 0x26 &&",
                "\tif ((drv_data->quirks & LG_RDESC_REL_ABS) && *rsize >= 50 &&"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The report_fixup functions in the HID subsystem in the Linux kernel before 3.16.2 might allow physically proximate attackers to cause a denial of service (out-of-bounds write) via a crafted device that provides a small report descriptor, related to (1) drivers/hid/hid-cherry.c, (2) drivers/hid/hid-kye.c, (3) drivers/hid/hid-lg.c, (4) drivers/hid/hid-monterey.c, (5) drivers/hid/hid-petalynx.c, and (6) drivers/hid/hid-sunplus.c.",
        "id": 517
    },
    {
        "cve_id": "CVE-2018-7740",
        "code_before_change": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\tstruct resv_map *resv_map;\n\tlong gbl_reserve;\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE) {\n\t\tresv_map = inode_resv_map(inode);\n\n\t\tchg = region_chg(resv_map, from, to);\n\n\t} else {\n\t\tresv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0) {\n\t\tret = chg;\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * There must be enough pages in the subpool for the mapping. If\n\t * the subpool has a minimum size, there may be some global\n\t * reservations already in place (gbl_reserve).\n\t */\n\tgbl_reserve = hugepage_subpool_get_pages(spool, chg);\n\tif (gbl_reserve < 0) {\n\t\tret = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand the pages back to the subpool if there are not\n\t */\n\tret = hugetlb_acct_memory(h, gbl_reserve);\n\tif (ret < 0) {\n\t\t/* put back original number of pages, chg */\n\t\t(void)hugepage_subpool_put_pages(spool, chg);\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE) {\n\t\tlong add = region_add(resv_map, from, to);\n\n\t\tif (unlikely(chg > add)) {\n\t\t\t/*\n\t\t\t * pages in this range were added to the reserve\n\t\t\t * map between region_chg and region_add.  This\n\t\t\t * indicates a race with alloc_huge_page.  Adjust\n\t\t\t * the subpool and reserve counts modified above\n\t\t\t * based on the difference.\n\t\t\t */\n\t\t\tlong rsv_adjust;\n\n\t\t\trsv_adjust = hugepage_subpool_put_pages(spool,\n\t\t\t\t\t\t\t\tchg - add);\n\t\t\thugetlb_acct_memory(h, -rsv_adjust);\n\t\t}\n\t}\n\treturn 0;\nout_err:\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\t/* Don't call region_abort if region_chg failed */\n\t\tif (chg >= 0)\n\t\t\tregion_abort(resv_map, from, to);\n\tif (vma && is_vma_resv_set(vma, HPAGE_RESV_OWNER))\n\t\tkref_put(&resv_map->refs, resv_map_release);\n\treturn ret;\n}",
        "code_after_change": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\tstruct resv_map *resv_map;\n\tlong gbl_reserve;\n\n\t/* This should never happen */\n\tif (from > to) {\n\t\tVM_WARN(1, \"%s called with a negative range\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE) {\n\t\tresv_map = inode_resv_map(inode);\n\n\t\tchg = region_chg(resv_map, from, to);\n\n\t} else {\n\t\tresv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0) {\n\t\tret = chg;\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * There must be enough pages in the subpool for the mapping. If\n\t * the subpool has a minimum size, there may be some global\n\t * reservations already in place (gbl_reserve).\n\t */\n\tgbl_reserve = hugepage_subpool_get_pages(spool, chg);\n\tif (gbl_reserve < 0) {\n\t\tret = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand the pages back to the subpool if there are not\n\t */\n\tret = hugetlb_acct_memory(h, gbl_reserve);\n\tif (ret < 0) {\n\t\t/* put back original number of pages, chg */\n\t\t(void)hugepage_subpool_put_pages(spool, chg);\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE) {\n\t\tlong add = region_add(resv_map, from, to);\n\n\t\tif (unlikely(chg > add)) {\n\t\t\t/*\n\t\t\t * pages in this range were added to the reserve\n\t\t\t * map between region_chg and region_add.  This\n\t\t\t * indicates a race with alloc_huge_page.  Adjust\n\t\t\t * the subpool and reserve counts modified above\n\t\t\t * based on the difference.\n\t\t\t */\n\t\t\tlong rsv_adjust;\n\n\t\t\trsv_adjust = hugepage_subpool_put_pages(spool,\n\t\t\t\t\t\t\t\tchg - add);\n\t\t\thugetlb_acct_memory(h, -rsv_adjust);\n\t\t}\n\t}\n\treturn 0;\nout_err:\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\t/* Don't call region_abort if region_chg failed */\n\t\tif (chg >= 0)\n\t\t\tregion_abort(resv_map, from, to);\n\tif (vma && is_vma_resv_set(vma, HPAGE_RESV_OWNER))\n\t\tkref_put(&resv_map->refs, resv_map_release);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,12 @@\n \tstruct hugepage_subpool *spool = subpool_inode(inode);\n \tstruct resv_map *resv_map;\n \tlong gbl_reserve;\n+\n+\t/* This should never happen */\n+\tif (from > to) {\n+\t\tVM_WARN(1, \"%s called with a negative range\\n\", __func__);\n+\t\treturn -EINVAL;\n+\t}\n \n \t/*\n \t * Only apply hugepage reservation if asked. At fault time, an",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* This should never happen */",
                "\tif (from > to) {",
                "\t\tVM_WARN(1, \"%s called with a negative range\\n\", __func__);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The resv_map_release function in mm/hugetlb.c in the Linux kernel through 4.15.7 allows local users to cause a denial of service (BUG) via a crafted application that makes mmap system calls and has a large pgoff argument to the remap_file_pages system call.",
        "id": 1849
    },
    {
        "cve_id": "CVE-2018-8822",
        "code_before_change": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n\t     __u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\n\tconst char *source;\n\tint result;\n\n\tncp_init_request(server);\n\tncp_add_byte(server, 0);\n\tncp_add_mem(server, file_id, 6);\n\tncp_add_be32(server, offset);\n\tncp_add_be16(server, to_read);\n\n\tif ((result = ncp_request(server, 72)) != 0) {\n\t\tgoto out;\n\t}\n\t*bytes_read = ncp_reply_be16(server, 0);\n\tsource = ncp_reply_data(server, 2 + (offset & 1));\n\n\tmemcpy(target, source, *bytes_read);\nout:\n\tncp_unlock_server(server);\n\treturn result;\n}",
        "code_after_change": "int\nncp_read_kernel(struct ncp_server *server, const char *file_id,\n\t     __u32 offset, __u16 to_read, char *target, int *bytes_read)\n{\n\tconst char *source;\n\tint result;\n\n\tncp_init_request(server);\n\tncp_add_byte(server, 0);\n\tncp_add_mem(server, file_id, 6);\n\tncp_add_be32(server, offset);\n\tncp_add_be16(server, to_read);\n\n\tif ((result = ncp_request(server, 72)) != 0) {\n\t\tgoto out;\n\t}\n\t*bytes_read = ncp_reply_be16(server, 0);\n\tif (*bytes_read > to_read) {\n\t\tresult = -EINVAL;\n\t\tgoto out;\n\t}\n\tsource = ncp_reply_data(server, 2 + (offset & 1));\n\n\tmemcpy(target, source, *bytes_read);\nout:\n\tncp_unlock_server(server);\n\treturn result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,6 +15,10 @@\n \t\tgoto out;\n \t}\n \t*bytes_read = ncp_reply_be16(server, 0);\n+\tif (*bytes_read > to_read) {\n+\t\tresult = -EINVAL;\n+\t\tgoto out;\n+\t}\n \tsource = ncp_reply_data(server, 2 + (offset & 1));\n \n \tmemcpy(target, source, *bytes_read);",
        "function_modified_lines": {
            "added": [
                "\tif (*bytes_read > to_read) {",
                "\t\tresult = -EINVAL;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Incorrect buffer length handling in the ncp_read_kernel function in fs/ncpfs/ncplib_kernel.c in the Linux kernel through 4.15.11, and in drivers/staging/ncpfs/ncplib_kernel.c in the Linux kernel 4.16-rc through 4.16-rc6, could be exploited by malicious NCPFS servers to crash the kernel or execute code.",
        "id": 1861
    },
    {
        "cve_id": "CVE-2022-3435",
        "code_before_change": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\n\t\t struct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tstruct rtnexthop *rtnh;\n\tint remaining;\n#endif\n\n\tif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\n\t\treturn 1;\n\n\tif (cfg->fc_nh_id) {\n\t\tif (fi->nh && cfg->fc_nh_id == fi->nh->id)\n\t\t\treturn 0;\n\t\treturn 1;\n\t}\n\n\tif (cfg->fc_oif || cfg->fc_gw_family) {\n\t\tstruct fib_nh *nh;\n\n\t\t/* cannot match on nexthop object attributes */\n\t\tif (fi->nh)\n\t\t\treturn 1;\n\n\t\tnh = fib_info_nh(fi, 0);\n\t\tif (cfg->fc_encap) {\n\t\t\tif (fib_encap_match(net, cfg->fc_encap_type,\n\t\t\t\t\t    cfg->fc_encap, nh, cfg, extack))\n\t\t\t\treturn 1;\n\t\t}\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\tif (cfg->fc_flow &&\n\t\t    cfg->fc_flow != nh->nh_tclassid)\n\t\t\treturn 1;\n#endif\n\t\tif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n\t\t    (cfg->fc_gw_family &&\n\t\t     cfg->fc_gw_family != nh->fib_nh_gw_family))\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET &&\n\t\t    cfg->fc_gw4 != nh->fib_nh_gw4)\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET6 &&\n\t\t    ipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tif (!cfg->fc_mp)\n\t\treturn 0;\n\n\trtnh = cfg->fc_mp;\n\tremaining = cfg->fc_mp_len;\n\n\tfor_nexthops(fi) {\n\t\tint attrlen;\n\n\t\tif (!rtnh_ok(rtnh, remaining))\n\t\t\treturn -EINVAL;\n\n\t\tif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\n\t\t\treturn 1;\n\n\t\tattrlen = rtnh_attrlen(rtnh);\n\t\tif (attrlen > 0) {\n\t\t\tstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\n\t\t\tint err;\n\n\t\t\tnla = nla_find(attrs, attrlen, RTA_GATEWAY);\n\t\t\tnlav = nla_find(attrs, attrlen, RTA_VIA);\n\t\t\tif (nla && nlav) {\n\t\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t\t       \"Nexthop configuration can not contain both GATEWAY and VIA\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (nla) {\n\t\t\t\t__be32 gw;\n\n\t\t\t\terr = fib_gw_from_attr(&gw, nla, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tif (nh->fib_nh_gw_family != AF_INET ||\n\t\t\t\t    gw != nh->fib_nh_gw4)\n\t\t\t\t\treturn 1;\n\t\t\t} else if (nlav) {\n\t\t\t\tstruct fib_config cfg2;\n\n\t\t\t\terr = fib_gw_from_via(&cfg2, nlav, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tswitch (nh->fib_nh_gw_family) {\n\t\t\t\tcase AF_INET:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET ||\n\t\t\t\t\t    cfg2.fc_gw4 != nh->fib_nh_gw4)\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase AF_INET6:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET6 ||\n\t\t\t\t\t    ipv6_addr_cmp(&cfg2.fc_gw6,\n\t\t\t\t\t\t\t  &nh->fib_nh_gw6))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\t\tnla = nla_find(attrs, attrlen, RTA_FLOW);\n\t\t\tif (nla) {\n\t\t\t\tif (nla_len(nla) < sizeof(u32)) {\n\t\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tif (nla_get_u32(nla) != nh->nh_tclassid)\n\t\t\t\t\treturn 1;\n\t\t\t}\n#endif\n\t\t}\n\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t} endfor_nexthops(fi);\n#endif\n\treturn 0;\n}",
        "code_after_change": "int fib_nh_match(struct net *net, struct fib_config *cfg, struct fib_info *fi,\n\t\t struct netlink_ext_ack *extack)\n{\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tstruct rtnexthop *rtnh;\n\tint remaining;\n#endif\n\n\tif (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)\n\t\treturn 1;\n\n\tif (cfg->fc_nh_id) {\n\t\tif (fi->nh && cfg->fc_nh_id == fi->nh->id)\n\t\t\treturn 0;\n\t\treturn 1;\n\t}\n\n\t/* cannot match on nexthop object attributes */\n\tif (fi->nh)\n\t\treturn 1;\n\n\tif (cfg->fc_oif || cfg->fc_gw_family) {\n\t\tstruct fib_nh *nh;\n\n\t\tnh = fib_info_nh(fi, 0);\n\t\tif (cfg->fc_encap) {\n\t\t\tif (fib_encap_match(net, cfg->fc_encap_type,\n\t\t\t\t\t    cfg->fc_encap, nh, cfg, extack))\n\t\t\t\treturn 1;\n\t\t}\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\tif (cfg->fc_flow &&\n\t\t    cfg->fc_flow != nh->nh_tclassid)\n\t\t\treturn 1;\n#endif\n\t\tif ((cfg->fc_oif && cfg->fc_oif != nh->fib_nh_oif) ||\n\t\t    (cfg->fc_gw_family &&\n\t\t     cfg->fc_gw_family != nh->fib_nh_gw_family))\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET &&\n\t\t    cfg->fc_gw4 != nh->fib_nh_gw4)\n\t\t\treturn 1;\n\n\t\tif (cfg->fc_gw_family == AF_INET6 &&\n\t\t    ipv6_addr_cmp(&cfg->fc_gw6, &nh->fib_nh_gw6))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n#ifdef CONFIG_IP_ROUTE_MULTIPATH\n\tif (!cfg->fc_mp)\n\t\treturn 0;\n\n\trtnh = cfg->fc_mp;\n\tremaining = cfg->fc_mp_len;\n\n\tfor_nexthops(fi) {\n\t\tint attrlen;\n\n\t\tif (!rtnh_ok(rtnh, remaining))\n\t\t\treturn -EINVAL;\n\n\t\tif (rtnh->rtnh_ifindex && rtnh->rtnh_ifindex != nh->fib_nh_oif)\n\t\t\treturn 1;\n\n\t\tattrlen = rtnh_attrlen(rtnh);\n\t\tif (attrlen > 0) {\n\t\t\tstruct nlattr *nla, *nlav, *attrs = rtnh_attrs(rtnh);\n\t\t\tint err;\n\n\t\t\tnla = nla_find(attrs, attrlen, RTA_GATEWAY);\n\t\t\tnlav = nla_find(attrs, attrlen, RTA_VIA);\n\t\t\tif (nla && nlav) {\n\t\t\t\tNL_SET_ERR_MSG(extack,\n\t\t\t\t\t       \"Nexthop configuration can not contain both GATEWAY and VIA\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (nla) {\n\t\t\t\t__be32 gw;\n\n\t\t\t\terr = fib_gw_from_attr(&gw, nla, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tif (nh->fib_nh_gw_family != AF_INET ||\n\t\t\t\t    gw != nh->fib_nh_gw4)\n\t\t\t\t\treturn 1;\n\t\t\t} else if (nlav) {\n\t\t\t\tstruct fib_config cfg2;\n\n\t\t\t\terr = fib_gw_from_via(&cfg2, nlav, extack);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tswitch (nh->fib_nh_gw_family) {\n\t\t\t\tcase AF_INET:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET ||\n\t\t\t\t\t    cfg2.fc_gw4 != nh->fib_nh_gw4)\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase AF_INET6:\n\t\t\t\t\tif (cfg2.fc_gw_family != AF_INET6 ||\n\t\t\t\t\t    ipv6_addr_cmp(&cfg2.fc_gw6,\n\t\t\t\t\t\t\t  &nh->fib_nh_gw6))\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\t\t\tnla = nla_find(attrs, attrlen, RTA_FLOW);\n\t\t\tif (nla) {\n\t\t\t\tif (nla_len(nla) < sizeof(u32)) {\n\t\t\t\t\tNL_SET_ERR_MSG(extack, \"Invalid RTA_FLOW\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\tif (nla_get_u32(nla) != nh->nh_tclassid)\n\t\t\t\t\treturn 1;\n\t\t\t}\n#endif\n\t\t}\n\n\t\trtnh = rtnh_next(rtnh, &remaining);\n\t} endfor_nexthops(fi);\n#endif\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,12 +15,12 @@\n \t\treturn 1;\n \t}\n \n+\t/* cannot match on nexthop object attributes */\n+\tif (fi->nh)\n+\t\treturn 1;\n+\n \tif (cfg->fc_oif || cfg->fc_gw_family) {\n \t\tstruct fib_nh *nh;\n-\n-\t\t/* cannot match on nexthop object attributes */\n-\t\tif (fi->nh)\n-\t\t\treturn 1;\n \n \t\tnh = fib_info_nh(fi, 0);\n \t\tif (cfg->fc_encap) {",
        "function_modified_lines": {
            "added": [
                "\t/* cannot match on nexthop object attributes */",
                "\tif (fi->nh)",
                "\t\treturn 1;",
                ""
            ],
            "deleted": [
                "",
                "\t\t/* cannot match on nexthop object attributes */",
                "\t\tif (fi->nh)",
                "\t\t\treturn 1;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability classified as problematic has been found in Linux Kernel. This affects the function fib_nh_match of the file net/ipv4/fib_semantics.c of the component IPv4 Handler. The manipulation leads to out-of-bounds read. It is possible to initiate the attack remotely. It is recommended to apply a patch to fix this issue. The identifier VDB-210357 was assigned to this vulnerability.",
        "id": 3599
    },
    {
        "cve_id": "CVE-2021-39633",
        "code_before_change": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\n\treturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}",
        "code_after_change": "static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n{\n\tif (csum && skb_checksum_start(skb) < skb->data)\n\t\treturn -EINVAL;\n\treturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,6 @@\n static int gre_handle_offloads(struct sk_buff *skb, bool csum)\n {\n+\tif (csum && skb_checksum_start(skb) < skb->data)\n+\t\treturn -EINVAL;\n \treturn iptunnel_handle_offloads(skb, csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (csum && skb_checksum_start(skb) < skb->data)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In gre_handle_offloads of ip_gre.c, there is a possible page fault due to an invalid memory access. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-150694665References: Upstream kernel",
        "id": 3091
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n\t\t\t\t       \"use the STANDARD target with \"\n\t\t\t\t       \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -36,9 +36,9 @@\n \t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n \t\tif ((unsigned char *)e - base == underflows[h]) {\n \t\t\tif (!check_underflow(e)) {\n-\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n-\t\t\t\t       \"use the STANDARD target with \"\n-\t\t\t\t       \"ACCEPT/DROP\\n\");\n+\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n+\t\t\t\t\t \"use the STANDARD target with \"\n+\t\t\t\t\t \"ACCEPT/DROP\\n\");\n \t\t\t\treturn -EINVAL;\n \t\t\t}\n \t\t\tnewinfo->underflow[h] = underflows[h];",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tpr_debug(\"Underflows must be unconditional and \"",
                "\t\t\t\t\t \"use the STANDARD target with \"",
                "\t\t\t\t\t \"ACCEPT/DROP\\n\");"
            ],
            "deleted": [
                "\t\t\t\tpr_err(\"Underflows must be unconditional and \"",
                "\t\t\t\t       \"use the STANDARD target with \"",
                "\t\t\t\t       \"ACCEPT/DROP\\n\");"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 965
    },
    {
        "cve_id": "CVE-2021-4157",
        "code_before_change": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tfh->size = be32_to_cpup(p++);\n\tif (fh->size > sizeof(struct nfs_fh)) {\n\t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n\t\t       fh->size);\n\t\treturn -EOVERFLOW;\n\t}\n\t/* fh.data */\n\tp = xdr_inline_decode(xdr, fh->size);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(&fh->data, p, fh->size);\n\tdprintk(\"%s: fh len %d\\n\", __func__, fh->size);\n\n\treturn 0;\n}",
        "code_after_change": "static int decode_nfs_fh(struct xdr_stream *xdr, struct nfs_fh *fh)\n{\n\t__be32 *p;\n\n\tp = xdr_inline_decode(xdr, 4);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tfh->size = be32_to_cpup(p++);\n\tif (fh->size > NFS_MAXFHSIZE) {\n\t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n\t\t       fh->size);\n\t\treturn -EOVERFLOW;\n\t}\n\t/* fh.data */\n\tp = xdr_inline_decode(xdr, fh->size);\n\tif (unlikely(!p))\n\t\treturn -ENOBUFS;\n\tmemcpy(&fh->data, p, fh->size);\n\tdprintk(\"%s: fh len %d\\n\", __func__, fh->size);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \tif (unlikely(!p))\n \t\treturn -ENOBUFS;\n \tfh->size = be32_to_cpup(p++);\n-\tif (fh->size > sizeof(struct nfs_fh)) {\n+\tif (fh->size > NFS_MAXFHSIZE) {\n \t\tprintk(KERN_ERR \"NFS flexfiles: Too big fh received %d\\n\",\n \t\t       fh->size);\n \t\treturn -EOVERFLOW;",
        "function_modified_lines": {
            "added": [
                "\tif (fh->size > NFS_MAXFHSIZE) {"
            ],
            "deleted": [
                "\tif (fh->size > sizeof(struct nfs_fh)) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An out of memory bounds write flaw (1 or 2 bytes of memory) in the Linux kernel NFS subsystem was found in the way users use mirroring (replication of files with NFS). A user, having access to the NFS mount, could potentially use this flaw to crash the system or escalate privileges on the system.",
        "id": 3139
    },
    {
        "cve_id": "CVE-2013-6381",
        "code_before_change": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\n\tstruct qeth_cmd_buffer *iob;\n\tstruct qeth_ipa_cmd *cmd;\n\tstruct qeth_snmp_ureq *ureq;\n\tint req_len;\n\tstruct qeth_arp_query_info qinfo = {0, };\n\tint rc = 0;\n\n\tQETH_CARD_TEXT(card, 3, \"snmpcmd\");\n\n\tif (card->info.guestlan)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n\t    (!card->options.layer2)) {\n\t\treturn -EOPNOTSUPP;\n\t}\n\t/* skip 4 bytes (data_len struct member) to get req_len */\n\tif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\n\t\treturn -EFAULT;\n\tureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\n\tif (IS_ERR(ureq)) {\n\t\tQETH_CARD_TEXT(card, 2, \"snmpnome\");\n\t\treturn PTR_ERR(ureq);\n\t}\n\tqinfo.udata_len = ureq->hdr.data_len;\n\tqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\n\tif (!qinfo.udata) {\n\t\tkfree(ureq);\n\t\treturn -ENOMEM;\n\t}\n\tqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\n\n\tiob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\n\t\t\t\t   QETH_SNMP_SETADP_CMDLENGTH + req_len);\n\tcmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\n\tmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\n\trc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\n\t\t\t\t    qeth_snmp_command_cb, (void *)&qinfo);\n\tif (rc)\n\t\tQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\n\t\t\t   QETH_CARD_IFNAME(card), rc);\n\telse {\n\t\tif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\n\t\t\trc = -EFAULT;\n\t}\n\n\tkfree(ureq);\n\tkfree(qinfo.udata);\n\treturn rc;\n}",
        "code_after_change": "int qeth_snmp_command(struct qeth_card *card, char __user *udata)\n{\n\tstruct qeth_cmd_buffer *iob;\n\tstruct qeth_ipa_cmd *cmd;\n\tstruct qeth_snmp_ureq *ureq;\n\tunsigned int req_len;\n\tstruct qeth_arp_query_info qinfo = {0, };\n\tint rc = 0;\n\n\tQETH_CARD_TEXT(card, 3, \"snmpcmd\");\n\n\tif (card->info.guestlan)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((!qeth_adp_supported(card, IPA_SETADP_SET_SNMP_CONTROL)) &&\n\t    (!card->options.layer2)) {\n\t\treturn -EOPNOTSUPP;\n\t}\n\t/* skip 4 bytes (data_len struct member) to get req_len */\n\tif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\n\t\treturn -EFAULT;\n\tif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -\n\t\t       sizeof(struct qeth_ipacmd_hdr) -\n\t\t       sizeof(struct qeth_ipacmd_setadpparms_hdr)))\n\t\treturn -EINVAL;\n\tureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\n\tif (IS_ERR(ureq)) {\n\t\tQETH_CARD_TEXT(card, 2, \"snmpnome\");\n\t\treturn PTR_ERR(ureq);\n\t}\n\tqinfo.udata_len = ureq->hdr.data_len;\n\tqinfo.udata = kzalloc(qinfo.udata_len, GFP_KERNEL);\n\tif (!qinfo.udata) {\n\t\tkfree(ureq);\n\t\treturn -ENOMEM;\n\t}\n\tqinfo.udata_offset = sizeof(struct qeth_snmp_ureq_hdr);\n\n\tiob = qeth_get_adapter_cmd(card, IPA_SETADP_SET_SNMP_CONTROL,\n\t\t\t\t   QETH_SNMP_SETADP_CMDLENGTH + req_len);\n\tcmd = (struct qeth_ipa_cmd *)(iob->data+IPA_PDU_HEADER_SIZE);\n\tmemcpy(&cmd->data.setadapterparms.data.snmp, &ureq->cmd, req_len);\n\trc = qeth_send_ipa_snmp_cmd(card, iob, QETH_SETADP_BASE_LEN + req_len,\n\t\t\t\t    qeth_snmp_command_cb, (void *)&qinfo);\n\tif (rc)\n\t\tQETH_DBF_MESSAGE(2, \"SNMP command failed on %s: (0x%x)\\n\",\n\t\t\t   QETH_CARD_IFNAME(card), rc);\n\telse {\n\t\tif (copy_to_user(udata, qinfo.udata, qinfo.udata_len))\n\t\t\trc = -EFAULT;\n\t}\n\n\tkfree(ureq);\n\tkfree(qinfo.udata);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct qeth_cmd_buffer *iob;\n \tstruct qeth_ipa_cmd *cmd;\n \tstruct qeth_snmp_ureq *ureq;\n-\tint req_len;\n+\tunsigned int req_len;\n \tstruct qeth_arp_query_info qinfo = {0, };\n \tint rc = 0;\n \n@@ -19,6 +19,10 @@\n \t/* skip 4 bytes (data_len struct member) to get req_len */\n \tif (copy_from_user(&req_len, udata + sizeof(int), sizeof(int)))\n \t\treturn -EFAULT;\n+\tif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -\n+\t\t       sizeof(struct qeth_ipacmd_hdr) -\n+\t\t       sizeof(struct qeth_ipacmd_setadpparms_hdr)))\n+\t\treturn -EINVAL;\n \tureq = memdup_user(udata, req_len + sizeof(struct qeth_snmp_ureq_hdr));\n \tif (IS_ERR(ureq)) {\n \t\tQETH_CARD_TEXT(card, 2, \"snmpnome\");",
        "function_modified_lines": {
            "added": [
                "\tunsigned int req_len;",
                "\tif (req_len > (QETH_BUFSIZE - IPA_PDU_HEADER_SIZE -",
                "\t\t       sizeof(struct qeth_ipacmd_hdr) -",
                "\t\t       sizeof(struct qeth_ipacmd_setadpparms_hdr)))",
                "\t\treturn -EINVAL;"
            ],
            "deleted": [
                "\tint req_len;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the qeth_snmp_command function in drivers/s390/net/qeth_core_main.c in the Linux kernel through 3.12.1 allows local users to cause a denial of service or possibly have unspecified other impact via an SNMP ioctl call with a length value that is incompatible with the command-buffer size.",
        "id": 348
    },
    {
        "cve_id": "CVE-2014-6416",
        "code_before_change": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
        "code_after_change": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *preply = &reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,13 +5,14 @@\n \tstruct ceph_x_ticket_handler *th;\n \tint ret = 0;\n \tstruct ceph_x_authorize_reply reply;\n+\tvoid *preply = &reply;\n \tvoid *p = au->reply_buf;\n \tvoid *end = p + sizeof(au->reply_buf);\n \n \tth = get_ticket_handler(ac, au->service);\n \tif (IS_ERR(th))\n \t\treturn PTR_ERR(th);\n-\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\n+\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\n \tif (ret < 0)\n \t\treturn ret;\n \tif (ret != sizeof(reply))",
        "function_modified_lines": {
            "added": [
                "\tvoid *preply = &reply;",
                "\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));"
            ],
            "deleted": [
                "\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "id": 581
    },
    {
        "cve_id": "CVE-2014-0069",
        "code_before_change": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\n\t\t unsigned long nr_segs, loff_t *poffset)\n{\n\tunsigned long nr_pages, i;\n\tsize_t copied, len, cur_len;\n\tssize_t total_written = 0;\n\tloff_t offset;\n\tstruct iov_iter it;\n\tstruct cifsFileInfo *open_file;\n\tstruct cifs_tcon *tcon;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct cifs_writedata *wdata, *tmp;\n\tstruct list_head wdata_list;\n\tint rc;\n\tpid_t pid;\n\n\tlen = iov_length(iov, nr_segs);\n\tif (!len)\n\t\treturn 0;\n\n\trc = generic_write_checks(file, poffset, &len, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tINIT_LIST_HEAD(&wdata_list);\n\tcifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\n\topen_file = file->private_data;\n\ttcon = tlink_tcon(open_file->tlink);\n\n\tif (!tcon->ses->server->ops->async_writev)\n\t\treturn -ENOSYS;\n\n\toffset = *poffset;\n\n\tif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\n\t\tpid = open_file->pid;\n\telse\n\t\tpid = current->tgid;\n\n\tiov_iter_init(&it, iov, nr_segs, len, 0);\n\tdo {\n\t\tsize_t save_len;\n\n\t\tnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\n\t\twdata = cifs_writedata_alloc(nr_pages,\n\t\t\t\t\t     cifs_uncached_writev_complete);\n\t\tif (!wdata) {\n\t\t\trc = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\trc = cifs_write_allocate_pages(wdata->pages, nr_pages);\n\t\tif (rc) {\n\t\t\tkfree(wdata);\n\t\t\tbreak;\n\t\t}\n\n\t\tsave_len = cur_len;\n\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\tcopied = min_t(const size_t, cur_len, PAGE_SIZE);\n\t\t\tcopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n\t\t\t\t\t\t\t 0, copied);\n\t\t\tcur_len -= copied;\n\t\t\tiov_iter_advance(&it, copied);\n\t\t}\n\t\tcur_len = save_len - cur_len;\n\n\t\twdata->sync_mode = WB_SYNC_ALL;\n\t\twdata->nr_pages = nr_pages;\n\t\twdata->offset = (__u64)offset;\n\t\twdata->cfile = cifsFileInfo_get(open_file);\n\t\twdata->pid = pid;\n\t\twdata->bytes = cur_len;\n\t\twdata->pagesz = PAGE_SIZE;\n\t\twdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\n\t\trc = cifs_uncached_retry_writev(wdata);\n\t\tif (rc) {\n\t\t\tkref_put(&wdata->refcount,\n\t\t\t\t cifs_uncached_writedata_release);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add_tail(&wdata->list, &wdata_list);\n\t\toffset += cur_len;\n\t\tlen -= cur_len;\n\t} while (len > 0);\n\n\t/*\n\t * If at least one write was successfully sent, then discard any rc\n\t * value from the later writes. If the other write succeeds, then\n\t * we'll end up returning whatever was written. If it fails, then\n\t * we'll get a new rc value from that.\n\t */\n\tif (!list_empty(&wdata_list))\n\t\trc = 0;\n\n\t/*\n\t * Wait for and collect replies for any successful sends in order of\n\t * increasing offset. Once an error is hit or we get a fatal signal\n\t * while waiting, then return without waiting for any more replies.\n\t */\nrestart_loop:\n\tlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\n\t\tif (!rc) {\n\t\t\t/* FIXME: freezable too? */\n\t\t\trc = wait_for_completion_killable(&wdata->done);\n\t\t\tif (rc)\n\t\t\t\trc = -EINTR;\n\t\t\telse if (wdata->result)\n\t\t\t\trc = wdata->result;\n\t\t\telse\n\t\t\t\ttotal_written += wdata->bytes;\n\n\t\t\t/* resend call if it's a retryable error */\n\t\t\tif (rc == -EAGAIN) {\n\t\t\t\trc = cifs_uncached_retry_writev(wdata);\n\t\t\t\tgoto restart_loop;\n\t\t\t}\n\t\t}\n\t\tlist_del_init(&wdata->list);\n\t\tkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n\t}\n\n\tif (total_written > 0)\n\t\t*poffset += total_written;\n\n\tcifs_stats_bytes_written(tcon, total_written);\n\treturn total_written ? total_written : (ssize_t)rc;\n}",
        "code_after_change": "static ssize_t\ncifs_iovec_write(struct file *file, const struct iovec *iov,\n\t\t unsigned long nr_segs, loff_t *poffset)\n{\n\tunsigned long nr_pages, i;\n\tsize_t bytes, copied, len, cur_len;\n\tssize_t total_written = 0;\n\tloff_t offset;\n\tstruct iov_iter it;\n\tstruct cifsFileInfo *open_file;\n\tstruct cifs_tcon *tcon;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct cifs_writedata *wdata, *tmp;\n\tstruct list_head wdata_list;\n\tint rc;\n\tpid_t pid;\n\n\tlen = iov_length(iov, nr_segs);\n\tif (!len)\n\t\treturn 0;\n\n\trc = generic_write_checks(file, poffset, &len, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tINIT_LIST_HEAD(&wdata_list);\n\tcifs_sb = CIFS_SB(file->f_path.dentry->d_sb);\n\topen_file = file->private_data;\n\ttcon = tlink_tcon(open_file->tlink);\n\n\tif (!tcon->ses->server->ops->async_writev)\n\t\treturn -ENOSYS;\n\n\toffset = *poffset;\n\n\tif (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_RWPIDFORWARD)\n\t\tpid = open_file->pid;\n\telse\n\t\tpid = current->tgid;\n\n\tiov_iter_init(&it, iov, nr_segs, len, 0);\n\tdo {\n\t\tsize_t save_len;\n\n\t\tnr_pages = get_numpages(cifs_sb->wsize, len, &cur_len);\n\t\twdata = cifs_writedata_alloc(nr_pages,\n\t\t\t\t\t     cifs_uncached_writev_complete);\n\t\tif (!wdata) {\n\t\t\trc = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\trc = cifs_write_allocate_pages(wdata->pages, nr_pages);\n\t\tif (rc) {\n\t\t\tkfree(wdata);\n\t\t\tbreak;\n\t\t}\n\n\t\tsave_len = cur_len;\n\t\tfor (i = 0; i < nr_pages; i++) {\n\t\t\tbytes = min_t(const size_t, cur_len, PAGE_SIZE);\n\t\t\tcopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n\t\t\t\t\t\t\t 0, bytes);\n\t\t\tcur_len -= copied;\n\t\t\tiov_iter_advance(&it, copied);\n\t\t\t/*\n\t\t\t * If we didn't copy as much as we expected, then that\n\t\t\t * may mean we trod into an unmapped area. Stop copying\n\t\t\t * at that point. On the next pass through the big\n\t\t\t * loop, we'll likely end up getting a zero-length\n\t\t\t * write and bailing out of it.\n\t\t\t */\n\t\t\tif (copied < bytes)\n\t\t\t\tbreak;\n\t\t}\n\t\tcur_len = save_len - cur_len;\n\n\t\t/*\n\t\t * If we have no data to send, then that probably means that\n\t\t * the copy above failed altogether. That's most likely because\n\t\t * the address in the iovec was bogus. Set the rc to -EFAULT,\n\t\t * free anything we allocated and bail out.\n\t\t */\n\t\tif (!cur_len) {\n\t\t\tfor (i = 0; i < nr_pages; i++)\n\t\t\t\tput_page(wdata->pages[i]);\n\t\t\tkfree(wdata);\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * i + 1 now represents the number of pages we actually used in\n\t\t * the copy phase above. Bring nr_pages down to that, and free\n\t\t * any pages that we didn't use.\n\t\t */\n\t\tfor ( ; nr_pages > i + 1; nr_pages--)\n\t\t\tput_page(wdata->pages[nr_pages - 1]);\n\n\t\twdata->sync_mode = WB_SYNC_ALL;\n\t\twdata->nr_pages = nr_pages;\n\t\twdata->offset = (__u64)offset;\n\t\twdata->cfile = cifsFileInfo_get(open_file);\n\t\twdata->pid = pid;\n\t\twdata->bytes = cur_len;\n\t\twdata->pagesz = PAGE_SIZE;\n\t\twdata->tailsz = cur_len - ((nr_pages - 1) * PAGE_SIZE);\n\t\trc = cifs_uncached_retry_writev(wdata);\n\t\tif (rc) {\n\t\t\tkref_put(&wdata->refcount,\n\t\t\t\t cifs_uncached_writedata_release);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add_tail(&wdata->list, &wdata_list);\n\t\toffset += cur_len;\n\t\tlen -= cur_len;\n\t} while (len > 0);\n\n\t/*\n\t * If at least one write was successfully sent, then discard any rc\n\t * value from the later writes. If the other write succeeds, then\n\t * we'll end up returning whatever was written. If it fails, then\n\t * we'll get a new rc value from that.\n\t */\n\tif (!list_empty(&wdata_list))\n\t\trc = 0;\n\n\t/*\n\t * Wait for and collect replies for any successful sends in order of\n\t * increasing offset. Once an error is hit or we get a fatal signal\n\t * while waiting, then return without waiting for any more replies.\n\t */\nrestart_loop:\n\tlist_for_each_entry_safe(wdata, tmp, &wdata_list, list) {\n\t\tif (!rc) {\n\t\t\t/* FIXME: freezable too? */\n\t\t\trc = wait_for_completion_killable(&wdata->done);\n\t\t\tif (rc)\n\t\t\t\trc = -EINTR;\n\t\t\telse if (wdata->result)\n\t\t\t\trc = wdata->result;\n\t\t\telse\n\t\t\t\ttotal_written += wdata->bytes;\n\n\t\t\t/* resend call if it's a retryable error */\n\t\t\tif (rc == -EAGAIN) {\n\t\t\t\trc = cifs_uncached_retry_writev(wdata);\n\t\t\t\tgoto restart_loop;\n\t\t\t}\n\t\t}\n\t\tlist_del_init(&wdata->list);\n\t\tkref_put(&wdata->refcount, cifs_uncached_writedata_release);\n\t}\n\n\tif (total_written > 0)\n\t\t*poffset += total_written;\n\n\tcifs_stats_bytes_written(tcon, total_written);\n\treturn total_written ? total_written : (ssize_t)rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \t\t unsigned long nr_segs, loff_t *poffset)\n {\n \tunsigned long nr_pages, i;\n-\tsize_t copied, len, cur_len;\n+\tsize_t bytes, copied, len, cur_len;\n \tssize_t total_written = 0;\n \tloff_t offset;\n \tstruct iov_iter it;\n@@ -58,13 +58,44 @@\n \n \t\tsave_len = cur_len;\n \t\tfor (i = 0; i < nr_pages; i++) {\n-\t\t\tcopied = min_t(const size_t, cur_len, PAGE_SIZE);\n+\t\t\tbytes = min_t(const size_t, cur_len, PAGE_SIZE);\n \t\t\tcopied = iov_iter_copy_from_user(wdata->pages[i], &it,\n-\t\t\t\t\t\t\t 0, copied);\n+\t\t\t\t\t\t\t 0, bytes);\n \t\t\tcur_len -= copied;\n \t\t\tiov_iter_advance(&it, copied);\n+\t\t\t/*\n+\t\t\t * If we didn't copy as much as we expected, then that\n+\t\t\t * may mean we trod into an unmapped area. Stop copying\n+\t\t\t * at that point. On the next pass through the big\n+\t\t\t * loop, we'll likely end up getting a zero-length\n+\t\t\t * write and bailing out of it.\n+\t\t\t */\n+\t\t\tif (copied < bytes)\n+\t\t\t\tbreak;\n \t\t}\n \t\tcur_len = save_len - cur_len;\n+\n+\t\t/*\n+\t\t * If we have no data to send, then that probably means that\n+\t\t * the copy above failed altogether. That's most likely because\n+\t\t * the address in the iovec was bogus. Set the rc to -EFAULT,\n+\t\t * free anything we allocated and bail out.\n+\t\t */\n+\t\tif (!cur_len) {\n+\t\t\tfor (i = 0; i < nr_pages; i++)\n+\t\t\t\tput_page(wdata->pages[i]);\n+\t\t\tkfree(wdata);\n+\t\t\trc = -EFAULT;\n+\t\t\tbreak;\n+\t\t}\n+\n+\t\t/*\n+\t\t * i + 1 now represents the number of pages we actually used in\n+\t\t * the copy phase above. Bring nr_pages down to that, and free\n+\t\t * any pages that we didn't use.\n+\t\t */\n+\t\tfor ( ; nr_pages > i + 1; nr_pages--)\n+\t\t\tput_page(wdata->pages[nr_pages - 1]);\n \n \t\twdata->sync_mode = WB_SYNC_ALL;\n \t\twdata->nr_pages = nr_pages;",
        "function_modified_lines": {
            "added": [
                "\tsize_t bytes, copied, len, cur_len;",
                "\t\t\tbytes = min_t(const size_t, cur_len, PAGE_SIZE);",
                "\t\t\t\t\t\t\t 0, bytes);",
                "\t\t\t/*",
                "\t\t\t * If we didn't copy as much as we expected, then that",
                "\t\t\t * may mean we trod into an unmapped area. Stop copying",
                "\t\t\t * at that point. On the next pass through the big",
                "\t\t\t * loop, we'll likely end up getting a zero-length",
                "\t\t\t * write and bailing out of it.",
                "\t\t\t */",
                "\t\t\tif (copied < bytes)",
                "\t\t\t\tbreak;",
                "",
                "\t\t/*",
                "\t\t * If we have no data to send, then that probably means that",
                "\t\t * the copy above failed altogether. That's most likely because",
                "\t\t * the address in the iovec was bogus. Set the rc to -EFAULT,",
                "\t\t * free anything we allocated and bail out.",
                "\t\t */",
                "\t\tif (!cur_len) {",
                "\t\t\tfor (i = 0; i < nr_pages; i++)",
                "\t\t\t\tput_page(wdata->pages[i]);",
                "\t\t\tkfree(wdata);",
                "\t\t\trc = -EFAULT;",
                "\t\t\tbreak;",
                "\t\t}",
                "",
                "\t\t/*",
                "\t\t * i + 1 now represents the number of pages we actually used in",
                "\t\t * the copy phase above. Bring nr_pages down to that, and free",
                "\t\t * any pages that we didn't use.",
                "\t\t */",
                "\t\tfor ( ; nr_pages > i + 1; nr_pages--)",
                "\t\t\tput_page(wdata->pages[nr_pages - 1]);"
            ],
            "deleted": [
                "\tsize_t copied, len, cur_len;",
                "\t\t\tcopied = min_t(const size_t, cur_len, PAGE_SIZE);",
                "\t\t\t\t\t\t\t 0, copied);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The cifs_iovec_write function in fs/cifs/file.c in the Linux kernel through 3.13.5 does not properly handle uncached write operations that copy fewer than the requested number of bytes, which allows local users to obtain sensitive information from kernel memory, cause a denial of service (memory corruption and system crash), or possibly gain privileges via a writev system call with a crafted pointer.",
        "id": 426
    },
    {
        "cve_id": "CVE-2017-7895",
        "code_before_change": "int\nnfs3svc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_writeargs *args)\n{\n\tunsigned int len, v, hdr, dlen;\n\tu32 max_blocksize = svc_max_payload(rqstp);\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tstruct kvec *tail = rqstp->rq_arg.tail;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\tp = xdr_decode_hyper(p, &args->offset);\n\n\targs->count = ntohl(*p++);\n\targs->stable = ntohl(*p++);\n\tlen = args->len = ntohl(*p++);\n\t/*\n\t * The count must equal the amount of data passed.\n\t */\n\tif (args->count != args->len)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len + tail->iov_len - hdr;\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\tif (args->count > max_blocksize) {\n\t\targs->count = max_blocksize;\n\t\tlen = args->len = max_blocksize;\n\t}\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
        "code_after_change": "int\nnfs3svc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_writeargs *args)\n{\n\tunsigned int len, v, hdr, dlen;\n\tu32 max_blocksize = svc_max_payload(rqstp);\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tstruct kvec *tail = rqstp->rq_arg.tail;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\tp = xdr_decode_hyper(p, &args->offset);\n\n\targs->count = ntohl(*p++);\n\targs->stable = ntohl(*p++);\n\tlen = args->len = ntohl(*p++);\n\tif ((void *)p > head->iov_base + head->iov_len)\n\t\treturn 0;\n\t/*\n\t * The count must equal the amount of data passed.\n\t */\n\tif (args->count != args->len)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len + tail->iov_len - hdr;\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\tif (args->count > max_blocksize) {\n\t\targs->count = max_blocksize;\n\t\tlen = args->len = max_blocksize;\n\t}\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,6 +15,8 @@\n \targs->count = ntohl(*p++);\n \targs->stable = ntohl(*p++);\n \tlen = args->len = ntohl(*p++);\n+\tif ((void *)p > head->iov_base + head->iov_len)\n+\t\treturn 0;\n \t/*\n \t * The count must equal the amount of data passed.\n \t */",
        "function_modified_lines": {
            "added": [
                "\tif ((void *)p > head->iov_base + head->iov_len)",
                "\t\treturn 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The NFSv2 and NFSv3 server implementations in the Linux kernel through 4.10.13 lack certain checks for the end of a buffer, which allows remote attackers to trigger pointer-arithmetic errors or possibly have unspecified other impact via crafted requests, related to fs/nfsd/nfs3xdr.c and fs/nfsd/nfsxdr.c.",
        "id": 1532
    },
    {
        "cve_id": "CVE-2015-1333",
        "code_before_change": "void __key_link_end(struct key *keyring,\n\t\t    const struct keyring_index_key *index_key,\n\t\t    struct assoc_array_edit *edit)\n\t__releases(&keyring->sem)\n\t__releases(&keyring_serialise_link_sem)\n{\n\tBUG_ON(index_key->type == NULL);\n\tkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\n\n\tif (index_key->type == &key_type_keyring)\n\t\tup_write(&keyring_serialise_link_sem);\n\n\tif (edit && !edit->dead_leaf) {\n\t\tkey_payload_reserve(keyring,\n\t\t\t\t    keyring->datalen - KEYQUOTA_LINK_BYTES);\n\t\tassoc_array_cancel_edit(edit);\n\t}\n\tup_write(&keyring->sem);\n}",
        "code_after_change": "void __key_link_end(struct key *keyring,\n\t\t    const struct keyring_index_key *index_key,\n\t\t    struct assoc_array_edit *edit)\n\t__releases(&keyring->sem)\n\t__releases(&keyring_serialise_link_sem)\n{\n\tBUG_ON(index_key->type == NULL);\n\tkenter(\"%d,%s,\", keyring->serial, index_key->type->name);\n\n\tif (index_key->type == &key_type_keyring)\n\t\tup_write(&keyring_serialise_link_sem);\n\n\tif (edit) {\n\t\tif (!edit->dead_leaf) {\n\t\t\tkey_payload_reserve(keyring,\n\t\t\t\tkeyring->datalen - KEYQUOTA_LINK_BYTES);\n\t\t}\n\t\tassoc_array_cancel_edit(edit);\n\t}\n\tup_write(&keyring->sem);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,9 +10,11 @@\n \tif (index_key->type == &key_type_keyring)\n \t\tup_write(&keyring_serialise_link_sem);\n \n-\tif (edit && !edit->dead_leaf) {\n-\t\tkey_payload_reserve(keyring,\n-\t\t\t\t    keyring->datalen - KEYQUOTA_LINK_BYTES);\n+\tif (edit) {\n+\t\tif (!edit->dead_leaf) {\n+\t\t\tkey_payload_reserve(keyring,\n+\t\t\t\tkeyring->datalen - KEYQUOTA_LINK_BYTES);\n+\t\t}\n \t\tassoc_array_cancel_edit(edit);\n \t}\n \tup_write(&keyring->sem);",
        "function_modified_lines": {
            "added": [
                "\tif (edit) {",
                "\t\tif (!edit->dead_leaf) {",
                "\t\t\tkey_payload_reserve(keyring,",
                "\t\t\t\tkeyring->datalen - KEYQUOTA_LINK_BYTES);",
                "\t\t}"
            ],
            "deleted": [
                "\tif (edit && !edit->dead_leaf) {",
                "\t\tkey_payload_reserve(keyring,",
                "\t\t\t\t    keyring->datalen - KEYQUOTA_LINK_BYTES);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Memory leak in the __key_link_end function in security/keys/keyring.c in the Linux kernel before 4.1.4 allows local users to cause a denial of service (memory consumption) via many add_key system calls that refer to existing keys.",
        "id": 728
    },
    {
        "cve_id": "CVE-2021-3635",
        "code_before_change": "static int nft_flush_table(struct nft_ctx *ctx)\n{\n\tstruct nft_flowtable *flowtable, *nft;\n\tstruct nft_chain *chain, *nc;\n\tstruct nft_object *obj, *ne;\n\tstruct nft_set *set, *ns;\n\tint err;\n\n\tlist_for_each_entry(chain, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delrule_by_chain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\n\t\tif (!nft_is_active_next(ctx->net, set))\n\t\t\tcontinue;\n\n\t\tif (nft_set_is_anonymous(set) &&\n\t\t    !list_empty(&set->bindings))\n\t\t\tcontinue;\n\n\t\terr = nft_delset(ctx, set);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\n\t\terr = nft_delflowtable(ctx, flowtable);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\n\t\terr = nft_delobj(ctx, obj);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delchain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\terr = nft_deltable(ctx);\nout:\n\treturn err;\n}",
        "code_after_change": "static int nft_flush_table(struct nft_ctx *ctx)\n{\n\tstruct nft_flowtable *flowtable, *nft;\n\tstruct nft_chain *chain, *nc;\n\tstruct nft_object *obj, *ne;\n\tstruct nft_set *set, *ns;\n\tint err;\n\n\tlist_for_each_entry(chain, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delrule_by_chain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(set, ns, &ctx->table->sets, list) {\n\t\tif (!nft_is_active_next(ctx->net, set))\n\t\t\tcontinue;\n\n\t\tif (nft_set_is_anonymous(set) &&\n\t\t    !list_empty(&set->bindings))\n\t\t\tcontinue;\n\n\t\terr = nft_delset(ctx, set);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\n\t\tif (!nft_is_active_next(ctx->net, flowtable))\n\t\t\tcontinue;\n\n\t\terr = nft_delflowtable(ctx, flowtable);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\n\t\tif (!nft_is_active_next(ctx->net, obj))\n\t\t\tcontinue;\n\n\t\terr = nft_delobj(ctx, obj);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tlist_for_each_entry_safe(chain, nc, &ctx->table->chains, list) {\n\t\tif (!nft_is_active_next(ctx->net, chain))\n\t\t\tcontinue;\n\n\t\tctx->chain = chain;\n\n\t\terr = nft_delchain(ctx);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\terr = nft_deltable(ctx);\nout:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,12 +31,18 @@\n \t}\n \n \tlist_for_each_entry_safe(flowtable, nft, &ctx->table->flowtables, list) {\n+\t\tif (!nft_is_active_next(ctx->net, flowtable))\n+\t\t\tcontinue;\n+\n \t\terr = nft_delflowtable(ctx, flowtable);\n \t\tif (err < 0)\n \t\t\tgoto out;\n \t}\n \n \tlist_for_each_entry_safe(obj, ne, &ctx->table->objects, list) {\n+\t\tif (!nft_is_active_next(ctx->net, obj))\n+\t\t\tcontinue;\n+\n \t\terr = nft_delobj(ctx, obj);\n \t\tif (err < 0)\n \t\t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "\t\tif (!nft_is_active_next(ctx->net, flowtable))",
                "\t\t\tcontinue;",
                "",
                "\t\tif (!nft_is_active_next(ctx->net, obj))",
                "\t\t\tcontinue;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A flaw was found in the Linux kernel netfilter implementation in versions prior to 5.5-rc7. A user with root (CAP_SYS_ADMIN) access is able to panic the system when issuing netfilter netflow commands.",
        "id": 3025
    },
    {
        "cve_id": "CVE-2016-5829",
        "code_before_change": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\n\tstruct hid_device *hid = hiddev->hid;\n\tstruct hiddev_report_info rinfo;\n\tstruct hiddev_usage_ref_multi *uref_multi = NULL;\n\tstruct hiddev_usage_ref *uref;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tint i;\n\n\turef_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\n\tif (!uref_multi)\n\t\treturn -ENOMEM;\n\turef = &uref_multi->uref;\n\tif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\n\t\tif (copy_from_user(uref_multi, user_arg,\n\t\t\t\t   sizeof(*uref_multi)))\n\t\t\tgoto fault;\n\t} else {\n\t\tif (copy_from_user(uref, user_arg, sizeof(*uref)))\n\t\t\tgoto fault;\n\t}\n\n\tswitch (cmd) {\n\tcase HIDIOCGUCODE:\n\t\trinfo.report_type = uref->report_type;\n\t\trinfo.report_id = uref->report_id;\n\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\tgoto inval;\n\n\t\tif (uref->field_index >= report->maxfield)\n\t\t\tgoto inval;\n\n\t\tfield = report->field[uref->field_index];\n\t\tif (uref->usage_index >= field->maxusage)\n\t\t\tgoto inval;\n\n\t\turef->usage_code = field->usage[uref->usage_index].hid;\n\n\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\tgoto fault;\n\n\t\tgoto goodreturn;\n\n\tdefault:\n\t\tif (cmd != HIDIOCGUSAGE &&\n\t\t    cmd != HIDIOCGUSAGES &&\n\t\t    uref->report_type == HID_REPORT_TYPE_INPUT)\n\t\t\tgoto inval;\n\n\t\tif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\n\t\t\tfield = hiddev_lookup_usage(hid, uref);\n\t\t\tif (field == NULL)\n\t\t\t\tgoto inval;\n\t\t} else {\n\t\t\trinfo.report_type = uref->report_type;\n\t\t\trinfo.report_id = uref->report_id;\n\t\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\t\tgoto inval;\n\n\t\t\tif (uref->field_index >= report->maxfield)\n\t\t\t\tgoto inval;\n\n\t\t\tfield = report->field[uref->field_index];\n\n\t\t\tif (cmd == HIDIOCGCOLLECTIONINDEX) {\n\t\t\t\tif (uref->usage_index >= field->maxusage)\n\t\t\t\t\tgoto inval;\n\t\t\t} else if (uref->usage_index >= field->report_count)\n\t\t\t\tgoto inval;\n\n\t\t\telse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n\t\t\t\t (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n\t\t\t\t  uref->usage_index + uref_multi->num_values > field->report_count))\n\t\t\t\tgoto inval;\n\t\t}\n\n\t\tswitch (cmd) {\n\t\tcase HIDIOCGUSAGE:\n\t\t\turef->value = field->value[uref->usage_index];\n\t\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCSUSAGE:\n\t\t\tfield->value[uref->usage_index] = uref->value;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCGCOLLECTIONINDEX:\n\t\t\ti = field->usage[uref->usage_index].collection_index;\n\t\t\tkfree(uref_multi);\n\t\t\treturn i;\n\t\tcase HIDIOCGUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\turef_multi->values[i] =\n\t\t\t\t    field->value[uref->usage_index + i];\n\t\t\tif (copy_to_user(user_arg, uref_multi,\n\t\t\t\t\t sizeof(*uref_multi)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\t\tcase HIDIOCSUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\tfield->value[uref->usage_index + i] =\n\t\t\t\t    uref_multi->values[i];\n\t\t\tgoto goodreturn;\n\t\t}\n\ngoodreturn:\n\t\tkfree(uref_multi);\n\t\treturn 0;\nfault:\n\t\tkfree(uref_multi);\n\t\treturn -EFAULT;\ninval:\n\t\tkfree(uref_multi);\n\t\treturn -EINVAL;\n\t}\n}",
        "code_after_change": "static noinline int hiddev_ioctl_usage(struct hiddev *hiddev, unsigned int cmd, void __user *user_arg)\n{\n\tstruct hid_device *hid = hiddev->hid;\n\tstruct hiddev_report_info rinfo;\n\tstruct hiddev_usage_ref_multi *uref_multi = NULL;\n\tstruct hiddev_usage_ref *uref;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tint i;\n\n\turef_multi = kmalloc(sizeof(struct hiddev_usage_ref_multi), GFP_KERNEL);\n\tif (!uref_multi)\n\t\treturn -ENOMEM;\n\turef = &uref_multi->uref;\n\tif (cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) {\n\t\tif (copy_from_user(uref_multi, user_arg,\n\t\t\t\t   sizeof(*uref_multi)))\n\t\t\tgoto fault;\n\t} else {\n\t\tif (copy_from_user(uref, user_arg, sizeof(*uref)))\n\t\t\tgoto fault;\n\t}\n\n\tswitch (cmd) {\n\tcase HIDIOCGUCODE:\n\t\trinfo.report_type = uref->report_type;\n\t\trinfo.report_id = uref->report_id;\n\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\tgoto inval;\n\n\t\tif (uref->field_index >= report->maxfield)\n\t\t\tgoto inval;\n\n\t\tfield = report->field[uref->field_index];\n\t\tif (uref->usage_index >= field->maxusage)\n\t\t\tgoto inval;\n\n\t\turef->usage_code = field->usage[uref->usage_index].hid;\n\n\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\tgoto fault;\n\n\t\tgoto goodreturn;\n\n\tdefault:\n\t\tif (cmd != HIDIOCGUSAGE &&\n\t\t    cmd != HIDIOCGUSAGES &&\n\t\t    uref->report_type == HID_REPORT_TYPE_INPUT)\n\t\t\tgoto inval;\n\n\t\tif (uref->report_id == HID_REPORT_ID_UNKNOWN) {\n\t\t\tfield = hiddev_lookup_usage(hid, uref);\n\t\t\tif (field == NULL)\n\t\t\t\tgoto inval;\n\t\t} else {\n\t\t\trinfo.report_type = uref->report_type;\n\t\t\trinfo.report_id = uref->report_id;\n\t\t\tif ((report = hiddev_lookup_report(hid, &rinfo)) == NULL)\n\t\t\t\tgoto inval;\n\n\t\t\tif (uref->field_index >= report->maxfield)\n\t\t\t\tgoto inval;\n\n\t\t\tfield = report->field[uref->field_index];\n\n\t\t\tif (cmd == HIDIOCGCOLLECTIONINDEX) {\n\t\t\t\tif (uref->usage_index >= field->maxusage)\n\t\t\t\t\tgoto inval;\n\t\t\t} else if (uref->usage_index >= field->report_count)\n\t\t\t\tgoto inval;\n\t\t}\n\n\t\tif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n\t\t    (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n\t\t     uref->usage_index + uref_multi->num_values > field->report_count))\n\t\t\tgoto inval;\n\n\t\tswitch (cmd) {\n\t\tcase HIDIOCGUSAGE:\n\t\t\turef->value = field->value[uref->usage_index];\n\t\t\tif (copy_to_user(user_arg, uref, sizeof(*uref)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCSUSAGE:\n\t\t\tfield->value[uref->usage_index] = uref->value;\n\t\t\tgoto goodreturn;\n\n\t\tcase HIDIOCGCOLLECTIONINDEX:\n\t\t\ti = field->usage[uref->usage_index].collection_index;\n\t\t\tkfree(uref_multi);\n\t\t\treturn i;\n\t\tcase HIDIOCGUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\turef_multi->values[i] =\n\t\t\t\t    field->value[uref->usage_index + i];\n\t\t\tif (copy_to_user(user_arg, uref_multi,\n\t\t\t\t\t sizeof(*uref_multi)))\n\t\t\t\tgoto fault;\n\t\t\tgoto goodreturn;\n\t\tcase HIDIOCSUSAGES:\n\t\t\tfor (i = 0; i < uref_multi->num_values; i++)\n\t\t\t\tfield->value[uref->usage_index + i] =\n\t\t\t\t    uref_multi->values[i];\n\t\t\tgoto goodreturn;\n\t\t}\n\ngoodreturn:\n\t\tkfree(uref_multi);\n\t\treturn 0;\nfault:\n\t\tkfree(uref_multi);\n\t\treturn -EFAULT;\ninval:\n\t\tkfree(uref_multi);\n\t\treturn -EINVAL;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -68,12 +68,12 @@\n \t\t\t\t\tgoto inval;\n \t\t\t} else if (uref->usage_index >= field->report_count)\n \t\t\t\tgoto inval;\n+\t\t}\n \n-\t\t\telse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n-\t\t\t\t (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n-\t\t\t\t  uref->usage_index + uref_multi->num_values > field->report_count))\n-\t\t\t\tgoto inval;\n-\t\t}\n+\t\tif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&\n+\t\t    (uref_multi->num_values > HID_MAX_MULTI_USAGES ||\n+\t\t     uref->usage_index + uref_multi->num_values > field->report_count))\n+\t\t\tgoto inval;\n \n \t\tswitch (cmd) {\n \t\tcase HIDIOCGUSAGE:",
        "function_modified_lines": {
            "added": [
                "\t\t}",
                "\t\tif ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&",
                "\t\t    (uref_multi->num_values > HID_MAX_MULTI_USAGES ||",
                "\t\t     uref->usage_index + uref_multi->num_values > field->report_count))",
                "\t\t\tgoto inval;"
            ],
            "deleted": [
                "\t\t\telse if ((cmd == HIDIOCGUSAGES || cmd == HIDIOCSUSAGES) &&",
                "\t\t\t\t (uref_multi->num_values > HID_MAX_MULTI_USAGES ||",
                "\t\t\t\t  uref->usage_index + uref_multi->num_values > field->report_count))",
                "\t\t\t\tgoto inval;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple heap-based buffer overflows in the hiddev_ioctl_usage function in drivers/hid/usbhid/hiddev.c in the Linux kernel through 4.6.3 allow local users to cause a denial of service or possibly have unspecified other impact via a crafted (1) HIDIOCGUSAGES or (2) HIDIOCSUSAGES ioctl call.",
        "id": 1058
    },
    {
        "cve_id": "CVE-2013-4512",
        "code_before_change": "static ssize_t exitcode_proc_write(struct file *file,\n\t\tconst char __user *buffer, size_t count, loff_t *pos)\n{\n\tchar *end, buf[sizeof(\"nnnnn\\0\")];\n\tint tmp;\n\n\tif (copy_from_user(buf, buffer, count))\n\t\treturn -EFAULT;\n\n\ttmp = simple_strtol(buf, &end, 0);\n\tif ((*end != '\\0') && !isspace(*end))\n\t\treturn -EINVAL;\n\n\tuml_exitcode = tmp;\n\treturn count;\n}",
        "code_after_change": "static ssize_t exitcode_proc_write(struct file *file,\n\t\tconst char __user *buffer, size_t count, loff_t *pos)\n{\n\tchar *end, buf[sizeof(\"nnnnn\\0\")];\n\tsize_t size;\n\tint tmp;\n\n\tsize = min(count, sizeof(buf));\n\tif (copy_from_user(buf, buffer, size))\n\t\treturn -EFAULT;\n\n\ttmp = simple_strtol(buf, &end, 0);\n\tif ((*end != '\\0') && !isspace(*end))\n\t\treturn -EINVAL;\n\n\tuml_exitcode = tmp;\n\treturn count;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,9 +2,11 @@\n \t\tconst char __user *buffer, size_t count, loff_t *pos)\n {\n \tchar *end, buf[sizeof(\"nnnnn\\0\")];\n+\tsize_t size;\n \tint tmp;\n \n-\tif (copy_from_user(buf, buffer, count))\n+\tsize = min(count, sizeof(buf));\n+\tif (copy_from_user(buf, buffer, size))\n \t\treturn -EFAULT;\n \n \ttmp = simple_strtol(buf, &end, 0);",
        "function_modified_lines": {
            "added": [
                "\tsize_t size;",
                "\tsize = min(count, sizeof(buf));",
                "\tif (copy_from_user(buf, buffer, size))"
            ],
            "deleted": [
                "\tif (copy_from_user(buf, buffer, count))"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the exitcode_proc_write function in arch/um/kernel/exitcode.c in the Linux kernel before 3.12 allows local users to cause a denial of service or possibly have unspecified other impact by leveraging root privileges for a write operation.",
        "id": 322
    },
    {
        "cve_id": "CVE-2017-18222",
        "code_before_change": "static int hns_gmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(g_gmac_stats_string);\n\n\treturn 0;\n}",
        "code_after_change": "static int hns_gmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn ARRAY_SIZE(g_gmac_stats_string);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static int hns_gmac_get_sset_count(int stringset)\n {\n-\tif (stringset == ETH_SS_STATS)\n+\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n \t\treturn ARRAY_SIZE(g_gmac_stats_string);\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
            ],
            "deleted": [
                "\tif (stringset == ETH_SS_STATS)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.12, Hisilicon Network Subsystem (HNS) does not consider the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, which allows local users to cause a denial of service (buffer overflow and memory corruption) or possibly have unspecified other impact, as demonstrated by incompatibility between hns_get_sset_count and ethtool_get_strings.",
        "id": 1407
    },
    {
        "cve_id": "CVE-2013-4312",
        "code_before_change": "void unix_inflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tspin_lock(&unix_gc_lock);\n\n\t\tif (atomic_long_inc_return(&u->inflight) == 1) {\n\t\t\tBUG_ON(!list_empty(&u->link));\n\t\t\tlist_add_tail(&u->link, &gc_inflight_list);\n\t\t} else {\n\t\t\tBUG_ON(list_empty(&u->link));\n\t\t}\n\t\tunix_tot_inflight++;\n\t\tspin_unlock(&unix_gc_lock);\n\t}\n}",
        "code_after_change": "void unix_inflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tif (atomic_long_inc_return(&u->inflight) == 1) {\n\t\t\tBUG_ON(!list_empty(&u->link));\n\t\t\tlist_add_tail(&u->link, &gc_inflight_list);\n\t\t} else {\n\t\t\tBUG_ON(list_empty(&u->link));\n\t\t}\n\t\tunix_tot_inflight++;\n\t}\n\tfp->f_cred->user->unix_inflight++;\n\tspin_unlock(&unix_gc_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,10 +2,10 @@\n {\n \tstruct sock *s = unix_get_socket(fp);\n \n+\tspin_lock(&unix_gc_lock);\n+\n \tif (s) {\n \t\tstruct unix_sock *u = unix_sk(s);\n-\n-\t\tspin_lock(&unix_gc_lock);\n \n \t\tif (atomic_long_inc_return(&u->inflight) == 1) {\n \t\t\tBUG_ON(!list_empty(&u->link));\n@@ -14,6 +14,7 @@\n \t\t\tBUG_ON(list_empty(&u->link));\n \t\t}\n \t\tunix_tot_inflight++;\n-\t\tspin_unlock(&unix_gc_lock);\n \t}\n+\tfp->f_cred->user->unix_inflight++;\n+\tspin_unlock(&unix_gc_lock);\n }",
        "function_modified_lines": {
            "added": [
                "\tspin_lock(&unix_gc_lock);",
                "",
                "\tfp->f_cred->user->unix_inflight++;",
                "\tspin_unlock(&unix_gc_lock);"
            ],
            "deleted": [
                "",
                "\t\tspin_lock(&unix_gc_lock);",
                "\t\tspin_unlock(&unix_gc_lock);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Linux kernel before 4.4.1 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by sending each descriptor over a UNIX socket before closing it, related to net/unix/af_unix.c and net/unix/garbage.c.",
        "id": 296
    },
    {
        "cve_id": "CVE-2017-8062",
        "code_before_change": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\n\t\t\t\t\t\t\t\tint num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tu8 obuf[0x40], ibuf[0x40];\n\n\tif (!d)\n\t\treturn -ENODEV;\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\n\tswitch (num) {\n\tcase 1:\n\t\tswitch (msg[0].addr) {\n\t\tcase SU3000_STREAM_CTRL:\n\t\t\tobuf[0] = msg[0].buf[0] + 0x36;\n\t\t\tobuf[1] = 3;\n\t\t\tobuf[2] = 0;\n\t\t\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tbreak;\n\t\tcase DW2102_RC_QUERY:\n\t\t\tobuf[0] = 0x10;\n\t\t\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tmsg[0].buf[1] = ibuf[0];\n\t\t\tmsg[0].buf[0] = ibuf[1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* always i2c write*/\n\t\t\tobuf[0] = 0x08;\n\t\t\tobuf[1] = msg[0].addr;\n\t\t\tobuf[2] = msg[0].len;\n\n\t\t\tmemcpy(&obuf[3], msg[0].buf, msg[0].len);\n\n\t\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,\n\t\t\t\t\t\tibuf, 1, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\t/* always i2c read */\n\t\tobuf[0] = 0x09;\n\t\tobuf[1] = msg[0].len;\n\t\tobuf[2] = msg[1].len;\n\t\tobuf[3] = msg[0].addr;\n\t\tmemcpy(&obuf[4], msg[0].buf, msg[0].len);\n\n\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,\n\t\t\t\t\tibuf, msg[1].len + 1, 0) < 0)\n\t\t\terr(\"i2c transfer failed.\");\n\n\t\tmemcpy(msg[1].buf, &ibuf[1], msg[1].len);\n\t\tbreak;\n\tdefault:\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet.\");\n\t\tbreak;\n\t}\n\tmutex_unlock(&d->i2c_mutex);\n\treturn num;\n}",
        "code_after_change": "static int su3000_i2c_transfer(struct i2c_adapter *adap, struct i2c_msg msg[],\n\t\t\t\t\t\t\t\tint num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tstruct dw2102_state *state;\n\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tstate = d->priv;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n\t\treturn -EAGAIN;\n\tif (mutex_lock_interruptible(&d->data_mutex) < 0) {\n\t\tmutex_unlock(&d->i2c_mutex);\n\t\treturn -EAGAIN;\n\t}\n\n\tswitch (num) {\n\tcase 1:\n\t\tswitch (msg[0].addr) {\n\t\tcase SU3000_STREAM_CTRL:\n\t\t\tstate->data[0] = msg[0].buf[0] + 0x36;\n\t\t\tstate->data[1] = 3;\n\t\t\tstate->data[2] = 0;\n\t\t\tif (dvb_usb_generic_rw(d, state->data, 3,\n\t\t\t\t\tstate->data, 0, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tbreak;\n\t\tcase DW2102_RC_QUERY:\n\t\t\tstate->data[0] = 0x10;\n\t\t\tif (dvb_usb_generic_rw(d, state->data, 1,\n\t\t\t\t\tstate->data, 2, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\t\t\tmsg[0].buf[1] = state->data[0];\n\t\t\tmsg[0].buf[0] = state->data[1];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* always i2c write*/\n\t\t\tstate->data[0] = 0x08;\n\t\t\tstate->data[1] = msg[0].addr;\n\t\t\tstate->data[2] = msg[0].len;\n\n\t\t\tmemcpy(&state->data[3], msg[0].buf, msg[0].len);\n\n\t\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,\n\t\t\t\t\t\tstate->data, 1, 0) < 0)\n\t\t\t\terr(\"i2c transfer failed.\");\n\n\t\t}\n\t\tbreak;\n\tcase 2:\n\t\t/* always i2c read */\n\t\tstate->data[0] = 0x09;\n\t\tstate->data[1] = msg[0].len;\n\t\tstate->data[2] = msg[1].len;\n\t\tstate->data[3] = msg[0].addr;\n\t\tmemcpy(&state->data[4], msg[0].buf, msg[0].len);\n\n\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,\n\t\t\t\t\tstate->data, msg[1].len + 1, 0) < 0)\n\t\t\terr(\"i2c transfer failed.\");\n\n\t\tmemcpy(msg[1].buf, &state->data[1], msg[1].len);\n\t\tbreak;\n\tdefault:\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet.\");\n\t\tbreak;\n\t}\n\tmutex_unlock(&d->data_mutex);\n\tmutex_unlock(&d->i2c_mutex);\n\treturn num;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,62 +2,72 @@\n \t\t\t\t\t\t\t\tint num)\n {\n \tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n-\tu8 obuf[0x40], ibuf[0x40];\n+\tstruct dw2102_state *state;\n \n \tif (!d)\n \t\treturn -ENODEV;\n+\n+\tstate = d->priv;\n+\n \tif (mutex_lock_interruptible(&d->i2c_mutex) < 0)\n \t\treturn -EAGAIN;\n+\tif (mutex_lock_interruptible(&d->data_mutex) < 0) {\n+\t\tmutex_unlock(&d->i2c_mutex);\n+\t\treturn -EAGAIN;\n+\t}\n \n \tswitch (num) {\n \tcase 1:\n \t\tswitch (msg[0].addr) {\n \t\tcase SU3000_STREAM_CTRL:\n-\t\t\tobuf[0] = msg[0].buf[0] + 0x36;\n-\t\t\tobuf[1] = 3;\n-\t\t\tobuf[2] = 0;\n-\t\t\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)\n+\t\t\tstate->data[0] = msg[0].buf[0] + 0x36;\n+\t\t\tstate->data[1] = 3;\n+\t\t\tstate->data[2] = 0;\n+\t\t\tif (dvb_usb_generic_rw(d, state->data, 3,\n+\t\t\t\t\tstate->data, 0, 0) < 0)\n \t\t\t\terr(\"i2c transfer failed.\");\n \t\t\tbreak;\n \t\tcase DW2102_RC_QUERY:\n-\t\t\tobuf[0] = 0x10;\n-\t\t\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)\n+\t\t\tstate->data[0] = 0x10;\n+\t\t\tif (dvb_usb_generic_rw(d, state->data, 1,\n+\t\t\t\t\tstate->data, 2, 0) < 0)\n \t\t\t\terr(\"i2c transfer failed.\");\n-\t\t\tmsg[0].buf[1] = ibuf[0];\n-\t\t\tmsg[0].buf[0] = ibuf[1];\n+\t\t\tmsg[0].buf[1] = state->data[0];\n+\t\t\tmsg[0].buf[0] = state->data[1];\n \t\t\tbreak;\n \t\tdefault:\n \t\t\t/* always i2c write*/\n-\t\t\tobuf[0] = 0x08;\n-\t\t\tobuf[1] = msg[0].addr;\n-\t\t\tobuf[2] = msg[0].len;\n+\t\t\tstate->data[0] = 0x08;\n+\t\t\tstate->data[1] = msg[0].addr;\n+\t\t\tstate->data[2] = msg[0].len;\n \n-\t\t\tmemcpy(&obuf[3], msg[0].buf, msg[0].len);\n+\t\t\tmemcpy(&state->data[3], msg[0].buf, msg[0].len);\n \n-\t\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,\n-\t\t\t\t\t\tibuf, 1, 0) < 0)\n+\t\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,\n+\t\t\t\t\t\tstate->data, 1, 0) < 0)\n \t\t\t\terr(\"i2c transfer failed.\");\n \n \t\t}\n \t\tbreak;\n \tcase 2:\n \t\t/* always i2c read */\n-\t\tobuf[0] = 0x09;\n-\t\tobuf[1] = msg[0].len;\n-\t\tobuf[2] = msg[1].len;\n-\t\tobuf[3] = msg[0].addr;\n-\t\tmemcpy(&obuf[4], msg[0].buf, msg[0].len);\n+\t\tstate->data[0] = 0x09;\n+\t\tstate->data[1] = msg[0].len;\n+\t\tstate->data[2] = msg[1].len;\n+\t\tstate->data[3] = msg[0].addr;\n+\t\tmemcpy(&state->data[4], msg[0].buf, msg[0].len);\n \n-\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,\n-\t\t\t\t\tibuf, msg[1].len + 1, 0) < 0)\n+\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,\n+\t\t\t\t\tstate->data, msg[1].len + 1, 0) < 0)\n \t\t\terr(\"i2c transfer failed.\");\n \n-\t\tmemcpy(msg[1].buf, &ibuf[1], msg[1].len);\n+\t\tmemcpy(msg[1].buf, &state->data[1], msg[1].len);\n \t\tbreak;\n \tdefault:\n \t\twarn(\"more than 2 i2c messages at a time is not handled yet.\");\n \t\tbreak;\n \t}\n+\tmutex_unlock(&d->data_mutex);\n \tmutex_unlock(&d->i2c_mutex);\n \treturn num;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct dw2102_state *state;",
                "",
                "\tstate = d->priv;",
                "",
                "\tif (mutex_lock_interruptible(&d->data_mutex) < 0) {",
                "\t\tmutex_unlock(&d->i2c_mutex);",
                "\t\treturn -EAGAIN;",
                "\t}",
                "\t\t\tstate->data[0] = msg[0].buf[0] + 0x36;",
                "\t\t\tstate->data[1] = 3;",
                "\t\t\tstate->data[2] = 0;",
                "\t\t\tif (dvb_usb_generic_rw(d, state->data, 3,",
                "\t\t\t\t\tstate->data, 0, 0) < 0)",
                "\t\t\tstate->data[0] = 0x10;",
                "\t\t\tif (dvb_usb_generic_rw(d, state->data, 1,",
                "\t\t\t\t\tstate->data, 2, 0) < 0)",
                "\t\t\tmsg[0].buf[1] = state->data[0];",
                "\t\t\tmsg[0].buf[0] = state->data[1];",
                "\t\t\tstate->data[0] = 0x08;",
                "\t\t\tstate->data[1] = msg[0].addr;",
                "\t\t\tstate->data[2] = msg[0].len;",
                "\t\t\tmemcpy(&state->data[3], msg[0].buf, msg[0].len);",
                "\t\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 3,",
                "\t\t\t\t\t\tstate->data, 1, 0) < 0)",
                "\t\tstate->data[0] = 0x09;",
                "\t\tstate->data[1] = msg[0].len;",
                "\t\tstate->data[2] = msg[1].len;",
                "\t\tstate->data[3] = msg[0].addr;",
                "\t\tmemcpy(&state->data[4], msg[0].buf, msg[0].len);",
                "\t\tif (dvb_usb_generic_rw(d, state->data, msg[0].len + 4,",
                "\t\t\t\t\tstate->data, msg[1].len + 1, 0) < 0)",
                "\t\tmemcpy(msg[1].buf, &state->data[1], msg[1].len);",
                "\tmutex_unlock(&d->data_mutex);"
            ],
            "deleted": [
                "\tu8 obuf[0x40], ibuf[0x40];",
                "\t\t\tobuf[0] = msg[0].buf[0] + 0x36;",
                "\t\t\tobuf[1] = 3;",
                "\t\t\tobuf[2] = 0;",
                "\t\t\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 0, 0) < 0)",
                "\t\t\tobuf[0] = 0x10;",
                "\t\t\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 2, 0) < 0)",
                "\t\t\tmsg[0].buf[1] = ibuf[0];",
                "\t\t\tmsg[0].buf[0] = ibuf[1];",
                "\t\t\tobuf[0] = 0x08;",
                "\t\t\tobuf[1] = msg[0].addr;",
                "\t\t\tobuf[2] = msg[0].len;",
                "\t\t\tmemcpy(&obuf[3], msg[0].buf, msg[0].len);",
                "\t\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 3,",
                "\t\t\t\t\t\tibuf, 1, 0) < 0)",
                "\t\tobuf[0] = 0x09;",
                "\t\tobuf[1] = msg[0].len;",
                "\t\tobuf[2] = msg[1].len;",
                "\t\tobuf[3] = msg[0].addr;",
                "\t\tmemcpy(&obuf[4], msg[0].buf, msg[0].len);",
                "\t\tif (dvb_usb_generic_rw(d, obuf, msg[0].len + 4,",
                "\t\t\t\t\tibuf, msg[1].len + 1, 0) < 0)",
                "\t\tmemcpy(msg[1].buf, &ibuf[1], msg[1].len);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dw2102.c in the Linux kernel 4.9.x and 4.10.x before 4.10.4 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1536
    },
    {
        "cve_id": "CVE-2018-7740",
        "code_before_change": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct inode *inode = file_inode(file);\n\tloff_t len, vma_len;\n\tint ret;\n\tstruct hstate *h = hstate_file(file);\n\n\t/*\n\t * vma address alignment (but not the pgoff alignment) has\n\t * already been checked by prepare_hugepage_range.  If you add\n\t * any error returns here, do so after setting VM_HUGETLB, so\n\t * is_vm_hugetlb_page tests below unmap_region go the right\n\t * way when do_mmap_pgoff unwinds (may be important on powerpc\n\t * and ia64).\n\t */\n\tvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\n\tvma->vm_ops = &hugetlb_vm_ops;\n\n\t/*\n\t * Offset passed to mmap (before page shift) could have been\n\t * negative when represented as a (l)off_t.\n\t */\n\tif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)\n\t\treturn -EINVAL;\n\n\tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n\t\treturn -EINVAL;\n\n\tvma_len = (loff_t)(vma->vm_end - vma->vm_start);\n\tlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\n\t/* check for overflow */\n\tif (len < vma_len)\n\t\treturn -EINVAL;\n\n\tinode_lock(inode);\n\tfile_accessed(file);\n\n\tret = -ENOMEM;\n\tif (hugetlb_reserve_pages(inode,\n\t\t\t\tvma->vm_pgoff >> huge_page_order(h),\n\t\t\t\tlen >> huge_page_shift(h), vma,\n\t\t\t\tvma->vm_flags))\n\t\tgoto out;\n\n\tret = 0;\n\tif (vma->vm_flags & VM_WRITE && inode->i_size < len)\n\t\ti_size_write(inode, len);\nout:\n\tinode_unlock(inode);\n\n\treturn ret;\n}",
        "code_after_change": "static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)\n{\n\tstruct inode *inode = file_inode(file);\n\tloff_t len, vma_len;\n\tint ret;\n\tstruct hstate *h = hstate_file(file);\n\n\t/*\n\t * vma address alignment (but not the pgoff alignment) has\n\t * already been checked by prepare_hugepage_range.  If you add\n\t * any error returns here, do so after setting VM_HUGETLB, so\n\t * is_vm_hugetlb_page tests below unmap_region go the right\n\t * way when do_mmap_pgoff unwinds (may be important on powerpc\n\t * and ia64).\n\t */\n\tvma->vm_flags |= VM_HUGETLB | VM_DONTEXPAND;\n\tvma->vm_ops = &hugetlb_vm_ops;\n\n\t/*\n\t * page based offset in vm_pgoff could be sufficiently large to\n\t * overflow a (l)off_t when converted to byte offset.\n\t */\n\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)\n\t\treturn -EINVAL;\n\n\t/* must be huge page aligned */\n\tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n\t\treturn -EINVAL;\n\n\tvma_len = (loff_t)(vma->vm_end - vma->vm_start);\n\tlen = vma_len + ((loff_t)vma->vm_pgoff << PAGE_SHIFT);\n\t/* check for overflow */\n\tif (len < vma_len)\n\t\treturn -EINVAL;\n\n\tinode_lock(inode);\n\tfile_accessed(file);\n\n\tret = -ENOMEM;\n\tif (hugetlb_reserve_pages(inode,\n\t\t\t\tvma->vm_pgoff >> huge_page_order(h),\n\t\t\t\tlen >> huge_page_shift(h), vma,\n\t\t\t\tvma->vm_flags))\n\t\tgoto out;\n\n\tret = 0;\n\tif (vma->vm_flags & VM_WRITE && inode->i_size < len)\n\t\ti_size_write(inode, len);\nout:\n\tinode_unlock(inode);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,12 +17,13 @@\n \tvma->vm_ops = &hugetlb_vm_ops;\n \n \t/*\n-\t * Offset passed to mmap (before page shift) could have been\n-\t * negative when represented as a (l)off_t.\n+\t * page based offset in vm_pgoff could be sufficiently large to\n+\t * overflow a (l)off_t when converted to byte offset.\n \t */\n-\tif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)\n+\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)\n \t\treturn -EINVAL;\n \n+\t/* must be huge page aligned */\n \tif (vma->vm_pgoff & (~huge_page_mask(h) >> PAGE_SHIFT))\n \t\treturn -EINVAL;\n ",
        "function_modified_lines": {
            "added": [
                "\t * page based offset in vm_pgoff could be sufficiently large to",
                "\t * overflow a (l)off_t when converted to byte offset.",
                "\tif (vma->vm_pgoff & PGOFF_LOFFT_MAX)",
                "\t/* must be huge page aligned */"
            ],
            "deleted": [
                "\t * Offset passed to mmap (before page shift) could have been",
                "\t * negative when represented as a (l)off_t.",
                "\tif (((loff_t)vma->vm_pgoff << PAGE_SHIFT) < 0)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The resv_map_release function in mm/hugetlb.c in the Linux kernel through 4.15.7 allows local users to cause a denial of service (BUG) via a crafted application that makes mmap system calls and has a large pgoff argument to the remap_file_pages system call.",
        "id": 1848
    },
    {
        "cve_id": "CVE-2017-18222",
        "code_before_change": "static int hns_xgmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(g_xgmac_stats_string);\n\n\treturn 0;\n}",
        "code_after_change": "static int hns_xgmac_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn ARRAY_SIZE(g_xgmac_stats_string);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static int hns_xgmac_get_sset_count(int stringset)\n {\n-\tif (stringset == ETH_SS_STATS)\n+\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n \t\treturn ARRAY_SIZE(g_xgmac_stats_string);\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
            ],
            "deleted": [
                "\tif (stringset == ETH_SS_STATS)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.12, Hisilicon Network Subsystem (HNS) does not consider the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, which allows local users to cause a denial of service (buffer overflow and memory corruption) or possibly have unspecified other impact, as demonstrated by incompatibility between hns_get_sset_count and ethtool_get_strings.",
        "id": 1410
    },
    {
        "cve_id": "CVE-2013-2893",
        "code_before_change": "static int hid_lg3ff_play(struct input_dev *dev, void *data,\n\t\t\t struct ff_effect *effect)\n{\n\tstruct hid_device *hid = input_get_drvdata(dev);\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct hid_report *report = list_entry(report_list->next, struct hid_report, list);\n\tint x, y;\n\n/*\n * Maxusage should always be 63 (maximum fields)\n * likely a better way to ensure this data is clean\n */\n\tmemset(report->field[0]->value, 0, sizeof(__s32)*report->field[0]->maxusage);\n\n\tswitch (effect->type) {\n\tcase FF_CONSTANT:\n/*\n * Already clamped in ff_memless\n * 0 is center (different then other logitech)\n */\n\t\tx = effect->u.ramp.start_level;\n\t\ty = effect->u.ramp.end_level;\n\n\t\t/* send command byte */\n\t\treport->field[0]->value[0] = 0x51;\n\n/*\n * Sign backwards from other Force3d pro\n * which get recast here in two's complement 8 bits\n */\n\t\treport->field[0]->value[1] = (unsigned char)(-x);\n\t\treport->field[0]->value[31] = (unsigned char)(-y);\n\n\t\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\t\tbreak;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int hid_lg3ff_play(struct input_dev *dev, void *data,\n\t\t\t struct ff_effect *effect)\n{\n\tstruct hid_device *hid = input_get_drvdata(dev);\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct hid_report *report = list_entry(report_list->next, struct hid_report, list);\n\tint x, y;\n\n/*\n * Available values in the field should always be 63, but we only use up to\n * 35. Instead, clear the entire area, however big it is.\n */\n\tmemset(report->field[0]->value, 0,\n\t       sizeof(__s32) * report->field[0]->report_count);\n\n\tswitch (effect->type) {\n\tcase FF_CONSTANT:\n/*\n * Already clamped in ff_memless\n * 0 is center (different then other logitech)\n */\n\t\tx = effect->u.ramp.start_level;\n\t\ty = effect->u.ramp.end_level;\n\n\t\t/* send command byte */\n\t\treport->field[0]->value[0] = 0x51;\n\n/*\n * Sign backwards from other Force3d pro\n * which get recast here in two's complement 8 bits\n */\n\t\treport->field[0]->value[1] = (unsigned char)(-x);\n\t\treport->field[0]->value[31] = (unsigned char)(-y);\n\n\t\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\t\tbreak;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,10 +7,11 @@\n \tint x, y;\n \n /*\n- * Maxusage should always be 63 (maximum fields)\n- * likely a better way to ensure this data is clean\n+ * Available values in the field should always be 63, but we only use up to\n+ * 35. Instead, clear the entire area, however big it is.\n  */\n-\tmemset(report->field[0]->value, 0, sizeof(__s32)*report->field[0]->maxusage);\n+\tmemset(report->field[0]->value, 0,\n+\t       sizeof(__s32) * report->field[0]->report_count);\n \n \tswitch (effect->type) {\n \tcase FF_CONSTANT:",
        "function_modified_lines": {
            "added": [
                " * Available values in the field should always be 63, but we only use up to",
                " * 35. Instead, clear the entire area, however big it is.",
                "\tmemset(report->field[0]->value, 0,",
                "\t       sizeof(__s32) * report->field[0]->report_count);"
            ],
            "deleted": [
                " * Maxusage should always be 63 (maximum fields)",
                " * likely a better way to ensure this data is clean",
                "\tmemset(report->field[0]->value, 0, sizeof(__s32)*report->field[0]->maxusage);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_LOGITECH_FF, CONFIG_LOGIG940_FF, or CONFIG_LOGIWHEELS_FF is enabled, allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) via a crafted device, related to (1) drivers/hid/hid-lgff.c, (2) drivers/hid/hid-lg3ff.c, and (3) drivers/hid/hid-lg4ff.c.",
        "id": 250
    },
    {
        "cve_id": "CVE-2017-8068",
        "code_before_change": "static int get_registers(pegasus_t *pegasus, __u16 indx, __u16 size, void *data)\n{\n\tint ret;\n\n\tret = usb_control_msg(pegasus->usb, usb_rcvctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_GET_REGS, PEGASUS_REQT_READ, 0,\n\t\t\t      indx, data, size, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\treturn ret;\n}",
        "code_after_change": "static int get_registers(pegasus_t *pegasus, __u16 indx, __u16 size, void *data)\n{\n\tu8 *buf;\n\tint ret;\n\n\tbuf = kmalloc(size, GFP_NOIO);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(pegasus->usb, usb_rcvctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_GET_REGS, PEGASUS_REQT_READ, 0,\n\t\t\t      indx, buf, size, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\telse if (ret <= size)\n\t\tmemcpy(data, buf, ret);\n\tkfree(buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,12 +1,20 @@\n static int get_registers(pegasus_t *pegasus, __u16 indx, __u16 size, void *data)\n {\n+\tu8 *buf;\n \tint ret;\n+\n+\tbuf = kmalloc(size, GFP_NOIO);\n+\tif (!buf)\n+\t\treturn -ENOMEM;\n \n \tret = usb_control_msg(pegasus->usb, usb_rcvctrlpipe(pegasus->usb, 0),\n \t\t\t      PEGASUS_REQ_GET_REGS, PEGASUS_REQT_READ, 0,\n-\t\t\t      indx, data, size, 1000);\n+\t\t\t      indx, buf, size, 1000);\n \tif (ret < 0)\n \t\tnetif_dbg(pegasus, drv, pegasus->net,\n \t\t\t  \"%s returned %d\\n\", __func__, ret);\n+\telse if (ret <= size)\n+\t\tmemcpy(data, buf, ret);\n+\tkfree(buf);\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tu8 *buf;",
                "",
                "\tbuf = kmalloc(size, GFP_NOIO);",
                "\tif (!buf)",
                "\t\treturn -ENOMEM;",
                "\t\t\t      indx, buf, size, 1000);",
                "\telse if (ret <= size)",
                "\t\tmemcpy(data, buf, ret);",
                "\tkfree(buf);"
            ],
            "deleted": [
                "\t\t\t      indx, data, size, 1000);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/usb/pegasus.c in the Linux kernel 4.9.x before 4.9.11 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1543
    },
    {
        "cve_id": "CVE-2007-6762",
        "code_before_change": "static int netlbl_cipsov4_add_common(struct genl_info *info,\n\t\t\t\t     struct cipso_v4_doi *doi_def)\n{\n\tstruct nlattr *nla;\n\tint nla_rem;\n\tu32 iter = 0;\n\n\tdoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\n\n\tif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\n\t\t\t\tNLBL_CIPSOV4_A_MAX,\n\t\t\t\tnetlbl_cipsov4_genl_policy) != 0)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\n\t\tif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\n\t\t\tif (iter > CIPSO_V4_TAG_MAXCNT)\n\t\t\t\treturn -EINVAL;\n\t\t\tdoi_def->tags[iter++] = nla_get_u8(nla);\n\t\t}\n\tif (iter < CIPSO_V4_TAG_MAXCNT)\n\t\tdoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;\n\n\treturn 0;\n}",
        "code_after_change": "static int netlbl_cipsov4_add_common(struct genl_info *info,\n\t\t\t\t     struct cipso_v4_doi *doi_def)\n{\n\tstruct nlattr *nla;\n\tint nla_rem;\n\tu32 iter = 0;\n\n\tdoi_def->doi = nla_get_u32(info->attrs[NLBL_CIPSOV4_A_DOI]);\n\n\tif (nla_validate_nested(info->attrs[NLBL_CIPSOV4_A_TAGLST],\n\t\t\t\tNLBL_CIPSOV4_A_MAX,\n\t\t\t\tnetlbl_cipsov4_genl_policy) != 0)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\n\t\tif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\n\t\t\tif (iter >= CIPSO_V4_TAG_MAXCNT)\n\t\t\t\treturn -EINVAL;\n\t\t\tdoi_def->tags[iter++] = nla_get_u8(nla);\n\t\t}\n\twhile (iter < CIPSO_V4_TAG_MAXCNT)\n\t\tdoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,12 +14,12 @@\n \n \tnla_for_each_nested(nla, info->attrs[NLBL_CIPSOV4_A_TAGLST], nla_rem)\n \t\tif (nla->nla_type == NLBL_CIPSOV4_A_TAG) {\n-\t\t\tif (iter > CIPSO_V4_TAG_MAXCNT)\n+\t\t\tif (iter >= CIPSO_V4_TAG_MAXCNT)\n \t\t\t\treturn -EINVAL;\n \t\t\tdoi_def->tags[iter++] = nla_get_u8(nla);\n \t\t}\n-\tif (iter < CIPSO_V4_TAG_MAXCNT)\n-\t\tdoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;\n+\twhile (iter < CIPSO_V4_TAG_MAXCNT)\n+\t\tdoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;\n \n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (iter >= CIPSO_V4_TAG_MAXCNT)",
                "\twhile (iter < CIPSO_V4_TAG_MAXCNT)",
                "\t\tdoi_def->tags[iter++] = CIPSO_V4_TAG_INVALID;"
            ],
            "deleted": [
                "\t\t\tif (iter > CIPSO_V4_TAG_MAXCNT)",
                "\tif (iter < CIPSO_V4_TAG_MAXCNT)",
                "\t\tdoi_def->tags[iter] = CIPSO_V4_TAG_INVALID;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 2.6.20, there is an off-by-one bug in net/netlabel/netlabel_cipso_v4.c where it is possible to overflow the doi_def->tags[] array.",
        "id": 7
    },
    {
        "cve_id": "CVE-2013-2899",
        "code_before_change": "static ssize_t picolcd_operation_mode_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct picolcd_data *data = dev_get_drvdata(dev);\n\tstruct hid_report *report = NULL;\n\tsize_t cnt = count;\n\tint timeout = data->opmode_delay;\n\tunsigned long flags;\n\n\tif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\n\t\tif (data->status & PICOLCD_BOOTLOADER)\n\t\t\treport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\n\t\tbuf += 3;\n\t\tcnt -= 3;\n\t} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\n\t\tif (!(data->status & PICOLCD_BOOTLOADER))\n\t\t\treport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\n\t\tbuf += 10;\n\t\tcnt -= 10;\n\t}\n\tif (!report)\n\t\treturn -EINVAL;\n\n\twhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\n\t\tcnt--;\n\tif (cnt != 0)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&data->lock, flags);\n\thid_set_field(report->field[0], 0, timeout & 0xff);\n\thid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\n\thid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\n\tspin_unlock_irqrestore(&data->lock, flags);\n\treturn count;\n}",
        "code_after_change": "static ssize_t picolcd_operation_mode_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tstruct picolcd_data *data = dev_get_drvdata(dev);\n\tstruct hid_report *report = NULL;\n\tsize_t cnt = count;\n\tint timeout = data->opmode_delay;\n\tunsigned long flags;\n\n\tif (cnt >= 3 && strncmp(\"lcd\", buf, 3) == 0) {\n\t\tif (data->status & PICOLCD_BOOTLOADER)\n\t\t\treport = picolcd_out_report(REPORT_EXIT_FLASHER, data->hdev);\n\t\tbuf += 3;\n\t\tcnt -= 3;\n\t} else if (cnt >= 10 && strncmp(\"bootloader\", buf, 10) == 0) {\n\t\tif (!(data->status & PICOLCD_BOOTLOADER))\n\t\t\treport = picolcd_out_report(REPORT_EXIT_KEYBOARD, data->hdev);\n\t\tbuf += 10;\n\t\tcnt -= 10;\n\t}\n\tif (!report || report->maxfield != 1)\n\t\treturn -EINVAL;\n\n\twhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))\n\t\tcnt--;\n\tif (cnt != 0)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&data->lock, flags);\n\thid_set_field(report->field[0], 0, timeout & 0xff);\n\thid_set_field(report->field[0], 1, (timeout >> 8) & 0xff);\n\thid_hw_request(data->hdev, report, HID_REQ_SET_REPORT);\n\tspin_unlock_irqrestore(&data->lock, flags);\n\treturn count;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t\tbuf += 10;\n \t\tcnt -= 10;\n \t}\n-\tif (!report)\n+\tif (!report || report->maxfield != 1)\n \t\treturn -EINVAL;\n \n \twhile (cnt > 0 && (buf[cnt-1] == '\\n' || buf[cnt-1] == '\\r'))",
        "function_modified_lines": {
            "added": [
                "\tif (!report || report->maxfield != 1)"
            ],
            "deleted": [
                "\tif (!report)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-picolcd_core.c in the Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_HID_PICOLCD is enabled, allows physically proximate attackers to cause a denial of service (NULL pointer dereference and OOPS) via a crafted device.",
        "id": 259
    },
    {
        "cve_id": "CVE-2017-17856",
        "code_before_change": "static int check_ptr_alignment(struct bpf_verifier_env *env,\n\t\t\t       const struct bpf_reg_state *reg,\n\t\t\t       int off, int size)\n{\n\tbool strict = env->strict_alignment;\n\tconst char *pointer_desc = \"\";\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\t/* Special case, because of NET_IP_ALIGN. Given metadata sits\n\t\t * right in front, treat it the very same way.\n\t\t */\n\t\treturn check_pkt_ptr_alignment(env, reg, off, size, strict);\n\tcase PTR_TO_MAP_VALUE:\n\t\tpointer_desc = \"value \";\n\t\tbreak;\n\tcase PTR_TO_CTX:\n\t\tpointer_desc = \"context \";\n\t\tbreak;\n\tcase PTR_TO_STACK:\n\t\tpointer_desc = \"stack \";\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\n\t\t\t\t\t   strict);\n}",
        "code_after_change": "static int check_ptr_alignment(struct bpf_verifier_env *env,\n\t\t\t       const struct bpf_reg_state *reg,\n\t\t\t       int off, int size)\n{\n\tbool strict = env->strict_alignment;\n\tconst char *pointer_desc = \"\";\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\t/* Special case, because of NET_IP_ALIGN. Given metadata sits\n\t\t * right in front, treat it the very same way.\n\t\t */\n\t\treturn check_pkt_ptr_alignment(env, reg, off, size, strict);\n\tcase PTR_TO_MAP_VALUE:\n\t\tpointer_desc = \"value \";\n\t\tbreak;\n\tcase PTR_TO_CTX:\n\t\tpointer_desc = \"context \";\n\t\tbreak;\n\tcase PTR_TO_STACK:\n\t\tpointer_desc = \"stack \";\n\t\t/* The stack spill tracking logic in check_stack_write()\n\t\t * and check_stack_read() relies on stack accesses being\n\t\t * aligned.\n\t\t */\n\t\tstrict = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn check_generic_ptr_alignment(env, reg, pointer_desc, off, size,\n\t\t\t\t\t   strict);\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,6 +20,11 @@\n \t\tbreak;\n \tcase PTR_TO_STACK:\n \t\tpointer_desc = \"stack \";\n+\t\t/* The stack spill tracking logic in check_stack_write()\n+\t\t * and check_stack_read() relies on stack accesses being\n+\t\t * aligned.\n+\t\t */\n+\t\tstrict = true;\n \t\tbreak;\n \tdefault:\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\t\t/* The stack spill tracking logic in check_stack_write()",
                "\t\t * and check_stack_read() relies on stack accesses being",
                "\t\t * aligned.",
                "\t\t */",
                "\t\tstrict = true;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 4.14.8 allows local users to cause a denial of service (memory corruption) or possibly have unspecified other impact by leveraging the lack of stack-pointer alignment enforcement.",
        "id": 1381
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "asmlinkage int vprintk(const char *fmt, va_list args)\n{\n\tint printed_len = 0;\n\tint current_log_level = default_message_loglevel;\n\tunsigned long flags;\n\tint this_cpu;\n\tchar *p;\n\tsize_t plen;\n\tchar special;\n\n\tboot_delay_msec();\n\tprintk_delay();\n\n\t/* This stops the holder of console_sem just where we want him */\n\tlocal_irq_save(flags);\n\tthis_cpu = smp_processor_id();\n\n\t/*\n\t * Ouch, printk recursed into itself!\n\t */\n\tif (unlikely(printk_cpu == this_cpu)) {\n\t\t/*\n\t\t * If a crash is occurring during printk() on this CPU,\n\t\t * then try to get the crash message out but make sure\n\t\t * we can't deadlock. Otherwise just return to avoid the\n\t\t * recursion and return - but flag the recursion so that\n\t\t * it can be printed at the next appropriate moment:\n\t\t */\n\t\tif (!oops_in_progress && !lockdep_recursing(current)) {\n\t\t\trecursion_bug = 1;\n\t\t\tgoto out_restore_irqs;\n\t\t}\n\t\tzap_locks();\n\t}\n\n\tlockdep_off();\n\traw_spin_lock(&logbuf_lock);\n\tprintk_cpu = this_cpu;\n\n\tif (recursion_bug) {\n\t\trecursion_bug = 0;\n\t\tstrcpy(printk_buf, recursion_bug_msg);\n\t\tprinted_len = strlen(recursion_bug_msg);\n\t}\n\t/* Emit the output into the temporary buffer */\n\tprinted_len += vscnprintf(printk_buf + printed_len,\n\t\t\t\t  sizeof(printk_buf) - printed_len, fmt, args);\n\n\tp = printk_buf;\n\n\t/* Read log level and handle special printk prefix */\n\tplen = log_prefix(p, &current_log_level, &special);\n\tif (plen) {\n\t\tp += plen;\n\n\t\tswitch (special) {\n\t\tcase 'c': /* Strip <c> KERN_CONT, continue line */\n\t\t\tplen = 0;\n\t\t\tbreak;\n\t\tcase 'd': /* Strip <d> KERN_DEFAULT, start new line */\n\t\t\tplen = 0;\n\t\tdefault:\n\t\t\tif (!new_text_line) {\n\t\t\t\temit_log_char('\\n');\n\t\t\t\tnew_text_line = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Copy the output into log_buf. If the caller didn't provide\n\t * the appropriate log prefix, we insert them here\n\t */\n\tfor (; *p; p++) {\n\t\tif (new_text_line) {\n\t\t\tnew_text_line = 0;\n\n\t\t\tif (plen) {\n\t\t\t\t/* Copy original log prefix */\n\t\t\t\tint i;\n\n\t\t\t\tfor (i = 0; i < plen; i++)\n\t\t\t\t\temit_log_char(printk_buf[i]);\n\t\t\t\tprinted_len += plen;\n\t\t\t} else {\n\t\t\t\t/* Add log prefix */\n\t\t\t\temit_log_char('<');\n\t\t\t\temit_log_char(current_log_level + '0');\n\t\t\t\temit_log_char('>');\n\t\t\t\tprinted_len += 3;\n\t\t\t}\n\n\t\t\tif (printk_time) {\n\t\t\t\t/* Add the current time stamp */\n\t\t\t\tchar tbuf[50], *tp;\n\t\t\t\tunsigned tlen;\n\t\t\t\tunsigned long long t;\n\t\t\t\tunsigned long nanosec_rem;\n\n\t\t\t\tt = cpu_clock(printk_cpu);\n\t\t\t\tnanosec_rem = do_div(t, 1000000000);\n\t\t\t\ttlen = sprintf(tbuf, \"[%5lu.%06lu] \",\n\t\t\t\t\t\t(unsigned long) t,\n\t\t\t\t\t\tnanosec_rem / 1000);\n\n\t\t\t\tfor (tp = tbuf; tp < tbuf + tlen; tp++)\n\t\t\t\t\temit_log_char(*tp);\n\t\t\t\tprinted_len += tlen;\n\t\t\t}\n\n\t\t\tif (!*p)\n\t\t\t\tbreak;\n\t\t}\n\n\t\temit_log_char(*p);\n\t\tif (*p == '\\n')\n\t\t\tnew_text_line = 1;\n\t}\n\n\t/*\n\t * Try to acquire and then immediately release the\n\t * console semaphore. The release will do all the\n\t * actual magic (print out buffers, wake up klogd,\n\t * etc).\n\t *\n\t * The console_trylock_for_printk() function\n\t * will release 'logbuf_lock' regardless of whether it\n\t * actually gets the semaphore or not.\n\t */\n\tif (console_trylock_for_printk(this_cpu))\n\t\tconsole_unlock();\n\n\tlockdep_on();\nout_restore_irqs:\n\tlocal_irq_restore(flags);\n\n\treturn printed_len;\n}",
        "code_after_change": "asmlinkage int vprintk(const char *fmt, va_list args)\n{\n\treturn vprintk_emit(0, -1, NULL, 0, fmt, args);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,138 +1,4 @@\n asmlinkage int vprintk(const char *fmt, va_list args)\n {\n-\tint printed_len = 0;\n-\tint current_log_level = default_message_loglevel;\n-\tunsigned long flags;\n-\tint this_cpu;\n-\tchar *p;\n-\tsize_t plen;\n-\tchar special;\n-\n-\tboot_delay_msec();\n-\tprintk_delay();\n-\n-\t/* This stops the holder of console_sem just where we want him */\n-\tlocal_irq_save(flags);\n-\tthis_cpu = smp_processor_id();\n-\n-\t/*\n-\t * Ouch, printk recursed into itself!\n-\t */\n-\tif (unlikely(printk_cpu == this_cpu)) {\n-\t\t/*\n-\t\t * If a crash is occurring during printk() on this CPU,\n-\t\t * then try to get the crash message out but make sure\n-\t\t * we can't deadlock. Otherwise just return to avoid the\n-\t\t * recursion and return - but flag the recursion so that\n-\t\t * it can be printed at the next appropriate moment:\n-\t\t */\n-\t\tif (!oops_in_progress && !lockdep_recursing(current)) {\n-\t\t\trecursion_bug = 1;\n-\t\t\tgoto out_restore_irqs;\n-\t\t}\n-\t\tzap_locks();\n-\t}\n-\n-\tlockdep_off();\n-\traw_spin_lock(&logbuf_lock);\n-\tprintk_cpu = this_cpu;\n-\n-\tif (recursion_bug) {\n-\t\trecursion_bug = 0;\n-\t\tstrcpy(printk_buf, recursion_bug_msg);\n-\t\tprinted_len = strlen(recursion_bug_msg);\n-\t}\n-\t/* Emit the output into the temporary buffer */\n-\tprinted_len += vscnprintf(printk_buf + printed_len,\n-\t\t\t\t  sizeof(printk_buf) - printed_len, fmt, args);\n-\n-\tp = printk_buf;\n-\n-\t/* Read log level and handle special printk prefix */\n-\tplen = log_prefix(p, &current_log_level, &special);\n-\tif (plen) {\n-\t\tp += plen;\n-\n-\t\tswitch (special) {\n-\t\tcase 'c': /* Strip <c> KERN_CONT, continue line */\n-\t\t\tplen = 0;\n-\t\t\tbreak;\n-\t\tcase 'd': /* Strip <d> KERN_DEFAULT, start new line */\n-\t\t\tplen = 0;\n-\t\tdefault:\n-\t\t\tif (!new_text_line) {\n-\t\t\t\temit_log_char('\\n');\n-\t\t\t\tnew_text_line = 1;\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t/*\n-\t * Copy the output into log_buf. If the caller didn't provide\n-\t * the appropriate log prefix, we insert them here\n-\t */\n-\tfor (; *p; p++) {\n-\t\tif (new_text_line) {\n-\t\t\tnew_text_line = 0;\n-\n-\t\t\tif (plen) {\n-\t\t\t\t/* Copy original log prefix */\n-\t\t\t\tint i;\n-\n-\t\t\t\tfor (i = 0; i < plen; i++)\n-\t\t\t\t\temit_log_char(printk_buf[i]);\n-\t\t\t\tprinted_len += plen;\n-\t\t\t} else {\n-\t\t\t\t/* Add log prefix */\n-\t\t\t\temit_log_char('<');\n-\t\t\t\temit_log_char(current_log_level + '0');\n-\t\t\t\temit_log_char('>');\n-\t\t\t\tprinted_len += 3;\n-\t\t\t}\n-\n-\t\t\tif (printk_time) {\n-\t\t\t\t/* Add the current time stamp */\n-\t\t\t\tchar tbuf[50], *tp;\n-\t\t\t\tunsigned tlen;\n-\t\t\t\tunsigned long long t;\n-\t\t\t\tunsigned long nanosec_rem;\n-\n-\t\t\t\tt = cpu_clock(printk_cpu);\n-\t\t\t\tnanosec_rem = do_div(t, 1000000000);\n-\t\t\t\ttlen = sprintf(tbuf, \"[%5lu.%06lu] \",\n-\t\t\t\t\t\t(unsigned long) t,\n-\t\t\t\t\t\tnanosec_rem / 1000);\n-\n-\t\t\t\tfor (tp = tbuf; tp < tbuf + tlen; tp++)\n-\t\t\t\t\temit_log_char(*tp);\n-\t\t\t\tprinted_len += tlen;\n-\t\t\t}\n-\n-\t\t\tif (!*p)\n-\t\t\t\tbreak;\n-\t\t}\n-\n-\t\temit_log_char(*p);\n-\t\tif (*p == '\\n')\n-\t\t\tnew_text_line = 1;\n-\t}\n-\n-\t/*\n-\t * Try to acquire and then immediately release the\n-\t * console semaphore. The release will do all the\n-\t * actual magic (print out buffers, wake up klogd,\n-\t * etc).\n-\t *\n-\t * The console_trylock_for_printk() function\n-\t * will release 'logbuf_lock' regardless of whether it\n-\t * actually gets the semaphore or not.\n-\t */\n-\tif (console_trylock_for_printk(this_cpu))\n-\t\tconsole_unlock();\n-\n-\tlockdep_on();\n-out_restore_irqs:\n-\tlocal_irq_restore(flags);\n-\n-\treturn printed_len;\n+\treturn vprintk_emit(0, -1, NULL, 0, fmt, args);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn vprintk_emit(0, -1, NULL, 0, fmt, args);"
            ],
            "deleted": [
                "\tint printed_len = 0;",
                "\tint current_log_level = default_message_loglevel;",
                "\tunsigned long flags;",
                "\tint this_cpu;",
                "\tchar *p;",
                "\tsize_t plen;",
                "\tchar special;",
                "",
                "\tboot_delay_msec();",
                "\tprintk_delay();",
                "",
                "\t/* This stops the holder of console_sem just where we want him */",
                "\tlocal_irq_save(flags);",
                "\tthis_cpu = smp_processor_id();",
                "",
                "\t/*",
                "\t * Ouch, printk recursed into itself!",
                "\t */",
                "\tif (unlikely(printk_cpu == this_cpu)) {",
                "\t\t/*",
                "\t\t * If a crash is occurring during printk() on this CPU,",
                "\t\t * then try to get the crash message out but make sure",
                "\t\t * we can't deadlock. Otherwise just return to avoid the",
                "\t\t * recursion and return - but flag the recursion so that",
                "\t\t * it can be printed at the next appropriate moment:",
                "\t\t */",
                "\t\tif (!oops_in_progress && !lockdep_recursing(current)) {",
                "\t\t\trecursion_bug = 1;",
                "\t\t\tgoto out_restore_irqs;",
                "\t\t}",
                "\t\tzap_locks();",
                "\t}",
                "",
                "\tlockdep_off();",
                "\traw_spin_lock(&logbuf_lock);",
                "\tprintk_cpu = this_cpu;",
                "",
                "\tif (recursion_bug) {",
                "\t\trecursion_bug = 0;",
                "\t\tstrcpy(printk_buf, recursion_bug_msg);",
                "\t\tprinted_len = strlen(recursion_bug_msg);",
                "\t}",
                "\t/* Emit the output into the temporary buffer */",
                "\tprinted_len += vscnprintf(printk_buf + printed_len,",
                "\t\t\t\t  sizeof(printk_buf) - printed_len, fmt, args);",
                "",
                "\tp = printk_buf;",
                "",
                "\t/* Read log level and handle special printk prefix */",
                "\tplen = log_prefix(p, &current_log_level, &special);",
                "\tif (plen) {",
                "\t\tp += plen;",
                "",
                "\t\tswitch (special) {",
                "\t\tcase 'c': /* Strip <c> KERN_CONT, continue line */",
                "\t\t\tplen = 0;",
                "\t\t\tbreak;",
                "\t\tcase 'd': /* Strip <d> KERN_DEFAULT, start new line */",
                "\t\t\tplen = 0;",
                "\t\tdefault:",
                "\t\t\tif (!new_text_line) {",
                "\t\t\t\temit_log_char('\\n');",
                "\t\t\t\tnew_text_line = 1;",
                "\t\t\t}",
                "\t\t}",
                "\t}",
                "",
                "\t/*",
                "\t * Copy the output into log_buf. If the caller didn't provide",
                "\t * the appropriate log prefix, we insert them here",
                "\t */",
                "\tfor (; *p; p++) {",
                "\t\tif (new_text_line) {",
                "\t\t\tnew_text_line = 0;",
                "",
                "\t\t\tif (plen) {",
                "\t\t\t\t/* Copy original log prefix */",
                "\t\t\t\tint i;",
                "",
                "\t\t\t\tfor (i = 0; i < plen; i++)",
                "\t\t\t\t\temit_log_char(printk_buf[i]);",
                "\t\t\t\tprinted_len += plen;",
                "\t\t\t} else {",
                "\t\t\t\t/* Add log prefix */",
                "\t\t\t\temit_log_char('<');",
                "\t\t\t\temit_log_char(current_log_level + '0');",
                "\t\t\t\temit_log_char('>');",
                "\t\t\t\tprinted_len += 3;",
                "\t\t\t}",
                "",
                "\t\t\tif (printk_time) {",
                "\t\t\t\t/* Add the current time stamp */",
                "\t\t\t\tchar tbuf[50], *tp;",
                "\t\t\t\tunsigned tlen;",
                "\t\t\t\tunsigned long long t;",
                "\t\t\t\tunsigned long nanosec_rem;",
                "",
                "\t\t\t\tt = cpu_clock(printk_cpu);",
                "\t\t\t\tnanosec_rem = do_div(t, 1000000000);",
                "\t\t\t\ttlen = sprintf(tbuf, \"[%5lu.%06lu] \",",
                "\t\t\t\t\t\t(unsigned long) t,",
                "\t\t\t\t\t\tnanosec_rem / 1000);",
                "",
                "\t\t\t\tfor (tp = tbuf; tp < tbuf + tlen; tp++)",
                "\t\t\t\t\temit_log_char(*tp);",
                "\t\t\t\tprinted_len += tlen;",
                "\t\t\t}",
                "",
                "\t\t\tif (!*p)",
                "\t\t\t\tbreak;",
                "\t\t}",
                "",
                "\t\temit_log_char(*p);",
                "\t\tif (*p == '\\n')",
                "\t\t\tnew_text_line = 1;",
                "\t}",
                "",
                "\t/*",
                "\t * Try to acquire and then immediately release the",
                "\t * console semaphore. The release will do all the",
                "\t * actual magic (print out buffers, wake up klogd,",
                "\t * etc).",
                "\t *",
                "\t * The console_trylock_for_printk() function",
                "\t * will release 'logbuf_lock' regardless of whether it",
                "\t * actually gets the semaphore or not.",
                "\t */",
                "\tif (console_trylock_for_printk(this_cpu))",
                "\t\tconsole_unlock();",
                "",
                "\tlockdep_on();",
                "out_restore_irqs:",
                "\tlocal_irq_restore(flags);",
                "",
                "\treturn printed_len;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 175
    },
    {
        "cve_id": "CVE-2015-5156",
        "code_before_change": "static int virtnet_probe(struct virtio_device *vdev)\n{\n\tint i, err;\n\tstruct net_device *dev;\n\tstruct virtnet_info *vi;\n\tu16 max_queue_pairs;\n\n\tif (!vdev->config->get) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!virtnet_validate_features(vdev))\n\t\treturn -EINVAL;\n\n\t/* Find if host supports multiqueue virtio_net device */\n\terr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\n\t\t\t\t   struct virtio_net_config,\n\t\t\t\t   max_virtqueue_pairs, &max_queue_pairs);\n\n\t/* We need at least 2 queue's */\n\tif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\n\t    max_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n\t    !virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tmax_queue_pairs = 1;\n\n\t/* Allocate ourselves a network device with room for our info */\n\tdev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\t/* Set up network device as normal. */\n\tdev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\n\tdev->netdev_ops = &virtnet_netdev;\n\tdev->features = NETIF_F_HIGHDMA;\n\n\tdev->ethtool_ops = &virtnet_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &vdev->dev);\n\n\t/* Do we support \"hardware\" checksums? */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\n\t\t/* This opens up the world of extra features. */\n\t\tdev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n\t\tif (csum)\n\t\t\tdev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\n\t\t\tdev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n\t\t\t\t| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n\t\t}\n\t\t/* Individual feature bits: what can host handle? */\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\n\t\t\tdev->hw_features |= NETIF_F_TSO;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\n\t\t\tdev->hw_features |= NETIF_F_TSO6;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\n\t\t\tdev->hw_features |= NETIF_F_TSO_ECN;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\n\t\t\tdev->hw_features |= NETIF_F_UFO;\n\n\t\tdev->features |= NETIF_F_GSO_ROBUST;\n\n\t\tif (gso)\n\t\t\tdev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n\t\t/* (!csum && gso) case will be fixed by register_netdev() */\n\t}\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\n\t\tdev->features |= NETIF_F_RXCSUM;\n\n\tdev->vlan_features = dev->features;\n\n\t/* Configuration may specify what MAC to use.  Otherwise random. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\n\t\tvirtio_cread_bytes(vdev,\n\t\t\t\t   offsetof(struct virtio_net_config, mac),\n\t\t\t\t   dev->dev_addr, dev->addr_len);\n\telse\n\t\teth_hw_addr_random(dev);\n\n\t/* Set up our device-specific information */\n\tvi = netdev_priv(dev);\n\tvi->dev = dev;\n\tvi->vdev = vdev;\n\tvdev->priv = vi;\n\tvi->stats = alloc_percpu(struct virtnet_stats);\n\terr = -ENOMEM;\n\tif (vi->stats == NULL)\n\t\tgoto free;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct virtnet_stats *virtnet_stats;\n\t\tvirtnet_stats = per_cpu_ptr(vi->stats, i);\n\t\tu64_stats_init(&virtnet_stats->tx_syncp);\n\t\tu64_stats_init(&virtnet_stats->rx_syncp);\n\t}\n\n\tINIT_WORK(&vi->config_work, virtnet_config_changed_work);\n\n\t/* If we can receive ANY GSO packets, we must allocate large ones. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\n\t\tvi->big_packets = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\n\t\tvi->mergeable_rx_bufs = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\n\telse\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr);\n\n\tif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->any_header_sg = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tvi->has_cvq = true;\n\n\tif (vi->any_header_sg)\n\t\tdev->needed_headroom = vi->hdr_len;\n\n\t/* Use single tx/rx queue pair as default */\n\tvi->curr_queue_pairs = 1;\n\tvi->max_queue_pairs = max_queue_pairs;\n\n\t/* Allocate/initialize the rx/tx queues, and invoke find_vqs */\n\terr = init_vqs(vi);\n\tif (err)\n\t\tgoto free_stats;\n\n#ifdef CONFIG_SYSFS\n\tif (vi->mergeable_rx_bufs)\n\t\tdev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\n\tnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\n\tnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering device failed\\n\");\n\t\tgoto free_vqs;\n\t}\n\n\tvirtio_device_ready(vdev);\n\n\t/* Last of all, set up some receive buffers. */\n\tfor (i = 0; i < vi->curr_queue_pairs; i++) {\n\t\ttry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\n\n\t\t/* If we didn't even get one input buffer, we're useless. */\n\t\tif (vi->rq[i].vq->num_free ==\n\t\t    virtqueue_get_vring_size(vi->rq[i].vq)) {\n\t\t\tfree_unused_bufs(vi);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_recv_bufs;\n\t\t}\n\t}\n\n\tvi->nb.notifier_call = &virtnet_cpu_callback;\n\terr = register_hotcpu_notifier(&vi->nb);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering cpu notifier failed\\n\");\n\t\tgoto free_recv_bufs;\n\t}\n\n\t/* Assume link up if device can't report link status,\n\t   otherwise get link status from config. */\n\tif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\n\t\tnetif_carrier_off(dev);\n\t\tschedule_work(&vi->config_work);\n\t} else {\n\t\tvi->status = VIRTIO_NET_S_LINK_UP;\n\t\tnetif_carrier_on(dev);\n\t}\n\n\tpr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\n\t\t dev->name, max_queue_pairs);\n\n\treturn 0;\n\nfree_recv_bufs:\n\tvi->vdev->config->reset(vdev);\n\n\tfree_receive_bufs(vi);\n\tunregister_netdev(dev);\nfree_vqs:\n\tcancel_delayed_work_sync(&vi->refill);\n\tfree_receive_page_frags(vi);\n\tvirtnet_del_vqs(vi);\nfree_stats:\n\tfree_percpu(vi->stats);\nfree:\n\tfree_netdev(dev);\n\treturn err;\n}",
        "code_after_change": "static int virtnet_probe(struct virtio_device *vdev)\n{\n\tint i, err;\n\tstruct net_device *dev;\n\tstruct virtnet_info *vi;\n\tu16 max_queue_pairs;\n\n\tif (!vdev->config->get) {\n\t\tdev_err(&vdev->dev, \"%s failure: config access disabled\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!virtnet_validate_features(vdev))\n\t\treturn -EINVAL;\n\n\t/* Find if host supports multiqueue virtio_net device */\n\terr = virtio_cread_feature(vdev, VIRTIO_NET_F_MQ,\n\t\t\t\t   struct virtio_net_config,\n\t\t\t\t   max_virtqueue_pairs, &max_queue_pairs);\n\n\t/* We need at least 2 queue's */\n\tif (err || max_queue_pairs < VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MIN ||\n\t    max_queue_pairs > VIRTIO_NET_CTRL_MQ_VQ_PAIRS_MAX ||\n\t    !virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tmax_queue_pairs = 1;\n\n\t/* Allocate ourselves a network device with room for our info */\n\tdev = alloc_etherdev_mq(sizeof(struct virtnet_info), max_queue_pairs);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\t/* Set up network device as normal. */\n\tdev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\n\tdev->netdev_ops = &virtnet_netdev;\n\tdev->features = NETIF_F_HIGHDMA;\n\n\tdev->ethtool_ops = &virtnet_ethtool_ops;\n\tSET_NETDEV_DEV(dev, &vdev->dev);\n\n\t/* Do we support \"hardware\" checksums? */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\n\t\t/* This opens up the world of extra features. */\n\t\tdev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n\t\tif (csum)\n\t\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\n\t\t\tdev->hw_features |= NETIF_F_TSO | NETIF_F_UFO\n\t\t\t\t| NETIF_F_TSO_ECN | NETIF_F_TSO6;\n\t\t}\n\t\t/* Individual feature bits: what can host handle? */\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO4))\n\t\t\tdev->hw_features |= NETIF_F_TSO;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_TSO6))\n\t\t\tdev->hw_features |= NETIF_F_TSO6;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_ECN))\n\t\t\tdev->hw_features |= NETIF_F_TSO_ECN;\n\t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_HOST_UFO))\n\t\t\tdev->hw_features |= NETIF_F_UFO;\n\n\t\tdev->features |= NETIF_F_GSO_ROBUST;\n\n\t\tif (gso)\n\t\t\tdev->features |= dev->hw_features & (NETIF_F_ALL_TSO|NETIF_F_UFO);\n\t\t/* (!csum && gso) case will be fixed by register_netdev() */\n\t}\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_CSUM))\n\t\tdev->features |= NETIF_F_RXCSUM;\n\n\tdev->vlan_features = dev->features;\n\n\t/* Configuration may specify what MAC to use.  Otherwise random. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MAC))\n\t\tvirtio_cread_bytes(vdev,\n\t\t\t\t   offsetof(struct virtio_net_config, mac),\n\t\t\t\t   dev->dev_addr, dev->addr_len);\n\telse\n\t\teth_hw_addr_random(dev);\n\n\t/* Set up our device-specific information */\n\tvi = netdev_priv(dev);\n\tvi->dev = dev;\n\tvi->vdev = vdev;\n\tvdev->priv = vi;\n\tvi->stats = alloc_percpu(struct virtnet_stats);\n\terr = -ENOMEM;\n\tif (vi->stats == NULL)\n\t\tgoto free;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct virtnet_stats *virtnet_stats;\n\t\tvirtnet_stats = per_cpu_ptr(vi->stats, i);\n\t\tu64_stats_init(&virtnet_stats->tx_syncp);\n\t\tu64_stats_init(&virtnet_stats->rx_syncp);\n\t}\n\n\tINIT_WORK(&vi->config_work, virtnet_config_changed_work);\n\n\t/* If we can receive ANY GSO packets, we must allocate large ones. */\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO4) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_TSO6) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_ECN) ||\n\t    virtio_has_feature(vdev, VIRTIO_NET_F_GUEST_UFO))\n\t\tvi->big_packets = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF))\n\t\tvi->mergeable_rx_bufs = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_MRG_RXBUF) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr_mrg_rxbuf);\n\telse\n\t\tvi->hdr_len = sizeof(struct virtio_net_hdr);\n\n\tif (virtio_has_feature(vdev, VIRTIO_F_ANY_LAYOUT) ||\n\t    virtio_has_feature(vdev, VIRTIO_F_VERSION_1))\n\t\tvi->any_header_sg = true;\n\n\tif (virtio_has_feature(vdev, VIRTIO_NET_F_CTRL_VQ))\n\t\tvi->has_cvq = true;\n\n\tif (vi->any_header_sg)\n\t\tdev->needed_headroom = vi->hdr_len;\n\n\t/* Use single tx/rx queue pair as default */\n\tvi->curr_queue_pairs = 1;\n\tvi->max_queue_pairs = max_queue_pairs;\n\n\t/* Allocate/initialize the rx/tx queues, and invoke find_vqs */\n\terr = init_vqs(vi);\n\tif (err)\n\t\tgoto free_stats;\n\n#ifdef CONFIG_SYSFS\n\tif (vi->mergeable_rx_bufs)\n\t\tdev->sysfs_rx_queue_group = &virtio_net_mrg_rx_group;\n#endif\n\tnetif_set_real_num_tx_queues(dev, vi->curr_queue_pairs);\n\tnetif_set_real_num_rx_queues(dev, vi->curr_queue_pairs);\n\n\terr = register_netdev(dev);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering device failed\\n\");\n\t\tgoto free_vqs;\n\t}\n\n\tvirtio_device_ready(vdev);\n\n\t/* Last of all, set up some receive buffers. */\n\tfor (i = 0; i < vi->curr_queue_pairs; i++) {\n\t\ttry_fill_recv(vi, &vi->rq[i], GFP_KERNEL);\n\n\t\t/* If we didn't even get one input buffer, we're useless. */\n\t\tif (vi->rq[i].vq->num_free ==\n\t\t    virtqueue_get_vring_size(vi->rq[i].vq)) {\n\t\t\tfree_unused_bufs(vi);\n\t\t\terr = -ENOMEM;\n\t\t\tgoto free_recv_bufs;\n\t\t}\n\t}\n\n\tvi->nb.notifier_call = &virtnet_cpu_callback;\n\terr = register_hotcpu_notifier(&vi->nb);\n\tif (err) {\n\t\tpr_debug(\"virtio_net: registering cpu notifier failed\\n\");\n\t\tgoto free_recv_bufs;\n\t}\n\n\t/* Assume link up if device can't report link status,\n\t   otherwise get link status from config. */\n\tif (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {\n\t\tnetif_carrier_off(dev);\n\t\tschedule_work(&vi->config_work);\n\t} else {\n\t\tvi->status = VIRTIO_NET_S_LINK_UP;\n\t\tnetif_carrier_on(dev);\n\t}\n\n\tpr_debug(\"virtnet: registered device %s with %d RX and TX vq's\\n\",\n\t\t dev->name, max_queue_pairs);\n\n\treturn 0;\n\nfree_recv_bufs:\n\tvi->vdev->config->reset(vdev);\n\n\tfree_receive_bufs(vi);\n\tunregister_netdev(dev);\nfree_vqs:\n\tcancel_delayed_work_sync(&vi->refill);\n\tfree_receive_page_frags(vi);\n\tvirtnet_del_vqs(vi);\nfree_stats:\n\tfree_percpu(vi->stats);\nfree:\n\tfree_netdev(dev);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -41,9 +41,9 @@\n \t/* Do we support \"hardware\" checksums? */\n \tif (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {\n \t\t/* This opens up the world of extra features. */\n-\t\tdev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n+\t\tdev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n \t\tif (csum)\n-\t\t\tdev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;\n+\t\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n \n \t\tif (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {\n \t\t\tdev->hw_features |= NETIF_F_TSO | NETIF_F_UFO",
        "function_modified_lines": {
            "added": [
                "\t\tdev->hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;",
                "\t\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;"
            ],
            "deleted": [
                "\t\tdev->hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;",
                "\t\t\tdev->features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The virtnet_probe function in drivers/net/virtio_net.c in the Linux kernel before 4.2 attempts to support a FRAGLIST feature without proper memory allocation, which allows guest OS users to cause a denial of service (buffer overflow and memory corruption) via a crafted sequence of fragmented packets.",
        "id": 772
    },
    {
        "cve_id": "CVE-2021-4204",
        "code_before_change": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstatic const int ctx_reg = BPF_REG_6;\n\tu8 mode = BPF_MODE(insn->code);\n\tint i, err;\n\n\tif (!may_access_skb(resolve_prog_type(env->prog))) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env->ops->gen_ld_abs) {\n\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\n\t    BPF_SIZE(insn->code) == BPF_DW ||\n\t    (mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* check whether implicit source operand (register R6) is readable */\n\terr = check_reg_arg(env, ctx_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\t/* Disallow usage of BPF_LD_[ABS|IND] with reference tracking, as\n\t * gen_ld_abs() may terminate the program at runtime, leading to\n\t * reference leak.\n\t */\n\terr = check_reference_leak(env);\n\tif (err) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\n\t\treturn err;\n\t}\n\n\tif (env->cur_state->active_spin_lock) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (regs[ctx_reg].type != PTR_TO_CTX) {\n\t\tverbose(env,\n\t\t\t\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (mode == BPF_IND) {\n\t\t/* check explicit source operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* reset caller saved regs to unreadable */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* mark destination R0 register as readable, since it contains\n\t * the value fetched from the packet.\n\t * Already marked as written above.\n\t */\n\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t/* ld_abs load up to 32-bit skb data. */\n\tregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\n\treturn 0;\n}",
        "code_after_change": "static int check_ld_abs(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstatic const int ctx_reg = BPF_REG_6;\n\tu8 mode = BPF_MODE(insn->code);\n\tint i, err;\n\n\tif (!may_access_skb(resolve_prog_type(env->prog))) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] instructions not allowed for this program type\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!env->ops->gen_ld_abs) {\n\t\tverbose(env, \"bpf verifier is misconfigured\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (insn->dst_reg != BPF_REG_0 || insn->off != 0 ||\n\t    BPF_SIZE(insn->code) == BPF_DW ||\n\t    (mode == BPF_ABS && insn->src_reg != BPF_REG_0)) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] uses reserved fields\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* check whether implicit source operand (register R6) is readable */\n\terr = check_reg_arg(env, ctx_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\t/* Disallow usage of BPF_LD_[ABS|IND] with reference tracking, as\n\t * gen_ld_abs() may terminate the program at runtime, leading to\n\t * reference leak.\n\t */\n\terr = check_reference_leak(env);\n\tif (err) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be mixed with socket references\\n\");\n\t\treturn err;\n\t}\n\n\tif (env->cur_state->active_spin_lock) {\n\t\tverbose(env, \"BPF_LD_[ABS|IND] cannot be used inside bpf_spin_lock-ed region\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (regs[ctx_reg].type != PTR_TO_CTX) {\n\t\tverbose(env,\n\t\t\t\"at the time of BPF_LD_ABS|IND R6 != pointer to skb\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (mode == BPF_IND) {\n\t\t/* check explicit source operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* reset caller saved regs to unreadable */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* mark destination R0 register as readable, since it contains\n\t * the value fetched from the packet.\n\t * Already marked as written above.\n\t */\n\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t/* ld_abs load up to 32-bit skb data. */\n\tregs[BPF_REG_0].subreg_def = env->insn_idx + 1;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -55,7 +55,7 @@\n \t\t\treturn err;\n \t}\n \n-\terr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);\n+\terr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);\n \tif (err < 0)\n \t\treturn err;\n ",
        "function_modified_lines": {
            "added": [
                "\terr = check_ptr_off_reg(env, &regs[ctx_reg], ctx_reg);"
            ],
            "deleted": [
                "\terr = check_ctx_reg(env, &regs[ctx_reg], ctx_reg);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An out-of-bounds (OOB) memory access flaw was found in the Linux kernel's eBPF due to an Improper Input Validation. This flaw allows a local attacker with a special privilege to crash the system or leak internal information.",
        "id": 3154
    },
    {
        "cve_id": "CVE-2023-6560",
        "code_before_change": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\n\t\t\t    unsigned long uaddr, size_t size)\n{\n\tstruct page **page_array;\n\tunsigned int nr_pages;\n\tint ret, i;\n\n\t*npages = 0;\n\n\tif (uaddr & (PAGE_SIZE - 1) || !size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tif (nr_pages > USHRT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\tpage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!page_array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\n\t\t\t\t\tpage_array);\n\tif (ret != nr_pages) {\nerr:\n\t\tio_pages_free(&page_array, ret > 0 ? ret : 0);\n\t\treturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n\t}\n\t/*\n\t * Should be a single page. If the ring is small enough that we can\n\t * use a normal page, that is fine. If we need multiple pages, then\n\t * userspace should use a huge page. That's the only way to guarantee\n\t * that we get contigious memory, outside of just being lucky or\n\t * (currently) having low memory fragmentation.\n\t */\n\tif (page_array[0] != page_array[ret - 1])\n\t\tgoto err;\n\n\t/*\n\t * Can't support mapping user allocated ring memory on 32-bit archs\n\t * where it could potentially reside in highmem. Just fail those with\n\t * -EINVAL, just like we did on kernels that didn't support this\n\t * feature.\n\t */\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tif (PageHighMem(page_array[i])) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t*pages = page_array;\n\t*npages = nr_pages;\n\treturn page_to_virt(page_array[0]);\n}",
        "code_after_change": "static void *__io_uaddr_map(struct page ***pages, unsigned short *npages,\n\t\t\t    unsigned long uaddr, size_t size)\n{\n\tstruct page **page_array;\n\tunsigned int nr_pages;\n\tvoid *page_addr;\n\tint ret, i;\n\n\t*npages = 0;\n\n\tif (uaddr & (PAGE_SIZE - 1) || !size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnr_pages = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\tif (nr_pages > USHRT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\tpage_array = kvmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!page_array)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = pin_user_pages_fast(uaddr, nr_pages, FOLL_WRITE | FOLL_LONGTERM,\n\t\t\t\t\tpage_array);\n\tif (ret != nr_pages) {\nerr:\n\t\tio_pages_free(&page_array, ret > 0 ? ret : 0);\n\t\treturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n\t}\n\n\tpage_addr = page_address(page_array[0]);\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tret = -EINVAL;\n\n\t\t/*\n\t\t * Can't support mapping user allocated ring memory on 32-bit\n\t\t * archs where it could potentially reside in highmem. Just\n\t\t * fail those with -EINVAL, just like we did on kernels that\n\t\t * didn't support this feature.\n\t\t */\n\t\tif (PageHighMem(page_array[i]))\n\t\t\tgoto err;\n\n\t\t/*\n\t\t * No support for discontig pages for now, should either be a\n\t\t * single normal page, or a huge page. Later on we can add\n\t\t * support for remapping discontig pages, for now we will\n\t\t * just fail them with EINVAL.\n\t\t */\n\t\tif (page_address(page_array[i]) != page_addr)\n\t\t\tgoto err;\n\t\tpage_addr += PAGE_SIZE;\n\t}\n\n\t*pages = page_array;\n\t*npages = nr_pages;\n\treturn page_to_virt(page_array[0]);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n {\n \tstruct page **page_array;\n \tunsigned int nr_pages;\n+\tvoid *page_addr;\n \tint ret, i;\n \n \t*npages = 0;\n@@ -24,27 +25,29 @@\n \t\tio_pages_free(&page_array, ret > 0 ? ret : 0);\n \t\treturn ret < 0 ? ERR_PTR(ret) : ERR_PTR(-EFAULT);\n \t}\n-\t/*\n-\t * Should be a single page. If the ring is small enough that we can\n-\t * use a normal page, that is fine. If we need multiple pages, then\n-\t * userspace should use a huge page. That's the only way to guarantee\n-\t * that we get contigious memory, outside of just being lucky or\n-\t * (currently) having low memory fragmentation.\n-\t */\n-\tif (page_array[0] != page_array[ret - 1])\n-\t\tgoto err;\n \n-\t/*\n-\t * Can't support mapping user allocated ring memory on 32-bit archs\n-\t * where it could potentially reside in highmem. Just fail those with\n-\t * -EINVAL, just like we did on kernels that didn't support this\n-\t * feature.\n-\t */\n+\tpage_addr = page_address(page_array[0]);\n \tfor (i = 0; i < nr_pages; i++) {\n-\t\tif (PageHighMem(page_array[i])) {\n-\t\t\tret = -EINVAL;\n+\t\tret = -EINVAL;\n+\n+\t\t/*\n+\t\t * Can't support mapping user allocated ring memory on 32-bit\n+\t\t * archs where it could potentially reside in highmem. Just\n+\t\t * fail those with -EINVAL, just like we did on kernels that\n+\t\t * didn't support this feature.\n+\t\t */\n+\t\tif (PageHighMem(page_array[i]))\n \t\t\tgoto err;\n-\t\t}\n+\n+\t\t/*\n+\t\t * No support for discontig pages for now, should either be a\n+\t\t * single normal page, or a huge page. Later on we can add\n+\t\t * support for remapping discontig pages, for now we will\n+\t\t * just fail them with EINVAL.\n+\t\t */\n+\t\tif (page_address(page_array[i]) != page_addr)\n+\t\t\tgoto err;\n+\t\tpage_addr += PAGE_SIZE;\n \t}\n \n \t*pages = page_array;",
        "function_modified_lines": {
            "added": [
                "\tvoid *page_addr;",
                "\tpage_addr = page_address(page_array[0]);",
                "\t\tret = -EINVAL;",
                "",
                "\t\t/*",
                "\t\t * Can't support mapping user allocated ring memory on 32-bit",
                "\t\t * archs where it could potentially reside in highmem. Just",
                "\t\t * fail those with -EINVAL, just like we did on kernels that",
                "\t\t * didn't support this feature.",
                "\t\t */",
                "\t\tif (PageHighMem(page_array[i]))",
                "",
                "\t\t/*",
                "\t\t * No support for discontig pages for now, should either be a",
                "\t\t * single normal page, or a huge page. Later on we can add",
                "\t\t * support for remapping discontig pages, for now we will",
                "\t\t * just fail them with EINVAL.",
                "\t\t */",
                "\t\tif (page_address(page_array[i]) != page_addr)",
                "\t\t\tgoto err;",
                "\t\tpage_addr += PAGE_SIZE;"
            ],
            "deleted": [
                "\t/*",
                "\t * Should be a single page. If the ring is small enough that we can",
                "\t * use a normal page, that is fine. If we need multiple pages, then",
                "\t * userspace should use a huge page. That's the only way to guarantee",
                "\t * that we get contigious memory, outside of just being lucky or",
                "\t * (currently) having low memory fragmentation.",
                "\t */",
                "\tif (page_array[0] != page_array[ret - 1])",
                "\t\tgoto err;",
                "\t/*",
                "\t * Can't support mapping user allocated ring memory on 32-bit archs",
                "\t * where it could potentially reside in highmem. Just fail those with",
                "\t * -EINVAL, just like we did on kernels that didn't support this",
                "\t * feature.",
                "\t */",
                "\t\tif (PageHighMem(page_array[i])) {",
                "\t\t\tret = -EINVAL;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An out-of-bounds memory access flaw was found in the io_uring SQ/CQ rings functionality in the Linux kernel. This issue could allow a local user to crash the system.",
        "id": 4303
    },
    {
        "cve_id": "CVE-2011-4098",
        "code_before_change": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t   loff_t len)\n{\n\tstruct inode *inode = file->f_path.dentry->d_inode;\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\n\tloff_t bytes, max_bytes;\n\tstruct gfs2_alloc *al;\n\tint error;\n\tloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\n\tloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\n\tnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\n\n\t/* We only support the FALLOC_FL_KEEP_SIZE mode */\n\tif (mode & ~FALLOC_FL_KEEP_SIZE)\n\t\treturn -EOPNOTSUPP;\n\n\toffset &= bsize_mask;\n\n\tlen = next - offset;\n\tbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\n\tif (!bytes)\n\t\tbytes = UINT_MAX;\n\tbytes &= bsize_mask;\n\tif (bytes == 0)\n\t\tbytes = sdp->sd_sb.sb_bsize;\n\n\tgfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\n\terror = gfs2_glock_nq(&ip->i_gh);\n\tif (unlikely(error))\n\t\tgoto out_uninit;\n\n\tif (!gfs2_write_alloc_required(ip, offset, len))\n\t\tgoto out_unlock;\n\n\twhile (len > 0) {\n\t\tif (len < bytes)\n\t\t\tbytes = len;\n\t\tal = gfs2_alloc_get(ip);\n\t\tif (!al) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terror = gfs2_quota_lock_check(ip);\n\t\tif (error)\n\t\t\tgoto out_alloc_put;\n\nretry:\n\t\tgfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\n\n\t\tal->al_requested = data_blocks + ind_blocks;\n\t\terror = gfs2_inplace_reserve(ip);\n\t\tif (error) {\n\t\t\tif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\n\t\t\t\tbytes >>= 1;\n\t\t\t\tbytes &= bsize_mask;\n\t\t\t\tif (bytes == 0)\n\t\t\t\t\tbytes = sdp->sd_sb.sb_bsize;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tgoto out_qunlock;\n\t\t}\n\t\tmax_bytes = bytes;\n\t\tcalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);\n\t\tal->al_requested = data_blocks + ind_blocks;\n\n\t\trblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\n\t\t\t  RES_RG_HDR + gfs2_rg_blocks(ip);\n\t\tif (gfs2_is_jdata(ip))\n\t\t\trblocks += data_blocks ? data_blocks : 1;\n\n\t\terror = gfs2_trans_begin(sdp, rblocks,\n\t\t\t\t\t PAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\terror = fallocate_chunk(inode, offset, max_bytes, mode);\n\t\tgfs2_trans_end(sdp);\n\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\tlen -= max_bytes;\n\t\toffset += max_bytes;\n\t\tgfs2_inplace_release(ip);\n\t\tgfs2_quota_unlock(ip);\n\t\tgfs2_alloc_put(ip);\n\t}\n\tgoto out_unlock;\n\nout_trans_fail:\n\tgfs2_inplace_release(ip);\nout_qunlock:\n\tgfs2_quota_unlock(ip);\nout_alloc_put:\n\tgfs2_alloc_put(ip);\nout_unlock:\n\tgfs2_glock_dq(&ip->i_gh);\nout_uninit:\n\tgfs2_holder_uninit(&ip->i_gh);\n\treturn error;\n}",
        "code_after_change": "static long gfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t   loff_t len)\n{\n\tstruct inode *inode = file->f_path.dentry->d_inode;\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tunsigned int data_blocks = 0, ind_blocks = 0, rblocks;\n\tloff_t bytes, max_bytes;\n\tstruct gfs2_alloc *al;\n\tint error;\n\tloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\n\tloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\n\tloff_t max_chunk_size = UINT_MAX & bsize_mask;\n\tnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\n\n\t/* We only support the FALLOC_FL_KEEP_SIZE mode */\n\tif (mode & ~FALLOC_FL_KEEP_SIZE)\n\t\treturn -EOPNOTSUPP;\n\n\toffset &= bsize_mask;\n\n\tlen = next - offset;\n\tbytes = sdp->sd_max_rg_data * sdp->sd_sb.sb_bsize / 2;\n\tif (!bytes)\n\t\tbytes = UINT_MAX;\n\tbytes &= bsize_mask;\n\tif (bytes == 0)\n\t\tbytes = sdp->sd_sb.sb_bsize;\n\n\tgfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &ip->i_gh);\n\terror = gfs2_glock_nq(&ip->i_gh);\n\tif (unlikely(error))\n\t\tgoto out_uninit;\n\n\tif (!gfs2_write_alloc_required(ip, offset, len))\n\t\tgoto out_unlock;\n\n\twhile (len > 0) {\n\t\tif (len < bytes)\n\t\t\tbytes = len;\n\t\tal = gfs2_alloc_get(ip);\n\t\tif (!al) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terror = gfs2_quota_lock_check(ip);\n\t\tif (error)\n\t\t\tgoto out_alloc_put;\n\nretry:\n\t\tgfs2_write_calc_reserv(ip, bytes, &data_blocks, &ind_blocks);\n\n\t\tal->al_requested = data_blocks + ind_blocks;\n\t\terror = gfs2_inplace_reserve(ip);\n\t\tif (error) {\n\t\t\tif (error == -ENOSPC && bytes > sdp->sd_sb.sb_bsize) {\n\t\t\t\tbytes >>= 1;\n\t\t\t\tbytes &= bsize_mask;\n\t\t\t\tif (bytes == 0)\n\t\t\t\t\tbytes = sdp->sd_sb.sb_bsize;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tgoto out_qunlock;\n\t\t}\n\t\tmax_bytes = bytes;\n\t\tcalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,\n\t\t\t\t&max_bytes, &data_blocks, &ind_blocks);\n\t\tal->al_requested = data_blocks + ind_blocks;\n\n\t\trblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +\n\t\t\t  RES_RG_HDR + gfs2_rg_blocks(ip);\n\t\tif (gfs2_is_jdata(ip))\n\t\t\trblocks += data_blocks ? data_blocks : 1;\n\n\t\terror = gfs2_trans_begin(sdp, rblocks,\n\t\t\t\t\t PAGE_CACHE_SIZE/sdp->sd_sb.sb_bsize);\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\terror = fallocate_chunk(inode, offset, max_bytes, mode);\n\t\tgfs2_trans_end(sdp);\n\n\t\tif (error)\n\t\t\tgoto out_trans_fail;\n\n\t\tlen -= max_bytes;\n\t\toffset += max_bytes;\n\t\tgfs2_inplace_release(ip);\n\t\tgfs2_quota_unlock(ip);\n\t\tgfs2_alloc_put(ip);\n\t}\n\tgoto out_unlock;\n\nout_trans_fail:\n\tgfs2_inplace_release(ip);\nout_qunlock:\n\tgfs2_quota_unlock(ip);\nout_alloc_put:\n\tgfs2_alloc_put(ip);\nout_unlock:\n\tgfs2_glock_dq(&ip->i_gh);\nout_uninit:\n\tgfs2_holder_uninit(&ip->i_gh);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,7 @@\n \tint error;\n \tloff_t bsize_mask = ~((loff_t)sdp->sd_sb.sb_bsize - 1);\n \tloff_t next = (offset + len - 1) >> sdp->sd_sb.sb_bsize_shift;\n+\tloff_t max_chunk_size = UINT_MAX & bsize_mask;\n \tnext = (next + 1) << sdp->sd_sb.sb_bsize_shift;\n \n \t/* We only support the FALLOC_FL_KEEP_SIZE mode */\n@@ -63,7 +64,8 @@\n \t\t\tgoto out_qunlock;\n \t\t}\n \t\tmax_bytes = bytes;\n-\t\tcalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);\n+\t\tcalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,\n+\t\t\t\t&max_bytes, &data_blocks, &ind_blocks);\n \t\tal->al_requested = data_blocks + ind_blocks;\n \n \t\trblocks = RES_DINODE + ind_blocks + RES_STATFS + RES_QUOTA +",
        "function_modified_lines": {
            "added": [
                "\tloff_t max_chunk_size = UINT_MAX & bsize_mask;",
                "\t\tcalc_max_reserv(ip, (len > max_chunk_size)? max_chunk_size: len,",
                "\t\t\t\t&max_bytes, &data_blocks, &ind_blocks);"
            ],
            "deleted": [
                "\t\tcalc_max_reserv(ip, len, &max_bytes, &data_blocks, &ind_blocks);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The fallocate implementation in the GFS2 filesystem in the Linux kernel before 3.2 relies on the page cache, which might allow local users to cause a denial of service by preallocating blocks in certain situations involving insufficient memory.",
        "id": 32
    },
    {
        "cve_id": "CVE-2016-3955",
        "code_before_change": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\n\tint ret;\n\tint size;\n\n\tif (ud->side == USBIP_STUB) {\n\t\t/* the direction of urb must be OUT. */\n\t\tif (usb_pipein(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->transfer_buffer_length;\n\t} else {\n\t\t/* the direction of urb must be IN. */\n\t\tif (usb_pipeout(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->actual_length;\n\t}\n\n\t/* no need to recv xbuff */\n\tif (!(size > 0))\n\t\treturn 0;\n\n\tret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\n\tif (ret != size) {\n\t\tdev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "int usbip_recv_xbuff(struct usbip_device *ud, struct urb *urb)\n{\n\tint ret;\n\tint size;\n\n\tif (ud->side == USBIP_STUB) {\n\t\t/* the direction of urb must be OUT. */\n\t\tif (usb_pipein(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->transfer_buffer_length;\n\t} else {\n\t\t/* the direction of urb must be IN. */\n\t\tif (usb_pipeout(urb->pipe))\n\t\t\treturn 0;\n\n\t\tsize = urb->actual_length;\n\t}\n\n\t/* no need to recv xbuff */\n\tif (!(size > 0))\n\t\treturn 0;\n\n\tif (size > urb->transfer_buffer_length) {\n\t\t/* should not happen, probably malicious packet */\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\tret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\n\tif (ret != size) {\n\t\tdev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);\n\t\tif (ud->side == USBIP_STUB) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n\t\t} else {\n\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n\t\t\treturn -EPIPE;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,17 @@\n \tif (!(size > 0))\n \t\treturn 0;\n \n+\tif (size > urb->transfer_buffer_length) {\n+\t\t/* should not happen, probably malicious packet */\n+\t\tif (ud->side == USBIP_STUB) {\n+\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);\n+\t\t\treturn 0;\n+\t\t} else {\n+\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);\n+\t\t\treturn -EPIPE;\n+\t\t}\n+\t}\n+\n \tret = usbip_recv(ud->tcp_socket, urb->transfer_buffer, size);\n \tif (ret != size) {\n \t\tdev_err(&urb->dev->dev, \"recv xbuf, %d\\n\", ret);",
        "function_modified_lines": {
            "added": [
                "\tif (size > urb->transfer_buffer_length) {",
                "\t\t/* should not happen, probably malicious packet */",
                "\t\tif (ud->side == USBIP_STUB) {",
                "\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_TCP);",
                "\t\t\treturn 0;",
                "\t\t} else {",
                "\t\t\tusbip_event_add(ud, VDEV_EVENT_ERROR_TCP);",
                "\t\t\treturn -EPIPE;",
                "\t\t}",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The usbip_recv_xbuff function in drivers/usb/usbip/usbip_common.c in the Linux kernel before 4.5.3 allows remote attackers to cause a denial of service (out-of-bounds write) or possibly have unspecified other impact via a crafted length value in a USB/IP packet.",
        "id": 1013
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "void log_buf_kexec_setup(void)\n{\n\tVMCOREINFO_SYMBOL(log_buf);\n\tVMCOREINFO_SYMBOL(log_end);\n\tVMCOREINFO_SYMBOL(log_buf_len);\n\tVMCOREINFO_SYMBOL(logged_chars);\n}",
        "code_after_change": "void log_buf_kexec_setup(void)\n{\n\tVMCOREINFO_SYMBOL(log_buf);\n\tVMCOREINFO_SYMBOL(log_buf_len);\n\tVMCOREINFO_SYMBOL(log_first_idx);\n\tVMCOREINFO_SYMBOL(log_next_idx);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n void log_buf_kexec_setup(void)\n {\n \tVMCOREINFO_SYMBOL(log_buf);\n-\tVMCOREINFO_SYMBOL(log_end);\n \tVMCOREINFO_SYMBOL(log_buf_len);\n-\tVMCOREINFO_SYMBOL(logged_chars);\n+\tVMCOREINFO_SYMBOL(log_first_idx);\n+\tVMCOREINFO_SYMBOL(log_next_idx);\n }",
        "function_modified_lines": {
            "added": [
                "\tVMCOREINFO_SYMBOL(log_first_idx);",
                "\tVMCOREINFO_SYMBOL(log_next_idx);"
            ],
            "deleted": [
                "\tVMCOREINFO_SYMBOL(log_end);",
                "\tVMCOREINFO_SYMBOL(logged_chars);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 174
    },
    {
        "cve_id": "CVE-2017-18379",
        "code_before_change": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\n\t\t\t\tu64 connection_id)\n{\n\tstruct nvmet_fc_tgt_assoc *assoc;\n\tstruct nvmet_fc_tgt_queue *queue;\n\tu64 association_id = nvmet_fc_getassociationid(connection_id);\n\tu16 qid = nvmet_fc_getqueueid(connection_id);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&tgtport->lock, flags);\n\tlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\n\t\tif (association_id == assoc->association_id) {\n\t\t\tqueue = assoc->queues[qid];\n\t\t\tif (queue &&\n\t\t\t    (!atomic_read(&queue->connected) ||\n\t\t\t     !nvmet_fc_tgt_q_get(queue)))\n\t\t\t\tqueue = NULL;\n\t\t\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\t\t\treturn queue;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\treturn NULL;\n}",
        "code_after_change": "static struct nvmet_fc_tgt_queue *\nnvmet_fc_find_target_queue(struct nvmet_fc_tgtport *tgtport,\n\t\t\t\tu64 connection_id)\n{\n\tstruct nvmet_fc_tgt_assoc *assoc;\n\tstruct nvmet_fc_tgt_queue *queue;\n\tu64 association_id = nvmet_fc_getassociationid(connection_id);\n\tu16 qid = nvmet_fc_getqueueid(connection_id);\n\tunsigned long flags;\n\n\tif (qid > NVMET_NR_QUEUES)\n\t\treturn NULL;\n\n\tspin_lock_irqsave(&tgtport->lock, flags);\n\tlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {\n\t\tif (association_id == assoc->association_id) {\n\t\t\tqueue = assoc->queues[qid];\n\t\t\tif (queue &&\n\t\t\t    (!atomic_read(&queue->connected) ||\n\t\t\t     !nvmet_fc_tgt_q_get(queue)))\n\t\t\t\tqueue = NULL;\n\t\t\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\t\t\treturn queue;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&tgtport->lock, flags);\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,9 @@\n \tu64 association_id = nvmet_fc_getassociationid(connection_id);\n \tu16 qid = nvmet_fc_getqueueid(connection_id);\n \tunsigned long flags;\n+\n+\tif (qid > NVMET_NR_QUEUES)\n+\t\treturn NULL;\n \n \tspin_lock_irqsave(&tgtport->lock, flags);\n \tlist_for_each_entry(assoc, &tgtport->assoc_list, a_list) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (qid > NVMET_NR_QUEUES)",
                "\t\treturn NULL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.14, an out of boundary access happened in drivers/nvme/target/fc.c.",
        "id": 1434
    },
    {
        "cve_id": "CVE-2013-1773",
        "code_before_change": "static int\nxlate_to_uni(const unsigned char *name, int len, unsigned char *outname,\n\t     int *longlen, int *outlen, int escape, int utf8,\n\t     struct nls_table *nls)\n{\n\tconst unsigned char *ip;\n\tunsigned char nc;\n\tunsigned char *op;\n\tunsigned int ec;\n\tint i, k, fill;\n\tint charlen;\n\n\tif (utf8) {\n\t\t*outlen = utf8s_to_utf16s(name, len, (wchar_t *)outname);\n\t\tif (*outlen < 0)\n\t\t\treturn *outlen;\n\t\telse if (*outlen > FAT_LFN_LEN)\n\t\t\treturn -ENAMETOOLONG;\n\n\t\top = &outname[*outlen * sizeof(wchar_t)];\n\t} else {\n\t\tif (nls) {\n\t\t\tfor (i = 0, ip = name, op = outname, *outlen = 0;\n\t\t\t     i < len && *outlen <= FAT_LFN_LEN;\n\t\t\t     *outlen += 1)\n\t\t\t{\n\t\t\t\tif (escape && (*ip == ':')) {\n\t\t\t\t\tif (i > len - 5)\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\tec = 0;\n\t\t\t\t\tfor (k = 1; k < 5; k++) {\n\t\t\t\t\t\tnc = ip[k];\n\t\t\t\t\t\tec <<= 4;\n\t\t\t\t\t\tif (nc >= '0' && nc <= '9') {\n\t\t\t\t\t\t\tec |= nc - '0';\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nc >= 'a' && nc <= 'f') {\n\t\t\t\t\t\t\tec |= nc - ('a' - 10);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nc >= 'A' && nc <= 'F') {\n\t\t\t\t\t\t\tec |= nc - ('A' - 10);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\t}\n\t\t\t\t\t*op++ = ec & 0xFF;\n\t\t\t\t\t*op++ = ec >> 8;\n\t\t\t\t\tip += 5;\n\t\t\t\t\ti += 5;\n\t\t\t\t} else {\n\t\t\t\t\tif ((charlen = nls->char2uni(ip, len - i, (wchar_t *)op)) < 0)\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\tip += charlen;\n\t\t\t\t\ti += charlen;\n\t\t\t\t\top += 2;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (i < len)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t} else {\n\t\t\tfor (i = 0, ip = name, op = outname, *outlen = 0;\n\t\t\t     i < len && *outlen <= FAT_LFN_LEN;\n\t\t\t     i++, *outlen += 1)\n\t\t\t{\n\t\t\t\t*op++ = *ip++;\n\t\t\t\t*op++ = 0;\n\t\t\t}\n\t\t\tif (i < len)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t}\n\t}\n\n\t*longlen = *outlen;\n\tif (*outlen % 13) {\n\t\t*op++ = 0;\n\t\t*op++ = 0;\n\t\t*outlen += 1;\n\t\tif (*outlen % 13) {\n\t\t\tfill = 13 - (*outlen % 13);\n\t\t\tfor (i = 0; i < fill; i++) {\n\t\t\t\t*op++ = 0xff;\n\t\t\t\t*op++ = 0xff;\n\t\t\t}\n\t\t\t*outlen += fill;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int\nxlate_to_uni(const unsigned char *name, int len, unsigned char *outname,\n\t     int *longlen, int *outlen, int escape, int utf8,\n\t     struct nls_table *nls)\n{\n\tconst unsigned char *ip;\n\tunsigned char nc;\n\tunsigned char *op;\n\tunsigned int ec;\n\tint i, k, fill;\n\tint charlen;\n\n\tif (utf8) {\n\t\t*outlen = utf8s_to_utf16s(name, len, UTF16_HOST_ENDIAN,\n\t\t\t\t(wchar_t *) outname, FAT_LFN_LEN + 2);\n\t\tif (*outlen < 0)\n\t\t\treturn *outlen;\n\t\telse if (*outlen > FAT_LFN_LEN)\n\t\t\treturn -ENAMETOOLONG;\n\n\t\top = &outname[*outlen * sizeof(wchar_t)];\n\t} else {\n\t\tif (nls) {\n\t\t\tfor (i = 0, ip = name, op = outname, *outlen = 0;\n\t\t\t     i < len && *outlen <= FAT_LFN_LEN;\n\t\t\t     *outlen += 1)\n\t\t\t{\n\t\t\t\tif (escape && (*ip == ':')) {\n\t\t\t\t\tif (i > len - 5)\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\tec = 0;\n\t\t\t\t\tfor (k = 1; k < 5; k++) {\n\t\t\t\t\t\tnc = ip[k];\n\t\t\t\t\t\tec <<= 4;\n\t\t\t\t\t\tif (nc >= '0' && nc <= '9') {\n\t\t\t\t\t\t\tec |= nc - '0';\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nc >= 'a' && nc <= 'f') {\n\t\t\t\t\t\t\tec |= nc - ('a' - 10);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (nc >= 'A' && nc <= 'F') {\n\t\t\t\t\t\t\tec |= nc - ('A' - 10);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\t}\n\t\t\t\t\t*op++ = ec & 0xFF;\n\t\t\t\t\t*op++ = ec >> 8;\n\t\t\t\t\tip += 5;\n\t\t\t\t\ti += 5;\n\t\t\t\t} else {\n\t\t\t\t\tif ((charlen = nls->char2uni(ip, len - i, (wchar_t *)op)) < 0)\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\tip += charlen;\n\t\t\t\t\ti += charlen;\n\t\t\t\t\top += 2;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (i < len)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t} else {\n\t\t\tfor (i = 0, ip = name, op = outname, *outlen = 0;\n\t\t\t     i < len && *outlen <= FAT_LFN_LEN;\n\t\t\t     i++, *outlen += 1)\n\t\t\t{\n\t\t\t\t*op++ = *ip++;\n\t\t\t\t*op++ = 0;\n\t\t\t}\n\t\t\tif (i < len)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t}\n\t}\n\n\t*longlen = *outlen;\n\tif (*outlen % 13) {\n\t\t*op++ = 0;\n\t\t*op++ = 0;\n\t\t*outlen += 1;\n\t\tif (*outlen % 13) {\n\t\t\tfill = 13 - (*outlen % 13);\n\t\t\tfor (i = 0; i < fill; i++) {\n\t\t\t\t*op++ = 0xff;\n\t\t\t\t*op++ = 0xff;\n\t\t\t}\n\t\t\t*outlen += fill;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,8 @@\n \tint charlen;\n \n \tif (utf8) {\n-\t\t*outlen = utf8s_to_utf16s(name, len, (wchar_t *)outname);\n+\t\t*outlen = utf8s_to_utf16s(name, len, UTF16_HOST_ENDIAN,\n+\t\t\t\t(wchar_t *) outname, FAT_LFN_LEN + 2);\n \t\tif (*outlen < 0)\n \t\t\treturn *outlen;\n \t\telse if (*outlen > FAT_LFN_LEN)",
        "function_modified_lines": {
            "added": [
                "\t\t*outlen = utf8s_to_utf16s(name, len, UTF16_HOST_ENDIAN,",
                "\t\t\t\t(wchar_t *) outname, FAT_LFN_LEN + 2);"
            ],
            "deleted": [
                "\t\t*outlen = utf8s_to_utf16s(name, len, (wchar_t *)outname);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the VFAT filesystem implementation in the Linux kernel before 3.3 allows local users to gain privileges or cause a denial of service (system crash) via a VFAT write operation on a filesystem with the utf8 mount option, which is not properly handled during UTF-8 to UTF-16 conversion.",
        "id": 182
    },
    {
        "cve_id": "CVE-2013-4588",
        "code_before_change": "static int\ndo_ip_vs_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tunsigned char arg[128];\n\tint ret = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (*len < get_arglen[GET_CMDID(cmd)]) {\n\t\tpr_err(\"get_ctl: len %u < %u\\n\",\n\t\t       *len, get_arglen[GET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(arg, user, get_arglen[GET_CMDID(cmd)]) != 0)\n\t\treturn -EFAULT;\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex))\n\t\treturn -ERESTARTSYS;\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_GET_VERSION:\n\t{\n\t\tchar buf[64];\n\n\t\tsprintf(buf, \"IP Virtual Server version %d.%d.%d (size=%d)\",\n\t\t\tNVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);\n\t\tif (copy_to_user(user, buf, strlen(buf)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\t*len = strlen(buf)+1;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_INFO:\n\t{\n\t\tstruct ip_vs_getinfo info;\n\t\tinfo.version = IP_VS_VERSION_CODE;\n\t\tinfo.size = IP_VS_CONN_TAB_SIZE;\n\t\tinfo.num_services = ip_vs_num_services;\n\t\tif (copy_to_user(user, &info, sizeof(info)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_SERVICES:\n\t{\n\t\tstruct ip_vs_get_services *get;\n\t\tint size;\n\n\t\tget = (struct ip_vs_get_services *)arg;\n\t\tsize = sizeof(*get) +\n\t\t\tsizeof(struct ip_vs_service_entry) * get->num_services;\n\t\tif (*len != size) {\n\t\t\tpr_err(\"length: %u != %u\\n\", *len, size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tret = __ip_vs_get_service_entries(get, user);\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_SERVICE:\n\t{\n\t\tstruct ip_vs_service_entry *entry;\n\t\tstruct ip_vs_service *svc;\n\t\tunion nf_inet_addr addr;\n\n\t\tentry = (struct ip_vs_service_entry *)arg;\n\t\taddr.ip = entry->addr;\n\t\tif (entry->fwmark)\n\t\t\tsvc = __ip_vs_svc_fwm_get(AF_INET, entry->fwmark);\n\t\telse\n\t\t\tsvc = __ip_vs_service_get(AF_INET, entry->protocol,\n\t\t\t\t\t\t  &addr, entry->port);\n\t\tif (svc) {\n\t\t\tip_vs_copy_service(entry, svc);\n\t\t\tif (copy_to_user(user, entry, sizeof(*entry)) != 0)\n\t\t\t\tret = -EFAULT;\n\t\t\tip_vs_service_put(svc);\n\t\t} else\n\t\t\tret = -ESRCH;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_DESTS:\n\t{\n\t\tstruct ip_vs_get_dests *get;\n\t\tint size;\n\n\t\tget = (struct ip_vs_get_dests *)arg;\n\t\tsize = sizeof(*get) +\n\t\t\tsizeof(struct ip_vs_dest_entry) * get->num_dests;\n\t\tif (*len != size) {\n\t\t\tpr_err(\"length: %u != %u\\n\", *len, size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tret = __ip_vs_get_dest_entries(get, user);\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_TIMEOUT:\n\t{\n\t\tstruct ip_vs_timeout_user t;\n\n\t\t__ip_vs_get_timeouts(&t);\n\t\tif (copy_to_user(user, &t, sizeof(t)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_DAEMON:\n\t{\n\t\tstruct ip_vs_daemon_user d[2];\n\n\t\tmemset(&d, 0, sizeof(d));\n\t\tif (ip_vs_sync_state & IP_VS_STATE_MASTER) {\n\t\t\td[0].state = IP_VS_STATE_MASTER;\n\t\t\tstrlcpy(d[0].mcast_ifn, ip_vs_master_mcast_ifn, sizeof(d[0].mcast_ifn));\n\t\t\td[0].syncid = ip_vs_master_syncid;\n\t\t}\n\t\tif (ip_vs_sync_state & IP_VS_STATE_BACKUP) {\n\t\t\td[1].state = IP_VS_STATE_BACKUP;\n\t\t\tstrlcpy(d[1].mcast_ifn, ip_vs_backup_mcast_ifn, sizeof(d[1].mcast_ifn));\n\t\t\td[1].syncid = ip_vs_backup_syncid;\n\t\t}\n\t\tif (copy_to_user(user, &d, sizeof(d)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n  out:\n\tmutex_unlock(&__ip_vs_mutex);\n\treturn ret;\n}",
        "code_after_change": "static int\ndo_ip_vs_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tunsigned char arg[128];\n\tint ret = 0;\n\tunsigned int copylen;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_GET_MAX)\n\t\treturn -EINVAL;\n\n\tif (*len < get_arglen[GET_CMDID(cmd)]) {\n\t\tpr_err(\"get_ctl: len %u < %u\\n\",\n\t\t       *len, get_arglen[GET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tcopylen = get_arglen[GET_CMDID(cmd)];\n\tif (copylen > 128)\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(arg, user, copylen) != 0)\n\t\treturn -EFAULT;\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex))\n\t\treturn -ERESTARTSYS;\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_GET_VERSION:\n\t{\n\t\tchar buf[64];\n\n\t\tsprintf(buf, \"IP Virtual Server version %d.%d.%d (size=%d)\",\n\t\t\tNVERSION(IP_VS_VERSION_CODE), IP_VS_CONN_TAB_SIZE);\n\t\tif (copy_to_user(user, buf, strlen(buf)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\t*len = strlen(buf)+1;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_INFO:\n\t{\n\t\tstruct ip_vs_getinfo info;\n\t\tinfo.version = IP_VS_VERSION_CODE;\n\t\tinfo.size = IP_VS_CONN_TAB_SIZE;\n\t\tinfo.num_services = ip_vs_num_services;\n\t\tif (copy_to_user(user, &info, sizeof(info)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_SERVICES:\n\t{\n\t\tstruct ip_vs_get_services *get;\n\t\tint size;\n\n\t\tget = (struct ip_vs_get_services *)arg;\n\t\tsize = sizeof(*get) +\n\t\t\tsizeof(struct ip_vs_service_entry) * get->num_services;\n\t\tif (*len != size) {\n\t\t\tpr_err(\"length: %u != %u\\n\", *len, size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tret = __ip_vs_get_service_entries(get, user);\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_SERVICE:\n\t{\n\t\tstruct ip_vs_service_entry *entry;\n\t\tstruct ip_vs_service *svc;\n\t\tunion nf_inet_addr addr;\n\n\t\tentry = (struct ip_vs_service_entry *)arg;\n\t\taddr.ip = entry->addr;\n\t\tif (entry->fwmark)\n\t\t\tsvc = __ip_vs_svc_fwm_get(AF_INET, entry->fwmark);\n\t\telse\n\t\t\tsvc = __ip_vs_service_get(AF_INET, entry->protocol,\n\t\t\t\t\t\t  &addr, entry->port);\n\t\tif (svc) {\n\t\t\tip_vs_copy_service(entry, svc);\n\t\t\tif (copy_to_user(user, entry, sizeof(*entry)) != 0)\n\t\t\t\tret = -EFAULT;\n\t\t\tip_vs_service_put(svc);\n\t\t} else\n\t\t\tret = -ESRCH;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_DESTS:\n\t{\n\t\tstruct ip_vs_get_dests *get;\n\t\tint size;\n\n\t\tget = (struct ip_vs_get_dests *)arg;\n\t\tsize = sizeof(*get) +\n\t\t\tsizeof(struct ip_vs_dest_entry) * get->num_dests;\n\t\tif (*len != size) {\n\t\t\tpr_err(\"length: %u != %u\\n\", *len, size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tret = __ip_vs_get_dest_entries(get, user);\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_TIMEOUT:\n\t{\n\t\tstruct ip_vs_timeout_user t;\n\n\t\t__ip_vs_get_timeouts(&t);\n\t\tif (copy_to_user(user, &t, sizeof(t)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tcase IP_VS_SO_GET_DAEMON:\n\t{\n\t\tstruct ip_vs_daemon_user d[2];\n\n\t\tmemset(&d, 0, sizeof(d));\n\t\tif (ip_vs_sync_state & IP_VS_STATE_MASTER) {\n\t\t\td[0].state = IP_VS_STATE_MASTER;\n\t\t\tstrlcpy(d[0].mcast_ifn, ip_vs_master_mcast_ifn, sizeof(d[0].mcast_ifn));\n\t\t\td[0].syncid = ip_vs_master_syncid;\n\t\t}\n\t\tif (ip_vs_sync_state & IP_VS_STATE_BACKUP) {\n\t\t\td[1].state = IP_VS_STATE_BACKUP;\n\t\t\tstrlcpy(d[1].mcast_ifn, ip_vs_backup_mcast_ifn, sizeof(d[1].mcast_ifn));\n\t\t\td[1].syncid = ip_vs_backup_syncid;\n\t\t}\n\t\tif (copy_to_user(user, &d, sizeof(d)) != 0)\n\t\t\tret = -EFAULT;\n\t}\n\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n  out:\n\tmutex_unlock(&__ip_vs_mutex);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,9 +3,13 @@\n {\n \tunsigned char arg[128];\n \tint ret = 0;\n+\tunsigned int copylen;\n \n \tif (!capable(CAP_NET_ADMIN))\n \t\treturn -EPERM;\n+\n+\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_GET_MAX)\n+\t\treturn -EINVAL;\n \n \tif (*len < get_arglen[GET_CMDID(cmd)]) {\n \t\tpr_err(\"get_ctl: len %u < %u\\n\",\n@@ -13,7 +17,11 @@\n \t\treturn -EINVAL;\n \t}\n \n-\tif (copy_from_user(arg, user, get_arglen[GET_CMDID(cmd)]) != 0)\n+\tcopylen = get_arglen[GET_CMDID(cmd)];\n+\tif (copylen > 128)\n+\t\treturn -EINVAL;\n+\n+\tif (copy_from_user(arg, user, copylen) != 0)\n \t\treturn -EFAULT;\n \n \tif (mutex_lock_interruptible(&__ip_vs_mutex))",
        "function_modified_lines": {
            "added": [
                "\tunsigned int copylen;",
                "",
                "\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_GET_MAX)",
                "\t\treturn -EINVAL;",
                "\tcopylen = get_arglen[GET_CMDID(cmd)];",
                "\tif (copylen > 128)",
                "\t\treturn -EINVAL;",
                "",
                "\tif (copy_from_user(arg, user, copylen) != 0)"
            ],
            "deleted": [
                "\tif (copy_from_user(arg, user, get_arglen[GET_CMDID(cmd)]) != 0)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple stack-based buffer overflows in net/netfilter/ipvs/ip_vs_ctl.c in the Linux kernel before 2.6.33, when CONFIG_IP_VS is used, allow local users to gain privileges by leveraging the CAP_NET_ADMIN capability for (1) a getsockopt system call, related to the do_ip_vs_get_ctl function, or (2) a setsockopt system call, related to the do_ip_vs_set_ctl function.",
        "id": 334
    },
    {
        "cve_id": "CVE-2021-4204",
        "code_before_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 arg,\n\t\t\t  struct bpf_call_arg_meta *meta,\n\t\t\t  const struct bpf_func_proto *fn)\n{\n\tu32 regno = BPF_REG_1 + arg;\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_arg_type arg_type = fn->arg_type[arg];\n\tenum bpf_reg_type type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (base_type(arg_type) == ARG_PTR_TO_MAP_VALUE ||\n\t    base_type(arg_type) == ARG_PTR_TO_UNINIT_MAP_VALUE) {\n\t\terr = resolve_map_arg_type(env, meta, &arg_type);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (register_is_null(reg) && type_may_be_null(arg_type))\n\t\t/* A NULL register has a SCALAR_VALUE type, so skip\n\t\t * type checking.\n\t\t */\n\t\tgoto skip_type_check;\n\n\terr = check_reg_type(env, regno, arg_type, fn->arg_btf_id[arg]);\n\tif (err)\n\t\treturn err;\n\n\tif (type == PTR_TO_CTX) {\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\nskip_type_check:\n\tif (reg->ref_obj_id) {\n\t\tif (meta->ref_obj_id) {\n\t\t\tverbose(env, \"verifier internal error: more than one arg with ref_obj_id R%d %u %u\\n\",\n\t\t\t\tregno, reg->ref_obj_id,\n\t\t\t\tmeta->ref_obj_id);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tmeta->ref_obj_id = reg->ref_obj_id;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tif (meta->map_ptr) {\n\t\t\t/* Use map_uid (which is unique id of inner map) to reject:\n\t\t\t * inner_map1 = bpf_map_lookup_elem(outer_map, key1)\n\t\t\t * inner_map2 = bpf_map_lookup_elem(outer_map, key2)\n\t\t\t * if (inner_map1 && inner_map2) {\n\t\t\t *     timer = bpf_map_lookup_elem(inner_map1);\n\t\t\t *     if (timer)\n\t\t\t *         // mismatch would have been allowed\n\t\t\t *         bpf_timer_init(timer, inner_map2);\n\t\t\t * }\n\t\t\t *\n\t\t\t * Comparing map_ptr is enough to distinguish normal and outer maps.\n\t\t\t */\n\t\t\tif (meta->map_ptr != reg->map_ptr ||\n\t\t\t    meta->map_uid != reg->map_uid) {\n\t\t\t\tverbose(env,\n\t\t\t\t\t\"timer pointer in R1 map_uid=%d doesn't match map pointer in R2 map_uid=%d\\n\",\n\t\t\t\t\tmeta->map_uid, reg->map_uid);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tmeta->map_ptr = reg->map_ptr;\n\t\tmeta->map_uid = reg->map_uid;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (base_type(arg_type) == ARG_PTR_TO_MAP_VALUE ||\n\t\t   base_type(arg_type) == ARG_PTR_TO_UNINIT_MAP_VALUE) {\n\t\tif (type_may_be_null(arg_type) && register_is_null(reg))\n\t\t\treturn 0;\n\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->raw_mode = (arg_type == ARG_PTR_TO_UNINIT_MAP_VALUE);\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      meta);\n\t} else if (arg_type == ARG_PTR_TO_PERCPU_BTF_ID) {\n\t\tif (!reg->btf_id) {\n\t\t\tverbose(env, \"Helper has invalid btf_id in R%d\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->ret_btf = reg->btf;\n\t\tmeta->ret_btf_id = reg->btf_id;\n\t} else if (arg_type == ARG_PTR_TO_SPIN_LOCK) {\n\t\tif (meta->func_id == BPF_FUNC_spin_lock) {\n\t\t\tif (process_spin_lock(env, regno, true))\n\t\t\t\treturn -EACCES;\n\t\t} else if (meta->func_id == BPF_FUNC_spin_unlock) {\n\t\t\tif (process_spin_lock(env, regno, false))\n\t\t\t\treturn -EACCES;\n\t\t} else {\n\t\t\tverbose(env, \"verifier internal error\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (arg_type == ARG_PTR_TO_TIMER) {\n\t\tif (process_timer_func(env, regno, meta))\n\t\t\treturn -EACCES;\n\t} else if (arg_type == ARG_PTR_TO_FUNC) {\n\t\tmeta->subprogno = reg->subprogno;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\t/* The access to this pointer is only checked when we hit the\n\t\t * next is_mem_size argument below.\n\t\t */\n\t\tmeta->raw_mode = (arg_type == ARG_PTR_TO_UNINIT_MEM);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* This is used to refine r0 return value bounds for helpers\n\t\t * that enforce this value as an upper bound on return values.\n\t\t * See do_refine_retval_range() for helpers that can refine\n\t\t * the return value. C type of helper is u32 so we pull register\n\t\t * bound from umax_value however, if negative verifier errors\n\t\t * out. Only upper bounds can be learned because retval is an\n\t\t * int type and negative retvals are allowed.\n\t\t */\n\t\tmeta->msize_max_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t\tif (!err)\n\t\t\terr = mark_chain_precision(env, regno);\n\t} else if (arg_type_is_alloc_size(arg_type)) {\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tverbose(env, \"R%d is not a known constant'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->mem_size = reg->var_off.value;\n\t} else if (arg_type_is_int_ptr(arg_type)) {\n\t\tint size = int_ptr_type_to_size(arg_type);\n\n\t\terr = check_helper_mem_access(env, regno, size, false, meta);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_ptr_alignment(env, reg, 0, size, true);\n\t} else if (arg_type == ARG_PTR_TO_CONST_STR) {\n\t\tstruct bpf_map *map = reg->map_ptr;\n\t\tint map_off;\n\t\tu64 map_addr;\n\t\tchar *str_ptr;\n\n\t\tif (!bpf_map_is_rdonly(map)) {\n\t\t\tverbose(env, \"R%d does not point to a readonly map'\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tverbose(env, \"R%d is not a constant address'\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!map->ops->map_direct_value_addr) {\n\t\t\tverbose(env, \"no direct value access support for this map type\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, reg->off,\n\t\t\t\t       map->value_size - reg->off, false);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tmap_off = reg->off + reg->var_off.value;\n\t\terr = map->ops->map_direct_value_addr(map, &map_addr, map_off);\n\t\tif (err) {\n\t\t\tverbose(env, \"direct value access on string failed\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\tstr_ptr = (char *)(long)(map_addr);\n\t\tif (!strnchr(str_ptr + map_off, map->value_size - map_off, 0)) {\n\t\t\tverbose(env, \"string is not zero-terminated\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 arg,\n\t\t\t  struct bpf_call_arg_meta *meta,\n\t\t\t  const struct bpf_func_proto *fn)\n{\n\tu32 regno = BPF_REG_1 + arg;\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_arg_type arg_type = fn->arg_type[arg];\n\tenum bpf_reg_type type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (base_type(arg_type) == ARG_PTR_TO_MAP_VALUE ||\n\t    base_type(arg_type) == ARG_PTR_TO_UNINIT_MAP_VALUE) {\n\t\terr = resolve_map_arg_type(env, meta, &arg_type);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (register_is_null(reg) && type_may_be_null(arg_type))\n\t\t/* A NULL register has a SCALAR_VALUE type, so skip\n\t\t * type checking.\n\t\t */\n\t\tgoto skip_type_check;\n\n\terr = check_reg_type(env, regno, arg_type, fn->arg_btf_id[arg]);\n\tif (err)\n\t\treturn err;\n\n\tif (type == PTR_TO_CTX) {\n\t\terr = check_ptr_off_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\nskip_type_check:\n\tif (reg->ref_obj_id) {\n\t\tif (meta->ref_obj_id) {\n\t\t\tverbose(env, \"verifier internal error: more than one arg with ref_obj_id R%d %u %u\\n\",\n\t\t\t\tregno, reg->ref_obj_id,\n\t\t\t\tmeta->ref_obj_id);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tmeta->ref_obj_id = reg->ref_obj_id;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tif (meta->map_ptr) {\n\t\t\t/* Use map_uid (which is unique id of inner map) to reject:\n\t\t\t * inner_map1 = bpf_map_lookup_elem(outer_map, key1)\n\t\t\t * inner_map2 = bpf_map_lookup_elem(outer_map, key2)\n\t\t\t * if (inner_map1 && inner_map2) {\n\t\t\t *     timer = bpf_map_lookup_elem(inner_map1);\n\t\t\t *     if (timer)\n\t\t\t *         // mismatch would have been allowed\n\t\t\t *         bpf_timer_init(timer, inner_map2);\n\t\t\t * }\n\t\t\t *\n\t\t\t * Comparing map_ptr is enough to distinguish normal and outer maps.\n\t\t\t */\n\t\t\tif (meta->map_ptr != reg->map_ptr ||\n\t\t\t    meta->map_uid != reg->map_uid) {\n\t\t\t\tverbose(env,\n\t\t\t\t\t\"timer pointer in R1 map_uid=%d doesn't match map pointer in R2 map_uid=%d\\n\",\n\t\t\t\t\tmeta->map_uid, reg->map_uid);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t\tmeta->map_ptr = reg->map_ptr;\n\t\tmeta->map_uid = reg->map_uid;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (base_type(arg_type) == ARG_PTR_TO_MAP_VALUE ||\n\t\t   base_type(arg_type) == ARG_PTR_TO_UNINIT_MAP_VALUE) {\n\t\tif (type_may_be_null(arg_type) && register_is_null(reg))\n\t\t\treturn 0;\n\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->raw_mode = (arg_type == ARG_PTR_TO_UNINIT_MAP_VALUE);\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      meta);\n\t} else if (arg_type == ARG_PTR_TO_PERCPU_BTF_ID) {\n\t\tif (!reg->btf_id) {\n\t\t\tverbose(env, \"Helper has invalid btf_id in R%d\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->ret_btf = reg->btf;\n\t\tmeta->ret_btf_id = reg->btf_id;\n\t} else if (arg_type == ARG_PTR_TO_SPIN_LOCK) {\n\t\tif (meta->func_id == BPF_FUNC_spin_lock) {\n\t\t\tif (process_spin_lock(env, regno, true))\n\t\t\t\treturn -EACCES;\n\t\t} else if (meta->func_id == BPF_FUNC_spin_unlock) {\n\t\t\tif (process_spin_lock(env, regno, false))\n\t\t\t\treturn -EACCES;\n\t\t} else {\n\t\t\tverbose(env, \"verifier internal error\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (arg_type == ARG_PTR_TO_TIMER) {\n\t\tif (process_timer_func(env, regno, meta))\n\t\t\treturn -EACCES;\n\t} else if (arg_type == ARG_PTR_TO_FUNC) {\n\t\tmeta->subprogno = reg->subprogno;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\t/* The access to this pointer is only checked when we hit the\n\t\t * next is_mem_size argument below.\n\t\t */\n\t\tmeta->raw_mode = (arg_type == ARG_PTR_TO_UNINIT_MEM);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* This is used to refine r0 return value bounds for helpers\n\t\t * that enforce this value as an upper bound on return values.\n\t\t * See do_refine_retval_range() for helpers that can refine\n\t\t * the return value. C type of helper is u32 so we pull register\n\t\t * bound from umax_value however, if negative verifier errors\n\t\t * out. Only upper bounds can be learned because retval is an\n\t\t * int type and negative retvals are allowed.\n\t\t */\n\t\tmeta->msize_max_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t\tif (!err)\n\t\t\terr = mark_chain_precision(env, regno);\n\t} else if (arg_type_is_alloc_size(arg_type)) {\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tverbose(env, \"R%d is not a known constant'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tmeta->mem_size = reg->var_off.value;\n\t} else if (arg_type_is_int_ptr(arg_type)) {\n\t\tint size = int_ptr_type_to_size(arg_type);\n\n\t\terr = check_helper_mem_access(env, regno, size, false, meta);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_ptr_alignment(env, reg, 0, size, true);\n\t} else if (arg_type == ARG_PTR_TO_CONST_STR) {\n\t\tstruct bpf_map *map = reg->map_ptr;\n\t\tint map_off;\n\t\tu64 map_addr;\n\t\tchar *str_ptr;\n\n\t\tif (!bpf_map_is_rdonly(map)) {\n\t\t\tverbose(env, \"R%d does not point to a readonly map'\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tverbose(env, \"R%d is not a constant address'\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!map->ops->map_direct_value_addr) {\n\t\t\tverbose(env, \"no direct value access support for this map type\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, reg->off,\n\t\t\t\t       map->value_size - reg->off, false);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tmap_off = reg->off + reg->var_off.value;\n\t\terr = map->ops->map_direct_value_addr(map, &map_addr, map_off);\n\t\tif (err) {\n\t\t\tverbose(env, \"direct value access on string failed\\n\");\n\t\t\treturn err;\n\t\t}\n\n\t\tstr_ptr = (char *)(long)(map_addr);\n\t\tif (!strnchr(str_ptr + map_off, map->value_size - map_off, 0)) {\n\t\t\tverbose(env, \"string is not zero-terminated\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -48,7 +48,7 @@\n \t\treturn err;\n \n \tif (type == PTR_TO_CTX) {\n-\t\terr = check_ctx_reg(env, reg, regno);\n+\t\terr = check_ptr_off_reg(env, reg, regno);\n \t\tif (err < 0)\n \t\t\treturn err;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\terr = check_ptr_off_reg(env, reg, regno);"
            ],
            "deleted": [
                "\t\terr = check_ctx_reg(env, reg, regno);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An out-of-bounds (OOB) memory access flaw was found in the Linux kernel's eBPF due to an Improper Input Validation. This flaw allows a local attacker with a special privilege to crash the system or leak internal information.",
        "id": 3152
    },
    {
        "cve_id": "CVE-2015-4036",
        "code_before_change": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\n\t\t   struct config_group *group,\n\t\t   const char *name)\n{\n\tstruct vhost_scsi_tport *tport = container_of(wwn,\n\t\t\tstruct vhost_scsi_tport, tport_wwn);\n\n\tstruct vhost_scsi_tpg *tpg;\n\tunsigned long tpgt;\n\tint ret;\n\n\tif (strstr(name, \"tpgt_\") != name)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\n\ttpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\n\tif (!tpg) {\n\t\tpr_err(\"Unable to allocate struct vhost_scsi_tpg\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tmutex_init(&tpg->tv_tpg_mutex);\n\tINIT_LIST_HEAD(&tpg->tv_tpg_list);\n\ttpg->tport = tport;\n\ttpg->tport_tpgt = tpgt;\n\n\tret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n\t\t\t\t&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0) {\n\t\tkfree(tpg);\n\t\treturn NULL;\n\t}\n\tmutex_lock(&vhost_scsi_mutex);\n\tlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\n\tmutex_unlock(&vhost_scsi_mutex);\n\n\treturn &tpg->se_tpg;\n}",
        "code_after_change": "static struct se_portal_group *\nvhost_scsi_make_tpg(struct se_wwn *wwn,\n\t\t   struct config_group *group,\n\t\t   const char *name)\n{\n\tstruct vhost_scsi_tport *tport = container_of(wwn,\n\t\t\tstruct vhost_scsi_tport, tport_wwn);\n\n\tstruct vhost_scsi_tpg *tpg;\n\tu16 tpgt;\n\tint ret;\n\n\tif (strstr(name, \"tpgt_\") != name)\n\t\treturn ERR_PTR(-EINVAL);\n\tif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)\n\t\treturn ERR_PTR(-EINVAL);\n\n\ttpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);\n\tif (!tpg) {\n\t\tpr_err(\"Unable to allocate struct vhost_scsi_tpg\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tmutex_init(&tpg->tv_tpg_mutex);\n\tINIT_LIST_HEAD(&tpg->tv_tpg_list);\n\ttpg->tport = tport;\n\ttpg->tport_tpgt = tpgt;\n\n\tret = core_tpg_register(&vhost_scsi_fabric_configfs->tf_ops, wwn,\n\t\t\t\t&tpg->se_tpg, tpg, TRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0) {\n\t\tkfree(tpg);\n\t\treturn NULL;\n\t}\n\tmutex_lock(&vhost_scsi_mutex);\n\tlist_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);\n\tmutex_unlock(&vhost_scsi_mutex);\n\n\treturn &tpg->se_tpg;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,12 +7,12 @@\n \t\t\tstruct vhost_scsi_tport, tport_wwn);\n \n \tstruct vhost_scsi_tpg *tpg;\n-\tunsigned long tpgt;\n+\tu16 tpgt;\n \tint ret;\n \n \tif (strstr(name, \"tpgt_\") != name)\n \t\treturn ERR_PTR(-EINVAL);\n-\tif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)\n+\tif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)\n \t\treturn ERR_PTR(-EINVAL);\n \n \ttpg = kzalloc(sizeof(struct vhost_scsi_tpg), GFP_KERNEL);",
        "function_modified_lines": {
            "added": [
                "\tu16 tpgt;",
                "\tif (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)"
            ],
            "deleted": [
                "\tunsigned long tpgt;",
                "\tif (kstrtoul(name + 5, 10, &tpgt) || tpgt > UINT_MAX)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Array index error in the tcm_vhost_make_tpg function in drivers/vhost/scsi.c in the Linux kernel before 4.0 might allow guest OS users to cause a denial of service (memory corruption) or possibly have unspecified other impact via a crafted VHOST_SCSI_SET_ENDPOINT ioctl call.  NOTE: the affected function was renamed to vhost_scsi_make_tpg before the vulnerability was announced.",
        "id": 761
    },
    {
        "cve_id": "CVE-2014-3184",
        "code_before_change": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n\t\t\trdesc[106] == 0x03) {\n\t\thid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\n\t\trdesc[105] = rdesc[110] = 0x03;\n\t\trdesc[106] = rdesc[111] = 0x21;\n\t}\n\treturn rdesc;\n}",
        "code_after_change": "static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n\t\t\trdesc[106] == 0x03) {\n\t\thid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\n\t\trdesc[105] = rdesc[110] = 0x03;\n\t\trdesc[106] = rdesc[111] = 0x21;\n\t}\n\treturn rdesc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static __u8 *sp_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n \t\tunsigned int *rsize)\n {\n-\tif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n+\tif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&\n \t\t\trdesc[106] == 0x03) {\n \t\thid_info(hdev, \"fixing up Sunplus Wireless Desktop report descriptor\\n\");\n \t\trdesc[105] = rdesc[110] = 0x03;",
        "function_modified_lines": {
            "added": [
                "\tif (*rsize >= 112 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&"
            ],
            "deleted": [
                "\tif (*rsize >= 107 && rdesc[104] == 0x26 && rdesc[105] == 0x80 &&"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The report_fixup functions in the HID subsystem in the Linux kernel before 3.16.2 might allow physically proximate attackers to cause a denial of service (out-of-bounds write) via a crafted device that provides a small report descriptor, related to (1) drivers/hid/hid-cherry.c, (2) drivers/hid/hid-kye.c, (3) drivers/hid/hid-lg.c, (4) drivers/hid/hid-monterey.c, (5) drivers/hid/hid-petalynx.c, and (6) drivers/hid/hid-sunplus.c.",
        "id": 520
    },
    {
        "cve_id": "CVE-2013-0231",
        "code_before_change": "int xen_pcibk_enable_msix(struct xen_pcibk_device *pdev,\n\t\t\t  struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint i, result;\n\tstruct msix_entry *entries;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI-X\\n\",\n\t\t       pci_name(dev));\n\tif (op->value > SH_INFO_MAX_VEC)\n\t\treturn -EINVAL;\n\n\tentries = kmalloc(op->value * sizeof(*entries), GFP_KERNEL);\n\tif (entries == NULL)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < op->value; i++) {\n\t\tentries[i].entry = op->msix_entries[i].entry;\n\t\tentries[i].vector = op->msix_entries[i].vector;\n\t}\n\n\tresult = pci_enable_msix(dev, entries, op->value);\n\n\tif (result == 0) {\n\t\tfor (i = 0; i < op->value; i++) {\n\t\t\top->msix_entries[i].entry = entries[i].entry;\n\t\t\tif (entries[i].vector)\n\t\t\t\top->msix_entries[i].vector =\n\t\t\t\t\txen_pirq_from_irq(entries[i].vector);\n\t\t\t\tif (unlikely(verbose_request))\n\t\t\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: \" \\\n\t\t\t\t\t\t\"MSI-X[%d]: %d\\n\",\n\t\t\t\t\t\tpci_name(dev), i,\n\t\t\t\t\t\top->msix_entries[i].vector);\n\t\t}\n\t} else {\n\t\tprintk(KERN_WARNING DRV_NAME \": %s: failed to enable MSI-X: err %d!\\n\",\n\t\t\tpci_name(dev), result);\n\t}\n\tkfree(entries);\n\n\top->value = result;\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn result > 0 ? 0 : result;\n}",
        "code_after_change": "int xen_pcibk_enable_msix(struct xen_pcibk_device *pdev,\n\t\t\t  struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint i, result;\n\tstruct msix_entry *entries;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI-X\\n\",\n\t\t       pci_name(dev));\n\tif (op->value > SH_INFO_MAX_VEC)\n\t\treturn -EINVAL;\n\n\tentries = kmalloc(op->value * sizeof(*entries), GFP_KERNEL);\n\tif (entries == NULL)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < op->value; i++) {\n\t\tentries[i].entry = op->msix_entries[i].entry;\n\t\tentries[i].vector = op->msix_entries[i].vector;\n\t}\n\n\tresult = pci_enable_msix(dev, entries, op->value);\n\n\tif (result == 0) {\n\t\tfor (i = 0; i < op->value; i++) {\n\t\t\top->msix_entries[i].entry = entries[i].entry;\n\t\t\tif (entries[i].vector)\n\t\t\t\top->msix_entries[i].vector =\n\t\t\t\t\txen_pirq_from_irq(entries[i].vector);\n\t\t\t\tif (unlikely(verbose_request))\n\t\t\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: \" \\\n\t\t\t\t\t\t\"MSI-X[%d]: %d\\n\",\n\t\t\t\t\t\tpci_name(dev), i,\n\t\t\t\t\t\top->msix_entries[i].vector);\n\t\t}\n\t} else\n\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI-X for guest %u: err %d!\\n\",\n\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n\t\t\t\t    result);\n\tkfree(entries);\n\n\top->value = result;\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn result > 0 ? 0 : result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -34,10 +34,10 @@\n \t\t\t\t\t\tpci_name(dev), i,\n \t\t\t\t\t\top->msix_entries[i].vector);\n \t\t}\n-\t} else {\n-\t\tprintk(KERN_WARNING DRV_NAME \": %s: failed to enable MSI-X: err %d!\\n\",\n-\t\t\tpci_name(dev), result);\n-\t}\n+\t} else\n+\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI-X for guest %u: err %d!\\n\",\n+\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n+\t\t\t\t    result);\n \tkfree(entries);\n \n \top->value = result;",
        "function_modified_lines": {
            "added": [
                "\t} else",
                "\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI-X for guest %u: err %d!\\n\",",
                "\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,",
                "\t\t\t\t    result);"
            ],
            "deleted": [
                "\t} else {",
                "\t\tprintk(KERN_WARNING DRV_NAME \": %s: failed to enable MSI-X: err %d!\\n\",",
                "\t\t\tpci_name(dev), result);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The pciback_enable_msi function in the PCI backend driver (drivers/xen/pciback/conf_space_capability_msi.c) in Xen for the Linux kernel 2.6.18 and 3.8 allows guest OS users with PCI device access to cause a denial of service via a large number of kernel log messages. NOTE: some of these details are obtained from third party information.",
        "id": 152
    },
    {
        "cve_id": "CVE-2013-0309",
        "code_before_change": "static inline int pmd_present(pmd_t pmd)\n{\n\treturn pmd_flags(pmd) & _PAGE_PRESENT;\n}",
        "code_after_change": "static inline int pmd_present(pmd_t pmd)\n{\n\t/*\n\t * Checking for _PAGE_PSE is needed too because\n\t * split_huge_page will temporarily clear the present bit (but\n\t * the _PAGE_PSE flag will remain set at all times while the\n\t * _PAGE_PRESENT bit is clear).\n\t */\n\treturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,10 @@\n static inline int pmd_present(pmd_t pmd)\n {\n-\treturn pmd_flags(pmd) & _PAGE_PRESENT;\n+\t/*\n+\t * Checking for _PAGE_PSE is needed too because\n+\t * split_huge_page will temporarily clear the present bit (but\n+\t * the _PAGE_PSE flag will remain set at all times while the\n+\t * _PAGE_PRESENT bit is clear).\n+\t */\n+\treturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);\n }",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * Checking for _PAGE_PSE is needed too because",
                "\t * split_huge_page will temporarily clear the present bit (but",
                "\t * the _PAGE_PSE flag will remain set at all times while the",
                "\t * _PAGE_PRESENT bit is clear).",
                "\t */",
                "\treturn pmd_flags(pmd) & (_PAGE_PRESENT | _PAGE_PROTNONE | _PAGE_PSE);"
            ],
            "deleted": [
                "\treturn pmd_flags(pmd) & _PAGE_PRESENT;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "arch/x86/include/asm/pgtable.h in the Linux kernel before 3.6.2, when transparent huge pages are used, does not properly support PROT_NONE memory regions, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "id": 155
    },
    {
        "cve_id": "CVE-2022-3625",
        "code_before_change": "static int devlink_param_set(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->set)\n\t\treturn -EOPNOTSUPP;\n\treturn param->set(devlink, param->id, ctx);\n}",
        "code_after_change": "static int devlink_param_set(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->set || devlink->reload_failed)\n\t\treturn -EOPNOTSUPP;\n\treturn param->set(devlink, param->id, ctx);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t     const struct devlink_param *param,\n \t\t\t     struct devlink_param_gset_ctx *ctx)\n {\n-\tif (!param->set)\n+\tif (!param->set || devlink->reload_failed)\n \t\treturn -EOPNOTSUPP;\n \treturn param->set(devlink, param->id, ctx);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!param->set || devlink->reload_failed)"
            ],
            "deleted": [
                "\tif (!param->set)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel. It has been classified as critical. This affects the function devlink_param_set/devlink_param_get of the file net/core/devlink.c of the component IPsec. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier VDB-211929 was assigned to this vulnerability.",
        "id": 3661
    },
    {
        "cve_id": "CVE-2017-7895",
        "code_before_change": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_symlinkargs *args)\n{\n\tunsigned int len, avail;\n\tchar *old, *new;\n\tstruct kvec *vec;\n\n\tif (!(p = decode_fh(p, &args->ffh)) ||\n\t    !(p = decode_filename(p, &args->fname, &args->flen))\n\t\t)\n\t\treturn 0;\n\tp = decode_sattr3(p, &args->attrs);\n\n\t/* now decode the pathname, which might be larger than the first page.\n\t * As we have to check for nul's anyway, we copy it into a new page\n\t * This page appears in the rq_res.pages list, but as pages_len is always\n\t * 0, it won't get in the way\n\t */\n\tlen = ntohl(*p++);\n\tif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\n\t\treturn 0;\n\targs->tname = new = page_address(*(rqstp->rq_next_page++));\n\targs->tlen = len;\n\t/* first copy and check from the first page */\n\told = (char*)p;\n\tvec = &rqstp->rq_arg.head[0];\n\tavail = vec->iov_len - (old - (char*)vec->iov_base);\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t/* now copy next page if there is one */\n\tif (len && !avail && rqstp->rq_arg.page_len) {\n\t\tavail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\n\t\told = page_address(rqstp->rq_arg.pages[0]);\n\t}\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t*new = '\\0';\n\tif (len)\n\t\treturn 0;\n\n\treturn 1;\n}",
        "code_after_change": "int\nnfs3svc_decode_symlinkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_symlinkargs *args)\n{\n\tunsigned int len, avail;\n\tchar *old, *new;\n\tstruct kvec *vec;\n\n\tif (!(p = decode_fh(p, &args->ffh)) ||\n\t    !(p = decode_filename(p, &args->fname, &args->flen))\n\t\t)\n\t\treturn 0;\n\tp = decode_sattr3(p, &args->attrs);\n\n\t/* now decode the pathname, which might be larger than the first page.\n\t * As we have to check for nul's anyway, we copy it into a new page\n\t * This page appears in the rq_res.pages list, but as pages_len is always\n\t * 0, it won't get in the way\n\t */\n\tlen = ntohl(*p++);\n\tif (len == 0 || len > NFS3_MAXPATHLEN || len >= PAGE_SIZE)\n\t\treturn 0;\n\targs->tname = new = page_address(*(rqstp->rq_next_page++));\n\targs->tlen = len;\n\t/* first copy and check from the first page */\n\told = (char*)p;\n\tvec = &rqstp->rq_arg.head[0];\n\tif ((void *)old > vec->iov_base + vec->iov_len)\n\t\treturn 0;\n\tavail = vec->iov_len - (old - (char*)vec->iov_base);\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t/* now copy next page if there is one */\n\tif (len && !avail && rqstp->rq_arg.page_len) {\n\t\tavail = min_t(unsigned int, rqstp->rq_arg.page_len, PAGE_SIZE);\n\t\told = page_address(rqstp->rq_arg.pages[0]);\n\t}\n\twhile (len && avail && *old) {\n\t\t*new++ = *old++;\n\t\tlen--;\n\t\tavail--;\n\t}\n\t*new = '\\0';\n\tif (len)\n\t\treturn 0;\n\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,8 @@\n \t/* first copy and check from the first page */\n \told = (char*)p;\n \tvec = &rqstp->rq_arg.head[0];\n+\tif ((void *)old > vec->iov_base + vec->iov_len)\n+\t\treturn 0;\n \tavail = vec->iov_len - (old - (char*)vec->iov_base);\n \twhile (len && avail && *old) {\n \t\t*new++ = *old++;",
        "function_modified_lines": {
            "added": [
                "\tif ((void *)old > vec->iov_base + vec->iov_len)",
                "\t\treturn 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The NFSv2 and NFSv3 server implementations in the Linux kernel through 4.10.13 lack certain checks for the end of a buffer, which allows remote attackers to trigger pointer-arithmetic errors or possibly have unspecified other impact via crafted requests, related to fs/nfsd/nfs3xdr.c and fs/nfsd/nfsxdr.c.",
        "id": 1531
    },
    {
        "cve_id": "CVE-2013-0231",
        "code_before_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint otherend = pdev->xdev->otherend_id;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",\n\t\t\totherend, status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
        "code_after_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",\n\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n\t\t\t\t    status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,6 @@\n \t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n {\n \tstruct xen_pcibk_dev_data *dev_data;\n-\tint otherend = pdev->xdev->otherend_id;\n \tint status;\n \n \tif (unlikely(verbose_request))\n@@ -11,8 +10,9 @@\n \tstatus = pci_enable_msi(dev);\n \n \tif (status) {\n-\t\tprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",\n-\t\t\totherend, status);\n+\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",\n+\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n+\t\t\t\t    status);\n \t\top->value = 0;\n \t\treturn XEN_PCI_ERR_op_failed;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\tpr_warn_ratelimited(DRV_NAME \": %s: error enabling MSI for guest %u: err %d\\n\",",
                "\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,",
                "\t\t\t\t    status);"
            ],
            "deleted": [
                "\tint otherend = pdev->xdev->otherend_id;",
                "\t\tprintk(KERN_ERR \"error enable msi for guest %x status %x\\n\",",
                "\t\t\totherend, status);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The pciback_enable_msi function in the PCI backend driver (drivers/xen/pciback/conf_space_capability_msi.c) in Xen for the Linux kernel 2.6.18 and 3.8 allows guest OS users with PCI device access to cause a denial of service via a large number of kernel log messages. NOTE: some of these details are obtained from third party information.",
        "id": 151
    },
    {
        "cve_id": "CVE-2018-14615",
        "code_before_change": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tunsigned long long iblocks;\n\n\tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n\tif (!iblocks) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, inode->i_ino, iblocks);\n\t\treturn false;\n\t}\n\n\tif (ino_of_node(node_page) != nid_of_node(node_page)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\t\t\t\"[%u, %u] run fsck to fix.\",\n\t\t\t__func__, inode->i_ino,\n\t\t\tino_of_node(node_page), nid_of_node(node_page));\n\t\treturn false;\n\t}\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode) &&\n\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n\t\t\t\"but extra_attr feature is off\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (F2FS_I(inode)->extent_tree) {\n\t\tstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\n\n\t\tif (ei->len &&\n\t\t\t(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n\t\t\t!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\n\t\t\t\t\t\t\tDATA_GENERIC))) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\t\t\t\t\"is incorrect, run fsck to fix\",\n\t\t\t\t__func__, inode->i_ino,\n\t\t\t\tei->blk, ei->fofs, ei->len);\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}",
        "code_after_change": "static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tunsigned long long iblocks;\n\n\tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n\tif (!iblocks) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode i_blocks i_ino=%lx iblocks=%llu, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, inode->i_ino, iblocks);\n\t\treturn false;\n\t}\n\n\tif (ino_of_node(node_page) != nid_of_node(node_page)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode footer i_ino=%lx, ino,nid: \"\n\t\t\t\"[%u, %u] run fsck to fix.\",\n\t\t\t__func__, inode->i_ino,\n\t\t\tino_of_node(node_page), nid_of_node(node_page));\n\t\treturn false;\n\t}\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)\n\t\t\t&& !f2fs_has_extra_attr(inode)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inode ino=%lx, run fsck to fix.\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (f2fs_has_extra_attr(inode) &&\n\t\t\t!f2fs_sb_has_extra_attr(sbi->sb)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) is with extra_attr, \"\n\t\t\t\"but extra_attr feature is off\",\n\t\t\t__func__, inode->i_ino);\n\t\treturn false;\n\t}\n\n\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\n\t\t\tfi->i_extra_isize % sizeof(__le32)) {\n\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"\n\t\t\t\"max: %zu\",\n\t\t\t__func__, inode->i_ino, fi->i_extra_isize,\n\t\t\tF2FS_TOTAL_EXTRA_ATTR_SIZE);\n\t\treturn false;\n\t}\n\n\tif (F2FS_I(inode)->extent_tree) {\n\t\tstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\n\n\t\tif (ei->len &&\n\t\t\t(!f2fs_is_valid_blkaddr(sbi, ei->blk, DATA_GENERIC) ||\n\t\t\t!f2fs_is_valid_blkaddr(sbi, ei->blk + ei->len - 1,\n\t\t\t\t\t\t\tDATA_GENERIC))) {\n\t\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n\t\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n\t\t\t\t\"%s: inode (ino=%lx) extent info [%u, %u, %u] \"\n\t\t\t\t\"is incorrect, run fsck to fix\",\n\t\t\t\t__func__, inode->i_ino,\n\t\t\t\tei->blk, ei->fofs, ei->len);\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,7 @@\n static bool sanity_check_inode(struct inode *inode, struct page *node_page)\n {\n \tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n+\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n \tunsigned long long iblocks;\n \n \tiblocks = le64_to_cpu(F2FS_INODE(node_page)->i_blocks);\n@@ -42,6 +43,17 @@\n \t\treturn false;\n \t}\n \n+\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||\n+\t\t\tfi->i_extra_isize % sizeof(__le32)) {\n+\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);\n+\t\tf2fs_msg(sbi->sb, KERN_WARNING,\n+\t\t\t\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"\n+\t\t\t\"max: %zu\",\n+\t\t\t__func__, inode->i_ino, fi->i_extra_isize,\n+\t\t\tF2FS_TOTAL_EXTRA_ATTR_SIZE);\n+\t\treturn false;\n+\t}\n+\n \tif (F2FS_I(inode)->extent_tree) {\n \t\tstruct extent_info *ei = &F2FS_I(inode)->extent_tree->largest;\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct f2fs_inode_info *fi = F2FS_I(inode);",
                "\tif (fi->i_extra_isize > F2FS_TOTAL_EXTRA_ATTR_SIZE ||",
                "\t\t\tfi->i_extra_isize % sizeof(__le32)) {",
                "\t\tset_sbi_flag(sbi, SBI_NEED_FSCK);",
                "\t\tf2fs_msg(sbi->sb, KERN_WARNING,",
                "\t\t\t\"%s: inode (ino=%lx) has corrupted i_extra_isize: %d, \"",
                "\t\t\t\"max: %zu\",",
                "\t\t\t__func__, inode->i_ino, fi->i_extra_isize,",
                "\t\t\tF2FS_TOTAL_EXTRA_ATTR_SIZE);",
                "\t\treturn false;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is a buffer overflow in truncate_inline_inode() in fs/f2fs/inline.c when umounting an f2fs image, because a length value may be negative.",
        "id": 1686
    },
    {
        "cve_id": "CVE-2013-4514",
        "code_before_change": "int wvlan_set_station_nickname(struct net_device *dev,\n\t\t      struct iw_request_info *info,\n\t\t      union iwreq_data *wrqu,\n\t\t      char *extra)\n{\n\tstruct wl_private *lp = wl_priv(dev);\n\tunsigned long flags;\n\tint         ret = 0;\n\t/*------------------------------------------------------------------------*/\n\n\n\tDBG_FUNC(\"wvlan_set_station_nickname\");\n\tDBG_ENTER(DbgInfo);\n\n\twl_lock(lp, &flags);\n\n\tmemset(lp->StationName, 0, sizeof(lp->StationName));\n\n\tmemcpy(lp->StationName, extra, wrqu->data.length);\n\n\t/* Commit the adapter parameters */\n\twl_apply(lp);\n\twl_unlock(lp, &flags);\n\n\tDBG_LEAVE(DbgInfo);\n\treturn ret;\n} /* wvlan_set_station_nickname */",
        "code_after_change": "int wvlan_set_station_nickname(struct net_device *dev,\n\t\t      struct iw_request_info *info,\n\t\t      union iwreq_data *wrqu,\n\t\t      char *extra)\n{\n\tstruct wl_private *lp = wl_priv(dev);\n\tunsigned long flags;\n\tsize_t len;\n\tint         ret = 0;\n\t/*------------------------------------------------------------------------*/\n\n\n\tDBG_FUNC(\"wvlan_set_station_nickname\");\n\tDBG_ENTER(DbgInfo);\n\n\twl_lock(lp, &flags);\n\n\tmemset(lp->StationName, 0, sizeof(lp->StationName));\n\tlen = min_t(size_t, wrqu->data.length, sizeof(lp->StationName));\n\tstrlcpy(lp->StationName, extra, len);\n\n\t/* Commit the adapter parameters */\n\twl_apply(lp);\n\twl_unlock(lp, &flags);\n\n\tDBG_LEAVE(DbgInfo);\n\treturn ret;\n} /* wvlan_set_station_nickname */",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n {\n \tstruct wl_private *lp = wl_priv(dev);\n \tunsigned long flags;\n+\tsize_t len;\n \tint         ret = 0;\n \t/*------------------------------------------------------------------------*/\n \n@@ -15,8 +16,8 @@\n \twl_lock(lp, &flags);\n \n \tmemset(lp->StationName, 0, sizeof(lp->StationName));\n-\n-\tmemcpy(lp->StationName, extra, wrqu->data.length);\n+\tlen = min_t(size_t, wrqu->data.length, sizeof(lp->StationName));\n+\tstrlcpy(lp->StationName, extra, len);\n \n \t/* Commit the adapter parameters */\n \twl_apply(lp);",
        "function_modified_lines": {
            "added": [
                "\tsize_t len;",
                "\tlen = min_t(size_t, wrqu->data.length, sizeof(lp->StationName));",
                "\tstrlcpy(lp->StationName, extra, len);"
            ],
            "deleted": [
                "",
                "\tmemcpy(lp->StationName, extra, wrqu->data.length);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple buffer overflows in drivers/staging/wlags49_h2/wl_priv.c in the Linux kernel before 3.12 allow local users to cause a denial of service or possibly have unspecified other impact by leveraging the CAP_NET_ADMIN capability and providing a long station-name string, related to the (1) wvlan_uil_put_info and (2) wvlan_set_station_nickname functions.",
        "id": 325
    },
    {
        "cve_id": "CVE-2011-5327",
        "code_before_change": "struct se_portal_group *tcm_loop_make_naa_tpg(\n\tstruct se_wwn *wwn,\n\tstruct config_group *group,\n\tconst char *name)\n{\n\tstruct tcm_loop_hba *tl_hba = container_of(wwn,\n\t\t\tstruct tcm_loop_hba, tl_hba_wwn);\n\tstruct tcm_loop_tpg *tl_tpg;\n\tchar *tpgt_str, *end_ptr;\n\tint ret;\n\tunsigned short int tpgt;\n\n\ttpgt_str = strstr(name, \"tpgt_\");\n\tif (!tpgt_str) {\n\t\tprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\t\t\t\t\" group\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttpgt_str += 5; /* Skip ahead of \"tpgt_\" */\n\ttpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\n\n\tif (tpgt > TL_TPGS_PER_HBA) {\n\t\tprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\t\t\t\t\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\n\ttl_tpg->tl_hba = tl_hba;\n\ttl_tpg->tl_tpgt = tpgt;\n\t/*\n\t * Register the tl_tpg as a emulated SAS TCM Target Endpoint\n\t */\n\tret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\n\t\t\twwn, &tl_tpg->tl_se_tpg, tl_tpg,\n\t\t\tTRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\t\t\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\n\t\tconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\n\n\treturn &tl_tpg->tl_se_tpg;\n}",
        "code_after_change": "struct se_portal_group *tcm_loop_make_naa_tpg(\n\tstruct se_wwn *wwn,\n\tstruct config_group *group,\n\tconst char *name)\n{\n\tstruct tcm_loop_hba *tl_hba = container_of(wwn,\n\t\t\tstruct tcm_loop_hba, tl_hba_wwn);\n\tstruct tcm_loop_tpg *tl_tpg;\n\tchar *tpgt_str, *end_ptr;\n\tint ret;\n\tunsigned short int tpgt;\n\n\ttpgt_str = strstr(name, \"tpgt_\");\n\tif (!tpgt_str) {\n\t\tprintk(KERN_ERR \"Unable to locate \\\"tpgt_#\\\" directory\"\n\t\t\t\t\" group\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttpgt_str += 5; /* Skip ahead of \"tpgt_\" */\n\ttpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\n\n\tif (tpgt >= TL_TPGS_PER_HBA) {\n\t\tprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n\t\t\t\t\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\ttl_tpg = &tl_hba->tl_hba_tpgs[tpgt];\n\ttl_tpg->tl_hba = tl_hba;\n\ttl_tpg->tl_tpgt = tpgt;\n\t/*\n\t * Register the tl_tpg as a emulated SAS TCM Target Endpoint\n\t */\n\tret = core_tpg_register(&tcm_loop_fabric_configfs->tf_ops,\n\t\t\twwn, &tl_tpg->tl_se_tpg, tl_tpg,\n\t\t\tTRANSPORT_TPG_TYPE_NORMAL);\n\tif (ret < 0)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tprintk(KERN_INFO \"TCM_Loop_ConfigFS: Allocated Emulated %s\"\n\t\t\" Target Port %s,t,0x%04x\\n\", tcm_loop_dump_proto_id(tl_hba),\n\t\tconfig_item_name(&wwn->wwn_group.cg_item), tpgt);\n\n\treturn &tl_tpg->tl_se_tpg;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \ttpgt_str += 5; /* Skip ahead of \"tpgt_\" */\n \ttpgt = (unsigned short int) simple_strtoul(tpgt_str, &end_ptr, 0);\n \n-\tif (tpgt > TL_TPGS_PER_HBA) {\n+\tif (tpgt >= TL_TPGS_PER_HBA) {\n \t\tprintk(KERN_ERR \"Passed tpgt: %hu exceeds TL_TPGS_PER_HBA:\"\n \t\t\t\t\" %u\\n\", tpgt, TL_TPGS_PER_HBA);\n \t\treturn ERR_PTR(-EINVAL);",
        "function_modified_lines": {
            "added": [
                "\tif (tpgt >= TL_TPGS_PER_HBA) {"
            ],
            "deleted": [
                "\tif (tpgt > TL_TPGS_PER_HBA) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 3.1, an off by one in the drivers/target/loopback/tcm_loop.c tcm_loop_make_naa_tpg() function could result in at least memory corruption.",
        "id": 39
    },
    {
        "cve_id": "CVE-2017-16534",
        "code_before_change": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\n\t\t\t\tstruct usb_interface *intf,\n\t\t\t\tu8 *buffer,\n\t\t\t\tint buflen)\n{\n\t/* duplicates are ignored */\n\tstruct usb_cdc_union_desc *union_header = NULL;\n\n\t/* duplicates are not tolerated */\n\tstruct usb_cdc_header_desc *header = NULL;\n\tstruct usb_cdc_ether_desc *ether = NULL;\n\tstruct usb_cdc_mdlm_detail_desc *detail = NULL;\n\tstruct usb_cdc_mdlm_desc *desc = NULL;\n\n\tunsigned int elength;\n\tint cnt = 0;\n\n\tmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\n\thdr->phonet_magic_present = false;\n\twhile (buflen > 0) {\n\t\telength = buffer[0];\n\t\tif (!elength) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage byte\\n\");\n\t\t\telength = 1;\n\t\t\tgoto next_desc;\n\t\t}\n\t\tif (buffer[1] != USB_DT_CS_INTERFACE) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage\\n\");\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\tswitch (buffer[2]) {\n\t\tcase USB_CDC_UNION_TYPE: /* we've found it */\n\t\t\tif (elength < sizeof(struct usb_cdc_union_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (union_header) {\n\t\t\t\tdev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\n\t\t\t\tgoto next_desc;\n\t\t\t}\n\t\t\tunion_header = (struct usb_cdc_union_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_COUNTRY_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_country_functional_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_country_functional_desc =\n\t\t\t\t(struct usb_cdc_country_functional_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_HEADER_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_header_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (header)\n\t\t\t\treturn -EINVAL;\n\t\t\theader = (struct usb_cdc_header_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ACM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_acm_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_acm_descriptor =\n\t\t\t\t(struct usb_cdc_acm_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ETHERNET_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_ether_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (ether)\n\t\t\t\treturn -EINVAL;\n\t\t\tether = (struct usb_cdc_ether_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_CALL_MANAGEMENT_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_call_mgmt_descriptor =\n\t\t\t\t(struct usb_cdc_call_mgmt_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_DMM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_dmm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_dmm_desc =\n\t\t\t\t(struct usb_cdc_dmm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (desc)\n\t\t\t\treturn -EINVAL;\n\t\t\tdesc = (struct usb_cdc_mdlm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_DETAIL_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (detail)\n\t\t\t\treturn -EINVAL;\n\t\t\tdetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_NCM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_ncm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_desc))\n\t\t\t\tgoto next_desc;\n\n\t\t\thdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_EXTENDED_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\n\t\t\t\tbreak;\n\t\t\thdr->usb_cdc_mbim_extended_desc =\n\t\t\t\t(struct usb_cdc_mbim_extended_desc *)buffer;\n\t\t\tbreak;\n\t\tcase CDC_PHONET_MAGIC_NUMBER:\n\t\t\thdr->phonet_magic_present = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/*\n\t\t\t * there are LOTS more CDC descriptors that\n\t\t\t * could legitimately be found here.\n\t\t\t */\n\t\t\tdev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\n\t\t\t\t\tbuffer[2], elength);\n\t\t\tgoto next_desc;\n\t\t}\n\t\tcnt++;\nnext_desc:\n\t\tbuflen -= elength;\n\t\tbuffer += elength;\n\t}\n\thdr->usb_cdc_union_desc = union_header;\n\thdr->usb_cdc_header_desc = header;\n\thdr->usb_cdc_mdlm_detail_desc = detail;\n\thdr->usb_cdc_mdlm_desc = desc;\n\thdr->usb_cdc_ether_desc = ether;\n\treturn cnt;\n}",
        "code_after_change": "int cdc_parse_cdc_header(struct usb_cdc_parsed_header *hdr,\n\t\t\t\tstruct usb_interface *intf,\n\t\t\t\tu8 *buffer,\n\t\t\t\tint buflen)\n{\n\t/* duplicates are ignored */\n\tstruct usb_cdc_union_desc *union_header = NULL;\n\n\t/* duplicates are not tolerated */\n\tstruct usb_cdc_header_desc *header = NULL;\n\tstruct usb_cdc_ether_desc *ether = NULL;\n\tstruct usb_cdc_mdlm_detail_desc *detail = NULL;\n\tstruct usb_cdc_mdlm_desc *desc = NULL;\n\n\tunsigned int elength;\n\tint cnt = 0;\n\n\tmemset(hdr, 0x00, sizeof(struct usb_cdc_parsed_header));\n\thdr->phonet_magic_present = false;\n\twhile (buflen > 0) {\n\t\telength = buffer[0];\n\t\tif (!elength) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage byte\\n\");\n\t\t\telength = 1;\n\t\t\tgoto next_desc;\n\t\t}\n\t\tif ((buflen < elength) || (elength < 3)) {\n\t\t\tdev_err(&intf->dev, \"invalid descriptor buffer length\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tif (buffer[1] != USB_DT_CS_INTERFACE) {\n\t\t\tdev_err(&intf->dev, \"skipping garbage\\n\");\n\t\t\tgoto next_desc;\n\t\t}\n\n\t\tswitch (buffer[2]) {\n\t\tcase USB_CDC_UNION_TYPE: /* we've found it */\n\t\t\tif (elength < sizeof(struct usb_cdc_union_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (union_header) {\n\t\t\t\tdev_err(&intf->dev, \"More than one union descriptor, skipping ...\\n\");\n\t\t\t\tgoto next_desc;\n\t\t\t}\n\t\t\tunion_header = (struct usb_cdc_union_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_COUNTRY_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_country_functional_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_country_functional_desc =\n\t\t\t\t(struct usb_cdc_country_functional_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_HEADER_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_header_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (header)\n\t\t\t\treturn -EINVAL;\n\t\t\theader = (struct usb_cdc_header_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ACM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_acm_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_acm_descriptor =\n\t\t\t\t(struct usb_cdc_acm_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_ETHERNET_TYPE:\n\t\t\tif (elength != sizeof(struct usb_cdc_ether_desc))\n\t\t\t\tgoto next_desc;\n\t\t\tif (ether)\n\t\t\t\treturn -EINVAL;\n\t\t\tether = (struct usb_cdc_ether_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_CALL_MANAGEMENT_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_call_mgmt_descriptor))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_call_mgmt_descriptor =\n\t\t\t\t(struct usb_cdc_call_mgmt_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_DMM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_dmm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_dmm_desc =\n\t\t\t\t(struct usb_cdc_dmm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (desc)\n\t\t\t\treturn -EINVAL;\n\t\t\tdesc = (struct usb_cdc_mdlm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MDLM_DETAIL_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mdlm_detail_desc *))\n\t\t\t\tgoto next_desc;\n\t\t\tif (detail)\n\t\t\t\treturn -EINVAL;\n\t\t\tdetail = (struct usb_cdc_mdlm_detail_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_NCM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_ncm_desc))\n\t\t\t\tgoto next_desc;\n\t\t\thdr->usb_cdc_ncm_desc = (struct usb_cdc_ncm_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_desc))\n\t\t\t\tgoto next_desc;\n\n\t\t\thdr->usb_cdc_mbim_desc = (struct usb_cdc_mbim_desc *)buffer;\n\t\t\tbreak;\n\t\tcase USB_CDC_MBIM_EXTENDED_TYPE:\n\t\t\tif (elength < sizeof(struct usb_cdc_mbim_extended_desc))\n\t\t\t\tbreak;\n\t\t\thdr->usb_cdc_mbim_extended_desc =\n\t\t\t\t(struct usb_cdc_mbim_extended_desc *)buffer;\n\t\t\tbreak;\n\t\tcase CDC_PHONET_MAGIC_NUMBER:\n\t\t\thdr->phonet_magic_present = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/*\n\t\t\t * there are LOTS more CDC descriptors that\n\t\t\t * could legitimately be found here.\n\t\t\t */\n\t\t\tdev_dbg(&intf->dev, \"Ignoring descriptor: type %02x, length %ud\\n\",\n\t\t\t\t\tbuffer[2], elength);\n\t\t\tgoto next_desc;\n\t\t}\n\t\tcnt++;\nnext_desc:\n\t\tbuflen -= elength;\n\t\tbuffer += elength;\n\t}\n\thdr->usb_cdc_union_desc = union_header;\n\thdr->usb_cdc_header_desc = header;\n\thdr->usb_cdc_mdlm_detail_desc = detail;\n\thdr->usb_cdc_mdlm_desc = desc;\n\thdr->usb_cdc_ether_desc = ether;\n\treturn cnt;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,6 +23,10 @@\n \t\t\tdev_err(&intf->dev, \"skipping garbage byte\\n\");\n \t\t\telength = 1;\n \t\t\tgoto next_desc;\n+\t\t}\n+\t\tif ((buflen < elength) || (elength < 3)) {\n+\t\t\tdev_err(&intf->dev, \"invalid descriptor buffer length\\n\");\n+\t\t\tbreak;\n \t\t}\n \t\tif (buffer[1] != USB_DT_CS_INTERFACE) {\n \t\t\tdev_err(&intf->dev, \"skipping garbage\\n\");",
        "function_modified_lines": {
            "added": [
                "\t\t}",
                "\t\tif ((buflen < elength) || (elength < 3)) {",
                "\t\t\tdev_err(&intf->dev, \"invalid descriptor buffer length\\n\");",
                "\t\t\tbreak;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The cdc_parse_cdc_header function in drivers/usb/core/message.c in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1321
    },
    {
        "cve_id": "CVE-2017-18193",
        "code_before_change": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct extent_tree *et;\n\tstruct extent_node *en;\n\tstruct extent_info ei;\n\n\tif (!f2fs_may_extent_tree(inode)) {\n\t\t/* drop largest extent */\n\t\tif (i_ext && i_ext->len) {\n\t\t\ti_ext->len = 0;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\n\tet = __grab_extent_tree(inode);\n\n\tif (!i_ext || !i_ext->len)\n\t\treturn false;\n\n\tget_extent_info(&ei, i_ext);\n\n\twrite_lock(&et->lock);\n\tif (atomic_read(&et->node_cnt))\n\t\tgoto out;\n\n\ten = __init_extent_tree(sbi, et, &ei);\n\tif (en) {\n\t\tspin_lock(&sbi->extent_lock);\n\t\tlist_add_tail(&en->list, &sbi->extent_list);\n\t\tspin_unlock(&sbi->extent_lock);\n\t}\nout:\n\twrite_unlock(&et->lock);\n\treturn false;\n}",
        "code_after_change": "bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n{\n\tbool ret =  __f2fs_init_extent_tree(inode, i_ext);\n\n\tif (!F2FS_I(inode)->extent_tree)\n\t\tset_inode_flag(inode, FI_NO_EXTENT);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,37 +1,9 @@\n bool f2fs_init_extent_tree(struct inode *inode, struct f2fs_extent *i_ext)\n {\n-\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n-\tstruct extent_tree *et;\n-\tstruct extent_node *en;\n-\tstruct extent_info ei;\n+\tbool ret =  __f2fs_init_extent_tree(inode, i_ext);\n \n-\tif (!f2fs_may_extent_tree(inode)) {\n-\t\t/* drop largest extent */\n-\t\tif (i_ext && i_ext->len) {\n-\t\t\ti_ext->len = 0;\n-\t\t\treturn true;\n-\t\t}\n-\t\treturn false;\n-\t}\n+\tif (!F2FS_I(inode)->extent_tree)\n+\t\tset_inode_flag(inode, FI_NO_EXTENT);\n \n-\tet = __grab_extent_tree(inode);\n-\n-\tif (!i_ext || !i_ext->len)\n-\t\treturn false;\n-\n-\tget_extent_info(&ei, i_ext);\n-\n-\twrite_lock(&et->lock);\n-\tif (atomic_read(&et->node_cnt))\n-\t\tgoto out;\n-\n-\ten = __init_extent_tree(sbi, et, &ei);\n-\tif (en) {\n-\t\tspin_lock(&sbi->extent_lock);\n-\t\tlist_add_tail(&en->list, &sbi->extent_list);\n-\t\tspin_unlock(&sbi->extent_lock);\n-\t}\n-out:\n-\twrite_unlock(&et->lock);\n-\treturn false;\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tbool ret =  __f2fs_init_extent_tree(inode, i_ext);",
                "\tif (!F2FS_I(inode)->extent_tree)",
                "\t\tset_inode_flag(inode, FI_NO_EXTENT);",
                "\treturn ret;"
            ],
            "deleted": [
                "\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);",
                "\tstruct extent_tree *et;",
                "\tstruct extent_node *en;",
                "\tstruct extent_info ei;",
                "\tif (!f2fs_may_extent_tree(inode)) {",
                "\t\t/* drop largest extent */",
                "\t\tif (i_ext && i_ext->len) {",
                "\t\t\ti_ext->len = 0;",
                "\t\t\treturn true;",
                "\t\t}",
                "\t\treturn false;",
                "\t}",
                "\tet = __grab_extent_tree(inode);",
                "",
                "\tif (!i_ext || !i_ext->len)",
                "\t\treturn false;",
                "",
                "\tget_extent_info(&ei, i_ext);",
                "",
                "\twrite_lock(&et->lock);",
                "\tif (atomic_read(&et->node_cnt))",
                "\t\tgoto out;",
                "",
                "\ten = __init_extent_tree(sbi, et, &ei);",
                "\tif (en) {",
                "\t\tspin_lock(&sbi->extent_lock);",
                "\t\tlist_add_tail(&en->list, &sbi->extent_list);",
                "\t\tspin_unlock(&sbi->extent_lock);",
                "\t}",
                "out:",
                "\twrite_unlock(&et->lock);",
                "\treturn false;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "fs/f2fs/extent_cache.c in the Linux kernel before 4.13 mishandles extent trees, which allows local users to cause a denial of service (BUG) via an application with multiple threads.",
        "id": 1394
    },
    {
        "cve_id": "CVE-2016-8633",
        "code_before_change": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\n\t\t\t\t int source_node_id, int generation,\n\t\t\t\t bool is_broadcast)\n{\n\tstruct sk_buff *skb;\n\tstruct net_device *net = dev->netdev;\n\tstruct rfc2734_header hdr;\n\tunsigned lf;\n\tunsigned long flags;\n\tstruct fwnet_peer *peer;\n\tstruct fwnet_partial_datagram *pd;\n\tint fg_off;\n\tint dg_size;\n\tu16 datagram_label;\n\tint retval;\n\tu16 ether_type;\n\n\thdr.w0 = be32_to_cpu(buf[0]);\n\tlf = fwnet_get_hdr_lf(&hdr);\n\tif (lf == RFC2374_HDR_UNFRAG) {\n\t\t/*\n\t\t * An unfragmented datagram has been received by the ieee1394\n\t\t * bus. Build an skbuff around it so we can pass it to the\n\t\t * high level network layer.\n\t\t */\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tbuf++;\n\t\tlen -= RFC2374_UNFRAG_HDR_SIZE;\n\n\t\tskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\n\t\tif (unlikely(!skb)) {\n\t\t\tnet->stats.rx_dropped++;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tskb_reserve(skb, LL_RESERVED_SPACE(net));\n\t\tmemcpy(skb_put(skb, len), buf, len);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    is_broadcast, ether_type);\n\t}\n\t/* A datagram fragment has been received, now the fun begins. */\n\thdr.w1 = ntohl(buf[1]);\n\tbuf += 2;\n\tlen -= RFC2374_FRAG_HDR_SIZE;\n\tif (lf == RFC2374_HDR_FIRSTFRAG) {\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tfg_off = 0;\n\t} else {\n\t\tether_type = 0;\n\t\tfg_off = fwnet_get_hdr_fg_off(&hdr);\n\t}\n\tdatagram_label = fwnet_get_hdr_dgl(&hdr);\n\tdg_size = fwnet_get_hdr_dg_size(&hdr); /* ??? + 1 */\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tpeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\n\tif (!peer) {\n\t\tretval = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tpd = fwnet_pd_find(peer, datagram_label);\n\tif (pd == NULL) {\n\t\twhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\n\t\t\t/* remove the oldest */\n\t\t\tfwnet_pd_delete(list_first_entry(&peer->pd_list,\n\t\t\t\tstruct fwnet_partial_datagram, pd_link));\n\t\t\tpeer->pdg_size--;\n\t\t}\n\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t  dg_size, buf, fg_off, len);\n\t\tif (pd == NULL) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tpeer->pdg_size++;\n\t} else {\n\t\tif (fwnet_frag_overlap(pd, fg_off, len) ||\n\t\t    pd->datagram_size != dg_size) {\n\t\t\t/*\n\t\t\t * Differing datagram sizes or overlapping fragments,\n\t\t\t * discard old datagram and start a new one.\n\t\t\t */\n\t\t\tfwnet_pd_delete(pd);\n\t\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t\t  dg_size, buf, fg_off, len);\n\t\t\tif (pd == NULL) {\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\n\t\t\t\t/*\n\t\t\t\t * Couldn't save off fragment anyway\n\t\t\t\t * so might as well obliterate the\n\t\t\t\t * datagram now.\n\t\t\t\t */\n\t\t\t\tfwnet_pd_delete(pd);\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t}\n\t} /* new datagram or add to existing one */\n\n\tif (lf == RFC2374_HDR_FIRSTFRAG)\n\t\tpd->ether_type = ether_type;\n\n\tif (fwnet_pd_is_complete(pd)) {\n\t\tether_type = pd->ether_type;\n\t\tpeer->pdg_size--;\n\t\tskb = skb_get(pd->skb);\n\t\tfwnet_pd_delete(pd);\n\n\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    false, ether_type);\n\t}\n\t/*\n\t * Datagram is not complete, we're done for the\n\t * moment.\n\t */\n\tretval = 0;\n fail:\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\treturn retval;\n}",
        "code_after_change": "static int fwnet_incoming_packet(struct fwnet_device *dev, __be32 *buf, int len,\n\t\t\t\t int source_node_id, int generation,\n\t\t\t\t bool is_broadcast)\n{\n\tstruct sk_buff *skb;\n\tstruct net_device *net = dev->netdev;\n\tstruct rfc2734_header hdr;\n\tunsigned lf;\n\tunsigned long flags;\n\tstruct fwnet_peer *peer;\n\tstruct fwnet_partial_datagram *pd;\n\tint fg_off;\n\tint dg_size;\n\tu16 datagram_label;\n\tint retval;\n\tu16 ether_type;\n\n\tif (len <= RFC2374_UNFRAG_HDR_SIZE)\n\t\treturn 0;\n\n\thdr.w0 = be32_to_cpu(buf[0]);\n\tlf = fwnet_get_hdr_lf(&hdr);\n\tif (lf == RFC2374_HDR_UNFRAG) {\n\t\t/*\n\t\t * An unfragmented datagram has been received by the ieee1394\n\t\t * bus. Build an skbuff around it so we can pass it to the\n\t\t * high level network layer.\n\t\t */\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tbuf++;\n\t\tlen -= RFC2374_UNFRAG_HDR_SIZE;\n\n\t\tskb = dev_alloc_skb(len + LL_RESERVED_SPACE(net));\n\t\tif (unlikely(!skb)) {\n\t\t\tnet->stats.rx_dropped++;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tskb_reserve(skb, LL_RESERVED_SPACE(net));\n\t\tmemcpy(skb_put(skb, len), buf, len);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    is_broadcast, ether_type);\n\t}\n\n\t/* A datagram fragment has been received, now the fun begins. */\n\n\tif (len <= RFC2374_FRAG_HDR_SIZE)\n\t\treturn 0;\n\n\thdr.w1 = ntohl(buf[1]);\n\tbuf += 2;\n\tlen -= RFC2374_FRAG_HDR_SIZE;\n\tif (lf == RFC2374_HDR_FIRSTFRAG) {\n\t\tether_type = fwnet_get_hdr_ether_type(&hdr);\n\t\tfg_off = 0;\n\t} else {\n\t\tether_type = 0;\n\t\tfg_off = fwnet_get_hdr_fg_off(&hdr);\n\t}\n\tdatagram_label = fwnet_get_hdr_dgl(&hdr);\n\tdg_size = fwnet_get_hdr_dg_size(&hdr); /* ??? + 1 */\n\n\tif (fg_off + len > dg_size)\n\t\treturn 0;\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tpeer = fwnet_peer_find_by_node_id(dev, source_node_id, generation);\n\tif (!peer) {\n\t\tretval = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\tpd = fwnet_pd_find(peer, datagram_label);\n\tif (pd == NULL) {\n\t\twhile (peer->pdg_size >= FWNET_MAX_FRAGMENTS) {\n\t\t\t/* remove the oldest */\n\t\t\tfwnet_pd_delete(list_first_entry(&peer->pd_list,\n\t\t\t\tstruct fwnet_partial_datagram, pd_link));\n\t\t\tpeer->pdg_size--;\n\t\t}\n\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t  dg_size, buf, fg_off, len);\n\t\tif (pd == NULL) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tpeer->pdg_size++;\n\t} else {\n\t\tif (fwnet_frag_overlap(pd, fg_off, len) ||\n\t\t    pd->datagram_size != dg_size) {\n\t\t\t/*\n\t\t\t * Differing datagram sizes or overlapping fragments,\n\t\t\t * discard old datagram and start a new one.\n\t\t\t */\n\t\t\tfwnet_pd_delete(pd);\n\t\t\tpd = fwnet_pd_new(net, peer, datagram_label,\n\t\t\t\t\t  dg_size, buf, fg_off, len);\n\t\t\tif (pd == NULL) {\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!fwnet_pd_update(peer, pd, buf, fg_off, len)) {\n\t\t\t\t/*\n\t\t\t\t * Couldn't save off fragment anyway\n\t\t\t\t * so might as well obliterate the\n\t\t\t\t * datagram now.\n\t\t\t\t */\n\t\t\t\tfwnet_pd_delete(pd);\n\t\t\t\tpeer->pdg_size--;\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t}\n\t} /* new datagram or add to existing one */\n\n\tif (lf == RFC2374_HDR_FIRSTFRAG)\n\t\tpd->ether_type = ether_type;\n\n\tif (fwnet_pd_is_complete(pd)) {\n\t\tether_type = pd->ether_type;\n\t\tpeer->pdg_size--;\n\t\tskb = skb_get(pd->skb);\n\t\tfwnet_pd_delete(pd);\n\n\t\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n\t\t\t\t\t\t    false, ether_type);\n\t}\n\t/*\n\t * Datagram is not complete, we're done for the\n\t * moment.\n\t */\n\tretval = 0;\n fail:\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,9 @@\n \tu16 datagram_label;\n \tint retval;\n \tu16 ether_type;\n+\n+\tif (len <= RFC2374_UNFRAG_HDR_SIZE)\n+\t\treturn 0;\n \n \thdr.w0 = be32_to_cpu(buf[0]);\n \tlf = fwnet_get_hdr_lf(&hdr);\n@@ -39,7 +42,12 @@\n \t\treturn fwnet_finish_incoming_packet(net, skb, source_node_id,\n \t\t\t\t\t\t    is_broadcast, ether_type);\n \t}\n+\n \t/* A datagram fragment has been received, now the fun begins. */\n+\n+\tif (len <= RFC2374_FRAG_HDR_SIZE)\n+\t\treturn 0;\n+\n \thdr.w1 = ntohl(buf[1]);\n \tbuf += 2;\n \tlen -= RFC2374_FRAG_HDR_SIZE;\n@@ -52,6 +60,9 @@\n \t}\n \tdatagram_label = fwnet_get_hdr_dgl(&hdr);\n \tdg_size = fwnet_get_hdr_dg_size(&hdr); /* ??? + 1 */\n+\n+\tif (fg_off + len > dg_size)\n+\t\treturn 0;\n \n \tspin_lock_irqsave(&dev->lock, flags);\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (len <= RFC2374_UNFRAG_HDR_SIZE)",
                "\t\treturn 0;",
                "",
                "",
                "\tif (len <= RFC2374_FRAG_HDR_SIZE)",
                "\t\treturn 0;",
                "",
                "",
                "\tif (fg_off + len > dg_size)",
                "\t\treturn 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119",
            "CWE-284"
        ],
        "cve_description": "drivers/firewire/net.c in the Linux kernel before 4.8.7, in certain unusual hardware configurations, allows remote attackers to execute arbitrary code via crafted fragmented packets.",
        "id": 1123
    },
    {
        "cve_id": "CVE-2022-3541",
        "code_before_change": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\n\t\t\t\t\tvoid *addrbuf)\n{\n\tstruct nvmem_cell *cell;\n\tssize_t len;\n\tu8 *mac;\n\n\t/* Get nvmem cell of mac-address from dts. */\n\tcell = of_nvmem_cell_get(np, \"mac-address\");\n\tif (IS_ERR(cell))\n\t\treturn PTR_ERR(cell);\n\n\t/* Read mac address from nvmem cell. */\n\tmac = nvmem_cell_read(cell, &len);\n\tnvmem_cell_put(cell);\n\tif (IS_ERR(mac))\n\t\treturn PTR_ERR(mac);\n\n\tif (len != ETH_ALEN) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Byte order of some samples are reversed.\n\t * Convert byte order here.\n\t */\n\tspl2sw_check_mac_vendor_id_and_convert(mac);\n\n\t/* Check if mac address is valid */\n\tif (!is_valid_ether_addr(mac)) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n\t\treturn -EINVAL;\n\t}\n\n\tether_addr_copy(addrbuf, mac);\n\tkfree(mac);\n\treturn 0;\n}",
        "code_after_change": "static int spl2sw_nvmem_get_mac_address(struct device *dev, struct device_node *np,\n\t\t\t\t\tvoid *addrbuf)\n{\n\tstruct nvmem_cell *cell;\n\tssize_t len;\n\tu8 *mac;\n\n\t/* Get nvmem cell of mac-address from dts. */\n\tcell = of_nvmem_cell_get(np, \"mac-address\");\n\tif (IS_ERR(cell))\n\t\treturn PTR_ERR(cell);\n\n\t/* Read mac address from nvmem cell. */\n\tmac = nvmem_cell_read(cell, &len);\n\tnvmem_cell_put(cell);\n\tif (IS_ERR(mac))\n\t\treturn PTR_ERR(mac);\n\n\tif (len != ETH_ALEN) {\n\t\tkfree(mac);\n\t\tdev_info(dev, \"Invalid length of mac address in nvmem!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Byte order of some samples are reversed.\n\t * Convert byte order here.\n\t */\n\tspl2sw_check_mac_vendor_id_and_convert(mac);\n\n\t/* Check if mac address is valid */\n\tif (!is_valid_ether_addr(mac)) {\n\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n\t\tkfree(mac);\n\t\treturn -EINVAL;\n\t}\n\n\tether_addr_copy(addrbuf, mac);\n\tkfree(mac);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,8 +29,8 @@\n \n \t/* Check if mac address is valid */\n \tif (!is_valid_ether_addr(mac)) {\n+\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n \t\tkfree(mac);\n-\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);\n \t\treturn -EINVAL;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);"
            ],
            "deleted": [
                "\t\tdev_info(dev, \"Invalid mac address in nvmem (%pM)!\\n\", mac);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability classified as critical has been found in Linux Kernel. This affects the function spl2sw_nvmem_get_mac_address of the file drivers/net/ethernet/sunplus/spl2sw_driver.c of the component BPF. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier VDB-211041 was assigned to this vulnerability.",
        "id": 3631
    },
    {
        "cve_id": "CVE-2017-1000253",
        "code_before_change": "static int load_elf_binary(struct linux_binprm *bprm)\n{\n\tstruct file *interpreter = NULL; /* to shut gcc up */\n \tunsigned long load_addr = 0, load_bias = 0;\n\tint load_addr_set = 0;\n\tchar * elf_interpreter = NULL;\n\tunsigned long error;\n\tstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\n\tunsigned long elf_bss, elf_brk;\n\tint retval, i;\n\tunsigned long elf_entry;\n\tunsigned long interp_load_addr = 0;\n\tunsigned long start_code, end_code, start_data, end_data;\n\tunsigned long reloc_func_desc __maybe_unused = 0;\n\tint executable_stack = EXSTACK_DEFAULT;\n\tstruct pt_regs *regs = current_pt_regs();\n\tstruct {\n\t\tstruct elfhdr elf_ex;\n\t\tstruct elfhdr interp_elf_ex;\n\t} *loc;\n\tstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\n\n\tloc = kmalloc(sizeof(*loc), GFP_KERNEL);\n\tif (!loc) {\n\t\tretval = -ENOMEM;\n\t\tgoto out_ret;\n\t}\n\t\n\t/* Get the exec-header */\n\tloc->elf_ex = *((struct elfhdr *)bprm->buf);\n\n\tretval = -ENOEXEC;\n\t/* First of all, some simple consistency checks */\n\tif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\tgoto out;\n\n\tif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\n\t\tgoto out;\n\tif (!elf_check_arch(&loc->elf_ex))\n\t\tgoto out;\n\tif (!bprm->file->f_op->mmap)\n\t\tgoto out;\n\n\telf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\n\tif (!elf_phdata)\n\t\tgoto out;\n\n\telf_ppnt = elf_phdata;\n\telf_bss = 0;\n\telf_brk = 0;\n\n\tstart_code = ~0UL;\n\tend_code = 0;\n\tstart_data = 0;\n\tend_data = 0;\n\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\n\t\tif (elf_ppnt->p_type == PT_INTERP) {\n\t\t\t/* This is the program interpreter used for\n\t\t\t * shared libraries - for now assume that this\n\t\t\t * is an a.out format binary\n\t\t\t */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_ppnt->p_filesz > PATH_MAX || \n\t\t\t    elf_ppnt->p_filesz < 2)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = -ENOMEM;\n\t\t\telf_interpreter = kmalloc(elf_ppnt->p_filesz,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!elf_interpreter)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = kernel_read(bprm->file, elf_ppnt->p_offset,\n\t\t\t\t\t     elf_interpreter,\n\t\t\t\t\t     elf_ppnt->p_filesz);\n\t\t\tif (retval != elf_ppnt->p_filesz) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_interp;\n\t\t\t}\n\t\t\t/* make sure path is NULL terminated */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\n\t\t\t\tgoto out_free_interp;\n\n\t\t\tinterpreter = open_exec(elf_interpreter);\n\t\t\tretval = PTR_ERR(interpreter);\n\t\t\tif (IS_ERR(interpreter))\n\t\t\t\tgoto out_free_interp;\n\n\t\t\t/*\n\t\t\t * If the binary is not readable then enforce\n\t\t\t * mm->dumpable = 0 regardless of the interpreter's\n\t\t\t * permissions.\n\t\t\t */\n\t\t\twould_dump(bprm, interpreter);\n\n\t\t\tretval = kernel_read(interpreter, 0, bprm->buf,\n\t\t\t\t\t     BINPRM_BUF_SIZE);\n\t\t\tif (retval != BINPRM_BUF_SIZE) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\n\t\t\t/* Get the exec headers */\n\t\t\tloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\n\t\t\tbreak;\n\t\t}\n\t\telf_ppnt++;\n\t}\n\n\telf_ppnt = elf_phdata;\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\n\t\tswitch (elf_ppnt->p_type) {\n\t\tcase PT_GNU_STACK:\n\t\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\t\texecutable_stack = EXSTACK_ENABLE_X;\n\t\t\telse\n\t\t\t\texecutable_stack = EXSTACK_DISABLE_X;\n\t\t\tbreak;\n\n\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\tretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\n\t\t\t\t\t\t  bprm->file, false,\n\t\t\t\t\t\t  &arch_state);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tbreak;\n\t\t}\n\n\t/* Some simple consistency checks for the interpreter */\n\tif (elf_interpreter) {\n\t\tretval = -ELIBBAD;\n\t\t/* Not an ELF interpreter */\n\t\tif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\t\tgoto out_free_dentry;\n\t\t/* Verify the interpreter has a valid arch */\n\t\tif (!elf_check_arch(&loc->interp_elf_ex))\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Load the interpreter program headers */\n\t\tinterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\n\t\t\t\t\t\t   interpreter);\n\t\tif (!interp_elf_phdata)\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Pass PT_LOPROC..PT_HIPROC headers to arch code */\n\t\telf_ppnt = interp_elf_phdata;\n\t\tfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\n\t\t\tswitch (elf_ppnt->p_type) {\n\t\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\t\tretval = arch_elf_pt_proc(&loc->interp_elf_ex,\n\t\t\t\t\t\t\t  elf_ppnt, interpreter,\n\t\t\t\t\t\t\t  true, &arch_state);\n\t\t\t\tif (retval)\n\t\t\t\t\tgoto out_free_dentry;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/*\n\t * Allow arch code to reject the ELF at this point, whilst it's\n\t * still possible to return an error to the code that invoked\n\t * the exec syscall.\n\t */\n\tretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Flush all traces of the currently running executable */\n\tretval = flush_old_exec(bprm);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Do this immediately, since STACK_TOP as used in setup_arg_pages\n\t   may depend on the personality.  */\n\tSET_PERSONALITY2(loc->elf_ex, &arch_state);\n\tif (elf_read_implies_exec(loc->elf_ex, executable_stack))\n\t\tcurrent->personality |= READ_IMPLIES_EXEC;\n\n\tif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\n\t\tcurrent->flags |= PF_RANDOMIZE;\n\n\tsetup_new_exec(bprm);\n\n\t/* Do this so that we can load the interpreter, if need be.  We will\n\t   change some of these later */\n\tretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\n\t\t\t\t executable_stack);\n\tif (retval < 0)\n\t\tgoto out_free_dentry;\n\t\n\tcurrent->mm->start_stack = bprm->p;\n\n\t/* Now we do a little grungy work by mmapping the ELF image into\n\t   the correct location in memory. */\n\tfor(i = 0, elf_ppnt = elf_phdata;\n\t    i < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\n\t\tint elf_prot = 0, elf_flags;\n\t\tunsigned long k, vaddr;\n\n\t\tif (elf_ppnt->p_type != PT_LOAD)\n\t\t\tcontinue;\n\n\t\tif (unlikely (elf_brk > elf_bss)) {\n\t\t\tunsigned long nbyte;\n\t            \n\t\t\t/* There was a PT_LOAD segment with p_memsz > p_filesz\n\t\t\t   before this one. Map anonymous pages, if needed,\n\t\t\t   and clear the area.  */\n\t\t\tretval = set_brk(elf_bss + load_bias,\n\t\t\t\t\t elf_brk + load_bias);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tnbyte = ELF_PAGEOFFSET(elf_bss);\n\t\t\tif (nbyte) {\n\t\t\t\tnbyte = ELF_MIN_ALIGN - nbyte;\n\t\t\t\tif (nbyte > elf_brk - elf_bss)\n\t\t\t\t\tnbyte = elf_brk - elf_bss;\n\t\t\t\tif (clear_user((void __user *)elf_bss +\n\t\t\t\t\t\t\tload_bias, nbyte)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * This bss-zeroing can fail if the ELF\n\t\t\t\t\t * file specifies odd protections. So\n\t\t\t\t\t * we don't check the return value\n\t\t\t\t\t */\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (elf_ppnt->p_flags & PF_R)\n\t\t\telf_prot |= PROT_READ;\n\t\tif (elf_ppnt->p_flags & PF_W)\n\t\t\telf_prot |= PROT_WRITE;\n\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\telf_prot |= PROT_EXEC;\n\n\t\telf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\n\n\t\tvaddr = elf_ppnt->p_vaddr;\n\t\tif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\n\t\t\telf_flags |= MAP_FIXED;\n\t\t} else if (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t/* Try and get dynamic programs out of the way of the\n\t\t\t * default mmap base, as well as whatever program they\n\t\t\t * might try to exec.  This is because the brk will\n\t\t\t * follow the loader, and is not movable.  */\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\n\t\t\t/* Memory randomization might have been switched off\n\t\t\t * in runtime via sysctl or explicit setting of\n\t\t\t * personality flags.\n\t\t\t * If that is the case, retain the original non-zero\n\t\t\t * load_bias value in order to establish proper\n\t\t\t * non-randomized mappings.\n\t\t\t */\n\t\t\tif (current->flags & PF_RANDOMIZE)\n\t\t\t\tload_bias = 0;\n\t\t\telse\n\t\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\n\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\n\t\t}\n\n\t\terror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\n\t\t\t\telf_prot, elf_flags, 0);\n\t\tif (BAD_ADDR(error)) {\n\t\t\tretval = IS_ERR((void *)error) ?\n\t\t\t\tPTR_ERR((void*)error) : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tif (!load_addr_set) {\n\t\t\tload_addr_set = 1;\n\t\t\tload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\n\t\t\tif (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t\tload_bias += error -\n\t\t\t\t             ELF_PAGESTART(load_bias + vaddr);\n\t\t\t\tload_addr += load_bias;\n\t\t\t\treloc_func_desc = load_bias;\n\t\t\t}\n\t\t}\n\t\tk = elf_ppnt->p_vaddr;\n\t\tif (k < start_code)\n\t\t\tstart_code = k;\n\t\tif (start_data < k)\n\t\t\tstart_data = k;\n\n\t\t/*\n\t\t * Check to see if the section's size will overflow the\n\t\t * allowed task size. Note that p_filesz must always be\n\t\t * <= p_memsz so it is only necessary to check p_memsz.\n\t\t */\n\t\tif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\n\t\t    elf_ppnt->p_memsz > TASK_SIZE ||\n\t\t    TASK_SIZE - elf_ppnt->p_memsz < k) {\n\t\t\t/* set_brk can never work. Avoid overflows. */\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\n\n\t\tif (k > elf_bss)\n\t\t\telf_bss = k;\n\t\tif ((elf_ppnt->p_flags & PF_X) && end_code < k)\n\t\t\tend_code = k;\n\t\tif (end_data < k)\n\t\t\tend_data = k;\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\n\t\tif (k > elf_brk)\n\t\t\telf_brk = k;\n\t}\n\n\tloc->elf_ex.e_entry += load_bias;\n\telf_bss += load_bias;\n\telf_brk += load_bias;\n\tstart_code += load_bias;\n\tend_code += load_bias;\n\tstart_data += load_bias;\n\tend_data += load_bias;\n\n\t/* Calling set_brk effectively mmaps the pages that we need\n\t * for the bss and break sections.  We must do this before\n\t * mapping in the interpreter, to make sure it doesn't wind\n\t * up getting placed where the bss needs to go.\n\t */\n\tretval = set_brk(elf_bss, elf_brk);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\tif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\n\t\tretval = -EFAULT; /* Nobody gets to see this, but.. */\n\t\tgoto out_free_dentry;\n\t}\n\n\tif (elf_interpreter) {\n\t\tunsigned long interp_map_addr = 0;\n\n\t\telf_entry = load_elf_interp(&loc->interp_elf_ex,\n\t\t\t\t\t    interpreter,\n\t\t\t\t\t    &interp_map_addr,\n\t\t\t\t\t    load_bias, interp_elf_phdata);\n\t\tif (!IS_ERR((void *)elf_entry)) {\n\t\t\t/*\n\t\t\t * load_elf_interp() returns relocation\n\t\t\t * adjustment\n\t\t\t */\n\t\t\tinterp_load_addr = elf_entry;\n\t\t\telf_entry += loc->interp_elf_ex.e_entry;\n\t\t}\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = IS_ERR((void *)elf_entry) ?\n\t\t\t\t\t(int)elf_entry : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t\treloc_func_desc = interp_load_addr;\n\n\t\tallow_write_access(interpreter);\n\t\tfput(interpreter);\n\t\tkfree(elf_interpreter);\n\t} else {\n\t\telf_entry = loc->elf_ex.e_entry;\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t}\n\n\tkfree(interp_elf_phdata);\n\tkfree(elf_phdata);\n\n\tset_binfmt(&elf_format);\n\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n\tretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\n\tif (retval < 0)\n\t\tgoto out;\n#endif /* ARCH_HAS_SETUP_ADDITIONAL_PAGES */\n\n\tinstall_exec_creds(bprm);\n\tretval = create_elf_tables(bprm, &loc->elf_ex,\n\t\t\t  load_addr, interp_load_addr);\n\tif (retval < 0)\n\t\tgoto out;\n\t/* N.B. passed_fileno might not be initialized? */\n\tcurrent->mm->end_code = end_code;\n\tcurrent->mm->start_code = start_code;\n\tcurrent->mm->start_data = start_data;\n\tcurrent->mm->end_data = end_data;\n\tcurrent->mm->start_stack = bprm->p;\n\n#ifdef arch_randomize_brk\n\tif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\n\t\tcurrent->mm->brk = current->mm->start_brk =\n\t\t\tarch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\n\t\tcurrent->brk_randomized = 1;\n#endif\n\t}\n#endif\n\n\tif (current->personality & MMAP_PAGE_ZERO) {\n\t\t/* Why this, you ask???  Well SVr4 maps page 0 as read-only,\n\t\t   and some applications \"depend\" upon this behavior.\n\t\t   Since we do not have the power to recompile these, we\n\t\t   emulate the SVr4 behavior. Sigh. */\n\t\terror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\n\t\t\t\tMAP_FIXED | MAP_PRIVATE, 0);\n\t}\n\n#ifdef ELF_PLAT_INIT\n\t/*\n\t * The ABI may specify that certain registers be set up in special\n\t * ways (on i386 %edx is the address of a DT_FINI function, for\n\t * example.  In addition, it may also specify (eg, PowerPC64 ELF)\n\t * that the e_entry field is the address of the function descriptor\n\t * for the startup routine, rather than the address of the startup\n\t * routine itself.  This macro performs whatever initialization to\n\t * the regs structure is required as well as any relocations to the\n\t * function descriptor entries when executing dynamically links apps.\n\t */\n\tELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\n\n\tstart_thread(regs, elf_entry, bprm->p);\n\tretval = 0;\nout:\n\tkfree(loc);\nout_ret:\n\treturn retval;\n\n\t/* error cleanup */\nout_free_dentry:\n\tkfree(interp_elf_phdata);\n\tallow_write_access(interpreter);\n\tif (interpreter)\n\t\tfput(interpreter);\nout_free_interp:\n\tkfree(elf_interpreter);\nout_free_ph:\n\tkfree(elf_phdata);\n\tgoto out;\n}",
        "code_after_change": "static int load_elf_binary(struct linux_binprm *bprm)\n{\n\tstruct file *interpreter = NULL; /* to shut gcc up */\n \tunsigned long load_addr = 0, load_bias = 0;\n\tint load_addr_set = 0;\n\tchar * elf_interpreter = NULL;\n\tunsigned long error;\n\tstruct elf_phdr *elf_ppnt, *elf_phdata, *interp_elf_phdata = NULL;\n\tunsigned long elf_bss, elf_brk;\n\tint retval, i;\n\tunsigned long elf_entry;\n\tunsigned long interp_load_addr = 0;\n\tunsigned long start_code, end_code, start_data, end_data;\n\tunsigned long reloc_func_desc __maybe_unused = 0;\n\tint executable_stack = EXSTACK_DEFAULT;\n\tstruct pt_regs *regs = current_pt_regs();\n\tstruct {\n\t\tstruct elfhdr elf_ex;\n\t\tstruct elfhdr interp_elf_ex;\n\t} *loc;\n\tstruct arch_elf_state arch_state = INIT_ARCH_ELF_STATE;\n\n\tloc = kmalloc(sizeof(*loc), GFP_KERNEL);\n\tif (!loc) {\n\t\tretval = -ENOMEM;\n\t\tgoto out_ret;\n\t}\n\t\n\t/* Get the exec-header */\n\tloc->elf_ex = *((struct elfhdr *)bprm->buf);\n\n\tretval = -ENOEXEC;\n\t/* First of all, some simple consistency checks */\n\tif (memcmp(loc->elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\tgoto out;\n\n\tif (loc->elf_ex.e_type != ET_EXEC && loc->elf_ex.e_type != ET_DYN)\n\t\tgoto out;\n\tif (!elf_check_arch(&loc->elf_ex))\n\t\tgoto out;\n\tif (!bprm->file->f_op->mmap)\n\t\tgoto out;\n\n\telf_phdata = load_elf_phdrs(&loc->elf_ex, bprm->file);\n\tif (!elf_phdata)\n\t\tgoto out;\n\n\telf_ppnt = elf_phdata;\n\telf_bss = 0;\n\telf_brk = 0;\n\n\tstart_code = ~0UL;\n\tend_code = 0;\n\tstart_data = 0;\n\tend_data = 0;\n\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++) {\n\t\tif (elf_ppnt->p_type == PT_INTERP) {\n\t\t\t/* This is the program interpreter used for\n\t\t\t * shared libraries - for now assume that this\n\t\t\t * is an a.out format binary\n\t\t\t */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_ppnt->p_filesz > PATH_MAX || \n\t\t\t    elf_ppnt->p_filesz < 2)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = -ENOMEM;\n\t\t\telf_interpreter = kmalloc(elf_ppnt->p_filesz,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!elf_interpreter)\n\t\t\t\tgoto out_free_ph;\n\n\t\t\tretval = kernel_read(bprm->file, elf_ppnt->p_offset,\n\t\t\t\t\t     elf_interpreter,\n\t\t\t\t\t     elf_ppnt->p_filesz);\n\t\t\tif (retval != elf_ppnt->p_filesz) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_interp;\n\t\t\t}\n\t\t\t/* make sure path is NULL terminated */\n\t\t\tretval = -ENOEXEC;\n\t\t\tif (elf_interpreter[elf_ppnt->p_filesz - 1] != '\\0')\n\t\t\t\tgoto out_free_interp;\n\n\t\t\tinterpreter = open_exec(elf_interpreter);\n\t\t\tretval = PTR_ERR(interpreter);\n\t\t\tif (IS_ERR(interpreter))\n\t\t\t\tgoto out_free_interp;\n\n\t\t\t/*\n\t\t\t * If the binary is not readable then enforce\n\t\t\t * mm->dumpable = 0 regardless of the interpreter's\n\t\t\t * permissions.\n\t\t\t */\n\t\t\twould_dump(bprm, interpreter);\n\n\t\t\tretval = kernel_read(interpreter, 0, bprm->buf,\n\t\t\t\t\t     BINPRM_BUF_SIZE);\n\t\t\tif (retval != BINPRM_BUF_SIZE) {\n\t\t\t\tif (retval >= 0)\n\t\t\t\t\tretval = -EIO;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\n\t\t\t/* Get the exec headers */\n\t\t\tloc->interp_elf_ex = *((struct elfhdr *)bprm->buf);\n\t\t\tbreak;\n\t\t}\n\t\telf_ppnt++;\n\t}\n\n\telf_ppnt = elf_phdata;\n\tfor (i = 0; i < loc->elf_ex.e_phnum; i++, elf_ppnt++)\n\t\tswitch (elf_ppnt->p_type) {\n\t\tcase PT_GNU_STACK:\n\t\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\t\texecutable_stack = EXSTACK_ENABLE_X;\n\t\t\telse\n\t\t\t\texecutable_stack = EXSTACK_DISABLE_X;\n\t\t\tbreak;\n\n\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\tretval = arch_elf_pt_proc(&loc->elf_ex, elf_ppnt,\n\t\t\t\t\t\t  bprm->file, false,\n\t\t\t\t\t\t  &arch_state);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tbreak;\n\t\t}\n\n\t/* Some simple consistency checks for the interpreter */\n\tif (elf_interpreter) {\n\t\tretval = -ELIBBAD;\n\t\t/* Not an ELF interpreter */\n\t\tif (memcmp(loc->interp_elf_ex.e_ident, ELFMAG, SELFMAG) != 0)\n\t\t\tgoto out_free_dentry;\n\t\t/* Verify the interpreter has a valid arch */\n\t\tif (!elf_check_arch(&loc->interp_elf_ex))\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Load the interpreter program headers */\n\t\tinterp_elf_phdata = load_elf_phdrs(&loc->interp_elf_ex,\n\t\t\t\t\t\t   interpreter);\n\t\tif (!interp_elf_phdata)\n\t\t\tgoto out_free_dentry;\n\n\t\t/* Pass PT_LOPROC..PT_HIPROC headers to arch code */\n\t\telf_ppnt = interp_elf_phdata;\n\t\tfor (i = 0; i < loc->interp_elf_ex.e_phnum; i++, elf_ppnt++)\n\t\t\tswitch (elf_ppnt->p_type) {\n\t\t\tcase PT_LOPROC ... PT_HIPROC:\n\t\t\t\tretval = arch_elf_pt_proc(&loc->interp_elf_ex,\n\t\t\t\t\t\t\t  elf_ppnt, interpreter,\n\t\t\t\t\t\t\t  true, &arch_state);\n\t\t\t\tif (retval)\n\t\t\t\t\tgoto out_free_dentry;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/*\n\t * Allow arch code to reject the ELF at this point, whilst it's\n\t * still possible to return an error to the code that invoked\n\t * the exec syscall.\n\t */\n\tretval = arch_check_elf(&loc->elf_ex, !!interpreter, &arch_state);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Flush all traces of the currently running executable */\n\tretval = flush_old_exec(bprm);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\n\t/* Do this immediately, since STACK_TOP as used in setup_arg_pages\n\t   may depend on the personality.  */\n\tSET_PERSONALITY2(loc->elf_ex, &arch_state);\n\tif (elf_read_implies_exec(loc->elf_ex, executable_stack))\n\t\tcurrent->personality |= READ_IMPLIES_EXEC;\n\n\tif (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)\n\t\tcurrent->flags |= PF_RANDOMIZE;\n\n\tsetup_new_exec(bprm);\n\n\t/* Do this so that we can load the interpreter, if need be.  We will\n\t   change some of these later */\n\tretval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),\n\t\t\t\t executable_stack);\n\tif (retval < 0)\n\t\tgoto out_free_dentry;\n\t\n\tcurrent->mm->start_stack = bprm->p;\n\n\t/* Now we do a little grungy work by mmapping the ELF image into\n\t   the correct location in memory. */\n\tfor(i = 0, elf_ppnt = elf_phdata;\n\t    i < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\n\t\tint elf_prot = 0, elf_flags;\n\t\tunsigned long k, vaddr;\n\t\tunsigned long total_size = 0;\n\n\t\tif (elf_ppnt->p_type != PT_LOAD)\n\t\t\tcontinue;\n\n\t\tif (unlikely (elf_brk > elf_bss)) {\n\t\t\tunsigned long nbyte;\n\t            \n\t\t\t/* There was a PT_LOAD segment with p_memsz > p_filesz\n\t\t\t   before this one. Map anonymous pages, if needed,\n\t\t\t   and clear the area.  */\n\t\t\tretval = set_brk(elf_bss + load_bias,\n\t\t\t\t\t elf_brk + load_bias);\n\t\t\tif (retval)\n\t\t\t\tgoto out_free_dentry;\n\t\t\tnbyte = ELF_PAGEOFFSET(elf_bss);\n\t\t\tif (nbyte) {\n\t\t\t\tnbyte = ELF_MIN_ALIGN - nbyte;\n\t\t\t\tif (nbyte > elf_brk - elf_bss)\n\t\t\t\t\tnbyte = elf_brk - elf_bss;\n\t\t\t\tif (clear_user((void __user *)elf_bss +\n\t\t\t\t\t\t\tload_bias, nbyte)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * This bss-zeroing can fail if the ELF\n\t\t\t\t\t * file specifies odd protections. So\n\t\t\t\t\t * we don't check the return value\n\t\t\t\t\t */\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (elf_ppnt->p_flags & PF_R)\n\t\t\telf_prot |= PROT_READ;\n\t\tif (elf_ppnt->p_flags & PF_W)\n\t\t\telf_prot |= PROT_WRITE;\n\t\tif (elf_ppnt->p_flags & PF_X)\n\t\t\telf_prot |= PROT_EXEC;\n\n\t\telf_flags = MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE;\n\n\t\tvaddr = elf_ppnt->p_vaddr;\n\t\tif (loc->elf_ex.e_type == ET_EXEC || load_addr_set) {\n\t\t\telf_flags |= MAP_FIXED;\n\t\t} else if (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t/* Try and get dynamic programs out of the way of the\n\t\t\t * default mmap base, as well as whatever program they\n\t\t\t * might try to exec.  This is because the brk will\n\t\t\t * follow the loader, and is not movable.  */\n#ifdef CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE\n\t\t\t/* Memory randomization might have been switched off\n\t\t\t * in runtime via sysctl or explicit setting of\n\t\t\t * personality flags.\n\t\t\t * If that is the case, retain the original non-zero\n\t\t\t * load_bias value in order to establish proper\n\t\t\t * non-randomized mappings.\n\t\t\t */\n\t\t\tif (current->flags & PF_RANDOMIZE)\n\t\t\t\tload_bias = 0;\n\t\t\telse\n\t\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#else\n\t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n#endif\n\t\t\ttotal_size = total_mapping_size(elf_phdata,\n\t\t\t\t\t\t\tloc->elf_ex.e_phnum);\n\t\t\tif (!total_size) {\n\t\t\t\terror = -EINVAL;\n\t\t\t\tgoto out_free_dentry;\n\t\t\t}\n\t\t}\n\n\t\terror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\n\t\t\t\telf_prot, elf_flags, total_size);\n\t\tif (BAD_ADDR(error)) {\n\t\t\tretval = IS_ERR((void *)error) ?\n\t\t\t\tPTR_ERR((void*)error) : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tif (!load_addr_set) {\n\t\t\tload_addr_set = 1;\n\t\t\tload_addr = (elf_ppnt->p_vaddr - elf_ppnt->p_offset);\n\t\t\tif (loc->elf_ex.e_type == ET_DYN) {\n\t\t\t\tload_bias += error -\n\t\t\t\t             ELF_PAGESTART(load_bias + vaddr);\n\t\t\t\tload_addr += load_bias;\n\t\t\t\treloc_func_desc = load_bias;\n\t\t\t}\n\t\t}\n\t\tk = elf_ppnt->p_vaddr;\n\t\tif (k < start_code)\n\t\t\tstart_code = k;\n\t\tif (start_data < k)\n\t\t\tstart_data = k;\n\n\t\t/*\n\t\t * Check to see if the section's size will overflow the\n\t\t * allowed task size. Note that p_filesz must always be\n\t\t * <= p_memsz so it is only necessary to check p_memsz.\n\t\t */\n\t\tif (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||\n\t\t    elf_ppnt->p_memsz > TASK_SIZE ||\n\t\t    TASK_SIZE - elf_ppnt->p_memsz < k) {\n\t\t\t/* set_brk can never work. Avoid overflows. */\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_filesz;\n\n\t\tif (k > elf_bss)\n\t\t\telf_bss = k;\n\t\tif ((elf_ppnt->p_flags & PF_X) && end_code < k)\n\t\t\tend_code = k;\n\t\tif (end_data < k)\n\t\t\tend_data = k;\n\t\tk = elf_ppnt->p_vaddr + elf_ppnt->p_memsz;\n\t\tif (k > elf_brk)\n\t\t\telf_brk = k;\n\t}\n\n\tloc->elf_ex.e_entry += load_bias;\n\telf_bss += load_bias;\n\telf_brk += load_bias;\n\tstart_code += load_bias;\n\tend_code += load_bias;\n\tstart_data += load_bias;\n\tend_data += load_bias;\n\n\t/* Calling set_brk effectively mmaps the pages that we need\n\t * for the bss and break sections.  We must do this before\n\t * mapping in the interpreter, to make sure it doesn't wind\n\t * up getting placed where the bss needs to go.\n\t */\n\tretval = set_brk(elf_bss, elf_brk);\n\tif (retval)\n\t\tgoto out_free_dentry;\n\tif (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {\n\t\tretval = -EFAULT; /* Nobody gets to see this, but.. */\n\t\tgoto out_free_dentry;\n\t}\n\n\tif (elf_interpreter) {\n\t\tunsigned long interp_map_addr = 0;\n\n\t\telf_entry = load_elf_interp(&loc->interp_elf_ex,\n\t\t\t\t\t    interpreter,\n\t\t\t\t\t    &interp_map_addr,\n\t\t\t\t\t    load_bias, interp_elf_phdata);\n\t\tif (!IS_ERR((void *)elf_entry)) {\n\t\t\t/*\n\t\t\t * load_elf_interp() returns relocation\n\t\t\t * adjustment\n\t\t\t */\n\t\t\tinterp_load_addr = elf_entry;\n\t\t\telf_entry += loc->interp_elf_ex.e_entry;\n\t\t}\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = IS_ERR((void *)elf_entry) ?\n\t\t\t\t\t(int)elf_entry : -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t\treloc_func_desc = interp_load_addr;\n\n\t\tallow_write_access(interpreter);\n\t\tfput(interpreter);\n\t\tkfree(elf_interpreter);\n\t} else {\n\t\telf_entry = loc->elf_ex.e_entry;\n\t\tif (BAD_ADDR(elf_entry)) {\n\t\t\tretval = -EINVAL;\n\t\t\tgoto out_free_dentry;\n\t\t}\n\t}\n\n\tkfree(interp_elf_phdata);\n\tkfree(elf_phdata);\n\n\tset_binfmt(&elf_format);\n\n#ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES\n\tretval = arch_setup_additional_pages(bprm, !!elf_interpreter);\n\tif (retval < 0)\n\t\tgoto out;\n#endif /* ARCH_HAS_SETUP_ADDITIONAL_PAGES */\n\n\tinstall_exec_creds(bprm);\n\tretval = create_elf_tables(bprm, &loc->elf_ex,\n\t\t\t  load_addr, interp_load_addr);\n\tif (retval < 0)\n\t\tgoto out;\n\t/* N.B. passed_fileno might not be initialized? */\n\tcurrent->mm->end_code = end_code;\n\tcurrent->mm->start_code = start_code;\n\tcurrent->mm->start_data = start_data;\n\tcurrent->mm->end_data = end_data;\n\tcurrent->mm->start_stack = bprm->p;\n\n#ifdef arch_randomize_brk\n\tif ((current->flags & PF_RANDOMIZE) && (randomize_va_space > 1)) {\n\t\tcurrent->mm->brk = current->mm->start_brk =\n\t\t\tarch_randomize_brk(current->mm);\n#ifdef CONFIG_COMPAT_BRK\n\t\tcurrent->brk_randomized = 1;\n#endif\n\t}\n#endif\n\n\tif (current->personality & MMAP_PAGE_ZERO) {\n\t\t/* Why this, you ask???  Well SVr4 maps page 0 as read-only,\n\t\t   and some applications \"depend\" upon this behavior.\n\t\t   Since we do not have the power to recompile these, we\n\t\t   emulate the SVr4 behavior. Sigh. */\n\t\terror = vm_mmap(NULL, 0, PAGE_SIZE, PROT_READ | PROT_EXEC,\n\t\t\t\tMAP_FIXED | MAP_PRIVATE, 0);\n\t}\n\n#ifdef ELF_PLAT_INIT\n\t/*\n\t * The ABI may specify that certain registers be set up in special\n\t * ways (on i386 %edx is the address of a DT_FINI function, for\n\t * example.  In addition, it may also specify (eg, PowerPC64 ELF)\n\t * that the e_entry field is the address of the function descriptor\n\t * for the startup routine, rather than the address of the startup\n\t * routine itself.  This macro performs whatever initialization to\n\t * the regs structure is required as well as any relocations to the\n\t * function descriptor entries when executing dynamically links apps.\n\t */\n\tELF_PLAT_INIT(regs, reloc_func_desc);\n#endif\n\n\tstart_thread(regs, elf_entry, bprm->p);\n\tretval = 0;\nout:\n\tkfree(loc);\nout_ret:\n\treturn retval;\n\n\t/* error cleanup */\nout_free_dentry:\n\tkfree(interp_elf_phdata);\n\tallow_write_access(interpreter);\n\tif (interpreter)\n\t\tfput(interpreter);\nout_free_interp:\n\tkfree(elf_interpreter);\nout_free_ph:\n\tkfree(elf_phdata);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -200,6 +200,7 @@\n \t    i < loc->elf_ex.e_phnum; i++, elf_ppnt++) {\n \t\tint elf_prot = 0, elf_flags;\n \t\tunsigned long k, vaddr;\n+\t\tunsigned long total_size = 0;\n \n \t\tif (elf_ppnt->p_type != PT_LOAD)\n \t\t\tcontinue;\n@@ -262,10 +263,16 @@\n #else\n \t\t\tload_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);\n #endif\n+\t\t\ttotal_size = total_mapping_size(elf_phdata,\n+\t\t\t\t\t\t\tloc->elf_ex.e_phnum);\n+\t\t\tif (!total_size) {\n+\t\t\t\terror = -EINVAL;\n+\t\t\t\tgoto out_free_dentry;\n+\t\t\t}\n \t\t}\n \n \t\terror = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,\n-\t\t\t\telf_prot, elf_flags, 0);\n+\t\t\t\telf_prot, elf_flags, total_size);\n \t\tif (BAD_ADDR(error)) {\n \t\t\tretval = IS_ERR((void *)error) ?\n \t\t\t\tPTR_ERR((void*)error) : -EINVAL;",
        "function_modified_lines": {
            "added": [
                "\t\tunsigned long total_size = 0;",
                "\t\t\ttotal_size = total_mapping_size(elf_phdata,",
                "\t\t\t\t\t\t\tloc->elf_ex.e_phnum);",
                "\t\t\tif (!total_size) {",
                "\t\t\t\terror = -EINVAL;",
                "\t\t\t\tgoto out_free_dentry;",
                "\t\t\t}",
                "\t\t\t\telf_prot, elf_flags, total_size);"
            ],
            "deleted": [
                "\t\t\t\telf_prot, elf_flags, 0);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Linux distributions that have not patched their long-term kernels with https://git.kernel.org/linus/a87938b2e246b81b4fb713edb371a9fa3c5c3c86 (committed on April 14, 2015). This kernel vulnerability was fixed in April 2015 by commit a87938b2e246b81b4fb713edb371a9fa3c5c3c86 (backported to Linux 3.10.77 in May 2015), but it was not recognized as a security threat. With CONFIG_ARCH_BINFMT_ELF_RANDOMIZE_PIE enabled, and a normal top-down address allocation strategy, load_elf_binary() will attempt to map a PIE binary into an address range immediately below mm->mmap_base. Unfortunately, load_elf_ binary() does not take account of the need to allocate sufficient space for the entire binary which means that, while the first PT_LOAD segment is mapped below mm->mmap_base, the subsequent PT_LOAD segment(s) end up being mapped above mm->mmap_base into the are that is supposed to be the \"gap\" between the stack and the binary.",
        "id": 1194
    },
    {
        "cve_id": "CVE-2013-2895",
        "code_before_change": "static int logi_dj_recv_send_report(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t    struct dj_report *dj_report)\n{\n\tstruct hid_device *hdev = djrcv_dev->hdev;\n\tstruct hid_report *report;\n\tstruct hid_report_enum *output_report_enum;\n\tu8 *data = (u8 *)(&dj_report->device_index);\n\tint i;\n\n\toutput_report_enum = &hdev->report_enum[HID_OUTPUT_REPORT];\n\treport = output_report_enum->report_id_hash[REPORT_ID_DJ_SHORT];\n\n\tif (!report) {\n\t\tdev_err(&hdev->dev, \"%s: unable to find dj report\\n\", __func__);\n\t\treturn -ENODEV;\n\t}\n\n\tfor (i = 0; i < report->field[0]->report_count; i++)\n\t\treport->field[0]->value[i] = data[i];\n\n\thid_hw_request(hdev, report, HID_REQ_SET_REPORT);\n\n\treturn 0;\n}",
        "code_after_change": "static int logi_dj_recv_send_report(struct dj_receiver_dev *djrcv_dev,\n\t\t\t\t    struct dj_report *dj_report)\n{\n\tstruct hid_device *hdev = djrcv_dev->hdev;\n\tstruct hid_report *report;\n\tstruct hid_report_enum *output_report_enum;\n\tu8 *data = (u8 *)(&dj_report->device_index);\n\tunsigned int i;\n\n\toutput_report_enum = &hdev->report_enum[HID_OUTPUT_REPORT];\n\treport = output_report_enum->report_id_hash[REPORT_ID_DJ_SHORT];\n\n\tif (!report) {\n\t\tdev_err(&hdev->dev, \"%s: unable to find dj report\\n\", __func__);\n\t\treturn -ENODEV;\n\t}\n\n\tfor (i = 0; i < DJREPORT_SHORT_LENGTH - 1; i++)\n\t\treport->field[0]->value[i] = data[i];\n\n\thid_hw_request(hdev, report, HID_REQ_SET_REPORT);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct hid_report *report;\n \tstruct hid_report_enum *output_report_enum;\n \tu8 *data = (u8 *)(&dj_report->device_index);\n-\tint i;\n+\tunsigned int i;\n \n \toutput_report_enum = &hdev->report_enum[HID_OUTPUT_REPORT];\n \treport = output_report_enum->report_id_hash[REPORT_ID_DJ_SHORT];\n@@ -15,7 +15,7 @@\n \t\treturn -ENODEV;\n \t}\n \n-\tfor (i = 0; i < report->field[0]->report_count; i++)\n+\tfor (i = 0; i < DJREPORT_SHORT_LENGTH - 1; i++)\n \t\treport->field[0]->value[i] = data[i];\n \n \thid_hw_request(hdev, report, HID_REQ_SET_REPORT);",
        "function_modified_lines": {
            "added": [
                "\tunsigned int i;",
                "\tfor (i = 0; i < DJREPORT_SHORT_LENGTH - 1; i++)"
            ],
            "deleted": [
                "\tint i;",
                "\tfor (i = 0; i < report->field[0]->report_count; i++)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-logitech-dj.c in the Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_HID_LOGITECH_DJ is enabled, allows physically proximate attackers to cause a denial of service (NULL pointer dereference and OOPS) or obtain sensitive information from kernel memory via a crafted device.",
        "id": 254
    },
    {
        "cve_id": "CVE-2014-0205",
        "code_before_change": "static int futex_wait_requeue_pi(u32 __user *uaddr, int fshared,\n\t\t\t\t u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t\t int clockrt, u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to = NULL;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct rt_mutex *pi_mutex = NULL;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2;\n\tstruct futex_q q;\n\tint res, ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tif (abs_time) {\n\t\tto = &timeout;\n\t\thrtimer_init_on_stack(&to->timer, clockrt ? CLOCK_REALTIME :\n\t\t\t\t      CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\n\t\thrtimer_init_sleeper(to, current);\n\t\thrtimer_set_expires_range_ns(&to->timer, *abs_time,\n\t\t\t\t\t     current->timer_slack_ns);\n\t}\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\tdebug_rt_mutex_init_waiter(&rt_waiter);\n\trt_waiter.task = NULL;\n\n\tkey2 = FUTEX_KEY_INIT;\n\tret = get_futex_key(uaddr2, fshared, &key2);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.pi_state = NULL;\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/* Prepare to wait on uaddr. */\n\tret = futex_wait_setup(uaddr, val, fshared, &q, &hb);\n\tif (ret)\n\t\tgoto out_key2;\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue_me(hb, &q, to);\n\n\tspin_lock(&hb->lock);\n\tret = handle_early_requeue_pi_wakeup(hb, &q, &key2, to);\n\tspin_unlock(&hb->lock);\n\tif (ret)\n\t\tgoto out_put_keys;\n\n\t/*\n\t * In order for us to be here, we know our q.key == key2, and since\n\t * we took the hb->lock above, we also know that futex_requeue() has\n\t * completed and we no longer have to concern ourselves with a wakeup\n\t * race with the atomic proxy lock acquition by the requeue code.\n\t */\n\n\t/* Check if the requeue code acquired the second futex for us. */\n\tif (!q.rt_waiter) {\n\t\t/*\n\t\t * Got the lock. We might not be the anticipated owner if we\n\t\t * did a lock-steal - fix up the PI-state in that case.\n\t\t */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_state_owner(uaddr2, &q, current,\n\t\t\t\t\t\t   fshared);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t}\n\t} else {\n\t\t/*\n\t\t * We have been woken up by futex_unlock_pi(), a timeout, or a\n\t\t * signal.  futex_unlock_pi() will not destroy the lock_ptr nor\n\t\t * the pi_state.\n\t\t */\n\t\tWARN_ON(!&q.pi_state);\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_finish_proxy_lock(pi_mutex, to, &rt_waiter, 1);\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\n\t\tspin_lock(q.lock_ptr);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_owner(uaddr2, fshared, &q, !ret);\n\t\t/*\n\t\t * If fixup_owner() returned an error, proprogate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\t/* Unqueue and drop the lock. */\n\t\tunqueue_me_pi(&q);\n\t}\n\n\t/*\n\t * If fixup_pi_state_owner() faulted and was unable to handle the\n\t * fault, unlock the rt_mutex and return the fault to userspace.\n\t */\n\tif (ret == -EFAULT) {\n\t\tif (rt_mutex_owner(pi_mutex) == current)\n\t\t\trt_mutex_unlock(pi_mutex);\n\t} else if (ret == -EINTR) {\n\t\t/*\n\t\t * We've already been requeued, but cannot restart by calling\n\t\t * futex_lock_pi() directly. We could restart this syscall, but\n\t\t * it would detect that the user space \"val\" changed and return\n\t\t * -EWOULDBLOCK.  Save the overhead of the restart and return\n\t\t * -EWOULDBLOCK directly.\n\t\t */\n\t\tret = -EWOULDBLOCK;\n\t}\n\nout_put_keys:\n\tput_futex_key(fshared, &q.key);\nout_key2:\n\tput_futex_key(fshared, &key2);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}",
        "code_after_change": "static int futex_wait_requeue_pi(u32 __user *uaddr, int fshared,\n\t\t\t\t u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t\t int clockrt, u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to = NULL;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct rt_mutex *pi_mutex = NULL;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2;\n\tstruct futex_q q;\n\tint res, ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tif (abs_time) {\n\t\tto = &timeout;\n\t\thrtimer_init_on_stack(&to->timer, clockrt ? CLOCK_REALTIME :\n\t\t\t\t      CLOCK_MONOTONIC, HRTIMER_MODE_ABS);\n\t\thrtimer_init_sleeper(to, current);\n\t\thrtimer_set_expires_range_ns(&to->timer, *abs_time,\n\t\t\t\t\t     current->timer_slack_ns);\n\t}\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\tdebug_rt_mutex_init_waiter(&rt_waiter);\n\trt_waiter.task = NULL;\n\n\tkey2 = FUTEX_KEY_INIT;\n\tret = get_futex_key(uaddr2, fshared, &key2);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.pi_state = NULL;\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/*\n\t * Prepare to wait on uaddr. On success, increments q.key (key1) ref\n\t * count.\n\t */\n\tret = futex_wait_setup(uaddr, val, fshared, &q, &hb);\n\tif (ret)\n\t\tgoto out_key2;\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue_me(hb, &q, to);\n\n\tspin_lock(&hb->lock);\n\tret = handle_early_requeue_pi_wakeup(hb, &q, &key2, to);\n\tspin_unlock(&hb->lock);\n\tif (ret)\n\t\tgoto out_put_keys;\n\n\t/*\n\t * In order for us to be here, we know our q.key == key2, and since\n\t * we took the hb->lock above, we also know that futex_requeue() has\n\t * completed and we no longer have to concern ourselves with a wakeup\n\t * race with the atomic proxy lock acquisition by the requeue code. The\n\t * futex_requeue dropped our key1 reference and incremented our key2\n\t * reference count.\n\t */\n\n\t/* Check if the requeue code acquired the second futex for us. */\n\tif (!q.rt_waiter) {\n\t\t/*\n\t\t * Got the lock. We might not be the anticipated owner if we\n\t\t * did a lock-steal - fix up the PI-state in that case.\n\t\t */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_state_owner(uaddr2, &q, current,\n\t\t\t\t\t\t   fshared);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t}\n\t} else {\n\t\t/*\n\t\t * We have been woken up by futex_unlock_pi(), a timeout, or a\n\t\t * signal.  futex_unlock_pi() will not destroy the lock_ptr nor\n\t\t * the pi_state.\n\t\t */\n\t\tWARN_ON(!&q.pi_state);\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_finish_proxy_lock(pi_mutex, to, &rt_waiter, 1);\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\n\t\tspin_lock(q.lock_ptr);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_owner(uaddr2, fshared, &q, !ret);\n\t\t/*\n\t\t * If fixup_owner() returned an error, proprogate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\t/* Unqueue and drop the lock. */\n\t\tunqueue_me_pi(&q);\n\t}\n\n\t/*\n\t * If fixup_pi_state_owner() faulted and was unable to handle the\n\t * fault, unlock the rt_mutex and return the fault to userspace.\n\t */\n\tif (ret == -EFAULT) {\n\t\tif (rt_mutex_owner(pi_mutex) == current)\n\t\t\trt_mutex_unlock(pi_mutex);\n\t} else if (ret == -EINTR) {\n\t\t/*\n\t\t * We've already been requeued, but cannot restart by calling\n\t\t * futex_lock_pi() directly. We could restart this syscall, but\n\t\t * it would detect that the user space \"val\" changed and return\n\t\t * -EWOULDBLOCK.  Save the overhead of the restart and return\n\t\t * -EWOULDBLOCK directly.\n\t\t */\n\t\tret = -EWOULDBLOCK;\n\t}\n\nout_put_keys:\n\tput_futex_key(fshared, &q.key);\nout_key2:\n\tput_futex_key(fshared, &key2);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,7 +39,10 @@\n \tq.rt_waiter = &rt_waiter;\n \tq.requeue_pi_key = &key2;\n \n-\t/* Prepare to wait on uaddr. */\n+\t/*\n+\t * Prepare to wait on uaddr. On success, increments q.key (key1) ref\n+\t * count.\n+\t */\n \tret = futex_wait_setup(uaddr, val, fshared, &q, &hb);\n \tif (ret)\n \t\tgoto out_key2;\n@@ -57,7 +60,9 @@\n \t * In order for us to be here, we know our q.key == key2, and since\n \t * we took the hb->lock above, we also know that futex_requeue() has\n \t * completed and we no longer have to concern ourselves with a wakeup\n-\t * race with the atomic proxy lock acquition by the requeue code.\n+\t * race with the atomic proxy lock acquisition by the requeue code. The\n+\t * futex_requeue dropped our key1 reference and incremented our key2\n+\t * reference count.\n \t */\n \n \t/* Check if the requeue code acquired the second futex for us. */",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * Prepare to wait on uaddr. On success, increments q.key (key1) ref",
                "\t * count.",
                "\t */",
                "\t * race with the atomic proxy lock acquisition by the requeue code. The",
                "\t * futex_requeue dropped our key1 reference and incremented our key2",
                "\t * reference count."
            ],
            "deleted": [
                "\t/* Prepare to wait on uaddr. */",
                "\t * race with the atomic proxy lock acquition by the requeue code."
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The futex_wait function in kernel/futex.c in the Linux kernel before 2.6.37 does not properly maintain a certain reference count during requeue operations, which allows local users to cause a denial of service (use-after-free and system crash) or possibly gain privileges via a crafted application that triggers a zero count.",
        "id": 466
    },
    {
        "cve_id": "CVE-2016-8658",
        "code_before_change": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\n\t\t\tstruct cfg80211_ap_settings *settings)\n{\n\ts32 ie_offset;\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct brcmf_if *ifp = netdev_priv(ndev);\n\tconst struct brcmf_tlv *ssid_ie;\n\tconst struct brcmf_tlv *country_ie;\n\tstruct brcmf_ssid_le ssid_le;\n\ts32 err = -EPERM;\n\tconst struct brcmf_tlv *rsn_ie;\n\tconst struct brcmf_vs_tlv *wpa_ie;\n\tstruct brcmf_join_params join_params;\n\tenum nl80211_iftype dev_role;\n\tstruct brcmf_fil_bss_enable_le bss_enable;\n\tu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\n\tbool mbss;\n\tint is_11d;\n\n\tbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\n\t\t  settings->chandef.chan->hw_value,\n\t\t  settings->chandef.center_freq1, settings->chandef.width,\n\t\t  settings->beacon_interval, settings->dtim_period);\n\tbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\n\t\t  settings->ssid, settings->ssid_len, settings->auth_type,\n\t\t  settings->inactivity_timeout);\n\tdev_role = ifp->vif->wdev.iftype;\n\tmbss = ifp->vif->mbss;\n\n\t/* store current 11d setting */\n\tbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\n\tcountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t      settings->beacon.tail_len,\n\t\t\t\t      WLAN_EID_COUNTRY);\n\tis_11d = country_ie ? 1 : 0;\n\n\tmemset(&ssid_le, 0, sizeof(ssid_le));\n\tif (settings->ssid == NULL || settings->ssid_len == 0) {\n\t\tie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\n\t\tssid_ie = brcmf_parse_tlvs(\n\t\t\t\t(u8 *)&settings->beacon.head[ie_offset],\n\t\t\t\tsettings->beacon.head_len - ie_offset,\n\t\t\t\tWLAN_EID_SSID);\n\t\tif (!ssid_ie)\n\t\t\treturn -EINVAL;\n\n\t\tmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\n\t\tssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\n\t\tbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n\t} else {\n\t\tmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\n\t\tssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n\t}\n\n\tif (!mbss) {\n\t\tbrcmf_set_mpc(ifp, 0);\n\t\tbrcmf_configure_arp_nd_offload(ifp, false);\n\t}\n\n\t/* find the RSN_IE */\n\trsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len, WLAN_EID_RSN);\n\n\t/* find the WPA_IE */\n\twpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len);\n\n\tif ((wpa_ie != NULL || rsn_ie != NULL)) {\n\t\tbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\n\t\tif (wpa_ie != NULL) {\n\t\t\t/* WPA IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, wpa_ie, false);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t} else {\n\t\t\tstruct brcmf_vs_tlv *tmp_ie;\n\n\t\t\ttmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\n\n\t\t\t/* RSN IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, tmp_ie, true);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t}\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\n\t\tbrcmf_configure_opensecurity(ifp);\n\t}\n\n\tbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\n\n\t/* Parameters shared by all radio interfaces */\n\tif (!mbss) {\n\t\tif (is_11d != ifp->vif->is_11d) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\n\t\t\t\t\t\t    is_11d);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->beacon_interval) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\n\t\t\t\t\t\t    settings->beacon_interval);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\n\t\t\t\t\t  err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->dtim_period) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\n\t\t\t\t\t\t    settings->dtim_period);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif ((dev_role == NL80211_IFTYPE_AP) &&\n\t\t    ((ifp->ifidx == 0) ||\n\t\t     !brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n\t\t}\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET INFRA error %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\n\t\t/* Multiple-BSS should use same 11d configuration */\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/* Interface specific setup */\n\tif (dev_role == NL80211_IFTYPE_AP) {\n\t\tif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting AP mode failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tif (!mbss) {\n\t\t\t/* Firmware 10.x requires setting channel after enabling\n\t\t\t * AP and before bringing interface up.\n\t\t\t */\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t\t  chanspec, err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\t/* On DOWN the firmware removes the WEP keys, reconfigure\n\t\t * them if they were set.\n\t\t */\n\t\tbrcmf_cfg80211_reconfigure_wep(ifp);\n\n\t\tmemset(&join_params, 0, sizeof(join_params));\n\t\t/* join parameters starts with ssid */\n\t\tmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\n\t\t/* create softap */\n\t\terr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n\t\t\t\t\t     &join_params, sizeof(join_params));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET SSID error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (settings->hidden_ssid) {\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\n\t\t\tif (err) {\n\t\t\t\tbrcmf_err(\"closednet error (%d)\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n\t} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\n\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t  chanspec, err);\n\t\t\tgoto exit;\n\t\t}\n\t\terr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\n\t\t\t\t\t\tsizeof(ssid_le));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting ssid failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\n\t\tbss_enable.enable = cpu_to_le32(1);\n\t\terr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\n\t\t\t\t\t       sizeof(bss_enable));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"bss_enable config failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n\t} else {\n\t\tWARN_ON(1);\n\t}\n\n\tset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\n\tbrcmf_net_setcarrier(ifp, true);\n\nexit:\n\tif ((err) && (!mbss)) {\n\t\tbrcmf_set_mpc(ifp, 1);\n\t\tbrcmf_configure_arp_nd_offload(ifp, true);\n\t}\n\treturn err;\n}",
        "code_after_change": "static s32\nbrcmf_cfg80211_start_ap(struct wiphy *wiphy, struct net_device *ndev,\n\t\t\tstruct cfg80211_ap_settings *settings)\n{\n\ts32 ie_offset;\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct brcmf_if *ifp = netdev_priv(ndev);\n\tconst struct brcmf_tlv *ssid_ie;\n\tconst struct brcmf_tlv *country_ie;\n\tstruct brcmf_ssid_le ssid_le;\n\ts32 err = -EPERM;\n\tconst struct brcmf_tlv *rsn_ie;\n\tconst struct brcmf_vs_tlv *wpa_ie;\n\tstruct brcmf_join_params join_params;\n\tenum nl80211_iftype dev_role;\n\tstruct brcmf_fil_bss_enable_le bss_enable;\n\tu16 chanspec = chandef_to_chanspec(&cfg->d11inf, &settings->chandef);\n\tbool mbss;\n\tint is_11d;\n\n\tbrcmf_dbg(TRACE, \"ctrlchn=%d, center=%d, bw=%d, beacon_interval=%d, dtim_period=%d,\\n\",\n\t\t  settings->chandef.chan->hw_value,\n\t\t  settings->chandef.center_freq1, settings->chandef.width,\n\t\t  settings->beacon_interval, settings->dtim_period);\n\tbrcmf_dbg(TRACE, \"ssid=%s(%zu), auth_type=%d, inactivity_timeout=%d\\n\",\n\t\t  settings->ssid, settings->ssid_len, settings->auth_type,\n\t\t  settings->inactivity_timeout);\n\tdev_role = ifp->vif->wdev.iftype;\n\tmbss = ifp->vif->mbss;\n\n\t/* store current 11d setting */\n\tbrcmf_fil_cmd_int_get(ifp, BRCMF_C_GET_REGULATORY, &ifp->vif->is_11d);\n\tcountry_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t      settings->beacon.tail_len,\n\t\t\t\t      WLAN_EID_COUNTRY);\n\tis_11d = country_ie ? 1 : 0;\n\n\tmemset(&ssid_le, 0, sizeof(ssid_le));\n\tif (settings->ssid == NULL || settings->ssid_len == 0) {\n\t\tie_offset = DOT11_MGMT_HDR_LEN + DOT11_BCN_PRB_FIXED_LEN;\n\t\tssid_ie = brcmf_parse_tlvs(\n\t\t\t\t(u8 *)&settings->beacon.head[ie_offset],\n\t\t\t\tsettings->beacon.head_len - ie_offset,\n\t\t\t\tWLAN_EID_SSID);\n\t\tif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)\n\t\t\treturn -EINVAL;\n\n\t\tmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);\n\t\tssid_le.SSID_len = cpu_to_le32(ssid_ie->len);\n\t\tbrcmf_dbg(TRACE, \"SSID is (%s) in Head\\n\", ssid_le.SSID);\n\t} else {\n\t\tmemcpy(ssid_le.SSID, settings->ssid, settings->ssid_len);\n\t\tssid_le.SSID_len = cpu_to_le32((u32)settings->ssid_len);\n\t}\n\n\tif (!mbss) {\n\t\tbrcmf_set_mpc(ifp, 0);\n\t\tbrcmf_configure_arp_nd_offload(ifp, false);\n\t}\n\n\t/* find the RSN_IE */\n\trsn_ie = brcmf_parse_tlvs((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len, WLAN_EID_RSN);\n\n\t/* find the WPA_IE */\n\twpa_ie = brcmf_find_wpaie((u8 *)settings->beacon.tail,\n\t\t\t\t  settings->beacon.tail_len);\n\n\tif ((wpa_ie != NULL || rsn_ie != NULL)) {\n\t\tbrcmf_dbg(TRACE, \"WPA(2) IE is found\\n\");\n\t\tif (wpa_ie != NULL) {\n\t\t\t/* WPA IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, wpa_ie, false);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t} else {\n\t\t\tstruct brcmf_vs_tlv *tmp_ie;\n\n\t\t\ttmp_ie = (struct brcmf_vs_tlv *)rsn_ie;\n\n\t\t\t/* RSN IE */\n\t\t\terr = brcmf_configure_wpaie(ifp, tmp_ie, true);\n\t\t\tif (err < 0)\n\t\t\t\tgoto exit;\n\t\t}\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"No WPA(2) IEs found\\n\");\n\t\tbrcmf_configure_opensecurity(ifp);\n\t}\n\n\tbrcmf_config_ap_mgmt_ie(ifp->vif, &settings->beacon);\n\n\t/* Parameters shared by all radio interfaces */\n\tif (!mbss) {\n\t\tif (is_11d != ifp->vif->is_11d) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_REGULATORY,\n\t\t\t\t\t\t    is_11d);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Regulatory Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->beacon_interval) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_BCNPRD,\n\t\t\t\t\t\t    settings->beacon_interval);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Beacon Interval Set Error, %d\\n\",\n\t\t\t\t\t  err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\tif (settings->dtim_period) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_DTIMPRD,\n\t\t\t\t\t\t    settings->dtim_period);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"DTIM Interval Set Error, %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif ((dev_role == NL80211_IFTYPE_AP) &&\n\t\t    ((ifp->ifidx == 0) ||\n\t\t     !brcmf_feat_is_enabled(ifp, BRCMF_FEAT_RSDB))) {\n\t\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_DOWN, 1);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"BRCMF_C_DOWN error %d\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"apsta\", 0);\n\t\t}\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_INFRA, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET INFRA error %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t} else if (WARN_ON(is_11d != ifp->vif->is_11d)) {\n\t\t/* Multiple-BSS should use same 11d configuration */\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/* Interface specific setup */\n\tif (dev_role == NL80211_IFTYPE_AP) {\n\t\tif ((brcmf_feat_is_enabled(ifp, BRCMF_FEAT_MBSS)) && (!mbss))\n\t\t\tbrcmf_fil_iovar_int_set(ifp, \"mbss\", 1);\n\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_SET_AP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting AP mode failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tif (!mbss) {\n\t\t\t/* Firmware 10.x requires setting channel after enabling\n\t\t\t * AP and before bringing interface up.\n\t\t\t */\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\t\tif (err < 0) {\n\t\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t\t  chanspec, err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\t\terr = brcmf_fil_cmd_int_set(ifp, BRCMF_C_UP, 1);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"BRCMF_C_UP error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\t/* On DOWN the firmware removes the WEP keys, reconfigure\n\t\t * them if they were set.\n\t\t */\n\t\tbrcmf_cfg80211_reconfigure_wep(ifp);\n\n\t\tmemset(&join_params, 0, sizeof(join_params));\n\t\t/* join parameters starts with ssid */\n\t\tmemcpy(&join_params.ssid_le, &ssid_le, sizeof(ssid_le));\n\t\t/* create softap */\n\t\terr = brcmf_fil_cmd_data_set(ifp, BRCMF_C_SET_SSID,\n\t\t\t\t\t     &join_params, sizeof(join_params));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"SET SSID error (%d)\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tif (settings->hidden_ssid) {\n\t\t\terr = brcmf_fil_iovar_int_set(ifp, \"closednet\", 1);\n\t\t\tif (err) {\n\t\t\t\tbrcmf_err(\"closednet error (%d)\\n\", err);\n\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"AP mode configuration complete\\n\");\n\t} else if (dev_role == NL80211_IFTYPE_P2P_GO) {\n\t\terr = brcmf_fil_iovar_int_set(ifp, \"chanspec\", chanspec);\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"Set Channel failed: chspec=%d, %d\\n\",\n\t\t\t\t  chanspec, err);\n\t\t\tgoto exit;\n\t\t}\n\t\terr = brcmf_fil_bsscfg_data_set(ifp, \"ssid\", &ssid_le,\n\t\t\t\t\t\tsizeof(ssid_le));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"setting ssid failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\t\tbss_enable.bsscfgidx = cpu_to_le32(ifp->bsscfgidx);\n\t\tbss_enable.enable = cpu_to_le32(1);\n\t\terr = brcmf_fil_iovar_data_set(ifp, \"bss\", &bss_enable,\n\t\t\t\t\t       sizeof(bss_enable));\n\t\tif (err < 0) {\n\t\t\tbrcmf_err(\"bss_enable config failed %d\\n\", err);\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbrcmf_dbg(TRACE, \"GO mode configuration complete\\n\");\n\t} else {\n\t\tWARN_ON(1);\n\t}\n\n\tset_bit(BRCMF_VIF_STATUS_AP_CREATED, &ifp->vif->sme_state);\n\tbrcmf_net_setcarrier(ifp, true);\n\nexit:\n\tif ((err) && (!mbss)) {\n\t\tbrcmf_set_mpc(ifp, 1);\n\t\tbrcmf_configure_arp_nd_offload(ifp, true);\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,7 +42,7 @@\n \t\t\t\t(u8 *)&settings->beacon.head[ie_offset],\n \t\t\t\tsettings->beacon.head_len - ie_offset,\n \t\t\t\tWLAN_EID_SSID);\n-\t\tif (!ssid_ie)\n+\t\tif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)\n \t\t\treturn -EINVAL;\n \n \t\tmemcpy(ssid_le.SSID, ssid_ie->data, ssid_ie->len);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!ssid_ie || ssid_ie->len > IEEE80211_MAX_SSID_LEN)"
            ],
            "deleted": [
                "\t\tif (!ssid_ie)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Stack-based buffer overflow in the brcmf_cfg80211_start_ap function in drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c in the Linux kernel before 4.7.5 allows local users to cause a denial of service (system crash) or possibly have unspecified other impact via a long SSID Information Element in a command to a Netlink socket.",
        "id": 1133
    },
    {
        "cve_id": "CVE-2022-3649",
        "code_before_change": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\n\tstruct super_block *sb = dir->i_sb;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct inode *inode;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_root *root;\n\tint err = -ENOMEM;\n\tino_t ino;\n\n\tinode = new_inode(sb);\n\tif (unlikely(!inode))\n\t\tgoto failed;\n\n\tmapping_set_gfp_mask(inode->i_mapping,\n\t\t\t   mapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\n\n\troot = NILFS_I(dir)->i_root;\n\tii = NILFS_I(inode);\n\tii->i_state = BIT(NILFS_I_NEW);\n\tii->i_root = root;\n\n\terr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);\n\tif (unlikely(err))\n\t\tgoto failed_ifile_create_inode;\n\t/* reference count of i_bh inherits from nilfs_mdt_read_block() */\n\n\tatomic64_inc(&root->inodes_count);\n\tinode_init_owner(&init_user_ns, inode, dir, mode);\n\tinode->i_ino = ino;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\n\tif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\n\t\terr = nilfs_bmap_read(ii->i_bmap, NULL);\n\t\tif (err < 0)\n\t\t\tgoto failed_after_creation;\n\n\t\tset_bit(NILFS_I_BMAP, &ii->i_state);\n\t\t/* No lock is needed; iget() ensures it. */\n\t}\n\n\tii->i_flags = nilfs_mask_flags(\n\t\tmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\n\n\t/* ii->i_file_acl = 0; */\n\t/* ii->i_dir_acl = 0; */\n\tii->i_dir_start_lookup = 0;\n\tnilfs_set_inode_flags(inode);\n\tspin_lock(&nilfs->ns_next_gen_lock);\n\tinode->i_generation = nilfs->ns_next_generation++;\n\tspin_unlock(&nilfs->ns_next_gen_lock);\n\tif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\n\t\terr = -EIO;\n\t\tgoto failed_after_creation;\n\t}\n\n\terr = nilfs_init_acl(inode, dir);\n\tif (unlikely(err))\n\t\t/*\n\t\t * Never occur.  When supporting nilfs_init_acl(),\n\t\t * proper cancellation of above jobs should be considered.\n\t\t */\n\t\tgoto failed_after_creation;\n\n\treturn inode;\n\n failed_after_creation:\n\tclear_nlink(inode);\n\tif (inode->i_state & I_NEW)\n\t\tunlock_new_inode(inode);\n\tiput(inode);  /*\n\t\t       * raw_inode will be deleted through\n\t\t       * nilfs_evict_inode().\n\t\t       */\n\tgoto failed;\n\n failed_ifile_create_inode:\n\tmake_bad_inode(inode);\n\tiput(inode);\n failed:\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "struct inode *nilfs_new_inode(struct inode *dir, umode_t mode)\n{\n\tstruct super_block *sb = dir->i_sb;\n\tstruct the_nilfs *nilfs = sb->s_fs_info;\n\tstruct inode *inode;\n\tstruct nilfs_inode_info *ii;\n\tstruct nilfs_root *root;\n\tstruct buffer_head *bh;\n\tint err = -ENOMEM;\n\tino_t ino;\n\n\tinode = new_inode(sb);\n\tif (unlikely(!inode))\n\t\tgoto failed;\n\n\tmapping_set_gfp_mask(inode->i_mapping,\n\t\t\t   mapping_gfp_constraint(inode->i_mapping, ~__GFP_FS));\n\n\troot = NILFS_I(dir)->i_root;\n\tii = NILFS_I(inode);\n\tii->i_state = BIT(NILFS_I_NEW);\n\tii->i_root = root;\n\n\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n\tif (unlikely(err))\n\t\tgoto failed_ifile_create_inode;\n\t/* reference count of i_bh inherits from nilfs_mdt_read_block() */\n\n\tif (unlikely(ino < NILFS_USER_INO)) {\n\t\tnilfs_warn(sb,\n\t\t\t   \"inode bitmap is inconsistent for reserved inodes\");\n\t\tdo {\n\t\t\tbrelse(bh);\n\t\t\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n\t\t\tif (unlikely(err))\n\t\t\t\tgoto failed_ifile_create_inode;\n\t\t} while (ino < NILFS_USER_INO);\n\n\t\tnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");\n\t}\n\tii->i_bh = bh;\n\n\tatomic64_inc(&root->inodes_count);\n\tinode_init_owner(&init_user_ns, inode, dir, mode);\n\tinode->i_ino = ino;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\n\tif (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) {\n\t\terr = nilfs_bmap_read(ii->i_bmap, NULL);\n\t\tif (err < 0)\n\t\t\tgoto failed_after_creation;\n\n\t\tset_bit(NILFS_I_BMAP, &ii->i_state);\n\t\t/* No lock is needed; iget() ensures it. */\n\t}\n\n\tii->i_flags = nilfs_mask_flags(\n\t\tmode, NILFS_I(dir)->i_flags & NILFS_FL_INHERITED);\n\n\t/* ii->i_file_acl = 0; */\n\t/* ii->i_dir_acl = 0; */\n\tii->i_dir_start_lookup = 0;\n\tnilfs_set_inode_flags(inode);\n\tspin_lock(&nilfs->ns_next_gen_lock);\n\tinode->i_generation = nilfs->ns_next_generation++;\n\tspin_unlock(&nilfs->ns_next_gen_lock);\n\tif (nilfs_insert_inode_locked(inode, root, ino) < 0) {\n\t\terr = -EIO;\n\t\tgoto failed_after_creation;\n\t}\n\n\terr = nilfs_init_acl(inode, dir);\n\tif (unlikely(err))\n\t\t/*\n\t\t * Never occur.  When supporting nilfs_init_acl(),\n\t\t * proper cancellation of above jobs should be considered.\n\t\t */\n\t\tgoto failed_after_creation;\n\n\treturn inode;\n\n failed_after_creation:\n\tclear_nlink(inode);\n\tif (inode->i_state & I_NEW)\n\t\tunlock_new_inode(inode);\n\tiput(inode);  /*\n\t\t       * raw_inode will be deleted through\n\t\t       * nilfs_evict_inode().\n\t\t       */\n\tgoto failed;\n\n failed_ifile_create_inode:\n\tmake_bad_inode(inode);\n\tiput(inode);\n failed:\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tstruct inode *inode;\n \tstruct nilfs_inode_info *ii;\n \tstruct nilfs_root *root;\n+\tstruct buffer_head *bh;\n \tint err = -ENOMEM;\n \tino_t ino;\n \n@@ -20,10 +21,24 @@\n \tii->i_state = BIT(NILFS_I_NEW);\n \tii->i_root = root;\n \n-\terr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);\n+\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n \tif (unlikely(err))\n \t\tgoto failed_ifile_create_inode;\n \t/* reference count of i_bh inherits from nilfs_mdt_read_block() */\n+\n+\tif (unlikely(ino < NILFS_USER_INO)) {\n+\t\tnilfs_warn(sb,\n+\t\t\t   \"inode bitmap is inconsistent for reserved inodes\");\n+\t\tdo {\n+\t\t\tbrelse(bh);\n+\t\t\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);\n+\t\t\tif (unlikely(err))\n+\t\t\t\tgoto failed_ifile_create_inode;\n+\t\t} while (ino < NILFS_USER_INO);\n+\n+\t\tnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");\n+\t}\n+\tii->i_bh = bh;\n \n \tatomic64_inc(&root->inodes_count);\n \tinode_init_owner(&init_user_ns, inode, dir, mode);",
        "function_modified_lines": {
            "added": [
                "\tstruct buffer_head *bh;",
                "\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);",
                "",
                "\tif (unlikely(ino < NILFS_USER_INO)) {",
                "\t\tnilfs_warn(sb,",
                "\t\t\t   \"inode bitmap is inconsistent for reserved inodes\");",
                "\t\tdo {",
                "\t\t\tbrelse(bh);",
                "\t\t\terr = nilfs_ifile_create_inode(root->ifile, &ino, &bh);",
                "\t\t\tif (unlikely(err))",
                "\t\t\t\tgoto failed_ifile_create_inode;",
                "\t\t} while (ino < NILFS_USER_INO);",
                "",
                "\t\tnilfs_info(sb, \"repaired inode bitmap for reserved inodes\");",
                "\t}",
                "\tii->i_bh = bh;"
            ],
            "deleted": [
                "\terr = nilfs_ifile_create_inode(root->ifile, &ino, &ii->i_bh);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel. It has been classified as problematic. Affected is the function nilfs_new_inode of the file fs/nilfs2/inode.c of the component BPF. The manipulation leads to use after free. It is possible to launch the attack remotely. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211992.",
        "id": 3676
    },
    {
        "cve_id": "CVE-2016-10764",
        "code_before_change": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\n\tstruct platform_device *pdev = cqspi->pdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct cqspi_flash_pdata *f_pdata;\n\tstruct spi_nor *nor;\n\tstruct mtd_info *mtd;\n\tunsigned int cs;\n\tint i, ret;\n\n\t/* Get flash device data */\n\tfor_each_available_child_of_node(dev->of_node, np) {\n\t\tif (of_property_read_u32(np, \"reg\", &cs)) {\n\t\t\tdev_err(dev, \"Couldn't determine chip select.\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (cs > CQSPI_MAX_CHIPSELECT) {\n\t\t\tdev_err(dev, \"Chip select %d out of range.\\n\", cs);\n\t\t\tgoto err;\n\t\t}\n\n\t\tf_pdata = &cqspi->f_pdata[cs];\n\t\tf_pdata->cqspi = cqspi;\n\t\tf_pdata->cs = cs;\n\n\t\tret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tnor = &f_pdata->nor;\n\t\tmtd = &nor->mtd;\n\n\t\tmtd->priv = nor;\n\n\t\tnor->dev = dev;\n\t\tspi_nor_set_flash_node(nor, np);\n\t\tnor->priv = f_pdata;\n\n\t\tnor->read_reg = cqspi_read_reg;\n\t\tnor->write_reg = cqspi_write_reg;\n\t\tnor->read = cqspi_read;\n\t\tnor->write = cqspi_write;\n\t\tnor->erase = cqspi_erase;\n\t\tnor->prepare = cqspi_prep;\n\t\tnor->unprepare = cqspi_unprep;\n\n\t\tmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\n\t\t\t\t\t   dev_name(dev), cs);\n\t\tif (!mtd->name) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = mtd_device_register(mtd, NULL, 0);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tf_pdata->registered = true;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\n\t\tif (cqspi->f_pdata[i].registered)\n\t\t\tmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\n\treturn ret;\n}",
        "code_after_change": "static int cqspi_setup_flash(struct cqspi_st *cqspi, struct device_node *np)\n{\n\tstruct platform_device *pdev = cqspi->pdev;\n\tstruct device *dev = &pdev->dev;\n\tstruct cqspi_flash_pdata *f_pdata;\n\tstruct spi_nor *nor;\n\tstruct mtd_info *mtd;\n\tunsigned int cs;\n\tint i, ret;\n\n\t/* Get flash device data */\n\tfor_each_available_child_of_node(dev->of_node, np) {\n\t\tif (of_property_read_u32(np, \"reg\", &cs)) {\n\t\t\tdev_err(dev, \"Couldn't determine chip select.\\n\");\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (cs >= CQSPI_MAX_CHIPSELECT) {\n\t\t\tdev_err(dev, \"Chip select %d out of range.\\n\", cs);\n\t\t\tgoto err;\n\t\t}\n\n\t\tf_pdata = &cqspi->f_pdata[cs];\n\t\tf_pdata->cqspi = cqspi;\n\t\tf_pdata->cs = cs;\n\n\t\tret = cqspi_of_get_flash_pdata(pdev, f_pdata, np);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tnor = &f_pdata->nor;\n\t\tmtd = &nor->mtd;\n\n\t\tmtd->priv = nor;\n\n\t\tnor->dev = dev;\n\t\tspi_nor_set_flash_node(nor, np);\n\t\tnor->priv = f_pdata;\n\n\t\tnor->read_reg = cqspi_read_reg;\n\t\tnor->write_reg = cqspi_write_reg;\n\t\tnor->read = cqspi_read;\n\t\tnor->write = cqspi_write;\n\t\tnor->erase = cqspi_erase;\n\t\tnor->prepare = cqspi_prep;\n\t\tnor->unprepare = cqspi_unprep;\n\n\t\tmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"%s.%d\",\n\t\t\t\t\t   dev_name(dev), cs);\n\t\tif (!mtd->name) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tret = mtd_device_register(mtd, NULL, 0);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tf_pdata->registered = true;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (i = 0; i < CQSPI_MAX_CHIPSELECT; i++)\n\t\tif (cqspi->f_pdata[i].registered)\n\t\t\tmtd_device_unregister(&cqspi->f_pdata[i].nor.mtd);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,7 +15,7 @@\n \t\t\tgoto err;\n \t\t}\n \n-\t\tif (cs > CQSPI_MAX_CHIPSELECT) {\n+\t\tif (cs >= CQSPI_MAX_CHIPSELECT) {\n \t\t\tdev_err(dev, \"Chip select %d out of range.\\n\", cs);\n \t\t\tgoto err;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (cs >= CQSPI_MAX_CHIPSELECT) {"
            ],
            "deleted": [
                "\t\tif (cs > CQSPI_MAX_CHIPSELECT) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.9.6, there is an off by one in the drivers/mtd/spi-nor/cadence-quadspi.c cqspi_setup_flash() function. There are CQSPI_MAX_CHIPSELECT elements in the ->f_pdata array so the \">\" should be \">=\" instead.",
        "id": 906
    },
    {
        "cve_id": "CVE-2011-4098",
        "code_before_change": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\n\t\t\t   struct buffer_head *bh_map, struct metapath *mp,\n\t\t\t   const unsigned int sheight,\n\t\t\t   const unsigned int height,\n\t\t\t   const unsigned int maxlen)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct buffer_head *dibh = mp->mp_bh[0];\n\tu64 bn, dblock = 0;\n\tunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\n\tunsigned dblks = 0;\n\tunsigned ptrs_per_blk;\n\tconst unsigned end_of_metadata = height - 1;\n\tint eob = 0;\n\tenum alloc_state state;\n\t__be64 *ptr;\n\t__be64 zero_bn = 0;\n\n\tBUG_ON(sheight < 1);\n\tBUG_ON(dibh == NULL);\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (height == sheight) {\n\t\tstruct buffer_head *bh;\n\t\t/* Bottom indirect block exists, find unalloced extent size */\n\t\tptr = metapointer(end_of_metadata, mp);\n\t\tbh = mp->mp_bh[end_of_metadata];\n\t\tdblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n\t\t\t\t\t   &eob);\n\t\tBUG_ON(dblks < 1);\n\t\tstate = ALLOC_DATA;\n\t} else {\n\t\t/* Need to allocate indirect blocks */\n\t\tptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\n\t\tdblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\n\t\tif (height == ip->i_height) {\n\t\t\t/* Writing into existing tree, extend tree down */\n\t\t\tiblks = height - sheight;\n\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t} else {\n\t\t\t/* Building up tree height */\n\t\t\tstate = ALLOC_GROW_HEIGHT;\n\t\t\tiblks = height - ip->i_height;\n\t\t\tbranch_start = metapath_branch_start(mp);\n\t\t\tiblks += (height - branch_start);\n\t\t}\n\t}\n\n\t/* start of the second part of the function (state machine) */\n\n\tblks = dblks + iblks;\n\ti = sheight;\n\tdo {\n\t\tint error;\n\t\tn = blks - alloced;\n\t\terror = gfs2_alloc_block(ip, &bn, &n);\n\t\tif (error)\n\t\t\treturn error;\n\t\talloced += n;\n\t\tif (state != ALLOC_DATA || gfs2_is_jdata(ip))\n\t\t\tgfs2_trans_add_unrevoke(sdp, bn, n);\n\t\tswitch (state) {\n\t\t/* Growing height of tree */\n\t\tcase ALLOC_GROW_HEIGHT:\n\t\t\tif (i == 1) {\n\t\t\t\tptr = (__be64 *)(dibh->b_data +\n\t\t\t\t\t\t sizeof(struct gfs2_dinode));\n\t\t\t\tzero_bn = *ptr;\n\t\t\t}\n\t\t\tfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\n\t\t\tif (i - 1 == height - ip->i_height) {\n\t\t\t\ti--;\n\t\t\t\tgfs2_buffer_copy_tail(mp->mp_bh[i],\n\t\t\t\t\t\tsizeof(struct gfs2_meta_header),\n\t\t\t\t\t\tdibh, sizeof(struct gfs2_dinode));\n\t\t\t\tgfs2_buffer_clear_tail(dibh,\n\t\t\t\t\t\tsizeof(struct gfs2_dinode) +\n\t\t\t\t\t\tsizeof(__be64));\n\t\t\t\tptr = (__be64 *)(mp->mp_bh[i]->b_data +\n\t\t\t\t\tsizeof(struct gfs2_meta_header));\n\t\t\t\t*ptr = zero_bn;\n\t\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t\t\tfor(i = branch_start; i < height; i++) {\n\t\t\t\t\tif (mp->mp_bh[i] == NULL)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tbrelse(mp->mp_bh[i]);\n\t\t\t\t\tmp->mp_bh[i] = NULL;\n\t\t\t\t}\n\t\t\t\ti = branch_start;\n\t\t\t}\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Branching from existing tree */\n\t\tcase ALLOC_GROW_DEPTH:\n\t\t\tif (i > 1 && i < height)\n\t\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\n\t\t\tfor (; i < height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i,\n\t\t\t\t\t\t   mp->mp_list[i-1], bn++);\n\t\t\tif (i == height)\n\t\t\t\tstate = ALLOC_DATA;\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Tree complete, adding data blocks */\n\t\tcase ALLOC_DATA:\n\t\t\tBUG_ON(n > dblks);\n\t\t\tBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\n\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\n\t\t\tdblks = n;\n\t\t\tptr = metapointer(end_of_metadata, mp);\n\t\t\tdblock = bn;\n\t\t\twhile (n-- > 0)\n\t\t\t\t*ptr++ = cpu_to_be64(bn++);\n\t\t\tbreak;\n\t\t}\n\t} while ((state != ALLOC_DATA) || !dblock);\n\n\tip->i_height = height;\n\tgfs2_add_inode_blocks(&ip->i_inode, alloced);\n\tgfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\n\tmap_bh(bh_map, inode->i_sb, dblock);\n\tbh_map->b_size = dblks << inode->i_blkbits;\n\tset_buffer_new(bh_map);\n\treturn 0;\n}",
        "code_after_change": "static int gfs2_bmap_alloc(struct inode *inode, const sector_t lblock,\n\t\t\t   struct buffer_head *bh_map, struct metapath *mp,\n\t\t\t   const unsigned int sheight,\n\t\t\t   const unsigned int height,\n\t\t\t   const unsigned int maxlen)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct super_block *sb = sdp->sd_vfs;\n\tstruct buffer_head *dibh = mp->mp_bh[0];\n\tu64 bn, dblock = 0;\n\tunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\n\tunsigned dblks = 0;\n\tunsigned ptrs_per_blk;\n\tconst unsigned end_of_metadata = height - 1;\n\tint ret;\n\tint eob = 0;\n\tenum alloc_state state;\n\t__be64 *ptr;\n\t__be64 zero_bn = 0;\n\n\tBUG_ON(sheight < 1);\n\tBUG_ON(dibh == NULL);\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (height == sheight) {\n\t\tstruct buffer_head *bh;\n\t\t/* Bottom indirect block exists, find unalloced extent size */\n\t\tptr = metapointer(end_of_metadata, mp);\n\t\tbh = mp->mp_bh[end_of_metadata];\n\t\tdblks = gfs2_extent_length(bh->b_data, bh->b_size, ptr, maxlen,\n\t\t\t\t\t   &eob);\n\t\tBUG_ON(dblks < 1);\n\t\tstate = ALLOC_DATA;\n\t} else {\n\t\t/* Need to allocate indirect blocks */\n\t\tptrs_per_blk = height > 1 ? sdp->sd_inptrs : sdp->sd_diptrs;\n\t\tdblks = min(maxlen, ptrs_per_blk - mp->mp_list[end_of_metadata]);\n\t\tif (height == ip->i_height) {\n\t\t\t/* Writing into existing tree, extend tree down */\n\t\t\tiblks = height - sheight;\n\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t} else {\n\t\t\t/* Building up tree height */\n\t\t\tstate = ALLOC_GROW_HEIGHT;\n\t\t\tiblks = height - ip->i_height;\n\t\t\tbranch_start = metapath_branch_start(mp);\n\t\t\tiblks += (height - branch_start);\n\t\t}\n\t}\n\n\t/* start of the second part of the function (state machine) */\n\n\tblks = dblks + iblks;\n\ti = sheight;\n\tdo {\n\t\tint error;\n\t\tn = blks - alloced;\n\t\terror = gfs2_alloc_block(ip, &bn, &n);\n\t\tif (error)\n\t\t\treturn error;\n\t\talloced += n;\n\t\tif (state != ALLOC_DATA || gfs2_is_jdata(ip))\n\t\t\tgfs2_trans_add_unrevoke(sdp, bn, n);\n\t\tswitch (state) {\n\t\t/* Growing height of tree */\n\t\tcase ALLOC_GROW_HEIGHT:\n\t\t\tif (i == 1) {\n\t\t\t\tptr = (__be64 *)(dibh->b_data +\n\t\t\t\t\t\t sizeof(struct gfs2_dinode));\n\t\t\t\tzero_bn = *ptr;\n\t\t\t}\n\t\t\tfor (; i - 1 < height - ip->i_height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i, 0, bn++);\n\t\t\tif (i - 1 == height - ip->i_height) {\n\t\t\t\ti--;\n\t\t\t\tgfs2_buffer_copy_tail(mp->mp_bh[i],\n\t\t\t\t\t\tsizeof(struct gfs2_meta_header),\n\t\t\t\t\t\tdibh, sizeof(struct gfs2_dinode));\n\t\t\t\tgfs2_buffer_clear_tail(dibh,\n\t\t\t\t\t\tsizeof(struct gfs2_dinode) +\n\t\t\t\t\t\tsizeof(__be64));\n\t\t\t\tptr = (__be64 *)(mp->mp_bh[i]->b_data +\n\t\t\t\t\tsizeof(struct gfs2_meta_header));\n\t\t\t\t*ptr = zero_bn;\n\t\t\t\tstate = ALLOC_GROW_DEPTH;\n\t\t\t\tfor(i = branch_start; i < height; i++) {\n\t\t\t\t\tif (mp->mp_bh[i] == NULL)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tbrelse(mp->mp_bh[i]);\n\t\t\t\t\tmp->mp_bh[i] = NULL;\n\t\t\t\t}\n\t\t\t\ti = branch_start;\n\t\t\t}\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Branching from existing tree */\n\t\tcase ALLOC_GROW_DEPTH:\n\t\t\tif (i > 1 && i < height)\n\t\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[i-1], 1);\n\t\t\tfor (; i < height && n > 0; i++, n--)\n\t\t\t\tgfs2_indirect_init(mp, ip->i_gl, i,\n\t\t\t\t\t\t   mp->mp_list[i-1], bn++);\n\t\t\tif (i == height)\n\t\t\t\tstate = ALLOC_DATA;\n\t\t\tif (n == 0)\n\t\t\t\tbreak;\n\t\t/* Tree complete, adding data blocks */\n\t\tcase ALLOC_DATA:\n\t\t\tBUG_ON(n > dblks);\n\t\t\tBUG_ON(mp->mp_bh[end_of_metadata] == NULL);\n\t\t\tgfs2_trans_add_bh(ip->i_gl, mp->mp_bh[end_of_metadata], 1);\n\t\t\tdblks = n;\n\t\t\tptr = metapointer(end_of_metadata, mp);\n\t\t\tdblock = bn;\n\t\t\twhile (n-- > 0)\n\t\t\t\t*ptr++ = cpu_to_be64(bn++);\n\t\t\tif (buffer_zeronew(bh_map)) {\n\t\t\t\tret = sb_issue_zeroout(sb, dblock, dblks,\n\t\t\t\t\t\t       GFP_NOFS);\n\t\t\t\tif (ret) {\n\t\t\t\t\tfs_err(sdp,\n\t\t\t\t\t       \"Failed to zero data buffers\\n\");\n\t\t\t\t\tclear_buffer_zeronew(bh_map);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t} while ((state != ALLOC_DATA) || !dblock);\n\n\tip->i_height = height;\n\tgfs2_add_inode_blocks(&ip->i_inode, alloced);\n\tgfs2_dinode_out(ip, mp->mp_bh[0]->b_data);\n\tmap_bh(bh_map, inode->i_sb, dblock);\n\tbh_map->b_size = dblks << inode->i_blkbits;\n\tset_buffer_new(bh_map);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,12 +6,14 @@\n {\n \tstruct gfs2_inode *ip = GFS2_I(inode);\n \tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n+\tstruct super_block *sb = sdp->sd_vfs;\n \tstruct buffer_head *dibh = mp->mp_bh[0];\n \tu64 bn, dblock = 0;\n \tunsigned n, i, blks, alloced = 0, iblks = 0, branch_start = 0;\n \tunsigned dblks = 0;\n \tunsigned ptrs_per_blk;\n \tconst unsigned end_of_metadata = height - 1;\n+\tint ret;\n \tint eob = 0;\n \tenum alloc_state state;\n \t__be64 *ptr;\n@@ -114,6 +116,15 @@\n \t\t\tdblock = bn;\n \t\t\twhile (n-- > 0)\n \t\t\t\t*ptr++ = cpu_to_be64(bn++);\n+\t\t\tif (buffer_zeronew(bh_map)) {\n+\t\t\t\tret = sb_issue_zeroout(sb, dblock, dblks,\n+\t\t\t\t\t\t       GFP_NOFS);\n+\t\t\t\tif (ret) {\n+\t\t\t\t\tfs_err(sdp,\n+\t\t\t\t\t       \"Failed to zero data buffers\\n\");\n+\t\t\t\t\tclear_buffer_zeronew(bh_map);\n+\t\t\t\t}\n+\t\t\t}\n \t\t\tbreak;\n \t\t}\n \t} while ((state != ALLOC_DATA) || !dblock);",
        "function_modified_lines": {
            "added": [
                "\tstruct super_block *sb = sdp->sd_vfs;",
                "\tint ret;",
                "\t\t\tif (buffer_zeronew(bh_map)) {",
                "\t\t\t\tret = sb_issue_zeroout(sb, dblock, dblks,",
                "\t\t\t\t\t\t       GFP_NOFS);",
                "\t\t\t\tif (ret) {",
                "\t\t\t\t\tfs_err(sdp,",
                "\t\t\t\t\t       \"Failed to zero data buffers\\n\");",
                "\t\t\t\t\tclear_buffer_zeronew(bh_map);",
                "\t\t\t\t}",
                "\t\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The fallocate implementation in the GFS2 filesystem in the Linux kernel before 3.2 relies on the page cache, which might allow local users to cause a denial of service by preallocating blocks in certain situations involving insufficient memory.",
        "id": 30
    },
    {
        "cve_id": "CVE-2017-5548",
        "code_before_change": "static int atusb_get_and_show_build(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tchar build[ATUSB_BUILD_SIZE + 1];\n\tint ret;\n\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_BUILD, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuild, ATUSB_BUILD_SIZE, 1000);\n\tif (ret >= 0) {\n\t\tbuild[ret] = 0;\n\t\tdev_info(&usb_dev->dev, \"Firmware: build %s\\n\", build);\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static int atusb_get_and_show_build(struct atusb *atusb)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tchar *build;\n\tint ret;\n\n\tbuild = kmalloc(ATUSB_BUILD_SIZE + 1, GFP_KERNEL);\n\tif (!build)\n\t\treturn -ENOMEM;\n\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_BUILD, ATUSB_REQ_FROM_DEV, 0, 0,\n\t\t\t\tbuild, ATUSB_BUILD_SIZE, 1000);\n\tif (ret >= 0) {\n\t\tbuild[ret] = 0;\n\t\tdev_info(&usb_dev->dev, \"Firmware: build %s\\n\", build);\n\t}\n\n\tkfree(build);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,12 @@\n static int atusb_get_and_show_build(struct atusb *atusb)\n {\n \tstruct usb_device *usb_dev = atusb->usb_dev;\n-\tchar build[ATUSB_BUILD_SIZE + 1];\n+\tchar *build;\n \tint ret;\n+\n+\tbuild = kmalloc(ATUSB_BUILD_SIZE + 1, GFP_KERNEL);\n+\tif (!build)\n+\t\treturn -ENOMEM;\n \n \tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n \t\t\t\tATUSB_BUILD, ATUSB_REQ_FROM_DEV, 0, 0,\n@@ -12,5 +16,6 @@\n \t\tdev_info(&usb_dev->dev, \"Firmware: build %s\\n\", build);\n \t}\n \n+\tkfree(build);\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tchar *build;",
                "",
                "\tbuild = kmalloc(ATUSB_BUILD_SIZE + 1, GFP_KERNEL);",
                "\tif (!build)",
                "\t\treturn -ENOMEM;",
                "\tkfree(build);"
            ],
            "deleted": [
                "\tchar build[ATUSB_BUILD_SIZE + 1];"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/ieee802154/atusb.c in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1464
    },
    {
        "cve_id": "CVE-2022-3640",
        "code_before_change": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\n\t\t\t       struct sk_buff *skb)\n{\n\tstruct l2cap_chan *chan;\n\n\tchan = l2cap_get_chan_by_scid(conn, cid);\n\tif (!chan) {\n\t\tif (cid == L2CAP_CID_A2MP) {\n\t\t\tchan = a2mp_channel_create(conn, skb);\n\t\t\tif (!chan) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tl2cap_chan_lock(chan);\n\t\t} else {\n\t\t\tBT_DBG(\"unknown cid 0x%4.4x\", cid);\n\t\t\t/* Drop packet and return */\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tBT_DBG(\"chan %p, len %d\", chan, skb->len);\n\n\t/* If we receive data on a fixed channel before the info req/rsp\n\t * procedure is done simply assume that the channel is supported\n\t * and mark it as ready.\n\t */\n\tif (chan->chan_type == L2CAP_CHAN_FIXED)\n\t\tl2cap_chan_ready(chan);\n\n\tif (chan->state != BT_CONNECTED)\n\t\tgoto drop;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_LE_FLOWCTL:\n\tcase L2CAP_MODE_EXT_FLOWCTL:\n\t\tif (l2cap_ecred_data_rcv(chan, skb) < 0)\n\t\t\tgoto drop;\n\n\t\tgoto done;\n\n\tcase L2CAP_MODE_BASIC:\n\t\t/* If socket recv buffers overflows we drop data here\n\t\t * which is *bad* because L2CAP has to be reliable.\n\t\t * But we don't have any other choice. L2CAP doesn't\n\t\t * provide flow control mechanism. */\n\n\t\tif (chan->imtu < skb->len) {\n\t\t\tBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\n\t\t\tgoto drop;\n\t\t}\n\n\t\tif (!chan->ops->recv(chan, skb))\n\t\t\tgoto done;\n\t\tbreak;\n\n\tcase L2CAP_MODE_ERTM:\n\tcase L2CAP_MODE_STREAMING:\n\t\tl2cap_data_rcv(chan, skb);\n\t\tgoto done;\n\n\tdefault:\n\t\tBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\n\t\tbreak;\n\t}\n\ndrop:\n\tkfree_skb(skb);\n\ndone:\n\tl2cap_chan_unlock(chan);\n\tl2cap_chan_put(chan);\n}",
        "code_after_change": "static void l2cap_data_channel(struct l2cap_conn *conn, u16 cid,\n\t\t\t       struct sk_buff *skb)\n{\n\tstruct l2cap_chan *chan;\n\n\tchan = l2cap_get_chan_by_scid(conn, cid);\n\tif (!chan) {\n\t\tif (cid == L2CAP_CID_A2MP) {\n\t\t\tchan = a2mp_channel_create(conn, skb);\n\t\t\tif (!chan) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tl2cap_chan_hold(chan);\n\t\t\tl2cap_chan_lock(chan);\n\t\t} else {\n\t\t\tBT_DBG(\"unknown cid 0x%4.4x\", cid);\n\t\t\t/* Drop packet and return */\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tBT_DBG(\"chan %p, len %d\", chan, skb->len);\n\n\t/* If we receive data on a fixed channel before the info req/rsp\n\t * procedure is done simply assume that the channel is supported\n\t * and mark it as ready.\n\t */\n\tif (chan->chan_type == L2CAP_CHAN_FIXED)\n\t\tl2cap_chan_ready(chan);\n\n\tif (chan->state != BT_CONNECTED)\n\t\tgoto drop;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_LE_FLOWCTL:\n\tcase L2CAP_MODE_EXT_FLOWCTL:\n\t\tif (l2cap_ecred_data_rcv(chan, skb) < 0)\n\t\t\tgoto drop;\n\n\t\tgoto done;\n\n\tcase L2CAP_MODE_BASIC:\n\t\t/* If socket recv buffers overflows we drop data here\n\t\t * which is *bad* because L2CAP has to be reliable.\n\t\t * But we don't have any other choice. L2CAP doesn't\n\t\t * provide flow control mechanism. */\n\n\t\tif (chan->imtu < skb->len) {\n\t\t\tBT_ERR(\"Dropping L2CAP data: receive buffer overflow\");\n\t\t\tgoto drop;\n\t\t}\n\n\t\tif (!chan->ops->recv(chan, skb))\n\t\t\tgoto done;\n\t\tbreak;\n\n\tcase L2CAP_MODE_ERTM:\n\tcase L2CAP_MODE_STREAMING:\n\t\tl2cap_data_rcv(chan, skb);\n\t\tgoto done;\n\n\tdefault:\n\t\tBT_DBG(\"chan %p: bad mode 0x%2.2x\", chan, chan->mode);\n\t\tbreak;\n\t}\n\ndrop:\n\tkfree_skb(skb);\n\ndone:\n\tl2cap_chan_unlock(chan);\n\tl2cap_chan_put(chan);\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,6 +12,7 @@\n \t\t\t\treturn;\n \t\t\t}\n \n+\t\t\tl2cap_chan_hold(chan);\n \t\t\tl2cap_chan_lock(chan);\n \t\t} else {\n \t\t\tBT_DBG(\"unknown cid 0x%4.4x\", cid);",
        "function_modified_lines": {
            "added": [
                "\t\t\tl2cap_chan_hold(chan);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability, which was classified as critical, was found in Linux Kernel. Affected is the function l2cap_conn_del of the file net/bluetooth/l2cap_core.c of the component Bluetooth. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211944.",
        "id": 3670
    },
    {
        "cve_id": "CVE-2017-16526",
        "code_before_change": "void uwbd_start(struct uwb_rc *rc)\n{\n\trc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");\n\tif (rc->uwbd.task == NULL)\n\t\tprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\t\t       \"UWB won't work\\n\");\n\telse\n\t\trc->uwbd.pid = rc->uwbd.task->pid;\n}",
        "code_after_change": "void uwbd_start(struct uwb_rc *rc)\n{\n\tstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");\n\tif (IS_ERR(task)) {\n\t\trc->uwbd.task = NULL;\n\t\tprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n\t\t       \"UWB won't work\\n\");\n\t} else {\n\t\trc->uwbd.task = task;\n\t\trc->uwbd.pid = rc->uwbd.task->pid;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,12 @@\n void uwbd_start(struct uwb_rc *rc)\n {\n-\trc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");\n-\tif (rc->uwbd.task == NULL)\n+\tstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");\n+\tif (IS_ERR(task)) {\n+\t\trc->uwbd.task = NULL;\n \t\tprintk(KERN_ERR \"UWB: Cannot start management daemon; \"\n \t\t       \"UWB won't work\\n\");\n-\telse\n+\t} else {\n+\t\trc->uwbd.task = task;\n \t\trc->uwbd.pid = rc->uwbd.task->pid;\n+\t}\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct task_struct *task = kthread_run(uwbd, rc, \"uwbd\");",
                "\tif (IS_ERR(task)) {",
                "\t\trc->uwbd.task = NULL;",
                "\t} else {",
                "\t\trc->uwbd.task = task;",
                "\t}"
            ],
            "deleted": [
                "\trc->uwbd.task = kthread_run(uwbd, rc, \"uwbd\");",
                "\tif (rc->uwbd.task == NULL)",
                "\telse"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/uwb/uwbd.c in the Linux kernel before 4.13.6 allows local users to cause a denial of service (general protection fault and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1310
    },
    {
        "cve_id": "CVE-2013-2850",
        "code_before_change": "static int iscsi_add_notunderstood_response(\n\tchar *key,\n\tchar *value,\n\tstruct iscsi_param_list *param_list)\n{\n\tstruct iscsi_extra_response *extra_response;\n\n\tif (strlen(value) > VALUE_MAXLEN) {\n\t\tpr_err(\"Value for notunderstood key \\\"%s\\\" exceeds %d,\"\n\t\t\t\" protocol error.\\n\", key, VALUE_MAXLEN);\n\t\treturn -1;\n\t}\n\n\textra_response = kzalloc(sizeof(struct iscsi_extra_response), GFP_KERNEL);\n\tif (!extra_response) {\n\t\tpr_err(\"Unable to allocate memory for\"\n\t\t\t\" struct iscsi_extra_response.\\n\");\n\t\treturn -1;\n\t}\n\tINIT_LIST_HEAD(&extra_response->er_list);\n\n\tstrncpy(extra_response->key, key, strlen(key) + 1);\n\tstrncpy(extra_response->value, NOTUNDERSTOOD,\n\t\t\tstrlen(NOTUNDERSTOOD) + 1);\n\n\tlist_add_tail(&extra_response->er_list,\n\t\t\t&param_list->extra_response_list);\n\treturn 0;\n}",
        "code_after_change": "static int iscsi_add_notunderstood_response(\n\tchar *key,\n\tchar *value,\n\tstruct iscsi_param_list *param_list)\n{\n\tstruct iscsi_extra_response *extra_response;\n\n\tif (strlen(value) > VALUE_MAXLEN) {\n\t\tpr_err(\"Value for notunderstood key \\\"%s\\\" exceeds %d,\"\n\t\t\t\" protocol error.\\n\", key, VALUE_MAXLEN);\n\t\treturn -1;\n\t}\n\n\textra_response = kzalloc(sizeof(struct iscsi_extra_response), GFP_KERNEL);\n\tif (!extra_response) {\n\t\tpr_err(\"Unable to allocate memory for\"\n\t\t\t\" struct iscsi_extra_response.\\n\");\n\t\treturn -1;\n\t}\n\tINIT_LIST_HEAD(&extra_response->er_list);\n\n\tstrlcpy(extra_response->key, key, sizeof(extra_response->key));\n\tstrlcpy(extra_response->value, NOTUNDERSTOOD,\n\t\tsizeof(extra_response->value));\n\n\tlist_add_tail(&extra_response->er_list,\n\t\t\t&param_list->extra_response_list);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,9 +19,9 @@\n \t}\n \tINIT_LIST_HEAD(&extra_response->er_list);\n \n-\tstrncpy(extra_response->key, key, strlen(key) + 1);\n-\tstrncpy(extra_response->value, NOTUNDERSTOOD,\n-\t\t\tstrlen(NOTUNDERSTOOD) + 1);\n+\tstrlcpy(extra_response->key, key, sizeof(extra_response->key));\n+\tstrlcpy(extra_response->value, NOTUNDERSTOOD,\n+\t\tsizeof(extra_response->value));\n \n \tlist_add_tail(&extra_response->er_list,\n \t\t\t&param_list->extra_response_list);",
        "function_modified_lines": {
            "added": [
                "\tstrlcpy(extra_response->key, key, sizeof(extra_response->key));",
                "\tstrlcpy(extra_response->value, NOTUNDERSTOOD,",
                "\t\tsizeof(extra_response->value));"
            ],
            "deleted": [
                "\tstrncpy(extra_response->key, key, strlen(key) + 1);",
                "\tstrncpy(extra_response->value, NOTUNDERSTOOD,",
                "\t\t\tstrlen(NOTUNDERSTOOD) + 1);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the iscsi_add_notunderstood_response function in drivers/target/iscsi/iscsi_target_parameters.c in the iSCSI target subsystem in the Linux kernel through 3.9.4 allows remote attackers to cause a denial of service (memory corruption and OOPS) or possibly execute arbitrary code via a long key that is not properly handled during construction of an error-response packet.",
        "id": 239
    },
    {
        "cve_id": "CVE-2014-3183",
        "code_before_change": "static int logi_dj_ll_raw_request(struct hid_device *hid,\n\t\t\t\t  unsigned char reportnum, __u8 *buf,\n\t\t\t\t  size_t count, unsigned char report_type,\n\t\t\t\t  int reqtype)\n{\n\tstruct dj_device *djdev = hid->driver_data;\n\tstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\n\tu8 *out_buf;\n\tint ret;\n\n\tif (buf[0] != REPORT_TYPE_LEDS)\n\t\treturn -EINVAL;\n\n\tout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\n\tif (!out_buf)\n\t\treturn -ENOMEM;\n\n\tif (count < DJREPORT_SHORT_LENGTH - 2)\n\t\tcount = DJREPORT_SHORT_LENGTH - 2;\n\n\tout_buf[0] = REPORT_ID_DJ_SHORT;\n\tout_buf[1] = djdev->device_index;\n\tmemcpy(out_buf + 2, buf, count);\n\n\tret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\n\t\tDJREPORT_SHORT_LENGTH, report_type, reqtype);\n\n\tkfree(out_buf);\n\treturn ret;\n}",
        "code_after_change": "static int logi_dj_ll_raw_request(struct hid_device *hid,\n\t\t\t\t  unsigned char reportnum, __u8 *buf,\n\t\t\t\t  size_t count, unsigned char report_type,\n\t\t\t\t  int reqtype)\n{\n\tstruct dj_device *djdev = hid->driver_data;\n\tstruct dj_receiver_dev *djrcv_dev = djdev->dj_receiver_dev;\n\tu8 *out_buf;\n\tint ret;\n\n\tif (buf[0] != REPORT_TYPE_LEDS)\n\t\treturn -EINVAL;\n\n\tout_buf = kzalloc(DJREPORT_SHORT_LENGTH, GFP_ATOMIC);\n\tif (!out_buf)\n\t\treturn -ENOMEM;\n\n\tif (count > DJREPORT_SHORT_LENGTH - 2)\n\t\tcount = DJREPORT_SHORT_LENGTH - 2;\n\n\tout_buf[0] = REPORT_ID_DJ_SHORT;\n\tout_buf[1] = djdev->device_index;\n\tmemcpy(out_buf + 2, buf, count);\n\n\tret = hid_hw_raw_request(djrcv_dev->hdev, out_buf[0], out_buf,\n\t\tDJREPORT_SHORT_LENGTH, report_type, reqtype);\n\n\tkfree(out_buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,7 +15,7 @@\n \tif (!out_buf)\n \t\treturn -ENOMEM;\n \n-\tif (count < DJREPORT_SHORT_LENGTH - 2)\n+\tif (count > DJREPORT_SHORT_LENGTH - 2)\n \t\tcount = DJREPORT_SHORT_LENGTH - 2;\n \n \tout_buf[0] = REPORT_ID_DJ_SHORT;",
        "function_modified_lines": {
            "added": [
                "\tif (count > DJREPORT_SHORT_LENGTH - 2)"
            ],
            "deleted": [
                "\tif (count < DJREPORT_SHORT_LENGTH - 2)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the logi_dj_ll_raw_request function in drivers/hid/hid-logitech-dj.c in the Linux kernel before 3.16.2 allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted device that specifies a large report size for an LED report.",
        "id": 514
    },
    {
        "cve_id": "CVE-2015-5283",
        "code_before_change": "static __init int sctp_init(void)\n{\n\tint i;\n\tint status = -EINVAL;\n\tunsigned long goal;\n\tunsigned long limit;\n\tint max_share;\n\tint order;\n\n\tsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\n\n\t/* Allocate bind_bucket and chunk caches. */\n\tstatus = -ENOBUFS;\n\tsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\n\t\t\t\t\t       sizeof(struct sctp_bind_bucket),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_bucket_cachep)\n\t\tgoto out;\n\n\tsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\n\t\t\t\t\t       sizeof(struct sctp_chunk),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_chunk_cachep)\n\t\tgoto err_chunk_cachep;\n\n\tstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\n\tif (status)\n\t\tgoto err_percpu_counter_init;\n\n\t/* Implementation specific variables. */\n\n\t/* Initialize default stream count setup information. */\n\tsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\n\tsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\n\n\t/* Initialize handle used for association ids. */\n\tidr_init(&sctp_assocs_id);\n\n\tlimit = nr_free_buffer_pages() / 8;\n\tlimit = max(limit, 128UL);\n\tsysctl_sctp_mem[0] = limit / 4 * 3;\n\tsysctl_sctp_mem[1] = limit;\n\tsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\n\n\t/* Set per-socket limits to no more than 1/128 the pressure threshold*/\n\tlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\n\tmax_share = min(4UL*1024*1024, limit);\n\n\tsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; /* give each asoc 1 page min */\n\tsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\n\tsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\n\n\tsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\n\tsysctl_sctp_wmem[1] = 16*1024;\n\tsysctl_sctp_wmem[2] = max(64*1024, max_share);\n\n\t/* Size and allocate the association hash table.\n\t * The methodology is similar to that of the tcp hash tables.\n\t */\n\tif (totalram_pages >= (128 * 1024))\n\t\tgoal = totalram_pages >> (22 - PAGE_SHIFT);\n\telse\n\t\tgoal = totalram_pages >> (24 - PAGE_SHIFT);\n\n\tfor (order = 0; (1UL << order) < goal; order++)\n\t\t;\n\n\tdo {\n\t\tsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_hashbucket);\n\t\tif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_assoc_hashtable = (struct sctp_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_assoc_hashtable && --order > 0);\n\tif (!sctp_assoc_hashtable) {\n\t\tpr_err(\"Failed association hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ahash_alloc;\n\t}\n\tfor (i = 0; i < sctp_assoc_hashsize; i++) {\n\t\trwlock_init(&sctp_assoc_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the endpoint hash table.  */\n\tsctp_ep_hashsize = 64;\n\tsctp_ep_hashtable =\n\t\tkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\n\tif (!sctp_ep_hashtable) {\n\t\tpr_err(\"Failed endpoint_hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ehash_alloc;\n\t}\n\tfor (i = 0; i < sctp_ep_hashsize; i++) {\n\t\trwlock_init(&sctp_ep_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the SCTP port hash table.  */\n\tdo {\n\t\tsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_bind_hashbucket);\n\t\tif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_port_hashtable && --order > 0);\n\tif (!sctp_port_hashtable) {\n\t\tpr_err(\"Failed bind hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_bhash_alloc;\n\t}\n\tfor (i = 0; i < sctp_port_hashsize; i++) {\n\t\tspin_lock_init(&sctp_port_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n\t}\n\n\tpr_info(\"Hash tables configured (established %d bind %d)\\n\",\n\t\tsctp_assoc_hashsize, sctp_port_hashsize);\n\n\tsctp_sysctl_register();\n\n\tINIT_LIST_HEAD(&sctp_address_families);\n\tsctp_v4_pf_init();\n\tsctp_v6_pf_init();\n\n\tstatus = sctp_v4_protosw_init();\n\n\tif (status)\n\t\tgoto err_protosw_init;\n\n\tstatus = sctp_v6_protosw_init();\n\tif (status)\n\t\tgoto err_v6_protosw_init;\n\n\tstatus = register_pernet_subsys(&sctp_net_ops);\n\tif (status)\n\t\tgoto err_register_pernet_subsys;\n\n\tstatus = sctp_v4_add_protocol();\n\tif (status)\n\t\tgoto err_add_protocol;\n\n\t/* Register SCTP with inet6 layer.  */\n\tstatus = sctp_v6_add_protocol();\n\tif (status)\n\t\tgoto err_v6_add_protocol;\n\nout:\n\treturn status;\nerr_v6_add_protocol:\n\tsctp_v4_del_protocol();\nerr_add_protocol:\n\tunregister_pernet_subsys(&sctp_net_ops);\nerr_register_pernet_subsys:\n\tsctp_v6_protosw_exit();\nerr_v6_protosw_init:\n\tsctp_v4_protosw_exit();\nerr_protosw_init:\n\tsctp_v4_pf_exit();\n\tsctp_v6_pf_exit();\n\tsctp_sysctl_unregister();\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\n\tkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\n\tkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\n\tkmem_cache_destroy(sctp_bucket_cachep);\n\tgoto out;\n}",
        "code_after_change": "static __init int sctp_init(void)\n{\n\tint i;\n\tint status = -EINVAL;\n\tunsigned long goal;\n\tunsigned long limit;\n\tint max_share;\n\tint order;\n\n\tsock_skb_cb_check_size(sizeof(struct sctp_ulpevent));\n\n\t/* Allocate bind_bucket and chunk caches. */\n\tstatus = -ENOBUFS;\n\tsctp_bucket_cachep = kmem_cache_create(\"sctp_bind_bucket\",\n\t\t\t\t\t       sizeof(struct sctp_bind_bucket),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_bucket_cachep)\n\t\tgoto out;\n\n\tsctp_chunk_cachep = kmem_cache_create(\"sctp_chunk\",\n\t\t\t\t\t       sizeof(struct sctp_chunk),\n\t\t\t\t\t       0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t       NULL);\n\tif (!sctp_chunk_cachep)\n\t\tgoto err_chunk_cachep;\n\n\tstatus = percpu_counter_init(&sctp_sockets_allocated, 0, GFP_KERNEL);\n\tif (status)\n\t\tgoto err_percpu_counter_init;\n\n\t/* Implementation specific variables. */\n\n\t/* Initialize default stream count setup information. */\n\tsctp_max_instreams    \t\t= SCTP_DEFAULT_INSTREAMS;\n\tsctp_max_outstreams   \t\t= SCTP_DEFAULT_OUTSTREAMS;\n\n\t/* Initialize handle used for association ids. */\n\tidr_init(&sctp_assocs_id);\n\n\tlimit = nr_free_buffer_pages() / 8;\n\tlimit = max(limit, 128UL);\n\tsysctl_sctp_mem[0] = limit / 4 * 3;\n\tsysctl_sctp_mem[1] = limit;\n\tsysctl_sctp_mem[2] = sysctl_sctp_mem[0] * 2;\n\n\t/* Set per-socket limits to no more than 1/128 the pressure threshold*/\n\tlimit = (sysctl_sctp_mem[1]) << (PAGE_SHIFT - 7);\n\tmax_share = min(4UL*1024*1024, limit);\n\n\tsysctl_sctp_rmem[0] = SK_MEM_QUANTUM; /* give each asoc 1 page min */\n\tsysctl_sctp_rmem[1] = 1500 * SKB_TRUESIZE(1);\n\tsysctl_sctp_rmem[2] = max(sysctl_sctp_rmem[1], max_share);\n\n\tsysctl_sctp_wmem[0] = SK_MEM_QUANTUM;\n\tsysctl_sctp_wmem[1] = 16*1024;\n\tsysctl_sctp_wmem[2] = max(64*1024, max_share);\n\n\t/* Size and allocate the association hash table.\n\t * The methodology is similar to that of the tcp hash tables.\n\t */\n\tif (totalram_pages >= (128 * 1024))\n\t\tgoal = totalram_pages >> (22 - PAGE_SHIFT);\n\telse\n\t\tgoal = totalram_pages >> (24 - PAGE_SHIFT);\n\n\tfor (order = 0; (1UL << order) < goal; order++)\n\t\t;\n\n\tdo {\n\t\tsctp_assoc_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_hashbucket);\n\t\tif ((sctp_assoc_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_assoc_hashtable = (struct sctp_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_assoc_hashtable && --order > 0);\n\tif (!sctp_assoc_hashtable) {\n\t\tpr_err(\"Failed association hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ahash_alloc;\n\t}\n\tfor (i = 0; i < sctp_assoc_hashsize; i++) {\n\t\trwlock_init(&sctp_assoc_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_assoc_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the endpoint hash table.  */\n\tsctp_ep_hashsize = 64;\n\tsctp_ep_hashtable =\n\t\tkmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);\n\tif (!sctp_ep_hashtable) {\n\t\tpr_err(\"Failed endpoint_hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_ehash_alloc;\n\t}\n\tfor (i = 0; i < sctp_ep_hashsize; i++) {\n\t\trwlock_init(&sctp_ep_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_ep_hashtable[i].chain);\n\t}\n\n\t/* Allocate and initialize the SCTP port hash table.  */\n\tdo {\n\t\tsctp_port_hashsize = (1UL << order) * PAGE_SIZE /\n\t\t\t\t\tsizeof(struct sctp_bind_hashbucket);\n\t\tif ((sctp_port_hashsize > (64 * 1024)) && order > 0)\n\t\t\tcontinue;\n\t\tsctp_port_hashtable = (struct sctp_bind_hashbucket *)\n\t\t\t__get_free_pages(GFP_ATOMIC|__GFP_NOWARN, order);\n\t} while (!sctp_port_hashtable && --order > 0);\n\tif (!sctp_port_hashtable) {\n\t\tpr_err(\"Failed bind hash alloc\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err_bhash_alloc;\n\t}\n\tfor (i = 0; i < sctp_port_hashsize; i++) {\n\t\tspin_lock_init(&sctp_port_hashtable[i].lock);\n\t\tINIT_HLIST_HEAD(&sctp_port_hashtable[i].chain);\n\t}\n\n\tpr_info(\"Hash tables configured (established %d bind %d)\\n\",\n\t\tsctp_assoc_hashsize, sctp_port_hashsize);\n\n\tsctp_sysctl_register();\n\n\tINIT_LIST_HEAD(&sctp_address_families);\n\tsctp_v4_pf_init();\n\tsctp_v6_pf_init();\n\n\tstatus = register_pernet_subsys(&sctp_defaults_ops);\n\tif (status)\n\t\tgoto err_register_defaults;\n\n\tstatus = sctp_v4_protosw_init();\n\tif (status)\n\t\tgoto err_protosw_init;\n\n\tstatus = sctp_v6_protosw_init();\n\tif (status)\n\t\tgoto err_v6_protosw_init;\n\n\tstatus = register_pernet_subsys(&sctp_ctrlsock_ops);\n\tif (status)\n\t\tgoto err_register_ctrlsock;\n\n\tstatus = sctp_v4_add_protocol();\n\tif (status)\n\t\tgoto err_add_protocol;\n\n\t/* Register SCTP with inet6 layer.  */\n\tstatus = sctp_v6_add_protocol();\n\tif (status)\n\t\tgoto err_v6_add_protocol;\n\nout:\n\treturn status;\nerr_v6_add_protocol:\n\tsctp_v4_del_protocol();\nerr_add_protocol:\n\tunregister_pernet_subsys(&sctp_ctrlsock_ops);\nerr_register_ctrlsock:\n\tsctp_v6_protosw_exit();\nerr_v6_protosw_init:\n\tsctp_v4_protosw_exit();\nerr_protosw_init:\n\tunregister_pernet_subsys(&sctp_defaults_ops);\nerr_register_defaults:\n\tsctp_v4_pf_exit();\n\tsctp_v6_pf_exit();\n\tsctp_sysctl_unregister();\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\nerr_bhash_alloc:\n\tkfree(sctp_ep_hashtable);\nerr_ehash_alloc:\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\nerr_ahash_alloc:\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\nerr_percpu_counter_init:\n\tkmem_cache_destroy(sctp_chunk_cachep);\nerr_chunk_cachep:\n\tkmem_cache_destroy(sctp_bucket_cachep);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -127,8 +127,11 @@\n \tsctp_v4_pf_init();\n \tsctp_v6_pf_init();\n \n+\tstatus = register_pernet_subsys(&sctp_defaults_ops);\n+\tif (status)\n+\t\tgoto err_register_defaults;\n+\n \tstatus = sctp_v4_protosw_init();\n-\n \tif (status)\n \t\tgoto err_protosw_init;\n \n@@ -136,9 +139,9 @@\n \tif (status)\n \t\tgoto err_v6_protosw_init;\n \n-\tstatus = register_pernet_subsys(&sctp_net_ops);\n+\tstatus = register_pernet_subsys(&sctp_ctrlsock_ops);\n \tif (status)\n-\t\tgoto err_register_pernet_subsys;\n+\t\tgoto err_register_ctrlsock;\n \n \tstatus = sctp_v4_add_protocol();\n \tif (status)\n@@ -154,12 +157,14 @@\n err_v6_add_protocol:\n \tsctp_v4_del_protocol();\n err_add_protocol:\n-\tunregister_pernet_subsys(&sctp_net_ops);\n-err_register_pernet_subsys:\n+\tunregister_pernet_subsys(&sctp_ctrlsock_ops);\n+err_register_ctrlsock:\n \tsctp_v6_protosw_exit();\n err_v6_protosw_init:\n \tsctp_v4_protosw_exit();\n err_protosw_init:\n+\tunregister_pernet_subsys(&sctp_defaults_ops);\n+err_register_defaults:\n \tsctp_v4_pf_exit();\n \tsctp_v6_pf_exit();\n \tsctp_sysctl_unregister();",
        "function_modified_lines": {
            "added": [
                "\tstatus = register_pernet_subsys(&sctp_defaults_ops);",
                "\tif (status)",
                "\t\tgoto err_register_defaults;",
                "",
                "\tstatus = register_pernet_subsys(&sctp_ctrlsock_ops);",
                "\t\tgoto err_register_ctrlsock;",
                "\tunregister_pernet_subsys(&sctp_ctrlsock_ops);",
                "err_register_ctrlsock:",
                "\tunregister_pernet_subsys(&sctp_defaults_ops);",
                "err_register_defaults:"
            ],
            "deleted": [
                "",
                "\tstatus = register_pernet_subsys(&sctp_net_ops);",
                "\t\tgoto err_register_pernet_subsys;",
                "\tunregister_pernet_subsys(&sctp_net_ops);",
                "err_register_pernet_subsys:"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The sctp_init function in net/sctp/protocol.c in the Linux kernel before 4.2.3 has an incorrect sequence of protocol-initialization steps, which allows local users to cause a denial of service (panic or memory corruption) by creating SCTP sockets before all of the steps have finished.",
        "id": 773
    },
    {
        "cve_id": "CVE-2016-1583",
        "code_before_change": "static struct dentry *proc_mount(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data)\n{\n\tint err;\n\tstruct super_block *sb;\n\tstruct pid_namespace *ns;\n\tchar *options;\n\n\tif (flags & MS_KERNMOUNT) {\n\t\tns = (struct pid_namespace *)data;\n\t\toptions = NULL;\n\t} else {\n\t\tns = task_active_pid_ns(current);\n\t\toptions = data;\n\n\t\t/* Does the mounter have privilege over the pid namespace? */\n\t\tif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\n\t\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\tsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\n\tif (IS_ERR(sb))\n\t\treturn ERR_CAST(sb);\n\n\tif (!proc_parse_options(options, ns)) {\n\t\tdeactivate_locked_super(sb);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!sb->s_root) {\n\t\terr = proc_fill_super(sb);\n\t\tif (err) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tsb->s_flags |= MS_ACTIVE;\n\t\t/* User space would break if executables appear on proc */\n\t\tsb->s_iflags |= SB_I_NOEXEC;\n\t}\n\n\treturn dget(sb->s_root);\n}",
        "code_after_change": "static struct dentry *proc_mount(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data)\n{\n\tint err;\n\tstruct super_block *sb;\n\tstruct pid_namespace *ns;\n\tchar *options;\n\n\tif (flags & MS_KERNMOUNT) {\n\t\tns = (struct pid_namespace *)data;\n\t\toptions = NULL;\n\t} else {\n\t\tns = task_active_pid_ns(current);\n\t\toptions = data;\n\n\t\t/* Does the mounter have privilege over the pid namespace? */\n\t\tif (!ns_capable(ns->user_ns, CAP_SYS_ADMIN))\n\t\t\treturn ERR_PTR(-EPERM);\n\t}\n\n\tsb = sget(fs_type, proc_test_super, proc_set_super, flags, ns);\n\tif (IS_ERR(sb))\n\t\treturn ERR_CAST(sb);\n\n\t/*\n\t * procfs isn't actually a stacking filesystem; however, there is\n\t * too much magic going on inside it to permit stacking things on\n\t * top of it\n\t */\n\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;\n\n\tif (!proc_parse_options(options, ns)) {\n\t\tdeactivate_locked_super(sb);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!sb->s_root) {\n\t\terr = proc_fill_super(sb);\n\t\tif (err) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\n\t\tsb->s_flags |= MS_ACTIVE;\n\t\t/* User space would break if executables appear on proc */\n\t\tsb->s_iflags |= SB_I_NOEXEC;\n\t}\n\n\treturn dget(sb->s_root);\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,13 @@\n \tif (IS_ERR(sb))\n \t\treturn ERR_CAST(sb);\n \n+\t/*\n+\t * procfs isn't actually a stacking filesystem; however, there is\n+\t * too much magic going on inside it to permit stacking things on\n+\t * top of it\n+\t */\n+\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;\n+\n \tif (!proc_parse_options(options, ns)) {\n \t\tdeactivate_locked_super(sb);\n \t\treturn ERR_PTR(-EINVAL);",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * procfs isn't actually a stacking filesystem; however, there is",
                "\t * too much magic going on inside it to permit stacking things on",
                "\t * top of it",
                "\t */",
                "\tsb->s_stack_depth = FILESYSTEM_MAX_STACK_DEPTH;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The ecryptfs_privileged_open function in fs/ecryptfs/kthread.c in the Linux kernel before 4.6.3 allows local users to gain privileges or cause a denial of service (stack memory consumption) via vectors involving crafted mmap calls for /proc pathnames, leading to recursive pagefault handling.",
        "id": 914
    },
    {
        "cve_id": "CVE-2015-5283",
        "code_before_change": "static __exit void sctp_exit(void)\n{\n\t/* BUG.  This should probably do something useful like clean\n\t * up all the remaining associations and all that memory.\n\t */\n\n\t/* Unregister with inet6/inet layers. */\n\tsctp_v6_del_protocol();\n\tsctp_v4_del_protocol();\n\n\tunregister_pernet_subsys(&sctp_net_ops);\n\n\t/* Free protosw registrations */\n\tsctp_v6_protosw_exit();\n\tsctp_v4_protosw_exit();\n\n\t/* Unregister with socket layer. */\n\tsctp_v6_pf_exit();\n\tsctp_v4_pf_exit();\n\n\tsctp_sysctl_unregister();\n\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\n\tkfree(sctp_ep_hashtable);\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\n\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\n\n\trcu_barrier(); /* Wait for completion of call_rcu()'s */\n\n\tkmem_cache_destroy(sctp_chunk_cachep);\n\tkmem_cache_destroy(sctp_bucket_cachep);\n}",
        "code_after_change": "static __exit void sctp_exit(void)\n{\n\t/* BUG.  This should probably do something useful like clean\n\t * up all the remaining associations and all that memory.\n\t */\n\n\t/* Unregister with inet6/inet layers. */\n\tsctp_v6_del_protocol();\n\tsctp_v4_del_protocol();\n\n\tunregister_pernet_subsys(&sctp_ctrlsock_ops);\n\n\t/* Free protosw registrations */\n\tsctp_v6_protosw_exit();\n\tsctp_v4_protosw_exit();\n\n\tunregister_pernet_subsys(&sctp_defaults_ops);\n\n\t/* Unregister with socket layer. */\n\tsctp_v6_pf_exit();\n\tsctp_v4_pf_exit();\n\n\tsctp_sysctl_unregister();\n\n\tfree_pages((unsigned long)sctp_assoc_hashtable,\n\t\t   get_order(sctp_assoc_hashsize *\n\t\t\t     sizeof(struct sctp_hashbucket)));\n\tkfree(sctp_ep_hashtable);\n\tfree_pages((unsigned long)sctp_port_hashtable,\n\t\t   get_order(sctp_port_hashsize *\n\t\t\t     sizeof(struct sctp_bind_hashbucket)));\n\n\tpercpu_counter_destroy(&sctp_sockets_allocated);\n\n\trcu_barrier(); /* Wait for completion of call_rcu()'s */\n\n\tkmem_cache_destroy(sctp_chunk_cachep);\n\tkmem_cache_destroy(sctp_bucket_cachep);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,11 +8,13 @@\n \tsctp_v6_del_protocol();\n \tsctp_v4_del_protocol();\n \n-\tunregister_pernet_subsys(&sctp_net_ops);\n+\tunregister_pernet_subsys(&sctp_ctrlsock_ops);\n \n \t/* Free protosw registrations */\n \tsctp_v6_protosw_exit();\n \tsctp_v4_protosw_exit();\n+\n+\tunregister_pernet_subsys(&sctp_defaults_ops);\n \n \t/* Unregister with socket layer. */\n \tsctp_v6_pf_exit();",
        "function_modified_lines": {
            "added": [
                "\tunregister_pernet_subsys(&sctp_ctrlsock_ops);",
                "",
                "\tunregister_pernet_subsys(&sctp_defaults_ops);"
            ],
            "deleted": [
                "\tunregister_pernet_subsys(&sctp_net_ops);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The sctp_init function in net/sctp/protocol.c in the Linux kernel before 4.2.3 has an incorrect sequence of protocol-initialization steps, which allows local users to cause a denial of service (panic or memory corruption) by creating SCTP sockets before all of the steps have finished.",
        "id": 774
    },
    {
        "cve_id": "CVE-2017-16996",
        "code_before_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno, int off,\n\t\t\t    int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno)\n{\n\tstruct bpf_verifier_state *state = env->cur_state;\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* ctx accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t */\n\t\tif (reg->off) {\n\t\t\tverbose(env,\n\t\t\t\t\"dereference of modified ctx ptr R%d off=%d+%d, ctx+const is allowed, ctx+const+const is not\\n\",\n\t\t\t\tregno, reg->off, off - reg->off);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env,\n\t\t\t\t\"variable ctx access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE)\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\telse\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\tregs[value_regno].id = 0;\n\t\t\tregs[value_regno].off = 0;\n\t\t\tregs[value_regno].range = 0;\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* stack accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t * See check_stack_read().\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env, \"variable stack access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\toff += reg->var_off.value;\n\t\tif (off >= 0 || off < -MAX_BPF_STACK) {\n\t\t\tverbose(env, \"invalid stack off=%d size=%d\\n\", off,\n\t\t\t\tsize);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (env->prog->aux->stack_depth < -off)\n\t\t\tenv->prog->aux->stack_depth = -off;\n\n\t\tif (t == BPF_WRITE)\n\t\t\terr = check_stack_write(env, state, off, size,\n\t\t\t\t\t\tvalue_regno);\n\t\telse\n\t\t\terr = check_stack_read(env, state, off, size,\n\t\t\t\t\t       value_regno);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tregs[value_regno].var_off =\n\t\t\ttnum_cast(regs[value_regno].var_off, size);\n\t\t__update_reg_bounds(&regs[value_regno]);\n\t}\n\treturn err;\n}",
        "code_after_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno, int off,\n\t\t\t    int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno)\n{\n\tstruct bpf_verifier_state *state = env->cur_state;\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* ctx accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t */\n\t\tif (reg->off) {\n\t\t\tverbose(env,\n\t\t\t\t\"dereference of modified ctx ptr R%d off=%d+%d, ctx+const is allowed, ctx+const+const is not\\n\",\n\t\t\t\tregno, reg->off, off - reg->off);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env,\n\t\t\t\t\"variable ctx access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE)\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\telse\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\tregs[value_regno].id = 0;\n\t\t\tregs[value_regno].off = 0;\n\t\t\tregs[value_regno].range = 0;\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* stack accesses must be at a fixed offset, so that we can\n\t\t * determine what type of data were returned.\n\t\t * See check_stack_read().\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off)) {\n\t\t\tchar tn_buf[48];\n\n\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\tverbose(env, \"variable stack access var_off=%s off=%d size=%d\",\n\t\t\t\ttn_buf, off, size);\n\t\t\treturn -EACCES;\n\t\t}\n\t\toff += reg->var_off.value;\n\t\tif (off >= 0 || off < -MAX_BPF_STACK) {\n\t\t\tverbose(env, \"invalid stack off=%d size=%d\\n\", off,\n\t\t\t\tsize);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (env->prog->aux->stack_depth < -off)\n\t\t\tenv->prog->aux->stack_depth = -off;\n\n\t\tif (t == BPF_WRITE)\n\t\t\terr = check_stack_write(env, state, off, size,\n\t\t\t\t\t\tvalue_regno);\n\t\telse\n\t\t\terr = check_stack_read(env, state, off, size,\n\t\t\t\t\t       value_regno);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -125,9 +125,7 @@\n \tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n \t    regs[value_regno].type == SCALAR_VALUE) {\n \t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n-\t\tregs[value_regno].var_off =\n-\t\t\ttnum_cast(regs[value_regno].var_off, size);\n-\t\t__update_reg_bounds(&regs[value_regno]);\n+\t\tcoerce_reg_to_size(&regs[value_regno], size);\n \t}\n \treturn err;\n }",
        "function_modified_lines": {
            "added": [
                "\t\tcoerce_reg_to_size(&regs[value_regno], size);"
            ],
            "deleted": [
                "\t\tregs[value_regno].var_off =",
                "\t\t\ttnum_cast(regs[value_regno].var_off, size);",
                "\t\t__update_reg_bounds(&regs[value_regno]);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 4.14.8 allows local users to cause a denial of service (memory corruption) or possibly have unspecified other impact by leveraging register truncation mishandling.",
        "id": 1356
    },
    {
        "cve_id": "CVE-2013-1860",
        "code_before_change": "static int wdm_post_reset(struct usb_interface *intf)\n{\n\tstruct wdm_device *desc = wdm_find_device(intf);\n\tint rv;\n\n\tclear_bit(WDM_RESETTING, &desc->flags);\n\trv = recover_from_urb_loss(desc);\n\tmutex_unlock(&desc->wlock);\n\tmutex_unlock(&desc->rlock);\n\treturn 0;\n}",
        "code_after_change": "static int wdm_post_reset(struct usb_interface *intf)\n{\n\tstruct wdm_device *desc = wdm_find_device(intf);\n\tint rv;\n\n\tclear_bit(WDM_OVERFLOW, &desc->flags);\n\tclear_bit(WDM_RESETTING, &desc->flags);\n\trv = recover_from_urb_loss(desc);\n\tmutex_unlock(&desc->wlock);\n\tmutex_unlock(&desc->rlock);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n \tstruct wdm_device *desc = wdm_find_device(intf);\n \tint rv;\n \n+\tclear_bit(WDM_OVERFLOW, &desc->flags);\n \tclear_bit(WDM_RESETTING, &desc->flags);\n \trv = recover_from_urb_loss(desc);\n \tmutex_unlock(&desc->wlock);",
        "function_modified_lines": {
            "added": [
                "\tclear_bit(WDM_OVERFLOW, &desc->flags);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the wdm_in_callback function in drivers/usb/class/cdc-wdm.c in the Linux kernel before 3.8.4 allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted cdc-wdm USB device.",
        "id": 202
    },
    {
        "cve_id": "CVE-2014-8884",
        "code_before_change": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\n\tstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\n\tu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n\t\t   0x00, 0x00, 0x00, 0x00,\n\t\t   0x00, 0x00 };\n\n\tmemcpy(&b[4], cmd->msg, cmd->msg_len);\n\n\tstate->config->send_command(fe, 0x72,\n\t\t\t\t    sizeof(b) - (6 - cmd->msg_len), b,\n\t\t\t\t    NULL, NULL);\n\n\treturn 0;\n}",
        "code_after_change": "static int ttusbdecfe_dvbs_diseqc_send_master_cmd(struct dvb_frontend* fe, struct dvb_diseqc_master_cmd *cmd)\n{\n\tstruct ttusbdecfe_state* state = (struct ttusbdecfe_state*) fe->demodulator_priv;\n\tu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n\t\t   0x00, 0x00, 0x00, 0x00,\n\t\t   0x00, 0x00 };\n\n\tif (cmd->msg_len > sizeof(b) - 4)\n\t\treturn -EINVAL;\n\n\tmemcpy(&b[4], cmd->msg, cmd->msg_len);\n\n\tstate->config->send_command(fe, 0x72,\n\t\t\t\t    sizeof(b) - (6 - cmd->msg_len), b,\n\t\t\t\t    NULL, NULL);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tu8 b[] = { 0x00, 0xff, 0x00, 0x00,\n \t\t   0x00, 0x00, 0x00, 0x00,\n \t\t   0x00, 0x00 };\n+\n+\tif (cmd->msg_len > sizeof(b) - 4)\n+\t\treturn -EINVAL;\n \n \tmemcpy(&b[4], cmd->msg, cmd->msg_len);\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (cmd->msg_len > sizeof(b) - 4)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Stack-based buffer overflow in the ttusbdecfe_dvbs_diseqc_send_master_cmd function in drivers/media/usb/ttusb-dec/ttusbdecfe.c in the Linux kernel before 3.17.4 allows local users to cause a denial of service (system crash) or possibly gain privileges via a large message length in an ioctl call.",
        "id": 676
    },
    {
        "cve_id": "CVE-2013-2234",
        "code_before_change": "static int key_notify_sa_flush(const struct km_event *c)\n{\n\tstruct sk_buff *skb;\n\tstruct sadb_msg *hdr;\n\n\tskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\thdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\n\thdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\n\thdr->sadb_msg_type = SADB_FLUSH;\n\thdr->sadb_msg_seq = c->seq;\n\thdr->sadb_msg_pid = c->portid;\n\thdr->sadb_msg_version = PF_KEY_V2;\n\thdr->sadb_msg_errno = (uint8_t) 0;\n\thdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\n\n\tpfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\n\n\treturn 0;\n}",
        "code_after_change": "static int key_notify_sa_flush(const struct km_event *c)\n{\n\tstruct sk_buff *skb;\n\tstruct sadb_msg *hdr;\n\n\tskb = alloc_skb(sizeof(struct sadb_msg) + 16, GFP_ATOMIC);\n\tif (!skb)\n\t\treturn -ENOBUFS;\n\thdr = (struct sadb_msg *) skb_put(skb, sizeof(struct sadb_msg));\n\thdr->sadb_msg_satype = pfkey_proto2satype(c->data.proto);\n\thdr->sadb_msg_type = SADB_FLUSH;\n\thdr->sadb_msg_seq = c->seq;\n\thdr->sadb_msg_pid = c->portid;\n\thdr->sadb_msg_version = PF_KEY_V2;\n\thdr->sadb_msg_errno = (uint8_t) 0;\n\thdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\n\thdr->sadb_msg_reserved = 0;\n\n\tpfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,7 @@\n \thdr->sadb_msg_version = PF_KEY_V2;\n \thdr->sadb_msg_errno = (uint8_t) 0;\n \thdr->sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));\n+\thdr->sadb_msg_reserved = 0;\n \n \tpfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c->net);\n ",
        "function_modified_lines": {
            "added": [
                "\thdr->sadb_msg_reserved = 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The (1) key_notify_sa_flush and (2) key_notify_policy_flush functions in net/key/af_key.c in the Linux kernel before 3.10 do not initialize certain structure members, which allows local users to obtain sensitive information from kernel heap memory by reading a broadcast message from the notify interface of an IPSec key_socket.",
        "id": 224
    },
    {
        "cve_id": "CVE-2017-8062",
        "code_before_change": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *d = adap->dev;\n\tstruct dw2102_state *state = d->priv;\n\tu8 obuf[3] = { 0xe, 0x80, 0 };\n\tu8 ibuf[] = { 0 };\n\tstruct i2c_adapter *i2c_adapter;\n\tstruct i2c_client *client;\n\tstruct i2c_board_info board_info;\n\tstruct m88ds3103_platform_data m88ds3103_pdata = {};\n\tstruct ts2020_config ts2020_config = {};\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x02;\n\tobuf[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\tmsleep(300);\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x83;\n\tobuf[2] = 0;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0xe;\n\tobuf[1] = 0x83;\n\tobuf[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tobuf[0] = 0x51;\n\n\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)\n\t\terr(\"command 0x51 transfer failed.\");\n\n\t/* attach demod */\n\tm88ds3103_pdata.clk = 27000000;\n\tm88ds3103_pdata.i2c_wr_max = 33;\n\tm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\n\tm88ds3103_pdata.ts_clk = 16000;\n\tm88ds3103_pdata.ts_clk_pol = 0;\n\tm88ds3103_pdata.spec_inv = 0;\n\tm88ds3103_pdata.agc = 0x99;\n\tm88ds3103_pdata.agc_inv = 0;\n\tm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\n\tm88ds3103_pdata.envelope_mode = 0;\n\tm88ds3103_pdata.lnb_hv_pol = 1;\n\tm88ds3103_pdata.lnb_en_pol = 0;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x68;\n\tboard_info.platform_data = &m88ds3103_pdata;\n\trequest_module(\"m88ds3103\");\n\tclient = i2c_new_device(&d->i2c_adap, &board_info);\n\tif (client == NULL || client->dev.driver == NULL)\n\t\treturn -ENODEV;\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\n\ti2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\n\n\tstate->i2c_client_demod = client;\n\n\t/* attach tuner */\n\tts2020_config.fe = adap->fe_adap[0].fe;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x60;\n\tboard_info.platform_data = &ts2020_config;\n\trequest_module(\"ts2020\");\n\tclient = i2c_new_device(i2c_adapter, &board_info);\n\n\tif (client == NULL || client->dev.driver == NULL) {\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\t/* delegate signal strength measurement to tuner */\n\tadap->fe_adap[0].fe->ops.read_signal_strength =\n\t\t\tadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\n\n\tstate->i2c_client_tuner = client;\n\n\t/* hook fe: need to resync the slave fifo when signal locks */\n\tstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\n\n\tstate->last_lock = 0;\n\n\treturn 0;\n}",
        "code_after_change": "static int tt_s2_4600_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *d = adap->dev;\n\tstruct dw2102_state *state = d->priv;\n\tstruct i2c_adapter *i2c_adapter;\n\tstruct i2c_client *client;\n\tstruct i2c_board_info board_info;\n\tstruct m88ds3103_platform_data m88ds3103_pdata = {};\n\tstruct ts2020_config ts2020_config = {};\n\n\tmutex_lock(&d->data_mutex);\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x80;\n\tstate->data[2] = 0x0;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x02;\n\tstate->data[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\tmsleep(300);\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x83;\n\tstate->data[2] = 0;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0xe;\n\tstate->data[1] = 0x83;\n\tstate->data[2] = 1;\n\n\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n\t\terr(\"command 0x0e transfer failed.\");\n\n\tstate->data[0] = 0x51;\n\n\tif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)\n\t\terr(\"command 0x51 transfer failed.\");\n\n\tmutex_unlock(&d->data_mutex);\n\n\t/* attach demod */\n\tm88ds3103_pdata.clk = 27000000;\n\tm88ds3103_pdata.i2c_wr_max = 33;\n\tm88ds3103_pdata.ts_mode = M88DS3103_TS_CI;\n\tm88ds3103_pdata.ts_clk = 16000;\n\tm88ds3103_pdata.ts_clk_pol = 0;\n\tm88ds3103_pdata.spec_inv = 0;\n\tm88ds3103_pdata.agc = 0x99;\n\tm88ds3103_pdata.agc_inv = 0;\n\tm88ds3103_pdata.clk_out = M88DS3103_CLOCK_OUT_ENABLED;\n\tm88ds3103_pdata.envelope_mode = 0;\n\tm88ds3103_pdata.lnb_hv_pol = 1;\n\tm88ds3103_pdata.lnb_en_pol = 0;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"m88ds3103\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x68;\n\tboard_info.platform_data = &m88ds3103_pdata;\n\trequest_module(\"m88ds3103\");\n\tclient = i2c_new_device(&d->i2c_adap, &board_info);\n\tif (client == NULL || client->dev.driver == NULL)\n\t\treturn -ENODEV;\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = m88ds3103_pdata.get_dvb_frontend(client);\n\ti2c_adapter = m88ds3103_pdata.get_i2c_adapter(client);\n\n\tstate->i2c_client_demod = client;\n\n\t/* attach tuner */\n\tts2020_config.fe = adap->fe_adap[0].fe;\n\tmemset(&board_info, 0, sizeof(board_info));\n\tstrlcpy(board_info.type, \"ts2022\", I2C_NAME_SIZE);\n\tboard_info.addr = 0x60;\n\tboard_info.platform_data = &ts2020_config;\n\trequest_module(\"ts2020\");\n\tclient = i2c_new_device(i2c_adapter, &board_info);\n\n\tif (client == NULL || client->dev.driver == NULL) {\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!try_module_get(client->dev.driver->owner)) {\n\t\ti2c_unregister_device(client);\n\t\tdvb_frontend_detach(adap->fe_adap[0].fe);\n\t\treturn -ENODEV;\n\t}\n\n\t/* delegate signal strength measurement to tuner */\n\tadap->fe_adap[0].fe->ops.read_signal_strength =\n\t\t\tadap->fe_adap[0].fe->ops.tuner_ops.get_rf_strength;\n\n\tstate->i2c_client_tuner = client;\n\n\t/* hook fe: need to resync the slave fifo when signal locks */\n\tstate->fe_read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = tt_s2_4600_read_status;\n\n\tstate->last_lock = 0;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,43 +2,49 @@\n {\n \tstruct dvb_usb_device *d = adap->dev;\n \tstruct dw2102_state *state = d->priv;\n-\tu8 obuf[3] = { 0xe, 0x80, 0 };\n-\tu8 ibuf[] = { 0 };\n \tstruct i2c_adapter *i2c_adapter;\n \tstruct i2c_client *client;\n \tstruct i2c_board_info board_info;\n \tstruct m88ds3103_platform_data m88ds3103_pdata = {};\n \tstruct ts2020_config ts2020_config = {};\n \n-\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n+\tmutex_lock(&d->data_mutex);\n+\n+\tstate->data[0] = 0xe;\n+\tstate->data[1] = 0x80;\n+\tstate->data[2] = 0x0;\n+\n+\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n \t\terr(\"command 0x0e transfer failed.\");\n \n-\tobuf[0] = 0xe;\n-\tobuf[1] = 0x02;\n-\tobuf[2] = 1;\n+\tstate->data[0] = 0xe;\n+\tstate->data[1] = 0x02;\n+\tstate->data[2] = 1;\n \n-\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n+\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n \t\terr(\"command 0x0e transfer failed.\");\n \tmsleep(300);\n \n-\tobuf[0] = 0xe;\n-\tobuf[1] = 0x83;\n-\tobuf[2] = 0;\n+\tstate->data[0] = 0xe;\n+\tstate->data[1] = 0x83;\n+\tstate->data[2] = 0;\n \n-\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n+\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n \t\terr(\"command 0x0e transfer failed.\");\n \n-\tobuf[0] = 0xe;\n-\tobuf[1] = 0x83;\n-\tobuf[2] = 1;\n+\tstate->data[0] = 0xe;\n+\tstate->data[1] = 0x83;\n+\tstate->data[2] = 1;\n \n-\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)\n+\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)\n \t\terr(\"command 0x0e transfer failed.\");\n \n-\tobuf[0] = 0x51;\n+\tstate->data[0] = 0x51;\n \n-\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)\n+\tif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)\n \t\terr(\"command 0x51 transfer failed.\");\n+\n+\tmutex_unlock(&d->data_mutex);\n \n \t/* attach demod */\n \tm88ds3103_pdata.clk = 27000000;",
        "function_modified_lines": {
            "added": [
                "\tmutex_lock(&d->data_mutex);",
                "",
                "\tstate->data[0] = 0xe;",
                "\tstate->data[1] = 0x80;",
                "\tstate->data[2] = 0x0;",
                "",
                "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
                "\tstate->data[0] = 0xe;",
                "\tstate->data[1] = 0x02;",
                "\tstate->data[2] = 1;",
                "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
                "\tstate->data[0] = 0xe;",
                "\tstate->data[1] = 0x83;",
                "\tstate->data[2] = 0;",
                "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
                "\tstate->data[0] = 0xe;",
                "\tstate->data[1] = 0x83;",
                "\tstate->data[2] = 1;",
                "\tif (dvb_usb_generic_rw(d, state->data, 3, state->data, 1, 0) < 0)",
                "\tstate->data[0] = 0x51;",
                "\tif (dvb_usb_generic_rw(d, state->data, 1, state->data, 1, 0) < 0)",
                "",
                "\tmutex_unlock(&d->data_mutex);"
            ],
            "deleted": [
                "\tu8 obuf[3] = { 0xe, 0x80, 0 };",
                "\tu8 ibuf[] = { 0 };",
                "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
                "\tobuf[0] = 0xe;",
                "\tobuf[1] = 0x02;",
                "\tobuf[2] = 1;",
                "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
                "\tobuf[0] = 0xe;",
                "\tobuf[1] = 0x83;",
                "\tobuf[2] = 0;",
                "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
                "\tobuf[0] = 0xe;",
                "\tobuf[1] = 0x83;",
                "\tobuf[2] = 1;",
                "\tif (dvb_usb_generic_rw(d, obuf, 3, ibuf, 1, 0) < 0)",
                "\tobuf[0] = 0x51;",
                "\tif (dvb_usb_generic_rw(d, obuf, 1, ibuf, 1, 0) < 0)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dw2102.c in the Linux kernel 4.9.x and 4.10.x before 4.10.4 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1538
    },
    {
        "cve_id": "CVE-2017-15126",
        "code_before_change": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\n\t\t\t\t\t      struct userfaultfd_wait_queue *ewq)\n{\n\tif (WARN_ON_ONCE(current->flags & PF_EXITING))\n\t\tgoto out;\n\n\tewq->ctx = ctx;\n\tinit_waitqueue_entry(&ewq->wq, current);\n\n\tspin_lock(&ctx->event_wqh.lock);\n\t/*\n\t * After the __add_wait_queue the uwq is visible to userland\n\t * through poll/read().\n\t */\n\t__add_wait_queue(&ctx->event_wqh, &ewq->wq);\n\tfor (;;) {\n\t\tset_current_state(TASK_KILLABLE);\n\t\tif (ewq->msg.event == 0)\n\t\t\tbreak;\n\t\tif (ACCESS_ONCE(ctx->released) ||\n\t\t    fatal_signal_pending(current)) {\n\t\t\t__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\n\t\t\tif (ewq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tstruct userfaultfd_ctx *new;\n\n\t\t\t\tnew = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tewq->msg.arg.reserved.reserved1;\n\n\t\t\t\tuserfaultfd_ctx_put(new);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\twake_up_poll(&ctx->fd_wqh, POLLIN);\n\t\tschedule();\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->event_wqh.lock);\n\n\t/*\n\t * ctx may go away after this if the userfault pseudo fd is\n\t * already released.\n\t */\nout:\n\tuserfaultfd_ctx_put(ctx);\n}",
        "code_after_change": "static void userfaultfd_event_wait_completion(struct userfaultfd_ctx *ctx,\n\t\t\t\t\t      struct userfaultfd_wait_queue *ewq)\n{\n\tif (WARN_ON_ONCE(current->flags & PF_EXITING))\n\t\tgoto out;\n\n\tewq->ctx = ctx;\n\tinit_waitqueue_entry(&ewq->wq, current);\n\n\tspin_lock(&ctx->event_wqh.lock);\n\t/*\n\t * After the __add_wait_queue the uwq is visible to userland\n\t * through poll/read().\n\t */\n\t__add_wait_queue(&ctx->event_wqh, &ewq->wq);\n\tfor (;;) {\n\t\tset_current_state(TASK_KILLABLE);\n\t\tif (ewq->msg.event == 0)\n\t\t\tbreak;\n\t\tif (ACCESS_ONCE(ctx->released) ||\n\t\t    fatal_signal_pending(current)) {\n\t\t\t/*\n\t\t\t * &ewq->wq may be queued in fork_event, but\n\t\t\t * __remove_wait_queue ignores the head\n\t\t\t * parameter. It would be a problem if it\n\t\t\t * didn't.\n\t\t\t */\n\t\t\t__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\n\t\t\tif (ewq->msg.event == UFFD_EVENT_FORK) {\n\t\t\t\tstruct userfaultfd_ctx *new;\n\n\t\t\t\tnew = (struct userfaultfd_ctx *)\n\t\t\t\t\t(unsigned long)\n\t\t\t\t\tewq->msg.arg.reserved.reserved1;\n\n\t\t\t\tuserfaultfd_ctx_put(new);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock(&ctx->event_wqh.lock);\n\n\t\twake_up_poll(&ctx->fd_wqh, POLLIN);\n\t\tschedule();\n\n\t\tspin_lock(&ctx->event_wqh.lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\tspin_unlock(&ctx->event_wqh.lock);\n\n\t/*\n\t * ctx may go away after this if the userfault pseudo fd is\n\t * already released.\n\t */\nout:\n\tuserfaultfd_ctx_put(ctx);\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,12 @@\n \t\t\tbreak;\n \t\tif (ACCESS_ONCE(ctx->released) ||\n \t\t    fatal_signal_pending(current)) {\n+\t\t\t/*\n+\t\t\t * &ewq->wq may be queued in fork_event, but\n+\t\t\t * __remove_wait_queue ignores the head\n+\t\t\t * parameter. It would be a problem if it\n+\t\t\t * didn't.\n+\t\t\t */\n \t\t\t__remove_wait_queue(&ctx->event_wqh, &ewq->wq);\n \t\t\tif (ewq->msg.event == UFFD_EVENT_FORK) {\n \t\t\t\tstruct userfaultfd_ctx *new;",
        "function_modified_lines": {
            "added": [
                "\t\t\t/*",
                "\t\t\t * &ewq->wq may be queued in fork_event, but",
                "\t\t\t * __remove_wait_queue ignores the head",
                "\t\t\t * parameter. It would be a problem if it",
                "\t\t\t * didn't.",
                "\t\t\t */"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A use-after-free flaw was found in fs/userfaultfd.c in the Linux kernel before 4.13.6. The issue is related to the handling of fork failure when dealing with event messages. Failure to fork correctly can lead to a situation where a fork event will be removed from an already freed list of events with userfaultfd_ctx_put().",
        "id": 1297
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "void kdb_syslog_data(char *syslog_data[4])\n{\n\tsyslog_data[0] = log_buf;\n\tsyslog_data[1] = log_buf + log_buf_len;\n\tsyslog_data[2] = log_buf + log_end -\n\t\t(logged_chars < log_buf_len ? logged_chars : log_buf_len);\n\tsyslog_data[3] = log_buf + log_end;\n}",
        "code_after_change": "void kdb_syslog_data(char *syslog_data[4])\n{\n\tsyslog_data[0] = log_buf;\n\tsyslog_data[1] = log_buf + log_buf_len;\n\tsyslog_data[2] = log_buf + log_first_idx;\n\tsyslog_data[3] = log_buf + log_next_idx;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,6 @@\n {\n \tsyslog_data[0] = log_buf;\n \tsyslog_data[1] = log_buf + log_buf_len;\n-\tsyslog_data[2] = log_buf + log_end -\n-\t\t(logged_chars < log_buf_len ? logged_chars : log_buf_len);\n-\tsyslog_data[3] = log_buf + log_end;\n+\tsyslog_data[2] = log_buf + log_first_idx;\n+\tsyslog_data[3] = log_buf + log_next_idx;\n }",
        "function_modified_lines": {
            "added": [
                "\tsyslog_data[2] = log_buf + log_first_idx;",
                "\tsyslog_data[3] = log_buf + log_next_idx;"
            ],
            "deleted": [
                "\tsyslog_data[2] = log_buf + log_end -",
                "\t\t(logged_chars < log_buf_len ? logged_chars : log_buf_len);",
                "\tsyslog_data[3] = log_buf + log_end;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 173
    },
    {
        "cve_id": "CVE-2018-12233",
        "code_before_change": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tint size;\n\tint ea_size = sizeDXD(&ji->ea);\n\tint blocks_needed, current_blocks;\n\ts64 blkno;\n\tint rc;\n\tint quota_allocation = 0;\n\n\t/* When fsck.jfs clears a bad ea, it doesn't clear the size */\n\tif (ji->ea.flag == 0)\n\t\tea_size = 0;\n\n\tif (ea_size == 0) {\n\t\tif (min_size == 0) {\n\t\t\tea_buf->flag = 0;\n\t\t\tea_buf->max_size = 0;\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\tif ((min_size <= sizeof (ji->i_inline_ea)) &&\n\t\t    (ji->mode2 & INLINEEA)) {\n\t\t\tea_buf->flag = EA_INLINE | EA_NEW;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tDXDlength(&ea_buf->new_ea, 0);\n\t\t\tDXDaddress(&ea_buf->new_ea, 0);\n\t\t\tea_buf->new_ea.flag = DXD_INLINE;\n\t\t\tDXDsize(&ea_buf->new_ea, min_size);\n\t\t\treturn 0;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else if (ji->ea.flag & DXD_INLINE) {\n\t\tif (min_size <= sizeof (ji->i_inline_ea)) {\n\t\t\tea_buf->flag = EA_INLINE;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tgoto size_check;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else {\n\t\tif (!(ji->ea.flag & DXD_EXTENT)) {\n\t\t\tjfs_error(sb, \"invalid ea.flag\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tcurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\n\t\t    sb->s_blocksize_bits;\n\t}\n\tsize = max(min_size, ea_size);\n\n\tif (size > PSIZE) {\n\t\t/*\n\t\t * To keep the rest of the code simple.  Allocate a\n\t\t * contiguous buffer to work with\n\t\t */\n\t\tea_buf->xattr = kmalloc(size, GFP_KERNEL);\n\t\tif (ea_buf->xattr == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tea_buf->flag = EA_MALLOC;\n\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tkfree(ea_buf->xattr);\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn rc;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tblocks_needed = (min_size + sb->s_blocksize - 1) >>\n\t    sb->s_blocksize_bits;\n\n\tif (blocks_needed > current_blocks) {\n\t\t/* Allocate new blocks to quota. */\n\t\trc = dquot_alloc_block(inode, blocks_needed);\n\t\tif (rc)\n\t\t\treturn -EDQUOT;\n\n\t\tquota_allocation = blocks_needed;\n\n\t\trc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n\t\t\t     &blkno);\n\t\tif (rc)\n\t\t\tgoto clean_up;\n\n\t\tDXDlength(&ea_buf->new_ea, blocks_needed);\n\t\tDXDaddress(&ea_buf->new_ea, blkno);\n\t\tea_buf->new_ea.flag = DXD_EXTENT;\n\t\tDXDsize(&ea_buf->new_ea, min_size);\n\n\t\tea_buf->flag = EA_EXTENT | EA_NEW;\n\n\t\tea_buf->mp = get_metapage(inode, blkno,\n\t\t\t\t\t  blocks_needed << sb->s_blocksize_bits,\n\t\t\t\t\t  1);\n\t\tif (ea_buf->mp == NULL) {\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\trc = -EIO;\n\t\t\tgoto clean_up;\n\t\t}\n\t\tea_buf->xattr = ea_buf->mp->data;\n\t\tea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tdiscard_metapage(ea_buf->mp);\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\tgoto clean_up;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tea_buf->flag = EA_EXTENT;\n\tea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\n\t\t\t\t   lengthDXD(&ji->ea) << sb->s_blocksize_bits,\n\t\t\t\t   1);\n\tif (ea_buf->mp == NULL) {\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\tea_buf->xattr = ea_buf->mp->data;\n\tea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n\t    ~(sb->s_blocksize - 1);\n\n      size_check:\n\tif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\n\t\tprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\n\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\n\t\t\t\t     ea_buf->xattr, ea_size, 1);\n\t\tea_release(inode, ea_buf);\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\n\treturn ea_size;\n\n      clean_up:\n\t/* Rollback quota allocation */\n\tif (quota_allocation)\n\t\tdquot_free_block(inode, quota_allocation);\n\n\treturn (rc);\n}",
        "code_after_change": "static int ea_get(struct inode *inode, struct ea_buffer *ea_buf, int min_size)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\tstruct super_block *sb = inode->i_sb;\n\tint size;\n\tint ea_size = sizeDXD(&ji->ea);\n\tint blocks_needed, current_blocks;\n\ts64 blkno;\n\tint rc;\n\tint quota_allocation = 0;\n\n\t/* When fsck.jfs clears a bad ea, it doesn't clear the size */\n\tif (ji->ea.flag == 0)\n\t\tea_size = 0;\n\n\tif (ea_size == 0) {\n\t\tif (min_size == 0) {\n\t\t\tea_buf->flag = 0;\n\t\t\tea_buf->max_size = 0;\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn 0;\n\t\t}\n\t\tif ((min_size <= sizeof (ji->i_inline_ea)) &&\n\t\t    (ji->mode2 & INLINEEA)) {\n\t\t\tea_buf->flag = EA_INLINE | EA_NEW;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tDXDlength(&ea_buf->new_ea, 0);\n\t\t\tDXDaddress(&ea_buf->new_ea, 0);\n\t\t\tea_buf->new_ea.flag = DXD_INLINE;\n\t\t\tDXDsize(&ea_buf->new_ea, min_size);\n\t\t\treturn 0;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else if (ji->ea.flag & DXD_INLINE) {\n\t\tif (min_size <= sizeof (ji->i_inline_ea)) {\n\t\t\tea_buf->flag = EA_INLINE;\n\t\t\tea_buf->max_size = sizeof (ji->i_inline_ea);\n\t\t\tea_buf->xattr = (struct jfs_ea_list *) ji->i_inline_ea;\n\t\t\tgoto size_check;\n\t\t}\n\t\tcurrent_blocks = 0;\n\t} else {\n\t\tif (!(ji->ea.flag & DXD_EXTENT)) {\n\t\t\tjfs_error(sb, \"invalid ea.flag\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tcurrent_blocks = (ea_size + sb->s_blocksize - 1) >>\n\t\t    sb->s_blocksize_bits;\n\t}\n\tsize = max(min_size, ea_size);\n\n\tif (size > PSIZE) {\n\t\t/*\n\t\t * To keep the rest of the code simple.  Allocate a\n\t\t * contiguous buffer to work with. Make the buffer large\n\t\t * enough to make use of the whole extent.\n\t\t */\n\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\n\t\tea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);\n\t\tif (ea_buf->xattr == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tea_buf->flag = EA_MALLOC;\n\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tkfree(ea_buf->xattr);\n\t\t\tea_buf->xattr = NULL;\n\t\t\treturn rc;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tblocks_needed = (min_size + sb->s_blocksize - 1) >>\n\t    sb->s_blocksize_bits;\n\n\tif (blocks_needed > current_blocks) {\n\t\t/* Allocate new blocks to quota. */\n\t\trc = dquot_alloc_block(inode, blocks_needed);\n\t\tif (rc)\n\t\t\treturn -EDQUOT;\n\n\t\tquota_allocation = blocks_needed;\n\n\t\trc = dbAlloc(inode, INOHINT(inode), (s64) blocks_needed,\n\t\t\t     &blkno);\n\t\tif (rc)\n\t\t\tgoto clean_up;\n\n\t\tDXDlength(&ea_buf->new_ea, blocks_needed);\n\t\tDXDaddress(&ea_buf->new_ea, blkno);\n\t\tea_buf->new_ea.flag = DXD_EXTENT;\n\t\tDXDsize(&ea_buf->new_ea, min_size);\n\n\t\tea_buf->flag = EA_EXTENT | EA_NEW;\n\n\t\tea_buf->mp = get_metapage(inode, blkno,\n\t\t\t\t\t  blocks_needed << sb->s_blocksize_bits,\n\t\t\t\t\t  1);\n\t\tif (ea_buf->mp == NULL) {\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\trc = -EIO;\n\t\t\tgoto clean_up;\n\t\t}\n\t\tea_buf->xattr = ea_buf->mp->data;\n\t\tea_buf->max_size = (min_size + sb->s_blocksize - 1) &\n\t\t    ~(sb->s_blocksize - 1);\n\t\tif (ea_size == 0)\n\t\t\treturn 0;\n\t\tif ((rc = ea_read(inode, ea_buf->xattr))) {\n\t\t\tdiscard_metapage(ea_buf->mp);\n\t\t\tdbFree(inode, blkno, (s64) blocks_needed);\n\t\t\tgoto clean_up;\n\t\t}\n\t\tgoto size_check;\n\t}\n\tea_buf->flag = EA_EXTENT;\n\tea_buf->mp = read_metapage(inode, addressDXD(&ji->ea),\n\t\t\t\t   lengthDXD(&ji->ea) << sb->s_blocksize_bits,\n\t\t\t\t   1);\n\tif (ea_buf->mp == NULL) {\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\tea_buf->xattr = ea_buf->mp->data;\n\tea_buf->max_size = (ea_size + sb->s_blocksize - 1) &\n\t    ~(sb->s_blocksize - 1);\n\n      size_check:\n\tif (EALIST_SIZE(ea_buf->xattr) != ea_size) {\n\t\tprintk(KERN_ERR \"ea_get: invalid extended attribute\\n\");\n\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_ADDRESS, 16, 1,\n\t\t\t\t     ea_buf->xattr, ea_size, 1);\n\t\tea_release(inode, ea_buf);\n\t\trc = -EIO;\n\t\tgoto clean_up;\n\t}\n\n\treturn ea_size;\n\n      clean_up:\n\t/* Rollback quota allocation */\n\tif (quota_allocation)\n\t\tdquot_free_block(inode, quota_allocation);\n\n\treturn (rc);\n}",
        "patch": "--- code before\n+++ code after\n@@ -53,15 +53,17 @@\n \tif (size > PSIZE) {\n \t\t/*\n \t\t * To keep the rest of the code simple.  Allocate a\n-\t\t * contiguous buffer to work with\n+\t\t * contiguous buffer to work with. Make the buffer large\n+\t\t * enough to make use of the whole extent.\n \t\t */\n-\t\tea_buf->xattr = kmalloc(size, GFP_KERNEL);\n+\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n+\t\t    ~(sb->s_blocksize - 1);\n+\n+\t\tea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);\n \t\tif (ea_buf->xattr == NULL)\n \t\t\treturn -ENOMEM;\n \n \t\tea_buf->flag = EA_MALLOC;\n-\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &\n-\t\t    ~(sb->s_blocksize - 1);\n \n \t\tif (ea_size == 0)\n \t\t\treturn 0;",
        "function_modified_lines": {
            "added": [
                "\t\t * contiguous buffer to work with. Make the buffer large",
                "\t\t * enough to make use of the whole extent.",
                "\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &",
                "\t\t    ~(sb->s_blocksize - 1);",
                "",
                "\t\tea_buf->xattr = kmalloc(ea_buf->max_size, GFP_KERNEL);"
            ],
            "deleted": [
                "\t\t * contiguous buffer to work with",
                "\t\tea_buf->xattr = kmalloc(size, GFP_KERNEL);",
                "\t\tea_buf->max_size = (size + sb->s_blocksize - 1) &",
                "\t\t    ~(sb->s_blocksize - 1);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the ea_get function in fs/jfs/xattr.c in the Linux kernel through 4.17.1, a memory corruption bug in JFS can be triggered by calling setxattr twice with two different extended attribute names on the same file. This vulnerability can be triggered by an unprivileged user with the ability to create files and execute programs. A kmalloc call is incorrect, leading to slab-out-of-bounds in jfs_xattr.",
        "id": 1652
    },
    {
        "cve_id": "CVE-2017-8068",
        "code_before_change": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\n\tint ret;\n\n\tret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\n\t\t\t      indx, &data, 1, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\treturn ret;\n}",
        "code_after_change": "static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n{\n\tu8 *buf;\n\tint ret;\n\n\tbuf = kmemdup(&data, 1, GFP_NOIO);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\n\t\t\t      PEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\n\t\t\t      indx, buf, 1, 1000);\n\tif (ret < 0)\n\t\tnetif_dbg(pegasus, drv, pegasus->net,\n\t\t\t  \"%s returned %d\\n\", __func__, ret);\n\tkfree(buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,12 +1,18 @@\n static int set_register(pegasus_t *pegasus, __u16 indx, __u8 data)\n {\n+\tu8 *buf;\n \tint ret;\n+\n+\tbuf = kmemdup(&data, 1, GFP_NOIO);\n+\tif (!buf)\n+\t\treturn -ENOMEM;\n \n \tret = usb_control_msg(pegasus->usb, usb_sndctrlpipe(pegasus->usb, 0),\n \t\t\t      PEGASUS_REQ_SET_REG, PEGASUS_REQT_WRITE, data,\n-\t\t\t      indx, &data, 1, 1000);\n+\t\t\t      indx, buf, 1, 1000);\n \tif (ret < 0)\n \t\tnetif_dbg(pegasus, drv, pegasus->net,\n \t\t\t  \"%s returned %d\\n\", __func__, ret);\n+\tkfree(buf);\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tu8 *buf;",
                "",
                "\tbuf = kmemdup(&data, 1, GFP_NOIO);",
                "\tif (!buf)",
                "\t\treturn -ENOMEM;",
                "\t\t\t      indx, buf, 1, 1000);",
                "\tkfree(buf);"
            ],
            "deleted": [
                "\t\t\t      indx, &data, 1, 1000);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/usb/pegasus.c in the Linux kernel 4.9.x before 4.9.11 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1542
    },
    {
        "cve_id": "CVE-2017-18222",
        "code_before_change": "int hns_rcb_get_ring_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn HNS_RING_STATIC_REG_NUM;\n\n\treturn 0;\n}",
        "code_after_change": "int hns_rcb_get_ring_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn HNS_RING_STATIC_REG_NUM;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n int hns_rcb_get_ring_sset_count(int stringset)\n {\n-\tif (stringset == ETH_SS_STATS)\n+\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n \t\treturn HNS_RING_STATIC_REG_NUM;\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
            ],
            "deleted": [
                "\tif (stringset == ETH_SS_STATS)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.12, Hisilicon Network Subsystem (HNS) does not consider the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, which allows local users to cause a denial of service (buffer overflow and memory corruption) or possibly have unspecified other impact, as demonstrated by incompatibility between hns_get_sset_count and ethtool_get_strings.",
        "id": 1409
    },
    {
        "cve_id": "CVE-2017-7541",
        "code_before_change": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\n\t\t       struct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct ieee80211_channel *chan = params->chan;\n\tconst u8 *buf = params->buf;\n\tsize_t len = params->len;\n\tconst struct ieee80211_mgmt *mgmt;\n\tstruct brcmf_cfg80211_vif *vif;\n\ts32 err = 0;\n\ts32 ie_offset;\n\ts32 ie_len;\n\tstruct brcmf_fil_action_frame_le *action_frame;\n\tstruct brcmf_fil_af_params_le *af_params;\n\tbool ack;\n\ts32 chan_nr;\n\tu32 freq;\n\n\tbrcmf_dbg(TRACE, \"Enter\\n\");\n\n\t*cookie = 0;\n\n\tmgmt = (const struct ieee80211_mgmt *)buf;\n\n\tif (!ieee80211_is_mgmt(mgmt->frame_control)) {\n\t\tbrcmf_err(\"Driver only allows MGMT packet type\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\n\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\t/* Right now the only reason to get a probe response */\n\t\t/* is for p2p listen response or for p2p GO from     */\n\t\t/* wpa_supplicant. Unfortunately the probe is send   */\n\t\t/* on primary ndev, while dongle wants it on the p2p */\n\t\t/* vif. Since this is only reason for a probe        */\n\t\t/* response to be sent, the vif is taken from cfg.   */\n\t\t/* If ever desired to send proberesp for non p2p     */\n\t\t/* response then data should be checked for          */\n\t\t/* \"DIRECT-\". Note in future supplicant will take    */\n\t\t/* dedicated p2p wdev to do this and then this 'hack'*/\n\t\t/* is not needed anymore.                            */\n\t\tie_offset =  DOT11_MGMT_HDR_LEN +\n\t\t\t     DOT11_BCN_PRB_FIXED_LEN;\n\t\tie_len = len - ie_offset;\n\t\tif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\n\t\t\tvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\n\t\terr = brcmf_vif_set_mgmt_ie(vif,\n\t\t\t\t\t    BRCMF_VNDR_IE_PRBRSP_FLAG,\n\t\t\t\t\t    &buf[ie_offset],\n\t\t\t\t\t    ie_len);\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\n\t\t\t\t\tGFP_KERNEL);\n\t} else if (ieee80211_is_action(mgmt->frame_control)) {\n\t\taf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\n\t\tif (af_params == NULL) {\n\t\t\tbrcmf_err(\"unable to allocate frame\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto exit;\n\t\t}\n\t\taction_frame = &af_params->action_frame;\n\t\t/* Add the packet Id */\n\t\taction_frame->packet_id = cpu_to_le32(*cookie);\n\t\t/* Add BSSID */\n\t\tmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\n\t\tmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\n\t\t/* Add the length exepted for 802.11 header  */\n\t\taction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\n\t\t/* Add the channel. Use the one specified as parameter if any or\n\t\t * the current one (got from the firmware) otherwise\n\t\t */\n\t\tif (chan)\n\t\t\tfreq = chan->center_freq;\n\t\telse\n\t\t\tbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n\t\t\t\t\t      &freq);\n\t\tchan_nr = ieee80211_frequency_to_channel(freq);\n\t\taf_params->channel = cpu_to_le32(chan_nr);\n\n\t\tmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\n\t\t       le16_to_cpu(action_frame->len));\n\n\t\tbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n\t\t\t  *cookie, le16_to_cpu(action_frame->len), freq);\n\n\t\tack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\n\t\t\t\t\t\t  af_params);\n\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\n\t\t\t\t\tGFP_KERNEL);\n\t\tkfree(af_params);\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\n\t\tbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n\t}\n\nexit:\n\treturn err;\n}",
        "code_after_change": "static int\nbrcmf_cfg80211_mgmt_tx(struct wiphy *wiphy, struct wireless_dev *wdev,\n\t\t       struct cfg80211_mgmt_tx_params *params, u64 *cookie)\n{\n\tstruct brcmf_cfg80211_info *cfg = wiphy_to_cfg(wiphy);\n\tstruct ieee80211_channel *chan = params->chan;\n\tconst u8 *buf = params->buf;\n\tsize_t len = params->len;\n\tconst struct ieee80211_mgmt *mgmt;\n\tstruct brcmf_cfg80211_vif *vif;\n\ts32 err = 0;\n\ts32 ie_offset;\n\ts32 ie_len;\n\tstruct brcmf_fil_action_frame_le *action_frame;\n\tstruct brcmf_fil_af_params_le *af_params;\n\tbool ack;\n\ts32 chan_nr;\n\tu32 freq;\n\n\tbrcmf_dbg(TRACE, \"Enter\\n\");\n\n\t*cookie = 0;\n\n\tmgmt = (const struct ieee80211_mgmt *)buf;\n\n\tif (!ieee80211_is_mgmt(mgmt->frame_control)) {\n\t\tbrcmf_err(\"Driver only allows MGMT packet type\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tvif = container_of(wdev, struct brcmf_cfg80211_vif, wdev);\n\n\tif (ieee80211_is_probe_resp(mgmt->frame_control)) {\n\t\t/* Right now the only reason to get a probe response */\n\t\t/* is for p2p listen response or for p2p GO from     */\n\t\t/* wpa_supplicant. Unfortunately the probe is send   */\n\t\t/* on primary ndev, while dongle wants it on the p2p */\n\t\t/* vif. Since this is only reason for a probe        */\n\t\t/* response to be sent, the vif is taken from cfg.   */\n\t\t/* If ever desired to send proberesp for non p2p     */\n\t\t/* response then data should be checked for          */\n\t\t/* \"DIRECT-\". Note in future supplicant will take    */\n\t\t/* dedicated p2p wdev to do this and then this 'hack'*/\n\t\t/* is not needed anymore.                            */\n\t\tie_offset =  DOT11_MGMT_HDR_LEN +\n\t\t\t     DOT11_BCN_PRB_FIXED_LEN;\n\t\tie_len = len - ie_offset;\n\t\tif (vif == cfg->p2p.bss_idx[P2PAPI_BSSCFG_PRIMARY].vif)\n\t\t\tvif = cfg->p2p.bss_idx[P2PAPI_BSSCFG_DEVICE].vif;\n\t\terr = brcmf_vif_set_mgmt_ie(vif,\n\t\t\t\t\t    BRCMF_VNDR_IE_PRBRSP_FLAG,\n\t\t\t\t\t    &buf[ie_offset],\n\t\t\t\t\t    ie_len);\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\n\t\t\t\t\tGFP_KERNEL);\n\t} else if (ieee80211_is_action(mgmt->frame_control)) {\n\t\tif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {\n\t\t\tbrcmf_err(\"invalid action frame length\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto exit;\n\t\t}\n\t\taf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\n\t\tif (af_params == NULL) {\n\t\t\tbrcmf_err(\"unable to allocate frame\\n\");\n\t\t\terr = -ENOMEM;\n\t\t\tgoto exit;\n\t\t}\n\t\taction_frame = &af_params->action_frame;\n\t\t/* Add the packet Id */\n\t\taction_frame->packet_id = cpu_to_le32(*cookie);\n\t\t/* Add BSSID */\n\t\tmemcpy(&action_frame->da[0], &mgmt->da[0], ETH_ALEN);\n\t\tmemcpy(&af_params->bssid[0], &mgmt->bssid[0], ETH_ALEN);\n\t\t/* Add the length exepted for 802.11 header  */\n\t\taction_frame->len = cpu_to_le16(len - DOT11_MGMT_HDR_LEN);\n\t\t/* Add the channel. Use the one specified as parameter if any or\n\t\t * the current one (got from the firmware) otherwise\n\t\t */\n\t\tif (chan)\n\t\t\tfreq = chan->center_freq;\n\t\telse\n\t\t\tbrcmf_fil_cmd_int_get(vif->ifp, BRCMF_C_GET_CHANNEL,\n\t\t\t\t\t      &freq);\n\t\tchan_nr = ieee80211_frequency_to_channel(freq);\n\t\taf_params->channel = cpu_to_le32(chan_nr);\n\n\t\tmemcpy(action_frame->data, &buf[DOT11_MGMT_HDR_LEN],\n\t\t       le16_to_cpu(action_frame->len));\n\n\t\tbrcmf_dbg(TRACE, \"Action frame, cookie=%lld, len=%d, freq=%d\\n\",\n\t\t\t  *cookie, le16_to_cpu(action_frame->len), freq);\n\n\t\tack = brcmf_p2p_send_action_frame(cfg, cfg_to_ndev(cfg),\n\t\t\t\t\t\t  af_params);\n\n\t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, ack,\n\t\t\t\t\tGFP_KERNEL);\n\t\tkfree(af_params);\n\t} else {\n\t\tbrcmf_dbg(TRACE, \"Unhandled, fc=%04x!!\\n\", mgmt->frame_control);\n\t\tbrcmf_dbg_hex_dump(true, buf, len, \"payload, len=%zu\\n\", len);\n\t}\n\nexit:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -54,6 +54,11 @@\n \t\tcfg80211_mgmt_tx_status(wdev, *cookie, buf, len, true,\n \t\t\t\t\tGFP_KERNEL);\n \t} else if (ieee80211_is_action(mgmt->frame_control)) {\n+\t\tif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {\n+\t\t\tbrcmf_err(\"invalid action frame length\\n\");\n+\t\t\terr = -EINVAL;\n+\t\t\tgoto exit;\n+\t\t}\n \t\taf_params = kzalloc(sizeof(*af_params), GFP_KERNEL);\n \t\tif (af_params == NULL) {\n \t\t\tbrcmf_err(\"unable to allocate frame\\n\");",
        "function_modified_lines": {
            "added": [
                "\t\tif (len > BRCMF_FIL_ACTION_FRAME_SIZE + DOT11_MGMT_HDR_LEN) {",
                "\t\t\tbrcmf_err(\"invalid action frame length\\n\");",
                "\t\t\terr = -EINVAL;",
                "\t\t\tgoto exit;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The brcmf_cfg80211_mgmt_tx function in drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c in the Linux kernel before 4.12.3 allows local users to cause a denial of service (buffer overflow and system crash) or possibly gain privileges via a crafted NL80211_CMD_FRAME Netlink packet.",
        "id": 1513
    },
    {
        "cve_id": "CVE-2014-2309",
        "code_before_change": "int ip6_route_add(struct fib6_config *cfg)\n{\n\tint err;\n\tstruct net *net = cfg->fc_nlinfo.nl_net;\n\tstruct rt6_info *rt = NULL;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tstruct fib6_table *table;\n\tint addr_type;\n\n\tif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\n\t\treturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\n\tif (cfg->fc_src_len)\n\t\treturn -EINVAL;\n#endif\n\tif (cfg->fc_ifindex) {\n\t\terr = -ENODEV;\n\t\tdev = dev_get_by_index(net, cfg->fc_ifindex);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_metric == 0)\n\t\tcfg->fc_metric = IP6_RT_PRIO_USER;\n\n\terr = -ENOBUFS;\n\tif (cfg->fc_nlinfo.nlh &&\n\t    !(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\ttable = fib6_get_table(net, cfg->fc_table);\n\t\tif (!table) {\n\t\t\tpr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\n\t\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t\t}\n\t} else {\n\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t}\n\n\tif (!table)\n\t\tgoto out;\n\n\trt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);\n\n\tif (!rt) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTF_EXPIRES)\n\t\trt6_set_expires(rt, jiffies +\n\t\t\t\tclock_t_to_jiffies(cfg->fc_expires));\n\telse\n\t\trt6_clean_expires(rt);\n\n\tif (cfg->fc_protocol == RTPROT_UNSPEC)\n\t\tcfg->fc_protocol = RTPROT_BOOT;\n\trt->rt6i_protocol = cfg->fc_protocol;\n\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\trt->dst.input = ip6_mc_input;\n\telse if (cfg->fc_flags & RTF_LOCAL)\n\t\trt->dst.input = ip6_input;\n\telse\n\t\trt->dst.input = ip6_forward;\n\n\trt->dst.output = ip6_output;\n\n\tipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\n\trt->rt6i_dst.plen = cfg->fc_dst_len;\n\tif (rt->rt6i_dst.plen == 128)\n\t       rt->dst.flags |= DST_HOST;\n\n\tif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\n\t\tu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\n\t\tif (!metrics) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tdst_init_metrics(&rt->dst, metrics, 0);\n\t}\n#ifdef CONFIG_IPV6_SUBTREES\n\tipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\n\trt->rt6i_src.plen = cfg->fc_src_len;\n#endif\n\n\trt->rt6i_metric = cfg->fc_metric;\n\n\t/* We cannot add true routes via loopback here,\n\t   they would result in kernel looping; promote them to reject routes\n\t */\n\tif ((cfg->fc_flags & RTF_REJECT) ||\n\t    (dev && (dev->flags & IFF_LOOPBACK) &&\n\t     !(addr_type & IPV6_ADDR_LOOPBACK) &&\n\t     !(cfg->fc_flags & RTF_LOCAL))) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tdev_put(dev);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tdev_hold(dev);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\n\t\tswitch (cfg->fc_type) {\n\t\tcase RTN_BLACKHOLE:\n\t\t\trt->dst.error = -EINVAL;\n\t\t\trt->dst.output = dst_discard;\n\t\t\trt->dst.input = dst_discard;\n\t\t\tbreak;\n\t\tcase RTN_PROHIBIT:\n\t\t\trt->dst.error = -EACCES;\n\t\t\trt->dst.output = ip6_pkt_prohibit_out;\n\t\t\trt->dst.input = ip6_pkt_prohibit;\n\t\t\tbreak;\n\t\tcase RTN_THROW:\n\t\tdefault:\n\t\t\trt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n\t\t\t\t\t: -ENETUNREACH;\n\t\t\trt->dst.output = ip6_pkt_discard_out;\n\t\t\trt->dst.input = ip6_pkt_discard;\n\t\t\tbreak;\n\t\t}\n\t\tgoto install_route;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\tconst struct in6_addr *gw_addr;\n\t\tint gwa_type;\n\n\t\tgw_addr = &cfg->fc_gateway;\n\t\trt->rt6i_gateway = *gw_addr;\n\t\tgwa_type = ipv6_addr_type(gw_addr);\n\n\t\tif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\n\t\t\tstruct rt6_info *grt;\n\n\t\t\t/* IPv6 strictly inhibits using not link-local\n\t\t\t   addresses as nexthop address.\n\t\t\t   Otherwise, router will not able to send redirects.\n\t\t\t   It is very good, but in some (rare!) circumstances\n\t\t\t   (SIT, PtP, NBMA NOARP links) it is handy to allow\n\t\t\t   some exceptions. --ANK\n\t\t\t */\n\t\t\terr = -EINVAL;\n\t\t\tif (!(gwa_type & IPV6_ADDR_UNICAST))\n\t\t\t\tgoto out;\n\n\t\t\tgrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\n\n\t\t\terr = -EHOSTUNREACH;\n\t\t\tif (!grt)\n\t\t\t\tgoto out;\n\t\t\tif (dev) {\n\t\t\t\tif (dev != grt->dst.dev) {\n\t\t\t\t\tip6_rt_put(grt);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev = grt->dst.dev;\n\t\t\t\tidev = grt->rt6i_idev;\n\t\t\t\tdev_hold(dev);\n\t\t\t\tin6_dev_hold(grt->rt6i_idev);\n\t\t\t}\n\t\t\tif (!(grt->rt6i_flags & RTF_GATEWAY))\n\t\t\t\terr = 0;\n\t\t\tip6_rt_put(grt);\n\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\terr = -EINVAL;\n\t\tif (!dev || (dev->flags & IFF_LOOPBACK))\n\t\t\tgoto out;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\n\t\tif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\trt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\n\t\trt->rt6i_prefsrc.plen = 128;\n\t} else\n\t\trt->rt6i_prefsrc.plen = 0;\n\n\trt->rt6i_flags = cfg->fc_flags;\n\ninstall_route:\n\tif (cfg->fc_mx) {\n\t\tstruct nlattr *nla;\n\t\tint remaining;\n\n\t\tnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\n\t\t\tint type = nla_type(nla);\n\n\t\t\tif (type) {\n\t\t\t\tif (type > RTAX_MAX) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tdst_metric_set(&rt->dst, type, nla_get_u32(nla));\n\t\t\t}\n\t\t}\n\t}\n\n\trt->dst.dev = dev;\n\trt->rt6i_idev = idev;\n\trt->rt6i_table = table;\n\n\tcfg->fc_nlinfo.nl_net = dev_net(dev);\n\n\treturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\n\nout:\n\tif (dev)\n\t\tdev_put(dev);\n\tif (idev)\n\t\tin6_dev_put(idev);\n\tif (rt)\n\t\tdst_free(&rt->dst);\n\treturn err;\n}",
        "code_after_change": "int ip6_route_add(struct fib6_config *cfg)\n{\n\tint err;\n\tstruct net *net = cfg->fc_nlinfo.nl_net;\n\tstruct rt6_info *rt = NULL;\n\tstruct net_device *dev = NULL;\n\tstruct inet6_dev *idev = NULL;\n\tstruct fib6_table *table;\n\tint addr_type;\n\n\tif (cfg->fc_dst_len > 128 || cfg->fc_src_len > 128)\n\t\treturn -EINVAL;\n#ifndef CONFIG_IPV6_SUBTREES\n\tif (cfg->fc_src_len)\n\t\treturn -EINVAL;\n#endif\n\tif (cfg->fc_ifindex) {\n\t\terr = -ENODEV;\n\t\tdev = dev_get_by_index(net, cfg->fc_ifindex);\n\t\tif (!dev)\n\t\t\tgoto out;\n\t\tidev = in6_dev_get(dev);\n\t\tif (!idev)\n\t\t\tgoto out;\n\t}\n\n\tif (cfg->fc_metric == 0)\n\t\tcfg->fc_metric = IP6_RT_PRIO_USER;\n\n\terr = -ENOBUFS;\n\tif (cfg->fc_nlinfo.nlh &&\n\t    !(cfg->fc_nlinfo.nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\ttable = fib6_get_table(net, cfg->fc_table);\n\t\tif (!table) {\n\t\t\tpr_warn(\"NLM_F_CREATE should be specified when creating new route\\n\");\n\t\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t\t}\n\t} else {\n\t\ttable = fib6_new_table(net, cfg->fc_table);\n\t}\n\n\tif (!table)\n\t\tgoto out;\n\n\trt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);\n\n\tif (!rt) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (cfg->fc_flags & RTF_EXPIRES)\n\t\trt6_set_expires(rt, jiffies +\n\t\t\t\tclock_t_to_jiffies(cfg->fc_expires));\n\telse\n\t\trt6_clean_expires(rt);\n\n\tif (cfg->fc_protocol == RTPROT_UNSPEC)\n\t\tcfg->fc_protocol = RTPROT_BOOT;\n\trt->rt6i_protocol = cfg->fc_protocol;\n\n\taddr_type = ipv6_addr_type(&cfg->fc_dst);\n\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\trt->dst.input = ip6_mc_input;\n\telse if (cfg->fc_flags & RTF_LOCAL)\n\t\trt->dst.input = ip6_input;\n\telse\n\t\trt->dst.input = ip6_forward;\n\n\trt->dst.output = ip6_output;\n\n\tipv6_addr_prefix(&rt->rt6i_dst.addr, &cfg->fc_dst, cfg->fc_dst_len);\n\trt->rt6i_dst.plen = cfg->fc_dst_len;\n\tif (rt->rt6i_dst.plen == 128)\n\t       rt->dst.flags |= DST_HOST;\n\n\tif (!(rt->dst.flags & DST_HOST) && cfg->fc_mx) {\n\t\tu32 *metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);\n\t\tif (!metrics) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tdst_init_metrics(&rt->dst, metrics, 0);\n\t}\n#ifdef CONFIG_IPV6_SUBTREES\n\tipv6_addr_prefix(&rt->rt6i_src.addr, &cfg->fc_src, cfg->fc_src_len);\n\trt->rt6i_src.plen = cfg->fc_src_len;\n#endif\n\n\trt->rt6i_metric = cfg->fc_metric;\n\n\t/* We cannot add true routes via loopback here,\n\t   they would result in kernel looping; promote them to reject routes\n\t */\n\tif ((cfg->fc_flags & RTF_REJECT) ||\n\t    (dev && (dev->flags & IFF_LOOPBACK) &&\n\t     !(addr_type & IPV6_ADDR_LOOPBACK) &&\n\t     !(cfg->fc_flags & RTF_LOCAL))) {\n\t\t/* hold loopback dev/idev if we haven't done so. */\n\t\tif (dev != net->loopback_dev) {\n\t\t\tif (dev) {\n\t\t\t\tdev_put(dev);\n\t\t\t\tin6_dev_put(idev);\n\t\t\t}\n\t\t\tdev = net->loopback_dev;\n\t\t\tdev_hold(dev);\n\t\t\tidev = in6_dev_get(dev);\n\t\t\tif (!idev) {\n\t\t\t\terr = -ENODEV;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trt->rt6i_flags = RTF_REJECT|RTF_NONEXTHOP;\n\t\tswitch (cfg->fc_type) {\n\t\tcase RTN_BLACKHOLE:\n\t\t\trt->dst.error = -EINVAL;\n\t\t\trt->dst.output = dst_discard;\n\t\t\trt->dst.input = dst_discard;\n\t\t\tbreak;\n\t\tcase RTN_PROHIBIT:\n\t\t\trt->dst.error = -EACCES;\n\t\t\trt->dst.output = ip6_pkt_prohibit_out;\n\t\t\trt->dst.input = ip6_pkt_prohibit;\n\t\t\tbreak;\n\t\tcase RTN_THROW:\n\t\tdefault:\n\t\t\trt->dst.error = (cfg->fc_type == RTN_THROW) ? -EAGAIN\n\t\t\t\t\t: -ENETUNREACH;\n\t\t\trt->dst.output = ip6_pkt_discard_out;\n\t\t\trt->dst.input = ip6_pkt_discard;\n\t\t\tbreak;\n\t\t}\n\t\tgoto install_route;\n\t}\n\n\tif (cfg->fc_flags & RTF_GATEWAY) {\n\t\tconst struct in6_addr *gw_addr;\n\t\tint gwa_type;\n\n\t\tgw_addr = &cfg->fc_gateway;\n\t\trt->rt6i_gateway = *gw_addr;\n\t\tgwa_type = ipv6_addr_type(gw_addr);\n\n\t\tif (gwa_type != (IPV6_ADDR_LINKLOCAL|IPV6_ADDR_UNICAST)) {\n\t\t\tstruct rt6_info *grt;\n\n\t\t\t/* IPv6 strictly inhibits using not link-local\n\t\t\t   addresses as nexthop address.\n\t\t\t   Otherwise, router will not able to send redirects.\n\t\t\t   It is very good, but in some (rare!) circumstances\n\t\t\t   (SIT, PtP, NBMA NOARP links) it is handy to allow\n\t\t\t   some exceptions. --ANK\n\t\t\t */\n\t\t\terr = -EINVAL;\n\t\t\tif (!(gwa_type & IPV6_ADDR_UNICAST))\n\t\t\t\tgoto out;\n\n\t\t\tgrt = rt6_lookup(net, gw_addr, NULL, cfg->fc_ifindex, 1);\n\n\t\t\terr = -EHOSTUNREACH;\n\t\t\tif (!grt)\n\t\t\t\tgoto out;\n\t\t\tif (dev) {\n\t\t\t\tif (dev != grt->dst.dev) {\n\t\t\t\t\tip6_rt_put(grt);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev = grt->dst.dev;\n\t\t\t\tidev = grt->rt6i_idev;\n\t\t\t\tdev_hold(dev);\n\t\t\t\tin6_dev_hold(grt->rt6i_idev);\n\t\t\t}\n\t\t\tif (!(grt->rt6i_flags & RTF_GATEWAY))\n\t\t\t\terr = 0;\n\t\t\tip6_rt_put(grt);\n\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\terr = -EINVAL;\n\t\tif (!dev || (dev->flags & IFF_LOOPBACK))\n\t\t\tgoto out;\n\t}\n\n\terr = -ENODEV;\n\tif (!dev)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(&cfg->fc_prefsrc)) {\n\t\tif (!ipv6_chk_addr(net, &cfg->fc_prefsrc, dev, 0)) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\trt->rt6i_prefsrc.addr = cfg->fc_prefsrc;\n\t\trt->rt6i_prefsrc.plen = 128;\n\t} else\n\t\trt->rt6i_prefsrc.plen = 0;\n\n\trt->rt6i_flags = cfg->fc_flags;\n\ninstall_route:\n\tif (cfg->fc_mx) {\n\t\tstruct nlattr *nla;\n\t\tint remaining;\n\n\t\tnla_for_each_attr(nla, cfg->fc_mx, cfg->fc_mx_len, remaining) {\n\t\t\tint type = nla_type(nla);\n\n\t\t\tif (type) {\n\t\t\t\tif (type > RTAX_MAX) {\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tdst_metric_set(&rt->dst, type, nla_get_u32(nla));\n\t\t\t}\n\t\t}\n\t}\n\n\trt->dst.dev = dev;\n\trt->rt6i_idev = idev;\n\trt->rt6i_table = table;\n\n\tcfg->fc_nlinfo.nl_net = dev_net(dev);\n\n\treturn __ip6_ins_rt(rt, &cfg->fc_nlinfo);\n\nout:\n\tif (dev)\n\t\tdev_put(dev);\n\tif (idev)\n\t\tin6_dev_put(idev);\n\tif (rt)\n\t\tdst_free(&rt->dst);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,7 +42,7 @@\n \tif (!table)\n \t\tgoto out;\n \n-\trt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);\n+\trt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);\n \n \tif (!rt) {\n \t\terr = -ENOMEM;",
        "function_modified_lines": {
            "added": [
                "\trt = ip6_dst_alloc(net, NULL, (cfg->fc_flags & RTF_ADDRCONF) ? 0 : DST_NOCOUNT, table);"
            ],
            "deleted": [
                "\trt = ip6_dst_alloc(net, NULL, DST_NOCOUNT, table);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The ip6_route_add function in net/ipv6/route.c in the Linux kernel through 3.13.6 does not properly count the addition of routes, which allows remote attackers to cause a denial of service (memory consumption) via a flood of ICMPv6 Router Advertisement packets.",
        "id": 480
    },
    {
        "cve_id": "CVE-2017-16913",
        "code_before_change": "static void stub_recv_cmd_submit(struct stub_device *sdev,\n\t\t\t\t struct usbip_header *pdu)\n{\n\tint ret;\n\tstruct stub_priv *priv;\n\tstruct usbip_device *ud = &sdev->ud;\n\tstruct usb_device *udev = sdev->udev;\n\tint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);\n\n\tif (pipe == -1)\n\t\treturn;\n\n\tpriv = stub_priv_alloc(sdev, pdu);\n\tif (!priv)\n\t\treturn;\n\n\t/* setup a urb */\n\tif (usb_pipeisoc(pipe))\n\t\tpriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\n\t\t\t\t\t  GFP_KERNEL);\n\telse\n\t\tpriv->urb = usb_alloc_urb(0, GFP_KERNEL);\n\n\tif (!priv->urb) {\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* allocate urb transfer buffer, if needed */\n\tif (pdu->u.cmd_submit.transfer_buffer_length > 0) {\n\t\tpriv->urb->transfer_buffer =\n\t\t\tkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\n\t\t\t\tGFP_KERNEL);\n\t\tif (!priv->urb->transfer_buffer) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* copy urb setup packet */\n\tpriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->urb->setup_packet) {\n\t\tdev_err(&udev->dev, \"allocate setup_packet\\n\");\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* set other members from the base header of pdu */\n\tpriv->urb->context                = (void *) priv;\n\tpriv->urb->dev                    = udev;\n\tpriv->urb->pipe                   = pipe;\n\tpriv->urb->complete               = stub_complete;\n\n\tusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\n\n\n\tif (usbip_recv_xbuff(ud, priv->urb) < 0)\n\t\treturn;\n\n\tif (usbip_recv_iso(ud, priv->urb) < 0)\n\t\treturn;\n\n\t/* no need to submit an intercepted request, but harmless? */\n\ttweak_special_requests(priv->urb);\n\n\tmasking_bogus_flags(priv->urb);\n\t/* urb is now ready to submit */\n\tret = usb_submit_urb(priv->urb, GFP_KERNEL);\n\n\tif (ret == 0)\n\t\tusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\n\t\t\t\t  pdu->base.seqnum);\n\telse {\n\t\tdev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\n\t\tusbip_dump_header(pdu);\n\t\tusbip_dump_urb(priv->urb);\n\n\t\t/*\n\t\t * Pessimistic.\n\t\t * This connection will be discarded.\n\t\t */\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n\t}\n\n\tusbip_dbg_stub_rx(\"Leave\\n\");\n}",
        "code_after_change": "static void stub_recv_cmd_submit(struct stub_device *sdev,\n\t\t\t\t struct usbip_header *pdu)\n{\n\tint ret;\n\tstruct stub_priv *priv;\n\tstruct usbip_device *ud = &sdev->ud;\n\tstruct usb_device *udev = sdev->udev;\n\tint pipe = get_pipe(sdev, pdu);\n\n\tif (pipe == -1)\n\t\treturn;\n\n\tpriv = stub_priv_alloc(sdev, pdu);\n\tif (!priv)\n\t\treturn;\n\n\t/* setup a urb */\n\tif (usb_pipeisoc(pipe))\n\t\tpriv->urb = usb_alloc_urb(pdu->u.cmd_submit.number_of_packets,\n\t\t\t\t\t  GFP_KERNEL);\n\telse\n\t\tpriv->urb = usb_alloc_urb(0, GFP_KERNEL);\n\n\tif (!priv->urb) {\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* allocate urb transfer buffer, if needed */\n\tif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&\n\t    pdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {\n\t\tpriv->urb->transfer_buffer =\n\t\t\tkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\n\t\t\t\tGFP_KERNEL);\n\t\tif (!priv->urb->transfer_buffer) {\n\t\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* copy urb setup packet */\n\tpriv->urb->setup_packet = kmemdup(&pdu->u.cmd_submit.setup, 8,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->urb->setup_packet) {\n\t\tdev_err(&udev->dev, \"allocate setup_packet\\n\");\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_MALLOC);\n\t\treturn;\n\t}\n\n\t/* set other members from the base header of pdu */\n\tpriv->urb->context                = (void *) priv;\n\tpriv->urb->dev                    = udev;\n\tpriv->urb->pipe                   = pipe;\n\tpriv->urb->complete               = stub_complete;\n\n\tusbip_pack_pdu(pdu, priv->urb, USBIP_CMD_SUBMIT, 0);\n\n\n\tif (usbip_recv_xbuff(ud, priv->urb) < 0)\n\t\treturn;\n\n\tif (usbip_recv_iso(ud, priv->urb) < 0)\n\t\treturn;\n\n\t/* no need to submit an intercepted request, but harmless? */\n\ttweak_special_requests(priv->urb);\n\n\tmasking_bogus_flags(priv->urb);\n\t/* urb is now ready to submit */\n\tret = usb_submit_urb(priv->urb, GFP_KERNEL);\n\n\tif (ret == 0)\n\t\tusbip_dbg_stub_rx(\"submit urb ok, seqnum %u\\n\",\n\t\t\t\t  pdu->base.seqnum);\n\telse {\n\t\tdev_err(&udev->dev, \"submit_urb error, %d\\n\", ret);\n\t\tusbip_dump_header(pdu);\n\t\tusbip_dump_urb(priv->urb);\n\n\t\t/*\n\t\t * Pessimistic.\n\t\t * This connection will be discarded.\n\t\t */\n\t\tusbip_event_add(ud, SDEV_EVENT_ERROR_SUBMIT);\n\t}\n\n\tusbip_dbg_stub_rx(\"Leave\\n\");\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct stub_priv *priv;\n \tstruct usbip_device *ud = &sdev->ud;\n \tstruct usb_device *udev = sdev->udev;\n-\tint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);\n+\tint pipe = get_pipe(sdev, pdu);\n \n \tif (pipe == -1)\n \t\treturn;\n@@ -27,7 +27,8 @@\n \t}\n \n \t/* allocate urb transfer buffer, if needed */\n-\tif (pdu->u.cmd_submit.transfer_buffer_length > 0) {\n+\tif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&\n+\t    pdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {\n \t\tpriv->urb->transfer_buffer =\n \t\t\tkzalloc(pdu->u.cmd_submit.transfer_buffer_length,\n \t\t\t\tGFP_KERNEL);",
        "function_modified_lines": {
            "added": [
                "\tint pipe = get_pipe(sdev, pdu);",
                "\tif (pdu->u.cmd_submit.transfer_buffer_length > 0 &&",
                "\t    pdu->u.cmd_submit.transfer_buffer_length <= INT_MAX) {"
            ],
            "deleted": [
                "\tint pipe = get_pipe(sdev, pdu->base.ep, pdu->base.direction);",
                "\tif (pdu->u.cmd_submit.transfer_buffer_length > 0) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The \"stub_recv_cmd_submit()\" function (drivers/usb/usbip/stub_rx.c) in the Linux Kernel before version 4.14.8, 4.9.71, and 4.4.114 when handling CMD_SUBMIT packets allows attackers to cause a denial of service (arbitrary memory allocation) via a specially crafted USB over IP packet.",
        "id": 1350
    },
    {
        "cve_id": "CVE-2017-5547",
        "code_before_change": "static enum led_brightness k90_backlight_get(struct led_classdev *led_cdev)\n{\n\tint ret;\n\tstruct k90_led *led = container_of(led_cdev, struct k90_led, cdev);\n\tstruct device *dev = led->cdev.dev->parent;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint brightness;\n\tchar data[8];\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\treturn -EIO;\n\t}\n\tbrightness = data[4];\n\tif (brightness < 0 || brightness > 3) {\n\t\tdev_warn(dev,\n\t\t\t \"Read invalid backlight brightness: %02hhx.\\n\",\n\t\t\t data[4]);\n\t\treturn -EIO;\n\t}\n\treturn brightness;\n}",
        "code_after_change": "static enum led_brightness k90_backlight_get(struct led_classdev *led_cdev)\n{\n\tint ret;\n\tstruct k90_led *led = container_of(led_cdev, struct k90_led, cdev);\n\tstruct device *dev = led->cdev.dev->parent;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint brightness;\n\tchar *data;\n\n\tdata = kmalloc(8, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tbrightness = data[4];\n\tif (brightness < 0 || brightness > 3) {\n\t\tdev_warn(dev,\n\t\t\t \"Read invalid backlight brightness: %02hhx.\\n\",\n\t\t\t data[4]);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tret = brightness;\nout:\n\tkfree(data);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,11 @@\n \tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n \tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n \tint brightness;\n-\tchar data[8];\n+\tchar *data;\n+\n+\tdata = kmalloc(8, GFP_KERNEL);\n+\tif (!data)\n+\t\treturn -ENOMEM;\n \n \tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n \t\t\t      K90_REQUEST_STATUS,\n@@ -16,14 +20,20 @@\n \tif (ret < 0) {\n \t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n \t\t\t ret);\n-\t\treturn -EIO;\n+\t\tret = -EIO;\n+\t\tgoto out;\n \t}\n \tbrightness = data[4];\n \tif (brightness < 0 || brightness > 3) {\n \t\tdev_warn(dev,\n \t\t\t \"Read invalid backlight brightness: %02hhx.\\n\",\n \t\t\t data[4]);\n-\t\treturn -EIO;\n+\t\tret = -EIO;\n+\t\tgoto out;\n \t}\n-\treturn brightness;\n+\tret = brightness;\n+out:\n+\tkfree(data);\n+\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tchar *data;",
                "",
                "\tdata = kmalloc(8, GFP_KERNEL);",
                "\tif (!data)",
                "\t\treturn -ENOMEM;",
                "\t\tret = -EIO;",
                "\t\tgoto out;",
                "\t\tret = -EIO;",
                "\t\tgoto out;",
                "\tret = brightness;",
                "out:",
                "\tkfree(data);",
                "",
                "\treturn ret;"
            ],
            "deleted": [
                "\tchar data[8];",
                "\t\treturn -EIO;",
                "\t\treturn -EIO;",
                "\treturn brightness;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-corsair.c in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1461
    },
    {
        "cve_id": "CVE-2016-8632",
        "code_before_change": "int tipc_enable_l2_media(struct net *net, struct tipc_bearer *b,\n\t\t\t struct nlattr *attr[])\n{\n\tstruct net_device *dev;\n\tchar *driver_name = strchr((const char *)b->name, ':') + 1;\n\n\t/* Find device with specified name */\n\tdev = dev_get_by_name(net, driver_name);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\t/* Associate TIPC bearer with L2 bearer */\n\trcu_assign_pointer(b->media_ptr, dev);\n\tmemset(&b->bcast_addr, 0, sizeof(b->bcast_addr));\n\tmemcpy(b->bcast_addr.value, dev->broadcast, b->media->hwaddr_len);\n\tb->bcast_addr.media_id = b->media->type_id;\n\tb->bcast_addr.broadcast = 1;\n\tb->mtu = dev->mtu;\n\tb->media->raw2addr(b, &b->addr, (char *)dev->dev_addr);\n\trcu_assign_pointer(dev->tipc_ptr, b);\n\treturn 0;\n}",
        "code_after_change": "int tipc_enable_l2_media(struct net *net, struct tipc_bearer *b,\n\t\t\t struct nlattr *attr[])\n{\n\tstruct net_device *dev;\n\tchar *driver_name = strchr((const char *)b->name, ':') + 1;\n\n\t/* Find device with specified name */\n\tdev = dev_get_by_name(net, driver_name);\n\tif (!dev)\n\t\treturn -ENODEV;\n\tif (tipc_mtu_bad(dev, 0)) {\n\t\tdev_put(dev);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Associate TIPC bearer with L2 bearer */\n\trcu_assign_pointer(b->media_ptr, dev);\n\tmemset(&b->bcast_addr, 0, sizeof(b->bcast_addr));\n\tmemcpy(b->bcast_addr.value, dev->broadcast, b->media->hwaddr_len);\n\tb->bcast_addr.media_id = b->media->type_id;\n\tb->bcast_addr.broadcast = 1;\n\tb->mtu = dev->mtu;\n\tb->media->raw2addr(b, &b->addr, (char *)dev->dev_addr);\n\trcu_assign_pointer(dev->tipc_ptr, b);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,10 @@\n \tdev = dev_get_by_name(net, driver_name);\n \tif (!dev)\n \t\treturn -ENODEV;\n+\tif (tipc_mtu_bad(dev, 0)) {\n+\t\tdev_put(dev);\n+\t\treturn -EINVAL;\n+\t}\n \n \t/* Associate TIPC bearer with L2 bearer */\n \trcu_assign_pointer(b->media_ptr, dev);",
        "function_modified_lines": {
            "added": [
                "\tif (tipc_mtu_bad(dev, 0)) {",
                "\t\tdev_put(dev);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264",
            "CWE-119"
        ],
        "cve_description": "The tipc_msg_build function in net/tipc/msg.c in the Linux kernel through 4.8.11 does not validate the relationship between the minimum fragment length and the maximum packet size, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) by leveraging the CAP_NET_ADMIN capability.",
        "id": 1121
    },
    {
        "cve_id": "CVE-2018-1120",
        "code_before_change": "static ssize_t environ_read(struct file *file, char __user *buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tchar *page;\n\tunsigned long src = *ppos;\n\tint ret = 0;\n\tstruct mm_struct *mm = file->private_data;\n\tunsigned long env_start, env_end;\n\n\t/* Ensure the process spawned far enough to have an environment. */\n\tif (!mm || !mm->env_end)\n\t\treturn 0;\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tret = 0;\n\tif (!mmget_not_zero(mm))\n\t\tgoto free;\n\n\tdown_read(&mm->mmap_sem);\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\twhile (count > 0) {\n\t\tsize_t this_len, max_len;\n\t\tint retval;\n\n\t\tif (src >= (env_end - env_start))\n\t\t\tbreak;\n\n\t\tthis_len = env_end - (env_start + src);\n\n\t\tmax_len = min_t(size_t, PAGE_SIZE, count);\n\t\tthis_len = min(max_len, this_len);\n\n\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, 0);\n\n\t\tif (retval <= 0) {\n\t\t\tret = retval;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_to_user(buf, page, retval)) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tret += retval;\n\t\tsrc += retval;\n\t\tbuf += retval;\n\t\tcount -= retval;\n\t}\n\t*ppos = src;\n\tmmput(mm);\n\nfree:\n\tfree_page((unsigned long) page);\n\treturn ret;\n}",
        "code_after_change": "static ssize_t environ_read(struct file *file, char __user *buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tchar *page;\n\tunsigned long src = *ppos;\n\tint ret = 0;\n\tstruct mm_struct *mm = file->private_data;\n\tunsigned long env_start, env_end;\n\n\t/* Ensure the process spawned far enough to have an environment. */\n\tif (!mm || !mm->env_end)\n\t\treturn 0;\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tret = 0;\n\tif (!mmget_not_zero(mm))\n\t\tgoto free;\n\n\tdown_read(&mm->mmap_sem);\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\twhile (count > 0) {\n\t\tsize_t this_len, max_len;\n\t\tint retval;\n\n\t\tif (src >= (env_end - env_start))\n\t\t\tbreak;\n\n\t\tthis_len = env_end - (env_start + src);\n\n\t\tmax_len = min_t(size_t, PAGE_SIZE, count);\n\t\tthis_len = min(max_len, this_len);\n\n\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, FOLL_ANON);\n\n\t\tif (retval <= 0) {\n\t\t\tret = retval;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_to_user(buf, page, retval)) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tret += retval;\n\t\tsrc += retval;\n\t\tbuf += retval;\n\t\tcount -= retval;\n\t}\n\t*ppos = src;\n\tmmput(mm);\n\nfree:\n\tfree_page((unsigned long) page);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -36,7 +36,7 @@\n \t\tmax_len = min_t(size_t, PAGE_SIZE, count);\n \t\tthis_len = min(max_len, this_len);\n \n-\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, 0);\n+\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, FOLL_ANON);\n \n \t\tif (retval <= 0) {\n \t\t\tret = retval;",
        "function_modified_lines": {
            "added": [
                "\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, FOLL_ANON);"
            ],
            "deleted": [
                "\t\tretval = access_remote_vm(mm, (env_start + src), page, this_len, 0);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A flaw was found affecting the Linux kernel before version 4.17. By mmap()ing a FUSE-backed file onto a process's memory containing command line arguments (or environment strings), an attacker can cause utilities from psutils or procps (such as ps, w) or any other program which makes a read() call to the /proc/<pid>/cmdline (or /proc/<pid>/environ) files to block indefinitely (denial of service) or for some controlled time (as a synchronization primitive for other attacks).",
        "id": 1636
    },
    {
        "cve_id": "CVE-2018-1120",
        "code_before_change": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\n\t\t\t\t     size_t _count, loff_t *pos)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tchar *page;\n\tunsigned long count = _count;\n\tunsigned long arg_start, arg_end, env_start, env_end;\n\tunsigned long len1, len2, len;\n\tunsigned long p;\n\tchar c;\n\tssize_t rv;\n\n\tBUG_ON(*pos < 0);\n\n\ttsk = get_proc_task(file_inode(file));\n\tif (!tsk)\n\t\treturn -ESRCH;\n\tmm = get_task_mm(tsk);\n\tput_task_struct(tsk);\n\tif (!mm)\n\t\treturn 0;\n\t/* Check if process spawned far enough to have cmdline. */\n\tif (!mm->env_end) {\n\t\trv = 0;\n\t\tgoto out_mmput;\n\t}\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page) {\n\t\trv = -ENOMEM;\n\t\tgoto out_mmput;\n\t}\n\n\tdown_read(&mm->mmap_sem);\n\targ_start = mm->arg_start;\n\targ_end = mm->arg_end;\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\tBUG_ON(arg_start > arg_end);\n\tBUG_ON(env_start > env_end);\n\n\tlen1 = arg_end - arg_start;\n\tlen2 = env_end - env_start;\n\n\t/* Empty ARGV. */\n\tif (len1 == 0) {\n\t\trv = 0;\n\t\tgoto out_free_page;\n\t}\n\t/*\n\t * Inherently racy -- command line shares address space\n\t * with code and data.\n\t */\n\trv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);\n\tif (rv <= 0)\n\t\tgoto out_free_page;\n\n\trv = 0;\n\n\tif (c == '\\0') {\n\t\t/* Command line (set of strings) occupies whole ARGV. */\n\t\tif (len1 <= *pos)\n\t\t\tgoto out_free_page;\n\n\t\tp = arg_start + *pos;\n\t\tlen = len1 - *pos;\n\t\twhile (count > 0 && len > 0) {\n\t\t\tunsigned int _count;\n\t\t\tint nr_read;\n\n\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n\t\t\tif (nr_read < 0)\n\t\t\t\trv = nr_read;\n\t\t\tif (nr_read <= 0)\n\t\t\t\tgoto out_free_page;\n\n\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\trv = -EFAULT;\n\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\tp\t+= nr_read;\n\t\t\tlen\t-= nr_read;\n\t\t\tbuf\t+= nr_read;\n\t\t\tcount\t-= nr_read;\n\t\t\trv\t+= nr_read;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Command line (1 string) occupies ARGV and\n\t\t * extends into ENVP.\n\t\t */\n\t\tstruct {\n\t\t\tunsigned long p;\n\t\t\tunsigned long len;\n\t\t} cmdline[2] = {\n\t\t\t{ .p = arg_start, .len = len1 },\n\t\t\t{ .p = env_start, .len = len2 },\n\t\t};\n\t\tloff_t pos1 = *pos;\n\t\tunsigned int i;\n\n\t\ti = 0;\n\t\twhile (i < 2 && pos1 >= cmdline[i].len) {\n\t\t\tpos1 -= cmdline[i].len;\n\t\t\ti++;\n\t\t}\n\t\twhile (i < 2) {\n\t\t\tp = cmdline[i].p + pos1;\n\t\t\tlen = cmdline[i].len - pos1;\n\t\t\twhile (count > 0 && len > 0) {\n\t\t\t\tunsigned int _count, l;\n\t\t\t\tint nr_read;\n\t\t\t\tbool final;\n\n\t\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n\t\t\t\tif (nr_read < 0)\n\t\t\t\t\trv = nr_read;\n\t\t\t\tif (nr_read <= 0)\n\t\t\t\t\tgoto out_free_page;\n\n\t\t\t\t/*\n\t\t\t\t * Command line can be shorter than whole ARGV\n\t\t\t\t * even if last \"marker\" byte says it is not.\n\t\t\t\t */\n\t\t\t\tfinal = false;\n\t\t\t\tl = strnlen(page, nr_read);\n\t\t\t\tif (l < nr_read) {\n\t\t\t\t\tnr_read = l;\n\t\t\t\t\tfinal = true;\n\t\t\t\t}\n\n\t\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\t\trv = -EFAULT;\n\t\t\t\t\tgoto out_free_page;\n\t\t\t\t}\n\n\t\t\t\tp\t+= nr_read;\n\t\t\t\tlen\t-= nr_read;\n\t\t\t\tbuf\t+= nr_read;\n\t\t\t\tcount\t-= nr_read;\n\t\t\t\trv\t+= nr_read;\n\n\t\t\t\tif (final)\n\t\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\t/* Only first chunk can be read partially. */\n\t\t\tpos1 = 0;\n\t\t\ti++;\n\t\t}\n\t}\n\nout_free_page:\n\tfree_page((unsigned long)page);\nout_mmput:\n\tmmput(mm);\n\tif (rv > 0)\n\t\t*pos += rv;\n\treturn rv;\n}",
        "code_after_change": "static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,\n\t\t\t\t     size_t _count, loff_t *pos)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tchar *page;\n\tunsigned long count = _count;\n\tunsigned long arg_start, arg_end, env_start, env_end;\n\tunsigned long len1, len2, len;\n\tunsigned long p;\n\tchar c;\n\tssize_t rv;\n\n\tBUG_ON(*pos < 0);\n\n\ttsk = get_proc_task(file_inode(file));\n\tif (!tsk)\n\t\treturn -ESRCH;\n\tmm = get_task_mm(tsk);\n\tput_task_struct(tsk);\n\tif (!mm)\n\t\treturn 0;\n\t/* Check if process spawned far enough to have cmdline. */\n\tif (!mm->env_end) {\n\t\trv = 0;\n\t\tgoto out_mmput;\n\t}\n\n\tpage = (char *)__get_free_page(GFP_KERNEL);\n\tif (!page) {\n\t\trv = -ENOMEM;\n\t\tgoto out_mmput;\n\t}\n\n\tdown_read(&mm->mmap_sem);\n\targ_start = mm->arg_start;\n\targ_end = mm->arg_end;\n\tenv_start = mm->env_start;\n\tenv_end = mm->env_end;\n\tup_read(&mm->mmap_sem);\n\n\tBUG_ON(arg_start > arg_end);\n\tBUG_ON(env_start > env_end);\n\n\tlen1 = arg_end - arg_start;\n\tlen2 = env_end - env_start;\n\n\t/* Empty ARGV. */\n\tif (len1 == 0) {\n\t\trv = 0;\n\t\tgoto out_free_page;\n\t}\n\t/*\n\t * Inherently racy -- command line shares address space\n\t * with code and data.\n\t */\n\trv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);\n\tif (rv <= 0)\n\t\tgoto out_free_page;\n\n\trv = 0;\n\n\tif (c == '\\0') {\n\t\t/* Command line (set of strings) occupies whole ARGV. */\n\t\tif (len1 <= *pos)\n\t\t\tgoto out_free_page;\n\n\t\tp = arg_start + *pos;\n\t\tlen = len1 - *pos;\n\t\twhile (count > 0 && len > 0) {\n\t\t\tunsigned int _count;\n\t\t\tint nr_read;\n\n\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n\t\t\tif (nr_read < 0)\n\t\t\t\trv = nr_read;\n\t\t\tif (nr_read <= 0)\n\t\t\t\tgoto out_free_page;\n\n\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\trv = -EFAULT;\n\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\tp\t+= nr_read;\n\t\t\tlen\t-= nr_read;\n\t\t\tbuf\t+= nr_read;\n\t\t\tcount\t-= nr_read;\n\t\t\trv\t+= nr_read;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Command line (1 string) occupies ARGV and\n\t\t * extends into ENVP.\n\t\t */\n\t\tstruct {\n\t\t\tunsigned long p;\n\t\t\tunsigned long len;\n\t\t} cmdline[2] = {\n\t\t\t{ .p = arg_start, .len = len1 },\n\t\t\t{ .p = env_start, .len = len2 },\n\t\t};\n\t\tloff_t pos1 = *pos;\n\t\tunsigned int i;\n\n\t\ti = 0;\n\t\twhile (i < 2 && pos1 >= cmdline[i].len) {\n\t\t\tpos1 -= cmdline[i].len;\n\t\t\ti++;\n\t\t}\n\t\twhile (i < 2) {\n\t\t\tp = cmdline[i].p + pos1;\n\t\t\tlen = cmdline[i].len - pos1;\n\t\t\twhile (count > 0 && len > 0) {\n\t\t\t\tunsigned int _count, l;\n\t\t\t\tint nr_read;\n\t\t\t\tbool final;\n\n\t\t\t\t_count = min3(count, len, PAGE_SIZE);\n\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n\t\t\t\tif (nr_read < 0)\n\t\t\t\t\trv = nr_read;\n\t\t\t\tif (nr_read <= 0)\n\t\t\t\t\tgoto out_free_page;\n\n\t\t\t\t/*\n\t\t\t\t * Command line can be shorter than whole ARGV\n\t\t\t\t * even if last \"marker\" byte says it is not.\n\t\t\t\t */\n\t\t\t\tfinal = false;\n\t\t\t\tl = strnlen(page, nr_read);\n\t\t\t\tif (l < nr_read) {\n\t\t\t\t\tnr_read = l;\n\t\t\t\t\tfinal = true;\n\t\t\t\t}\n\n\t\t\t\tif (copy_to_user(buf, page, nr_read)) {\n\t\t\t\t\trv = -EFAULT;\n\t\t\t\t\tgoto out_free_page;\n\t\t\t\t}\n\n\t\t\t\tp\t+= nr_read;\n\t\t\t\tlen\t-= nr_read;\n\t\t\t\tbuf\t+= nr_read;\n\t\t\t\tcount\t-= nr_read;\n\t\t\t\trv\t+= nr_read;\n\n\t\t\t\tif (final)\n\t\t\t\t\tgoto out_free_page;\n\t\t\t}\n\n\t\t\t/* Only first chunk can be read partially. */\n\t\t\tpos1 = 0;\n\t\t\ti++;\n\t\t}\n\t}\n\nout_free_page:\n\tfree_page((unsigned long)page);\nout_mmput:\n\tmmput(mm);\n\tif (rv > 0)\n\t\t*pos += rv;\n\treturn rv;\n}",
        "patch": "--- code before\n+++ code after\n@@ -54,7 +54,7 @@\n \t * Inherently racy -- command line shares address space\n \t * with code and data.\n \t */\n-\trv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);\n+\trv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);\n \tif (rv <= 0)\n \t\tgoto out_free_page;\n \n@@ -72,7 +72,7 @@\n \t\t\tint nr_read;\n \n \t\t\t_count = min3(count, len, PAGE_SIZE);\n-\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n+\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n \t\t\tif (nr_read < 0)\n \t\t\t\trv = nr_read;\n \t\t\tif (nr_read <= 0)\n@@ -118,7 +118,7 @@\n \t\t\t\tbool final;\n \n \t\t\t\t_count = min3(count, len, PAGE_SIZE);\n-\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);\n+\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);\n \t\t\t\tif (nr_read < 0)\n \t\t\t\t\trv = nr_read;\n \t\t\t\tif (nr_read <= 0)",
        "function_modified_lines": {
            "added": [
                "\trv = access_remote_vm(mm, arg_end - 1, &c, 1, FOLL_ANON);",
                "\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);",
                "\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, FOLL_ANON);"
            ],
            "deleted": [
                "\trv = access_remote_vm(mm, arg_end - 1, &c, 1, 0);",
                "\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);",
                "\t\t\t\tnr_read = access_remote_vm(mm, p, page, _count, 0);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A flaw was found affecting the Linux kernel before version 4.17. By mmap()ing a FUSE-backed file onto a process's memory containing command line arguments (or environment strings), an attacker can cause utilities from psutils or procps (such as ps, w) or any other program which makes a read() call to the /proc/<pid>/cmdline (or /proc/<pid>/environ) files to block indefinitely (denial of service) or for some controlled time (as a synchronization primitive for other attacks).",
        "id": 1635
    },
    {
        "cve_id": "CVE-2014-3182",
        "code_before_change": "static int logi_dj_raw_event(struct hid_device *hdev,\n\t\t\t     struct hid_report *report, u8 *data,\n\t\t\t     int size)\n{\n\tstruct dj_receiver_dev *djrcv_dev = hid_get_drvdata(hdev);\n\tstruct dj_report *dj_report = (struct dj_report *) data;\n\tunsigned long flags;\n\tbool report_processed = false;\n\n\tdbg_hid(\"%s, size:%d\\n\", __func__, size);\n\n\t/* Here we receive all data coming from iface 2, there are 4 cases:\n\t *\n\t * 1) Data should continue its normal processing i.e. data does not\n\t * come from the DJ collection, in which case we do nothing and\n\t * return 0, so hid-core can continue normal processing (will forward\n\t * to associated hidraw device)\n\t *\n\t * 2) Data is from DJ collection, and is intended for this driver i. e.\n\t * data contains arrival, departure, etc notifications, in which case\n\t * we queue them for delayed processing by the work queue. We return 1\n\t * to hid-core as no further processing is required from it.\n\t *\n\t * 3) Data is from DJ collection, and informs a connection change,\n\t * if the change means rf link loss, then we must send a null report\n\t * to the upper layer to discard potentially pressed keys that may be\n\t * repeated forever by the input layer. Return 1 to hid-core as no\n\t * further processing is required.\n\t *\n\t * 4) Data is from DJ collection and is an actual input event from\n\t * a paired DJ device in which case we forward it to the correct hid\n\t * device (via hid_input_report() ) and return 1 so hid-core does not do\n\t * anything else with it.\n\t */\n\n\tspin_lock_irqsave(&djrcv_dev->lock, flags);\n\tif (dj_report->report_id == REPORT_ID_DJ_SHORT) {\n\t\tswitch (dj_report->report_type) {\n\t\tcase REPORT_TYPE_NOTIF_DEVICE_PAIRED:\n\t\tcase REPORT_TYPE_NOTIF_DEVICE_UNPAIRED:\n\t\t\tlogi_dj_recv_queue_notification(djrcv_dev, dj_report);\n\t\t\tbreak;\n\t\tcase REPORT_TYPE_NOTIF_CONNECTION_STATUS:\n\t\t\tif (dj_report->report_params[CONNECTION_STATUS_PARAM_STATUS] ==\n\t\t\t    STATUS_LINKLOSS) {\n\t\t\t\tlogi_dj_recv_forward_null_report(djrcv_dev, dj_report);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlogi_dj_recv_forward_report(djrcv_dev, dj_report);\n\t\t}\n\t\treport_processed = true;\n\t}\n\tspin_unlock_irqrestore(&djrcv_dev->lock, flags);\n\n\treturn report_processed;\n}",
        "code_after_change": "static int logi_dj_raw_event(struct hid_device *hdev,\n\t\t\t     struct hid_report *report, u8 *data,\n\t\t\t     int size)\n{\n\tstruct dj_receiver_dev *djrcv_dev = hid_get_drvdata(hdev);\n\tstruct dj_report *dj_report = (struct dj_report *) data;\n\tunsigned long flags;\n\tbool report_processed = false;\n\n\tdbg_hid(\"%s, size:%d\\n\", __func__, size);\n\n\t/* Here we receive all data coming from iface 2, there are 4 cases:\n\t *\n\t * 1) Data should continue its normal processing i.e. data does not\n\t * come from the DJ collection, in which case we do nothing and\n\t * return 0, so hid-core can continue normal processing (will forward\n\t * to associated hidraw device)\n\t *\n\t * 2) Data is from DJ collection, and is intended for this driver i. e.\n\t * data contains arrival, departure, etc notifications, in which case\n\t * we queue them for delayed processing by the work queue. We return 1\n\t * to hid-core as no further processing is required from it.\n\t *\n\t * 3) Data is from DJ collection, and informs a connection change,\n\t * if the change means rf link loss, then we must send a null report\n\t * to the upper layer to discard potentially pressed keys that may be\n\t * repeated forever by the input layer. Return 1 to hid-core as no\n\t * further processing is required.\n\t *\n\t * 4) Data is from DJ collection and is an actual input event from\n\t * a paired DJ device in which case we forward it to the correct hid\n\t * device (via hid_input_report() ) and return 1 so hid-core does not do\n\t * anything else with it.\n\t */\n\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\n\t\tdev_err(&hdev->dev, \"%s: invalid device index:%d\\n\",\n\t\t\t\t__func__, dj_report->device_index);\n\t\treturn false;\n\t}\n\n\tspin_lock_irqsave(&djrcv_dev->lock, flags);\n\tif (dj_report->report_id == REPORT_ID_DJ_SHORT) {\n\t\tswitch (dj_report->report_type) {\n\t\tcase REPORT_TYPE_NOTIF_DEVICE_PAIRED:\n\t\tcase REPORT_TYPE_NOTIF_DEVICE_UNPAIRED:\n\t\t\tlogi_dj_recv_queue_notification(djrcv_dev, dj_report);\n\t\t\tbreak;\n\t\tcase REPORT_TYPE_NOTIF_CONNECTION_STATUS:\n\t\t\tif (dj_report->report_params[CONNECTION_STATUS_PARAM_STATUS] ==\n\t\t\t    STATUS_LINKLOSS) {\n\t\t\t\tlogi_dj_recv_forward_null_report(djrcv_dev, dj_report);\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlogi_dj_recv_forward_report(djrcv_dev, dj_report);\n\t\t}\n\t\treport_processed = true;\n\t}\n\tspin_unlock_irqrestore(&djrcv_dev->lock, flags);\n\n\treturn report_processed;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,6 +32,12 @@\n \t * device (via hid_input_report() ) and return 1 so hid-core does not do\n \t * anything else with it.\n \t */\n+\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||\n+\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {\n+\t\tdev_err(&hdev->dev, \"%s: invalid device index:%d\\n\",\n+\t\t\t\t__func__, dj_report->device_index);\n+\t\treturn false;\n+\t}\n \n \tspin_lock_irqsave(&djrcv_dev->lock, flags);\n \tif (dj_report->report_id == REPORT_ID_DJ_SHORT) {",
        "function_modified_lines": {
            "added": [
                "\tif ((dj_report->device_index < DJ_DEVICE_INDEX_MIN) ||",
                "\t    (dj_report->device_index > DJ_DEVICE_INDEX_MAX)) {",
                "\t\tdev_err(&hdev->dev, \"%s: invalid device index:%d\\n\",",
                "\t\t\t\t__func__, dj_report->device_index);",
                "\t\treturn false;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Array index error in the logi_dj_raw_event function in drivers/hid/hid-logitech-dj.c in the Linux kernel before 3.16.2 allows physically proximate attackers to execute arbitrary code or cause a denial of service (invalid kfree) via a crafted device that provides a malformed REPORT_TYPE_NOTIF_DEVICE_UNPAIRED value.",
        "id": 513
    },
    {
        "cve_id": "CVE-2021-22543",
        "code_before_change": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\n\t\t\t       unsigned long addr, bool *async,\n\t\t\t       bool write_fault, bool *writable,\n\t\t\t       kvm_pfn_t *p_pfn)\n{\n\tkvm_pfn_t pfn;\n\tpte_t *ptep;\n\tspinlock_t *ptl;\n\tint r;\n\n\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\tif (r) {\n\t\t/*\n\t\t * get_user_pages fails for VM_IO and VM_PFNMAP vmas and does\n\t\t * not call the fault handler, so do it here.\n\t\t */\n\t\tbool unlocked = false;\n\t\tr = fixup_user_fault(current->mm, addr,\n\t\t\t\t     (write_fault ? FAULT_FLAG_WRITE : 0),\n\t\t\t\t     &unlocked);\n\t\tif (unlocked)\n\t\t\treturn -EAGAIN;\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tif (write_fault && !pte_write(*ptep)) {\n\t\tpfn = KVM_PFN_ERR_RO_FAULT;\n\t\tgoto out;\n\t}\n\n\tif (writable)\n\t\t*writable = pte_write(*ptep);\n\tpfn = pte_pfn(*ptep);\n\n\t/*\n\t * Get a reference here because callers of *hva_to_pfn* and\n\t * *gfn_to_pfn* ultimately call kvm_release_pfn_clean on the\n\t * returned pfn.  This is only needed if the VMA has VM_MIXEDMAP\n\t * set, but the kvm_get_pfn/kvm_release_pfn_clean pair will\n\t * simply do nothing for reserved pfns.\n\t *\n\t * Whoever called remap_pfn_range is also going to call e.g.\n\t * unmap_mapping_range before the underlying pages are freed,\n\t * causing a call to our MMU notifier.\n\t */ \n\tkvm_get_pfn(pfn);\n\nout:\n\tpte_unmap_unlock(ptep, ptl);\n\t*p_pfn = pfn;\n\treturn 0;\n}",
        "code_after_change": "static int hva_to_pfn_remapped(struct vm_area_struct *vma,\n\t\t\t       unsigned long addr, bool *async,\n\t\t\t       bool write_fault, bool *writable,\n\t\t\t       kvm_pfn_t *p_pfn)\n{\n\tkvm_pfn_t pfn;\n\tpte_t *ptep;\n\tspinlock_t *ptl;\n\tint r;\n\n\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\tif (r) {\n\t\t/*\n\t\t * get_user_pages fails for VM_IO and VM_PFNMAP vmas and does\n\t\t * not call the fault handler, so do it here.\n\t\t */\n\t\tbool unlocked = false;\n\t\tr = fixup_user_fault(current->mm, addr,\n\t\t\t\t     (write_fault ? FAULT_FLAG_WRITE : 0),\n\t\t\t\t     &unlocked);\n\t\tif (unlocked)\n\t\t\treturn -EAGAIN;\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = follow_pte(vma->vm_mm, addr, &ptep, &ptl);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tif (write_fault && !pte_write(*ptep)) {\n\t\tpfn = KVM_PFN_ERR_RO_FAULT;\n\t\tgoto out;\n\t}\n\n\tif (writable)\n\t\t*writable = pte_write(*ptep);\n\tpfn = pte_pfn(*ptep);\n\n\t/*\n\t * Get a reference here because callers of *hva_to_pfn* and\n\t * *gfn_to_pfn* ultimately call kvm_release_pfn_clean on the\n\t * returned pfn.  This is only needed if the VMA has VM_MIXEDMAP\n\t * set, but the kvm_get_pfn/kvm_release_pfn_clean pair will\n\t * simply do nothing for reserved pfns.\n\t *\n\t * Whoever called remap_pfn_range is also going to call e.g.\n\t * unmap_mapping_range before the underlying pages are freed,\n\t * causing a call to our MMU notifier.\n\t *\n\t * Certain IO or PFNMAP mappings can be backed with valid\n\t * struct pages, but be allocated without refcounting e.g.,\n\t * tail pages of non-compound higher order allocations, which\n\t * would then underflow the refcount when the caller does the\n\t * required put_page. Don't allow those pages here.\n\t */ \n\tif (!kvm_try_get_pfn(pfn))\n\t\tr = -EFAULT;\n\nout:\n\tpte_unmap_unlock(ptep, ptl);\n\t*p_pfn = pfn;\n\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,11 +47,19 @@\n \t * Whoever called remap_pfn_range is also going to call e.g.\n \t * unmap_mapping_range before the underlying pages are freed,\n \t * causing a call to our MMU notifier.\n+\t *\n+\t * Certain IO or PFNMAP mappings can be backed with valid\n+\t * struct pages, but be allocated without refcounting e.g.,\n+\t * tail pages of non-compound higher order allocations, which\n+\t * would then underflow the refcount when the caller does the\n+\t * required put_page. Don't allow those pages here.\n \t */ \n-\tkvm_get_pfn(pfn);\n+\tif (!kvm_try_get_pfn(pfn))\n+\t\tr = -EFAULT;\n \n out:\n \tpte_unmap_unlock(ptep, ptl);\n \t*p_pfn = pfn;\n-\treturn 0;\n+\n+\treturn r;\n }",
        "function_modified_lines": {
            "added": [
                "\t *",
                "\t * Certain IO or PFNMAP mappings can be backed with valid",
                "\t * struct pages, but be allocated without refcounting e.g.,",
                "\t * tail pages of non-compound higher order allocations, which",
                "\t * would then underflow the refcount when the caller does the",
                "\t * required put_page. Don't allow those pages here.",
                "\tif (!kvm_try_get_pfn(pfn))",
                "\t\tr = -EFAULT;",
                "",
                "\treturn r;"
            ],
            "deleted": [
                "\tkvm_get_pfn(pfn);",
                "\treturn 0;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An issue was discovered in Linux: KVM through Improper handling of VM_IO|VM_PFNMAP vmas in KVM can bypass RO checks and can lead to pages being freed while still accessible by the VMM and guest. This allows users with the ability to start and control a VM to read/write random pages of memory and can result in local privilege escalation.",
        "id": 2880
    },
    {
        "cve_id": "CVE-2018-7566",
        "code_before_change": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *offset)\n{\n\tstruct snd_seq_client *client = file->private_data;\n\tint written = 0, len;\n\tint err = -EINVAL;\n\tstruct snd_seq_event event;\n\n\tif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\n\t\treturn -ENXIO;\n\n\t/* check client structures are in place */\n\tif (snd_BUG_ON(!client))\n\t\treturn -ENXIO;\n\t\t\n\tif (!client->accept_output || client->pool == NULL)\n\t\treturn -ENXIO;\n\n\t/* allocate the pool now if the pool is not allocated yet */ \n\tif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\n\t\tif (snd_seq_pool_init(client->pool) < 0)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* only process whole events */\n\twhile (count >= sizeof(struct snd_seq_event)) {\n\t\t/* Read in the event header from the user */\n\t\tlen = sizeof(event);\n\t\tif (copy_from_user(&event, buf, len)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tevent.source.client = client->number;\t/* fill in client number */\n\t\t/* Check for extension data length */\n\t\tif (check_event_type_and_length(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* check for special events */\n\t\tif (event.type == SNDRV_SEQ_EVENT_NONE)\n\t\t\tgoto __skip_event;\n\t\telse if (snd_seq_ev_is_reserved(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (snd_seq_ev_is_variable(&event)) {\n\t\t\tint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\n\t\t\tif ((size_t)(extlen + len) > count) {\n\t\t\t\t/* back out, will get an error this time or next */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* set user space pointer */\n\t\t\tevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\n\t\t\tevent.data.ext.ptr = (char __force *)buf\n\t\t\t\t\t\t+ sizeof(struct snd_seq_event);\n\t\t\tlen += extlen; /* increment data length */\n\t\t} else {\n#ifdef CONFIG_COMPAT\n\t\t\tif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\n\t\t\t\tvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\n\t\t\t\tevent.data.ext.ptr = ptr;\n\t\t\t}\n#endif\n\t\t}\n\n\t\t/* ok, enqueue it */\n\t\terr = snd_seq_client_enqueue_event(client, &event, file,\n\t\t\t\t\t\t   !(file->f_flags & O_NONBLOCK),\n\t\t\t\t\t\t   0, 0);\n\t\tif (err < 0)\n\t\t\tbreak;\n\n\t__skip_event:\n\t\t/* Update pointers and counts */\n\t\tcount -= len;\n\t\tbuf += len;\n\t\twritten += len;\n\t}\n\n\treturn written ? written : err;\n}",
        "code_after_change": "static ssize_t snd_seq_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *offset)\n{\n\tstruct snd_seq_client *client = file->private_data;\n\tint written = 0, len;\n\tint err;\n\tstruct snd_seq_event event;\n\n\tif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\n\t\treturn -ENXIO;\n\n\t/* check client structures are in place */\n\tif (snd_BUG_ON(!client))\n\t\treturn -ENXIO;\n\t\t\n\tif (!client->accept_output || client->pool == NULL)\n\t\treturn -ENXIO;\n\n\t/* allocate the pool now if the pool is not allocated yet */ \n\tif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\n\t\tmutex_lock(&client->ioctl_mutex);\n\t\terr = snd_seq_pool_init(client->pool);\n\t\tmutex_unlock(&client->ioctl_mutex);\n\t\tif (err < 0)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* only process whole events */\n\terr = -EINVAL;\n\twhile (count >= sizeof(struct snd_seq_event)) {\n\t\t/* Read in the event header from the user */\n\t\tlen = sizeof(event);\n\t\tif (copy_from_user(&event, buf, len)) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tevent.source.client = client->number;\t/* fill in client number */\n\t\t/* Check for extension data length */\n\t\tif (check_event_type_and_length(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* check for special events */\n\t\tif (event.type == SNDRV_SEQ_EVENT_NONE)\n\t\t\tgoto __skip_event;\n\t\telse if (snd_seq_ev_is_reserved(&event)) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (snd_seq_ev_is_variable(&event)) {\n\t\t\tint extlen = event.data.ext.len & ~SNDRV_SEQ_EXT_MASK;\n\t\t\tif ((size_t)(extlen + len) > count) {\n\t\t\t\t/* back out, will get an error this time or next */\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* set user space pointer */\n\t\t\tevent.data.ext.len = extlen | SNDRV_SEQ_EXT_USRPTR;\n\t\t\tevent.data.ext.ptr = (char __force *)buf\n\t\t\t\t\t\t+ sizeof(struct snd_seq_event);\n\t\t\tlen += extlen; /* increment data length */\n\t\t} else {\n#ifdef CONFIG_COMPAT\n\t\t\tif (client->convert32 && snd_seq_ev_is_varusr(&event)) {\n\t\t\t\tvoid *ptr = (void __force *)compat_ptr(event.data.raw32.d[1]);\n\t\t\t\tevent.data.ext.ptr = ptr;\n\t\t\t}\n#endif\n\t\t}\n\n\t\t/* ok, enqueue it */\n\t\terr = snd_seq_client_enqueue_event(client, &event, file,\n\t\t\t\t\t\t   !(file->f_flags & O_NONBLOCK),\n\t\t\t\t\t\t   0, 0);\n\t\tif (err < 0)\n\t\t\tbreak;\n\n\t__skip_event:\n\t\t/* Update pointers and counts */\n\t\tcount -= len;\n\t\tbuf += len;\n\t\twritten += len;\n\t}\n\n\treturn written ? written : err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n {\n \tstruct snd_seq_client *client = file->private_data;\n \tint written = 0, len;\n-\tint err = -EINVAL;\n+\tint err;\n \tstruct snd_seq_event event;\n \n \tif (!(snd_seq_file_flags(file) & SNDRV_SEQ_LFLG_OUTPUT))\n@@ -18,11 +18,15 @@\n \n \t/* allocate the pool now if the pool is not allocated yet */ \n \tif (client->pool->size > 0 && !snd_seq_write_pool_allocated(client)) {\n-\t\tif (snd_seq_pool_init(client->pool) < 0)\n+\t\tmutex_lock(&client->ioctl_mutex);\n+\t\terr = snd_seq_pool_init(client->pool);\n+\t\tmutex_unlock(&client->ioctl_mutex);\n+\t\tif (err < 0)\n \t\t\treturn -ENOMEM;\n \t}\n \n \t/* only process whole events */\n+\terr = -EINVAL;\n \twhile (count >= sizeof(struct snd_seq_event)) {\n \t\t/* Read in the event header from the user */\n \t\tlen = sizeof(event);",
        "function_modified_lines": {
            "added": [
                "\tint err;",
                "\t\tmutex_lock(&client->ioctl_mutex);",
                "\t\terr = snd_seq_pool_init(client->pool);",
                "\t\tmutex_unlock(&client->ioctl_mutex);",
                "\t\tif (err < 0)",
                "\terr = -EINVAL;"
            ],
            "deleted": [
                "\tint err = -EINVAL;",
                "\t\tif (snd_seq_pool_init(client->pool) < 0)"
            ]
        },
        "cwe": [
            "CWE-119",
            "CWE-362"
        ],
        "cve_description": "The Linux kernel 4.15 has a Buffer Overflow via an SNDRV_SEQ_IOCTL_SET_CLIENT_POOL ioctl write operation to /dev/snd/seq by a local user.",
        "id": 1847
    },
    {
        "cve_id": "CVE-2013-2893",
        "code_before_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tstruct hid_report *report;\n\tstruct hid_field *field;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tstruct usb_device_descriptor *udesc;\n\tint error, i, j;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\t/* Find the report to use */\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"No output report found\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Check that the report looks ok */\n\treport = list_entry(report_list->next, struct hid_report, list);\n\tif (!report) {\n\t\thid_err(hid, \"NULL output report\\n\");\n\t\treturn -1;\n\t}\n\n\tfield = report->field[0];\n\tif (!field) {\n\t\thid_err(hid, \"NULL field\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\t\t\t     \"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Attempt to switch wheel to native mode when applicable */\n\tudesc = &(hid_to_usb_dev(hid)->descriptor);\n\tif (!udesc) {\n\t\thid_err(hid, \"NULL USB device descriptor\\n\");\n\t\treturn -1;\n\t}\n\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\trev_maj = bcdDevice >> 8;\n\trev_min = bcdDevice & 0xff;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\n\t\tdbg_hid(\"Generic wheel detected, can it do native?\\n\");\n\t\tdbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\n\n\t\tfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\n\t\t\tif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\n\t\t\t\thid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\n\t\t\t\thid_info(hid, \"Switched to native mode\\n\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\n\n\tif (error)\n\t\treturn error;\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\tif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t/* Formula Force EX expects different autocentering command */\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Get private driver data */\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize device properties */\n\tentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\n\tif (!entry) {\n\t\thid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->device_props = entry;\n\n\tentry->product_id = lg4ff_devices[i].product_id;\n\tentry->min_range = lg4ff_devices[i].min_range;\n\tentry->max_range = lg4ff_devices[i].max_range;\n\tentry->set_range = lg4ff_devices[i].set_range;\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\treturn error;\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->range = entry->max_range;\n\tif (entry->set_range != NULL)\n\t\tentry->set_range(hid, entry->range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27 only */\n\tentry->led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->led[j];\n\t\t\t\t\tentry->led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n}",
        "code_after_change": "int lg4ff_init(struct hid_device *hid)\n{\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tstruct lg4ff_device_entry *entry;\n\tstruct lg_drv_data *drv_data;\n\tstruct usb_device_descriptor *udesc;\n\tint error, i, j;\n\t__u16 bcdDevice, rev_maj, rev_min;\n\n\t/* Check that the report looks ok */\n\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -1;\n\n\t/* Check what wheel has been connected */\n\tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {\n\t\tif (hid->product == lg4ff_devices[i].product_id) {\n\t\t\tdbg_hid(\"Found compatible device, product ID %04X\\n\", lg4ff_devices[i].product_id);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(lg4ff_devices)) {\n\t\thid_err(hid, \"Device is not supported by lg4ff driver. If you think it should be, consider reporting a bug to\"\n\t\t\t     \"LKML, Simon Wood <simon@mungewell.org> or Michal Maly <madcatxster@gmail.com>\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Attempt to switch wheel to native mode when applicable */\n\tudesc = &(hid_to_usb_dev(hid)->descriptor);\n\tif (!udesc) {\n\t\thid_err(hid, \"NULL USB device descriptor\\n\");\n\t\treturn -1;\n\t}\n\tbcdDevice = le16_to_cpu(udesc->bcdDevice);\n\trev_maj = bcdDevice >> 8;\n\trev_min = bcdDevice & 0xff;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_WHEEL) {\n\t\tdbg_hid(\"Generic wheel detected, can it do native?\\n\");\n\t\tdbg_hid(\"USB revision: %2x.%02x\\n\", rev_maj, rev_min);\n\n\t\tfor (j = 0; j < ARRAY_SIZE(lg4ff_revs); j++) {\n\t\t\tif (lg4ff_revs[j].rev_maj == rev_maj && lg4ff_revs[j].rev_min == rev_min) {\n\t\t\t\thid_lg4ff_switch_native(hid, lg4ff_revs[j].command);\n\t\t\t\thid_info(hid, \"Switched to native mode\\n\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Set supported force feedback capabilities */\n\tfor (j = 0; lg4ff_devices[i].ff_effects[j] >= 0; j++)\n\t\tset_bit(lg4ff_devices[i].ff_effects[j], dev->ffbit);\n\n\terror = input_ff_create_memless(dev, NULL, hid_lg4ff_play);\n\n\tif (error)\n\t\treturn error;\n\n\t/* Check if autocentering is available and\n\t * set the centering force to zero by default */\n\tif (test_bit(FF_AUTOCENTER, dev->ffbit)) {\n\t\tif (rev_maj == FFEX_REV_MAJ && rev_min == FFEX_REV_MIN)\t/* Formula Force EX expects different autocentering command */\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_ffex;\n\t\telse\n\t\t\tdev->ff->set_autocenter = hid_lg4ff_set_autocenter_default;\n\n\t\tdev->ff->set_autocenter(dev, 0);\n\t}\n\n\t/* Get private driver data */\n\tdrv_data = hid_get_drvdata(hid);\n\tif (!drv_data) {\n\t\thid_err(hid, \"Cannot add device, private driver data not allocated\\n\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize device properties */\n\tentry = kzalloc(sizeof(struct lg4ff_device_entry), GFP_KERNEL);\n\tif (!entry) {\n\t\thid_err(hid, \"Cannot add device, insufficient memory to allocate device properties.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->device_props = entry;\n\n\tentry->product_id = lg4ff_devices[i].product_id;\n\tentry->min_range = lg4ff_devices[i].min_range;\n\tentry->max_range = lg4ff_devices[i].max_range;\n\tentry->set_range = lg4ff_devices[i].set_range;\n\n\t/* Create sysfs interface */\n\terror = device_create_file(&hid->dev, &dev_attr_range);\n\tif (error)\n\t\treturn error;\n\tdbg_hid(\"sysfs interface created\\n\");\n\n\t/* Set the maximum range to start with */\n\tentry->range = entry->max_range;\n\tif (entry->set_range != NULL)\n\t\tentry->set_range(hid, entry->range);\n\n#ifdef CONFIG_LEDS_CLASS\n\t/* register led subsystem - G27 only */\n\tentry->led_state = 0;\n\tfor (j = 0; j < 5; j++)\n\t\tentry->led[j] = NULL;\n\n\tif (lg4ff_devices[i].product_id == USB_DEVICE_ID_LOGITECH_G27_WHEEL) {\n\t\tstruct led_classdev *led;\n\t\tsize_t name_sz;\n\t\tchar *name;\n\n\t\tlg4ff_set_leds(hid, 0);\n\n\t\tname_sz = strlen(dev_name(&hid->dev)) + 8;\n\n\t\tfor (j = 0; j < 5; j++) {\n\t\t\tled = kzalloc(sizeof(struct led_classdev)+name_sz, GFP_KERNEL);\n\t\t\tif (!led) {\n\t\t\t\thid_err(hid, \"can't allocate memory for LED %d\\n\", j);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tname = (void *)(&led[1]);\n\t\t\tsnprintf(name, name_sz, \"%s::RPM%d\", dev_name(&hid->dev), j+1);\n\t\t\tled->name = name;\n\t\t\tled->brightness = 0;\n\t\t\tled->max_brightness = 1;\n\t\t\tled->brightness_get = lg4ff_led_get_brightness;\n\t\t\tled->brightness_set = lg4ff_led_set_brightness;\n\n\t\t\tentry->led[j] = led;\n\t\t\terror = led_classdev_register(&hid->dev, led);\n\n\t\t\tif (error) {\n\t\t\t\thid_err(hid, \"failed to register LED %d. Aborting.\\n\", j);\nerr:\n\t\t\t\t/* Deregister LEDs (if any) */\n\t\t\t\tfor (j = 0; j < 5; j++) {\n\t\t\t\t\tled = entry->led[j];\n\t\t\t\t\tentry->led[j] = NULL;\n\t\t\t\t\tif (!led)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tled_classdev_unregister(led);\n\t\t\t\t\tkfree(led);\n\t\t\t\t}\n\t\t\t\tgoto out;\t/* Let the driver continue without LEDs */\n\t\t\t}\n\t\t}\n\t}\nout:\n#endif\n\thid_info(hid, \"Force feedback support for Logitech Gaming Wheels\\n\");\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,34 +1,16 @@\n int lg4ff_init(struct hid_device *hid)\n {\n \tstruct hid_input *hidinput = list_entry(hid->inputs.next, struct hid_input, list);\n-\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;\n \tstruct input_dev *dev = hidinput->input;\n-\tstruct hid_report *report;\n-\tstruct hid_field *field;\n \tstruct lg4ff_device_entry *entry;\n \tstruct lg_drv_data *drv_data;\n \tstruct usb_device_descriptor *udesc;\n \tint error, i, j;\n \t__u16 bcdDevice, rev_maj, rev_min;\n \n-\t/* Find the report to use */\n-\tif (list_empty(report_list)) {\n-\t\thid_err(hid, \"No output report found\\n\");\n+\t/* Check that the report looks ok */\n+\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))\n \t\treturn -1;\n-\t}\n-\n-\t/* Check that the report looks ok */\n-\treport = list_entry(report_list->next, struct hid_report, list);\n-\tif (!report) {\n-\t\thid_err(hid, \"NULL output report\\n\");\n-\t\treturn -1;\n-\t}\n-\n-\tfield = report->field[0];\n-\tif (!field) {\n-\t\thid_err(hid, \"NULL field\\n\");\n-\t\treturn -1;\n-\t}\n \n \t/* Check what wheel has been connected */\n \tfor (i = 0; i < ARRAY_SIZE(lg4ff_devices); i++) {",
        "function_modified_lines": {
            "added": [
                "\t/* Check that the report looks ok */",
                "\tif (!hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7))"
            ],
            "deleted": [
                "\tstruct list_head *report_list = &hid->report_enum[HID_OUTPUT_REPORT].report_list;",
                "\tstruct hid_report *report;",
                "\tstruct hid_field *field;",
                "\t/* Find the report to use */",
                "\tif (list_empty(report_list)) {",
                "\t\thid_err(hid, \"No output report found\\n\");",
                "\t}",
                "",
                "\t/* Check that the report looks ok */",
                "\treport = list_entry(report_list->next, struct hid_report, list);",
                "\tif (!report) {",
                "\t\thid_err(hid, \"NULL output report\\n\");",
                "\t\treturn -1;",
                "\t}",
                "",
                "\tfield = report->field[0];",
                "\tif (!field) {",
                "\t\thid_err(hid, \"NULL field\\n\");",
                "\t\treturn -1;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_LOGITECH_FF, CONFIG_LOGIG940_FF, or CONFIG_LOGIWHEELS_FF is enabled, allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) via a crafted device, related to (1) drivers/hid/hid-lgff.c, (2) drivers/hid/hid-lg3ff.c, and (3) drivers/hid/hid-lg4ff.c.",
        "id": 251
    },
    {
        "cve_id": "CVE-2018-20855",
        "code_before_change": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\n\t\t\t    struct ib_qp_init_attr *init_attr,\n\t\t\t    struct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\n\tstruct mlx5_ib_resources *devr = &dev->devr;\n\tint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\n\tstruct mlx5_core_dev *mdev = dev->mdev;\n\tstruct mlx5_ib_create_qp_resp resp;\n\tstruct mlx5_ib_cq *send_cq;\n\tstruct mlx5_ib_cq *recv_cq;\n\tunsigned long flags;\n\tu32 uidx = MLX5_IB_DEFAULT_UIDX;\n\tstruct mlx5_ib_create_qp ucmd;\n\tstruct mlx5_ib_qp_base *base;\n\tint mlx5_st;\n\tvoid *qpc;\n\tu32 *in;\n\tint err;\n\n\tmutex_init(&qp->mutex);\n\tspin_lock_init(&qp->sq.lock);\n\tspin_lock_init(&qp->rq.lock);\n\n\tmlx5_st = to_mlx5_st(init_attr->qp_type);\n\tif (mlx5_st < 0)\n\t\treturn -EINVAL;\n\n\tif (init_attr->rwq_ind_tbl) {\n\t\tif (!udata)\n\t\t\treturn -ENOSYS;\n\n\t\terr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\n\t\treturn err;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\n\t\tif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\n\t\t\tmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n\t\t}\n\t}\n\n\tif (init_attr->create_flags &\n\t\t\t(IB_QP_CREATE_CROSS_CHANNEL |\n\t\t\t IB_QP_CREATE_MANAGED_SEND |\n\t\t\t IB_QP_CREATE_MANAGED_RECV)) {\n\t\tif (!MLX5_CAP_GEN(mdev, cd)) {\n\t\t\tmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\n\t\t\tqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_SEND;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\n\t\tif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\n\t\t\tmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\n\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n\t\t    !MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n\t}\n\n\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\n\t\tqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\n\n\tif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\n\t\tif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\n\t\t      MLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n\t\t    (init_attr->qp_type != IB_QPT_RAW_PACKET))\n\t\t\treturn -EOPNOTSUPP;\n\t\tqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n\t}\n\n\tif (pd && pd->uobject) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\n\t\t\tmlx5_ib_dbg(dev, \"copy failed\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\terr = get_qp_user_index(to_mucontext(pd->uobject->context),\n\t\t\t\t\t&ucmd, udata->inlen, &uidx);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\n\t\tqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\n\t\tif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\n\t\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n\t\t\t    !tunnel_offload_supported(mdev)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tqp->tunnel_offload_en = true;\n\t\t}\n\n\t\tif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\n\t\t\tif (init_attr->qp_type != IB_QPT_UD ||\n\t\t\t    (MLX5_CAP_GEN(dev->mdev, port_type) !=\n\t\t\t     MLX5_CAP_PORT_TYPE_IB) ||\n\t\t\t    !mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\tqp->flags |= MLX5_IB_QP_UNDERLAY;\n\t\t\tqp->underlay_qpn = init_attr->source_qpn;\n\t\t}\n\t} else {\n\t\tqp->wq_sig = !!wq_signature;\n\t}\n\n\tbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t\tqp->flags & MLX5_IB_QP_UNDERLAY) ?\n\t       &qp->raw_packet_qp.rq.base :\n\t       &qp->trans_qp.base;\n\n\tqp->has_rq = qp_has_rq(init_attr);\n\terr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\n\t\t\t  qp, (pd && pd->uobject) ? &ucmd : NULL);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tif (pd) {\n\t\tif (pd->uobject) {\n\t\t\t__u32 max_wqes =\n\t\t\t\t1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\n\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\n\t\t\tif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\n\t\t\t    ucmd.rq_wqe_count != qp->rq.wqe_cnt) {\n\t\t\t\tmlx5_ib_dbg(dev, \"invalid rq params\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (ucmd.sq_wqe_count > max_wqes) {\n\t\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\n\t\t\t\t\t    ucmd.sq_wqe_count, max_wqes);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (init_attr->create_flags &\n\t\t\t    mlx5_ib_create_qp_sqpn_qp1()) {\n\t\t\t\tmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\terr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n\t\t\t\t\t     &resp, &inlen, base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t} else {\n\t\t\terr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\n\t\t\t\t\t       base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t}\n\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tin = kvzalloc(inlen, GFP_KERNEL);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\n\t\tqp->create_type = MLX5_QP_EMPTY;\n\t}\n\n\tif (is_sqp(init_attr->qp_type))\n\t\tqp->port = init_attr->port_num;\n\n\tqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\n\n\tMLX5_SET(qpc, qpc, st, mlx5_st);\n\tMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\n\n\tif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\n\t\tMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\n\telse\n\t\tMLX5_SET(qpc, qpc, latency_sensitive, 1);\n\n\n\tif (qp->wq_sig)\n\t\tMLX5_SET(qpc, qpc, wq_signature, 1);\n\n\tif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\n\t\tMLX5_SET(qpc, qpc, block_lb_mc, 1);\n\n\tif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\n\t\tMLX5_SET(qpc, qpc, cd_master, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\n\t\tMLX5_SET(qpc, qpc, cd_slave_send, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\n\t\tMLX5_SET(qpc, qpc, cd_slave_receive, 1);\n\n\tif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\n\t\tint rcqe_sz;\n\t\tint scqe_sz;\n\n\t\trcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\n\t\tscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\n\n\t\tif (rcqe_sz == 128)\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\n\t\telse\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\n\n\t\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\n\t\t\tif (scqe_sz == 128)\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\n\t\t\telse\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n\t\t}\n\t}\n\n\tif (qp->rq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\n\t\tMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n\t}\n\n\tMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\n\n\tif (qp->sq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n\t} else {\n\t\tMLX5_SET(qpc, qpc, no_sq, 1);\n\t\tif (init_attr->srq &&\n\t\t    init_attr->srq->srq_type == IB_SRQT_TM)\n\t\t\tMLX5_SET(qpc, qpc, offload_type,\n\t\t\t\t MLX5_QPC_OFFLOAD_TYPE_RNDV);\n\t}\n\n\t/* Set default resources */\n\tswitch (init_attr->qp_type) {\n\tcase IB_QPT_XRC_TGT:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\n\t\tbreak;\n\tcase IB_QPT_XRC_INI:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tbreak;\n\tdefault:\n\t\tif (init_attr->srq) {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n\t\t} else {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n\t\t}\n\t}\n\n\tif (init_attr->send_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\n\n\tif (init_attr->recv_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\n\n\tMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\n\n\t/* 0xffffff means we ask to work with cqe version 0 */\n\tif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\n\t\tMLX5_SET(qpc, qpc, user_index, uidx);\n\n\t/* we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\n\t\tMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\n\t\tqp->flags |= MLX5_IB_QP_LSO;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\n\t\tif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\n\t\t\tmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err;\n\t\t} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tMLX5_SET(qpc, qpc, end_padding_mode,\n\t\t\t\t MLX5_WQ_END_PAD_MODE_ALIGN);\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n\t\t}\n\t}\n\n\tif (inlen < 0) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t    qp->flags & MLX5_IB_QP_UNDERLAY) {\n\t\tqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\n\t\traw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\n\t\terr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n\t} else {\n\t\terr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n\t}\n\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"create qp failed\\n\");\n\t\tgoto err_create;\n\t}\n\n\tkvfree(in);\n\n\tbase->container_mibqp = qp;\n\tbase->mqp.event = mlx5_ib_qp_event;\n\n\tget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n\t\t&send_cq, &recv_cq);\n\tspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\n\tmlx5_ib_lock_cqs(send_cq, recv_cq);\n\t/* Maintain device to QPs access, needed for further handling via reset\n\t * flow\n\t */\n\tlist_add_tail(&qp->qps_list, &dev->qp_list);\n\t/* Maintain CQ to QPs access, needed for further handling via reset flow\n\t */\n\tif (send_cq)\n\t\tlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\n\tif (recv_cq)\n\t\tlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\n\tmlx5_ib_unlock_cqs(send_cq, recv_cq);\n\tspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\n\n\treturn 0;\n\nerr_create:\n\tif (qp->create_type == MLX5_QP_USER)\n\t\tdestroy_qp_user(dev, pd, qp, base);\n\telse if (qp->create_type == MLX5_QP_KERNEL)\n\t\tdestroy_qp_kernel(dev, qp);\n\nerr:\n\tkvfree(in);\n\treturn err;\n}",
        "code_after_change": "static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,\n\t\t\t    struct ib_qp_init_attr *init_attr,\n\t\t\t    struct ib_udata *udata, struct mlx5_ib_qp *qp)\n{\n\tstruct mlx5_ib_resources *devr = &dev->devr;\n\tint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\n\tstruct mlx5_core_dev *mdev = dev->mdev;\n\tstruct mlx5_ib_create_qp_resp resp = {};\n\tstruct mlx5_ib_cq *send_cq;\n\tstruct mlx5_ib_cq *recv_cq;\n\tunsigned long flags;\n\tu32 uidx = MLX5_IB_DEFAULT_UIDX;\n\tstruct mlx5_ib_create_qp ucmd;\n\tstruct mlx5_ib_qp_base *base;\n\tint mlx5_st;\n\tvoid *qpc;\n\tu32 *in;\n\tint err;\n\n\tmutex_init(&qp->mutex);\n\tspin_lock_init(&qp->sq.lock);\n\tspin_lock_init(&qp->rq.lock);\n\n\tmlx5_st = to_mlx5_st(init_attr->qp_type);\n\tif (mlx5_st < 0)\n\t\treturn -EINVAL;\n\n\tif (init_attr->rwq_ind_tbl) {\n\t\tif (!udata)\n\t\t\treturn -ENOSYS;\n\n\t\terr = create_rss_raw_qp_tir(dev, qp, pd, init_attr, udata);\n\t\treturn err;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK) {\n\t\tif (!MLX5_CAP_GEN(mdev, block_lb_mc)) {\n\t\t\tmlx5_ib_dbg(dev, \"block multicast loopback isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK;\n\t\t}\n\t}\n\n\tif (init_attr->create_flags &\n\t\t\t(IB_QP_CREATE_CROSS_CHANNEL |\n\t\t\t IB_QP_CREATE_MANAGED_SEND |\n\t\t\t IB_QP_CREATE_MANAGED_RECV)) {\n\t\tif (!MLX5_CAP_GEN(mdev, cd)) {\n\t\t\tmlx5_ib_dbg(dev, \"cross-channel isn't supported\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (init_attr->create_flags & IB_QP_CREATE_CROSS_CHANNEL)\n\t\t\tqp->flags |= MLX5_IB_QP_CROSS_CHANNEL;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_SEND)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_SEND;\n\t\tif (init_attr->create_flags & IB_QP_CREATE_MANAGED_RECV)\n\t\t\tqp->flags |= MLX5_IB_QP_MANAGED_RECV;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO))\n\t\tif (!MLX5_CAP_GEN(mdev, ipoib_basic_offloads)) {\n\t\t\tmlx5_ib_dbg(dev, \"ipoib UD lso qp isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_SCATTER_FCS) {\n\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS is supported only for Raw Packet QPs\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tif (!MLX5_CAP_GEN(dev->mdev, eth_net_offloads) ||\n\t\t    !MLX5_CAP_ETH(dev->mdev, scatter_fcs)) {\n\t\t\tmlx5_ib_dbg(dev, \"Scatter FCS isn't supported\\n\");\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\t\tqp->flags |= MLX5_IB_QP_CAP_SCATTER_FCS;\n\t}\n\n\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)\n\t\tqp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;\n\n\tif (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {\n\t\tif (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&\n\t\t      MLX5_CAP_ETH(dev->mdev, vlan_cap)) ||\n\t\t    (init_attr->qp_type != IB_QPT_RAW_PACKET))\n\t\t\treturn -EOPNOTSUPP;\n\t\tqp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;\n\t}\n\n\tif (pd && pd->uobject) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {\n\t\t\tmlx5_ib_dbg(dev, \"copy failed\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\terr = get_qp_user_index(to_mucontext(pd->uobject->context),\n\t\t\t\t\t&ucmd, udata->inlen, &uidx);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tqp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);\n\t\tqp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);\n\t\tif (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {\n\t\t\tif (init_attr->qp_type != IB_QPT_RAW_PACKET ||\n\t\t\t    !tunnel_offload_supported(mdev)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Tunnel offload isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t\tqp->tunnel_offload_en = true;\n\t\t}\n\n\t\tif (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {\n\t\t\tif (init_attr->qp_type != IB_QPT_UD ||\n\t\t\t    (MLX5_CAP_GEN(dev->mdev, port_type) !=\n\t\t\t     MLX5_CAP_PORT_TYPE_IB) ||\n\t\t\t    !mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {\n\t\t\t\tmlx5_ib_dbg(dev, \"Source QP option isn't supported\\n\");\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\n\t\t\tqp->flags |= MLX5_IB_QP_UNDERLAY;\n\t\t\tqp->underlay_qpn = init_attr->source_qpn;\n\t\t}\n\t} else {\n\t\tqp->wq_sig = !!wq_signature;\n\t}\n\n\tbase = (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t\tqp->flags & MLX5_IB_QP_UNDERLAY) ?\n\t       &qp->raw_packet_qp.rq.base :\n\t       &qp->trans_qp.base;\n\n\tqp->has_rq = qp_has_rq(init_attr);\n\terr = set_rq_size(dev, &init_attr->cap, qp->has_rq,\n\t\t\t  qp, (pd && pd->uobject) ? &ucmd : NULL);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tif (pd) {\n\t\tif (pd->uobject) {\n\t\t\t__u32 max_wqes =\n\t\t\t\t1 << MLX5_CAP_GEN(mdev, log_max_qp_sz);\n\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d)\\n\", ucmd.sq_wqe_count);\n\t\t\tif (ucmd.rq_wqe_shift != qp->rq.wqe_shift ||\n\t\t\t    ucmd.rq_wqe_count != qp->rq.wqe_cnt) {\n\t\t\t\tmlx5_ib_dbg(dev, \"invalid rq params\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (ucmd.sq_wqe_count > max_wqes) {\n\t\t\t\tmlx5_ib_dbg(dev, \"requested sq_wqe_count (%d) > max allowed (%d)\\n\",\n\t\t\t\t\t    ucmd.sq_wqe_count, max_wqes);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (init_attr->create_flags &\n\t\t\t    mlx5_ib_create_qp_sqpn_qp1()) {\n\t\t\t\tmlx5_ib_dbg(dev, \"user-space is not allowed to create UD QPs spoofing as QP1\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\terr = create_user_qp(dev, pd, qp, udata, init_attr, &in,\n\t\t\t\t\t     &resp, &inlen, base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t} else {\n\t\t\terr = create_kernel_qp(dev, init_attr, qp, &in, &inlen,\n\t\t\t\t\t       base);\n\t\t\tif (err)\n\t\t\t\tmlx5_ib_dbg(dev, \"err %d\\n\", err);\n\t\t}\n\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tin = kvzalloc(inlen, GFP_KERNEL);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\n\t\tqp->create_type = MLX5_QP_EMPTY;\n\t}\n\n\tif (is_sqp(init_attr->qp_type))\n\t\tqp->port = init_attr->port_num;\n\n\tqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\n\n\tMLX5_SET(qpc, qpc, st, mlx5_st);\n\tMLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);\n\n\tif (init_attr->qp_type != MLX5_IB_QPT_REG_UMR)\n\t\tMLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);\n\telse\n\t\tMLX5_SET(qpc, qpc, latency_sensitive, 1);\n\n\n\tif (qp->wq_sig)\n\t\tMLX5_SET(qpc, qpc, wq_signature, 1);\n\n\tif (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)\n\t\tMLX5_SET(qpc, qpc, block_lb_mc, 1);\n\n\tif (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)\n\t\tMLX5_SET(qpc, qpc, cd_master, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_SEND)\n\t\tMLX5_SET(qpc, qpc, cd_slave_send, 1);\n\tif (qp->flags & MLX5_IB_QP_MANAGED_RECV)\n\t\tMLX5_SET(qpc, qpc, cd_slave_receive, 1);\n\n\tif (qp->scat_cqe && is_connected(init_attr->qp_type)) {\n\t\tint rcqe_sz;\n\t\tint scqe_sz;\n\n\t\trcqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->recv_cq);\n\t\tscqe_sz = mlx5_ib_get_cqe_size(dev, init_attr->send_cq);\n\n\t\tif (rcqe_sz == 128)\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA64_CQE);\n\t\telse\n\t\t\tMLX5_SET(qpc, qpc, cs_res, MLX5_RES_SCAT_DATA32_CQE);\n\n\t\tif (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR) {\n\t\t\tif (scqe_sz == 128)\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA64_CQE);\n\t\t\telse\n\t\t\t\tMLX5_SET(qpc, qpc, cs_req, MLX5_REQ_SCAT_DATA32_CQE);\n\t\t}\n\t}\n\n\tif (qp->rq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);\n\t\tMLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));\n\t}\n\n\tMLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, init_attr));\n\n\tif (qp->sq.wqe_cnt) {\n\t\tMLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));\n\t} else {\n\t\tMLX5_SET(qpc, qpc, no_sq, 1);\n\t\tif (init_attr->srq &&\n\t\t    init_attr->srq->srq_type == IB_SRQT_TM)\n\t\t\tMLX5_SET(qpc, qpc, offload_type,\n\t\t\t\t MLX5_QPC_OFFLOAD_TYPE_RNDV);\n\t}\n\n\t/* Set default resources */\n\tswitch (init_attr->qp_type) {\n\tcase IB_QPT_XRC_TGT:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(init_attr->xrcd)->xrcdn);\n\t\tbreak;\n\tcase IB_QPT_XRC_INI:\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);\n\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);\n\t\tbreak;\n\tdefault:\n\t\tif (init_attr->srq) {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(init_attr->srq)->msrq.srqn);\n\t\t} else {\n\t\t\tMLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);\n\t\t\tMLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s1)->msrq.srqn);\n\t\t}\n\t}\n\n\tif (init_attr->send_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_snd, to_mcq(init_attr->send_cq)->mcq.cqn);\n\n\tif (init_attr->recv_cq)\n\t\tMLX5_SET(qpc, qpc, cqn_rcv, to_mcq(init_attr->recv_cq)->mcq.cqn);\n\n\tMLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);\n\n\t/* 0xffffff means we ask to work with cqe version 0 */\n\tif (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)\n\t\tMLX5_SET(qpc, qpc, user_index, uidx);\n\n\t/* we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */\n\tif (init_attr->qp_type == IB_QPT_UD &&\n\t    (init_attr->create_flags & IB_QP_CREATE_IPOIB_UD_LSO)) {\n\t\tMLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);\n\t\tqp->flags |= MLX5_IB_QP_LSO;\n\t}\n\n\tif (init_attr->create_flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {\n\t\tif (!MLX5_CAP_GEN(dev->mdev, end_pad)) {\n\t\t\tmlx5_ib_dbg(dev, \"scatter end padding is not supported\\n\");\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err;\n\t\t} else if (init_attr->qp_type != IB_QPT_RAW_PACKET) {\n\t\t\tMLX5_SET(qpc, qpc, end_padding_mode,\n\t\t\t\t MLX5_WQ_END_PAD_MODE_ALIGN);\n\t\t} else {\n\t\t\tqp->flags |= MLX5_IB_QP_PCI_WRITE_END_PADDING;\n\t\t}\n\t}\n\n\tif (inlen < 0) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (init_attr->qp_type == IB_QPT_RAW_PACKET ||\n\t    qp->flags & MLX5_IB_QP_UNDERLAY) {\n\t\tqp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;\n\t\traw_packet_qp_copy_info(qp, &qp->raw_packet_qp);\n\t\terr = create_raw_packet_qp(dev, qp, in, inlen, pd);\n\t} else {\n\t\terr = mlx5_core_create_qp(dev->mdev, &base->mqp, in, inlen);\n\t}\n\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"create qp failed\\n\");\n\t\tgoto err_create;\n\t}\n\n\tkvfree(in);\n\n\tbase->container_mibqp = qp;\n\tbase->mqp.event = mlx5_ib_qp_event;\n\n\tget_cqs(init_attr->qp_type, init_attr->send_cq, init_attr->recv_cq,\n\t\t&send_cq, &recv_cq);\n\tspin_lock_irqsave(&dev->reset_flow_resource_lock, flags);\n\tmlx5_ib_lock_cqs(send_cq, recv_cq);\n\t/* Maintain device to QPs access, needed for further handling via reset\n\t * flow\n\t */\n\tlist_add_tail(&qp->qps_list, &dev->qp_list);\n\t/* Maintain CQ to QPs access, needed for further handling via reset flow\n\t */\n\tif (send_cq)\n\t\tlist_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);\n\tif (recv_cq)\n\t\tlist_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);\n\tmlx5_ib_unlock_cqs(send_cq, recv_cq);\n\tspin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);\n\n\treturn 0;\n\nerr_create:\n\tif (qp->create_type == MLX5_QP_USER)\n\t\tdestroy_qp_user(dev, pd, qp, base);\n\telse if (qp->create_type == MLX5_QP_KERNEL)\n\t\tdestroy_qp_kernel(dev, qp);\n\nerr:\n\tkvfree(in);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct mlx5_ib_resources *devr = &dev->devr;\n \tint inlen = MLX5_ST_SZ_BYTES(create_qp_in);\n \tstruct mlx5_core_dev *mdev = dev->mdev;\n-\tstruct mlx5_ib_create_qp_resp resp;\n+\tstruct mlx5_ib_create_qp_resp resp = {};\n \tstruct mlx5_ib_cq *send_cq;\n \tstruct mlx5_ib_cq *recv_cq;\n \tunsigned long flags;",
        "function_modified_lines": {
            "added": [
                "\tstruct mlx5_ib_create_qp_resp resp = {};"
            ],
            "deleted": [
                "\tstruct mlx5_ib_create_qp_resp resp;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 4.18.7. In create_qp_common in drivers/infiniband/hw/mlx5/qp.c, mlx5_ib_create_qp_resp was never initialized, resulting in a leak of stack memory to userspace.",
        "id": 1786
    },
    {
        "cve_id": "CVE-2014-0205",
        "code_before_change": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\tget_futex_key_refs(&q->key);\n\thb = hash_futex(&q->key);\n\tq->lock_ptr = &hb->lock;\n\n\tspin_lock(&hb->lock);\n\treturn hb;\n}",
        "code_after_change": "static inline struct futex_hash_bucket *queue_lock(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\thb = hash_futex(&q->key);\n\tq->lock_ptr = &hb->lock;\n\n\tspin_lock(&hb->lock);\n\treturn hb;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,6 @@\n {\n \tstruct futex_hash_bucket *hb;\n \n-\tget_futex_key_refs(&q->key);\n \thb = hash_futex(&q->key);\n \tq->lock_ptr = &hb->lock;\n ",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tget_futex_key_refs(&q->key);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The futex_wait function in kernel/futex.c in the Linux kernel before 2.6.37 does not properly maintain a certain reference count during requeue operations, which allows local users to cause a denial of service (use-after-free and system crash) or possibly gain privileges via a crafted application that triggers a zero count.",
        "id": 467
    },
    {
        "cve_id": "CVE-2016-5728",
        "code_before_change": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\n\tstruct vop_vdev *vdev = f->private_data;\n\tstruct vop_info *vi = vdev->vi;\n\tvoid __user *argp = (void __user *)arg;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase MIC_VIRTIO_ADD_DEVICE:\n\t{\n\t\tstruct mic_device_desc dd, *dd_config;\n\n\t\tif (copy_from_user(&dd, argp, sizeof(dd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\n\t\t    dd.num_vq > MIC_MAX_VRINGS)\n\t\t\treturn -EINVAL;\n\n\t\tdd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\n\t\tif (!dd_config)\n\t\t\treturn -ENOMEM;\n\t\tif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_ret;\n\t\t}\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tmutex_lock(&vi->vop_mutex);\n\t\tret = vop_virtio_add_device(vdev, dd_config);\n\t\tif (ret)\n\t\t\tgoto unlock_ret;\n\t\tlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\n\t\tmutex_unlock(&vi->vop_mutex);\n\t\tmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\n\t\tkfree(dd_config);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_COPY_DESC:\n\t{\n\t\tstruct mic_copy_desc copy;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto _unlock_ret;\n\n\t\tif (copy_from_user(&copy, argp, sizeof(copy))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto _unlock_ret;\n\t\t}\n\n\t\tret = vop_virtio_copy_desc(vdev, &copy);\n\t\tif (ret < 0)\n\t\t\tgoto _unlock_ret;\n\t\tif (copy_to_user(\n\t\t\t&((struct mic_copy_desc __user *)argp)->out_len,\n\t\t\t&copy.out_len, sizeof(copy.out_len)))\n\t\t\tret = -EFAULT;\n_unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_CONFIG_CHANGE:\n\t{\n\t\tvoid *buf;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto __unlock_ret;\n\t\tbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto __unlock_ret;\n\t\t}\n\t\tif (copy_from_user(buf, argp, vdev->dd->config_len)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto done;\n\t\t}\n\t\tret = vop_virtio_config_change(vdev, buf);\ndone:\n\t\tkfree(buf);\n__unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t};\n\treturn 0;\n}",
        "code_after_change": "static long vop_ioctl(struct file *f, unsigned int cmd, unsigned long arg)\n{\n\tstruct vop_vdev *vdev = f->private_data;\n\tstruct vop_info *vi = vdev->vi;\n\tvoid __user *argp = (void __user *)arg;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase MIC_VIRTIO_ADD_DEVICE:\n\t{\n\t\tstruct mic_device_desc dd, *dd_config;\n\n\t\tif (copy_from_user(&dd, argp, sizeof(dd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (mic_aligned_desc_size(&dd) > MIC_MAX_DESC_BLK_SIZE ||\n\t\t    dd.num_vq > MIC_MAX_VRINGS)\n\t\t\treturn -EINVAL;\n\n\t\tdd_config = kzalloc(mic_desc_size(&dd), GFP_KERNEL);\n\t\tif (!dd_config)\n\t\t\treturn -ENOMEM;\n\t\tif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_ret;\n\t\t}\n\t\t/* Ensure desc has not changed between the two reads */\n\t\tif (memcmp(&dd, dd_config, sizeof(dd))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto free_ret;\n\t\t}\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tmutex_lock(&vi->vop_mutex);\n\t\tret = vop_virtio_add_device(vdev, dd_config);\n\t\tif (ret)\n\t\t\tgoto unlock_ret;\n\t\tlist_add_tail(&vdev->list, &vi->vdev_list);\nunlock_ret:\n\t\tmutex_unlock(&vi->vop_mutex);\n\t\tmutex_unlock(&vdev->vdev_mutex);\nfree_ret:\n\t\tkfree(dd_config);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_COPY_DESC:\n\t{\n\t\tstruct mic_copy_desc copy;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto _unlock_ret;\n\n\t\tif (copy_from_user(&copy, argp, sizeof(copy))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto _unlock_ret;\n\t\t}\n\n\t\tret = vop_virtio_copy_desc(vdev, &copy);\n\t\tif (ret < 0)\n\t\t\tgoto _unlock_ret;\n\t\tif (copy_to_user(\n\t\t\t&((struct mic_copy_desc __user *)argp)->out_len,\n\t\t\t&copy.out_len, sizeof(copy.out_len)))\n\t\t\tret = -EFAULT;\n_unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tcase MIC_VIRTIO_CONFIG_CHANGE:\n\t{\n\t\tvoid *buf;\n\n\t\tmutex_lock(&vdev->vdev_mutex);\n\t\tret = vop_vdev_inited(vdev);\n\t\tif (ret)\n\t\t\tgoto __unlock_ret;\n\t\tbuf = kzalloc(vdev->dd->config_len, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto __unlock_ret;\n\t\t}\n\t\tif (copy_from_user(buf, argp, vdev->dd->config_len)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto done;\n\t\t}\n\t\tret = vop_virtio_config_change(vdev, buf);\ndone:\n\t\tkfree(buf);\n__unlock_ret:\n\t\tmutex_unlock(&vdev->vdev_mutex);\n\t\treturn ret;\n\t}\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t};\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,11 @@\n \t\t\treturn -ENOMEM;\n \t\tif (copy_from_user(dd_config, argp, mic_desc_size(&dd))) {\n \t\t\tret = -EFAULT;\n+\t\t\tgoto free_ret;\n+\t\t}\n+\t\t/* Ensure desc has not changed between the two reads */\n+\t\tif (memcmp(&dd, dd_config, sizeof(dd))) {\n+\t\t\tret = -EINVAL;\n \t\t\tgoto free_ret;\n \t\t}\n \t\tmutex_lock(&vdev->vdev_mutex);",
        "function_modified_lines": {
            "added": [
                "\t\t\tgoto free_ret;",
                "\t\t}",
                "\t\t/* Ensure desc has not changed between the two reads */",
                "\t\tif (memcmp(&dd, dd_config, sizeof(dd))) {",
                "\t\t\tret = -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Race condition in the vop_ioctl function in drivers/misc/mic/vop/vop_vringh.c in the MIC VOP driver in the Linux kernel before 4.6.1 allows local users to obtain sensitive information from kernel memory or cause a denial of service (memory corruption and system crash) by changing a certain header, aka a \"double fetch\" vulnerability.",
        "id": 1056
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(&e->ip))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
        "code_after_change": "static bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tconst struct xt_entry_target *t;\n \tunsigned int verdict;\n \n-\tif (!unconditional(&e->ip))\n+\tif (!unconditional(e))\n \t\treturn false;\n \tt = ipt_get_target_c(e);\n \tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)",
        "function_modified_lines": {
            "added": [
                "\tif (!unconditional(e))"
            ],
            "deleted": [
                "\tif (!unconditional(&e->ip))"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 968
    },
    {
        "cve_id": "CVE-2022-3625",
        "code_before_change": "static int devlink_param_get(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->get)\n\t\treturn -EOPNOTSUPP;\n\treturn param->get(devlink, param->id, ctx);\n}",
        "code_after_change": "static int devlink_param_get(struct devlink *devlink,\n\t\t\t     const struct devlink_param *param,\n\t\t\t     struct devlink_param_gset_ctx *ctx)\n{\n\tif (!param->get || devlink->reload_failed)\n\t\treturn -EOPNOTSUPP;\n\treturn param->get(devlink, param->id, ctx);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t     const struct devlink_param *param,\n \t\t\t     struct devlink_param_gset_ctx *ctx)\n {\n-\tif (!param->get)\n+\tif (!param->get || devlink->reload_failed)\n \t\treturn -EOPNOTSUPP;\n \treturn param->get(devlink, param->id, ctx);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!param->get || devlink->reload_failed)"
            ],
            "deleted": [
                "\tif (!param->get)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel. It has been classified as critical. This affects the function devlink_param_set/devlink_param_get of the file net/core/devlink.c of the component IPsec. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier VDB-211929 was assigned to this vulnerability.",
        "id": 3660
    },
    {
        "cve_id": "CVE-2014-3184",
        "code_before_change": "static __u8 *kye_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tswitch (hdev->product) {\n\tcase USB_DEVICE_ID_KYE_ERGO_525V:\n\t\t/* the fixups that need to be done:\n\t\t *   - change led usage page to button for extra buttons\n\t\t *   - report size 8 count 1 must be size 1 count 8 for button\n\t\t *     bitfield\n\t\t *   - change the button usage range to 4-7 for the extra\n\t\t *     buttons\n\t\t */\n\t\tif (*rsize >= 74 &&\n\t\t\trdesc[61] == 0x05 && rdesc[62] == 0x08 &&\n\t\t\trdesc[63] == 0x19 && rdesc[64] == 0x08 &&\n\t\t\trdesc[65] == 0x29 && rdesc[66] == 0x0f &&\n\t\t\trdesc[71] == 0x75 && rdesc[72] == 0x08 &&\n\t\t\trdesc[73] == 0x95 && rdesc[74] == 0x01) {\n\t\t\thid_info(hdev,\n\t\t\t\t \"fixing up Kye/Genius Ergo Mouse \"\n\t\t\t\t \"report descriptor\\n\");\n\t\t\trdesc[62] = 0x09;\n\t\t\trdesc[64] = 0x04;\n\t\t\trdesc[66] = 0x07;\n\t\t\trdesc[72] = 0x01;\n\t\t\trdesc[74] = 0x08;\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_EASYPEN_I405X:\n\t\tif (*rsize == EASYPEN_I405X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = easypen_i405x_rdesc_fixed;\n\t\t\t*rsize = sizeof(easypen_i405x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_MOUSEPEN_I608X:\n\t\tif (*rsize == MOUSEPEN_I608X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = mousepen_i608x_rdesc_fixed;\n\t\t\t*rsize = sizeof(mousepen_i608x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_EASYPEN_M610X:\n\t\tif (*rsize == EASYPEN_M610X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = easypen_m610x_rdesc_fixed;\n\t\t\t*rsize = sizeof(easypen_m610x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_GILA_GAMING_MOUSE:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 104,\n\t\t\t\t\t\"Genius Gila Gaming Mouse\");\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_GX_IMPERATOR:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 83,\n\t\t\t\t\t\"Genius Gx Imperator Keyboard\");\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_MANTICORE:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 104,\n\t\t\t\t\t\"Genius Manticore Keyboard\");\n\t\tbreak;\n\t}\n\treturn rdesc;\n}",
        "code_after_change": "static __u8 *kye_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tswitch (hdev->product) {\n\tcase USB_DEVICE_ID_KYE_ERGO_525V:\n\t\t/* the fixups that need to be done:\n\t\t *   - change led usage page to button for extra buttons\n\t\t *   - report size 8 count 1 must be size 1 count 8 for button\n\t\t *     bitfield\n\t\t *   - change the button usage range to 4-7 for the extra\n\t\t *     buttons\n\t\t */\n\t\tif (*rsize >= 75 &&\n\t\t\trdesc[61] == 0x05 && rdesc[62] == 0x08 &&\n\t\t\trdesc[63] == 0x19 && rdesc[64] == 0x08 &&\n\t\t\trdesc[65] == 0x29 && rdesc[66] == 0x0f &&\n\t\t\trdesc[71] == 0x75 && rdesc[72] == 0x08 &&\n\t\t\trdesc[73] == 0x95 && rdesc[74] == 0x01) {\n\t\t\thid_info(hdev,\n\t\t\t\t \"fixing up Kye/Genius Ergo Mouse \"\n\t\t\t\t \"report descriptor\\n\");\n\t\t\trdesc[62] = 0x09;\n\t\t\trdesc[64] = 0x04;\n\t\t\trdesc[66] = 0x07;\n\t\t\trdesc[72] = 0x01;\n\t\t\trdesc[74] = 0x08;\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_EASYPEN_I405X:\n\t\tif (*rsize == EASYPEN_I405X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = easypen_i405x_rdesc_fixed;\n\t\t\t*rsize = sizeof(easypen_i405x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_MOUSEPEN_I608X:\n\t\tif (*rsize == MOUSEPEN_I608X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = mousepen_i608x_rdesc_fixed;\n\t\t\t*rsize = sizeof(mousepen_i608x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_KYE_EASYPEN_M610X:\n\t\tif (*rsize == EASYPEN_M610X_RDESC_ORIG_SIZE) {\n\t\t\trdesc = easypen_m610x_rdesc_fixed;\n\t\t\t*rsize = sizeof(easypen_m610x_rdesc_fixed);\n\t\t}\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_GILA_GAMING_MOUSE:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 104,\n\t\t\t\t\t\"Genius Gila Gaming Mouse\");\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_GX_IMPERATOR:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 83,\n\t\t\t\t\t\"Genius Gx Imperator Keyboard\");\n\t\tbreak;\n\tcase USB_DEVICE_ID_GENIUS_MANTICORE:\n\t\trdesc = kye_consumer_control_fixup(hdev, rdesc, rsize, 104,\n\t\t\t\t\t\"Genius Manticore Keyboard\");\n\t\tbreak;\n\t}\n\treturn rdesc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t\t *   - change the button usage range to 4-7 for the extra\n \t\t *     buttons\n \t\t */\n-\t\tif (*rsize >= 74 &&\n+\t\tif (*rsize >= 75 &&\n \t\t\trdesc[61] == 0x05 && rdesc[62] == 0x08 &&\n \t\t\trdesc[63] == 0x19 && rdesc[64] == 0x08 &&\n \t\t\trdesc[65] == 0x29 && rdesc[66] == 0x0f &&",
        "function_modified_lines": {
            "added": [
                "\t\tif (*rsize >= 75 &&"
            ],
            "deleted": [
                "\t\tif (*rsize >= 74 &&"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The report_fixup functions in the HID subsystem in the Linux kernel before 3.16.2 might allow physically proximate attackers to cause a denial of service (out-of-bounds write) via a crafted device that provides a small report descriptor, related to (1) drivers/hid/hid-cherry.c, (2) drivers/hid/hid-kye.c, (3) drivers/hid/hid-lg.c, (4) drivers/hid/hid-monterey.c, (5) drivers/hid/hid-petalynx.c, and (6) drivers/hid/hid-sunplus.c.",
        "id": 516
    },
    {
        "cve_id": "CVE-2018-1000199",
        "code_before_change": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\n\tu64 old_addr = bp->attr.bp_addr;\n\tu64 old_len = bp->attr.bp_len;\n\tint old_type = bp->attr.bp_type;\n\tint err = 0;\n\n\t/*\n\t * modify_user_hw_breakpoint can be invoked with IRQs disabled and hence it\n\t * will not be possible to raise IPIs that invoke __perf_event_disable.\n\t * So call the function directly after making sure we are targeting the\n\t * current task.\n\t */\n\tif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\n\t\tperf_event_disable_local(bp);\n\telse\n\t\tperf_event_disable(bp);\n\n\tbp->attr.bp_addr = attr->bp_addr;\n\tbp->attr.bp_type = attr->bp_type;\n\tbp->attr.bp_len = attr->bp_len;\n\n\tif (attr->disabled)\n\t\tgoto end;\n\n\terr = validate_hw_breakpoint(bp);\n\tif (!err)\n\t\tperf_event_enable(bp);\n\n\tif (err) {\n\t\tbp->attr.bp_addr = old_addr;\n\t\tbp->attr.bp_type = old_type;\n\t\tbp->attr.bp_len = old_len;\n\t\tif (!bp->attr.disabled)\n\t\t\tperf_event_enable(bp);\n\n\t\treturn err;\n\t}\n\nend:\n\tbp->attr.disabled = attr->disabled;\n\n\treturn 0;\n}",
        "code_after_change": "int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n{\n\t/*\n\t * modify_user_hw_breakpoint can be invoked with IRQs disabled and hence it\n\t * will not be possible to raise IPIs that invoke __perf_event_disable.\n\t * So call the function directly after making sure we are targeting the\n\t * current task.\n\t */\n\tif (irqs_disabled() && bp->ctx && bp->ctx->task == current)\n\t\tperf_event_disable_local(bp);\n\telse\n\t\tperf_event_disable(bp);\n\n\tbp->attr.bp_addr = attr->bp_addr;\n\tbp->attr.bp_type = attr->bp_type;\n\tbp->attr.bp_len = attr->bp_len;\n\tbp->attr.disabled = 1;\n\n\tif (!attr->disabled) {\n\t\tint err = validate_hw_breakpoint(bp);\n\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tperf_event_enable(bp);\n\t\tbp->attr.disabled = 0;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,5 @@\n int modify_user_hw_breakpoint(struct perf_event *bp, struct perf_event_attr *attr)\n {\n-\tu64 old_addr = bp->attr.bp_addr;\n-\tu64 old_len = bp->attr.bp_len;\n-\tint old_type = bp->attr.bp_type;\n-\tint err = 0;\n-\n \t/*\n \t * modify_user_hw_breakpoint can be invoked with IRQs disabled and hence it\n \t * will not be possible to raise IPIs that invoke __perf_event_disable.\n@@ -19,26 +14,17 @@\n \tbp->attr.bp_addr = attr->bp_addr;\n \tbp->attr.bp_type = attr->bp_type;\n \tbp->attr.bp_len = attr->bp_len;\n+\tbp->attr.disabled = 1;\n \n-\tif (attr->disabled)\n-\t\tgoto end;\n+\tif (!attr->disabled) {\n+\t\tint err = validate_hw_breakpoint(bp);\n \n-\terr = validate_hw_breakpoint(bp);\n-\tif (!err)\n+\t\tif (err)\n+\t\t\treturn err;\n+\n \t\tperf_event_enable(bp);\n-\n-\tif (err) {\n-\t\tbp->attr.bp_addr = old_addr;\n-\t\tbp->attr.bp_type = old_type;\n-\t\tbp->attr.bp_len = old_len;\n-\t\tif (!bp->attr.disabled)\n-\t\t\tperf_event_enable(bp);\n-\n-\t\treturn err;\n+\t\tbp->attr.disabled = 0;\n \t}\n-\n-end:\n-\tbp->attr.disabled = attr->disabled;\n \n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tbp->attr.disabled = 1;",
                "\tif (!attr->disabled) {",
                "\t\tint err = validate_hw_breakpoint(bp);",
                "\t\tif (err)",
                "\t\t\treturn err;",
                "",
                "\t\tbp->attr.disabled = 0;"
            ],
            "deleted": [
                "\tu64 old_addr = bp->attr.bp_addr;",
                "\tu64 old_len = bp->attr.bp_len;",
                "\tint old_type = bp->attr.bp_type;",
                "\tint err = 0;",
                "",
                "\tif (attr->disabled)",
                "\t\tgoto end;",
                "\terr = validate_hw_breakpoint(bp);",
                "\tif (!err)",
                "",
                "\tif (err) {",
                "\t\tbp->attr.bp_addr = old_addr;",
                "\t\tbp->attr.bp_type = old_type;",
                "\t\tbp->attr.bp_len = old_len;",
                "\t\tif (!bp->attr.disabled)",
                "\t\t\tperf_event_enable(bp);",
                "",
                "\t\treturn err;",
                "",
                "end:",
                "\tbp->attr.disabled = attr->disabled;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Linux Kernel version 3.18 contains a dangerous feature vulnerability in modify_user_hw_breakpoint() that can result in crash and possibly memory corruption. This attack appear to be exploitable via local code execution and the ability to use ptrace. This vulnerability appears to have been fixed in git commit f67b15037a7a50c57f72e69a6d59941ad90a0f0f.",
        "id": 1577
    },
    {
        "cve_id": "CVE-2006-3635",
        "code_before_change": "void __init\nsetup_arch (char **cmdline_p)\n{\n\tunw_init();\n\n\tia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n\n\t*cmdline_p = __va(ia64_boot_param->command_line);\n\tstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\n\n\tefi_init();\n\tio_port_init();\n\n#ifdef CONFIG_IA64_GENERIC\n\t/* machvec needs to be parsed from the command line\n\t * before parse_early_param() is called to ensure\n\t * that ia64_mv is initialised before any command line\n\t * settings may cause console setup to occur\n\t */\n\tmachvec_init_from_cmdline(*cmdline_p);\n#endif\n\n\tparse_early_param();\n\n\tif (early_console_setup(*cmdline_p) == 0)\n\t\tmark_bsp_online();\n\n#ifdef CONFIG_ACPI\n\t/* Initialize the ACPI boot-time table parser */\n\tacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\n\tacpi_numa_init();\n\tper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n\t\t32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\n\tsmp_build_cpu_map();\t/* happens, e.g., with the Ski simulator */\n# endif\n#endif /* CONFIG_APCI_BOOT */\n\n\tfind_memory();\n\n\t/* process SAL system table: */\n\tia64_sal_init(__va(efi.sal_systab));\n\n#ifdef CONFIG_SMP\n\tcpu_physical_id(0) = hard_smp_processor_id();\n#endif\n\n\tcpu_init();\t/* initialize the bootstrap CPU */\n\tmmu_context_init();\t/* initialize context_id bitmap */\n\n\tcheck_sal_cache_flush();\n\n#ifdef CONFIG_ACPI\n\tacpi_boot_init();\n#endif\n\n#ifdef CONFIG_VT\n\tif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\n\t\tconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\n\t\t/*\n\t\t * Non-legacy systems may route legacy VGA MMIO range to system\n\t\t * memory.  vga_con probes the MMIO hole, so memory looks like\n\t\t * a VGA device to it.  The EFI memory map can tell us if it's\n\t\t * memory so we can avoid this problem.\n\t\t */\n\t\tif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\n\t\t\tconswitchp = &vga_con;\n# endif\n\t}\n#endif\n\n\t/* enable IA-64 Machine Check Abort Handling unless disabled */\n\tif (!nomca)\n\t\tia64_mca_init();\n\n\tplatform_setup(cmdline_p);\n\tpaging_init();\n}",
        "code_after_change": "void __init\nsetup_arch (char **cmdline_p)\n{\n\tunw_init();\n\n\tia64_patch_vtop((u64) __start___vtop_patchlist, (u64) __end___vtop_patchlist);\n\n\t*cmdline_p = __va(ia64_boot_param->command_line);\n\tstrlcpy(boot_command_line, *cmdline_p, COMMAND_LINE_SIZE);\n\n\tefi_init();\n\tio_port_init();\n\n#ifdef CONFIG_IA64_GENERIC\n\t/* machvec needs to be parsed from the command line\n\t * before parse_early_param() is called to ensure\n\t * that ia64_mv is initialised before any command line\n\t * settings may cause console setup to occur\n\t */\n\tmachvec_init_from_cmdline(*cmdline_p);\n#endif\n\n\tparse_early_param();\n\n\tif (early_console_setup(*cmdline_p) == 0)\n\t\tmark_bsp_online();\n\n#ifdef CONFIG_ACPI\n\t/* Initialize the ACPI boot-time table parser */\n\tacpi_table_init();\n# ifdef CONFIG_ACPI_NUMA\n\tacpi_numa_init();\n\tper_cpu_scan_finalize((cpus_weight(early_cpu_possible_map) == 0 ?\n\t\t32 : cpus_weight(early_cpu_possible_map)), additional_cpus);\n# endif\n#else\n# ifdef CONFIG_SMP\n\tsmp_build_cpu_map();\t/* happens, e.g., with the Ski simulator */\n# endif\n#endif /* CONFIG_APCI_BOOT */\n\n\tfind_memory();\n\n\t/* process SAL system table: */\n\tia64_sal_init(__va(efi.sal_systab));\n\n#ifdef CONFIG_ITANIUM\n\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n#else\n\t{\n\t\tu64 num_phys_stacked;\n\n\t\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)\n\t\t\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n\t}\n#endif\n\n#ifdef CONFIG_SMP\n\tcpu_physical_id(0) = hard_smp_processor_id();\n#endif\n\n\tcpu_init();\t/* initialize the bootstrap CPU */\n\tmmu_context_init();\t/* initialize context_id bitmap */\n\n\tcheck_sal_cache_flush();\n\n#ifdef CONFIG_ACPI\n\tacpi_boot_init();\n#endif\n\n#ifdef CONFIG_VT\n\tif (!conswitchp) {\n# if defined(CONFIG_DUMMY_CONSOLE)\n\t\tconswitchp = &dummy_con;\n# endif\n# if defined(CONFIG_VGA_CONSOLE)\n\t\t/*\n\t\t * Non-legacy systems may route legacy VGA MMIO range to system\n\t\t * memory.  vga_con probes the MMIO hole, so memory looks like\n\t\t * a VGA device to it.  The EFI memory map can tell us if it's\n\t\t * memory so we can avoid this problem.\n\t\t */\n\t\tif (efi_mem_type(0xA0000) != EFI_CONVENTIONAL_MEMORY)\n\t\t\tconswitchp = &vga_con;\n# endif\n\t}\n#endif\n\n\t/* enable IA-64 Machine Check Abort Handling unless disabled */\n\tif (!nomca)\n\t\tia64_mca_init();\n\n\tplatform_setup(cmdline_p);\n\tpaging_init();\n}",
        "patch": "--- code before\n+++ code after\n@@ -44,6 +44,17 @@\n \t/* process SAL system table: */\n \tia64_sal_init(__va(efi.sal_systab));\n \n+#ifdef CONFIG_ITANIUM\n+\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n+#else\n+\t{\n+\t\tu64 num_phys_stacked;\n+\n+\t\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)\n+\t\t\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);\n+\t}\n+#endif\n+\n #ifdef CONFIG_SMP\n \tcpu_physical_id(0) = hard_smp_processor_id();\n #endif",
        "function_modified_lines": {
            "added": [
                "#ifdef CONFIG_ITANIUM",
                "\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);",
                "#else",
                "\t{",
                "\t\tu64 num_phys_stacked;",
                "",
                "\t\tif (ia64_pal_rse_info(&num_phys_stacked, 0) == 0 && num_phys_stacked > 96)",
                "\t\t\tia64_patch_rse((u64) __start___rse_patchlist, (u64) __end___rse_patchlist);",
                "\t}",
                "#endif",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The ia64 subsystem in the Linux kernel before 2.6.26 allows local users to cause a denial of service (stack consumption and system crash) via a crafted application that leverages the mishandling of invalid Register Stack Engine (RSE) state.",
        "id": 1
    },
    {
        "cve_id": "CVE-2016-7042",
        "code_before_change": "static int proc_keys_show(struct seq_file *m, void *v)\n{\n\tstruct rb_node *_p = v;\n\tstruct key *key = rb_entry(_p, struct key, serial_node);\n\tstruct timespec now;\n\tunsigned long timo;\n\tkey_ref_t key_ref, skey_ref;\n\tchar xbuf[12];\n\tint rc;\n\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= key->type,\n\t\t.index_key.description\t= key->description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= lookup_user_key_possessed,\n\t\t.match_data.raw_data\t= key,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n\t};\n\n\tkey_ref = make_key_ref(key, 0);\n\n\t/* determine if the key is possessed by this process (a test we can\n\t * skip if the key does not indicate the possessor can view it\n\t */\n\tif (key->perm & KEY_POS_VIEW) {\n\t\tskey_ref = search_my_process_keyrings(&ctx);\n\t\tif (!IS_ERR(skey_ref)) {\n\t\t\tkey_ref_put(skey_ref);\n\t\t\tkey_ref = make_key_ref(key, 1);\n\t\t}\n\t}\n\n\t/* check whether the current task is allowed to view the key (assuming\n\t * non-possession)\n\t * - the caller holds a spinlock, and thus the RCU read lock, making our\n\t *   access to __current_cred() safe\n\t */\n\trc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\n\tif (rc < 0)\n\t\treturn 0;\n\n\tnow = current_kernel_time();\n\n\trcu_read_lock();\n\n\t/* come up with a suitable timeout value */\n\tif (key->expiry == 0) {\n\t\tmemcpy(xbuf, \"perm\", 5);\n\t} else if (now.tv_sec >= key->expiry) {\n\t\tmemcpy(xbuf, \"expd\", 5);\n\t} else {\n\t\ttimo = key->expiry - now.tv_sec;\n\n\t\tif (timo < 60)\n\t\t\tsprintf(xbuf, \"%lus\", timo);\n\t\telse if (timo < 60*60)\n\t\t\tsprintf(xbuf, \"%lum\", timo / 60);\n\t\telse if (timo < 60*60*24)\n\t\t\tsprintf(xbuf, \"%luh\", timo / (60*60));\n\t\telse if (timo < 60*60*24*7)\n\t\t\tsprintf(xbuf, \"%lud\", timo / (60*60*24));\n\t\telse\n\t\t\tsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n\t}\n\n#define showflag(KEY, LETTER, FLAG) \\\n\t(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\n\n\tseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\n\t\t   key->serial,\n\t\t   showflag(key, 'I', KEY_FLAG_INSTANTIATED),\n\t\t   showflag(key, 'R', KEY_FLAG_REVOKED),\n\t\t   showflag(key, 'D', KEY_FLAG_DEAD),\n\t\t   showflag(key, 'Q', KEY_FLAG_IN_QUOTA),\n\t\t   showflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\n\t\t   showflag(key, 'N', KEY_FLAG_NEGATIVE),\n\t\t   showflag(key, 'i', KEY_FLAG_INVALIDATED),\n\t\t   atomic_read(&key->usage),\n\t\t   xbuf,\n\t\t   key->perm,\n\t\t   from_kuid_munged(seq_user_ns(m), key->uid),\n\t\t   from_kgid_munged(seq_user_ns(m), key->gid),\n\t\t   key->type->name);\n\n#undef showflag\n\n\tif (key->type->describe)\n\t\tkey->type->describe(key, m);\n\tseq_putc(m, '\\n');\n\n\trcu_read_unlock();\n\treturn 0;\n}",
        "code_after_change": "static int proc_keys_show(struct seq_file *m, void *v)\n{\n\tstruct rb_node *_p = v;\n\tstruct key *key = rb_entry(_p, struct key, serial_node);\n\tstruct timespec now;\n\tunsigned long timo;\n\tkey_ref_t key_ref, skey_ref;\n\tchar xbuf[16];\n\tint rc;\n\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= key->type,\n\t\t.index_key.description\t= key->description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= lookup_user_key_possessed,\n\t\t.match_data.raw_data\t= key,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_NO_STATE_CHECK,\n\t};\n\n\tkey_ref = make_key_ref(key, 0);\n\n\t/* determine if the key is possessed by this process (a test we can\n\t * skip if the key does not indicate the possessor can view it\n\t */\n\tif (key->perm & KEY_POS_VIEW) {\n\t\tskey_ref = search_my_process_keyrings(&ctx);\n\t\tif (!IS_ERR(skey_ref)) {\n\t\t\tkey_ref_put(skey_ref);\n\t\t\tkey_ref = make_key_ref(key, 1);\n\t\t}\n\t}\n\n\t/* check whether the current task is allowed to view the key (assuming\n\t * non-possession)\n\t * - the caller holds a spinlock, and thus the RCU read lock, making our\n\t *   access to __current_cred() safe\n\t */\n\trc = key_task_permission(key_ref, ctx.cred, KEY_NEED_VIEW);\n\tif (rc < 0)\n\t\treturn 0;\n\n\tnow = current_kernel_time();\n\n\trcu_read_lock();\n\n\t/* come up with a suitable timeout value */\n\tif (key->expiry == 0) {\n\t\tmemcpy(xbuf, \"perm\", 5);\n\t} else if (now.tv_sec >= key->expiry) {\n\t\tmemcpy(xbuf, \"expd\", 5);\n\t} else {\n\t\ttimo = key->expiry - now.tv_sec;\n\n\t\tif (timo < 60)\n\t\t\tsprintf(xbuf, \"%lus\", timo);\n\t\telse if (timo < 60*60)\n\t\t\tsprintf(xbuf, \"%lum\", timo / 60);\n\t\telse if (timo < 60*60*24)\n\t\t\tsprintf(xbuf, \"%luh\", timo / (60*60));\n\t\telse if (timo < 60*60*24*7)\n\t\t\tsprintf(xbuf, \"%lud\", timo / (60*60*24));\n\t\telse\n\t\t\tsprintf(xbuf, \"%luw\", timo / (60*60*24*7));\n\t}\n\n#define showflag(KEY, LETTER, FLAG) \\\n\t(test_bit(FLAG,\t&(KEY)->flags) ? LETTER : '-')\n\n\tseq_printf(m, \"%08x %c%c%c%c%c%c%c %5d %4s %08x %5d %5d %-9.9s \",\n\t\t   key->serial,\n\t\t   showflag(key, 'I', KEY_FLAG_INSTANTIATED),\n\t\t   showflag(key, 'R', KEY_FLAG_REVOKED),\n\t\t   showflag(key, 'D', KEY_FLAG_DEAD),\n\t\t   showflag(key, 'Q', KEY_FLAG_IN_QUOTA),\n\t\t   showflag(key, 'U', KEY_FLAG_USER_CONSTRUCT),\n\t\t   showflag(key, 'N', KEY_FLAG_NEGATIVE),\n\t\t   showflag(key, 'i', KEY_FLAG_INVALIDATED),\n\t\t   atomic_read(&key->usage),\n\t\t   xbuf,\n\t\t   key->perm,\n\t\t   from_kuid_munged(seq_user_ns(m), key->uid),\n\t\t   from_kgid_munged(seq_user_ns(m), key->gid),\n\t\t   key->type->name);\n\n#undef showflag\n\n\tif (key->type->describe)\n\t\tkey->type->describe(key, m);\n\tseq_putc(m, '\\n');\n\n\trcu_read_unlock();\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct timespec now;\n \tunsigned long timo;\n \tkey_ref_t key_ref, skey_ref;\n-\tchar xbuf[12];\n+\tchar xbuf[16];\n \tint rc;\n \n \tstruct keyring_search_context ctx = {",
        "function_modified_lines": {
            "added": [
                "\tchar xbuf[16];"
            ],
            "deleted": [
                "\tchar xbuf[12];"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The proc_keys_show function in security/keys/proc.c in the Linux kernel through 4.8.2, when the GNU Compiler Collection (gcc) stack protector is enabled, uses an incorrect buffer size for certain timeout data, which allows local users to cause a denial of service (stack memory corruption and panic) by reading the /proc/keys file.",
        "id": 1092
    },
    {
        "cve_id": "CVE-2022-3545",
        "code_before_change": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\n\t       u64 addr, unsigned long *offset, size_t length)\n{\n\tstruct nfp_cpp_area_cache *cache;\n\tint err;\n\n\t/* Early exit when length == 0, which prevents\n\t * the need for special case code below when\n\t * checking against available cache size.\n\t */\n\tif (length == 0 || id == 0)\n\t\treturn NULL;\n\n\t/* Remap from cpp_island to cpp_target */\n\terr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\n\tif (err < 0)\n\t\treturn NULL;\n\n\tmutex_lock(&cpp->area_cache_mutex);\n\n\tif (list_empty(&cpp->area_cache_list)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\taddr += *offset;\n\n\t/* See if we have a match */\n\tlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\n\t\tif (id == cache->id &&\n\t\t    addr >= cache->addr &&\n\t\t    addr + length <= cache->addr + cache->size)\n\t\t\tgoto exit;\n\t}\n\n\t/* No matches - inspect the tail of the LRU */\n\tcache = list_entry(cpp->area_cache_list.prev,\n\t\t\t   struct nfp_cpp_area_cache, entry);\n\n\t/* Can we fit in the cache entry? */\n\tif (round_down(addr + length - 1, cache->size) !=\n\t    round_down(addr, cache->size)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\t/* If id != 0, we will need to release it */\n\tif (cache->id) {\n\t\tnfp_cpp_area_release(cache->area);\n\t\tcache->id = 0;\n\t\tcache->addr = 0;\n\t}\n\n\t/* Adjust the start address to be cache size aligned */\n\tcache->id = id;\n\tcache->addr = addr & ~(u64)(cache->size - 1);\n\n\t/* Re-init to the new ID and address */\n\tif (cpp->op->area_init) {\n\t\terr = cpp->op->area_init(cache->area,\n\t\t\t\t\t id, cache->addr, cache->size);\n\t\tif (err < 0) {\n\t\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Attempt to acquire */\n\terr = nfp_cpp_area_acquire(cache->area);\n\tif (err < 0) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\nexit:\n\t/* Adjust offset */\n\t*offset = addr - cache->addr;\n\treturn cache;\n}",
        "code_after_change": "static struct nfp_cpp_area_cache *\narea_cache_get(struct nfp_cpp *cpp, u32 id,\n\t       u64 addr, unsigned long *offset, size_t length)\n{\n\tstruct nfp_cpp_area_cache *cache;\n\tint err;\n\n\t/* Early exit when length == 0, which prevents\n\t * the need for special case code below when\n\t * checking against available cache size.\n\t */\n\tif (length == 0 || id == 0)\n\t\treturn NULL;\n\n\t/* Remap from cpp_island to cpp_target */\n\terr = nfp_target_cpp(id, addr, &id, &addr, cpp->imb_cat_table);\n\tif (err < 0)\n\t\treturn NULL;\n\n\tmutex_lock(&cpp->area_cache_mutex);\n\n\tif (list_empty(&cpp->area_cache_list)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\taddr += *offset;\n\n\t/* See if we have a match */\n\tlist_for_each_entry(cache, &cpp->area_cache_list, entry) {\n\t\tif (id == cache->id &&\n\t\t    addr >= cache->addr &&\n\t\t    addr + length <= cache->addr + cache->size)\n\t\t\tgoto exit;\n\t}\n\n\t/* No matches - inspect the tail of the LRU */\n\tcache = list_entry(cpp->area_cache_list.prev,\n\t\t\t   struct nfp_cpp_area_cache, entry);\n\n\t/* Can we fit in the cache entry? */\n\tif (round_down(addr + length - 1, cache->size) !=\n\t    round_down(addr, cache->size)) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\t/* If id != 0, we will need to release it */\n\tif (cache->id) {\n\t\tnfp_cpp_area_release(cache->area);\n\t\tcache->id = 0;\n\t\tcache->addr = 0;\n\t}\n\n\t/* Adjust the start address to be cache size aligned */\n\tcache->addr = addr & ~(u64)(cache->size - 1);\n\n\t/* Re-init to the new ID and address */\n\tif (cpp->op->area_init) {\n\t\terr = cpp->op->area_init(cache->area,\n\t\t\t\t\t id, cache->addr, cache->size);\n\t\tif (err < 0) {\n\t\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Attempt to acquire */\n\terr = nfp_cpp_area_acquire(cache->area);\n\tif (err < 0) {\n\t\tmutex_unlock(&cpp->area_cache_mutex);\n\t\treturn NULL;\n\t}\n\n\tcache->id = id;\n\nexit:\n\t/* Adjust offset */\n\t*offset = addr - cache->addr;\n\treturn cache;\n}",
        "patch": "--- code before\n+++ code after\n@@ -53,7 +53,6 @@\n \t}\n \n \t/* Adjust the start address to be cache size aligned */\n-\tcache->id = id;\n \tcache->addr = addr & ~(u64)(cache->size - 1);\n \n \t/* Re-init to the new ID and address */\n@@ -73,6 +72,8 @@\n \t\treturn NULL;\n \t}\n \n+\tcache->id = id;\n+\n exit:\n \t/* Adjust offset */\n \t*offset = addr - cache->addr;",
        "function_modified_lines": {
            "added": [
                "\tcache->id = id;",
                ""
            ],
            "deleted": [
                "\tcache->id = id;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A vulnerability has been found in Linux Kernel and classified as critical. Affected by this vulnerability is the function area_cache_get of the file drivers/net/ethernet/netronome/nfp/nfpcore/nfp_cppcore.c of the component IPsec. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier VDB-211045 was assigned to this vulnerability.",
        "id": 3635
    },
    {
        "cve_id": "CVE-2017-8069",
        "code_before_change": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\n\treturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t       RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n\t\t\t       indx, 0, data, size, 500);\n}",
        "code_after_change": "static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n{\n\tvoid *buf;\n\tint ret;\n\n\tbuf = kmalloc(size, GFP_NOIO);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n\t\t\t      indx, 0, buf, size, 500);\n\tif (ret > 0 && ret <= size)\n\t\tmemcpy(data, buf, ret);\n\tkfree(buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,17 @@\n static int get_registers(rtl8150_t * dev, u16 indx, u16 size, void *data)\n {\n-\treturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n-\t\t\t       RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n-\t\t\t       indx, 0, data, size, 500);\n+\tvoid *buf;\n+\tint ret;\n+\n+\tbuf = kmalloc(size, GFP_NOIO);\n+\tif (!buf)\n+\t\treturn -ENOMEM;\n+\n+\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n+\t\t\t      RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,\n+\t\t\t      indx, 0, buf, size, 500);\n+\tif (ret > 0 && ret <= size)\n+\t\tmemcpy(data, buf, ret);\n+\tkfree(buf);\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tvoid *buf;",
                "\tint ret;",
                "",
                "\tbuf = kmalloc(size, GFP_NOIO);",
                "\tif (!buf)",
                "\t\treturn -ENOMEM;",
                "",
                "\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),",
                "\t\t\t      RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,",
                "\t\t\t      indx, 0, buf, size, 500);",
                "\tif (ret > 0 && ret <= size)",
                "\t\tmemcpy(data, buf, ret);",
                "\tkfree(buf);",
                "\treturn ret;"
            ],
            "deleted": [
                "\treturn usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),",
                "\t\t\t       RTL8150_REQ_GET_REGS, RTL8150_REQT_READ,",
                "\t\t\t       indx, 0, data, size, 500);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/usb/rtl8150.c in the Linux kernel 4.9.x before 4.9.11 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1544
    },
    {
        "cve_id": "CVE-2012-6712",
        "code_before_change": "static void iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)\n{\n\n\tif (!(priv->stations[sta_id].used & IWL_STA_DRIVER_ACTIVE))\n\t\tIWL_ERR(priv, \"ACTIVATE a non DRIVER active station id %u \"\n\t\t\t\"addr %pM\\n\",\n\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\n\tif (priv->stations[sta_id].used & IWL_STA_UCODE_ACTIVE) {\n\t\tIWL_DEBUG_ASSOC(priv,\n\t\t\t\t\"STA id %u addr %pM already present in uCode \"\n\t\t\t\t\"(according to driver)\\n\",\n\t\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\t} else {\n\t\tpriv->stations[sta_id].used |= IWL_STA_UCODE_ACTIVE;\n\t\tIWL_DEBUG_ASSOC(priv, \"Added STA id %u addr %pM to uCode\\n\",\n\t\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\t}\n}",
        "code_after_change": "static int iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)\n{\n\tif (sta_id >= IWLAGN_STATION_COUNT) {\n\t\tIWL_ERR(priv, \"invalid sta_id %u\", sta_id);\n\t\treturn -EINVAL;\n\t}\n\tif (!(priv->stations[sta_id].used & IWL_STA_DRIVER_ACTIVE))\n\t\tIWL_ERR(priv, \"ACTIVATE a non DRIVER active station id %u \"\n\t\t\t\"addr %pM\\n\",\n\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\n\tif (priv->stations[sta_id].used & IWL_STA_UCODE_ACTIVE) {\n\t\tIWL_DEBUG_ASSOC(priv,\n\t\t\t\t\"STA id %u addr %pM already present in uCode \"\n\t\t\t\t\"(according to driver)\\n\",\n\t\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\t} else {\n\t\tpriv->stations[sta_id].used |= IWL_STA_UCODE_ACTIVE;\n\t\tIWL_DEBUG_ASSOC(priv, \"Added STA id %u addr %pM to uCode\\n\",\n\t\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,9 @@\n-static void iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)\n+static int iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)\n {\n-\n+\tif (sta_id >= IWLAGN_STATION_COUNT) {\n+\t\tIWL_ERR(priv, \"invalid sta_id %u\", sta_id);\n+\t\treturn -EINVAL;\n+\t}\n \tif (!(priv->stations[sta_id].used & IWL_STA_DRIVER_ACTIVE))\n \t\tIWL_ERR(priv, \"ACTIVATE a non DRIVER active station id %u \"\n \t\t\t\"addr %pM\\n\",\n@@ -16,4 +19,5 @@\n \t\tIWL_DEBUG_ASSOC(priv, \"Added STA id %u addr %pM to uCode\\n\",\n \t\t\t\tsta_id, priv->stations[sta_id].sta.sta.addr);\n \t}\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "static int iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)",
                "\tif (sta_id >= IWLAGN_STATION_COUNT) {",
                "\t\tIWL_ERR(priv, \"invalid sta_id %u\", sta_id);",
                "\t\treturn -EINVAL;",
                "\t}",
                "\treturn 0;"
            ],
            "deleted": [
                "static void iwl_sta_ucode_activate(struct iwl_priv *priv, u8 sta_id)",
                ""
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 3.4, a buffer overflow occurs in drivers/net/wireless/iwlwifi/iwl-agn-sta.c, which will cause at least memory corruption.",
        "id": 144
    },
    {
        "cve_id": "CVE-2016-8632",
        "code_before_change": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\n\t\t\t\tvoid *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct net *net = dev_net(dev);\n\tstruct tipc_bearer *b;\n\n\tb = rtnl_dereference(dev->tipc_ptr);\n\tif (!b)\n\t\treturn NOTIFY_DONE;\n\n\tb->mtu = dev->mtu;\n\n\tswitch (evt) {\n\tcase NETDEV_CHANGE:\n\t\tif (netif_carrier_ok(dev))\n\t\t\tbreak;\n\tcase NETDEV_UP:\n\t\ttest_and_set_bit_lock(0, &b->up);\n\t\tbreak;\n\tcase NETDEV_GOING_DOWN:\n\t\tclear_bit_unlock(0, &b->up);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEADDR:\n\t\tb->media->raw2addr(b, &b->addr,\n\t\t\t\t   (char *)dev->dev_addr);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\tcase NETDEV_CHANGENAME:\n\t\tbearer_disable(dev_net(dev), b);\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}",
        "code_after_change": "static int tipc_l2_device_event(struct notifier_block *nb, unsigned long evt,\n\t\t\t\tvoid *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\tstruct net *net = dev_net(dev);\n\tstruct tipc_bearer *b;\n\n\tb = rtnl_dereference(dev->tipc_ptr);\n\tif (!b)\n\t\treturn NOTIFY_DONE;\n\n\tswitch (evt) {\n\tcase NETDEV_CHANGE:\n\t\tif (netif_carrier_ok(dev))\n\t\t\tbreak;\n\tcase NETDEV_UP:\n\t\ttest_and_set_bit_lock(0, &b->up);\n\t\tbreak;\n\tcase NETDEV_GOING_DOWN:\n\t\tclear_bit_unlock(0, &b->up);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\tif (tipc_mtu_bad(dev, 0)) {\n\t\t\tbearer_disable(net, b);\n\t\t\tbreak;\n\t\t}\n\t\tb->mtu = dev->mtu;\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_CHANGEADDR:\n\t\tb->media->raw2addr(b, &b->addr,\n\t\t\t\t   (char *)dev->dev_addr);\n\t\ttipc_reset_bearer(net, b);\n\t\tbreak;\n\tcase NETDEV_UNREGISTER:\n\tcase NETDEV_CHANGENAME:\n\t\tbearer_disable(dev_net(dev), b);\n\t\tbreak;\n\t}\n\treturn NOTIFY_OK;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,8 +8,6 @@\n \tb = rtnl_dereference(dev->tipc_ptr);\n \tif (!b)\n \t\treturn NOTIFY_DONE;\n-\n-\tb->mtu = dev->mtu;\n \n \tswitch (evt) {\n \tcase NETDEV_CHANGE:\n@@ -23,6 +21,11 @@\n \t\ttipc_reset_bearer(net, b);\n \t\tbreak;\n \tcase NETDEV_CHANGEMTU:\n+\t\tif (tipc_mtu_bad(dev, 0)) {\n+\t\t\tbearer_disable(net, b);\n+\t\t\tbreak;\n+\t\t}\n+\t\tb->mtu = dev->mtu;\n \t\ttipc_reset_bearer(net, b);\n \t\tbreak;\n \tcase NETDEV_CHANGEADDR:",
        "function_modified_lines": {
            "added": [
                "\t\tif (tipc_mtu_bad(dev, 0)) {",
                "\t\t\tbearer_disable(net, b);",
                "\t\t\tbreak;",
                "\t\t}",
                "\t\tb->mtu = dev->mtu;"
            ],
            "deleted": [
                "",
                "\tb->mtu = dev->mtu;"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-119"
        ],
        "cve_description": "The tipc_msg_build function in net/tipc/msg.c in the Linux kernel through 4.8.11 does not validate the relationship between the minimum fragment length and the maximum packet size, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) by leveraging the CAP_NET_ADMIN capability.",
        "id": 1120
    },
    {
        "cve_id": "CVE-2012-2119",
        "code_before_change": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\n\t\t\t\t  int offset, size_t count)\n{\n\tint len = iov_length(from, count) - offset;\n\tint copy = skb_headlen(skb);\n\tint size, offset1 = 0;\n\tint i = 0;\n\n\t/* Skip over from offset */\n\twhile (count && (offset >= from->iov_len)) {\n\t\toffset -= from->iov_len;\n\t\t++from;\n\t\t--count;\n\t}\n\n\t/* copy up to skb headlen */\n\twhile (count && (copy > 0)) {\n\t\tsize = min_t(unsigned int, copy, from->iov_len - offset);\n\t\tif (copy_from_user(skb->data + offset1, from->iov_base + offset,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\t\tif (copy > size) {\n\t\t\t++from;\n\t\t\t--count;\n\t\t}\n\t\tcopy -= size;\n\t\toffset1 += size;\n\t\toffset = 0;\n\t}\n\n\tif (len == offset1)\n\t\treturn 0;\n\n\twhile (count--) {\n\t\tstruct page *page[MAX_SKB_FRAGS];\n\t\tint num_pages;\n\t\tunsigned long base;\n\n\t\tlen = from->iov_len - offset1;\n\t\tif (!len) {\n\t\t\toffset1 = 0;\n\t\t\t++from;\n\t\t\tcontinue;\n\t\t}\n\t\tbase = (unsigned long)from->iov_base + offset1;\n\t\tsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\n\t\tnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\n\t\tif ((num_pages != size) ||\n\t\t    (num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\n\t\t\t/* put_page is in skb free */\n\t\t\treturn -EFAULT;\n\t\tskb->data_len += len;\n\t\tskb->len += len;\n\t\tskb->truesize += len;\n\t\tatomic_add(len, &skb->sk->sk_wmem_alloc);\n\t\twhile (len) {\n\t\t\tint off = base & ~PAGE_MASK;\n\t\t\tint size = min_t(int, len, PAGE_SIZE - off);\n\t\t\t__skb_fill_page_desc(skb, i, page[i], off, size);\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t\t/* increase sk_wmem_alloc */\n\t\t\tbase += size;\n\t\t\tlen -= size;\n\t\t\ti++;\n\t\t}\n\t\toffset1 = 0;\n\t\t++from;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int zerocopy_sg_from_iovec(struct sk_buff *skb, const struct iovec *from,\n\t\t\t\t  int offset, size_t count)\n{\n\tint len = iov_length(from, count) - offset;\n\tint copy = skb_headlen(skb);\n\tint size, offset1 = 0;\n\tint i = 0;\n\n\t/* Skip over from offset */\n\twhile (count && (offset >= from->iov_len)) {\n\t\toffset -= from->iov_len;\n\t\t++from;\n\t\t--count;\n\t}\n\n\t/* copy up to skb headlen */\n\twhile (count && (copy > 0)) {\n\t\tsize = min_t(unsigned int, copy, from->iov_len - offset);\n\t\tif (copy_from_user(skb->data + offset1, from->iov_base + offset,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\t\tif (copy > size) {\n\t\t\t++from;\n\t\t\t--count;\n\t\t\toffset = 0;\n\t\t} else\n\t\t\toffset += size;\n\t\tcopy -= size;\n\t\toffset1 += size;\n\t}\n\n\tif (len == offset1)\n\t\treturn 0;\n\n\twhile (count--) {\n\t\tstruct page *page[MAX_SKB_FRAGS];\n\t\tint num_pages;\n\t\tunsigned long base;\n\n\t\tlen = from->iov_len - offset;\n\t\tif (!len) {\n\t\t\toffset = 0;\n\t\t\t++from;\n\t\t\tcontinue;\n\t\t}\n\t\tbase = (unsigned long)from->iov_base + offset;\n\t\tsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\n\t\tnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\n\t\tif ((num_pages != size) ||\n\t\t    (num_pages > MAX_SKB_FRAGS - skb_shinfo(skb)->nr_frags))\n\t\t\t/* put_page is in skb free */\n\t\t\treturn -EFAULT;\n\t\tskb->data_len += len;\n\t\tskb->len += len;\n\t\tskb->truesize += len;\n\t\tatomic_add(len, &skb->sk->sk_wmem_alloc);\n\t\twhile (len) {\n\t\t\tint off = base & ~PAGE_MASK;\n\t\t\tint size = min_t(int, len, PAGE_SIZE - off);\n\t\t\t__skb_fill_page_desc(skb, i, page[i], off, size);\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t\t/* increase sk_wmem_alloc */\n\t\t\tbase += size;\n\t\t\tlen -= size;\n\t\t\ti++;\n\t\t}\n\t\toffset = 0;\n\t\t++from;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,10 +22,11 @@\n \t\tif (copy > size) {\n \t\t\t++from;\n \t\t\t--count;\n-\t\t}\n+\t\t\toffset = 0;\n+\t\t} else\n+\t\t\toffset += size;\n \t\tcopy -= size;\n \t\toffset1 += size;\n-\t\toffset = 0;\n \t}\n \n \tif (len == offset1)\n@@ -36,13 +37,13 @@\n \t\tint num_pages;\n \t\tunsigned long base;\n \n-\t\tlen = from->iov_len - offset1;\n+\t\tlen = from->iov_len - offset;\n \t\tif (!len) {\n-\t\t\toffset1 = 0;\n+\t\t\toffset = 0;\n \t\t\t++from;\n \t\t\tcontinue;\n \t\t}\n-\t\tbase = (unsigned long)from->iov_base + offset1;\n+\t\tbase = (unsigned long)from->iov_base + offset;\n \t\tsize = ((base & ~PAGE_MASK) + len + ~PAGE_MASK) >> PAGE_SHIFT;\n \t\tnum_pages = get_user_pages_fast(base, size, 0, &page[i]);\n \t\tif ((num_pages != size) ||\n@@ -63,7 +64,7 @@\n \t\t\tlen -= size;\n \t\t\ti++;\n \t\t}\n-\t\toffset1 = 0;\n+\t\toffset = 0;\n \t\t++from;\n \t}\n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\t\t\toffset = 0;",
                "\t\t} else",
                "\t\t\toffset += size;",
                "\t\tlen = from->iov_len - offset;",
                "\t\t\toffset = 0;",
                "\t\tbase = (unsigned long)from->iov_base + offset;",
                "\t\toffset = 0;"
            ],
            "deleted": [
                "\t\t}",
                "\t\toffset = 0;",
                "\t\tlen = from->iov_len - offset1;",
                "\t\t\toffset1 = 0;",
                "\t\tbase = (unsigned long)from->iov_base + offset1;",
                "\t\toffset1 = 0;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the macvtap device driver in the Linux kernel before 3.4.5, when running in certain configurations, allows privileged KVM guest users to cause a denial of service (crash) via a long descriptor with a long vector length.",
        "id": 40
    },
    {
        "cve_id": "CVE-2017-7895",
        "code_before_change": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd_writeargs *args)\n{\n\tunsigned int len, hdr, dlen;\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tint v;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\n\tp++;\t\t\t\t/* beginoffset */\n\targs->offset = ntohl(*p++);\t/* offset */\n\tp++;\t\t\t\t/* totalcount */\n\tlen = args->len = ntohl(*p++);\n\t/*\n\t * The protocol specifies a maximum of 8192 bytes.\n\t */\n\tif (len > NFSSVC_MAXBLKSIZE_V2)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\n\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
        "code_after_change": "int\nnfssvc_decode_writeargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd_writeargs *args)\n{\n\tunsigned int len, hdr, dlen;\n\tstruct kvec *head = rqstp->rq_arg.head;\n\tint v;\n\n\tp = decode_fh(p, &args->fh);\n\tif (!p)\n\t\treturn 0;\n\n\tp++;\t\t\t\t/* beginoffset */\n\targs->offset = ntohl(*p++);\t/* offset */\n\tp++;\t\t\t\t/* totalcount */\n\tlen = args->len = ntohl(*p++);\n\t/*\n\t * The protocol specifies a maximum of 8192 bytes.\n\t */\n\tif (len > NFSSVC_MAXBLKSIZE_V2)\n\t\treturn 0;\n\n\t/*\n\t * Check to make sure that we got the right number of\n\t * bytes.\n\t */\n\thdr = (void*)p - head->iov_base;\n\tif (hdr > head->iov_len)\n\t\treturn 0;\n\tdlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\n\n\t/*\n\t * Round the length of the data which was specified up to\n\t * the next multiple of XDR units and then compare that\n\t * against the length which was actually received.\n\t * Note that when RPCSEC/GSS (for example) is used, the\n\t * data buffer can be padded so dlen might be larger\n\t * than required.  It must never be smaller.\n\t */\n\tif (dlen < XDR_QUADLEN(len)*4)\n\t\treturn 0;\n\n\trqstp->rq_vec[0].iov_base = (void*)p;\n\trqstp->rq_vec[0].iov_len = head->iov_len - hdr;\n\tv = 0;\n\twhile (len > rqstp->rq_vec[v].iov_len) {\n\t\tlen -= rqstp->rq_vec[v].iov_len;\n\t\tv++;\n\t\trqstp->rq_vec[v].iov_base = page_address(rqstp->rq_pages[v]);\n\t\trqstp->rq_vec[v].iov_len = PAGE_SIZE;\n\t}\n\trqstp->rq_vec[v].iov_len = len;\n\targs->vlen = v + 1;\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,8 @@\n \t * bytes.\n \t */\n \thdr = (void*)p - head->iov_base;\n+\tif (hdr > head->iov_len)\n+\t\treturn 0;\n \tdlen = head->iov_len + rqstp->rq_arg.page_len - hdr;\n \n \t/*",
        "function_modified_lines": {
            "added": [
                "\tif (hdr > head->iov_len)",
                "\t\treturn 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The NFSv2 and NFSv3 server implementations in the Linux kernel through 4.10.13 lack certain checks for the end of a buffer, which allows remote attackers to trigger pointer-arithmetic errors or possibly have unspecified other impact via crafted requests, related to fs/nfsd/nfs3xdr.c and fs/nfsd/nfsxdr.c.",
        "id": 1533
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static int mark_source_chains(const struct xt_table_info *newinfo,\n\t\t\t      unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t * to 0 as we leave), and comefrom to save source hook bitmask.\n\t */\n\tfor (hook = 0; hook < NF_ARP_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct arpt_entry *e\n\t\t\t= (struct arpt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)arpt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_ARP_NUMHOOKS)) {\n\t\t\t\tpr_notice(\"arptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom\n\t\t\t\t|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((e->target_offset == sizeof(struct arpt_entry) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0 && unconditional(&e->arp)) ||\n\t\t\t    visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t * big jump.\n\t\t\t\t */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_ARP_NUMHOOKS);\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct arpt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int mark_source_chains(const struct xt_table_info *newinfo,\n\t\t\t      unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t * to 0 as we leave), and comefrom to save source hook bitmask.\n\t */\n\tfor (hook = 0; hook < NF_ARP_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct arpt_entry *e\n\t\t\t= (struct arpt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)arpt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_ARP_NUMHOOKS)) {\n\t\t\t\tpr_notice(\"arptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom\n\t\t\t\t|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t * big jump.\n\t\t\t\t */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_ARP_NUMHOOKS);\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct arpt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,11 +31,10 @@\n \t\t\t\t|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));\n \n \t\t\t/* Unconditional return/END. */\n-\t\t\tif ((e->target_offset == sizeof(struct arpt_entry) &&\n+\t\t\tif ((unconditional(e) &&\n \t\t\t     (strcmp(t->target.u.user.name,\n \t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n-\t\t\t     t->verdict < 0 && unconditional(&e->arp)) ||\n-\t\t\t    visited) {\n+\t\t\t     t->verdict < 0) || visited) {\n \t\t\t\tunsigned int oldpos, size;\n \n \t\t\t\tif ((strcmp(t->target.u.user.name,",
        "function_modified_lines": {
            "added": [
                "\t\t\tif ((unconditional(e) &&",
                "\t\t\t     t->verdict < 0) || visited) {"
            ],
            "deleted": [
                "\t\t\tif ((e->target_offset == sizeof(struct arpt_entry) &&",
                "\t\t\t     t->verdict < 0 && unconditional(&e->arp)) ||",
                "\t\t\t    visited) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 964
    },
    {
        "cve_id": "CVE-2014-0205",
        "code_before_change": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\n\tspin_unlock(&hb->lock);\n\tdrop_futex_key_refs(&q->key);\n}",
        "code_after_change": "static inline void\nqueue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n{\n\tspin_unlock(&hb->lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,5 +2,4 @@\n queue_unlock(struct futex_q *q, struct futex_hash_bucket *hb)\n {\n \tspin_unlock(&hb->lock);\n-\tdrop_futex_key_refs(&q->key);\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tdrop_futex_key_refs(&q->key);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The futex_wait function in kernel/futex.c in the Linux kernel before 2.6.37 does not properly maintain a certain reference count during requeue operations, which allows local users to cause a denial of service (use-after-free and system crash) or possibly gain privileges via a crafted application that triggers a zero count.",
        "id": 464
    },
    {
        "cve_id": "CVE-2015-2666",
        "code_before_change": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\n\t\t\t     void *data, size_t size,\n\t\t\t     struct mc_saved_data *mc_saved_data,\n\t\t\t     unsigned long *mc_saved_in_initrd,\n\t\t\t     struct ucode_cpu_info *uci)\n{\n\tu8 *ucode_ptr = data;\n\tunsigned int leftover = size;\n\tenum ucode_state state = UCODE_OK;\n\tunsigned int mc_size;\n\tstruct microcode_header_intel *mc_header;\n\tstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\n\tunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\n\tint i;\n\n\twhile (leftover) {\n\t\tmc_header = (struct microcode_header_intel *)ucode_ptr;\n\n\t\tmc_size = get_totalsize(mc_header);\n\t\tif (!mc_size || mc_size > leftover ||\n\t\t\tmicrocode_sanity_check(ucode_ptr, 0) < 0)\n\t\t\tbreak;\n\n\t\tleftover -= mc_size;\n\n\t\t/*\n\t\t * Since APs with same family and model as the BSP may boot in\n\t\t * the platform, we need to find and save microcode patches\n\t\t * with the same family and model as the BSP.\n\t\t */\n\t\tif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\n\t\t\t UCODE_OK) {\n\t\t\tucode_ptr += mc_size;\n\t\t\tcontinue;\n\t\t}\n\n\t\t_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\n\n\t\tucode_ptr += mc_size;\n\t}\n\n\tif (leftover) {\n\t\tstate = UCODE_ERROR;\n\t\tgoto out;\n\t}\n\n\tif (mc_saved_count == 0) {\n\t\tstate = UCODE_NFOUND;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < mc_saved_count; i++)\n\t\tmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\n\n\tmc_saved_data->mc_saved_count = mc_saved_count;\nout:\n\treturn state;\n}",
        "code_after_change": "static enum ucode_state __init\nget_matching_model_microcode(int cpu, unsigned long start,\n\t\t\t     void *data, size_t size,\n\t\t\t     struct mc_saved_data *mc_saved_data,\n\t\t\t     unsigned long *mc_saved_in_initrd,\n\t\t\t     struct ucode_cpu_info *uci)\n{\n\tu8 *ucode_ptr = data;\n\tunsigned int leftover = size;\n\tenum ucode_state state = UCODE_OK;\n\tunsigned int mc_size;\n\tstruct microcode_header_intel *mc_header;\n\tstruct microcode_intel *mc_saved_tmp[MAX_UCODE_COUNT];\n\tunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\n\tint i;\n\n\twhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {\n\t\tmc_header = (struct microcode_header_intel *)ucode_ptr;\n\n\t\tmc_size = get_totalsize(mc_header);\n\t\tif (!mc_size || mc_size > leftover ||\n\t\t\tmicrocode_sanity_check(ucode_ptr, 0) < 0)\n\t\t\tbreak;\n\n\t\tleftover -= mc_size;\n\n\t\t/*\n\t\t * Since APs with same family and model as the BSP may boot in\n\t\t * the platform, we need to find and save microcode patches\n\t\t * with the same family and model as the BSP.\n\t\t */\n\t\tif (matching_model_microcode(mc_header, uci->cpu_sig.sig) !=\n\t\t\t UCODE_OK) {\n\t\t\tucode_ptr += mc_size;\n\t\t\tcontinue;\n\t\t}\n\n\t\t_save_mc(mc_saved_tmp, ucode_ptr, &mc_saved_count);\n\n\t\tucode_ptr += mc_size;\n\t}\n\n\tif (leftover) {\n\t\tstate = UCODE_ERROR;\n\t\tgoto out;\n\t}\n\n\tif (mc_saved_count == 0) {\n\t\tstate = UCODE_NFOUND;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < mc_saved_count; i++)\n\t\tmc_saved_in_initrd[i] = (unsigned long)mc_saved_tmp[i] - start;\n\n\tmc_saved_data->mc_saved_count = mc_saved_count;\nout:\n\treturn state;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,7 @@\n \tunsigned int mc_saved_count = mc_saved_data->mc_saved_count;\n \tint i;\n \n-\twhile (leftover) {\n+\twhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {\n \t\tmc_header = (struct microcode_header_intel *)ucode_ptr;\n \n \t\tmc_size = get_totalsize(mc_header);",
        "function_modified_lines": {
            "added": [
                "\twhile (leftover && mc_saved_count < ARRAY_SIZE(mc_saved_tmp)) {"
            ],
            "deleted": [
                "\twhile (leftover) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Stack-based buffer overflow in the get_matching_model_microcode function in arch/x86/kernel/cpu/microcode/intel_early.c in the Linux kernel before 4.0 allows context-dependent attackers to gain privileges by constructing a crafted microcode header and leveraging root privileges for write access to the initrd.",
        "id": 740
    },
    {
        "cve_id": "CVE-2010-5332",
        "code_before_change": "int mlx4_register_vlan(struct mlx4_dev *dev, u8 port, u16 vlan, int *index)\n{\n\tstruct mlx4_vlan_table *table = &mlx4_priv(dev)->port[port].vlan_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmutex_lock(&table->mutex);\n\tfor (i = MLX4_VLAN_REGULAR; i < MLX4_MAX_VLAN_NUM; i++) {\n\t\tif (free < 0 && (table->refs[i] == 0)) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (table->refs[i] &&\n\t\t    (vlan == (MLX4_VLAN_MASK &\n\t\t\t      be32_to_cpu(table->entries[i])))) {\n\t\t\t/* Vlan already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (table->total == table->max) {\n\t\t/* No free vlan entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be32(vlan | MLX4_VLAN_VALID);\n\n\terr = mlx4_set_port_vlan_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_warn(dev, \"Failed adding vlan: %u\\n\", vlan);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
        "code_after_change": "int mlx4_register_vlan(struct mlx4_dev *dev, u8 port, u16 vlan, int *index)\n{\n\tstruct mlx4_vlan_table *table = &mlx4_priv(dev)->port[port].vlan_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmutex_lock(&table->mutex);\n\tfor (i = MLX4_VLAN_REGULAR; i < MLX4_MAX_VLAN_NUM; i++) {\n\t\tif (free < 0 && (table->refs[i] == 0)) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (table->refs[i] &&\n\t\t    (vlan == (MLX4_VLAN_MASK &\n\t\t\t      be32_to_cpu(table->entries[i])))) {\n\t\t\t/* Vlan already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (free < 0) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (table->total == table->max) {\n\t\t/* No free vlan entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be32(vlan | MLX4_VLAN_VALID);\n\n\terr = mlx4_set_port_vlan_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_warn(dev, \"Failed adding vlan: %u\\n\", vlan);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,11 @@\n \t\t\t++table->refs[i];\n \t\t\tgoto out;\n \t\t}\n+\t}\n+\n+\tif (free < 0) {\n+\t\terr = -ENOMEM;\n+\t\tgoto out;\n \t}\n \n \tif (table->total == table->max) {",
        "function_modified_lines": {
            "added": [
                "\t}",
                "",
                "\tif (free < 0) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto out;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 2.6.37, an out of bounds array access happened in drivers/net/mlx4/port.c. When searching for a free entry in either mlx4_register_vlan() or mlx4_register_mac(), and there is no free entry, the loop terminates without updating the local variable free thus causing out of array bounds access.",
        "id": 29
    },
    {
        "cve_id": "CVE-2016-4998",
        "code_before_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "code_after_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,7 +31,7 @@\n \tif (!arp_checkentry(&e->arp))\n \t\treturn -EINVAL;\n \n-\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n+\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n \t\t\t\t\t    e->next_offset);\n \tif (ret)\n \t\treturn ret;",
        "function_modified_lines": {
            "added": [
                "\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,"
            ],
            "deleted": [
                "\tret = xt_compat_check_entry_offsets(e, e->target_offset,"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The IPT_SO_SET_REPLACE setsockopt implementation in the netfilter subsystem in the Linux kernel before 4.6 allows local users to cause a denial of service (out-of-bounds read) or possibly obtain sensitive information from kernel heap memory by leveraging in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.",
        "id": 1045
    },
    {
        "cve_id": "CVE-2013-2890",
        "code_before_change": "static int buzz_init(struct hid_device *hdev)\n{\n\tstruct sony_sc *drv_data;\n\tstruct buzz_extra *buzz;\n\tint n, ret = 0;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tdrv_data = hid_get_drvdata(hdev);\n\tBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\n\n\tbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\n\tif (!buzz) {\n\t\thid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->extra = buzz;\n\n\t/* Clear LEDs as we have no way of reading their initial state. This is\n\t * only relevant if the driver is loaded after somebody actively set the\n\t * LEDs to on */\n\tbuzz_set_leds(hdev, 0x00);\n\n\tname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\n\n\tfor (n = 0; n < 4; n++) {\n\t\tled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = buzz_led_get_brightness;\n\t\tled->brightness_set = buzz_led_set_brightness;\n\n\t\tif (led_classdev_register(&hdev->dev, led)) {\n\t\t\thid_err(hdev, \"Failed to register LED %d\\n\", n);\n\t\t\tkfree(led);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tbuzz->leds[n] = led;\n\t}\n\n\treturn ret;\n\nerror_leds:\n\tfor (n = 0; n < 4; n++) {\n\t\tled = buzz->leds[n];\n\t\tbuzz->leds[n] = NULL;\n\t\tif (!led)\n\t\t\tcontinue;\n\t\tled_classdev_unregister(led);\n\t\tkfree(led);\n\t}\n\n\tkfree(drv_data->extra);\n\tdrv_data->extra = NULL;\n\treturn ret;\n}",
        "code_after_change": "static int buzz_init(struct hid_device *hdev)\n{\n\tstruct sony_sc *drv_data;\n\tstruct buzz_extra *buzz;\n\tint n, ret = 0;\n\tstruct led_classdev *led;\n\tsize_t name_sz;\n\tchar *name;\n\n\tdrv_data = hid_get_drvdata(hdev);\n\tBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\n\n\t/* Validate expected report characteristics. */\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))\n\t\treturn -ENODEV;\n\n\tbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\n\tif (!buzz) {\n\t\thid_err(hdev, \"Insufficient memory, cannot allocate driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tdrv_data->extra = buzz;\n\n\t/* Clear LEDs as we have no way of reading their initial state. This is\n\t * only relevant if the driver is loaded after somebody actively set the\n\t * LEDs to on */\n\tbuzz_set_leds(hdev, 0x00);\n\n\tname_sz = strlen(dev_name(&hdev->dev)) + strlen(\"::buzz#\") + 1;\n\n\tfor (n = 0; n < 4; n++) {\n\t\tled = kzalloc(sizeof(struct led_classdev) + name_sz, GFP_KERNEL);\n\t\tif (!led) {\n\t\t\thid_err(hdev, \"Couldn't allocate memory for LED %d\\n\", n);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tname = (void *)(&led[1]);\n\t\tsnprintf(name, name_sz, \"%s::buzz%d\", dev_name(&hdev->dev), n + 1);\n\t\tled->name = name;\n\t\tled->brightness = 0;\n\t\tled->max_brightness = 1;\n\t\tled->brightness_get = buzz_led_get_brightness;\n\t\tled->brightness_set = buzz_led_set_brightness;\n\n\t\tif (led_classdev_register(&hdev->dev, led)) {\n\t\t\thid_err(hdev, \"Failed to register LED %d\\n\", n);\n\t\t\tkfree(led);\n\t\t\tgoto error_leds;\n\t\t}\n\n\t\tbuzz->leds[n] = led;\n\t}\n\n\treturn ret;\n\nerror_leds:\n\tfor (n = 0; n < 4; n++) {\n\t\tled = buzz->leds[n];\n\t\tbuzz->leds[n] = NULL;\n\t\tif (!led)\n\t\t\tcontinue;\n\t\tled_classdev_unregister(led);\n\t\tkfree(led);\n\t}\n\n\tkfree(drv_data->extra);\n\tdrv_data->extra = NULL;\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,10 @@\n \n \tdrv_data = hid_get_drvdata(hdev);\n \tBUG_ON(!(drv_data->quirks & BUZZ_CONTROLLER));\n+\n+\t/* Validate expected report characteristics. */\n+\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))\n+\t\treturn -ENODEV;\n \n \tbuzz = kzalloc(sizeof(*buzz), GFP_KERNEL);\n \tif (!buzz) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* Validate expected report characteristics. */",
                "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 0, 0, 7))",
                "\t\treturn -ENODEV;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-sony.c in the Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_HID_SONY is enabled, allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) via a crafted device.",
        "id": 247
    },
    {
        "cve_id": "CVE-2013-2893",
        "code_before_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct list_head *report_list =\n\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\tif (list_empty(report_list)) {\n\t\thid_err(hid, \"no output report found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treport = list_entry(report_list->next, struct hid_report, list);\n\n\tif (report->maxfield < 1) {\n\t\thid_err(hid, \"output report is empty\\n\");\n\t\treturn -ENODEV;\n\t}\n\tif (report->field[0]->report_count < 7) {\n\t\thid_err(hid, \"not enough values in the field\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
        "code_after_change": "int lg2ff_init(struct hid_device *hid)\n{\n\tstruct lg2ff_device *lg2ff;\n\tstruct hid_report *report;\n\tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n\t\t\t\t\t\tstruct hid_input, list);\n\tstruct input_dev *dev = hidinput->input;\n\tint error;\n\n\t/* Check that the report looks ok */\n\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\n\tif (!report)\n\t\treturn -ENODEV;\n\n\tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n\tif (!lg2ff)\n\t\treturn -ENOMEM;\n\n\tset_bit(FF_RUMBLE, dev->ffbit);\n\n\terror = input_ff_create_memless(dev, lg2ff, play_effect);\n\tif (error) {\n\t\tkfree(lg2ff);\n\t\treturn error;\n\t}\n\n\tlg2ff->report = report;\n\treport->field[0]->value[0] = 0xf3;\n\treport->field[0]->value[1] = 0x00;\n\treport->field[0]->value[2] = 0x00;\n\treport->field[0]->value[3] = 0x00;\n\treport->field[0]->value[4] = 0x00;\n\treport->field[0]->value[5] = 0x00;\n\treport->field[0]->value[6] = 0x00;\n\n\thid_hw_request(hid, report, HID_REQ_SET_REPORT);\n\n\thid_info(hid, \"Force feedback for Logitech RumblePad/Rumblepad 2 by Anssi Hannula <anssi.hannula@gmail.com>\\n\");\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,26 +4,13 @@\n \tstruct hid_report *report;\n \tstruct hid_input *hidinput = list_entry(hid->inputs.next,\n \t\t\t\t\t\tstruct hid_input, list);\n-\tstruct list_head *report_list =\n-\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;\n \tstruct input_dev *dev = hidinput->input;\n \tint error;\n \n-\tif (list_empty(report_list)) {\n-\t\thid_err(hid, \"no output report found\\n\");\n+\t/* Check that the report looks ok */\n+\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);\n+\tif (!report)\n \t\treturn -ENODEV;\n-\t}\n-\n-\treport = list_entry(report_list->next, struct hid_report, list);\n-\n-\tif (report->maxfield < 1) {\n-\t\thid_err(hid, \"output report is empty\\n\");\n-\t\treturn -ENODEV;\n-\t}\n-\tif (report->field[0]->report_count < 7) {\n-\t\thid_err(hid, \"not enough values in the field\\n\");\n-\t\treturn -ENODEV;\n-\t}\n \n \tlg2ff = kmalloc(sizeof(struct lg2ff_device), GFP_KERNEL);\n \tif (!lg2ff)",
        "function_modified_lines": {
            "added": [
                "\t/* Check that the report looks ok */",
                "\treport = hid_validate_values(hid, HID_OUTPUT_REPORT, 0, 0, 7);",
                "\tif (!report)"
            ],
            "deleted": [
                "\tstruct list_head *report_list =",
                "\t\t\t&hid->report_enum[HID_OUTPUT_REPORT].report_list;",
                "\tif (list_empty(report_list)) {",
                "\t\thid_err(hid, \"no output report found\\n\");",
                "\t}",
                "",
                "\treport = list_entry(report_list->next, struct hid_report, list);",
                "",
                "\tif (report->maxfield < 1) {",
                "\t\thid_err(hid, \"output report is empty\\n\");",
                "\t\treturn -ENODEV;",
                "\t}",
                "\tif (report->field[0]->report_count < 7) {",
                "\t\thid_err(hid, \"not enough values in the field\\n\");",
                "\t\treturn -ENODEV;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_LOGITECH_FF, CONFIG_LOGIG940_FF, or CONFIG_LOGIWHEELS_FF is enabled, allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) via a crafted device, related to (1) drivers/hid/hid-lgff.c, (2) drivers/hid/hid-lg3ff.c, and (3) drivers/hid/hid-lg4ff.c.",
        "id": 249
    },
    {
        "cve_id": "CVE-2023-21264",
        "code_before_change": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\n\t\t\t\t      enum kvm_pgtable_walk_flags visit)\n{\n\tstruct check_walk_data *d = ctx->arg;\n\n\tif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))\n\t\treturn -EINVAL;\n\n\treturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;\n}",
        "code_after_change": "static int __check_page_state_visitor(const struct kvm_pgtable_visit_ctx *ctx,\n\t\t\t\t      enum kvm_pgtable_walk_flags visit)\n{\n\tstruct check_walk_data *d = ctx->arg;\n\n\treturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,8 +3,5 @@\n {\n \tstruct check_walk_data *d = ctx->arg;\n \n-\tif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))\n-\t\treturn -EINVAL;\n-\n-\treturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;\n+\treturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;\n }",
        "function_modified_lines": {
            "added": [
                "\treturn d->get_page_state(ctx->old, ctx->addr) == d->desired ? 0 : -EPERM;"
            ],
            "deleted": [
                "\tif (kvm_pte_valid(ctx->old) && !addr_is_allowed_memory(kvm_pte_to_phys(ctx->old)))",
                "\t\treturn -EINVAL;",
                "",
                "\treturn d->get_page_state(ctx->old) == d->desired ? 0 : -EPERM;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In multiple functions of mem_protect.c, there is a possible way to access hypervisor memory due to a memory access check in the wrong place. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.\n\n",
        "id": 3918
    },
    {
        "cve_id": "CVE-2016-8632",
        "code_before_change": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\n\t\t\t   struct nlattr *attrs[])\n{\n\tint err = -EINVAL;\n\tstruct udp_bearer *ub;\n\tstruct udp_media_addr remote = {0};\n\tstruct udp_media_addr local = {0};\n\tstruct udp_port_cfg udp_conf = {0};\n\tstruct udp_tunnel_sock_cfg tuncfg = {NULL};\n\tstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\n\n\tub = kzalloc(sizeof(*ub), GFP_ATOMIC);\n\tif (!ub)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ub->rcast.list);\n\n\tif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\n\t\tgoto err;\n\n\tif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\n\t\t\t     attrs[TIPC_NLA_BEARER_UDP_OPTS],\n\t\t\t     tipc_nl_udp_policy))\n\t\tgoto err;\n\n\tif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\n\t\tpr_err(\"Invalid UDP bearer configuration\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n\t\t\t\t  &ub->ifindex);\n\tif (err)\n\t\tgoto err;\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\n\tif (err)\n\t\tgoto err;\n\n\tb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\n\tb->bcast_addr.broadcast = 1;\n\trcu_assign_pointer(b->media_ptr, ub);\n\trcu_assign_pointer(ub->bearer, b);\n\ttipc_udp_media_addr_set(&b->addr, &local);\n\tif (local.proto == htons(ETH_P_IP)) {\n\t\tstruct net_device *dev;\n\n\t\tdev = __ip_dev_find(net, local.ipv4.s_addr, false);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tudp_conf.family = AF_INET;\n\t\tudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\n\t\tudp_conf.use_udp_checksums = false;\n\t\tub->ifindex = dev->ifindex;\n\t\tb->mtu = dev->mtu - sizeof(struct iphdr)\n\t\t\t- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n\t} else if (local.proto == htons(ETH_P_IPV6)) {\n\t\tudp_conf.family = AF_INET6;\n\t\tudp_conf.use_udp6_tx_checksums = true;\n\t\tudp_conf.use_udp6_rx_checksums = true;\n\t\tudp_conf.local_ip6 = in6addr_any;\n\t\tb->mtu = 1280;\n#endif\n\t} else {\n\t\terr = -EAFNOSUPPORT;\n\t\tgoto err;\n\t}\n\tudp_conf.local_udp_port = local.port;\n\terr = udp_sock_create(net, &udp_conf, &ub->ubsock);\n\tif (err)\n\t\tgoto err;\n\ttuncfg.sk_user_data = ub;\n\ttuncfg.encap_type = 1;\n\ttuncfg.encap_rcv = tipc_udp_recv;\n\ttuncfg.encap_destroy = NULL;\n\tsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\n\n\t/**\n\t * The bcast media address port is used for all peers and the ip\n\t * is used if it's a multicast address.\n\t */\n\tmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\n\tif (tipc_udp_is_mcast_addr(&remote))\n\t\terr = enable_mcast(ub, &remote);\n\telse\n\t\terr = tipc_udp_rcast_add(b, &remote);\n\tif (err)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tif (ub->ubsock)\n\t\tudp_tunnel_sock_release(ub->ubsock);\n\tkfree(ub);\n\treturn err;\n}",
        "code_after_change": "static int tipc_udp_enable(struct net *net, struct tipc_bearer *b,\n\t\t\t   struct nlattr *attrs[])\n{\n\tint err = -EINVAL;\n\tstruct udp_bearer *ub;\n\tstruct udp_media_addr remote = {0};\n\tstruct udp_media_addr local = {0};\n\tstruct udp_port_cfg udp_conf = {0};\n\tstruct udp_tunnel_sock_cfg tuncfg = {NULL};\n\tstruct nlattr *opts[TIPC_NLA_UDP_MAX + 1];\n\n\tub = kzalloc(sizeof(*ub), GFP_ATOMIC);\n\tif (!ub)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ub->rcast.list);\n\n\tif (!attrs[TIPC_NLA_BEARER_UDP_OPTS])\n\t\tgoto err;\n\n\tif (nla_parse_nested(opts, TIPC_NLA_UDP_MAX,\n\t\t\t     attrs[TIPC_NLA_BEARER_UDP_OPTS],\n\t\t\t     tipc_nl_udp_policy))\n\t\tgoto err;\n\n\tif (!opts[TIPC_NLA_UDP_LOCAL] || !opts[TIPC_NLA_UDP_REMOTE]) {\n\t\tpr_err(\"Invalid UDP bearer configuration\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_LOCAL], &local,\n\t\t\t\t  &ub->ifindex);\n\tif (err)\n\t\tgoto err;\n\n\terr = tipc_parse_udp_addr(opts[TIPC_NLA_UDP_REMOTE], &remote, NULL);\n\tif (err)\n\t\tgoto err;\n\n\tb->bcast_addr.media_id = TIPC_MEDIA_TYPE_UDP;\n\tb->bcast_addr.broadcast = 1;\n\trcu_assign_pointer(b->media_ptr, ub);\n\trcu_assign_pointer(ub->bearer, b);\n\ttipc_udp_media_addr_set(&b->addr, &local);\n\tif (local.proto == htons(ETH_P_IP)) {\n\t\tstruct net_device *dev;\n\n\t\tdev = __ip_dev_find(net, local.ipv4.s_addr, false);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tudp_conf.family = AF_INET;\n\t\tudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\n\t\tudp_conf.use_udp_checksums = false;\n\t\tub->ifindex = dev->ifindex;\n\t\tif (tipc_mtu_bad(dev, sizeof(struct iphdr) +\n\t\t\t\t      sizeof(struct udphdr))) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tb->mtu = dev->mtu - sizeof(struct iphdr)\n\t\t\t- sizeof(struct udphdr);\n#if IS_ENABLED(CONFIG_IPV6)\n\t} else if (local.proto == htons(ETH_P_IPV6)) {\n\t\tudp_conf.family = AF_INET6;\n\t\tudp_conf.use_udp6_tx_checksums = true;\n\t\tudp_conf.use_udp6_rx_checksums = true;\n\t\tudp_conf.local_ip6 = in6addr_any;\n\t\tb->mtu = 1280;\n#endif\n\t} else {\n\t\terr = -EAFNOSUPPORT;\n\t\tgoto err;\n\t}\n\tudp_conf.local_udp_port = local.port;\n\terr = udp_sock_create(net, &udp_conf, &ub->ubsock);\n\tif (err)\n\t\tgoto err;\n\ttuncfg.sk_user_data = ub;\n\ttuncfg.encap_type = 1;\n\ttuncfg.encap_rcv = tipc_udp_recv;\n\ttuncfg.encap_destroy = NULL;\n\tsetup_udp_tunnel_sock(net, ub->ubsock, &tuncfg);\n\n\t/**\n\t * The bcast media address port is used for all peers and the ip\n\t * is used if it's a multicast address.\n\t */\n\tmemcpy(&b->bcast_addr.value, &remote, sizeof(remote));\n\tif (tipc_udp_is_mcast_addr(&remote))\n\t\terr = enable_mcast(ub, &remote);\n\telse\n\t\terr = tipc_udp_rcast_add(b, &remote);\n\tif (err)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tif (ub->ubsock)\n\t\tudp_tunnel_sock_release(ub->ubsock);\n\tkfree(ub);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -55,6 +55,11 @@\n \t\tudp_conf.local_ip.s_addr = htonl(INADDR_ANY);\n \t\tudp_conf.use_udp_checksums = false;\n \t\tub->ifindex = dev->ifindex;\n+\t\tif (tipc_mtu_bad(dev, sizeof(struct iphdr) +\n+\t\t\t\t      sizeof(struct udphdr))) {\n+\t\t\terr = -EINVAL;\n+\t\t\tgoto err;\n+\t\t}\n \t\tb->mtu = dev->mtu - sizeof(struct iphdr)\n \t\t\t- sizeof(struct udphdr);\n #if IS_ENABLED(CONFIG_IPV6)",
        "function_modified_lines": {
            "added": [
                "\t\tif (tipc_mtu_bad(dev, sizeof(struct iphdr) +",
                "\t\t\t\t      sizeof(struct udphdr))) {",
                "\t\t\terr = -EINVAL;",
                "\t\t\tgoto err;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264",
            "CWE-119"
        ],
        "cve_description": "The tipc_msg_build function in net/tipc/msg.c in the Linux kernel through 4.8.11 does not validate the relationship between the minimum fragment length and the maximum packet size, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) by leveraging the CAP_NET_ADMIN capability.",
        "id": 1122
    },
    {
        "cve_id": "CVE-2017-8061",
        "code_before_change": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\n\tstruct hexline *hx;\n\tu8 reset;\n\tint ret,pos=0;\n\n\thx = kmalloc(sizeof(*hx), GFP_KERNEL);\n\tif (!hx)\n\t\treturn -ENOMEM;\n\n\t/* stop the CPU */\n\treset = 1;\n\tif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)\n\t\terr(\"could not stop the USB controller CPU.\");\n\n\twhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\n\t\tdeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\n\t\tret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\n\n\t\tif (ret != hx->len) {\n\t\t\terr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\n\t\t\t\tret, hx->len);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret < 0) {\n\t\terr(\"firmware download failed at %d with %d\",pos,ret);\n\t\tkfree(hx);\n\t\treturn ret;\n\t}\n\n\tif (ret == 0) {\n\t\t/* restart the CPU */\n\t\treset = 0;\n\t\tif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {\n\t\t\terr(\"could not restart the USB controller CPU.\");\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else\n\t\tret = -EIO;\n\n\tkfree(hx);\n\n\treturn ret;\n}",
        "code_after_change": "int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n{\n\tstruct hexline *hx;\n\tu8 *buf;\n\tint ret, pos = 0;\n\tu16 cpu_cs_register = cypress[type].cpu_cs_register;\n\n\tbuf = kmalloc(sizeof(*hx), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\thx = (struct hexline *)buf;\n\n\t/* stop the CPU */\n\tbuf[0] = 1;\n\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)\n\t\terr(\"could not stop the USB controller CPU.\");\n\n\twhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\n\t\tdeb_fw(\"writing to address 0x%04x (buffer: 0x%02x %02x)\\n\", hx->addr, hx->len, hx->chk);\n\t\tret = usb_cypress_writemem(udev, hx->addr, hx->data, hx->len);\n\n\t\tif (ret != hx->len) {\n\t\t\terr(\"error while transferring firmware (transferred size: %d, block size: %d)\",\n\t\t\t\tret, hx->len);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (ret < 0) {\n\t\terr(\"firmware download failed at %d with %d\",pos,ret);\n\t\tkfree(buf);\n\t\treturn ret;\n\t}\n\n\tif (ret == 0) {\n\t\t/* restart the CPU */\n\t\tbuf[0] = 0;\n\t\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {\n\t\t\terr(\"could not restart the USB controller CPU.\");\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else\n\t\tret = -EIO;\n\n\tkfree(buf);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,16 +1,18 @@\n int usb_cypress_load_firmware(struct usb_device *udev, const struct firmware *fw, int type)\n {\n \tstruct hexline *hx;\n-\tu8 reset;\n-\tint ret,pos=0;\n+\tu8 *buf;\n+\tint ret, pos = 0;\n+\tu16 cpu_cs_register = cypress[type].cpu_cs_register;\n \n-\thx = kmalloc(sizeof(*hx), GFP_KERNEL);\n-\tif (!hx)\n+\tbuf = kmalloc(sizeof(*hx), GFP_KERNEL);\n+\tif (!buf)\n \t\treturn -ENOMEM;\n+\thx = (struct hexline *)buf;\n \n \t/* stop the CPU */\n-\treset = 1;\n-\tif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)\n+\tbuf[0] = 1;\n+\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)\n \t\terr(\"could not stop the USB controller CPU.\");\n \n \twhile ((ret = dvb_usb_get_hexline(fw, hx, &pos)) > 0) {\n@@ -26,21 +28,21 @@\n \t}\n \tif (ret < 0) {\n \t\terr(\"firmware download failed at %d with %d\",pos,ret);\n-\t\tkfree(hx);\n+\t\tkfree(buf);\n \t\treturn ret;\n \t}\n \n \tif (ret == 0) {\n \t\t/* restart the CPU */\n-\t\treset = 0;\n-\t\tif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {\n+\t\tbuf[0] = 0;\n+\t\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {\n \t\t\terr(\"could not restart the USB controller CPU.\");\n \t\t\tret = -EINVAL;\n \t\t}\n \t} else\n \t\tret = -EIO;\n \n-\tkfree(hx);\n+\tkfree(buf);\n \n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tu8 *buf;",
                "\tint ret, pos = 0;",
                "\tu16 cpu_cs_register = cypress[type].cpu_cs_register;",
                "\tbuf = kmalloc(sizeof(*hx), GFP_KERNEL);",
                "\tif (!buf)",
                "\thx = (struct hexline *)buf;",
                "\tbuf[0] = 1;",
                "\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1)",
                "\t\tkfree(buf);",
                "\t\tbuf[0] = 0;",
                "\t\tif (usb_cypress_writemem(udev, cpu_cs_register, buf, 1) != 1) {",
                "\tkfree(buf);"
            ],
            "deleted": [
                "\tu8 reset;",
                "\tint ret,pos=0;",
                "\thx = kmalloc(sizeof(*hx), GFP_KERNEL);",
                "\tif (!hx)",
                "\treset = 1;",
                "\tif ((ret = usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1)) != 1)",
                "\t\tkfree(hx);",
                "\t\treset = 0;",
                "\t\tif (ret || usb_cypress_writemem(udev,cypress[type].cpu_cs_register,&reset,1) != 1) {",
                "\tkfree(hx);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dvb-usb-firmware.c in the Linux kernel 4.9.x and 4.10.x before 4.10.7 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1535
    },
    {
        "cve_id": "CVE-2017-5548",
        "code_before_change": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tint ret;\n\tuint8_t value;\n\n\tdev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n\t\t\t\t0, reg, &value, 1, 1000);\n\treturn ret >= 0 ? value : ret;\n}",
        "code_after_change": "static int atusb_read_reg(struct atusb *atusb, uint8_t reg)\n{\n\tstruct usb_device *usb_dev = atusb->usb_dev;\n\tint ret;\n\tuint8_t *buffer;\n\tuint8_t value;\n\n\tbuffer = kmalloc(1, GFP_KERNEL);\n\tif (!buffer)\n\t\treturn -ENOMEM;\n\n\tdev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\n\tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n\t\t\t\tATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n\t\t\t\t0, reg, buffer, 1, 1000);\n\n\tif (ret >= 0) {\n\t\tvalue = buffer[0];\n\t\tkfree(buffer);\n\t\treturn value;\n\t} else {\n\t\tkfree(buffer);\n\t\treturn ret;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,11 +2,24 @@\n {\n \tstruct usb_device *usb_dev = atusb->usb_dev;\n \tint ret;\n+\tuint8_t *buffer;\n \tuint8_t value;\n+\n+\tbuffer = kmalloc(1, GFP_KERNEL);\n+\tif (!buffer)\n+\t\treturn -ENOMEM;\n \n \tdev_dbg(&usb_dev->dev, \"atusb: reg = 0x%x\\n\", reg);\n \tret = atusb_control_msg(atusb, usb_rcvctrlpipe(usb_dev, 0),\n \t\t\t\tATUSB_REG_READ, ATUSB_REQ_FROM_DEV,\n-\t\t\t\t0, reg, &value, 1, 1000);\n-\treturn ret >= 0 ? value : ret;\n+\t\t\t\t0, reg, buffer, 1, 1000);\n+\n+\tif (ret >= 0) {\n+\t\tvalue = buffer[0];\n+\t\tkfree(buffer);\n+\t\treturn value;\n+\t} else {\n+\t\tkfree(buffer);\n+\t\treturn ret;\n+\t}\n }",
        "function_modified_lines": {
            "added": [
                "\tuint8_t *buffer;",
                "",
                "\tbuffer = kmalloc(1, GFP_KERNEL);",
                "\tif (!buffer)",
                "\t\treturn -ENOMEM;",
                "\t\t\t\t0, reg, buffer, 1, 1000);",
                "",
                "\tif (ret >= 0) {",
                "\t\tvalue = buffer[0];",
                "\t\tkfree(buffer);",
                "\t\treturn value;",
                "\t} else {",
                "\t\tkfree(buffer);",
                "\t\treturn ret;",
                "\t}"
            ],
            "deleted": [
                "\t\t\t\t0, reg, &value, 1, 1000);",
                "\treturn ret >= 0 ? value : ret;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/net/ieee802154/atusb.c in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1465
    },
    {
        "cve_id": "CVE-2017-12762",
        "code_before_change": "char *\nisdn_net_newslave(char *parm)\n{\n\tchar *p = strchr(parm, ',');\n\tisdn_net_dev *n;\n\tchar newname[10];\n\n\tif (p) {\n\t\t/* Slave-Name MUST not be empty */\n\t\tif (!strlen(p + 1))\n\t\t\treturn NULL;\n\t\tstrcpy(newname, p + 1);\n\t\t*p = 0;\n\t\t/* Master must already exist */\n\t\tif (!(n = isdn_net_findif(parm)))\n\t\t\treturn NULL;\n\t\t/* Master must be a real interface, not a slave */\n\t\tif (n->local->master)\n\t\t\treturn NULL;\n\t\t/* Master must not be started yet */\n\t\tif (isdn_net_device_started(n))\n\t\t\treturn NULL;\n\t\treturn (isdn_net_new(newname, n->dev));\n\t}\n\treturn NULL;\n}",
        "code_after_change": "char *\nisdn_net_newslave(char *parm)\n{\n\tchar *p = strchr(parm, ',');\n\tisdn_net_dev *n;\n\tchar newname[10];\n\n\tif (p) {\n\t\t/* Slave-Name MUST not be empty or overflow 'newname' */\n\t\tif (strscpy(newname, p + 1, sizeof(newname)) <= 0)\n\t\t\treturn NULL;\n\t\t*p = 0;\n\t\t/* Master must already exist */\n\t\tif (!(n = isdn_net_findif(parm)))\n\t\t\treturn NULL;\n\t\t/* Master must be a real interface, not a slave */\n\t\tif (n->local->master)\n\t\t\treturn NULL;\n\t\t/* Master must not be started yet */\n\t\tif (isdn_net_device_started(n))\n\t\t\treturn NULL;\n\t\treturn (isdn_net_new(newname, n->dev));\n\t}\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,10 +6,9 @@\n \tchar newname[10];\n \n \tif (p) {\n-\t\t/* Slave-Name MUST not be empty */\n-\t\tif (!strlen(p + 1))\n+\t\t/* Slave-Name MUST not be empty or overflow 'newname' */\n+\t\tif (strscpy(newname, p + 1, sizeof(newname)) <= 0)\n \t\t\treturn NULL;\n-\t\tstrcpy(newname, p + 1);\n \t\t*p = 0;\n \t\t/* Master must already exist */\n \t\tif (!(n = isdn_net_findif(parm)))",
        "function_modified_lines": {
            "added": [
                "\t\t/* Slave-Name MUST not be empty or overflow 'newname' */",
                "\t\tif (strscpy(newname, p + 1, sizeof(newname)) <= 0)"
            ],
            "deleted": [
                "\t\t/* Slave-Name MUST not be empty */",
                "\t\tif (!strlen(p + 1))",
                "\t\tstrcpy(newname, p + 1);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In /drivers/isdn/i4l/isdn_net.c: A user-controlled buffer is copied into a local buffer of constant size using strcpy without a length check which can cause a buffer overflow. This affects the Linux kernel 4.9-stable tree, 4.12-stable tree, 3.18-stable tree, and 4.4-stable tree.",
        "id": 1264
    },
    {
        "cve_id": "CVE-2012-2137",
        "code_before_change": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\n\t\t\t       struct kvm_kernel_irq_routing_entry *e,\n\t\t\t       const struct kvm_irq_routing_entry *ue)\n{\n\tint r = -EINVAL;\n\tint delta;\n\tunsigned max_pin;\n\tstruct kvm_kernel_irq_routing_entry *ei;\n\tstruct hlist_node *n;\n\n\t/*\n\t * Do not allow GSI to be mapped to the same irqchip more than once.\n\t * Allow only one to one mapping between GSI and MSI.\n\t */\n\thlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\n\t\tif (ei->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->u.irqchip.irqchip == ei->irqchip.irqchip)\n\t\t\treturn r;\n\n\te->gsi = ue->gsi;\n\te->type = ue->type;\n\tswitch (ue->type) {\n\tcase KVM_IRQ_ROUTING_IRQCHIP:\n\t\tdelta = 0;\n\t\tswitch (ue->u.irqchip.irqchip) {\n\t\tcase KVM_IRQCHIP_PIC_MASTER:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_PIC_SLAVE:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tdelta = 8;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_IOAPIC:\n\t\t\tmax_pin = KVM_IOAPIC_NUM_PINS;\n\t\t\te->set = kvm_set_ioapic_irq;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto out;\n\t\t}\n\t\te->irqchip.irqchip = ue->u.irqchip.irqchip;\n\t\te->irqchip.pin = ue->u.irqchip.pin + delta;\n\t\tif (e->irqchip.pin >= max_pin)\n\t\t\tgoto out;\n\t\trt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\te->set = kvm_set_msi;\n\t\te->msi.address_lo = ue->u.msi.address_lo;\n\t\te->msi.address_hi = ue->u.msi.address_hi;\n\t\te->msi.data = ue->u.msi.data;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\thlist_add_head(&e->link, &rt->map[e->gsi]);\n\tr = 0;\nout:\n\treturn r;\n}",
        "code_after_change": "static int setup_routing_entry(struct kvm_irq_routing_table *rt,\n\t\t\t       struct kvm_kernel_irq_routing_entry *e,\n\t\t\t       const struct kvm_irq_routing_entry *ue)\n{\n\tint r = -EINVAL;\n\tint delta;\n\tunsigned max_pin;\n\tstruct kvm_kernel_irq_routing_entry *ei;\n\tstruct hlist_node *n;\n\n\t/*\n\t * Do not allow GSI to be mapped to the same irqchip more than once.\n\t * Allow only one to one mapping between GSI and MSI.\n\t */\n\thlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\n\t\tif (ei->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->type == KVM_IRQ_ROUTING_MSI ||\n\t\t    ue->u.irqchip.irqchip == ei->irqchip.irqchip)\n\t\t\treturn r;\n\n\te->gsi = ue->gsi;\n\te->type = ue->type;\n\tswitch (ue->type) {\n\tcase KVM_IRQ_ROUTING_IRQCHIP:\n\t\tdelta = 0;\n\t\tswitch (ue->u.irqchip.irqchip) {\n\t\tcase KVM_IRQCHIP_PIC_MASTER:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_PIC_SLAVE:\n\t\t\te->set = kvm_set_pic_irq;\n\t\t\tmax_pin = 16;\n\t\t\tdelta = 8;\n\t\t\tbreak;\n\t\tcase KVM_IRQCHIP_IOAPIC:\n\t\t\tmax_pin = KVM_IOAPIC_NUM_PINS;\n\t\t\te->set = kvm_set_ioapic_irq;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto out;\n\t\t}\n\t\te->irqchip.irqchip = ue->u.irqchip.irqchip;\n\t\te->irqchip.pin = ue->u.irqchip.pin + delta;\n\t\tif (e->irqchip.pin >= max_pin)\n\t\t\tgoto out;\n\t\trt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\n\t\tbreak;\n\tcase KVM_IRQ_ROUTING_MSI:\n\t\te->set = kvm_set_msi;\n\t\te->msi.address_lo = ue->u.msi.address_lo;\n\t\te->msi.address_hi = ue->u.msi.address_hi;\n\t\te->msi.data = ue->u.msi.data;\n\t\tbreak;\n\tdefault:\n\t\tgoto out;\n\t}\n\n\thlist_add_head(&e->link, &rt->map[e->gsi]);\n\tr = 0;\nout:\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,7 @@\n \t */\n \thlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\n \t\tif (ei->type == KVM_IRQ_ROUTING_MSI ||\n+\t\t    ue->type == KVM_IRQ_ROUTING_MSI ||\n \t\t    ue->u.irqchip.irqchip == ei->irqchip.irqchip)\n \t\t\treturn r;\n ",
        "function_modified_lines": {
            "added": [
                "\t\t    ue->type == KVM_IRQ_ROUTING_MSI ||"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in virt/kvm/irq_comm.c in the KVM subsystem in the Linux kernel before 3.2.24 allows local users to cause a denial of service (crash) and possibly execute arbitrary code via vectors related to Message Signaled Interrupts (MSI), irq routing entries, and an incorrect check by the setup_routing_entry function before invoking the kvm_set_irq function.",
        "id": 42
    },
    {
        "cve_id": "CVE-2014-6416",
        "code_before_change": "static int ceph_x_proc_ticket_reply(struct ceph_auth_client *ac,\n\t\t\t\t    struct ceph_crypto_key *secret,\n\t\t\t\t    void *buf, void *end)\n{\n\tvoid *p = buf;\n\tchar *dbuf;\n\tchar *ticket_buf;\n\tu8 reply_struct_v;\n\tu32 num;\n\tint ret;\n\n\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n\tif (!dbuf)\n\t\treturn -ENOMEM;\n\n\tret = -ENOMEM;\n\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n\tif (!ticket_buf)\n\t\tgoto out_dbuf;\n\n\tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n\tif (reply_struct_v != 1)\n\t\treturn -EINVAL;\n\n\tceph_decode_32_safe(&p, end, num, bad);\n\tdout(\"%d tickets\\n\", num);\n\n\twhile (num--) {\n\t\tret = process_one_ticket(ac, secret, &p, end,\n\t\t\t\t\t dbuf, ticket_buf);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tret = 0;\nout:\n\tkfree(ticket_buf);\nout_dbuf:\n\tkfree(dbuf);\n\treturn ret;\n\nbad:\n\tret = -EINVAL;\n\tgoto out;\n}",
        "code_after_change": "static int ceph_x_proc_ticket_reply(struct ceph_auth_client *ac,\n\t\t\t\t    struct ceph_crypto_key *secret,\n\t\t\t\t    void *buf, void *end)\n{\n\tvoid *p = buf;\n\tu8 reply_struct_v;\n\tu32 num;\n\tint ret;\n\n\tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n\tif (reply_struct_v != 1)\n\t\treturn -EINVAL;\n\n\tceph_decode_32_safe(&p, end, num, bad);\n\tdout(\"%d tickets\\n\", num);\n\n\twhile (num--) {\n\t\tret = process_one_ticket(ac, secret, &p, end);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n\nbad:\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,20 +3,9 @@\n \t\t\t\t    void *buf, void *end)\n {\n \tvoid *p = buf;\n-\tchar *dbuf;\n-\tchar *ticket_buf;\n \tu8 reply_struct_v;\n \tu32 num;\n \tint ret;\n-\n-\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n-\tif (!dbuf)\n-\t\treturn -ENOMEM;\n-\n-\tret = -ENOMEM;\n-\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n-\tif (!ticket_buf)\n-\t\tgoto out_dbuf;\n \n \tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n \tif (reply_struct_v != 1)\n@@ -26,20 +15,13 @@\n \tdout(\"%d tickets\\n\", num);\n \n \twhile (num--) {\n-\t\tret = process_one_ticket(ac, secret, &p, end,\n-\t\t\t\t\t dbuf, ticket_buf);\n+\t\tret = process_one_ticket(ac, secret, &p, end);\n \t\tif (ret)\n-\t\t\tgoto out;\n+\t\t\treturn ret;\n \t}\n \n-\tret = 0;\n-out:\n-\tkfree(ticket_buf);\n-out_dbuf:\n-\tkfree(dbuf);\n-\treturn ret;\n+\treturn 0;\n \n bad:\n-\tret = -EINVAL;\n-\tgoto out;\n+\treturn -EINVAL;\n }",
        "function_modified_lines": {
            "added": [
                "\t\tret = process_one_ticket(ac, secret, &p, end);",
                "\t\t\treturn ret;",
                "\treturn 0;",
                "\treturn -EINVAL;"
            ],
            "deleted": [
                "\tchar *dbuf;",
                "\tchar *ticket_buf;",
                "",
                "\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);",
                "\tif (!dbuf)",
                "\t\treturn -ENOMEM;",
                "",
                "\tret = -ENOMEM;",
                "\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);",
                "\tif (!ticket_buf)",
                "\t\tgoto out_dbuf;",
                "\t\tret = process_one_ticket(ac, secret, &p, end,",
                "\t\t\t\t\t dbuf, ticket_buf);",
                "\t\t\tgoto out;",
                "\tret = 0;",
                "out:",
                "\tkfree(ticket_buf);",
                "out_dbuf:",
                "\tkfree(dbuf);",
                "\treturn ret;",
                "\tret = -EINVAL;",
                "\tgoto out;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "id": 582
    },
    {
        "cve_id": "CVE-2007-6761",
        "code_before_change": "static void\nvideobuf_vm_close(struct vm_area_struct *vma)\n{\n\tstruct videobuf_mapping *map = vma->vm_private_data;\n\tstruct videobuf_queue *q = map->q;\n\tint i;\n\n\tdprintk(2,\"vm_close %p [count=%d,vma=%08lx-%08lx]\\n\",map,\n\t\tmap->count,vma->vm_start,vma->vm_end);\n\n\tmap->count--;\n\tif (0 == map->count) {\n\t\tdprintk(1,\"munmap %p q=%p\\n\",map,q);\n\t\tmutex_lock(&q->lock);\n\t\tfor (i = 0; i < VIDEO_MAX_FRAME; i++) {\n\t\t\tif (NULL == q->bufs[i])\n\t\t\t\tcontinue;\n\n\t\t\tif (q->bufs[i]->map != map)\n\t\t\t\tcontinue;\n\n\t\t\tq->ops->buf_release(q,q->bufs[i]);\n\n\t\t\tq->bufs[i]->map   = NULL;\n\t\t\tq->bufs[i]->baddr = 0;\n\t\t}\n\t\tmutex_unlock(&q->lock);\n\t\tkfree(map);\n\t}\n\treturn;\n}",
        "code_after_change": "static void\nvideobuf_vm_close(struct vm_area_struct *vma)\n{\n\tstruct videobuf_mapping *map = vma->vm_private_data;\n\tstruct videobuf_queue *q = map->q;\n\tint i;\n\n\tdprintk(2,\"vm_close %p [count=%u,vma=%08lx-%08lx]\\n\",map,\n\t\tmap->count,vma->vm_start,vma->vm_end);\n\n\tmap->count--;\n\tif (0 == map->count) {\n\t\tdprintk(1,\"munmap %p q=%p\\n\",map,q);\n\t\tmutex_lock(&q->lock);\n\t\tfor (i = 0; i < VIDEO_MAX_FRAME; i++) {\n\t\t\tif (NULL == q->bufs[i])\n\t\t\t\tcontinue;\n\n\t\t\tif (q->bufs[i]->map != map)\n\t\t\t\tcontinue;\n\n\t\t\tq->ops->buf_release(q,q->bufs[i]);\n\n\t\t\tq->bufs[i]->map   = NULL;\n\t\t\tq->bufs[i]->baddr = 0;\n\t\t}\n\t\tmutex_unlock(&q->lock);\n\t\tkfree(map);\n\t}\n\treturn;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct videobuf_queue *q = map->q;\n \tint i;\n \n-\tdprintk(2,\"vm_close %p [count=%d,vma=%08lx-%08lx]\\n\",map,\n+\tdprintk(2,\"vm_close %p [count=%u,vma=%08lx-%08lx]\\n\",map,\n \t\tmap->count,vma->vm_start,vma->vm_end);\n \n \tmap->count--;",
        "function_modified_lines": {
            "added": [
                "\tdprintk(2,\"vm_close %p [count=%u,vma=%08lx-%08lx]\\n\",map,"
            ],
            "deleted": [
                "\tdprintk(2,\"vm_close %p [count=%d,vma=%08lx-%08lx]\\n\",map,"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/media/video/videobuf-vmalloc.c in the Linux kernel before 2.6.24 does not initialize videobuf_mapping data structures, which allows local users to trigger an incorrect count value and videobuf leak via unspecified vectors, a different vulnerability than CVE-2010-5321.",
        "id": 5
    },
    {
        "cve_id": "CVE-2016-4998",
        "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,7 +27,8 @@\n \tif (!ip_checkentry(&e->ip))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "function_modified_lines": {
            "added": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ],
            "deleted": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The IPT_SO_SET_REPLACE setsockopt implementation in the netfilter subsystem in the Linux kernel before 4.6 allows local users to cause a denial of service (out-of-bounds read) or possibly obtain sensitive information from kernel heap memory by leveraging in-container root access to provide a crafted offset value that leads to crossing a ruleset blob boundary.",
        "id": 1047
    },
    {
        "cve_id": "CVE-2014-3185",
        "code_before_change": "static void command_port_read_callback(struct urb *urb)\n{\n\tstruct usb_serial_port *command_port = urb->context;\n\tstruct whiteheat_command_private *command_info;\n\tint status = urb->status;\n\tunsigned char *data = urb->transfer_buffer;\n\tint result;\n\n\tcommand_info = usb_get_serial_port_data(command_port);\n\tif (!command_info) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (status) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\n\t\tif (status != -ENOENT)\n\t\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t\treturn;\n\t}\n\n\tusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\n\n\tif (data[0] == WHITEHEAT_CMD_COMPLETE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_EVENT) {\n\t\t/* These are unsolicited reports from the firmware, hence no\n\t\t   waiting command to wakeup */\n\t\tdev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n\t} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {\n\t\tmemcpy(command_info->result_buffer, &data[1],\n\t\t\t\t\t\turb->actual_length - 1);\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else\n\t\tdev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\n\n\t/* Continue trying to always read */\n\tresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\n\tif (result)\n\t\tdev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n\t\t\t__func__, result);\n}",
        "code_after_change": "static void command_port_read_callback(struct urb *urb)\n{\n\tstruct usb_serial_port *command_port = urb->context;\n\tstruct whiteheat_command_private *command_info;\n\tint status = urb->status;\n\tunsigned char *data = urb->transfer_buffer;\n\tint result;\n\n\tcommand_info = usb_get_serial_port_data(command_port);\n\tif (!command_info) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (!urb->actual_length) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);\n\t\treturn;\n\t}\n\tif (status) {\n\t\tdev_dbg(&urb->dev->dev, \"%s - nonzero urb status: %d\\n\", __func__, status);\n\t\tif (status != -ENOENT)\n\t\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t\treturn;\n\t}\n\n\tusb_serial_debug_data(&command_port->dev, __func__, urb->actual_length, data);\n\n\tif (data[0] == WHITEHEAT_CMD_COMPLETE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_CMD_FAILURE) {\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_FAILURE;\n\t\twake_up(&command_info->wait_command);\n\t} else if (data[0] == WHITEHEAT_EVENT) {\n\t\t/* These are unsolicited reports from the firmware, hence no\n\t\t   waiting command to wakeup */\n\t\tdev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n\t} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&\n\t\t(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {\n\t\tmemcpy(command_info->result_buffer, &data[1],\n\t\t\t\t\t\turb->actual_length - 1);\n\t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;\n\t\twake_up(&command_info->wait_command);\n\t} else\n\t\tdev_dbg(&urb->dev->dev, \"%s - bad reply from firmware\\n\", __func__);\n\n\t/* Continue trying to always read */\n\tresult = usb_submit_urb(command_port->read_urb, GFP_ATOMIC);\n\tif (result)\n\t\tdev_dbg(&urb->dev->dev, \"%s - failed resubmitting read urb, error %d\\n\",\n\t\t\t__func__, result);\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,10 @@\n \tcommand_info = usb_get_serial_port_data(command_port);\n \tif (!command_info) {\n \t\tdev_dbg(&urb->dev->dev, \"%s - command_info is NULL, exiting.\\n\", __func__);\n+\t\treturn;\n+\t}\n+\tif (!urb->actual_length) {\n+\t\tdev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);\n \t\treturn;\n \t}\n \tif (status) {\n@@ -31,7 +35,8 @@\n \t\t/* These are unsolicited reports from the firmware, hence no\n \t\t   waiting command to wakeup */\n \t\tdev_dbg(&urb->dev->dev, \"%s - event received\\n\", __func__);\n-\t} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {\n+\t} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&\n+\t\t(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {\n \t\tmemcpy(command_info->result_buffer, &data[1],\n \t\t\t\t\t\turb->actual_length - 1);\n \t\tcommand_info->command_finished = WHITEHEAT_CMD_COMPLETE;",
        "function_modified_lines": {
            "added": [
                "\t\treturn;",
                "\t}",
                "\tif (!urb->actual_length) {",
                "\t\tdev_dbg(&urb->dev->dev, \"%s - empty response, exiting.\\n\", __func__);",
                "\t} else if ((data[0] == WHITEHEAT_GET_DTR_RTS) &&",
                "\t\t(urb->actual_length - 1 <= sizeof(command_info->result_buffer))) {"
            ],
            "deleted": [
                "\t} else if (data[0] == WHITEHEAT_GET_DTR_RTS) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple buffer overflows in the command_port_read_callback function in drivers/usb/serial/whiteheat.c in the Whiteheat USB Serial Driver in the Linux kernel before 3.16.2 allow physically proximate attackers to execute arbitrary code or cause a denial of service (memory corruption and system crash) via a crafted device that provides a large amount of (1) EHCI or (2) XHCI data associated with a bulk response.",
        "id": 521
    },
    {
        "cve_id": "CVE-2015-4002",
        "code_before_change": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\n\tstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\n\tstruct oz_usb_ctx *usb_ctx;\n\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\n\tif (usb_ctx)\n\t\toz_usb_get(usb_ctx);\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tif (usb_ctx == NULL)\n\t\treturn; /* Context has gone so nothing to do. */\n\tif (usb_ctx->stopped)\n\t\tgoto done;\n\t/* If sequence number is non-zero then check it is not a duplicate.\n\t * Zero sequence numbers are always accepted.\n\t */\n\tif (usb_hdr->elt_seq_num != 0) {\n\t\tif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\n\t\t\t/* Reject duplicate element. */\n\t\t\tgoto done;\n\t}\n\tusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\n\tswitch (usb_hdr->type) {\n\tcase OZ_GET_DESC_RSP: {\n\t\t\tstruct oz_get_desc_rsp *body =\n\t\t\t\t(struct oz_get_desc_rsp *)usb_hdr;\n\t\t\tint data_len = elt->length -\n\t\t\t\t\tsizeof(struct oz_get_desc_rsp) + 1;\n\t\t\tu16 offs = le16_to_cpu(get_unaligned(&body->offset));\n\t\t\tu16 total_size =\n\t\t\t\tle16_to_cpu(get_unaligned(&body->total_size));\n\t\t\toz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\n\t\t\toz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\t\tbody->rcode, body->data,\n\t\t\t\t\tdata_len, offs, total_size);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_CONFIG_RSP: {\n\t\t\tstruct oz_set_config_rsp *body =\n\t\t\t\t(struct oz_set_config_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_INTERFACE_RSP: {\n\t\t\tstruct oz_set_interface_rsp *body =\n\t\t\t\t(struct oz_set_interface_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport,\n\t\t\t\tbody->req_id, body->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_VENDOR_CLASS_RSP: {\n\t\t\tstruct oz_vendor_class_rsp *body =\n\t\t\t\t(struct oz_vendor_class_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, body->data, elt->length-\n\t\t\t\tsizeof(struct oz_vendor_class_rsp)+1);\n\t\t}\n\t\tbreak;\n\tcase OZ_USB_ENDPOINT_DATA:\n\t\toz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\n\t\tbreak;\n\t}\ndone:\n\toz_usb_put(usb_ctx);\n}",
        "code_after_change": "void oz_usb_rx(struct oz_pd *pd, struct oz_elt *elt)\n{\n\tstruct oz_usb_hdr *usb_hdr = (struct oz_usb_hdr *)(elt + 1);\n\tstruct oz_usb_ctx *usb_ctx;\n\n\tspin_lock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tusb_ctx = (struct oz_usb_ctx *)pd->app_ctx[OZ_APPID_USB];\n\tif (usb_ctx)\n\t\toz_usb_get(usb_ctx);\n\tspin_unlock_bh(&pd->app_lock[OZ_APPID_USB]);\n\tif (usb_ctx == NULL)\n\t\treturn; /* Context has gone so nothing to do. */\n\tif (usb_ctx->stopped)\n\t\tgoto done;\n\t/* If sequence number is non-zero then check it is not a duplicate.\n\t * Zero sequence numbers are always accepted.\n\t */\n\tif (usb_hdr->elt_seq_num != 0) {\n\t\tif (((usb_ctx->rx_seq_num - usb_hdr->elt_seq_num) & 0x80) == 0)\n\t\t\t/* Reject duplicate element. */\n\t\t\tgoto done;\n\t}\n\tusb_ctx->rx_seq_num = usb_hdr->elt_seq_num;\n\tswitch (usb_hdr->type) {\n\tcase OZ_GET_DESC_RSP: {\n\t\t\tstruct oz_get_desc_rsp *body =\n\t\t\t\t(struct oz_get_desc_rsp *)usb_hdr;\n\t\t\tu16 offs, total_size;\n\t\t\tu8 data_len;\n\n\t\t\tif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)\n\t\t\t\tbreak;\n\t\t\tdata_len = elt->length -\n\t\t\t\t\t(sizeof(struct oz_get_desc_rsp) - 1);\n\t\t\toffs = le16_to_cpu(get_unaligned(&body->offset));\n\t\t\ttotal_size =\n\t\t\t\tle16_to_cpu(get_unaligned(&body->total_size));\n\t\t\toz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\n\t\t\toz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\t\tbody->rcode, body->data,\n\t\t\t\t\tdata_len, offs, total_size);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_CONFIG_RSP: {\n\t\t\tstruct oz_set_config_rsp *body =\n\t\t\t\t(struct oz_set_config_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_SET_INTERFACE_RSP: {\n\t\t\tstruct oz_set_interface_rsp *body =\n\t\t\t\t(struct oz_set_interface_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport,\n\t\t\t\tbody->req_id, body->rcode, NULL, 0);\n\t\t}\n\t\tbreak;\n\tcase OZ_VENDOR_CLASS_RSP: {\n\t\t\tstruct oz_vendor_class_rsp *body =\n\t\t\t\t(struct oz_vendor_class_rsp *)usb_hdr;\n\t\t\toz_hcd_control_cnf(usb_ctx->hport, body->req_id,\n\t\t\t\tbody->rcode, body->data, elt->length-\n\t\t\t\tsizeof(struct oz_vendor_class_rsp)+1);\n\t\t}\n\t\tbreak;\n\tcase OZ_USB_ENDPOINT_DATA:\n\t\toz_usb_handle_ep_data(usb_ctx, usb_hdr, elt->length);\n\t\tbreak;\n\t}\ndone:\n\toz_usb_put(usb_ctx);\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,10 +25,15 @@\n \tcase OZ_GET_DESC_RSP: {\n \t\t\tstruct oz_get_desc_rsp *body =\n \t\t\t\t(struct oz_get_desc_rsp *)usb_hdr;\n-\t\t\tint data_len = elt->length -\n-\t\t\t\t\tsizeof(struct oz_get_desc_rsp) + 1;\n-\t\t\tu16 offs = le16_to_cpu(get_unaligned(&body->offset));\n-\t\t\tu16 total_size =\n+\t\t\tu16 offs, total_size;\n+\t\t\tu8 data_len;\n+\n+\t\t\tif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)\n+\t\t\t\tbreak;\n+\t\t\tdata_len = elt->length -\n+\t\t\t\t\t(sizeof(struct oz_get_desc_rsp) - 1);\n+\t\t\toffs = le16_to_cpu(get_unaligned(&body->offset));\n+\t\t\ttotal_size =\n \t\t\t\tle16_to_cpu(get_unaligned(&body->total_size));\n \t\t\toz_dbg(ON, \"USB_REQ_GET_DESCRIPTOR - cnf\\n\");\n \t\t\toz_hcd_get_desc_cnf(usb_ctx->hport, body->req_id,",
        "function_modified_lines": {
            "added": [
                "\t\t\tu16 offs, total_size;",
                "\t\t\tu8 data_len;",
                "",
                "\t\t\tif (elt->length < sizeof(struct oz_get_desc_rsp) - 1)",
                "\t\t\t\tbreak;",
                "\t\t\tdata_len = elt->length -",
                "\t\t\t\t\t(sizeof(struct oz_get_desc_rsp) - 1);",
                "\t\t\toffs = le16_to_cpu(get_unaligned(&body->offset));",
                "\t\t\ttotal_size ="
            ],
            "deleted": [
                "\t\t\tint data_len = elt->length -",
                "\t\t\t\t\tsizeof(struct oz_get_desc_rsp) + 1;",
                "\t\t\tu16 offs = le16_to_cpu(get_unaligned(&body->offset));",
                "\t\t\tu16 total_size ="
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/staging/ozwpan/ozusbsvc1.c in the OZWPAN driver in the Linux kernel through 4.0.5 does not ensure that certain length values are sufficiently large, which allows remote attackers to cause a denial of service (system crash or large loop) or possibly execute arbitrary code via a crafted packet, related to the (1) oz_usb_rx and (2) oz_usb_handle_ep_data functions.",
        "id": 759
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "static int console_trylock_for_printk(unsigned int cpu)\n\t__releases(&logbuf_lock)\n{\n\tint retval = 0, wake = 0;\n\n\tif (console_trylock()) {\n\t\tretval = 1;\n\n\t\t/*\n\t\t * If we can't use the console, we need to release\n\t\t * the console semaphore by hand to avoid flushing\n\t\t * the buffer. We need to hold the console semaphore\n\t\t * in order to do this test safely.\n\t\t */\n\t\tif (!can_use_console(cpu)) {\n\t\t\tconsole_locked = 0;\n\t\t\twake = 1;\n\t\t\tretval = 0;\n\t\t}\n\t}\n\tprintk_cpu = UINT_MAX;\n\tif (wake)\n\t\tup(&console_sem);\n\traw_spin_unlock(&logbuf_lock);\n\treturn retval;\n}",
        "code_after_change": "static int console_trylock_for_printk(unsigned int cpu)\n\t__releases(&logbuf_lock)\n{\n\tint retval = 0, wake = 0;\n\n\tif (console_trylock()) {\n\t\tretval = 1;\n\n\t\t/*\n\t\t * If we can't use the console, we need to release\n\t\t * the console semaphore by hand to avoid flushing\n\t\t * the buffer. We need to hold the console semaphore\n\t\t * in order to do this test safely.\n\t\t */\n\t\tif (!can_use_console(cpu)) {\n\t\t\tconsole_locked = 0;\n\t\t\twake = 1;\n\t\t\tretval = 0;\n\t\t}\n\t}\n\tlogbuf_cpu = UINT_MAX;\n\tif (wake)\n\t\tup(&console_sem);\n\traw_spin_unlock(&logbuf_lock);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t\t\tretval = 0;\n \t\t}\n \t}\n-\tprintk_cpu = UINT_MAX;\n+\tlogbuf_cpu = UINT_MAX;\n \tif (wake)\n \t\tup(&console_sem);\n \traw_spin_unlock(&logbuf_lock);",
        "function_modified_lines": {
            "added": [
                "\tlogbuf_cpu = UINT_MAX;"
            ],
            "deleted": [
                "\tprintk_cpu = UINT_MAX;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 180
    },
    {
        "cve_id": "CVE-2017-5547",
        "code_before_change": "static ssize_t k90_show_current_profile(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint current_profile;\n\tchar data[8];\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\treturn -EIO;\n\t}\n\tcurrent_profile = data[7];\n\tif (current_profile < 1 || current_profile > 3) {\n\t\tdev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\n\t\t\t data[7]);\n\t\treturn -EIO;\n\t}\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\n}",
        "code_after_change": "static ssize_t k90_show_current_profile(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tint ret;\n\tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n\tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n\tint current_profile;\n\tchar *data;\n\n\tdata = kmalloc(8, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n\t\t\t      K90_REQUEST_STATUS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR |\n\t\t\t      USB_RECIP_DEVICE, 0, 0, data, 8,\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n\t\t\t ret);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tcurrent_profile = data[7];\n\tif (current_profile < 1 || current_profile > 3) {\n\t\tdev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\n\t\t\t data[7]);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\nout:\n\tkfree(data);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,11 @@\n \tstruct usb_interface *usbif = to_usb_interface(dev->parent);\n \tstruct usb_device *usbdev = interface_to_usbdev(usbif);\n \tint current_profile;\n-\tchar data[8];\n+\tchar *data;\n+\n+\tdata = kmalloc(8, GFP_KERNEL);\n+\tif (!data)\n+\t\treturn -ENOMEM;\n \n \tret = usb_control_msg(usbdev, usb_rcvctrlpipe(usbdev, 0),\n \t\t\t      K90_REQUEST_STATUS,\n@@ -16,14 +20,20 @@\n \tif (ret < 0) {\n \t\tdev_warn(dev, \"Failed to get K90 initial state (error %d).\\n\",\n \t\t\t ret);\n-\t\treturn -EIO;\n+\t\tret = -EIO;\n+\t\tgoto out;\n \t}\n \tcurrent_profile = data[7];\n \tif (current_profile < 1 || current_profile > 3) {\n \t\tdev_warn(dev, \"Read invalid current profile: %02hhx.\\n\",\n \t\t\t data[7]);\n-\t\treturn -EIO;\n+\t\tret = -EIO;\n+\t\tgoto out;\n \t}\n \n-\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\n+\tret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);\n+out:\n+\tkfree(data);\n+\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tchar *data;",
                "",
                "\tdata = kmalloc(8, GFP_KERNEL);",
                "\tif (!data)",
                "\t\treturn -ENOMEM;",
                "\t\tret = -EIO;",
                "\t\tgoto out;",
                "\t\tret = -EIO;",
                "\t\tgoto out;",
                "\tret = snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);",
                "out:",
                "\tkfree(data);",
                "",
                "\treturn ret;"
            ],
            "deleted": [
                "\tchar data[8];",
                "\t\treturn -EIO;",
                "\t\treturn -EIO;",
                "\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", current_profile);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-corsair.c in the Linux kernel 4.9.x before 4.9.6 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash or memory corruption) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1462
    },
    {
        "cve_id": "CVE-2014-3184",
        "code_before_change": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n\t\t\trdesc[41] == 0x00 && rdesc[59] == 0x26 &&\n\t\t\trdesc[60] == 0xf9 && rdesc[61] == 0x00) {\n\t\thid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\n\t\trdesc[60] = 0xfa;\n\t\trdesc[40] = 0xfa;\n\t}\n\treturn rdesc;\n}",
        "code_after_change": "static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n\t\tunsigned int *rsize)\n{\n\tif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n\t\t\trdesc[41] == 0x00 && rdesc[59] == 0x26 &&\n\t\t\trdesc[60] == 0xf9 && rdesc[61] == 0x00) {\n\t\thid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");\n\t\trdesc[60] = 0xfa;\n\t\trdesc[40] = 0xfa;\n\t}\n\treturn rdesc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static __u8 *pl_report_fixup(struct hid_device *hdev, __u8 *rdesc,\n \t\tunsigned int *rsize)\n {\n-\tif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n+\tif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&\n \t\t\trdesc[41] == 0x00 && rdesc[59] == 0x26 &&\n \t\t\trdesc[60] == 0xf9 && rdesc[61] == 0x00) {\n \t\thid_info(hdev, \"fixing up Petalynx Maxter Remote report descriptor\\n\");",
        "function_modified_lines": {
            "added": [
                "\tif (*rsize >= 62 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&"
            ],
            "deleted": [
                "\tif (*rsize >= 60 && rdesc[39] == 0x2a && rdesc[40] == 0xf5 &&"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The report_fixup functions in the HID subsystem in the Linux kernel before 3.16.2 might allow physically proximate attackers to cause a denial of service (out-of-bounds write) via a crafted device that provides a small report descriptor, related to (1) drivers/hid/hid-cherry.c, (2) drivers/hid/hid-kye.c, (3) drivers/hid/hid-lg.c, (4) drivers/hid/hid-monterey.c, (5) drivers/hid/hid-petalynx.c, and (6) drivers/hid/hid-sunplus.c.",
        "id": 519
    },
    {
        "cve_id": "CVE-2011-4098",
        "code_before_change": "static int fallocate_chunk(struct inode *inode, loff_t offset, loff_t len,\n\t\t\t   int mode)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct buffer_head *dibh;\n\tint error;\n\tu64 start = offset >> PAGE_CACHE_SHIFT;\n\tunsigned int start_offset = offset & ~PAGE_CACHE_MASK;\n\tu64 end = (offset + len - 1) >> PAGE_CACHE_SHIFT;\n\tpgoff_t curr;\n\tstruct page *page;\n\tunsigned int end_offset = (offset + len) & ~PAGE_CACHE_MASK;\n\tunsigned int from, to;\n\n\tif (!end_offset)\n\t\tend_offset = PAGE_CACHE_SIZE;\n\n\terror = gfs2_meta_inode_buffer(ip, &dibh);\n\tif (unlikely(error))\n\t\tgoto out;\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (gfs2_is_stuffed(ip)) {\n\t\terror = gfs2_unstuff_dinode(ip, NULL);\n\t\tif (unlikely(error))\n\t\t\tgoto out;\n\t}\n\n\tcurr = start;\n\toffset = start << PAGE_CACHE_SHIFT;\n\tfrom = start_offset;\n\tto = PAGE_CACHE_SIZE;\n\twhile (curr <= end) {\n\t\tpage = grab_cache_page_write_begin(inode->i_mapping, curr,\n\t\t\t\t\t\t   AOP_FLAG_NOFS);\n\t\tif (unlikely(!page)) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (curr == end)\n\t\t\tto = end_offset;\n\t\terror = write_empty_blocks(page, from, to, mode);\n\t\tif (!error && offset + to > inode->i_size &&\n\t\t    !(mode & FALLOC_FL_KEEP_SIZE)) {\n\t\t\ti_size_write(inode, offset + to);\n\t\t}\n\t\tunlock_page(page);\n\t\tpage_cache_release(page);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tcurr++;\n\t\toffset += PAGE_CACHE_SIZE;\n\t\tfrom = 0;\n\t}\n\n\tmark_inode_dirty(inode);\n\n\tbrelse(dibh);\n\nout:\n\treturn error;\n}",
        "code_after_change": "static int fallocate_chunk(struct inode *inode, loff_t offset, loff_t len,\n\t\t\t   int mode)\n{\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct buffer_head *dibh;\n\tint error;\n\tunsigned int nr_blks;\n\tsector_t lblock = offset >> inode->i_blkbits;\n\n\terror = gfs2_meta_inode_buffer(ip, &dibh);\n\tif (unlikely(error))\n\t\treturn error;\n\n\tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n\n\tif (gfs2_is_stuffed(ip)) {\n\t\terror = gfs2_unstuff_dinode(ip, NULL);\n\t\tif (unlikely(error))\n\t\t\tgoto out;\n\t}\n\n\twhile (len) {\n\t\tstruct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };\n\t\tbh_map.b_size = len;\n\t\tset_buffer_zeronew(&bh_map);\n\n\t\terror = gfs2_block_map(inode, lblock, &bh_map, 1);\n\t\tif (unlikely(error))\n\t\t\tgoto out;\n\t\tlen -= bh_map.b_size;\n\t\tnr_blks = bh_map.b_size >> inode->i_blkbits;\n\t\tlblock += nr_blks;\n\t\tif (!buffer_new(&bh_map))\n\t\t\tcontinue;\n\t\tif (unlikely(!buffer_zeronew(&bh_map))) {\n\t\t\terror = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (offset + len > inode->i_size && !(mode & FALLOC_FL_KEEP_SIZE))\n\t\ti_size_write(inode, offset + len);\n\n\tmark_inode_dirty(inode);\n\nout:\n\tbrelse(dibh);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,20 +4,12 @@\n \tstruct gfs2_inode *ip = GFS2_I(inode);\n \tstruct buffer_head *dibh;\n \tint error;\n-\tu64 start = offset >> PAGE_CACHE_SHIFT;\n-\tunsigned int start_offset = offset & ~PAGE_CACHE_MASK;\n-\tu64 end = (offset + len - 1) >> PAGE_CACHE_SHIFT;\n-\tpgoff_t curr;\n-\tstruct page *page;\n-\tunsigned int end_offset = (offset + len) & ~PAGE_CACHE_MASK;\n-\tunsigned int from, to;\n-\n-\tif (!end_offset)\n-\t\tend_offset = PAGE_CACHE_SIZE;\n+\tunsigned int nr_blks;\n+\tsector_t lblock = offset >> inode->i_blkbits;\n \n \terror = gfs2_meta_inode_buffer(ip, &dibh);\n \tif (unlikely(error))\n-\t\tgoto out;\n+\t\treturn error;\n \n \tgfs2_trans_add_bh(ip->i_gl, dibh, 1);\n \n@@ -27,38 +19,30 @@\n \t\t\tgoto out;\n \t}\n \n-\tcurr = start;\n-\toffset = start << PAGE_CACHE_SHIFT;\n-\tfrom = start_offset;\n-\tto = PAGE_CACHE_SIZE;\n-\twhile (curr <= end) {\n-\t\tpage = grab_cache_page_write_begin(inode->i_mapping, curr,\n-\t\t\t\t\t\t   AOP_FLAG_NOFS);\n-\t\tif (unlikely(!page)) {\n-\t\t\terror = -ENOMEM;\n+\twhile (len) {\n+\t\tstruct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };\n+\t\tbh_map.b_size = len;\n+\t\tset_buffer_zeronew(&bh_map);\n+\n+\t\terror = gfs2_block_map(inode, lblock, &bh_map, 1);\n+\t\tif (unlikely(error))\n+\t\t\tgoto out;\n+\t\tlen -= bh_map.b_size;\n+\t\tnr_blks = bh_map.b_size >> inode->i_blkbits;\n+\t\tlblock += nr_blks;\n+\t\tif (!buffer_new(&bh_map))\n+\t\t\tcontinue;\n+\t\tif (unlikely(!buffer_zeronew(&bh_map))) {\n+\t\t\terror = -EIO;\n \t\t\tgoto out;\n \t\t}\n-\n-\t\tif (curr == end)\n-\t\t\tto = end_offset;\n-\t\terror = write_empty_blocks(page, from, to, mode);\n-\t\tif (!error && offset + to > inode->i_size &&\n-\t\t    !(mode & FALLOC_FL_KEEP_SIZE)) {\n-\t\t\ti_size_write(inode, offset + to);\n-\t\t}\n-\t\tunlock_page(page);\n-\t\tpage_cache_release(page);\n-\t\tif (error)\n-\t\t\tgoto out;\n-\t\tcurr++;\n-\t\toffset += PAGE_CACHE_SIZE;\n-\t\tfrom = 0;\n \t}\n+\tif (offset + len > inode->i_size && !(mode & FALLOC_FL_KEEP_SIZE))\n+\t\ti_size_write(inode, offset + len);\n \n \tmark_inode_dirty(inode);\n \n+out:\n \tbrelse(dibh);\n-\n-out:\n \treturn error;\n }",
        "function_modified_lines": {
            "added": [
                "\tunsigned int nr_blks;",
                "\tsector_t lblock = offset >> inode->i_blkbits;",
                "\t\treturn error;",
                "\twhile (len) {",
                "\t\tstruct buffer_head bh_map = { .b_state = 0, .b_blocknr = 0 };",
                "\t\tbh_map.b_size = len;",
                "\t\tset_buffer_zeronew(&bh_map);",
                "",
                "\t\terror = gfs2_block_map(inode, lblock, &bh_map, 1);",
                "\t\tif (unlikely(error))",
                "\t\t\tgoto out;",
                "\t\tlen -= bh_map.b_size;",
                "\t\tnr_blks = bh_map.b_size >> inode->i_blkbits;",
                "\t\tlblock += nr_blks;",
                "\t\tif (!buffer_new(&bh_map))",
                "\t\t\tcontinue;",
                "\t\tif (unlikely(!buffer_zeronew(&bh_map))) {",
                "\t\t\terror = -EIO;",
                "\tif (offset + len > inode->i_size && !(mode & FALLOC_FL_KEEP_SIZE))",
                "\t\ti_size_write(inode, offset + len);",
                "out:"
            ],
            "deleted": [
                "\tu64 start = offset >> PAGE_CACHE_SHIFT;",
                "\tunsigned int start_offset = offset & ~PAGE_CACHE_MASK;",
                "\tu64 end = (offset + len - 1) >> PAGE_CACHE_SHIFT;",
                "\tpgoff_t curr;",
                "\tstruct page *page;",
                "\tunsigned int end_offset = (offset + len) & ~PAGE_CACHE_MASK;",
                "\tunsigned int from, to;",
                "",
                "\tif (!end_offset)",
                "\t\tend_offset = PAGE_CACHE_SIZE;",
                "\t\tgoto out;",
                "\tcurr = start;",
                "\toffset = start << PAGE_CACHE_SHIFT;",
                "\tfrom = start_offset;",
                "\tto = PAGE_CACHE_SIZE;",
                "\twhile (curr <= end) {",
                "\t\tpage = grab_cache_page_write_begin(inode->i_mapping, curr,",
                "\t\t\t\t\t\t   AOP_FLAG_NOFS);",
                "\t\tif (unlikely(!page)) {",
                "\t\t\terror = -ENOMEM;",
                "",
                "\t\tif (curr == end)",
                "\t\t\tto = end_offset;",
                "\t\terror = write_empty_blocks(page, from, to, mode);",
                "\t\tif (!error && offset + to > inode->i_size &&",
                "\t\t    !(mode & FALLOC_FL_KEEP_SIZE)) {",
                "\t\t\ti_size_write(inode, offset + to);",
                "\t\t}",
                "\t\tunlock_page(page);",
                "\t\tpage_cache_release(page);",
                "\t\tif (error)",
                "\t\t\tgoto out;",
                "\t\tcurr++;",
                "\t\toffset += PAGE_CACHE_SIZE;",
                "\t\tfrom = 0;",
                "",
                "out:"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The fallocate implementation in the GFS2 filesystem in the Linux kernel before 3.2 relies on the page cache, which might allow local users to cause a denial of service by preallocating blocks in certain situations involving insufficient memory.",
        "id": 31
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\n\tunsigned long end;\n\tunsigned chars;\n\tstruct kmsg_dumper *dumper;\n\tconst char *s1, *s2;\n\tunsigned long l1, l2;\n\tunsigned long flags;\n\n\tif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\n\t\treturn;\n\n\t/* Theoretically, the log could move on after we do this, but\n\t   there's not a lot we can do about that. The new messages\n\t   will overwrite the start of what we dump. */\n\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\tend = log_end & LOG_BUF_MASK;\n\tchars = logged_chars;\n\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\n\tif (chars > end) {\n\t\ts1 = log_buf + log_buf_len - chars + end;\n\t\tl1 = chars - end;\n\n\t\ts2 = log_buf;\n\t\tl2 = end;\n\t} else {\n\t\ts1 = \"\";\n\t\tl1 = 0;\n\n\t\ts2 = log_buf + end - chars;\n\t\tl2 = chars;\n\t}\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(dumper, &dump_list, list)\n\t\tdumper->dump(dumper, reason, s1, l1, s2, l2);\n\trcu_read_unlock();\n}",
        "code_after_change": "void kmsg_dump(enum kmsg_dump_reason reason)\n{\n\tu64 idx;\n\tstruct kmsg_dumper *dumper;\n\tconst char *s1, *s2;\n\tunsigned long l1, l2;\n\tunsigned long flags;\n\n\tif ((reason > KMSG_DUMP_OOPS) && !always_kmsg_dump)\n\t\treturn;\n\n\t/* Theoretically, the log could move on after we do this, but\n\t   there's not a lot we can do about that. The new messages\n\t   will overwrite the start of what we dump. */\n\n\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\tif (syslog_seq < log_first_seq)\n\t\tidx = syslog_idx;\n\telse\n\t\tidx = log_first_idx;\n\n\tif (idx > log_next_idx) {\n\t\ts1 = log_buf;\n\t\tl1 = log_next_idx;\n\n\t\ts2 = log_buf + idx;\n\t\tl2 = log_buf_len - idx;\n\t} else {\n\t\ts1 = \"\";\n\t\tl1 = 0;\n\n\t\ts2 = log_buf + idx;\n\t\tl2 = log_next_idx - idx;\n\t}\n\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(dumper, &dump_list, list)\n\t\tdumper->dump(dumper, reason, s1, l1, s2, l2);\n\trcu_read_unlock();\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,6 @@\n void kmsg_dump(enum kmsg_dump_reason reason)\n {\n-\tunsigned long end;\n-\tunsigned chars;\n+\tu64 idx;\n \tstruct kmsg_dumper *dumper;\n \tconst char *s1, *s2;\n \tunsigned long l1, l2;\n@@ -13,24 +12,27 @@\n \t/* Theoretically, the log could move on after we do this, but\n \t   there's not a lot we can do about that. The new messages\n \t   will overwrite the start of what we dump. */\n+\n \traw_spin_lock_irqsave(&logbuf_lock, flags);\n-\tend = log_end & LOG_BUF_MASK;\n-\tchars = logged_chars;\n-\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n+\tif (syslog_seq < log_first_seq)\n+\t\tidx = syslog_idx;\n+\telse\n+\t\tidx = log_first_idx;\n \n-\tif (chars > end) {\n-\t\ts1 = log_buf + log_buf_len - chars + end;\n-\t\tl1 = chars - end;\n+\tif (idx > log_next_idx) {\n+\t\ts1 = log_buf;\n+\t\tl1 = log_next_idx;\n \n-\t\ts2 = log_buf;\n-\t\tl2 = end;\n+\t\ts2 = log_buf + idx;\n+\t\tl2 = log_buf_len - idx;\n \t} else {\n \t\ts1 = \"\";\n \t\tl1 = 0;\n \n-\t\ts2 = log_buf + end - chars;\n-\t\tl2 = chars;\n+\t\ts2 = log_buf + idx;\n+\t\tl2 = log_next_idx - idx;\n \t}\n+\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n \n \trcu_read_lock();\n \tlist_for_each_entry_rcu(dumper, &dump_list, list)",
        "function_modified_lines": {
            "added": [
                "\tu64 idx;",
                "",
                "\tif (syslog_seq < log_first_seq)",
                "\t\tidx = syslog_idx;",
                "\telse",
                "\t\tidx = log_first_idx;",
                "\tif (idx > log_next_idx) {",
                "\t\ts1 = log_buf;",
                "\t\tl1 = log_next_idx;",
                "\t\ts2 = log_buf + idx;",
                "\t\tl2 = log_buf_len - idx;",
                "\t\ts2 = log_buf + idx;",
                "\t\tl2 = log_next_idx - idx;",
                "\traw_spin_unlock_irqrestore(&logbuf_lock, flags);"
            ],
            "deleted": [
                "\tunsigned long end;",
                "\tunsigned chars;",
                "\tend = log_end & LOG_BUF_MASK;",
                "\tchars = logged_chars;",
                "\traw_spin_unlock_irqrestore(&logbuf_lock, flags);",
                "\tif (chars > end) {",
                "\t\ts1 = log_buf + log_buf_len - chars + end;",
                "\t\tl1 = chars - end;",
                "\t\ts2 = log_buf;",
                "\t\tl2 = end;",
                "\t\ts2 = log_buf + end - chars;",
                "\t\tl2 = chars;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 178
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (s->target_offset == sizeof(struct ip6t_entry) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0 &&\n\t\t    unconditional(&s->ipv6)) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
        "code_after_change": "static inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,11 +12,10 @@\n \t} else if (s == e) {\n \t\t(*rulenum)++;\n \n-\t\tif (s->target_offset == sizeof(struct ip6t_entry) &&\n+\t\tif (unconditional(s) &&\n \t\t    strcmp(t->target.u.kernel.target->name,\n \t\t\t   XT_STANDARD_TARGET) == 0 &&\n-\t\t    t->verdict < 0 &&\n-\t\t    unconditional(&s->ipv6)) {\n+\t\t    t->verdict < 0) {\n \t\t\t/* Tail of chains: STANDARD target (return/policy) */\n \t\t\t*comment = *chainname == hookname\n \t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]",
        "function_modified_lines": {
            "added": [
                "\t\tif (unconditional(s) &&",
                "\t\t    t->verdict < 0) {"
            ],
            "deleted": [
                "\t\tif (s->target_offset == sizeof(struct ip6t_entry) &&",
                "\t\t    t->verdict < 0 &&",
                "\t\t    unconditional(&s->ipv6)) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 969
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n\t\t\t\t       \"use the STANDARD target with \"\n\t\t\t\t       \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_entry(e);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -36,9 +36,9 @@\n \t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n \t\tif ((unsigned char *)e - base == underflows[h]) {\n \t\t\tif (!check_underflow(e)) {\n-\t\t\t\tpr_err(\"Underflows must be unconditional and \"\n-\t\t\t\t       \"use the STANDARD target with \"\n-\t\t\t\t       \"ACCEPT/DROP\\n\");\n+\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n+\t\t\t\t\t \"use the STANDARD target with \"\n+\t\t\t\t\t \"ACCEPT/DROP\\n\");\n \t\t\t\treturn -EINVAL;\n \t\t\t}\n \t\t\tnewinfo->underflow[h] = underflows[h];",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tpr_debug(\"Underflows must be unconditional and \"",
                "\t\t\t\t\t \"use the STANDARD target with \"",
                "\t\t\t\t\t \"ACCEPT/DROP\\n\");"
            ],
            "deleted": [
                "\t\t\t\tpr_err(\"Underflows must be unconditional and \"",
                "\t\t\t\t       \"use the STANDARD target with \"",
                "\t\t\t\t       \"ACCEPT/DROP\\n\");"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 971
    },
    {
        "cve_id": "CVE-2017-7187",
        "code_before_change": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = (void __user *)arg;\n\tint __user *ip = p;\n\tint result, val, read_only;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t   \"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\n\tread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\n\n\tswitch (cmd_in) {\n\tcase SG_IO:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (!scsi_block_when_processing_errors(sdp->device))\n\t\t\treturn -ENXIO;\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\n\t\t\treturn -EFAULT;\n\t\tresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n\t\t\t\t 1, read_only, 1, &srp);\n\t\tif (result < 0)\n\t\t\treturn result;\n\t\tresult = wait_event_interruptible(sfp->read_wait,\n\t\t\t(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\twrite_lock_irq(&sfp->rq_list_lock);\n\t\tif (srp->done) {\n\t\t\tsrp->done = 2;\n\t\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\t\tresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\n\t\t\treturn (result < 0) ? result : 0;\n\t\t}\n\t\tsrp->orphan = 1;\n\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\treturn result;\t/* -ERESTARTSYS because signal hit process */\n\tcase SG_SET_TIMEOUT:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val < 0)\n\t\t\treturn -EIO;\n\t\tif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\n\t\t\tval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\n\t\t\t\t    INT_MAX);\n\t\tsfp->timeout_user = val;\n\t\tsfp->timeout = mult_frac(val, HZ, USER_HZ);\n\n\t\treturn 0;\n\tcase SG_GET_TIMEOUT:\t/* N.B. User receives timeout as return value */\n\t\t\t\t/* strange ..., for backward compatibility */\n\t\treturn sfp->timeout_user;\n\tcase SG_SET_FORCE_LOW_DMA:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val) {\n\t\t\tsfp->low_dma = 1;\n\t\t\tif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\n\t\t\t\tval = (int) sfp->reserve.bufflen;\n\t\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\t\tsg_build_reserve(sfp, val);\n\t\t\t}\n\t\t} else {\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\tsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_LOW_DMA:\n\t\treturn put_user((int) sfp->low_dma, ip);\n\tcase SG_GET_SCSI_ID:\n\t\tif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_scsi_id_t __user *sg_idp = p;\n\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\t__put_user((int) sdp->device->host->host_no,\n\t\t\t\t   &sg_idp->host_no);\n\t\t\t__put_user((int) sdp->device->channel,\n\t\t\t\t   &sg_idp->channel);\n\t\t\t__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n\t\t\t__put_user((int) sdp->device->lun, &sg_idp->lun);\n\t\t\t__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n\t\t\t__put_user((short) sdp->device->host->cmd_per_lun,\n\t\t\t\t   &sg_idp->h_cmd_per_lun);\n\t\t\t__put_user((short) sdp->device->queue_depth,\n\t\t\t\t   &sg_idp->d_queue_depth);\n\t\t\t__put_user(0, &sg_idp->unused[0]);\n\t\t\t__put_user(0, &sg_idp->unused[1]);\n\t\t\treturn 0;\n\t\t}\n\tcase SG_SET_FORCE_PACK_ID:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->force_packid = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_PACK_ID:\n\t\tif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\n\t\t\treturn -EFAULT;\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned)) {\n\t\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock,\n\t\t\t\t\t\t       iflags);\n\t\t\t\t__put_user(srp->header.pack_id, ip);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t__put_user(-1, ip);\n\t\treturn 0;\n\tcase SG_GET_NUM_WAITING:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned))\n\t\t\t\t++val;\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_SG_TABLESIZE:\n\t\treturn put_user(sdp->sg_tablesize, ip);\n\tcase SG_SET_RESERVED_SIZE:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n                if (val < 0)\n                        return -EINVAL;\n\t\tval = min_t(int, val,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\tif (val != sfp->reserve.bufflen) {\n\t\t\tif (sg_res_in_use(sfp) || sfp->mmap_called)\n\t\t\t\treturn -EBUSY;\n\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\tsg_build_reserve(sfp, val);\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_RESERVED_SIZE:\n\t\tval = min_t(int, sfp->reserve.bufflen,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\treturn put_user(val, ip);\n\tcase SG_SET_COMMAND_Q:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->cmd_q = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_COMMAND_Q:\n\t\treturn put_user((int) sfp->cmd_q, ip);\n\tcase SG_SET_KEEP_ORPHAN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->keep_orphan = val;\n\t\treturn 0;\n\tcase SG_GET_KEEP_ORPHAN:\n\t\treturn put_user((int) sfp->keep_orphan, ip);\n\tcase SG_NEXT_CMD_LEN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n\t\treturn 0;\n\tcase SG_GET_VERSION_NUM:\n\t\treturn put_user(sg_version_num, ip);\n\tcase SG_GET_ACCESS_COUNT:\n\t\t/* faked - we don't have a real access count anymore */\n\t\tval = (sdp->device ? 1 : 0);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_REQUEST_TABLE:\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_req_info_t *rinfo;\n\t\t\tunsigned int ms;\n\n\t\t\trinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\n\t\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rinfo)\n\t\t\t\treturn -ENOMEM;\n\t\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\t\tfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n\t\t\t     ++val, srp = srp ? srp->nextrp : srp) {\n\t\t\t\tmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\n\t\t\t\tif (srp) {\n\t\t\t\t\trinfo[val].req_state = srp->done + 1;\n\t\t\t\t\trinfo[val].problem =\n\t\t\t\t\t    srp->header.masked_status & \n\t\t\t\t\t    srp->header.host_status & \n\t\t\t\t\t    srp->header.driver_status;\n\t\t\t\t\tif (srp->done)\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t\tsrp->header.duration;\n\t\t\t\t\telse {\n\t\t\t\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t    (ms > srp->header.duration) ?\n\t\t\t\t\t\t    (ms - srp->header.duration) : 0;\n\t\t\t\t\t}\n\t\t\t\t\trinfo[val].orphan = srp->orphan;\n\t\t\t\t\trinfo[val].sg_io_owned =\n\t\t\t\t\t\t\tsrp->sg_io_owned;\n\t\t\t\t\trinfo[val].pack_id =\n\t\t\t\t\t\t\tsrp->header.pack_id;\n\t\t\t\t\trinfo[val].usr_ptr =\n\t\t\t\t\t\t\tsrp->header.usr_ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t\tresult = __copy_to_user(p, rinfo, \n\t\t\t\t\t\tSZ_SG_REQ_INFO * SG_MAX_QUEUE);\n\t\t\tresult = result ? -EFAULT : 0;\n\t\t\tkfree(rinfo);\n\t\t\treturn result;\n\t\t}\n\tcase SG_EMULATED_HOST:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn put_user(sdp->device->host->hostt->emulated, ip);\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (read_only) {\n\t\t\tunsigned char opcode = WRITE_6;\n\t\t\tScsi_Ioctl_Command __user *siocp = p;\n\n\t\t\tif (copy_from_user(&opcode, siocp->data, 1))\n\t\t\t\treturn -EFAULT;\n\t\t\tif (sg_allow_access(filp, &opcode))\n\t\t\t\treturn -EPERM;\n\t\t}\n\t\treturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\n\tcase SG_SET_DEBUG:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsdp->sgdebug = (char) val;\n\t\treturn 0;\n\tcase BLKSECTGET:\n\t\treturn put_user(max_sectors_bytes(sdp->device->request_queue),\n\t\t\t\tip);\n\tcase BLKTRACESETUP:\n\t\treturn blk_trace_setup(sdp->device->request_queue,\n\t\t\t\t       sdp->disk->disk_name,\n\t\t\t\t       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),\n\t\t\t\t       NULL,\n\t\t\t\t       (char *)arg);\n\tcase BLKTRACESTART:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 1);\n\tcase BLKTRACESTOP:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 0);\n\tcase BLKTRACETEARDOWN:\n\t\treturn blk_trace_remove(sdp->device->request_queue);\n\tcase SCSI_IOCTL_GET_IDLUN:\n\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\tcase SCSI_IOCTL_PROBE_HOST:\n\tcase SG_GET_TRANSFORM:\n\tcase SG_SCSI_RESET:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\tif (read_only)\n\t\t\treturn -EPERM;\t/* don't know so take safe approach */\n\t\tbreak;\n\t}\n\n\tresult = scsi_ioctl_block_when_processing_errors(sdp->device,\n\t\t\tcmd_in, filp->f_flags & O_NDELAY);\n\tif (result)\n\t\treturn result;\n\treturn scsi_ioctl(sdp->device, cmd_in, p);\n}",
        "code_after_change": "static long\nsg_ioctl(struct file *filp, unsigned int cmd_in, unsigned long arg)\n{\n\tvoid __user *p = (void __user *)arg;\n\tint __user *ip = p;\n\tint result, val, read_only;\n\tSg_device *sdp;\n\tSg_fd *sfp;\n\tSg_request *srp;\n\tunsigned long iflags;\n\n\tif ((!(sfp = (Sg_fd *) filp->private_data)) || (!(sdp = sfp->parentdp)))\n\t\treturn -ENXIO;\n\n\tSCSI_LOG_TIMEOUT(3, sg_printk(KERN_INFO, sdp,\n\t\t\t\t   \"sg_ioctl: cmd=0x%x\\n\", (int) cmd_in));\n\tread_only = (O_RDWR != (filp->f_flags & O_ACCMODE));\n\n\tswitch (cmd_in) {\n\tcase SG_IO:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (!scsi_block_when_processing_errors(sdp->device))\n\t\t\treturn -ENXIO;\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_IO_HDR))\n\t\t\treturn -EFAULT;\n\t\tresult = sg_new_write(sfp, filp, p, SZ_SG_IO_HDR,\n\t\t\t\t 1, read_only, 1, &srp);\n\t\tif (result < 0)\n\t\t\treturn result;\n\t\tresult = wait_event_interruptible(sfp->read_wait,\n\t\t\t(srp_done(sfp, srp) || atomic_read(&sdp->detaching)));\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\twrite_lock_irq(&sfp->rq_list_lock);\n\t\tif (srp->done) {\n\t\t\tsrp->done = 2;\n\t\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\t\tresult = sg_new_read(sfp, p, SZ_SG_IO_HDR, srp);\n\t\t\treturn (result < 0) ? result : 0;\n\t\t}\n\t\tsrp->orphan = 1;\n\t\twrite_unlock_irq(&sfp->rq_list_lock);\n\t\treturn result;\t/* -ERESTARTSYS because signal hit process */\n\tcase SG_SET_TIMEOUT:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val < 0)\n\t\t\treturn -EIO;\n\t\tif (val >= mult_frac((s64)INT_MAX, USER_HZ, HZ))\n\t\t\tval = min_t(s64, mult_frac((s64)INT_MAX, USER_HZ, HZ),\n\t\t\t\t    INT_MAX);\n\t\tsfp->timeout_user = val;\n\t\tsfp->timeout = mult_frac(val, HZ, USER_HZ);\n\n\t\treturn 0;\n\tcase SG_GET_TIMEOUT:\t/* N.B. User receives timeout as return value */\n\t\t\t\t/* strange ..., for backward compatibility */\n\t\treturn sfp->timeout_user;\n\tcase SG_SET_FORCE_LOW_DMA:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val) {\n\t\t\tsfp->low_dma = 1;\n\t\t\tif ((0 == sfp->low_dma) && (0 == sg_res_in_use(sfp))) {\n\t\t\t\tval = (int) sfp->reserve.bufflen;\n\t\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\t\tsg_build_reserve(sfp, val);\n\t\t\t}\n\t\t} else {\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\tsfp->low_dma = sdp->device->host->unchecked_isa_dma;\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_LOW_DMA:\n\t\treturn put_user((int) sfp->low_dma, ip);\n\tcase SG_GET_SCSI_ID:\n\t\tif (!access_ok(VERIFY_WRITE, p, sizeof (sg_scsi_id_t)))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_scsi_id_t __user *sg_idp = p;\n\n\t\t\tif (atomic_read(&sdp->detaching))\n\t\t\t\treturn -ENODEV;\n\t\t\t__put_user((int) sdp->device->host->host_no,\n\t\t\t\t   &sg_idp->host_no);\n\t\t\t__put_user((int) sdp->device->channel,\n\t\t\t\t   &sg_idp->channel);\n\t\t\t__put_user((int) sdp->device->id, &sg_idp->scsi_id);\n\t\t\t__put_user((int) sdp->device->lun, &sg_idp->lun);\n\t\t\t__put_user((int) sdp->device->type, &sg_idp->scsi_type);\n\t\t\t__put_user((short) sdp->device->host->cmd_per_lun,\n\t\t\t\t   &sg_idp->h_cmd_per_lun);\n\t\t\t__put_user((short) sdp->device->queue_depth,\n\t\t\t\t   &sg_idp->d_queue_depth);\n\t\t\t__put_user(0, &sg_idp->unused[0]);\n\t\t\t__put_user(0, &sg_idp->unused[1]);\n\t\t\treturn 0;\n\t\t}\n\tcase SG_SET_FORCE_PACK_ID:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->force_packid = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_PACK_ID:\n\t\tif (!access_ok(VERIFY_WRITE, ip, sizeof (int)))\n\t\t\treturn -EFAULT;\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned)) {\n\t\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock,\n\t\t\t\t\t\t       iflags);\n\t\t\t\t__put_user(srp->header.pack_id, ip);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t__put_user(-1, ip);\n\t\treturn 0;\n\tcase SG_GET_NUM_WAITING:\n\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\tfor (val = 0, srp = sfp->headrp; srp; srp = srp->nextrp) {\n\t\t\tif ((1 == srp->done) && (!srp->sg_io_owned))\n\t\t\t\t++val;\n\t\t}\n\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_SG_TABLESIZE:\n\t\treturn put_user(sdp->sg_tablesize, ip);\n\tcase SG_SET_RESERVED_SIZE:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n                if (val < 0)\n                        return -EINVAL;\n\t\tval = min_t(int, val,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\tif (val != sfp->reserve.bufflen) {\n\t\t\tif (sg_res_in_use(sfp) || sfp->mmap_called)\n\t\t\t\treturn -EBUSY;\n\t\t\tsg_remove_scat(sfp, &sfp->reserve);\n\t\t\tsg_build_reserve(sfp, val);\n\t\t}\n\t\treturn 0;\n\tcase SG_GET_RESERVED_SIZE:\n\t\tval = min_t(int, sfp->reserve.bufflen,\n\t\t\t    max_sectors_bytes(sdp->device->request_queue));\n\t\treturn put_user(val, ip);\n\tcase SG_SET_COMMAND_Q:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->cmd_q = val ? 1 : 0;\n\t\treturn 0;\n\tcase SG_GET_COMMAND_Q:\n\t\treturn put_user((int) sfp->cmd_q, ip);\n\tcase SG_SET_KEEP_ORPHAN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsfp->keep_orphan = val;\n\t\treturn 0;\n\tcase SG_GET_KEEP_ORPHAN:\n\t\treturn put_user((int) sfp->keep_orphan, ip);\n\tcase SG_NEXT_CMD_LEN:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tif (val > SG_MAX_CDB_SIZE)\n\t\t\treturn -ENOMEM;\n\t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n\t\treturn 0;\n\tcase SG_GET_VERSION_NUM:\n\t\treturn put_user(sg_version_num, ip);\n\tcase SG_GET_ACCESS_COUNT:\n\t\t/* faked - we don't have a real access count anymore */\n\t\tval = (sdp->device ? 1 : 0);\n\t\treturn put_user(val, ip);\n\tcase SG_GET_REQUEST_TABLE:\n\t\tif (!access_ok(VERIFY_WRITE, p, SZ_SG_REQ_INFO * SG_MAX_QUEUE))\n\t\t\treturn -EFAULT;\n\t\telse {\n\t\t\tsg_req_info_t *rinfo;\n\t\t\tunsigned int ms;\n\n\t\t\trinfo = kmalloc(SZ_SG_REQ_INFO * SG_MAX_QUEUE,\n\t\t\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rinfo)\n\t\t\t\treturn -ENOMEM;\n\t\t\tread_lock_irqsave(&sfp->rq_list_lock, iflags);\n\t\t\tfor (srp = sfp->headrp, val = 0; val < SG_MAX_QUEUE;\n\t\t\t     ++val, srp = srp ? srp->nextrp : srp) {\n\t\t\t\tmemset(&rinfo[val], 0, SZ_SG_REQ_INFO);\n\t\t\t\tif (srp) {\n\t\t\t\t\trinfo[val].req_state = srp->done + 1;\n\t\t\t\t\trinfo[val].problem =\n\t\t\t\t\t    srp->header.masked_status & \n\t\t\t\t\t    srp->header.host_status & \n\t\t\t\t\t    srp->header.driver_status;\n\t\t\t\t\tif (srp->done)\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t\tsrp->header.duration;\n\t\t\t\t\telse {\n\t\t\t\t\t\tms = jiffies_to_msecs(jiffies);\n\t\t\t\t\t\trinfo[val].duration =\n\t\t\t\t\t\t    (ms > srp->header.duration) ?\n\t\t\t\t\t\t    (ms - srp->header.duration) : 0;\n\t\t\t\t\t}\n\t\t\t\t\trinfo[val].orphan = srp->orphan;\n\t\t\t\t\trinfo[val].sg_io_owned =\n\t\t\t\t\t\t\tsrp->sg_io_owned;\n\t\t\t\t\trinfo[val].pack_id =\n\t\t\t\t\t\t\tsrp->header.pack_id;\n\t\t\t\t\trinfo[val].usr_ptr =\n\t\t\t\t\t\t\tsrp->header.usr_ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tread_unlock_irqrestore(&sfp->rq_list_lock, iflags);\n\t\t\tresult = __copy_to_user(p, rinfo, \n\t\t\t\t\t\tSZ_SG_REQ_INFO * SG_MAX_QUEUE);\n\t\t\tresult = result ? -EFAULT : 0;\n\t\t\tkfree(rinfo);\n\t\t\treturn result;\n\t\t}\n\tcase SG_EMULATED_HOST:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\treturn put_user(sdp->device->host->hostt->emulated, ip);\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tif (read_only) {\n\t\t\tunsigned char opcode = WRITE_6;\n\t\t\tScsi_Ioctl_Command __user *siocp = p;\n\n\t\t\tif (copy_from_user(&opcode, siocp->data, 1))\n\t\t\t\treturn -EFAULT;\n\t\t\tif (sg_allow_access(filp, &opcode))\n\t\t\t\treturn -EPERM;\n\t\t}\n\t\treturn sg_scsi_ioctl(sdp->device->request_queue, NULL, filp->f_mode, p);\n\tcase SG_SET_DEBUG:\n\t\tresult = get_user(val, ip);\n\t\tif (result)\n\t\t\treturn result;\n\t\tsdp->sgdebug = (char) val;\n\t\treturn 0;\n\tcase BLKSECTGET:\n\t\treturn put_user(max_sectors_bytes(sdp->device->request_queue),\n\t\t\t\tip);\n\tcase BLKTRACESETUP:\n\t\treturn blk_trace_setup(sdp->device->request_queue,\n\t\t\t\t       sdp->disk->disk_name,\n\t\t\t\t       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),\n\t\t\t\t       NULL,\n\t\t\t\t       (char *)arg);\n\tcase BLKTRACESTART:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 1);\n\tcase BLKTRACESTOP:\n\t\treturn blk_trace_startstop(sdp->device->request_queue, 0);\n\tcase BLKTRACETEARDOWN:\n\t\treturn blk_trace_remove(sdp->device->request_queue);\n\tcase SCSI_IOCTL_GET_IDLUN:\n\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\tcase SCSI_IOCTL_PROBE_HOST:\n\tcase SG_GET_TRANSFORM:\n\tcase SG_SCSI_RESET:\n\t\tif (atomic_read(&sdp->detaching))\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\tif (read_only)\n\t\t\treturn -EPERM;\t/* don't know so take safe approach */\n\t\tbreak;\n\t}\n\n\tresult = scsi_ioctl_block_when_processing_errors(sdp->device,\n\t\t\tcmd_in, filp->f_flags & O_NDELAY);\n\tif (result)\n\t\treturn result;\n\treturn scsi_ioctl(sdp->device, cmd_in, p);\n}",
        "patch": "--- code before\n+++ code after\n@@ -170,6 +170,8 @@\n \t\tresult = get_user(val, ip);\n \t\tif (result)\n \t\t\treturn result;\n+\t\tif (val > SG_MAX_CDB_SIZE)\n+\t\t\treturn -ENOMEM;\n \t\tsfp->next_cmd_len = (val > 0) ? val : 0;\n \t\treturn 0;\n \tcase SG_GET_VERSION_NUM:",
        "function_modified_lines": {
            "added": [
                "\t\tif (val > SG_MAX_CDB_SIZE)",
                "\t\t\treturn -ENOMEM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The sg_ioctl function in drivers/scsi/sg.c in the Linux kernel through 4.10.4 allows local users to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a large command size in an SG_NEXT_CMD_LEN ioctl call, leading to out-of-bounds write access in the sg_write function.",
        "id": 1490
    },
    {
        "cve_id": "CVE-2015-4036",
        "code_before_change": "static void\nvhost_scsi_send_evt(struct vhost_scsi *vs,\n\t\t   struct vhost_scsi_tpg *tpg,\n\t\t   struct se_lun *lun,\n\t\t   u32 event,\n\t\t   u32 reason)\n{\n\tstruct vhost_scsi_evt *evt;\n\n\tevt = vhost_scsi_allocate_evt(vs, event, reason);\n\tif (!evt)\n\t\treturn;\n\n\tif (tpg && lun) {\n\t\t/* TODO: share lun setup code with virtio-scsi.ko */\n\t\t/*\n\t\t * Note: evt->event is zeroed when we allocate it and\n\t\t * lun[4-7] need to be zero according to virtio-scsi spec.\n\t\t */\n\t\tevt->event.lun[0] = 0x01;\n\t\tevt->event.lun[1] = tpg->tport_tpgt & 0xFF;\n\t\tif (lun->unpacked_lun >= 256)\n\t\t\tevt->event.lun[2] = lun->unpacked_lun >> 8 | 0x40 ;\n\t\tevt->event.lun[3] = lun->unpacked_lun & 0xFF;\n\t}\n\n\tllist_add(&evt->list, &vs->vs_event_list);\n\tvhost_work_queue(&vs->dev, &vs->vs_event_work);\n}",
        "code_after_change": "static void\nvhost_scsi_send_evt(struct vhost_scsi *vs,\n\t\t   struct vhost_scsi_tpg *tpg,\n\t\t   struct se_lun *lun,\n\t\t   u32 event,\n\t\t   u32 reason)\n{\n\tstruct vhost_scsi_evt *evt;\n\n\tevt = vhost_scsi_allocate_evt(vs, event, reason);\n\tif (!evt)\n\t\treturn;\n\n\tif (tpg && lun) {\n\t\t/* TODO: share lun setup code with virtio-scsi.ko */\n\t\t/*\n\t\t * Note: evt->event is zeroed when we allocate it and\n\t\t * lun[4-7] need to be zero according to virtio-scsi spec.\n\t\t */\n\t\tevt->event.lun[0] = 0x01;\n\t\tevt->event.lun[1] = tpg->tport_tpgt;\n\t\tif (lun->unpacked_lun >= 256)\n\t\t\tevt->event.lun[2] = lun->unpacked_lun >> 8 | 0x40 ;\n\t\tevt->event.lun[3] = lun->unpacked_lun & 0xFF;\n\t}\n\n\tllist_add(&evt->list, &vs->vs_event_list);\n\tvhost_work_queue(&vs->dev, &vs->vs_event_work);\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t\t * lun[4-7] need to be zero according to virtio-scsi spec.\n \t\t */\n \t\tevt->event.lun[0] = 0x01;\n-\t\tevt->event.lun[1] = tpg->tport_tpgt & 0xFF;\n+\t\tevt->event.lun[1] = tpg->tport_tpgt;\n \t\tif (lun->unpacked_lun >= 256)\n \t\t\tevt->event.lun[2] = lun->unpacked_lun >> 8 | 0x40 ;\n \t\tevt->event.lun[3] = lun->unpacked_lun & 0xFF;",
        "function_modified_lines": {
            "added": [
                "\t\tevt->event.lun[1] = tpg->tport_tpgt;"
            ],
            "deleted": [
                "\t\tevt->event.lun[1] = tpg->tport_tpgt & 0xFF;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Array index error in the tcm_vhost_make_tpg function in drivers/vhost/scsi.c in the Linux kernel before 4.0 might allow guest OS users to cause a denial of service (memory corruption) or possibly have unspecified other impact via a crafted VHOST_SCSI_SET_ENDPOINT ioctl call.  NOTE: the affected function was renamed to vhost_scsi_make_tpg before the vulnerability was announced.",
        "id": 762
    },
    {
        "cve_id": "CVE-2017-14497",
        "code_before_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, netoff, hdrlen;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr)\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0)\n\t\t\t\tsnaplen = 0;\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (po->stats.stats1.tp_drops)\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tif (po->has_vnet_hdr) {\n\t\tif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t\t    vio_le(), true)) {\n\t\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t\tgoto drop_n_account;\n\t\t}\n\t}\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tgetnstimeofday(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\t__packet_set_status(po, h.raw, status);\n\t\tsk->sk_data_ready(sk);\n\t} else {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tis_drop_n_account = true;\n\tpo->stats.stats1.tp_drops++;\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
        "code_after_change": "static int tpacket_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t       struct packet_type *pt, struct net_device *orig_dev)\n{\n\tstruct sock *sk;\n\tstruct packet_sock *po;\n\tstruct sockaddr_ll *sll;\n\tunion tpacket_uhdr h;\n\tu8 *skb_head = skb->data;\n\tint skb_len = skb->len;\n\tunsigned int snaplen, res;\n\tunsigned long status = TP_STATUS_USER;\n\tunsigned short macoff, netoff, hdrlen;\n\tstruct sk_buff *copy_skb = NULL;\n\tstruct timespec ts;\n\t__u32 ts_status;\n\tbool is_drop_n_account = false;\n\tbool do_vnet = false;\n\n\t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n\t * We may add members to them until current aligned size without forcing\n\t * userspace to call getsockopt(..., PACKET_HDRLEN, ...).\n\t */\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h2)) != 32);\n\tBUILD_BUG_ON(TPACKET_ALIGN(sizeof(*h.h3)) != 48);\n\n\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\tgoto drop;\n\n\tsk = pt->af_packet_priv;\n\tpo = pkt_sk(sk);\n\n\tif (!net_eq(dev_net(dev), sock_net(sk)))\n\t\tgoto drop;\n\n\tif (dev->header_ops) {\n\t\tif (sk->sk_type != SOCK_DGRAM)\n\t\t\tskb_push(skb, skb->data - skb_mac_header(skb));\n\t\telse if (skb->pkt_type == PACKET_OUTGOING) {\n\t\t\t/* Special case: outgoing packets have ll header at head */\n\t\t\tskb_pull(skb, skb_network_offset(skb));\n\t\t}\n\t}\n\n\tsnaplen = skb->len;\n\n\tres = run_filter(skb, sk, snaplen);\n\tif (!res)\n\t\tgoto drop_n_restore;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstatus |= TP_STATUS_CSUMNOTREADY;\n\telse if (skb->pkt_type != PACKET_OUTGOING &&\n\t\t (skb->ip_summed == CHECKSUM_COMPLETE ||\n\t\t  skb_csum_unnecessary(skb)))\n\t\tstatus |= TP_STATUS_CSUM_VALID;\n\n\tif (snaplen > res)\n\t\tsnaplen = res;\n\n\tif (sk->sk_type == SOCK_DGRAM) {\n\t\tmacoff = netoff = TPACKET_ALIGN(po->tp_hdrlen) + 16 +\n\t\t\t\t  po->tp_reserve;\n\t} else {\n\t\tunsigned int maclen = skb_network_offset(skb);\n\t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n\t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n\t\t\t\t       po->tp_reserve;\n\t\tif (po->has_vnet_hdr) {\n\t\t\tnetoff += sizeof(struct virtio_net_hdr);\n\t\t\tdo_vnet = true;\n\t\t}\n\t\tmacoff = netoff - maclen;\n\t}\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tif (macoff + snaplen > po->rx_ring.frame_size) {\n\t\t\tif (po->copy_thresh &&\n\t\t\t    atomic_read(&sk->sk_rmem_alloc) < sk->sk_rcvbuf) {\n\t\t\t\tif (skb_shared(skb)) {\n\t\t\t\t\tcopy_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\t} else {\n\t\t\t\t\tcopy_skb = skb_get(skb);\n\t\t\t\t\tskb_head = skb->data;\n\t\t\t\t}\n\t\t\t\tif (copy_skb)\n\t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n\t\t\t}\n\t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n\t\t\tif ((int)snaplen < 0) {\n\t\t\t\tsnaplen = 0;\n\t\t\t\tdo_vnet = false;\n\t\t\t}\n\t\t}\n\t} else if (unlikely(macoff + snaplen >\n\t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n\t\tu32 nval;\n\n\t\tnval = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len - macoff;\n\t\tpr_err_once(\"tpacket_rcv: packet too big, clamped from %u to %u. macoff=%u\\n\",\n\t\t\t    snaplen, nval, macoff);\n\t\tsnaplen = nval;\n\t\tif (unlikely((int)snaplen < 0)) {\n\t\t\tsnaplen = 0;\n\t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n\t\t\tdo_vnet = false;\n\t\t}\n\t}\n\tspin_lock(&sk->sk_receive_queue.lock);\n\th.raw = packet_current_rx_frame(po, skb,\n\t\t\t\t\tTP_STATUS_KERNEL, (macoff+snaplen));\n\tif (!h.raw)\n\t\tgoto drop_n_account;\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tpacket_increment_rx_head(po, &po->rx_ring);\n\t/*\n\t * LOSING will be reported till you read the stats,\n\t * because it's COR - Clear On Read.\n\t * Anyways, moving it for V1/V2 only as V3 doesn't need this\n\t * at packet level.\n\t */\n\t\tif (po->stats.stats1.tp_drops)\n\t\t\tstatus |= TP_STATUS_LOSING;\n\t}\n\tpo->stats.stats1.tp_packets++;\n\tif (copy_skb) {\n\t\tstatus |= TP_STATUS_COPY;\n\t\t__skb_queue_tail(&sk->sk_receive_queue, copy_skb);\n\t}\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tif (do_vnet) {\n\t\tif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\n\t\t\t\t\t    sizeof(struct virtio_net_hdr),\n\t\t\t\t\t    vio_le(), true)) {\n\t\t\tspin_lock(&sk->sk_receive_queue.lock);\n\t\t\tgoto drop_n_account;\n\t\t}\n\t}\n\n\tskb_copy_bits(skb, 0, h.raw + macoff, snaplen);\n\n\tif (!(ts_status = tpacket_get_timestamp(skb, &ts, po->tp_tstamp)))\n\t\tgetnstimeofday(&ts);\n\n\tstatus |= ts_status;\n\n\tswitch (po->tp_version) {\n\tcase TPACKET_V1:\n\t\th.h1->tp_len = skb->len;\n\t\th.h1->tp_snaplen = snaplen;\n\t\th.h1->tp_mac = macoff;\n\t\th.h1->tp_net = netoff;\n\t\th.h1->tp_sec = ts.tv_sec;\n\t\th.h1->tp_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t\thdrlen = sizeof(*h.h1);\n\t\tbreak;\n\tcase TPACKET_V2:\n\t\th.h2->tp_len = skb->len;\n\t\th.h2->tp_snaplen = snaplen;\n\t\th.h2->tp_mac = macoff;\n\t\th.h2->tp_net = netoff;\n\t\th.h2->tp_sec = ts.tv_sec;\n\t\th.h2->tp_nsec = ts.tv_nsec;\n\t\tif (skb_vlan_tag_present(skb)) {\n\t\t\th.h2->tp_vlan_tci = skb_vlan_tag_get(skb);\n\t\t\th.h2->tp_vlan_tpid = ntohs(skb->vlan_proto);\n\t\t\tstatus |= TP_STATUS_VLAN_VALID | TP_STATUS_VLAN_TPID_VALID;\n\t\t} else {\n\t\t\th.h2->tp_vlan_tci = 0;\n\t\t\th.h2->tp_vlan_tpid = 0;\n\t\t}\n\t\tmemset(h.h2->tp_padding, 0, sizeof(h.h2->tp_padding));\n\t\thdrlen = sizeof(*h.h2);\n\t\tbreak;\n\tcase TPACKET_V3:\n\t\t/* tp_nxt_offset,vlan are already populated above.\n\t\t * So DONT clear those fields here\n\t\t */\n\t\th.h3->tp_status |= status;\n\t\th.h3->tp_len = skb->len;\n\t\th.h3->tp_snaplen = snaplen;\n\t\th.h3->tp_mac = macoff;\n\t\th.h3->tp_net = netoff;\n\t\th.h3->tp_sec  = ts.tv_sec;\n\t\th.h3->tp_nsec = ts.tv_nsec;\n\t\tmemset(h.h3->tp_padding, 0, sizeof(h.h3->tp_padding));\n\t\thdrlen = sizeof(*h.h3);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tsll = h.raw + TPACKET_ALIGN(hdrlen);\n\tsll->sll_halen = dev_parse_header(skb, sll->sll_addr);\n\tsll->sll_family = AF_PACKET;\n\tsll->sll_hatype = dev->type;\n\tsll->sll_protocol = skb->protocol;\n\tsll->sll_pkttype = skb->pkt_type;\n\tif (unlikely(po->origdev))\n\t\tsll->sll_ifindex = orig_dev->ifindex;\n\telse\n\t\tsll->sll_ifindex = dev->ifindex;\n\n\tsmp_mb();\n\n#if ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE == 1\n\tif (po->tp_version <= TPACKET_V2) {\n\t\tu8 *start, *end;\n\n\t\tend = (u8 *) PAGE_ALIGN((unsigned long) h.raw +\n\t\t\t\t\tmacoff + snaplen);\n\n\t\tfor (start = h.raw; start < end; start += PAGE_SIZE)\n\t\t\tflush_dcache_page(pgv_to_page(start));\n\t}\n\tsmp_wmb();\n#endif\n\n\tif (po->tp_version <= TPACKET_V2) {\n\t\t__packet_set_status(po, h.raw, status);\n\t\tsk->sk_data_ready(sk);\n\t} else {\n\t\tprb_clear_blk_fill_status(&po->rx_ring);\n\t}\n\ndrop_n_restore:\n\tif (skb_head != skb->data && skb_shared(skb)) {\n\t\tskb->data = skb_head;\n\t\tskb->len = skb_len;\n\t}\ndrop:\n\tif (!is_drop_n_account)\n\t\tconsume_skb(skb);\n\telse\n\t\tkfree_skb(skb);\n\treturn 0;\n\ndrop_n_account:\n\tis_drop_n_account = true;\n\tpo->stats.stats1.tp_drops++;\n\tspin_unlock(&sk->sk_receive_queue.lock);\n\n\tsk->sk_data_ready(sk);\n\tkfree_skb(copy_skb);\n\tgoto drop_n_restore;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,7 @@\n \tstruct timespec ts;\n \t__u32 ts_status;\n \tbool is_drop_n_account = false;\n+\tbool do_vnet = false;\n \n \t/* struct tpacket{2,3}_hdr is aligned to a multiple of TPACKET_ALIGNMENT.\n \t * We may add members to them until current aligned size without forcing\n@@ -64,8 +65,10 @@\n \t\tnetoff = TPACKET_ALIGN(po->tp_hdrlen +\n \t\t\t\t       (maclen < 16 ? 16 : maclen)) +\n \t\t\t\t       po->tp_reserve;\n-\t\tif (po->has_vnet_hdr)\n+\t\tif (po->has_vnet_hdr) {\n \t\t\tnetoff += sizeof(struct virtio_net_hdr);\n+\t\t\tdo_vnet = true;\n+\t\t}\n \t\tmacoff = netoff - maclen;\n \t}\n \tif (po->tp_version <= TPACKET_V2) {\n@@ -82,8 +85,10 @@\n \t\t\t\t\tskb_set_owner_r(copy_skb, sk);\n \t\t\t}\n \t\t\tsnaplen = po->rx_ring.frame_size - macoff;\n-\t\t\tif ((int)snaplen < 0)\n+\t\t\tif ((int)snaplen < 0) {\n \t\t\t\tsnaplen = 0;\n+\t\t\t\tdo_vnet = false;\n+\t\t\t}\n \t\t}\n \t} else if (unlikely(macoff + snaplen >\n \t\t\t    GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len)) {\n@@ -96,6 +101,7 @@\n \t\tif (unlikely((int)snaplen < 0)) {\n \t\t\tsnaplen = 0;\n \t\t\tmacoff = GET_PBDQC_FROM_RB(&po->rx_ring)->max_frame_len;\n+\t\t\tdo_vnet = false;\n \t\t}\n \t}\n \tspin_lock(&sk->sk_receive_queue.lock);\n@@ -121,7 +127,7 @@\n \t}\n \tspin_unlock(&sk->sk_receive_queue.lock);\n \n-\tif (po->has_vnet_hdr) {\n+\tif (do_vnet) {\n \t\tif (virtio_net_hdr_from_skb(skb, h.raw + macoff -\n \t\t\t\t\t    sizeof(struct virtio_net_hdr),\n \t\t\t\t\t    vio_le(), true)) {",
        "function_modified_lines": {
            "added": [
                "\tbool do_vnet = false;",
                "\t\tif (po->has_vnet_hdr) {",
                "\t\t\tdo_vnet = true;",
                "\t\t}",
                "\t\t\tif ((int)snaplen < 0) {",
                "\t\t\t\tdo_vnet = false;",
                "\t\t\t}",
                "\t\t\tdo_vnet = false;",
                "\tif (do_vnet) {"
            ],
            "deleted": [
                "\t\tif (po->has_vnet_hdr)",
                "\t\t\tif ((int)snaplen < 0)",
                "\tif (po->has_vnet_hdr) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The tpacket_rcv function in net/packet/af_packet.c in the Linux kernel before 4.13 mishandles vnet headers, which might allow local users to cause a denial of service (buffer overflow, and disk and memory corruption) or possibly have unspecified other impact via crafted system calls.",
        "id": 1285
    },
    {
        "cve_id": "CVE-2018-1120",
        "code_before_change": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\n\tvm_flags_t vm_flags = vma->vm_flags;\n\tint write = (gup_flags & FOLL_WRITE);\n\tint foreign = (gup_flags & FOLL_REMOTE);\n\n\tif (vm_flags & (VM_IO | VM_PFNMAP))\n\t\treturn -EFAULT;\n\n\tif (write) {\n\t\tif (!(vm_flags & VM_WRITE)) {\n\t\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\t\treturn -EFAULT;\n\t\t\t/*\n\t\t\t * We used to let the write,force case do COW in a\n\t\t\t * VM_MAYWRITE VM_SHARED !VM_WRITE vma, so ptrace could\n\t\t\t * set a breakpoint in a read-only mapping of an\n\t\t\t * executable, without corrupting the file (yet only\n\t\t\t * when that file had been opened for writing!).\n\t\t\t * Anon pages in shared mappings are surprising: now\n\t\t\t * just reject it.\n\t\t\t */\n\t\t\tif (!is_cow_mapping(vm_flags))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (!(vm_flags & VM_READ)) {\n\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\treturn -EFAULT;\n\t\t/*\n\t\t * Is there actually any vma we can reach here which does not\n\t\t * have VM_MAYREAD set?\n\t\t */\n\t\tif (!(vm_flags & VM_MAYREAD))\n\t\t\treturn -EFAULT;\n\t}\n\t/*\n\t * gups are always data accesses, not instruction\n\t * fetches, so execute=false here\n\t */\n\tif (!arch_vma_access_permitted(vma, write, false, foreign))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
        "code_after_change": "static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)\n{\n\tvm_flags_t vm_flags = vma->vm_flags;\n\tint write = (gup_flags & FOLL_WRITE);\n\tint foreign = (gup_flags & FOLL_REMOTE);\n\n\tif (vm_flags & (VM_IO | VM_PFNMAP))\n\t\treturn -EFAULT;\n\n\tif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))\n\t\treturn -EFAULT;\n\n\tif (write) {\n\t\tif (!(vm_flags & VM_WRITE)) {\n\t\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\t\treturn -EFAULT;\n\t\t\t/*\n\t\t\t * We used to let the write,force case do COW in a\n\t\t\t * VM_MAYWRITE VM_SHARED !VM_WRITE vma, so ptrace could\n\t\t\t * set a breakpoint in a read-only mapping of an\n\t\t\t * executable, without corrupting the file (yet only\n\t\t\t * when that file had been opened for writing!).\n\t\t\t * Anon pages in shared mappings are surprising: now\n\t\t\t * just reject it.\n\t\t\t */\n\t\t\tif (!is_cow_mapping(vm_flags))\n\t\t\t\treturn -EFAULT;\n\t\t}\n\t} else if (!(vm_flags & VM_READ)) {\n\t\tif (!(gup_flags & FOLL_FORCE))\n\t\t\treturn -EFAULT;\n\t\t/*\n\t\t * Is there actually any vma we can reach here which does not\n\t\t * have VM_MAYREAD set?\n\t\t */\n\t\tif (!(vm_flags & VM_MAYREAD))\n\t\t\treturn -EFAULT;\n\t}\n\t/*\n\t * gups are always data accesses, not instruction\n\t * fetches, so execute=false here\n\t */\n\tif (!arch_vma_access_permitted(vma, write, false, foreign))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tint foreign = (gup_flags & FOLL_REMOTE);\n \n \tif (vm_flags & (VM_IO | VM_PFNMAP))\n+\t\treturn -EFAULT;\n+\n+\tif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))\n \t\treturn -EFAULT;\n \n \tif (write) {",
        "function_modified_lines": {
            "added": [
                "\t\treturn -EFAULT;",
                "",
                "\tif (gup_flags & FOLL_ANON && !vma_is_anonymous(vma))"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A flaw was found affecting the Linux kernel before version 4.17. By mmap()ing a FUSE-backed file onto a process's memory containing command line arguments (or environment strings), an attacker can cause utilities from psutils or procps (such as ps, w) or any other program which makes a read() call to the /proc/<pid>/cmdline (or /proc/<pid>/environ) files to block indefinitely (denial of service) or for some controlled time (as a synchronization primitive for other attacks).",
        "id": 1637
    },
    {
        "cve_id": "CVE-2021-4204",
        "code_before_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (base_type(reg->type) == PTR_TO_MEM) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\n\t\tif (type_may_be_null(reg->type)) {\n\t\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && rdonly_mem) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (base_type(reg->type) == PTR_TO_BUF) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\t\tconst char *buf_info;\n\t\tu32 *max_access;\n\n\t\tif (rdonly_mem) {\n\t\t\tif (t == BPF_WRITE) {\n\t\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t\tbuf_info = \"rdonly\";\n\t\t\tmax_access = &env->prog->aux->max_rdonly_access;\n\t\t} else {\n\t\t\tbuf_info = \"rdwr\";\n\t\t\tmax_access = &env->prog->aux->max_rdwr_access;\n\t\t}\n\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  buf_info, max_access);\n\n\t\tif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "code_after_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (base_type(reg->type) == PTR_TO_MEM) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\n\t\tif (type_may_be_null(reg->type)) {\n\t\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && rdonly_mem) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && value_regno >= 0 && (t == BPF_READ || rdonly_mem))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ptr_off_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (base_type(reg->type) == PTR_TO_BUF) {\n\t\tbool rdonly_mem = type_is_rdonly_mem(reg->type);\n\t\tconst char *buf_info;\n\t\tu32 *max_access;\n\n\t\tif (rdonly_mem) {\n\t\t\tif (t == BPF_WRITE) {\n\t\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t\tbuf_info = \"rdonly\";\n\t\t\tmax_access = &env->prog->aux->max_rdonly_access;\n\t\t} else {\n\t\t\tbuf_info = \"rdwr\";\n\t\t\tmax_access = &env->prog->aux->max_rdwr_access;\n\t\t}\n\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  buf_info, max_access);\n\n\t\tif (!err && value_regno >= 0 && (rdonly_mem || t == BPF_READ))\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -98,7 +98,7 @@\n \t\t\treturn -EACCES;\n \t\t}\n \n-\t\terr = check_ctx_reg(env, reg, regno);\n+\t\terr = check_ptr_off_reg(env, reg, regno);\n \t\tif (err < 0)\n \t\t\treturn err;\n ",
        "function_modified_lines": {
            "added": [
                "\t\terr = check_ptr_off_reg(env, reg, regno);"
            ],
            "deleted": [
                "\t\terr = check_ctx_reg(env, reg, regno);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "An out-of-bounds (OOB) memory access flaw was found in the Linux kernel's eBPF due to an Improper Input Validation. This flaw allows a local attacker with a special privilege to crash the system or leak internal information.",
        "id": 3153
    },
    {
        "cve_id": "CVE-2013-1860",
        "code_before_change": "static void wdm_in_callback(struct urb *urb)\n{\n\tstruct wdm_device *desc = urb->context;\n\tint status = urb->status;\n\n\tspin_lock(&desc->iuspin);\n\tclear_bit(WDM_RESPONDING, &desc->flags);\n\n\tif (status) {\n\t\tswitch (status) {\n\t\tcase -ENOENT:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ENOENT\");\n\t\t\tgoto skip_error;\n\t\tcase -ECONNRESET:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ECONNRESET\");\n\t\t\tgoto skip_error;\n\t\tcase -ESHUTDOWN:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ESHUTDOWN\");\n\t\t\tgoto skip_error;\n\t\tcase -EPIPE:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -EPIPE\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"Unexpected error %d\\n\", status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdesc->rerr = status;\n\tdesc->reslength = urb->actual_length;\n\tmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);\n\tdesc->length += desc->reslength;\nskip_error:\n\twake_up(&desc->wait);\n\n\tset_bit(WDM_READ, &desc->flags);\n\tspin_unlock(&desc->iuspin);\n}",
        "code_after_change": "static void wdm_in_callback(struct urb *urb)\n{\n\tstruct wdm_device *desc = urb->context;\n\tint status = urb->status;\n\tint length = urb->actual_length;\n\n\tspin_lock(&desc->iuspin);\n\tclear_bit(WDM_RESPONDING, &desc->flags);\n\n\tif (status) {\n\t\tswitch (status) {\n\t\tcase -ENOENT:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ENOENT\");\n\t\t\tgoto skip_error;\n\t\tcase -ECONNRESET:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ECONNRESET\");\n\t\t\tgoto skip_error;\n\t\tcase -ESHUTDOWN:\n\t\t\tdev_dbg(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -ESHUTDOWN\");\n\t\t\tgoto skip_error;\n\t\tcase -EPIPE:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"nonzero urb status received: -EPIPE\\n\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(&desc->intf->dev,\n\t\t\t\t\"Unexpected error %d\\n\", status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tdesc->rerr = status;\n\tif (length + desc->length > desc->wMaxCommand) {\n\t\t/* The buffer would overflow */\n\t\tset_bit(WDM_OVERFLOW, &desc->flags);\n\t} else {\n\t\t/* we may already be in overflow */\n\t\tif (!test_bit(WDM_OVERFLOW, &desc->flags)) {\n\t\t\tmemmove(desc->ubuf + desc->length, desc->inbuf, length);\n\t\t\tdesc->length += length;\n\t\t\tdesc->reslength = length;\n\t\t}\n\t}\nskip_error:\n\twake_up(&desc->wait);\n\n\tset_bit(WDM_READ, &desc->flags);\n\tspin_unlock(&desc->iuspin);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,7 @@\n {\n \tstruct wdm_device *desc = urb->context;\n \tint status = urb->status;\n+\tint length = urb->actual_length;\n \n \tspin_lock(&desc->iuspin);\n \tclear_bit(WDM_RESPONDING, &desc->flags);\n@@ -32,9 +33,17 @@\n \t}\n \n \tdesc->rerr = status;\n-\tdesc->reslength = urb->actual_length;\n-\tmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);\n-\tdesc->length += desc->reslength;\n+\tif (length + desc->length > desc->wMaxCommand) {\n+\t\t/* The buffer would overflow */\n+\t\tset_bit(WDM_OVERFLOW, &desc->flags);\n+\t} else {\n+\t\t/* we may already be in overflow */\n+\t\tif (!test_bit(WDM_OVERFLOW, &desc->flags)) {\n+\t\t\tmemmove(desc->ubuf + desc->length, desc->inbuf, length);\n+\t\t\tdesc->length += length;\n+\t\t\tdesc->reslength = length;\n+\t\t}\n+\t}\n skip_error:\n \twake_up(&desc->wait);\n ",
        "function_modified_lines": {
            "added": [
                "\tint length = urb->actual_length;",
                "\tif (length + desc->length > desc->wMaxCommand) {",
                "\t\t/* The buffer would overflow */",
                "\t\tset_bit(WDM_OVERFLOW, &desc->flags);",
                "\t} else {",
                "\t\t/* we may already be in overflow */",
                "\t\tif (!test_bit(WDM_OVERFLOW, &desc->flags)) {",
                "\t\t\tmemmove(desc->ubuf + desc->length, desc->inbuf, length);",
                "\t\t\tdesc->length += length;",
                "\t\t\tdesc->reslength = length;",
                "\t\t}",
                "\t}"
            ],
            "deleted": [
                "\tdesc->reslength = urb->actual_length;",
                "\tmemmove(desc->ubuf + desc->length, desc->inbuf, desc->reslength);",
                "\tdesc->length += desc->reslength;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the wdm_in_callback function in drivers/usb/class/cdc-wdm.c in the Linux kernel before 3.8.4 allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted cdc-wdm USB device.",
        "id": 203
    },
    {
        "cve_id": "CVE-2013-2894",
        "code_before_change": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\n\tstruct device *dev = &hdev->dev;\n\tstruct tpkbd_data_pointer *data_pointer;\n\tsize_t name_sz = strlen(dev_name(dev)) + 16;\n\tchar *name_mute, *name_micmute;\n\tint ret;\n\n\tif (sysfs_create_group(&hdev->dev.kobj,\n\t\t\t\t&tpkbd_attr_group_pointer)) {\n\t\thid_warn(hdev, \"Could not create sysfs group\\n\");\n\t}\n\n\tdata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\n\tif (data_pointer == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t// set same default values as windows driver\n\tdata_pointer->sensitivity = 0xa0;\n\tdata_pointer->press_speed = 0x38;\n\n\tname_mute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_mute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\n\n\tname_micmute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_micmute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err2;\n\t}\n\tsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\n\n\thid_set_drvdata(hdev, data_pointer);\n\n\tdata_pointer->led_mute.name = name_mute;\n\tdata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_mute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_mute);\n\n\tdata_pointer->led_micmute.name = name_micmute;\n\tdata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_micmute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_micmute);\n\n\ttpkbd_features_set(hdev);\n\n\treturn 0;\n\nerr2:\n\tkfree(name_mute);\nerr:\n\tkfree(data_pointer);\n\treturn ret;\n}",
        "code_after_change": "static int tpkbd_probe_tp(struct hid_device *hdev)\n{\n\tstruct device *dev = &hdev->dev;\n\tstruct tpkbd_data_pointer *data_pointer;\n\tsize_t name_sz = strlen(dev_name(dev)) + 16;\n\tchar *name_mute, *name_micmute;\n\tint i, ret;\n\n\t/* Validate required reports. */\n\tfor (i = 0; i < 4; i++) {\n\t\tif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))\n\t\t\treturn -ENODEV;\n\t}\n\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))\n\t\treturn -ENODEV;\n\n\tif (sysfs_create_group(&hdev->dev.kobj,\n\t\t\t\t&tpkbd_attr_group_pointer)) {\n\t\thid_warn(hdev, \"Could not create sysfs group\\n\");\n\t}\n\n\tdata_pointer = kzalloc(sizeof(struct tpkbd_data_pointer), GFP_KERNEL);\n\tif (data_pointer == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for driver data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t// set same default values as windows driver\n\tdata_pointer->sensitivity = 0xa0;\n\tdata_pointer->press_speed = 0x38;\n\n\tname_mute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_mute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tsnprintf(name_mute, name_sz, \"%s:amber:mute\", dev_name(dev));\n\n\tname_micmute = kzalloc(name_sz, GFP_KERNEL);\n\tif (name_micmute == NULL) {\n\t\thid_err(hdev, \"Could not allocate memory for led data\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err2;\n\t}\n\tsnprintf(name_micmute, name_sz, \"%s:amber:micmute\", dev_name(dev));\n\n\thid_set_drvdata(hdev, data_pointer);\n\n\tdata_pointer->led_mute.name = name_mute;\n\tdata_pointer->led_mute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_mute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_mute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_mute);\n\n\tdata_pointer->led_micmute.name = name_micmute;\n\tdata_pointer->led_micmute.brightness_get = tpkbd_led_brightness_get;\n\tdata_pointer->led_micmute.brightness_set = tpkbd_led_brightness_set;\n\tdata_pointer->led_micmute.dev = dev;\n\tled_classdev_register(dev, &data_pointer->led_micmute);\n\n\ttpkbd_features_set(hdev);\n\n\treturn 0;\n\nerr2:\n\tkfree(name_mute);\nerr:\n\tkfree(data_pointer);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,15 @@\n \tstruct tpkbd_data_pointer *data_pointer;\n \tsize_t name_sz = strlen(dev_name(dev)) + 16;\n \tchar *name_mute, *name_micmute;\n-\tint ret;\n+\tint i, ret;\n+\n+\t/* Validate required reports. */\n+\tfor (i = 0; i < 4; i++) {\n+\t\tif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))\n+\t\t\treturn -ENODEV;\n+\t}\n+\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))\n+\t\treturn -ENODEV;\n \n \tif (sysfs_create_group(&hdev->dev.kobj,\n \t\t\t\t&tpkbd_attr_group_pointer)) {",
        "function_modified_lines": {
            "added": [
                "\tint i, ret;",
                "",
                "\t/* Validate required reports. */",
                "\tfor (i = 0; i < 4; i++) {",
                "\t\tif (!hid_validate_values(hdev, HID_FEATURE_REPORT, 4, i, 1))",
                "\t\t\treturn -ENODEV;",
                "\t}",
                "\tif (!hid_validate_values(hdev, HID_OUTPUT_REPORT, 3, 0, 2))",
                "\t\treturn -ENODEV;"
            ],
            "deleted": [
                "\tint ret;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/hid/hid-lenovo-tpkbd.c in the Human Interface Device (HID) subsystem in the Linux kernel through 3.11, when CONFIG_HID_LENOVO_TPKBD is enabled, allows physically proximate attackers to cause a denial of service (heap-based out-of-bounds write) via a crafted device.",
        "id": 252
    },
    {
        "cve_id": "CVE-2014-9728",
        "code_before_change": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tstruct kernel_lb_addr *iloc = &iinfo->i_location;\n\tunsigned int link_count;\n\tunsigned int indirections = 0;\n\tint ret = -EIO;\n\nreread:\n\tif (iloc->logicalBlockNum >=\n\t    sbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\n\t\tudf_debug(\"block=%d, partition=%d out of range\\n\",\n\t\t\t  iloc->logicalBlockNum, iloc->partitionReferenceNum);\n\t\treturn -EIO;\n\t}\n\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\treturn -EIO;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tgoto out;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength) {\n\t\t\t\tbrelse(ibh);\n\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n\t\t\t\t       sizeof(struct kernel_lb_addr));\n\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n\t\t\t\t\tudf_err(inode->i_sb,\n\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n\t\t\t\t\t\t\" (max %d supported)\\n\",\n\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tgoto reread;\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tgoto out;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn 0;\n\t}\n\n\tret = -EIO;\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count) {\n\t\tif (!hidden_inode) {\n\t\t\tret = -ESTALE;\n\t\t\tgoto out;\n\t\t}\n\t\tlink_count = 1;\n\t}\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\tinode->i_generation = iinfo->i_unique;\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tgoto out;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tbrelse(bh);\n\treturn ret;\n}",
        "code_after_change": "static int udf_read_inode(struct inode *inode, bool hidden_inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tstruct kernel_lb_addr *iloc = &iinfo->i_location;\n\tunsigned int link_count;\n\tunsigned int indirections = 0;\n\tint ret = -EIO;\n\nreread:\n\tif (iloc->logicalBlockNum >=\n\t    sbi->s_partmaps[iloc->partitionReferenceNum].s_partition_len) {\n\t\tudf_debug(\"block=%d, partition=%d out of range\\n\",\n\t\t\t  iloc->logicalBlockNum, iloc->partitionReferenceNum);\n\t\treturn -EIO;\n\t}\n\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, iloc, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\treturn -EIO;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tgoto out;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, iloc, 1, &ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength) {\n\t\t\t\tbrelse(ibh);\n\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n\t\t\t\t       sizeof(struct kernel_lb_addr));\n\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n\t\t\t\t\tudf_err(inode->i_sb,\n\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n\t\t\t\t\t\t\" (max %d supported)\\n\",\n\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t\tbrelse(bh);\n\t\t\t\tgoto reread;\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tgoto out;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tret = udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn 0;\n\t}\n\n\tret = -EIO;\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count) {\n\t\tif (!hidden_inode) {\n\t\t\tret = -ESTALE;\n\t\t\tgoto out;\n\t\t}\n\t\tlink_count = 1;\n\t}\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\tinode->i_generation = iinfo->i_unique;\n\n\t/* Sanity checks for files in ICB so that we don't get confused later */\n\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n\t\t/*\n\t\t * For file in ICB data is stored in allocation descriptor\n\t\t * so sizes should match\n\t\t */\n\t\tif (iinfo->i_lenAlloc != inode->i_size)\n\t\t\tgoto out;\n\t\t/* File in ICB has to fit in there... */\n\t\tif (inode->i_size > inode->i_sb->s_blocksize -\n\t\t\t\t\tudf_file_entry_alloc_offset(inode))\n\t\t\tgoto out;\n\t}\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tgoto out;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tgoto out;\n\t}\n\tret = 0;\nout:\n\tbrelse(bh);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -210,6 +210,20 @@\n \t}\n \tinode->i_generation = iinfo->i_unique;\n \n+\t/* Sanity checks for files in ICB so that we don't get confused later */\n+\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n+\t\t/*\n+\t\t * For file in ICB data is stored in allocation descriptor\n+\t\t * so sizes should match\n+\t\t */\n+\t\tif (iinfo->i_lenAlloc != inode->i_size)\n+\t\t\tgoto out;\n+\t\t/* File in ICB has to fit in there... */\n+\t\tif (inode->i_size > inode->i_sb->s_blocksize -\n+\t\t\t\t\tudf_file_entry_alloc_offset(inode))\n+\t\t\tgoto out;\n+\t}\n+\n \tswitch (fe->icbTag.fileType) {\n \tcase ICBTAG_FILE_TYPE_DIRECTORY:\n \t\tinode->i_op = &udf_dir_inode_operations;",
        "function_modified_lines": {
            "added": [
                "\t/* Sanity checks for files in ICB so that we don't get confused later */",
                "\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {",
                "\t\t/*",
                "\t\t * For file in ICB data is stored in allocation descriptor",
                "\t\t * so sizes should match",
                "\t\t */",
                "\t\tif (iinfo->i_lenAlloc != inode->i_size)",
                "\t\t\tgoto out;",
                "\t\t/* File in ICB has to fit in there... */",
                "\t\tif (inode->i_size > inode->i_sb->s_blocksize -",
                "\t\t\t\t\tudf_file_entry_alloc_offset(inode))",
                "\t\t\tgoto out;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not validate certain lengths, which allows local users to cause a denial of service (buffer over-read and system crash) via a crafted filesystem image, related to fs/udf/inode.c and fs/udf/symlink.c.",
        "id": 693
    },
    {
        "cve_id": "CVE-2009-2692",
        "code_before_change": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn sock->ops->sendpage(sock, page, offset, size, flags);\n}",
        "code_after_change": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn kernel_sendpage(sock, page, offset, size, flags);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,5 +10,5 @@\n \tif (more)\n \t\tflags |= MSG_MORE;\n \n-\treturn sock->ops->sendpage(sock, page, offset, size, flags);\n+\treturn kernel_sendpage(sock, page, offset, size, flags);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn kernel_sendpage(sock, page, offset, size, flags);"
            ],
            "deleted": [
                "\treturn sock->ops->sendpage(sock, page, offset, size, flags);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Linux kernel 2.6.0 through 2.6.30.4, and 2.4.4 through 2.4.37.4, does not initialize all function pointers for socket operations in proto_ops structures, which allows local users to trigger a NULL pointer dereference and gain privileges by using mmap to map page zero, placing arbitrary code on this page, and then invoking an unavailable operation, as demonstrated by the sendpage operation (sock_sendpage function) on a PF_PPPOX socket.",
        "id": 10
    },
    {
        "cve_id": "CVE-2012-3364",
        "code_before_change": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfcb_poll->sensb_res_len = *data++;\n\n\tpr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\n\n\tmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\n\tdata += nfcb_poll->sensb_res_len;\n\n\treturn data;\n}",
        "code_after_change": "static __u8 *nci_extract_rf_params_nfcb_passive_poll(struct nci_dev *ndev,\n\t\t\tstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n\t\t\t\t\t\t     __u8 *data)\n{\n\tnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);\n\n\tpr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\n\n\tmemcpy(nfcb_poll->sensb_res, data, nfcb_poll->sensb_res_len);\n\tdata += nfcb_poll->sensb_res_len;\n\n\treturn data;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\tstruct rf_tech_specific_params_nfcb_poll *nfcb_poll,\n \t\t\t\t\t\t     __u8 *data)\n {\n-\tnfcb_poll->sensb_res_len = *data++;\n+\tnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);\n \n \tpr_debug(\"sensb_res_len %d\\n\", nfcb_poll->sensb_res_len);\n ",
        "function_modified_lines": {
            "added": [
                "\tnfcb_poll->sensb_res_len = min_t(__u8, *data++, NFC_SENSB_RES_MAXSIZE);"
            ],
            "deleted": [
                "\tnfcb_poll->sensb_res_len = *data++;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple stack-based buffer overflows in the Near Field Communication Controller Interface (NCI) in the Linux kernel before 3.4.5 allow remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via incoming frames with crafted length fields.",
        "id": 57
    },
    {
        "cve_id": "CVE-2014-0205",
        "code_before_change": "static void unqueue_me_pi(struct futex_q *q)\n{\n\tWARN_ON(plist_node_empty(&q->list));\n\tplist_del(&q->list, &q->list.plist);\n\n\tBUG_ON(!q->pi_state);\n\tfree_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n\n\tspin_unlock(q->lock_ptr);\n\n\tdrop_futex_key_refs(&q->key);\n}",
        "code_after_change": "static void unqueue_me_pi(struct futex_q *q)\n{\n\tWARN_ON(plist_node_empty(&q->list));\n\tplist_del(&q->list, &q->list.plist);\n\n\tBUG_ON(!q->pi_state);\n\tfree_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n\n\tspin_unlock(q->lock_ptr);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,4 @@\n \tq->pi_state = NULL;\n \n \tspin_unlock(q->lock_ptr);\n-\n-\tdrop_futex_key_refs(&q->key);\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "",
                "\tdrop_futex_key_refs(&q->key);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The futex_wait function in kernel/futex.c in the Linux kernel before 2.6.37 does not properly maintain a certain reference count during requeue operations, which allows local users to cause a denial of service (use-after-free and system crash) or possibly gain privileges via a crafted application that triggers a zero count.",
        "id": 468
    },
    {
        "cve_id": "CVE-2013-4312",
        "code_before_change": "void unix_notinflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tspin_lock(&unix_gc_lock);\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t\tspin_unlock(&unix_gc_lock);\n\t}\n}",
        "code_after_change": "void unix_notinflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t}\n\tfp->f_cred->user->unix_inflight--;\n\tspin_unlock(&unix_gc_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,15 +2,17 @@\n {\n \tstruct sock *s = unix_get_socket(fp);\n \n+\tspin_lock(&unix_gc_lock);\n+\n \tif (s) {\n \t\tstruct unix_sock *u = unix_sk(s);\n \n-\t\tspin_lock(&unix_gc_lock);\n \t\tBUG_ON(list_empty(&u->link));\n \n \t\tif (atomic_long_dec_and_test(&u->inflight))\n \t\t\tlist_del_init(&u->link);\n \t\tunix_tot_inflight--;\n-\t\tspin_unlock(&unix_gc_lock);\n \t}\n+\tfp->f_cred->user->unix_inflight--;\n+\tspin_unlock(&unix_gc_lock);\n }",
        "function_modified_lines": {
            "added": [
                "\tspin_lock(&unix_gc_lock);",
                "",
                "\tfp->f_cred->user->unix_inflight--;",
                "\tspin_unlock(&unix_gc_lock);"
            ],
            "deleted": [
                "\t\tspin_lock(&unix_gc_lock);",
                "\t\tspin_unlock(&unix_gc_lock);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The Linux kernel before 4.4.1 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by sending each descriptor over a UNIX socket before closing it, related to net/unix/af_unix.c and net/unix/garbage.c.",
        "id": 295
    },
    {
        "cve_id": "CVE-2013-1773",
        "code_before_change": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\n\tstruct hv_kvp_msg  *kvp_msg;\n\tstruct hv_kvp_msg_enumerate  *kvp_data;\n\tchar\t*key_name;\n\tstruct icmsg_hdr *icmsghdrp;\n\tint\tkeylen, valuelen;\n\tu32\tbuf_len;\n\tstruct vmbus_channel *channel;\n\tu64\treq_id;\n\n\t/*\n\t * If a transaction is not active; log and return.\n\t */\n\n\tif (!kvp_transaction.active) {\n\t\t/*\n\t\t * This is a spurious call!\n\t\t */\n\t\tpr_warn(\"KVP: Transaction not active\\n\");\n\t\treturn;\n\t}\n\t/*\n\t * Copy the global state for completing the transaction. Note that\n\t * only one transaction can be active at a time.\n\t */\n\n\tbuf_len = kvp_transaction.recv_len;\n\tchannel = kvp_transaction.recv_channel;\n\treq_id = kvp_transaction.recv_req_id;\n\n\tkvp_transaction.active = false;\n\n\tif (channel->onchannel_callback == NULL)\n\t\t/*\n\t\t * We have raced with util driver being unloaded;\n\t\t * silently return.\n\t\t */\n\t\treturn;\n\n\ticmsghdrp = (struct icmsg_hdr *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr)];\n\tkvp_msg = (struct hv_kvp_msg *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr) +\n\t\t\tsizeof(struct icmsg_hdr)];\n\tkvp_data = &kvp_msg->kvp_data;\n\tkey_name = key;\n\n\t/*\n\t * If the error parameter is set, terminate the host's enumeration.\n\t */\n\tif (error) {\n\t\t/*\n\t\t * We don't support this index or the we have timedout;\n\t\t * terminate the host-side iteration by returning an error.\n\t\t */\n\t\ticmsghdrp->status = HV_E_FAIL;\n\t\tgoto response_done;\n\t}\n\n\t/*\n\t * The windows host expects the key/value pair to be encoded\n\t * in utf16.\n\t */\n\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name),\n\t\t\t\t(wchar_t *)kvp_data->data.key);\n\tkvp_data->data.key_size = 2*(keylen + 1); /* utf16 encoding */\n\tvaluelen = utf8s_to_utf16s(value, strlen(value),\n\t\t\t\t(wchar_t *)kvp_data->data.value);\n\tkvp_data->data.value_size = 2*(valuelen + 1); /* utf16 encoding */\n\n\tkvp_data->data.value_type = REG_SZ; /* all our values are strings */\n\ticmsghdrp->status = HV_S_OK;\n\nresponse_done:\n\ticmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\n\n\tvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\n\t\t\t\tVM_PKT_DATA_INBAND, 0);\n\n}",
        "code_after_change": "static void\nkvp_respond_to_host(char *key, char *value, int error)\n{\n\tstruct hv_kvp_msg  *kvp_msg;\n\tstruct hv_kvp_msg_enumerate  *kvp_data;\n\tchar\t*key_name;\n\tstruct icmsg_hdr *icmsghdrp;\n\tint\tkeylen, valuelen;\n\tu32\tbuf_len;\n\tstruct vmbus_channel *channel;\n\tu64\treq_id;\n\n\t/*\n\t * If a transaction is not active; log and return.\n\t */\n\n\tif (!kvp_transaction.active) {\n\t\t/*\n\t\t * This is a spurious call!\n\t\t */\n\t\tpr_warn(\"KVP: Transaction not active\\n\");\n\t\treturn;\n\t}\n\t/*\n\t * Copy the global state for completing the transaction. Note that\n\t * only one transaction can be active at a time.\n\t */\n\n\tbuf_len = kvp_transaction.recv_len;\n\tchannel = kvp_transaction.recv_channel;\n\treq_id = kvp_transaction.recv_req_id;\n\n\tkvp_transaction.active = false;\n\n\tif (channel->onchannel_callback == NULL)\n\t\t/*\n\t\t * We have raced with util driver being unloaded;\n\t\t * silently return.\n\t\t */\n\t\treturn;\n\n\ticmsghdrp = (struct icmsg_hdr *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr)];\n\tkvp_msg = (struct hv_kvp_msg *)\n\t\t\t&recv_buffer[sizeof(struct vmbuspipe_hdr) +\n\t\t\tsizeof(struct icmsg_hdr)];\n\tkvp_data = &kvp_msg->kvp_data;\n\tkey_name = key;\n\n\t/*\n\t * If the error parameter is set, terminate the host's enumeration.\n\t */\n\tif (error) {\n\t\t/*\n\t\t * We don't support this index or the we have timedout;\n\t\t * terminate the host-side iteration by returning an error.\n\t\t */\n\t\ticmsghdrp->status = HV_E_FAIL;\n\t\tgoto response_done;\n\t}\n\n\t/*\n\t * The windows host expects the key/value pair to be encoded\n\t * in utf16.\n\t */\n\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,\n\t\t\t\t(wchar_t *) kvp_data->data.key,\n\t\t\t\tHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);\n\tkvp_data->data.key_size = 2*(keylen + 1); /* utf16 encoding */\n\tvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,\n\t\t\t\t(wchar_t *) kvp_data->data.value,\n\t\t\t\tHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);\n\tkvp_data->data.value_size = 2*(valuelen + 1); /* utf16 encoding */\n\n\tkvp_data->data.value_type = REG_SZ; /* all our values are strings */\n\ticmsghdrp->status = HV_S_OK;\n\nresponse_done:\n\ticmsghdrp->icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;\n\n\tvmbus_sendpacket(channel, recv_buffer, buf_len, req_id,\n\t\t\t\tVM_PKT_DATA_INBAND, 0);\n\n}",
        "patch": "--- code before\n+++ code after\n@@ -63,11 +63,13 @@\n \t * The windows host expects the key/value pair to be encoded\n \t * in utf16.\n \t */\n-\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name),\n-\t\t\t\t(wchar_t *)kvp_data->data.key);\n+\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,\n+\t\t\t\t(wchar_t *) kvp_data->data.key,\n+\t\t\t\tHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);\n \tkvp_data->data.key_size = 2*(keylen + 1); /* utf16 encoding */\n-\tvaluelen = utf8s_to_utf16s(value, strlen(value),\n-\t\t\t\t(wchar_t *)kvp_data->data.value);\n+\tvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,\n+\t\t\t\t(wchar_t *) kvp_data->data.value,\n+\t\t\t\tHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);\n \tkvp_data->data.value_size = 2*(valuelen + 1); /* utf16 encoding */\n \n \tkvp_data->data.value_type = REG_SZ; /* all our values are strings */",
        "function_modified_lines": {
            "added": [
                "\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name), UTF16_HOST_ENDIAN,",
                "\t\t\t\t(wchar_t *) kvp_data->data.key,",
                "\t\t\t\tHV_KVP_EXCHANGE_MAX_KEY_SIZE / 2);",
                "\tvaluelen = utf8s_to_utf16s(value, strlen(value), UTF16_HOST_ENDIAN,",
                "\t\t\t\t(wchar_t *) kvp_data->data.value,",
                "\t\t\t\tHV_KVP_EXCHANGE_MAX_VALUE_SIZE / 2);"
            ],
            "deleted": [
                "\tkeylen = utf8s_to_utf16s(key_name, strlen(key_name),",
                "\t\t\t\t(wchar_t *)kvp_data->data.key);",
                "\tvaluelen = utf8s_to_utf16s(value, strlen(value),",
                "\t\t\t\t(wchar_t *)kvp_data->data.value);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the VFAT filesystem implementation in the Linux kernel before 3.3 allows local users to gain privileges or cause a denial of service (system crash) via a VFAT write operation on a filesystem with the utf8 mount option, which is not properly handled during UTF-8 to UTF-16 conversion.",
        "id": 181
    },
    {
        "cve_id": "CVE-2010-5332",
        "code_before_change": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\n\tstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\n\tmutex_lock(&table->mutex);\n\tfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\n\t\tif (free < 0 && !table->refs[i]) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n\t\t\t/* MAC already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\n\n\tif (table->total == table->max) {\n\t\t/* No free mac entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\n\n\terr = mlx4_set_port_mac_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
        "code_after_change": "int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *index)\n{\n\tstruct mlx4_mac_table *table = &mlx4_priv(dev)->port[port].mac_table;\n\tint i, err = 0;\n\tint free = -1;\n\n\tmlx4_dbg(dev, \"Registering MAC: 0x%llx\\n\", (unsigned long long) mac);\n\tmutex_lock(&table->mutex);\n\tfor (i = 0; i < MLX4_MAX_MAC_NUM - 1; i++) {\n\t\tif (free < 0 && !table->refs[i]) {\n\t\t\tfree = i;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (mac == (MLX4_MAC_MASK & be64_to_cpu(table->entries[i]))) {\n\t\t\t/* MAC already registered, increase refernce count */\n\t\t\t*index = i;\n\t\t\t++table->refs[i];\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (free < 0) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\n\n\tif (table->total == table->max) {\n\t\t/* No free mac entries */\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t/* Register new MAC */\n\ttable->refs[free] = 1;\n\ttable->entries[free] = cpu_to_be64(mac | MLX4_MAC_VALID);\n\n\terr = mlx4_set_port_mac_table(dev, port, table->entries);\n\tif (unlikely(err)) {\n\t\tmlx4_err(dev, \"Failed adding MAC: 0x%llx\\n\", (unsigned long long) mac);\n\t\ttable->refs[free] = 0;\n\t\ttable->entries[free] = 0;\n\t\tgoto out;\n\t}\n\n\t*index = free;\n\t++table->total;\nout:\n\tmutex_unlock(&table->mutex);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,12 @@\n \t\t\tgoto out;\n \t\t}\n \t}\n+\n+\tif (free < 0) {\n+\t\terr = -ENOMEM;\n+\t\tgoto out;\n+\t}\n+\n \tmlx4_dbg(dev, \"Free MAC index is %d\\n\", free);\n \n \tif (table->total == table->max) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (free < 0) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto out;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 2.6.37, an out of bounds array access happened in drivers/net/mlx4/port.c. When searching for a free entry in either mlx4_register_vlan() or mlx4_register_mac(), and there is no free entry, the loop terminates without updating the local variable free thus causing out of array bounds access.",
        "id": 28
    },
    {
        "cve_id": "CVE-2016-6187",
        "code_before_change": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* args points to a PAGE_SIZE buffer, AppArmor requires that\n\t * the buffer must be null terminated or have size <= PAGE_SIZE -1\n\t * so that AppArmor can null terminate them\n\t */\n\tif (args[size - 1] != '\\0') {\n\t\tif (size == PAGE_SIZE)\n\t\t\treturn -EINVAL;\n\t\targs[size] = '\\0';\n\t}\n\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\targs = value;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\treturn -EINVAL;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\treturn -EINVAL;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\treturn -EINVAL;\n\n\tif (!error)\n\t\terror = size;\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\treturn -EINVAL;\n}",
        "code_after_change": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *largs = NULL, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\t/* AppArmor requires that the buffer must be null terminated atm */\n\tif (args[size - 1] != '\\0') {\n\t\t/* null terminate */\n\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(args, value, size);\n\t\targs[size] = '\\0';\n\t}\n\n\terror = -EINVAL;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\tgoto out;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\tgoto out;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\tgoto fail;\n\n\tif (!error)\n\t\terror = size;\nout:\n\tkfree(largs);\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,34 +3,34 @@\n {\n \tstruct common_audit_data sa;\n \tstruct apparmor_audit_data aad = {0,};\n-\tchar *command, *args = value;\n+\tchar *command, *largs = NULL, *args = value;\n \tsize_t arg_size;\n \tint error;\n \n \tif (size == 0)\n \t\treturn -EINVAL;\n-\t/* args points to a PAGE_SIZE buffer, AppArmor requires that\n-\t * the buffer must be null terminated or have size <= PAGE_SIZE -1\n-\t * so that AppArmor can null terminate them\n-\t */\n-\tif (args[size - 1] != '\\0') {\n-\t\tif (size == PAGE_SIZE)\n-\t\t\treturn -EINVAL;\n-\t\targs[size] = '\\0';\n-\t}\n-\n \t/* task can only write its own attributes */\n \tif (current != task)\n \t\treturn -EACCES;\n \n-\targs = value;\n+\t/* AppArmor requires that the buffer must be null terminated atm */\n+\tif (args[size - 1] != '\\0') {\n+\t\t/* null terminate */\n+\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);\n+\t\tif (!args)\n+\t\t\treturn -ENOMEM;\n+\t\tmemcpy(args, value, size);\n+\t\targs[size] = '\\0';\n+\t}\n+\n+\terror = -EINVAL;\n \targs = strim(args);\n \tcommand = strsep(&args, \" \");\n \tif (!args)\n-\t\treturn -EINVAL;\n+\t\tgoto out;\n \targs = skip_spaces(args);\n \tif (!*args)\n-\t\treturn -EINVAL;\n+\t\tgoto out;\n \n \targ_size = size - (args - (char *) value);\n \tif (strcmp(name, \"current\") == 0) {\n@@ -56,10 +56,12 @@\n \t\t\tgoto fail;\n \t} else\n \t\t/* only support the \"current\" and \"exec\" process attributes */\n-\t\treturn -EINVAL;\n+\t\tgoto fail;\n \n \tif (!error)\n \t\terror = size;\n+out:\n+\tkfree(largs);\n \treturn error;\n \n fail:\n@@ -68,7 +70,7 @@\n \taad.profile = aa_current_profile();\n \taad.op = OP_SETPROCATTR;\n \taad.info = name;\n-\taad.error = -EINVAL;\n+\taad.error = error = -EINVAL;\n \taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n-\treturn -EINVAL;\n+\tgoto out;\n }",
        "function_modified_lines": {
            "added": [
                "\tchar *command, *largs = NULL, *args = value;",
                "\t/* AppArmor requires that the buffer must be null terminated atm */",
                "\tif (args[size - 1] != '\\0') {",
                "\t\t/* null terminate */",
                "\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);",
                "\t\tif (!args)",
                "\t\t\treturn -ENOMEM;",
                "\t\tmemcpy(args, value, size);",
                "\t\targs[size] = '\\0';",
                "\t}",
                "",
                "\terror = -EINVAL;",
                "\t\tgoto out;",
                "\t\tgoto out;",
                "\t\tgoto fail;",
                "out:",
                "\tkfree(largs);",
                "\taad.error = error = -EINVAL;",
                "\tgoto out;"
            ],
            "deleted": [
                "\tchar *command, *args = value;",
                "\t/* args points to a PAGE_SIZE buffer, AppArmor requires that",
                "\t * the buffer must be null terminated or have size <= PAGE_SIZE -1",
                "\t * so that AppArmor can null terminate them",
                "\t */",
                "\tif (args[size - 1] != '\\0') {",
                "\t\tif (size == PAGE_SIZE)",
                "\t\t\treturn -EINVAL;",
                "\t\targs[size] = '\\0';",
                "\t}",
                "",
                "\targs = value;",
                "\t\treturn -EINVAL;",
                "\t\treturn -EINVAL;",
                "\t\treturn -EINVAL;",
                "\taad.error = -EINVAL;",
                "\treturn -EINVAL;"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-119"
        ],
        "cve_description": "The apparmor_setprocattr function in security/apparmor/lsm.c in the Linux kernel before 4.6.5 does not validate the buffer size, which allows local users to gain privileges by triggering an AppArmor setprocattr hook.",
        "id": 1064
    },
    {
        "cve_id": "CVE-2022-2964",
        "code_before_change": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\n\tstruct sk_buff *ax_skb;\n\tint pkt_cnt;\n\tu32 rx_hdr;\n\tu16 hdr_off;\n\tu32 *pkt_hdr;\n\n\t/* This check is no longer done by usbnet */\n\tif (skb->len < dev->net->hard_header_len)\n\t\treturn 0;\n\n\tskb_trim(skb, skb->len - 4);\n\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n\n\tpkt_cnt = (u16)rx_hdr;\n\thdr_off = (u16)(rx_hdr >> 16);\n\tpkt_hdr = (u32 *)(skb->data + hdr_off);\n\n\twhile (pkt_cnt--) {\n\t\tu16 pkt_len;\n\n\t\tle32_to_cpus(pkt_hdr);\n\t\tpkt_len = (*pkt_hdr >> 16) & 0x1fff;\n\n\t\t/* Check CRC or runt packet */\n\t\tif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||\n\t\t    (*pkt_hdr & AX_RXHDR_DROP_ERR)) {\n\t\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n\t\t\tpkt_hdr++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (pkt_cnt == 0) {\n\t\t\tskb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(skb, 2);\n\t\t\tskb_set_tail_pointer(skb, skb->len);\n\t\t\tskb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(skb, pkt_hdr);\n\t\t\treturn 1;\n\t\t}\n\n\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n\t\tif (ax_skb) {\n\t\t\tax_skb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(ax_skb, 2);\n\t\t\tskb_set_tail_pointer(ax_skb, ax_skb->len);\n\t\t\tax_skb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(ax_skb, pkt_hdr);\n\t\t\tusbnet_skb_return(dev, ax_skb);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\n\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n\t\tpkt_hdr++;\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)\n{\n\tstruct sk_buff *ax_skb;\n\tint pkt_cnt;\n\tu32 rx_hdr;\n\tu16 hdr_off;\n\tu32 *pkt_hdr;\n\n\t/* At the end of the SKB, there's a header telling us how many packets\n\t * are bundled into this buffer and where we can find an array of\n\t * per-packet metadata (which contains elements encoded into u16).\n\t */\n\tif (skb->len < 4)\n\t\treturn 0;\n\tskb_trim(skb, skb->len - 4);\n\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n\tpkt_cnt = (u16)rx_hdr;\n\thdr_off = (u16)(rx_hdr >> 16);\n\n\tif (pkt_cnt == 0)\n\t\treturn 0;\n\n\t/* Make sure that the bounds of the metadata array are inside the SKB\n\t * (and in front of the counter at the end).\n\t */\n\tif (pkt_cnt * 2 + hdr_off > skb->len)\n\t\treturn 0;\n\tpkt_hdr = (u32 *)(skb->data + hdr_off);\n\n\t/* Packets must not overlap the metadata array */\n\tskb_trim(skb, hdr_off);\n\n\tfor (; ; pkt_cnt--, pkt_hdr++) {\n\t\tu16 pkt_len;\n\n\t\tle32_to_cpus(pkt_hdr);\n\t\tpkt_len = (*pkt_hdr >> 16) & 0x1fff;\n\n\t\tif (pkt_len > skb->len)\n\t\t\treturn 0;\n\n\t\t/* Check CRC or runt packet */\n\t\tif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&\n\t\t    pkt_len >= 2 + ETH_HLEN) {\n\t\t\tbool last = (pkt_cnt == 0);\n\n\t\t\tif (last) {\n\t\t\t\tax_skb = skb;\n\t\t\t} else {\n\t\t\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n\t\t\t\tif (!ax_skb)\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tax_skb->len = pkt_len;\n\t\t\t/* Skip IP alignment pseudo header */\n\t\t\tskb_pull(ax_skb, 2);\n\t\t\tskb_set_tail_pointer(ax_skb, ax_skb->len);\n\t\t\tax_skb->truesize = pkt_len + sizeof(struct sk_buff);\n\t\t\tax88179_rx_checksum(ax_skb, pkt_hdr);\n\n\t\t\tif (last)\n\t\t\t\treturn 1;\n\n\t\t\tusbnet_skb_return(dev, ax_skb);\n\t\t}\n\n\t\t/* Trim this packet away from the SKB */\n\t\tif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))\n\t\t\treturn 0;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,56 +6,66 @@\n \tu16 hdr_off;\n \tu32 *pkt_hdr;\n \n-\t/* This check is no longer done by usbnet */\n-\tif (skb->len < dev->net->hard_header_len)\n+\t/* At the end of the SKB, there's a header telling us how many packets\n+\t * are bundled into this buffer and where we can find an array of\n+\t * per-packet metadata (which contains elements encoded into u16).\n+\t */\n+\tif (skb->len < 4)\n+\t\treturn 0;\n+\tskb_trim(skb, skb->len - 4);\n+\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n+\tpkt_cnt = (u16)rx_hdr;\n+\thdr_off = (u16)(rx_hdr >> 16);\n+\n+\tif (pkt_cnt == 0)\n \t\treturn 0;\n \n-\tskb_trim(skb, skb->len - 4);\n-\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));\n-\n-\tpkt_cnt = (u16)rx_hdr;\n-\thdr_off = (u16)(rx_hdr >> 16);\n+\t/* Make sure that the bounds of the metadata array are inside the SKB\n+\t * (and in front of the counter at the end).\n+\t */\n+\tif (pkt_cnt * 2 + hdr_off > skb->len)\n+\t\treturn 0;\n \tpkt_hdr = (u32 *)(skb->data + hdr_off);\n \n-\twhile (pkt_cnt--) {\n+\t/* Packets must not overlap the metadata array */\n+\tskb_trim(skb, hdr_off);\n+\n+\tfor (; ; pkt_cnt--, pkt_hdr++) {\n \t\tu16 pkt_len;\n \n \t\tle32_to_cpus(pkt_hdr);\n \t\tpkt_len = (*pkt_hdr >> 16) & 0x1fff;\n \n+\t\tif (pkt_len > skb->len)\n+\t\t\treturn 0;\n+\n \t\t/* Check CRC or runt packet */\n-\t\tif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||\n-\t\t    (*pkt_hdr & AX_RXHDR_DROP_ERR)) {\n-\t\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n-\t\t\tpkt_hdr++;\n-\t\t\tcontinue;\n-\t\t}\n+\t\tif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&\n+\t\t    pkt_len >= 2 + ETH_HLEN) {\n+\t\t\tbool last = (pkt_cnt == 0);\n \n-\t\tif (pkt_cnt == 0) {\n-\t\t\tskb->len = pkt_len;\n-\t\t\t/* Skip IP alignment pseudo header */\n-\t\t\tskb_pull(skb, 2);\n-\t\t\tskb_set_tail_pointer(skb, skb->len);\n-\t\t\tskb->truesize = pkt_len + sizeof(struct sk_buff);\n-\t\t\tax88179_rx_checksum(skb, pkt_hdr);\n-\t\t\treturn 1;\n-\t\t}\n-\n-\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n-\t\tif (ax_skb) {\n+\t\t\tif (last) {\n+\t\t\t\tax_skb = skb;\n+\t\t\t} else {\n+\t\t\t\tax_skb = skb_clone(skb, GFP_ATOMIC);\n+\t\t\t\tif (!ax_skb)\n+\t\t\t\t\treturn 0;\n+\t\t\t}\n \t\t\tax_skb->len = pkt_len;\n \t\t\t/* Skip IP alignment pseudo header */\n \t\t\tskb_pull(ax_skb, 2);\n \t\t\tskb_set_tail_pointer(ax_skb, ax_skb->len);\n \t\t\tax_skb->truesize = pkt_len + sizeof(struct sk_buff);\n \t\t\tax88179_rx_checksum(ax_skb, pkt_hdr);\n+\n+\t\t\tif (last)\n+\t\t\t\treturn 1;\n+\n \t\t\tusbnet_skb_return(dev, ax_skb);\n-\t\t} else {\n-\t\t\treturn 0;\n \t\t}\n \n-\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);\n-\t\tpkt_hdr++;\n+\t\t/* Trim this packet away from the SKB */\n+\t\tif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))\n+\t\t\treturn 0;\n \t}\n-\treturn 1;\n }",
        "function_modified_lines": {
            "added": [
                "\t/* At the end of the SKB, there's a header telling us how many packets",
                "\t * are bundled into this buffer and where we can find an array of",
                "\t * per-packet metadata (which contains elements encoded into u16).",
                "\t */",
                "\tif (skb->len < 4)",
                "\t\treturn 0;",
                "\tskb_trim(skb, skb->len - 4);",
                "\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));",
                "\tpkt_cnt = (u16)rx_hdr;",
                "\thdr_off = (u16)(rx_hdr >> 16);",
                "",
                "\tif (pkt_cnt == 0)",
                "\t/* Make sure that the bounds of the metadata array are inside the SKB",
                "\t * (and in front of the counter at the end).",
                "\t */",
                "\tif (pkt_cnt * 2 + hdr_off > skb->len)",
                "\t\treturn 0;",
                "\t/* Packets must not overlap the metadata array */",
                "\tskb_trim(skb, hdr_off);",
                "",
                "\tfor (; ; pkt_cnt--, pkt_hdr++) {",
                "\t\tif (pkt_len > skb->len)",
                "\t\t\treturn 0;",
                "",
                "\t\tif (((*pkt_hdr & (AX_RXHDR_CRC_ERR | AX_RXHDR_DROP_ERR)) == 0) &&",
                "\t\t    pkt_len >= 2 + ETH_HLEN) {",
                "\t\t\tbool last = (pkt_cnt == 0);",
                "\t\t\tif (last) {",
                "\t\t\t\tax_skb = skb;",
                "\t\t\t} else {",
                "\t\t\t\tax_skb = skb_clone(skb, GFP_ATOMIC);",
                "\t\t\t\tif (!ax_skb)",
                "\t\t\t\t\treturn 0;",
                "\t\t\t}",
                "",
                "\t\t\tif (last)",
                "\t\t\t\treturn 1;",
                "",
                "\t\t/* Trim this packet away from the SKB */",
                "\t\tif (!skb_pull(skb, (pkt_len + 7) & 0xFFF8))",
                "\t\t\treturn 0;"
            ],
            "deleted": [
                "\t/* This check is no longer done by usbnet */",
                "\tif (skb->len < dev->net->hard_header_len)",
                "\tskb_trim(skb, skb->len - 4);",
                "\trx_hdr = get_unaligned_le32(skb_tail_pointer(skb));",
                "",
                "\tpkt_cnt = (u16)rx_hdr;",
                "\thdr_off = (u16)(rx_hdr >> 16);",
                "\twhile (pkt_cnt--) {",
                "\t\tif ((*pkt_hdr & AX_RXHDR_CRC_ERR) ||",
                "\t\t    (*pkt_hdr & AX_RXHDR_DROP_ERR)) {",
                "\t\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);",
                "\t\t\tpkt_hdr++;",
                "\t\t\tcontinue;",
                "\t\t}",
                "\t\tif (pkt_cnt == 0) {",
                "\t\t\tskb->len = pkt_len;",
                "\t\t\t/* Skip IP alignment pseudo header */",
                "\t\t\tskb_pull(skb, 2);",
                "\t\t\tskb_set_tail_pointer(skb, skb->len);",
                "\t\t\tskb->truesize = pkt_len + sizeof(struct sk_buff);",
                "\t\t\tax88179_rx_checksum(skb, pkt_hdr);",
                "\t\t\treturn 1;",
                "\t\t}",
                "",
                "\t\tax_skb = skb_clone(skb, GFP_ATOMIC);",
                "\t\tif (ax_skb) {",
                "\t\t} else {",
                "\t\t\treturn 0;",
                "\t\tskb_pull(skb, (pkt_len + 7) & 0xFFF8);",
                "\t\tpkt_hdr++;",
                "\treturn 1;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "A flaw was found in the Linux kernel’s driver for the ASIX AX88179_178A-based USB 2.0/3.0 Gigabit Ethernet Devices. The vulnerability contains multiple out-of-bounds reads and possible out-of-bounds writes.",
        "id": 3525
    },
    {
        "cve_id": "CVE-2014-3186",
        "code_before_change": "static int picolcd_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *raw_data, int size)\n{\n\tstruct picolcd_data *data = hid_get_drvdata(hdev);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (!data)\n\t\treturn 1;\n\n\tif (report->id == REPORT_KEY_STATE) {\n\t\tif (data->input_keys)\n\t\t\tret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n\t} else if (report->id == REPORT_IR_DATA) {\n\t\tret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n\t} else {\n\t\tspin_lock_irqsave(&data->lock, flags);\n\t\t/*\n\t\t * We let the caller of picolcd_send_and_wait() check if the\n\t\t * report we got is one of the expected ones or not.\n\t\t */\n\t\tif (data->pending) {\n\t\t\tmemcpy(data->pending->raw_data, raw_data+1, size-1);\n\t\t\tdata->pending->raw_size  = size-1;\n\t\t\tdata->pending->in_report = report;\n\t\t\tcomplete(&data->pending->ready);\n\t\t}\n\t\tspin_unlock_irqrestore(&data->lock, flags);\n\t}\n\n\tpicolcd_debug_raw_event(data, hdev, report, raw_data, size);\n\treturn 1;\n}",
        "code_after_change": "static int picolcd_raw_event(struct hid_device *hdev,\n\t\tstruct hid_report *report, u8 *raw_data, int size)\n{\n\tstruct picolcd_data *data = hid_get_drvdata(hdev);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (!data)\n\t\treturn 1;\n\n\tif (size > 64) {\n\t\thid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",\n\t\t\t\tsize);\n\t\treturn 0;\n\t}\n\n\tif (report->id == REPORT_KEY_STATE) {\n\t\tif (data->input_keys)\n\t\t\tret = picolcd_raw_keypad(data, report, raw_data+1, size-1);\n\t} else if (report->id == REPORT_IR_DATA) {\n\t\tret = picolcd_raw_cir(data, report, raw_data+1, size-1);\n\t} else {\n\t\tspin_lock_irqsave(&data->lock, flags);\n\t\t/*\n\t\t * We let the caller of picolcd_send_and_wait() check if the\n\t\t * report we got is one of the expected ones or not.\n\t\t */\n\t\tif (data->pending) {\n\t\t\tmemcpy(data->pending->raw_data, raw_data+1, size-1);\n\t\t\tdata->pending->raw_size  = size-1;\n\t\t\tdata->pending->in_report = report;\n\t\t\tcomplete(&data->pending->ready);\n\t\t}\n\t\tspin_unlock_irqrestore(&data->lock, flags);\n\t}\n\n\tpicolcd_debug_raw_event(data, hdev, report, raw_data, size);\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,12 @@\n \n \tif (!data)\n \t\treturn 1;\n+\n+\tif (size > 64) {\n+\t\thid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",\n+\t\t\t\tsize);\n+\t\treturn 0;\n+\t}\n \n \tif (report->id == REPORT_KEY_STATE) {\n \t\tif (data->input_keys)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (size > 64) {",
                "\t\thid_warn(hdev, \"invalid size value (%d) for picolcd raw event\\n\",",
                "\t\t\t\tsize);",
                "\t\treturn 0;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Buffer overflow in the picolcd_raw_event function in devices/hid/hid-picolcd_core.c in the PicoLCD HID device driver in the Linux kernel through 3.16.3, as used in Android on Nexus 7 devices, allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted device that sends a large report.",
        "id": 522
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "void register_console(struct console *newcon)\n{\n\tint i;\n\tunsigned long flags;\n\tstruct console *bcon = NULL;\n\n\t/*\n\t * before we register a new CON_BOOT console, make sure we don't\n\t * already have a valid console\n\t */\n\tif (console_drivers && newcon->flags & CON_BOOT) {\n\t\t/* find the last or real console */\n\t\tfor_each_console(bcon) {\n\t\t\tif (!(bcon->flags & CON_BOOT)) {\n\t\t\t\tprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\n\t\t\t\t\tnewcon->name, newcon->index);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (console_drivers && console_drivers->flags & CON_BOOT)\n\t\tbcon = console_drivers;\n\n\tif (preferred_console < 0 || bcon || !console_drivers)\n\t\tpreferred_console = selected_console;\n\n\tif (newcon->early_setup)\n\t\tnewcon->early_setup();\n\n\t/*\n\t *\tSee if we want to use this console driver. If we\n\t *\tdidn't select a console we take the first one\n\t *\tthat registers here.\n\t */\n\tif (preferred_console < 0) {\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = 0;\n\t\tif (newcon->setup == NULL ||\n\t\t    newcon->setup(newcon, NULL) == 0) {\n\t\t\tnewcon->flags |= CON_ENABLED;\n\t\t\tif (newcon->device) {\n\t\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\t\tpreferred_console = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tSee if this console matches one we selected on\n\t *\tthe command line.\n\t */\n\tfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\n\t\t\ti++) {\n\t\tif (strcmp(console_cmdline[i].name, newcon->name) != 0)\n\t\t\tcontinue;\n\t\tif (newcon->index >= 0 &&\n\t\t    newcon->index != console_cmdline[i].index)\n\t\t\tcontinue;\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\n\t\tif (console_cmdline[i].brl_options) {\n\t\t\tnewcon->flags |= CON_BRL;\n\t\t\tbraille_register_console(newcon,\n\t\t\t\t\tconsole_cmdline[i].index,\n\t\t\t\t\tconsole_cmdline[i].options,\n\t\t\t\t\tconsole_cmdline[i].brl_options);\n\t\t\treturn;\n\t\t}\n#endif\n\t\tif (newcon->setup &&\n\t\t    newcon->setup(newcon, console_cmdline[i].options) != 0)\n\t\t\tbreak;\n\t\tnewcon->flags |= CON_ENABLED;\n\t\tnewcon->index = console_cmdline[i].index;\n\t\tif (i == selected_console) {\n\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\tpreferred_console = selected_console;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (!(newcon->flags & CON_ENABLED))\n\t\treturn;\n\n\t/*\n\t * If we have a bootconsole, and are switching to a real console,\n\t * don't print everything out again, since when the boot console, and\n\t * the real console are the same physical device, it's annoying to\n\t * see the beginning boot messages twice\n\t */\n\tif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\n\t\tnewcon->flags &= ~CON_PRINTBUFFER;\n\n\t/*\n\t *\tPut this console in the list - keep the\n\t *\tpreferred driver at the head of the list.\n\t */\n\tconsole_lock();\n\tif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\n\t\tnewcon->next = console_drivers;\n\t\tconsole_drivers = newcon;\n\t\tif (newcon->next)\n\t\t\tnewcon->next->flags &= ~CON_CONSDEV;\n\t} else {\n\t\tnewcon->next = console_drivers->next;\n\t\tconsole_drivers->next = newcon;\n\t}\n\tif (newcon->flags & CON_PRINTBUFFER) {\n\t\t/*\n\t\t * console_unlock(); will print out the buffered messages\n\t\t * for us.\n\t\t */\n\t\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\t\tcon_start = log_start;\n\t\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\t\t/*\n\t\t * We're about to replay the log buffer.  Only do this to the\n\t\t * just-registered console to avoid excessive message spam to\n\t\t * the already-registered consoles.\n\t\t */\n\t\texclusive_console = newcon;\n\t}\n\tconsole_unlock();\n\tconsole_sysfs_notify();\n\n\t/*\n\t * By unregistering the bootconsoles after we enable the real console\n\t * we get the \"console xxx enabled\" message on all the consoles -\n\t * boot consoles, real consoles, etc - this is to ensure that end\n\t * users know there might be something in the kernel's log buffer that\n\t * went to the bootconsole (that they do not see on the real console)\n\t */\n\tif (bcon &&\n\t    ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n\t    !keep_bootcon) {\n\t\t/* we need to iterate through twice, to make sure we print\n\t\t * everything out, before we unregister the console(s)\n\t\t */\n\t\tprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\n\t\t\tnewcon->name, newcon->index);\n\t\tfor_each_console(bcon)\n\t\t\tif (bcon->flags & CON_BOOT)\n\t\t\t\tunregister_console(bcon);\n\t} else {\n\t\tprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n\t\t\t(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\n\t\t\tnewcon->name, newcon->index);\n\t}\n}",
        "code_after_change": "void register_console(struct console *newcon)\n{\n\tint i;\n\tunsigned long flags;\n\tstruct console *bcon = NULL;\n\n\t/*\n\t * before we register a new CON_BOOT console, make sure we don't\n\t * already have a valid console\n\t */\n\tif (console_drivers && newcon->flags & CON_BOOT) {\n\t\t/* find the last or real console */\n\t\tfor_each_console(bcon) {\n\t\t\tif (!(bcon->flags & CON_BOOT)) {\n\t\t\t\tprintk(KERN_INFO \"Too late to register bootconsole %s%d\\n\",\n\t\t\t\t\tnewcon->name, newcon->index);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (console_drivers && console_drivers->flags & CON_BOOT)\n\t\tbcon = console_drivers;\n\n\tif (preferred_console < 0 || bcon || !console_drivers)\n\t\tpreferred_console = selected_console;\n\n\tif (newcon->early_setup)\n\t\tnewcon->early_setup();\n\n\t/*\n\t *\tSee if we want to use this console driver. If we\n\t *\tdidn't select a console we take the first one\n\t *\tthat registers here.\n\t */\n\tif (preferred_console < 0) {\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = 0;\n\t\tif (newcon->setup == NULL ||\n\t\t    newcon->setup(newcon, NULL) == 0) {\n\t\t\tnewcon->flags |= CON_ENABLED;\n\t\t\tif (newcon->device) {\n\t\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\t\tpreferred_console = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tSee if this console matches one we selected on\n\t *\tthe command line.\n\t */\n\tfor (i = 0; i < MAX_CMDLINECONSOLES && console_cmdline[i].name[0];\n\t\t\ti++) {\n\t\tif (strcmp(console_cmdline[i].name, newcon->name) != 0)\n\t\t\tcontinue;\n\t\tif (newcon->index >= 0 &&\n\t\t    newcon->index != console_cmdline[i].index)\n\t\t\tcontinue;\n\t\tif (newcon->index < 0)\n\t\t\tnewcon->index = console_cmdline[i].index;\n#ifdef CONFIG_A11Y_BRAILLE_CONSOLE\n\t\tif (console_cmdline[i].brl_options) {\n\t\t\tnewcon->flags |= CON_BRL;\n\t\t\tbraille_register_console(newcon,\n\t\t\t\t\tconsole_cmdline[i].index,\n\t\t\t\t\tconsole_cmdline[i].options,\n\t\t\t\t\tconsole_cmdline[i].brl_options);\n\t\t\treturn;\n\t\t}\n#endif\n\t\tif (newcon->setup &&\n\t\t    newcon->setup(newcon, console_cmdline[i].options) != 0)\n\t\t\tbreak;\n\t\tnewcon->flags |= CON_ENABLED;\n\t\tnewcon->index = console_cmdline[i].index;\n\t\tif (i == selected_console) {\n\t\t\tnewcon->flags |= CON_CONSDEV;\n\t\t\tpreferred_console = selected_console;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (!(newcon->flags & CON_ENABLED))\n\t\treturn;\n\n\t/*\n\t * If we have a bootconsole, and are switching to a real console,\n\t * don't print everything out again, since when the boot console, and\n\t * the real console are the same physical device, it's annoying to\n\t * see the beginning boot messages twice\n\t */\n\tif (bcon && ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV))\n\t\tnewcon->flags &= ~CON_PRINTBUFFER;\n\n\t/*\n\t *\tPut this console in the list - keep the\n\t *\tpreferred driver at the head of the list.\n\t */\n\tconsole_lock();\n\tif ((newcon->flags & CON_CONSDEV) || console_drivers == NULL) {\n\t\tnewcon->next = console_drivers;\n\t\tconsole_drivers = newcon;\n\t\tif (newcon->next)\n\t\t\tnewcon->next->flags &= ~CON_CONSDEV;\n\t} else {\n\t\tnewcon->next = console_drivers->next;\n\t\tconsole_drivers->next = newcon;\n\t}\n\tif (newcon->flags & CON_PRINTBUFFER) {\n\t\t/*\n\t\t * console_unlock(); will print out the buffered messages\n\t\t * for us.\n\t\t */\n\t\traw_spin_lock_irqsave(&logbuf_lock, flags);\n\t\tconsole_seq = syslog_seq;\n\t\tconsole_idx = syslog_idx;\n\t\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n\t\t/*\n\t\t * We're about to replay the log buffer.  Only do this to the\n\t\t * just-registered console to avoid excessive message spam to\n\t\t * the already-registered consoles.\n\t\t */\n\t\texclusive_console = newcon;\n\t}\n\tconsole_unlock();\n\tconsole_sysfs_notify();\n\n\t/*\n\t * By unregistering the bootconsoles after we enable the real console\n\t * we get the \"console xxx enabled\" message on all the consoles -\n\t * boot consoles, real consoles, etc - this is to ensure that end\n\t * users know there might be something in the kernel's log buffer that\n\t * went to the bootconsole (that they do not see on the real console)\n\t */\n\tif (bcon &&\n\t    ((newcon->flags & (CON_CONSDEV | CON_BOOT)) == CON_CONSDEV) &&\n\t    !keep_bootcon) {\n\t\t/* we need to iterate through twice, to make sure we print\n\t\t * everything out, before we unregister the console(s)\n\t\t */\n\t\tprintk(KERN_INFO \"console [%s%d] enabled, bootconsole disabled\\n\",\n\t\t\tnewcon->name, newcon->index);\n\t\tfor_each_console(bcon)\n\t\t\tif (bcon->flags & CON_BOOT)\n\t\t\t\tunregister_console(bcon);\n\t} else {\n\t\tprintk(KERN_INFO \"%sconsole [%s%d] enabled\\n\",\n\t\t\t(newcon->flags & CON_BOOT) ? \"boot\" : \"\" ,\n\t\t\tnewcon->name, newcon->index);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -113,7 +113,8 @@\n \t\t * for us.\n \t\t */\n \t\traw_spin_lock_irqsave(&logbuf_lock, flags);\n-\t\tcon_start = log_start;\n+\t\tconsole_seq = syslog_seq;\n+\t\tconsole_idx = syslog_idx;\n \t\traw_spin_unlock_irqrestore(&logbuf_lock, flags);\n \t\t/*\n \t\t * We're about to replay the log buffer.  Only do this to the",
        "function_modified_lines": {
            "added": [
                "\t\tconsole_seq = syslog_seq;",
                "\t\tconsole_idx = syslog_idx;"
            ],
            "deleted": [
                "\t\tcon_start = log_start;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 179
    },
    {
        "cve_id": "CVE-2016-9793",
        "code_before_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_setbindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_REUSEPORT:\n\t\tsk->sk_reuseport = valbool;\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check_tx = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) ||\n\t\t    ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (val & SOF_TIMESTAMPING_OPT_ID &&\n\t\t    !(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\n\t\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\t\tif ((1 << sk->sk_state) &\n\t\t\t\t    (TCPF_CLOSE | TCPF_LISTEN)) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsk->sk_tskey = tcp_sk(sk)->snd_una;\n\t\t\t} else {\n\t\t\t\tsk->sk_tskey = 0;\n\t\t\t}\n\t\t}\n\t\tsk->sk_tsflags = val;\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_BPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_CBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_EBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_LOCK_FILTER:\n\t\tif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tret = sock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tcase SO_SELECT_ERR_QUEUE:\n\t\tsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\n\t\tbreak;\n\n#ifdef CONFIG_NET_RX_BUSY_POLL\n\tcase SO_BUSY_POLL:\n\t\t/* allow unprivileged users to decrease the value */\n\t\tif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse {\n\t\t\tif (val < 0)\n\t\t\t\tret = -EINVAL;\n\t\t\telse\n\t\t\t\tsk->sk_ll_usec = val;\n\t\t}\n\t\tbreak;\n#endif\n\n\tcase SO_MAX_PACING_RATE:\n\t\tsk->sk_max_pacing_rate = val;\n\t\tsk->sk_pacing_rate = min(sk->sk_pacing_rate,\n\t\t\t\t\t sk->sk_max_pacing_rate);\n\t\tbreak;\n\n\tcase SO_INCOMING_CPU:\n\t\tsk->sk_incoming_cpu = val;\n\t\tbreak;\n\n\tcase SO_CNX_ADVICE:\n\t\tif (val == 1)\n\t\t\tdst_negative_advice(sk);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "code_after_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_setbindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_REUSEPORT:\n\t\tsk->sk_reuseport = valbool;\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check_tx = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) ||\n\t\t    ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (val & SOF_TIMESTAMPING_OPT_ID &&\n\t\t    !(sk->sk_tsflags & SOF_TIMESTAMPING_OPT_ID)) {\n\t\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\t\tif ((1 << sk->sk_state) &\n\t\t\t\t    (TCPF_CLOSE | TCPF_LISTEN)) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsk->sk_tskey = tcp_sk(sk)->snd_una;\n\t\t\t} else {\n\t\t\t\tsk->sk_tskey = 0;\n\t\t\t}\n\t\t}\n\t\tsk->sk_tsflags = val;\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_BPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_CBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_ATTACH_REUSEPORT_EBPF:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(u32)) {\n\t\t\tu32 ufd;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&ufd, optval, sizeof(ufd)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_reuseport_attach_bpf(ufd, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_LOCK_FILTER:\n\t\tif (sock_flag(sk, SOCK_FILTER_LOCKED) && !valbool)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_FILTER_LOCKED, valbool);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tret = sock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tcase SO_SELECT_ERR_QUEUE:\n\t\tsock_valbool_flag(sk, SOCK_SELECT_ERR_QUEUE, valbool);\n\t\tbreak;\n\n#ifdef CONFIG_NET_RX_BUSY_POLL\n\tcase SO_BUSY_POLL:\n\t\t/* allow unprivileged users to decrease the value */\n\t\tif ((val > sk->sk_ll_usec) && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse {\n\t\t\tif (val < 0)\n\t\t\t\tret = -EINVAL;\n\t\t\telse\n\t\t\t\tsk->sk_ll_usec = val;\n\t\t}\n\t\tbreak;\n#endif\n\n\tcase SO_MAX_PACING_RATE:\n\t\tsk->sk_max_pacing_rate = val;\n\t\tsk->sk_pacing_rate = min(sk->sk_pacing_rate,\n\t\t\t\t\t sk->sk_max_pacing_rate);\n\t\tbreak;\n\n\tcase SO_INCOMING_CPU:\n\t\tsk->sk_incoming_cpu = val;\n\t\tbreak;\n\n\tcase SO_CNX_ADVICE:\n\t\tif (val == 1)\n\t\t\tdst_negative_advice(sk);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -58,7 +58,7 @@\n \t\tval = min_t(u32, val, sysctl_wmem_max);\n set_sndbuf:\n \t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n-\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n+\t\tsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);\n \t\t/* Wake up sending tasks if we upped the value. */\n \t\tsk->sk_write_space(sk);\n \t\tbreak;\n@@ -94,7 +94,7 @@\n \t\t * returning the value we actually used in getsockopt\n \t\t * is the most desirable behavior.\n \t\t */\n-\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n+\t\tsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);\n \t\tbreak;\n \n \tcase SO_RCVBUFFORCE:",
        "function_modified_lines": {
            "added": [
                "\t\tsk->sk_sndbuf = max_t(int, val * 2, SOCK_MIN_SNDBUF);",
                "\t\tsk->sk_rcvbuf = max_t(int, val * 2, SOCK_MIN_RCVBUF);"
            ],
            "deleted": [
                "\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);",
                "\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The sock_setsockopt function in net/core/sock.c in the Linux kernel before 4.8.14 mishandles negative values of sk_sndbuf and sk_rcvbuf, which allows local users to cause a denial of service (memory corruption and system crash) or possibly have unspecified other impact by leveraging the CAP_NET_ADMIN capability for a crafted setsockopt system call with the (1) SO_SNDBUFFORCE or (2) SO_RCVBUFFORCE option.",
        "id": 1167
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static inline int\nget_chainname_rulenum(const struct ipt_entry *s, const struct ipt_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ipt_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (s->target_offset == sizeof(struct ipt_entry) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t   t->verdict < 0 &&\n\t\t   unconditional(&s->ip)) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
        "code_after_change": "static inline int\nget_chainname_rulenum(const struct ipt_entry *s, const struct ipt_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ipt_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t   t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,11 +12,10 @@\n \t} else if (s == e) {\n \t\t(*rulenum)++;\n \n-\t\tif (s->target_offset == sizeof(struct ipt_entry) &&\n+\t\tif (unconditional(s) &&\n \t\t    strcmp(t->target.u.kernel.target->name,\n \t\t\t   XT_STANDARD_TARGET) == 0 &&\n-\t\t   t->verdict < 0 &&\n-\t\t   unconditional(&s->ip)) {\n+\t\t   t->verdict < 0) {\n \t\t\t/* Tail of chains: STANDARD target (return/policy) */\n \t\t\t*comment = *chainname == hookname\n \t\t\t\t? comments[NF_IP_TRACE_COMMENT_POLICY]",
        "function_modified_lines": {
            "added": [
                "\t\tif (unconditional(s) &&",
                "\t\t   t->verdict < 0) {"
            ],
            "deleted": [
                "\t\tif (s->target_offset == sizeof(struct ipt_entry) &&",
                "\t\t   t->verdict < 0 &&",
                "\t\t   unconditional(&s->ip)) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 966
    },
    {
        "cve_id": "CVE-2017-8063",
        "code_before_change": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\n\t\t\t  u8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\n\tstruct cxusb_state *st = d->priv;\n\tint ret, wo;\n\n\tif (1 + wlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c wr: len=%d is too big!\\n\", wlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\two = (rbuf == NULL || rlen == 0); /* write-only */\n\n\tmutex_lock(&d->data_mutex);\n\tst->data[0] = cmd;\n\tmemcpy(&st->data[1], wbuf, wlen);\n\tif (wo)\n\t\tret = dvb_usb_generic_write(d, st->data, 1 + wlen);\n\telse\n\t\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen,\n\t\t\t\t\t rbuf, rlen, 0);\n\n\tmutex_unlock(&d->data_mutex);\n\treturn ret;\n}",
        "code_after_change": "static int cxusb_ctrl_msg(struct dvb_usb_device *d,\n\t\t\t  u8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n{\n\tstruct cxusb_state *st = d->priv;\n\tint ret;\n\n\tif (1 + wlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c wr: len=%d is too big!\\n\", wlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (rlen > MAX_XFER_SIZE) {\n\t\twarn(\"i2c rd: len=%d is too big!\\n\", rlen);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tmutex_lock(&d->data_mutex);\n\tst->data[0] = cmd;\n\tmemcpy(&st->data[1], wbuf, wlen);\n\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);\n\tif (!ret && rbuf && rlen)\n\t\tmemcpy(rbuf, st->data, rlen);\n\n\tmutex_unlock(&d->data_mutex);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,23 +2,24 @@\n \t\t\t  u8 cmd, u8 *wbuf, int wlen, u8 *rbuf, int rlen)\n {\n \tstruct cxusb_state *st = d->priv;\n-\tint ret, wo;\n+\tint ret;\n \n \tif (1 + wlen > MAX_XFER_SIZE) {\n \t\twarn(\"i2c wr: len=%d is too big!\\n\", wlen);\n \t\treturn -EOPNOTSUPP;\n \t}\n \n-\two = (rbuf == NULL || rlen == 0); /* write-only */\n+\tif (rlen > MAX_XFER_SIZE) {\n+\t\twarn(\"i2c rd: len=%d is too big!\\n\", rlen);\n+\t\treturn -EOPNOTSUPP;\n+\t}\n \n \tmutex_lock(&d->data_mutex);\n \tst->data[0] = cmd;\n \tmemcpy(&st->data[1], wbuf, wlen);\n-\tif (wo)\n-\t\tret = dvb_usb_generic_write(d, st->data, 1 + wlen);\n-\telse\n-\t\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen,\n-\t\t\t\t\t rbuf, rlen, 0);\n+\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);\n+\tif (!ret && rbuf && rlen)\n+\t\tmemcpy(rbuf, st->data, rlen);\n \n \tmutex_unlock(&d->data_mutex);\n \treturn ret;",
        "function_modified_lines": {
            "added": [
                "\tint ret;",
                "\tif (rlen > MAX_XFER_SIZE) {",
                "\t\twarn(\"i2c rd: len=%d is too big!\\n\", rlen);",
                "\t\treturn -EOPNOTSUPP;",
                "\t}",
                "\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen, st->data, rlen, 0);",
                "\tif (!ret && rbuf && rlen)",
                "\t\tmemcpy(rbuf, st->data, rlen);"
            ],
            "deleted": [
                "\tint ret, wo;",
                "\two = (rbuf == NULL || rlen == 0); /* write-only */",
                "\tif (wo)",
                "\t\tret = dvb_usb_generic_write(d, st->data, 1 + wlen);",
                "\telse",
                "\t\tret = dvb_usb_generic_rw(d, st->data, 1 + wlen,",
                "\t\t\t\t\t rbuf, rlen, 0);"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/cxusb.c in the Linux kernel 4.9.x and 4.10.x before 4.10.12 interacts incorrectly with the CONFIG_VMAP_STACK option, which allows local users to cause a denial of service (system crash) or possibly have unspecified other impact by leveraging use of more than one virtual page for a DMA scatterlist.",
        "id": 1539
    },
    {
        "cve_id": "CVE-2018-5848",
        "code_before_change": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\n\tstatic const char *const names[] = {\n\t\t[WMI_FRAME_BEACON]\t= \"BEACON\",\n\t\t[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n\t\t[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n\t\t[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n\t\t[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n\t};\n\tint rc;\n\tu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\n\tstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);\n\n\tif (!cmd) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\tif (!ie)\n\t\tie_len = 0;\n\n\tcmd->mgmt_frm_type = type;\n\t/* BUG: FW API define ieLen as u8. Will fix FW */\n\tcmd->ie_len = cpu_to_le16(ie_len);\n\tmemcpy(cmd->ie_info, ie, ie_len);\n\trc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\n\tkfree(cmd);\nout:\n\tif (rc) {\n\t\tconst char *name = type < ARRAY_SIZE(names) ?\n\t\t\t\t   names[type] : \"??\";\n\t\twil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n\t}\n\n\treturn rc;\n}",
        "code_after_change": "int wmi_set_ie(struct wil6210_priv *wil, u8 type, u16 ie_len, const void *ie)\n{\n\tstatic const char *const names[] = {\n\t\t[WMI_FRAME_BEACON]\t= \"BEACON\",\n\t\t[WMI_FRAME_PROBE_REQ]\t= \"PROBE_REQ\",\n\t\t[WMI_FRAME_PROBE_RESP]\t= \"WMI_FRAME_PROBE_RESP\",\n\t\t[WMI_FRAME_ASSOC_REQ]\t= \"WMI_FRAME_ASSOC_REQ\",\n\t\t[WMI_FRAME_ASSOC_RESP]\t= \"WMI_FRAME_ASSOC_RESP\",\n\t};\n\tint rc;\n\tu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\n\tstruct wmi_set_appie_cmd *cmd;\n\n\tif (len < ie_len) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tcmd = kzalloc(len, GFP_KERNEL);\n\tif (!cmd) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\tif (!ie)\n\t\tie_len = 0;\n\n\tcmd->mgmt_frm_type = type;\n\t/* BUG: FW API define ieLen as u8. Will fix FW */\n\tcmd->ie_len = cpu_to_le16(ie_len);\n\tmemcpy(cmd->ie_info, ie, ie_len);\n\trc = wmi_send(wil, WMI_SET_APPIE_CMDID, cmd, len);\n\tkfree(cmd);\nout:\n\tif (rc) {\n\t\tconst char *name = type < ARRAY_SIZE(names) ?\n\t\t\t\t   names[type] : \"??\";\n\t\twil_err(wil, \"set_ie(%d %s) failed : %d\\n\", type, name, rc);\n\t}\n\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,8 +9,14 @@\n \t};\n \tint rc;\n \tu16 len = sizeof(struct wmi_set_appie_cmd) + ie_len;\n-\tstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);\n+\tstruct wmi_set_appie_cmd *cmd;\n \n+\tif (len < ie_len) {\n+\t\trc = -EINVAL;\n+\t\tgoto out;\n+\t}\n+\n+\tcmd = kzalloc(len, GFP_KERNEL);\n \tif (!cmd) {\n \t\trc = -ENOMEM;\n \t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "\tstruct wmi_set_appie_cmd *cmd;",
                "\tif (len < ie_len) {",
                "\t\trc = -EINVAL;",
                "\t\tgoto out;",
                "\t}",
                "",
                "\tcmd = kzalloc(len, GFP_KERNEL);"
            ],
            "deleted": [
                "\tstruct wmi_set_appie_cmd *cmd = kzalloc(len, GFP_KERNEL);"
            ]
        },
        "cwe": [
            "CWE-119",
            "CWE-190"
        ],
        "cve_description": "In the function wmi_set_ie(), the length validation code does not handle unsigned integer overflow properly. As a result, a large value of the 'ie_len' argument can cause a buffer overflow in all Android releases from CAF (Android for MSM, Firefox OS for MSM, QRD Android) using the Linux Kernel.",
        "id": 1839
    },
    {
        "cve_id": "CVE-2012-3364",
        "code_before_change": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\n\t\t\tstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\n\tstruct activation_params_nfca_poll_iso_dep *nfca_poll;\n\tstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\n\n\tswitch (ntf->activation_rf_tech_and_mode) {\n\tcase NCI_NFC_A_PASSIVE_POLL_MODE:\n\t\tnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\n\t\tnfca_poll->rats_res_len = *data++;\n\t\tpr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\n\t\tif (nfca_poll->rats_res_len > 0) {\n\t\t\tmemcpy(nfca_poll->rats_res,\n\t\t\t       data, nfca_poll->rats_res_len);\n\t\t}\n\t\tbreak;\n\n\tcase NCI_NFC_B_PASSIVE_POLL_MODE:\n\t\tnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\n\t\tnfcb_poll->attrib_res_len = *data++;\n\t\tpr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\n\t\tif (nfcb_poll->attrib_res_len > 0) {\n\t\t\tmemcpy(nfcb_poll->attrib_res,\n\t\t\t       data, nfcb_poll->attrib_res_len);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\n\t\t       ntf->activation_rf_tech_and_mode);\n\t\treturn NCI_STATUS_RF_PROTOCOL_ERROR;\n\t}\n\n\treturn NCI_STATUS_OK;\n}",
        "code_after_change": "static int nci_extract_activation_params_iso_dep(struct nci_dev *ndev,\n\t\t\tstruct nci_rf_intf_activated_ntf *ntf, __u8 *data)\n{\n\tstruct activation_params_nfca_poll_iso_dep *nfca_poll;\n\tstruct activation_params_nfcb_poll_iso_dep *nfcb_poll;\n\n\tswitch (ntf->activation_rf_tech_and_mode) {\n\tcase NCI_NFC_A_PASSIVE_POLL_MODE:\n\t\tnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\n\t\tnfca_poll->rats_res_len = min_t(__u8, *data++, 20);\n\t\tpr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\n\t\tif (nfca_poll->rats_res_len > 0) {\n\t\t\tmemcpy(nfca_poll->rats_res,\n\t\t\t       data, nfca_poll->rats_res_len);\n\t\t}\n\t\tbreak;\n\n\tcase NCI_NFC_B_PASSIVE_POLL_MODE:\n\t\tnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\n\t\tnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);\n\t\tpr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\n\t\tif (nfcb_poll->attrib_res_len > 0) {\n\t\t\tmemcpy(nfcb_poll->attrib_res,\n\t\t\t       data, nfcb_poll->attrib_res_len);\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(\"unsupported activation_rf_tech_and_mode 0x%x\\n\",\n\t\t       ntf->activation_rf_tech_and_mode);\n\t\treturn NCI_STATUS_RF_PROTOCOL_ERROR;\n\t}\n\n\treturn NCI_STATUS_OK;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,7 @@\n \tswitch (ntf->activation_rf_tech_and_mode) {\n \tcase NCI_NFC_A_PASSIVE_POLL_MODE:\n \t\tnfca_poll = &ntf->activation_params.nfca_poll_iso_dep;\n-\t\tnfca_poll->rats_res_len = *data++;\n+\t\tnfca_poll->rats_res_len = min_t(__u8, *data++, 20);\n \t\tpr_debug(\"rats_res_len %d\\n\", nfca_poll->rats_res_len);\n \t\tif (nfca_poll->rats_res_len > 0) {\n \t\t\tmemcpy(nfca_poll->rats_res,\n@@ -17,7 +17,7 @@\n \n \tcase NCI_NFC_B_PASSIVE_POLL_MODE:\n \t\tnfcb_poll = &ntf->activation_params.nfcb_poll_iso_dep;\n-\t\tnfcb_poll->attrib_res_len = *data++;\n+\t\tnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);\n \t\tpr_debug(\"attrib_res_len %d\\n\", nfcb_poll->attrib_res_len);\n \t\tif (nfcb_poll->attrib_res_len > 0) {\n \t\t\tmemcpy(nfcb_poll->attrib_res,",
        "function_modified_lines": {
            "added": [
                "\t\tnfca_poll->rats_res_len = min_t(__u8, *data++, 20);",
                "\t\tnfcb_poll->attrib_res_len = min_t(__u8, *data++, 50);"
            ],
            "deleted": [
                "\t\tnfca_poll->rats_res_len = *data++;",
                "\t\tnfcb_poll->attrib_res_len = *data++;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple stack-based buffer overflows in the Near Field Communication Controller Interface (NCI) in the Linux kernel before 3.4.5 allow remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via incoming frames with crafted length fields.",
        "id": 54
    },
    {
        "cve_id": "CVE-2013-6382",
        "code_before_change": "STATIC int\nxfs_compat_attrlist_by_handle(\n\tstruct file\t\t*parfilp,\n\tvoid\t\t\t__user *arg)\n{\n\tint\t\t\terror;\n\tattrlist_cursor_kern_t\t*cursor;\n\tcompat_xfs_fsop_attrlist_handlereq_t al_hreq;\n\tstruct dentry\t\t*dentry;\n\tchar\t\t\t*kbuf;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -XFS_ERROR(EPERM);\n\tif (copy_from_user(&al_hreq, arg,\n\t\t\t   sizeof(compat_xfs_fsop_attrlist_handlereq_t)))\n\t\treturn -XFS_ERROR(EFAULT);\n\tif (al_hreq.buflen > XATTR_LIST_MAX)\n\t\treturn -XFS_ERROR(EINVAL);\n\n\t/*\n\t * Reject flags, only allow namespaces.\n\t */\n\tif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\n\t\treturn -XFS_ERROR(EINVAL);\n\n\tdentry = xfs_compat_handlereq_to_dentry(parfilp, &al_hreq.hreq);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\terror = -ENOMEM;\n\tkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\n\tif (!kbuf)\n\t\tgoto out_dput;\n\n\tcursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\n\terror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\n\t\t\t\t\tal_hreq.flags, cursor);\n\tif (error)\n\t\tgoto out_kfree;\n\n\tif (copy_to_user(compat_ptr(al_hreq.buffer), kbuf, al_hreq.buflen))\n\t\terror = -EFAULT;\n\nout_kfree:\n\tkmem_free(kbuf);\nout_dput:\n\tdput(dentry);\n\treturn error;\n}",
        "code_after_change": "STATIC int\nxfs_compat_attrlist_by_handle(\n\tstruct file\t\t*parfilp,\n\tvoid\t\t\t__user *arg)\n{\n\tint\t\t\terror;\n\tattrlist_cursor_kern_t\t*cursor;\n\tcompat_xfs_fsop_attrlist_handlereq_t al_hreq;\n\tstruct dentry\t\t*dentry;\n\tchar\t\t\t*kbuf;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -XFS_ERROR(EPERM);\n\tif (copy_from_user(&al_hreq, arg,\n\t\t\t   sizeof(compat_xfs_fsop_attrlist_handlereq_t)))\n\t\treturn -XFS_ERROR(EFAULT);\n\tif (al_hreq.buflen < sizeof(struct attrlist) ||\n\t    al_hreq.buflen > XATTR_LIST_MAX)\n\t\treturn -XFS_ERROR(EINVAL);\n\n\t/*\n\t * Reject flags, only allow namespaces.\n\t */\n\tif (al_hreq.flags & ~(ATTR_ROOT | ATTR_SECURE))\n\t\treturn -XFS_ERROR(EINVAL);\n\n\tdentry = xfs_compat_handlereq_to_dentry(parfilp, &al_hreq.hreq);\n\tif (IS_ERR(dentry))\n\t\treturn PTR_ERR(dentry);\n\n\terror = -ENOMEM;\n\tkbuf = kmem_zalloc_large(al_hreq.buflen, KM_SLEEP);\n\tif (!kbuf)\n\t\tgoto out_dput;\n\n\tcursor = (attrlist_cursor_kern_t *)&al_hreq.pos;\n\terror = -xfs_attr_list(XFS_I(dentry->d_inode), kbuf, al_hreq.buflen,\n\t\t\t\t\tal_hreq.flags, cursor);\n\tif (error)\n\t\tgoto out_kfree;\n\n\tif (copy_to_user(compat_ptr(al_hreq.buffer), kbuf, al_hreq.buflen))\n\t\terror = -EFAULT;\n\nout_kfree:\n\tkmem_free(kbuf);\nout_dput:\n\tdput(dentry);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,8 @@\n \tif (copy_from_user(&al_hreq, arg,\n \t\t\t   sizeof(compat_xfs_fsop_attrlist_handlereq_t)))\n \t\treturn -XFS_ERROR(EFAULT);\n-\tif (al_hreq.buflen > XATTR_LIST_MAX)\n+\tif (al_hreq.buflen < sizeof(struct attrlist) ||\n+\t    al_hreq.buflen > XATTR_LIST_MAX)\n \t\treturn -XFS_ERROR(EINVAL);\n \n \t/*",
        "function_modified_lines": {
            "added": [
                "\tif (al_hreq.buflen < sizeof(struct attrlist) ||",
                "\t    al_hreq.buflen > XATTR_LIST_MAX)"
            ],
            "deleted": [
                "\tif (al_hreq.buflen > XATTR_LIST_MAX)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple buffer underflows in the XFS implementation in the Linux kernel through 3.12.1 allow local users to cause a denial of service (memory corruption) or possibly have unspecified other impact by leveraging the CAP_SYS_ADMIN capability for a (1) XFS_IOC_ATTRLIST_BY_HANDLE or (2) XFS_IOC_ATTRLIST_BY_HANDLE_32 ioctl call with a crafted length value, related to the xfs_attrlist_by_handle function in fs/xfs/xfs_ioctl.c and the xfs_compat_attrlist_by_handle function in fs/xfs/xfs_ioctl32.c.",
        "id": 350
    },
    {
        "cve_id": "CVE-2013-1860",
        "code_before_change": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\n\tint rv, cntr;\n\tint i = 0;\n\tstruct wdm_device *desc = file->private_data;\n\n\n\trv = mutex_lock_interruptible(&desc->rlock); /*concurrent reads */\n\tif (rv < 0)\n\t\treturn -ERESTARTSYS;\n\n\tcntr = ACCESS_ONCE(desc->length);\n\tif (cntr == 0) {\n\t\tdesc->read = 0;\nretry:\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\ti++;\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tif (!test_bit(WDM_READ, &desc->flags)) {\n\t\t\t\trv = cntr ? cntr : -EAGAIN;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\trv = 0;\n\t\t} else {\n\t\t\trv = wait_event_interruptible(desc->wait,\n\t\t\t\ttest_bit(WDM_READ, &desc->flags));\n\t\t}\n\n\t\t/* may have happened while we slept */\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_RESETTING, &desc->flags)) {\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\tusb_mark_last_busy(interface_to_usbdev(desc->intf));\n\t\tif (rv < 0) {\n\t\t\trv = -ERESTARTSYS;\n\t\t\tgoto err;\n\t\t}\n\n\t\tspin_lock_irq(&desc->iuspin);\n\n\t\tif (desc->rerr) { /* read completed, error happened */\n\t\t\tdesc->rerr = 0;\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\t/*\n\t\t * recheck whether we've lost the race\n\t\t * against the completion handler\n\t\t */\n\t\tif (!test_bit(WDM_READ, &desc->flags)) { /* lost race */\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (!desc->reslength) { /* zero length read */\n\t\t\tdev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\n\t\t\tclear_bit(WDM_READ, &desc->flags);\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tcntr = desc->length;\n\t\tspin_unlock_irq(&desc->iuspin);\n\t}\n\n\tif (cntr > count)\n\t\tcntr = count;\n\trv = copy_to_user(buffer, desc->ubuf, cntr);\n\tif (rv > 0) {\n\t\trv = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tspin_lock_irq(&desc->iuspin);\n\n\tfor (i = 0; i < desc->length - cntr; i++)\n\t\tdesc->ubuf[i] = desc->ubuf[i + cntr];\n\n\tdesc->length -= cntr;\n\t/* in case we had outstanding data */\n\tif (!desc->length)\n\t\tclear_bit(WDM_READ, &desc->flags);\n\n\tspin_unlock_irq(&desc->iuspin);\n\n\trv = cntr;\n\nerr:\n\tmutex_unlock(&desc->rlock);\n\treturn rv;\n}",
        "code_after_change": "static ssize_t wdm_read\n(struct file *file, char __user *buffer, size_t count, loff_t *ppos)\n{\n\tint rv, cntr;\n\tint i = 0;\n\tstruct wdm_device *desc = file->private_data;\n\n\n\trv = mutex_lock_interruptible(&desc->rlock); /*concurrent reads */\n\tif (rv < 0)\n\t\treturn -ERESTARTSYS;\n\n\tcntr = ACCESS_ONCE(desc->length);\n\tif (cntr == 0) {\n\t\tdesc->read = 0;\nretry:\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_OVERFLOW, &desc->flags)) {\n\t\t\tclear_bit(WDM_OVERFLOW, &desc->flags);\n\t\t\trv = -ENOBUFS;\n\t\t\tgoto err;\n\t\t}\n\t\ti++;\n\t\tif (file->f_flags & O_NONBLOCK) {\n\t\t\tif (!test_bit(WDM_READ, &desc->flags)) {\n\t\t\t\trv = cntr ? cntr : -EAGAIN;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\trv = 0;\n\t\t} else {\n\t\t\trv = wait_event_interruptible(desc->wait,\n\t\t\t\ttest_bit(WDM_READ, &desc->flags));\n\t\t}\n\n\t\t/* may have happened while we slept */\n\t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n\t\t\trv = -ENODEV;\n\t\t\tgoto err;\n\t\t}\n\t\tif (test_bit(WDM_RESETTING, &desc->flags)) {\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\tusb_mark_last_busy(interface_to_usbdev(desc->intf));\n\t\tif (rv < 0) {\n\t\t\trv = -ERESTARTSYS;\n\t\t\tgoto err;\n\t\t}\n\n\t\tspin_lock_irq(&desc->iuspin);\n\n\t\tif (desc->rerr) { /* read completed, error happened */\n\t\t\tdesc->rerr = 0;\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\trv = -EIO;\n\t\t\tgoto err;\n\t\t}\n\t\t/*\n\t\t * recheck whether we've lost the race\n\t\t * against the completion handler\n\t\t */\n\t\tif (!test_bit(WDM_READ, &desc->flags)) { /* lost race */\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\n\t\tif (!desc->reslength) { /* zero length read */\n\t\t\tdev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\n\t\t\tclear_bit(WDM_READ, &desc->flags);\n\t\t\tspin_unlock_irq(&desc->iuspin);\n\t\t\tgoto retry;\n\t\t}\n\t\tcntr = desc->length;\n\t\tspin_unlock_irq(&desc->iuspin);\n\t}\n\n\tif (cntr > count)\n\t\tcntr = count;\n\trv = copy_to_user(buffer, desc->ubuf, cntr);\n\tif (rv > 0) {\n\t\trv = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tspin_lock_irq(&desc->iuspin);\n\n\tfor (i = 0; i < desc->length - cntr; i++)\n\t\tdesc->ubuf[i] = desc->ubuf[i + cntr];\n\n\tdesc->length -= cntr;\n\t/* in case we had outstanding data */\n\tif (!desc->length)\n\t\tclear_bit(WDM_READ, &desc->flags);\n\n\tspin_unlock_irq(&desc->iuspin);\n\n\trv = cntr;\n\nerr:\n\tmutex_unlock(&desc->rlock);\n\treturn rv;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,6 +16,11 @@\n retry:\n \t\tif (test_bit(WDM_DISCONNECTING, &desc->flags)) {\n \t\t\trv = -ENODEV;\n+\t\t\tgoto err;\n+\t\t}\n+\t\tif (test_bit(WDM_OVERFLOW, &desc->flags)) {\n+\t\t\tclear_bit(WDM_OVERFLOW, &desc->flags);\n+\t\t\trv = -ENOBUFS;\n \t\t\tgoto err;\n \t\t}\n \t\ti++;\n@@ -61,6 +66,7 @@\n \t\t\tspin_unlock_irq(&desc->iuspin);\n \t\t\tgoto retry;\n \t\t}\n+\n \t\tif (!desc->reslength) { /* zero length read */\n \t\t\tdev_dbg(&desc->intf->dev, \"%s: zero length - clearing WDM_READ\\n\", __func__);\n \t\t\tclear_bit(WDM_READ, &desc->flags);",
        "function_modified_lines": {
            "added": [
                "\t\t\tgoto err;",
                "\t\t}",
                "\t\tif (test_bit(WDM_OVERFLOW, &desc->flags)) {",
                "\t\t\tclear_bit(WDM_OVERFLOW, &desc->flags);",
                "\t\t\trv = -ENOBUFS;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Heap-based buffer overflow in the wdm_in_callback function in drivers/usb/class/cdc-wdm.c in the Linux kernel before 3.8.4 allows physically proximate attackers to cause a denial of service (system crash) or possibly execute arbitrary code via a crafted cdc-wdm USB device.",
        "id": 201
    },
    {
        "cve_id": "CVE-2016-3134",
        "code_before_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ipt_entry *e = (struct ipt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ipt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((e->target_offset == sizeof(struct ipt_entry) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0 && unconditional(&e->ip)) ||\n\t\t\t    visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ipt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "code_after_change": "static int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ipt_entry *e = (struct ipt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ipt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ipt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t}\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -29,11 +29,10 @@\n \t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n \n \t\t\t/* Unconditional return/END. */\n-\t\t\tif ((e->target_offset == sizeof(struct ipt_entry) &&\n+\t\t\tif ((unconditional(e) &&\n \t\t\t     (strcmp(t->target.u.user.name,\n \t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n-\t\t\t     t->verdict < 0 && unconditional(&e->ip)) ||\n-\t\t\t    visited) {\n+\t\t\t     t->verdict < 0) || visited) {\n \t\t\t\tunsigned int oldpos, size;\n \n \t\t\t\tif ((strcmp(t->target.u.user.name,",
        "function_modified_lines": {
            "added": [
                "\t\t\tif ((unconditional(e) &&",
                "\t\t\t     t->verdict < 0) || visited) {"
            ],
            "deleted": [
                "\t\t\tif ((e->target_offset == sizeof(struct ipt_entry) &&",
                "\t\t\t     t->verdict < 0 && unconditional(&e->ip)) ||",
                "\t\t\t    visited) {"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.5.2 does not validate certain offset fields, which allows local users to gain privileges or cause a denial of service (heap memory corruption) via an IPT_SO_SET_REPLACE setsockopt call.",
        "id": 967
    },
    {
        "cve_id": "CVE-2016-8633",
        "code_before_change": "static void fwnet_receive_broadcast(struct fw_iso_context *context,\n\t\tu32 cycle, size_t header_length, void *header, void *data)\n{\n\tstruct fwnet_device *dev;\n\tstruct fw_iso_packet packet;\n\t__be16 *hdr_ptr;\n\t__be32 *buf_ptr;\n\tint retval;\n\tu32 length;\n\tu16 source_node_id;\n\tu32 specifier_id;\n\tu32 ver;\n\tunsigned long offset;\n\tunsigned long flags;\n\n\tdev = data;\n\thdr_ptr = header;\n\tlength = be16_to_cpup(hdr_ptr);\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\toffset = dev->rcv_buffer_size * dev->broadcast_rcv_next_ptr;\n\tbuf_ptr = dev->broadcast_rcv_buffer_ptrs[dev->broadcast_rcv_next_ptr++];\n\tif (dev->broadcast_rcv_next_ptr == dev->num_broadcast_rcv_ptrs)\n\t\tdev->broadcast_rcv_next_ptr = 0;\n\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\tspecifier_id =    (be32_to_cpu(buf_ptr[0]) & 0xffff) << 8\n\t\t\t| (be32_to_cpu(buf_ptr[1]) & 0xff000000) >> 24;\n\tver = be32_to_cpu(buf_ptr[1]) & 0xffffff;\n\tsource_node_id = be32_to_cpu(buf_ptr[0]) >> 16;\n\n\tif (specifier_id == IANA_SPECIFIER_ID &&\n\t    (ver == RFC2734_SW_VERSION\n#if IS_ENABLED(CONFIG_IPV6)\n\t     || ver == RFC3146_SW_VERSION\n#endif\n\t    )) {\n\t\tbuf_ptr += 2;\n\t\tlength -= IEEE1394_GASP_HDR_SIZE;\n\t\tfwnet_incoming_packet(dev, buf_ptr, length, source_node_id,\n\t\t\t\t      context->card->generation, true);\n\t}\n\n\tpacket.payload_length = dev->rcv_buffer_size;\n\tpacket.interrupt = 1;\n\tpacket.skip = 0;\n\tpacket.tag = 3;\n\tpacket.sy = 0;\n\tpacket.header_length = IEEE1394_GASP_HDR_SIZE;\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tretval = fw_iso_context_queue(dev->broadcast_rcv_context, &packet,\n\t\t\t\t      &dev->broadcast_rcv_buffer, offset);\n\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\tif (retval >= 0)\n\t\tfw_iso_context_queue_flush(dev->broadcast_rcv_context);\n\telse\n\t\tdev_err(&dev->netdev->dev, \"requeue failed\\n\");\n}",
        "code_after_change": "static void fwnet_receive_broadcast(struct fw_iso_context *context,\n\t\tu32 cycle, size_t header_length, void *header, void *data)\n{\n\tstruct fwnet_device *dev;\n\tstruct fw_iso_packet packet;\n\t__be16 *hdr_ptr;\n\t__be32 *buf_ptr;\n\tint retval;\n\tu32 length;\n\tunsigned long offset;\n\tunsigned long flags;\n\n\tdev = data;\n\thdr_ptr = header;\n\tlength = be16_to_cpup(hdr_ptr);\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\toffset = dev->rcv_buffer_size * dev->broadcast_rcv_next_ptr;\n\tbuf_ptr = dev->broadcast_rcv_buffer_ptrs[dev->broadcast_rcv_next_ptr++];\n\tif (dev->broadcast_rcv_next_ptr == dev->num_broadcast_rcv_ptrs)\n\t\tdev->broadcast_rcv_next_ptr = 0;\n\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\tif (length > IEEE1394_GASP_HDR_SIZE &&\n\t    gasp_specifier_id(buf_ptr) == IANA_SPECIFIER_ID &&\n\t    (gasp_version(buf_ptr) == RFC2734_SW_VERSION\n#if IS_ENABLED(CONFIG_IPV6)\n\t     || gasp_version(buf_ptr) == RFC3146_SW_VERSION\n#endif\n\t    ))\n\t\tfwnet_incoming_packet(dev, buf_ptr + 2,\n\t\t\t\t      length - IEEE1394_GASP_HDR_SIZE,\n\t\t\t\t      gasp_source_id(buf_ptr),\n\t\t\t\t      context->card->generation, true);\n\n\tpacket.payload_length = dev->rcv_buffer_size;\n\tpacket.interrupt = 1;\n\tpacket.skip = 0;\n\tpacket.tag = 3;\n\tpacket.sy = 0;\n\tpacket.header_length = IEEE1394_GASP_HDR_SIZE;\n\n\tspin_lock_irqsave(&dev->lock, flags);\n\n\tretval = fw_iso_context_queue(dev->broadcast_rcv_context, &packet,\n\t\t\t\t      &dev->broadcast_rcv_buffer, offset);\n\n\tspin_unlock_irqrestore(&dev->lock, flags);\n\n\tif (retval >= 0)\n\t\tfw_iso_context_queue_flush(dev->broadcast_rcv_context);\n\telse\n\t\tdev_err(&dev->netdev->dev, \"requeue failed\\n\");\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,9 +7,6 @@\n \t__be32 *buf_ptr;\n \tint retval;\n \tu32 length;\n-\tu16 source_node_id;\n-\tu32 specifier_id;\n-\tu32 ver;\n \tunsigned long offset;\n \tunsigned long flags;\n \n@@ -26,22 +23,17 @@\n \n \tspin_unlock_irqrestore(&dev->lock, flags);\n \n-\tspecifier_id =    (be32_to_cpu(buf_ptr[0]) & 0xffff) << 8\n-\t\t\t| (be32_to_cpu(buf_ptr[1]) & 0xff000000) >> 24;\n-\tver = be32_to_cpu(buf_ptr[1]) & 0xffffff;\n-\tsource_node_id = be32_to_cpu(buf_ptr[0]) >> 16;\n-\n-\tif (specifier_id == IANA_SPECIFIER_ID &&\n-\t    (ver == RFC2734_SW_VERSION\n+\tif (length > IEEE1394_GASP_HDR_SIZE &&\n+\t    gasp_specifier_id(buf_ptr) == IANA_SPECIFIER_ID &&\n+\t    (gasp_version(buf_ptr) == RFC2734_SW_VERSION\n #if IS_ENABLED(CONFIG_IPV6)\n-\t     || ver == RFC3146_SW_VERSION\n+\t     || gasp_version(buf_ptr) == RFC3146_SW_VERSION\n #endif\n-\t    )) {\n-\t\tbuf_ptr += 2;\n-\t\tlength -= IEEE1394_GASP_HDR_SIZE;\n-\t\tfwnet_incoming_packet(dev, buf_ptr, length, source_node_id,\n+\t    ))\n+\t\tfwnet_incoming_packet(dev, buf_ptr + 2,\n+\t\t\t\t      length - IEEE1394_GASP_HDR_SIZE,\n+\t\t\t\t      gasp_source_id(buf_ptr),\n \t\t\t\t      context->card->generation, true);\n-\t}\n \n \tpacket.payload_length = dev->rcv_buffer_size;\n \tpacket.interrupt = 1;",
        "function_modified_lines": {
            "added": [
                "\tif (length > IEEE1394_GASP_HDR_SIZE &&",
                "\t    gasp_specifier_id(buf_ptr) == IANA_SPECIFIER_ID &&",
                "\t    (gasp_version(buf_ptr) == RFC2734_SW_VERSION",
                "\t     || gasp_version(buf_ptr) == RFC3146_SW_VERSION",
                "\t    ))",
                "\t\tfwnet_incoming_packet(dev, buf_ptr + 2,",
                "\t\t\t\t      length - IEEE1394_GASP_HDR_SIZE,",
                "\t\t\t\t      gasp_source_id(buf_ptr),"
            ],
            "deleted": [
                "\tu16 source_node_id;",
                "\tu32 specifier_id;",
                "\tu32 ver;",
                "\tspecifier_id =    (be32_to_cpu(buf_ptr[0]) & 0xffff) << 8",
                "\t\t\t| (be32_to_cpu(buf_ptr[1]) & 0xff000000) >> 24;",
                "\tver = be32_to_cpu(buf_ptr[1]) & 0xffffff;",
                "\tsource_node_id = be32_to_cpu(buf_ptr[0]) >> 16;",
                "",
                "\tif (specifier_id == IANA_SPECIFIER_ID &&",
                "\t    (ver == RFC2734_SW_VERSION",
                "\t     || ver == RFC3146_SW_VERSION",
                "\t    )) {",
                "\t\tbuf_ptr += 2;",
                "\t\tlength -= IEEE1394_GASP_HDR_SIZE;",
                "\t\tfwnet_incoming_packet(dev, buf_ptr, length, source_node_id,",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-119",
            "CWE-284"
        ],
        "cve_description": "drivers/firewire/net.c in the Linux kernel before 4.8.7, in certain unusual hardware configurations, allows remote attackers to execute arbitrary code via crafted fragmented packets.",
        "id": 1124
    },
    {
        "cve_id": "CVE-2017-18222",
        "code_before_change": "int hns_ppe_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\treturn ETH_PPE_STATIC_NUM;\n\treturn 0;\n}",
        "code_after_change": "int hns_ppe_get_sset_count(int stringset)\n{\n\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n\t\treturn ETH_PPE_STATIC_NUM;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n int hns_ppe_get_sset_count(int stringset)\n {\n-\tif (stringset == ETH_SS_STATS)\n+\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)\n \t\treturn ETH_PPE_STATIC_NUM;\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (stringset == ETH_SS_STATS || stringset == ETH_SS_PRIV_FLAGS)"
            ],
            "deleted": [
                "\tif (stringset == ETH_SS_STATS)"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "In the Linux kernel before 4.12, Hisilicon Network Subsystem (HNS) does not consider the ETH_SS_PRIV_FLAGS case when retrieving sset_count data, which allows local users to cause a denial of service (buffer overflow and memory corruption) or possibly have unspecified other impact, as demonstrated by incompatibility between hns_get_sset_count and ethtool_get_strings.",
        "id": 1408
    },
    {
        "cve_id": "CVE-2013-1772",
        "code_before_change": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\n\tunsigned i, j, limit, count;\n\tint do_clear = 0;\n\tchar c;\n\tint error;\n\n\terror = check_syslog_permissions(type, from_file);\n\tif (error)\n\t\tgoto out;\n\n\terror = security_syslog(type);\n\tif (error)\n\t\treturn error;\n\n\tswitch (type) {\n\tcase SYSLOG_ACTION_CLOSE:\t/* Close log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_OPEN:\t/* Open log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_READ:\t/* Read from log */\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = wait_event_interruptible(log_wait,\n\t\t\t\t\t\t\t(log_start - log_end));\n\t\tif (error)\n\t\t\tgoto out;\n\t\ti = 0;\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\twhile (!error && (log_start != log_end) && i < len) {\n\t\t\tc = LOG_BUF(log_start);\n\t\t\tlog_start++;\n\t\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\t\terror = __put_user(c,buf);\n\t\t\tbuf++;\n\t\t\ti++;\n\t\t\tcond_resched();\n\t\t\traw_spin_lock_irq(&logbuf_lock);\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tif (!error)\n\t\t\terror = i;\n\t\tbreak;\n\t/* Read/clear last kernel messages */\n\tcase SYSLOG_ACTION_READ_CLEAR:\n\t\tdo_clear = 1;\n\t\t/* FALL THRU */\n\t/* Read last kernel messages */\n\tcase SYSLOG_ACTION_READ_ALL:\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tcount = len;\n\t\tif (count > log_buf_len)\n\t\t\tcount = log_buf_len;\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\tif (count > logged_chars)\n\t\t\tcount = logged_chars;\n\t\tif (do_clear)\n\t\t\tlogged_chars = 0;\n\t\tlimit = log_end;\n\t\t/*\n\t\t * __put_user() could sleep, and while we sleep\n\t\t * printk() could overwrite the messages\n\t\t * we try to copy to user space. Therefore\n\t\t * the messages are copied in reverse. <manfreds>\n\t\t */\n\t\tfor (i = 0; i < count && !error; i++) {\n\t\t\tj = limit-1-i;\n\t\t\tif (j + log_buf_len < log_end)\n\t\t\t\tbreak;\n\t\t\tc = LOG_BUF(j);\n\t\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\t\terror = __put_user(c,&buf[count-1-i]);\n\t\t\tcond_resched();\n\t\t\traw_spin_lock_irq(&logbuf_lock);\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tif (error)\n\t\t\tbreak;\n\t\terror = i;\n\t\tif (i != count) {\n\t\t\tint offset = count-error;\n\t\t\t/* buffer overflow during copy, correct user buffer. */\n\t\t\tfor (i = 0; i < error; i++) {\n\t\t\t\tif (__get_user(c,&buf[i+offset]) ||\n\t\t\t\t    __put_user(c,&buf[i])) {\n\t\t\t\t\terror = -EFAULT;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcond_resched();\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t/* Clear ring buffer */\n\tcase SYSLOG_ACTION_CLEAR:\n\t\tlogged_chars = 0;\n\t\tbreak;\n\t/* Disable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_OFF:\n\t\tif (saved_console_loglevel == -1)\n\t\t\tsaved_console_loglevel = console_loglevel;\n\t\tconsole_loglevel = minimum_console_loglevel;\n\t\tbreak;\n\t/* Enable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_ON:\n\t\tif (saved_console_loglevel != -1) {\n\t\t\tconsole_loglevel = saved_console_loglevel;\n\t\t\tsaved_console_loglevel = -1;\n\t\t}\n\t\tbreak;\n\t/* Set level of messages printed to console */\n\tcase SYSLOG_ACTION_CONSOLE_LEVEL:\n\t\terror = -EINVAL;\n\t\tif (len < 1 || len > 8)\n\t\t\tgoto out;\n\t\tif (len < minimum_console_loglevel)\n\t\t\tlen = minimum_console_loglevel;\n\t\tconsole_loglevel = len;\n\t\t/* Implicitly re-enable logging to console */\n\t\tsaved_console_loglevel = -1;\n\t\terror = 0;\n\t\tbreak;\n\t/* Number of chars in the log buffer */\n\tcase SYSLOG_ACTION_SIZE_UNREAD:\n\t\terror = log_end - log_start;\n\t\tbreak;\n\t/* Size of the log buffer */\n\tcase SYSLOG_ACTION_SIZE_BUFFER:\n\t\terror = log_buf_len;\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
        "code_after_change": "int do_syslog(int type, char __user *buf, int len, bool from_file)\n{\n\tbool clear = false;\n\tstatic int saved_console_loglevel = -1;\n\tint error;\n\n\terror = check_syslog_permissions(type, from_file);\n\tif (error)\n\t\tgoto out;\n\n\terror = security_syslog(type);\n\tif (error)\n\t\treturn error;\n\n\tswitch (type) {\n\tcase SYSLOG_ACTION_CLOSE:\t/* Close log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_OPEN:\t/* Open log */\n\t\tbreak;\n\tcase SYSLOG_ACTION_READ:\t/* Read from log */\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = wait_event_interruptible(log_wait,\n\t\t\t\t\t\t syslog_seq != log_next_seq);\n\t\tif (error)\n\t\t\tgoto out;\n\t\terror = syslog_print(buf, len);\n\t\tbreak;\n\t/* Read/clear last kernel messages */\n\tcase SYSLOG_ACTION_READ_CLEAR:\n\t\tclear = true;\n\t\t/* FALL THRU */\n\t/* Read last kernel messages */\n\tcase SYSLOG_ACTION_READ_ALL:\n\t\terror = -EINVAL;\n\t\tif (!buf || len < 0)\n\t\t\tgoto out;\n\t\terror = 0;\n\t\tif (!len)\n\t\t\tgoto out;\n\t\tif (!access_ok(VERIFY_WRITE, buf, len)) {\n\t\t\terror = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\terror = syslog_print_all(buf, len, clear);\n\t\tbreak;\n\t/* Clear ring buffer */\n\tcase SYSLOG_ACTION_CLEAR:\n\t\tsyslog_print_all(NULL, 0, true);\n\t/* Disable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_OFF:\n\t\tif (saved_console_loglevel == -1)\n\t\t\tsaved_console_loglevel = console_loglevel;\n\t\tconsole_loglevel = minimum_console_loglevel;\n\t\tbreak;\n\t/* Enable logging to console */\n\tcase SYSLOG_ACTION_CONSOLE_ON:\n\t\tif (saved_console_loglevel != -1) {\n\t\t\tconsole_loglevel = saved_console_loglevel;\n\t\t\tsaved_console_loglevel = -1;\n\t\t}\n\t\tbreak;\n\t/* Set level of messages printed to console */\n\tcase SYSLOG_ACTION_CONSOLE_LEVEL:\n\t\terror = -EINVAL;\n\t\tif (len < 1 || len > 8)\n\t\t\tgoto out;\n\t\tif (len < minimum_console_loglevel)\n\t\t\tlen = minimum_console_loglevel;\n\t\tconsole_loglevel = len;\n\t\t/* Implicitly re-enable logging to console */\n\t\tsaved_console_loglevel = -1;\n\t\terror = 0;\n\t\tbreak;\n\t/* Number of chars in the log buffer */\n\tcase SYSLOG_ACTION_SIZE_UNREAD:\n\t\traw_spin_lock_irq(&logbuf_lock);\n\t\tif (syslog_seq < log_first_seq) {\n\t\t\t/* messages are gone, move to first one */\n\t\t\tsyslog_seq = log_first_seq;\n\t\t\tsyslog_idx = log_first_idx;\n\t\t}\n\t\tif (from_file) {\n\t\t\t/*\n\t\t\t * Short-cut for poll(/\"proc/kmsg\") which simply checks\n\t\t\t * for pending data, not the size; return the count of\n\t\t\t * records, not the length.\n\t\t\t */\n\t\t\terror = log_next_idx - syslog_idx;\n\t\t} else {\n\t\t\tu64 seq;\n\t\t\tu32 idx;\n\n\t\t\terror = 0;\n\t\t\tseq = syslog_seq;\n\t\t\tidx = syslog_idx;\n\t\t\twhile (seq < log_next_seq) {\n\t\t\t\terror += syslog_print_line(idx, NULL, 0);\n\t\t\t\tidx = log_next(idx);\n\t\t\t\tseq++;\n\t\t\t}\n\t\t}\n\t\traw_spin_unlock_irq(&logbuf_lock);\n\t\tbreak;\n\t/* Size of the log buffer */\n\tcase SYSLOG_ACTION_SIZE_BUFFER:\n\t\terror = log_buf_len;\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,7 @@\n int do_syslog(int type, char __user *buf, int len, bool from_file)\n {\n-\tunsigned i, j, limit, count;\n-\tint do_clear = 0;\n-\tchar c;\n+\tbool clear = false;\n+\tstatic int saved_console_loglevel = -1;\n \tint error;\n \n \terror = check_syslog_permissions(type, from_file);\n@@ -30,28 +29,14 @@\n \t\t\tgoto out;\n \t\t}\n \t\terror = wait_event_interruptible(log_wait,\n-\t\t\t\t\t\t\t(log_start - log_end));\n+\t\t\t\t\t\t syslog_seq != log_next_seq);\n \t\tif (error)\n \t\t\tgoto out;\n-\t\ti = 0;\n-\t\traw_spin_lock_irq(&logbuf_lock);\n-\t\twhile (!error && (log_start != log_end) && i < len) {\n-\t\t\tc = LOG_BUF(log_start);\n-\t\t\tlog_start++;\n-\t\t\traw_spin_unlock_irq(&logbuf_lock);\n-\t\t\terror = __put_user(c,buf);\n-\t\t\tbuf++;\n-\t\t\ti++;\n-\t\t\tcond_resched();\n-\t\t\traw_spin_lock_irq(&logbuf_lock);\n-\t\t}\n-\t\traw_spin_unlock_irq(&logbuf_lock);\n-\t\tif (!error)\n-\t\t\terror = i;\n+\t\terror = syslog_print(buf, len);\n \t\tbreak;\n \t/* Read/clear last kernel messages */\n \tcase SYSLOG_ACTION_READ_CLEAR:\n-\t\tdo_clear = 1;\n+\t\tclear = true;\n \t\t/* FALL THRU */\n \t/* Read last kernel messages */\n \tcase SYSLOG_ACTION_READ_ALL:\n@@ -65,52 +50,11 @@\n \t\t\terror = -EFAULT;\n \t\t\tgoto out;\n \t\t}\n-\t\tcount = len;\n-\t\tif (count > log_buf_len)\n-\t\t\tcount = log_buf_len;\n-\t\traw_spin_lock_irq(&logbuf_lock);\n-\t\tif (count > logged_chars)\n-\t\t\tcount = logged_chars;\n-\t\tif (do_clear)\n-\t\t\tlogged_chars = 0;\n-\t\tlimit = log_end;\n-\t\t/*\n-\t\t * __put_user() could sleep, and while we sleep\n-\t\t * printk() could overwrite the messages\n-\t\t * we try to copy to user space. Therefore\n-\t\t * the messages are copied in reverse. <manfreds>\n-\t\t */\n-\t\tfor (i = 0; i < count && !error; i++) {\n-\t\t\tj = limit-1-i;\n-\t\t\tif (j + log_buf_len < log_end)\n-\t\t\t\tbreak;\n-\t\t\tc = LOG_BUF(j);\n-\t\t\traw_spin_unlock_irq(&logbuf_lock);\n-\t\t\terror = __put_user(c,&buf[count-1-i]);\n-\t\t\tcond_resched();\n-\t\t\traw_spin_lock_irq(&logbuf_lock);\n-\t\t}\n-\t\traw_spin_unlock_irq(&logbuf_lock);\n-\t\tif (error)\n-\t\t\tbreak;\n-\t\terror = i;\n-\t\tif (i != count) {\n-\t\t\tint offset = count-error;\n-\t\t\t/* buffer overflow during copy, correct user buffer. */\n-\t\t\tfor (i = 0; i < error; i++) {\n-\t\t\t\tif (__get_user(c,&buf[i+offset]) ||\n-\t\t\t\t    __put_user(c,&buf[i])) {\n-\t\t\t\t\terror = -EFAULT;\n-\t\t\t\t\tbreak;\n-\t\t\t\t}\n-\t\t\t\tcond_resched();\n-\t\t\t}\n-\t\t}\n+\t\terror = syslog_print_all(buf, len, clear);\n \t\tbreak;\n \t/* Clear ring buffer */\n \tcase SYSLOG_ACTION_CLEAR:\n-\t\tlogged_chars = 0;\n-\t\tbreak;\n+\t\tsyslog_print_all(NULL, 0, true);\n \t/* Disable logging to console */\n \tcase SYSLOG_ACTION_CONSOLE_OFF:\n \t\tif (saved_console_loglevel == -1)\n@@ -138,7 +82,33 @@\n \t\tbreak;\n \t/* Number of chars in the log buffer */\n \tcase SYSLOG_ACTION_SIZE_UNREAD:\n-\t\terror = log_end - log_start;\n+\t\traw_spin_lock_irq(&logbuf_lock);\n+\t\tif (syslog_seq < log_first_seq) {\n+\t\t\t/* messages are gone, move to first one */\n+\t\t\tsyslog_seq = log_first_seq;\n+\t\t\tsyslog_idx = log_first_idx;\n+\t\t}\n+\t\tif (from_file) {\n+\t\t\t/*\n+\t\t\t * Short-cut for poll(/\"proc/kmsg\") which simply checks\n+\t\t\t * for pending data, not the size; return the count of\n+\t\t\t * records, not the length.\n+\t\t\t */\n+\t\t\terror = log_next_idx - syslog_idx;\n+\t\t} else {\n+\t\t\tu64 seq;\n+\t\t\tu32 idx;\n+\n+\t\t\terror = 0;\n+\t\t\tseq = syslog_seq;\n+\t\t\tidx = syslog_idx;\n+\t\t\twhile (seq < log_next_seq) {\n+\t\t\t\terror += syslog_print_line(idx, NULL, 0);\n+\t\t\t\tidx = log_next(idx);\n+\t\t\t\tseq++;\n+\t\t\t}\n+\t\t}\n+\t\traw_spin_unlock_irq(&logbuf_lock);\n \t\tbreak;\n \t/* Size of the log buffer */\n \tcase SYSLOG_ACTION_SIZE_BUFFER:",
        "function_modified_lines": {
            "added": [
                "\tbool clear = false;",
                "\tstatic int saved_console_loglevel = -1;",
                "\t\t\t\t\t\t syslog_seq != log_next_seq);",
                "\t\terror = syslog_print(buf, len);",
                "\t\tclear = true;",
                "\t\terror = syslog_print_all(buf, len, clear);",
                "\t\tsyslog_print_all(NULL, 0, true);",
                "\t\traw_spin_lock_irq(&logbuf_lock);",
                "\t\tif (syslog_seq < log_first_seq) {",
                "\t\t\t/* messages are gone, move to first one */",
                "\t\t\tsyslog_seq = log_first_seq;",
                "\t\t\tsyslog_idx = log_first_idx;",
                "\t\t}",
                "\t\tif (from_file) {",
                "\t\t\t/*",
                "\t\t\t * Short-cut for poll(/\"proc/kmsg\") which simply checks",
                "\t\t\t * for pending data, not the size; return the count of",
                "\t\t\t * records, not the length.",
                "\t\t\t */",
                "\t\t\terror = log_next_idx - syslog_idx;",
                "\t\t} else {",
                "\t\t\tu64 seq;",
                "\t\t\tu32 idx;",
                "",
                "\t\t\terror = 0;",
                "\t\t\tseq = syslog_seq;",
                "\t\t\tidx = syslog_idx;",
                "\t\t\twhile (seq < log_next_seq) {",
                "\t\t\t\terror += syslog_print_line(idx, NULL, 0);",
                "\t\t\t\tidx = log_next(idx);",
                "\t\t\t\tseq++;",
                "\t\t\t}",
                "\t\t}",
                "\t\traw_spin_unlock_irq(&logbuf_lock);"
            ],
            "deleted": [
                "\tunsigned i, j, limit, count;",
                "\tint do_clear = 0;",
                "\tchar c;",
                "\t\t\t\t\t\t\t(log_start - log_end));",
                "\t\ti = 0;",
                "\t\traw_spin_lock_irq(&logbuf_lock);",
                "\t\twhile (!error && (log_start != log_end) && i < len) {",
                "\t\t\tc = LOG_BUF(log_start);",
                "\t\t\tlog_start++;",
                "\t\t\traw_spin_unlock_irq(&logbuf_lock);",
                "\t\t\terror = __put_user(c,buf);",
                "\t\t\tbuf++;",
                "\t\t\ti++;",
                "\t\t\tcond_resched();",
                "\t\t\traw_spin_lock_irq(&logbuf_lock);",
                "\t\t}",
                "\t\traw_spin_unlock_irq(&logbuf_lock);",
                "\t\tif (!error)",
                "\t\t\terror = i;",
                "\t\tdo_clear = 1;",
                "\t\tcount = len;",
                "\t\tif (count > log_buf_len)",
                "\t\t\tcount = log_buf_len;",
                "\t\traw_spin_lock_irq(&logbuf_lock);",
                "\t\tif (count > logged_chars)",
                "\t\t\tcount = logged_chars;",
                "\t\tif (do_clear)",
                "\t\t\tlogged_chars = 0;",
                "\t\tlimit = log_end;",
                "\t\t/*",
                "\t\t * __put_user() could sleep, and while we sleep",
                "\t\t * printk() could overwrite the messages",
                "\t\t * we try to copy to user space. Therefore",
                "\t\t * the messages are copied in reverse. <manfreds>",
                "\t\t */",
                "\t\tfor (i = 0; i < count && !error; i++) {",
                "\t\t\tj = limit-1-i;",
                "\t\t\tif (j + log_buf_len < log_end)",
                "\t\t\t\tbreak;",
                "\t\t\tc = LOG_BUF(j);",
                "\t\t\traw_spin_unlock_irq(&logbuf_lock);",
                "\t\t\terror = __put_user(c,&buf[count-1-i]);",
                "\t\t\tcond_resched();",
                "\t\t\traw_spin_lock_irq(&logbuf_lock);",
                "\t\t}",
                "\t\traw_spin_unlock_irq(&logbuf_lock);",
                "\t\tif (error)",
                "\t\t\tbreak;",
                "\t\terror = i;",
                "\t\tif (i != count) {",
                "\t\t\tint offset = count-error;",
                "\t\t\t/* buffer overflow during copy, correct user buffer. */",
                "\t\t\tfor (i = 0; i < error; i++) {",
                "\t\t\t\tif (__get_user(c,&buf[i+offset]) ||",
                "\t\t\t\t    __put_user(c,&buf[i])) {",
                "\t\t\t\t\terror = -EFAULT;",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}",
                "\t\t\t\tcond_resched();",
                "\t\t\t}",
                "\t\t}",
                "\t\tlogged_chars = 0;",
                "\t\tbreak;",
                "\t\terror = log_end - log_start;"
            ]
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "The log_prefix function in kernel/printk.c in the Linux kernel 3.x before 3.4.33 does not properly remove a prefix string from a syslog header, which allows local users to cause a denial of service (buffer overflow and system crash) by leveraging /dev/kmsg write access and triggering a call_console_drivers function call.",
        "id": 176
    },
    {
        "cve_id": "CVE-2013-4588",
        "code_before_change": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\tunsigned char arg[MAX_ARG_LEN];\n\tstruct ip_vs_service_user *usvc_compat;\n\tstruct ip_vs_service_user_kern usvc;\n\tstruct ip_vs_service *svc;\n\tstruct ip_vs_dest_user *udest_compat;\n\tstruct ip_vs_dest_user_kern udest;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (len != set_arglen[SET_CMDID(cmd)]) {\n\t\tpr_err(\"set_ctl: len %u != %u\\n\",\n\t\t       len, set_arglen[SET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(arg, user, len) != 0)\n\t\treturn -EFAULT;\n\n\t/* increase the module use count */\n\tip_vs_use_count_inc();\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out_dec;\n\t}\n\n\tif (cmd == IP_VS_SO_SET_FLUSH) {\n\t\t/* Flush the virtual service */\n\t\tret = ip_vs_flush();\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\n\t\t/* Set timeout values for (tcp tcpfin udp) */\n\t\tret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = stop_sync_thread(dm->state);\n\t\tgoto out_unlock;\n\t}\n\n\tusvc_compat = (struct ip_vs_service_user *)arg;\n\tudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\n\n\t/* We only use the new structs internally, so copy userspace compat\n\t * structs to extended internal versions */\n\tip_vs_copy_usvc_compat(&usvc, usvc_compat);\n\tip_vs_copy_udest_compat(&udest, udest_compat);\n\n\tif (cmd == IP_VS_SO_SET_ZERO) {\n\t\t/* if no service address is set, zero counters in all */\n\t\tif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\n\t\t\tret = ip_vs_zero_all();\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\t/* Check for valid protocol: TCP or UDP, even for fwmark!=0 */\n\tif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\n\t\tpr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\n\t\t       usvc.protocol, &usvc.addr.ip,\n\t\t       ntohs(usvc.port), usvc.sched_name);\n\t\tret = -EFAULT;\n\t\tgoto out_unlock;\n\t}\n\n\t/* Lookup the exact service by <protocol, addr, port> or fwmark */\n\tif (usvc.fwmark == 0)\n\t\tsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n\t\t\t\t\t  &usvc.addr, usvc.port);\n\telse\n\t\tsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\n\n\tif (cmd != IP_VS_SO_SET_ADD\n\t    && (svc == NULL || svc->protocol != usvc.protocol)) {\n\t\tret = -ESRCH;\n\t\tgoto out_unlock;\n\t}\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_SET_ADD:\n\t\tif (svc != NULL)\n\t\t\tret = -EEXIST;\n\t\telse\n\t\t\tret = ip_vs_add_service(&usvc, &svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDIT:\n\t\tret = ip_vs_edit_service(svc, &usvc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DEL:\n\t\tret = ip_vs_del_service(svc);\n\t\tif (!ret)\n\t\t\tgoto out_unlock;\n\t\tbreak;\n\tcase IP_VS_SO_SET_ZERO:\n\t\tret = ip_vs_zero_service(svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_ADDDEST:\n\t\tret = ip_vs_add_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDITDEST:\n\t\tret = ip_vs_edit_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DELDEST:\n\t\tret = ip_vs_del_dest(svc, &udest);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\tif (svc)\n\t\tip_vs_service_put(svc);\n\n  out_unlock:\n\tmutex_unlock(&__ip_vs_mutex);\n  out_dec:\n\t/* decrease the module use count */\n\tip_vs_use_count_dec();\n\n\treturn ret;\n}",
        "code_after_change": "static int\ndo_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\tunsigned char arg[MAX_ARG_LEN];\n\tstruct ip_vs_service_user *usvc_compat;\n\tstruct ip_vs_service_user_kern usvc;\n\tstruct ip_vs_service *svc;\n\tstruct ip_vs_dest_user *udest_compat;\n\tstruct ip_vs_dest_user_kern udest;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)\n\t\treturn -EINVAL;\n\tif (len < 0 || len >  MAX_ARG_LEN)\n\t\treturn -EINVAL;\n\tif (len != set_arglen[SET_CMDID(cmd)]) {\n\t\tpr_err(\"set_ctl: len %u != %u\\n\",\n\t\t       len, set_arglen[SET_CMDID(cmd)]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(arg, user, len) != 0)\n\t\treturn -EFAULT;\n\n\t/* increase the module use count */\n\tip_vs_use_count_inc();\n\n\tif (mutex_lock_interruptible(&__ip_vs_mutex)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out_dec;\n\t}\n\n\tif (cmd == IP_VS_SO_SET_FLUSH) {\n\t\t/* Flush the virtual service */\n\t\tret = ip_vs_flush();\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_TIMEOUT) {\n\t\t/* Set timeout values for (tcp tcpfin udp) */\n\t\tret = ip_vs_set_timeout((struct ip_vs_timeout_user *)arg);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STARTDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = start_sync_thread(dm->state, dm->mcast_ifn, dm->syncid);\n\t\tgoto out_unlock;\n\t} else if (cmd == IP_VS_SO_SET_STOPDAEMON) {\n\t\tstruct ip_vs_daemon_user *dm = (struct ip_vs_daemon_user *)arg;\n\t\tret = stop_sync_thread(dm->state);\n\t\tgoto out_unlock;\n\t}\n\n\tusvc_compat = (struct ip_vs_service_user *)arg;\n\tudest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);\n\n\t/* We only use the new structs internally, so copy userspace compat\n\t * structs to extended internal versions */\n\tip_vs_copy_usvc_compat(&usvc, usvc_compat);\n\tip_vs_copy_udest_compat(&udest, udest_compat);\n\n\tif (cmd == IP_VS_SO_SET_ZERO) {\n\t\t/* if no service address is set, zero counters in all */\n\t\tif (!usvc.fwmark && !usvc.addr.ip && !usvc.port) {\n\t\t\tret = ip_vs_zero_all();\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\t/* Check for valid protocol: TCP or UDP, even for fwmark!=0 */\n\tif (usvc.protocol != IPPROTO_TCP && usvc.protocol != IPPROTO_UDP) {\n\t\tpr_err(\"set_ctl: invalid protocol: %d %pI4:%d %s\\n\",\n\t\t       usvc.protocol, &usvc.addr.ip,\n\t\t       ntohs(usvc.port), usvc.sched_name);\n\t\tret = -EFAULT;\n\t\tgoto out_unlock;\n\t}\n\n\t/* Lookup the exact service by <protocol, addr, port> or fwmark */\n\tif (usvc.fwmark == 0)\n\t\tsvc = __ip_vs_service_get(usvc.af, usvc.protocol,\n\t\t\t\t\t  &usvc.addr, usvc.port);\n\telse\n\t\tsvc = __ip_vs_svc_fwm_get(usvc.af, usvc.fwmark);\n\n\tif (cmd != IP_VS_SO_SET_ADD\n\t    && (svc == NULL || svc->protocol != usvc.protocol)) {\n\t\tret = -ESRCH;\n\t\tgoto out_unlock;\n\t}\n\n\tswitch (cmd) {\n\tcase IP_VS_SO_SET_ADD:\n\t\tif (svc != NULL)\n\t\t\tret = -EEXIST;\n\t\telse\n\t\t\tret = ip_vs_add_service(&usvc, &svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDIT:\n\t\tret = ip_vs_edit_service(svc, &usvc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DEL:\n\t\tret = ip_vs_del_service(svc);\n\t\tif (!ret)\n\t\t\tgoto out_unlock;\n\t\tbreak;\n\tcase IP_VS_SO_SET_ZERO:\n\t\tret = ip_vs_zero_service(svc);\n\t\tbreak;\n\tcase IP_VS_SO_SET_ADDDEST:\n\t\tret = ip_vs_add_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_EDITDEST:\n\t\tret = ip_vs_edit_dest(svc, &udest);\n\t\tbreak;\n\tcase IP_VS_SO_SET_DELDEST:\n\t\tret = ip_vs_del_dest(svc, &udest);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\tif (svc)\n\t\tip_vs_service_put(svc);\n\n  out_unlock:\n\tmutex_unlock(&__ip_vs_mutex);\n  out_dec:\n\t/* decrease the module use count */\n\tip_vs_use_count_dec();\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,6 +12,10 @@\n \tif (!capable(CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n+\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)\n+\t\treturn -EINVAL;\n+\tif (len < 0 || len >  MAX_ARG_LEN)\n+\t\treturn -EINVAL;\n \tif (len != set_arglen[SET_CMDID(cmd)]) {\n \t\tpr_err(\"set_ctl: len %u != %u\\n\",\n \t\t       len, set_arglen[SET_CMDID(cmd)]);",
        "function_modified_lines": {
            "added": [
                "\tif (cmd < IP_VS_BASE_CTL || cmd > IP_VS_SO_SET_MAX)",
                "\t\treturn -EINVAL;",
                "\tif (len < 0 || len >  MAX_ARG_LEN)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-119"
        ],
        "cve_description": "Multiple stack-based buffer overflows in net/netfilter/ipvs/ip_vs_ctl.c in the Linux kernel before 2.6.33, when CONFIG_IP_VS is used, allow local users to gain privileges by leveraging the CAP_NET_ADMIN capability for (1) a getsockopt system call, related to the do_ip_vs_get_ctl function, or (2) a setsockopt system call, related to the do_ip_vs_set_ctl function.",
        "id": 333
    }
]