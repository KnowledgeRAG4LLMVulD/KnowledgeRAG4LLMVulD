[
    {
        "cve_id": "CVE-2023-31083",
        "code_before_change": "static int hci_uart_tty_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\t\t      unsigned long arg)\n{\n\tstruct hci_uart *hu = tty->disc_data;\n\tint err = 0;\n\n\tBT_DBG(\"\");\n\n\t/* Verify the status of the device */\n\tif (!hu)\n\t\treturn -EBADF;\n\n\tswitch (cmd) {\n\tcase HCIUARTSETPROTO:\n\t\tif (!test_and_set_bit(HCI_UART_PROTO_SET, &hu->flags)) {\n\t\t\terr = hci_uart_set_proto(hu, arg);\n\t\t\tif (err)\n\t\t\t\tclear_bit(HCI_UART_PROTO_SET, &hu->flags);\n\t\t} else\n\t\t\terr = -EBUSY;\n\t\tbreak;\n\n\tcase HCIUARTGETPROTO:\n\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags))\n\t\t\terr = hu->proto->id;\n\t\telse\n\t\t\terr = -EUNATCH;\n\t\tbreak;\n\n\tcase HCIUARTGETDEVICE:\n\t\tif (test_bit(HCI_UART_REGISTERED, &hu->flags))\n\t\t\terr = hu->hdev->id;\n\t\telse\n\t\t\terr = -EUNATCH;\n\t\tbreak;\n\n\tcase HCIUARTSETFLAGS:\n\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags))\n\t\t\terr = -EBUSY;\n\t\telse\n\t\t\terr = hci_uart_set_flags(hu, arg);\n\t\tbreak;\n\n\tcase HCIUARTGETFLAGS:\n\t\terr = hu->hdev_flags;\n\t\tbreak;\n\n\tdefault:\n\t\terr = n_tty_ioctl_helper(tty, cmd, arg);\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int hci_uart_tty_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\t\t      unsigned long arg)\n{\n\tstruct hci_uart *hu = tty->disc_data;\n\tint err = 0;\n\n\tBT_DBG(\"\");\n\n\t/* Verify the status of the device */\n\tif (!hu)\n\t\treturn -EBADF;\n\n\tswitch (cmd) {\n\tcase HCIUARTSETPROTO:\n\t\tif (!test_and_set_bit(HCI_UART_PROTO_SET, &hu->flags)) {\n\t\t\terr = hci_uart_set_proto(hu, arg);\n\t\t\tif (err)\n\t\t\t\tclear_bit(HCI_UART_PROTO_SET, &hu->flags);\n\t\t} else\n\t\t\terr = -EBUSY;\n\t\tbreak;\n\n\tcase HCIUARTGETPROTO:\n\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags) &&\n\t\t    test_bit(HCI_UART_PROTO_READY, &hu->flags))\n\t\t\terr = hu->proto->id;\n\t\telse\n\t\t\terr = -EUNATCH;\n\t\tbreak;\n\n\tcase HCIUARTGETDEVICE:\n\t\tif (test_bit(HCI_UART_REGISTERED, &hu->flags))\n\t\t\terr = hu->hdev->id;\n\t\telse\n\t\t\terr = -EUNATCH;\n\t\tbreak;\n\n\tcase HCIUARTSETFLAGS:\n\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags))\n\t\t\terr = -EBUSY;\n\t\telse\n\t\t\terr = hci_uart_set_flags(hu, arg);\n\t\tbreak;\n\n\tcase HCIUARTGETFLAGS:\n\t\terr = hu->hdev_flags;\n\t\tbreak;\n\n\tdefault:\n\t\terr = n_tty_ioctl_helper(tty, cmd, arg);\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,7 +21,8 @@\n \t\tbreak;\n \n \tcase HCIUARTGETPROTO:\n-\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags))\n+\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags) &&\n+\t\t    test_bit(HCI_UART_PROTO_READY, &hu->flags))\n \t\t\terr = hu->proto->id;\n \t\telse\n \t\t\terr = -EUNATCH;",
        "function_modified_lines": {
            "added": [
                "\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags) &&",
                "\t\t    test_bit(HCI_UART_PROTO_READY, &hu->flags))"
            ],
            "deleted": [
                "\t\tif (test_bit(HCI_UART_PROTO_SET, &hu->flags))"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in drivers/bluetooth/hci_ldisc.c in the Linux kernel 6.2. In hci_uart_tty_ioctl, there is a race condition between HCIUARTSETPROTO and HCIUARTGETPROTO. HCI_UART_PROTO_SET is set before hu->proto is set. A NULL pointer dereference may occur.",
        "id": 3995
    },
    {
        "cve_id": "CVE-2017-15116",
        "code_before_change": "static int crypto_rng_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_rng *rng = __crypto_rng_cast(tfm);\n\tstruct rng_alg *alg = crypto_rng_alg(rng);\n\tstruct old_rng_alg *oalg = crypto_old_rng_alg(rng);\n\n\tif (oalg->rng_make_random) {\n\t\trng->generate = generate;\n\t\trng->seed = rngapi_reset;\n\t\trng->seedsize = oalg->seedsize;\n\t\treturn 0;\n\t}\n\n\trng->generate = alg->generate;\n\trng->seed = alg->seed;\n\trng->seedsize = alg->seedsize;\n\n\treturn 0;\n}",
        "code_after_change": "static int crypto_rng_init_tfm(struct crypto_tfm *tfm)\n{\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,19 +1,4 @@\n static int crypto_rng_init_tfm(struct crypto_tfm *tfm)\n {\n-\tstruct crypto_rng *rng = __crypto_rng_cast(tfm);\n-\tstruct rng_alg *alg = crypto_rng_alg(rng);\n-\tstruct old_rng_alg *oalg = crypto_old_rng_alg(rng);\n-\n-\tif (oalg->rng_make_random) {\n-\t\trng->generate = generate;\n-\t\trng->seed = rngapi_reset;\n-\t\trng->seedsize = oalg->seedsize;\n-\t\treturn 0;\n-\t}\n-\n-\trng->generate = alg->generate;\n-\trng->seed = alg->seed;\n-\trng->seedsize = alg->seedsize;\n-\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tstruct crypto_rng *rng = __crypto_rng_cast(tfm);",
                "\tstruct rng_alg *alg = crypto_rng_alg(rng);",
                "\tstruct old_rng_alg *oalg = crypto_old_rng_alg(rng);",
                "",
                "\tif (oalg->rng_make_random) {",
                "\t\trng->generate = generate;",
                "\t\trng->seed = rngapi_reset;",
                "\t\trng->seedsize = oalg->seedsize;",
                "\t\treturn 0;",
                "\t}",
                "",
                "\trng->generate = alg->generate;",
                "\trng->seed = alg->seed;",
                "\trng->seedsize = alg->seedsize;",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The rngapi_reset function in crypto/rng.c in the Linux kernel before 4.2 allows attackers to cause a denial of service (NULL pointer dereference).",
        "id": 1291
    },
    {
        "cve_id": "CVE-2018-7492",
        "code_before_change": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}",
        "code_after_change": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0 || !rs->rs_transport) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \tlong i;\n \tint ret;\n \n-\tif (rs->rs_bound_addr == 0) {\n+\tif (rs->rs_bound_addr == 0 || !rs->rs_transport) {\n \t\tret = -ENOTCONN; /* XXX not a great errno */\n \t\tgoto out;\n \t}",
        "function_modified_lines": {
            "added": [
                "\tif (rs->rs_bound_addr == 0 || !rs->rs_transport) {"
            ],
            "deleted": [
                "\tif (rs->rs_bound_addr == 0) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference was found in the net/rds/rdma.c __rds_rdma_map() function in the Linux kernel before 4.14.7 allowing local attackers to cause a system panic and a denial-of-service, related to RDS_GET_MR and RDS_GET_MR_FOR_DEST.",
        "id": 1846
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "bool ksmbd_conn_alive(struct ksmbd_conn *conn)\n{\n\tif (!ksmbd_server_running())\n\t\treturn false;\n\n\tif (conn->status == KSMBD_SESS_EXITING)\n\t\treturn false;\n\n\tif (kthread_should_stop())\n\t\treturn false;\n\n\tif (atomic_read(&conn->stats.open_files_count) > 0)\n\t\treturn true;\n\n\t/*\n\t * Stop current session if the time that get last request from client\n\t * is bigger than deadtime user configured and opening file count is\n\t * zero.\n\t */\n\tif (server_conf.deadtime > 0 &&\n\t    time_after(jiffies, conn->last_active + server_conf.deadtime)) {\n\t\tksmbd_debug(CONN, \"No response from client in %lu minutes\\n\",\n\t\t\t    server_conf.deadtime / SMB_ECHO_INTERVAL);\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "code_after_change": "bool ksmbd_conn_alive(struct ksmbd_conn *conn)\n{\n\tif (!ksmbd_server_running())\n\t\treturn false;\n\n\tif (ksmbd_conn_exiting(conn))\n\t\treturn false;\n\n\tif (kthread_should_stop())\n\t\treturn false;\n\n\tif (atomic_read(&conn->stats.open_files_count) > 0)\n\t\treturn true;\n\n\t/*\n\t * Stop current session if the time that get last request from client\n\t * is bigger than deadtime user configured and opening file count is\n\t * zero.\n\t */\n\tif (server_conf.deadtime > 0 &&\n\t    time_after(jiffies, conn->last_active + server_conf.deadtime)) {\n\t\tksmbd_debug(CONN, \"No response from client in %lu minutes\\n\",\n\t\t\t    server_conf.deadtime / SMB_ECHO_INTERVAL);\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tif (!ksmbd_server_running())\n \t\treturn false;\n \n-\tif (conn->status == KSMBD_SESS_EXITING)\n+\tif (ksmbd_conn_exiting(conn))\n \t\treturn false;\n \n \tif (kthread_should_stop())",
        "function_modified_lines": {
            "added": [
                "\tif (ksmbd_conn_exiting(conn))"
            ],
            "deleted": [
                "\tif (conn->status == KSMBD_SESS_EXITING)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4027
    },
    {
        "cve_id": "CVE-2023-0122",
        "code_before_change": "int nvmet_setup_auth(struct nvmet_ctrl *ctrl)\n{\n\tint ret = 0;\n\tstruct nvmet_host_link *p;\n\tstruct nvmet_host *host = NULL;\n\tconst char *hash_name;\n\n\tdown_read(&nvmet_config_sem);\n\tif (nvmet_is_disc_subsys(ctrl->subsys))\n\t\tgoto out_unlock;\n\n\tif (ctrl->subsys->allow_any_host)\n\t\tgoto out_unlock;\n\n\tlist_for_each_entry(p, &ctrl->subsys->hosts, entry) {\n\t\tpr_debug(\"check %s\\n\", nvmet_host_name(p->host));\n\t\tif (strcmp(nvmet_host_name(p->host), ctrl->hostnqn))\n\t\t\tcontinue;\n\t\thost = p->host;\n\t\tbreak;\n\t}\n\tif (!host) {\n\t\tpr_debug(\"host %s not found\\n\", ctrl->hostnqn);\n\t\tret = -EPERM;\n\t\tgoto out_unlock;\n\t}\n\n\tret = nvmet_setup_dhgroup(ctrl, host->dhchap_dhgroup_id);\n\tif (ret < 0)\n\t\tpr_warn(\"Failed to setup DH group\");\n\n\tif (!host->dhchap_secret) {\n\t\tpr_debug(\"No authentication provided\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tif (host->dhchap_hash_id == ctrl->shash_id) {\n\t\tpr_debug(\"Re-use existing hash ID %d\\n\",\n\t\t\t ctrl->shash_id);\n\t} else {\n\t\thash_name = nvme_auth_hmac_name(host->dhchap_hash_id);\n\t\tif (!hash_name) {\n\t\t\tpr_warn(\"Hash ID %d invalid\\n\", host->dhchap_hash_id);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tctrl->shash_id = host->dhchap_hash_id;\n\t}\n\n\t/* Skip the 'DHHC-1:XX:' prefix */\n\tnvme_auth_free_key(ctrl->host_key);\n\tctrl->host_key = nvme_auth_extract_key(host->dhchap_secret + 10,\n\t\t\t\t\t       host->dhchap_key_hash);\n\tif (IS_ERR(ctrl->host_key)) {\n\t\tret = PTR_ERR(ctrl->host_key);\n\t\tctrl->host_key = NULL;\n\t\tgoto out_free_hash;\n\t}\n\tpr_debug(\"%s: using hash %s key %*ph\\n\", __func__,\n\t\t ctrl->host_key->hash > 0 ?\n\t\t nvme_auth_hmac_name(ctrl->host_key->hash) : \"none\",\n\t\t (int)ctrl->host_key->len, ctrl->host_key->key);\n\n\tnvme_auth_free_key(ctrl->ctrl_key);\n\tif (!host->dhchap_ctrl_secret) {\n\t\tctrl->ctrl_key = NULL;\n\t\tgoto out_unlock;\n\t}\n\n\tctrl->ctrl_key = nvme_auth_extract_key(host->dhchap_ctrl_secret + 10,\n\t\t\t\t\t       host->dhchap_ctrl_key_hash);\n\tif (IS_ERR(ctrl->ctrl_key)) {\n\t\tret = PTR_ERR(ctrl->ctrl_key);\n\t\tctrl->ctrl_key = NULL;\n\t}\n\tpr_debug(\"%s: using ctrl hash %s key %*ph\\n\", __func__,\n\t\t ctrl->ctrl_key->hash > 0 ?\n\t\t nvme_auth_hmac_name(ctrl->ctrl_key->hash) : \"none\",\n\t\t (int)ctrl->ctrl_key->len, ctrl->ctrl_key->key);\n\nout_free_hash:\n\tif (ret) {\n\t\tif (ctrl->host_key) {\n\t\t\tnvme_auth_free_key(ctrl->host_key);\n\t\t\tctrl->host_key = NULL;\n\t\t}\n\t\tctrl->shash_id = 0;\n\t}\nout_unlock:\n\tup_read(&nvmet_config_sem);\n\n\treturn ret;\n}",
        "code_after_change": "int nvmet_setup_auth(struct nvmet_ctrl *ctrl)\n{\n\tint ret = 0;\n\tstruct nvmet_host_link *p;\n\tstruct nvmet_host *host = NULL;\n\tconst char *hash_name;\n\n\tdown_read(&nvmet_config_sem);\n\tif (nvmet_is_disc_subsys(ctrl->subsys))\n\t\tgoto out_unlock;\n\n\tif (ctrl->subsys->allow_any_host)\n\t\tgoto out_unlock;\n\n\tlist_for_each_entry(p, &ctrl->subsys->hosts, entry) {\n\t\tpr_debug(\"check %s\\n\", nvmet_host_name(p->host));\n\t\tif (strcmp(nvmet_host_name(p->host), ctrl->hostnqn))\n\t\t\tcontinue;\n\t\thost = p->host;\n\t\tbreak;\n\t}\n\tif (!host) {\n\t\tpr_debug(\"host %s not found\\n\", ctrl->hostnqn);\n\t\tret = -EPERM;\n\t\tgoto out_unlock;\n\t}\n\n\tret = nvmet_setup_dhgroup(ctrl, host->dhchap_dhgroup_id);\n\tif (ret < 0)\n\t\tpr_warn(\"Failed to setup DH group\");\n\n\tif (!host->dhchap_secret) {\n\t\tpr_debug(\"No authentication provided\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tif (host->dhchap_hash_id == ctrl->shash_id) {\n\t\tpr_debug(\"Re-use existing hash ID %d\\n\",\n\t\t\t ctrl->shash_id);\n\t} else {\n\t\thash_name = nvme_auth_hmac_name(host->dhchap_hash_id);\n\t\tif (!hash_name) {\n\t\t\tpr_warn(\"Hash ID %d invalid\\n\", host->dhchap_hash_id);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tctrl->shash_id = host->dhchap_hash_id;\n\t}\n\n\t/* Skip the 'DHHC-1:XX:' prefix */\n\tnvme_auth_free_key(ctrl->host_key);\n\tctrl->host_key = nvme_auth_extract_key(host->dhchap_secret + 10,\n\t\t\t\t\t       host->dhchap_key_hash);\n\tif (IS_ERR(ctrl->host_key)) {\n\t\tret = PTR_ERR(ctrl->host_key);\n\t\tctrl->host_key = NULL;\n\t\tgoto out_free_hash;\n\t}\n\tpr_debug(\"%s: using hash %s key %*ph\\n\", __func__,\n\t\t ctrl->host_key->hash > 0 ?\n\t\t nvme_auth_hmac_name(ctrl->host_key->hash) : \"none\",\n\t\t (int)ctrl->host_key->len, ctrl->host_key->key);\n\n\tnvme_auth_free_key(ctrl->ctrl_key);\n\tif (!host->dhchap_ctrl_secret) {\n\t\tctrl->ctrl_key = NULL;\n\t\tgoto out_unlock;\n\t}\n\n\tctrl->ctrl_key = nvme_auth_extract_key(host->dhchap_ctrl_secret + 10,\n\t\t\t\t\t       host->dhchap_ctrl_key_hash);\n\tif (IS_ERR(ctrl->ctrl_key)) {\n\t\tret = PTR_ERR(ctrl->ctrl_key);\n\t\tctrl->ctrl_key = NULL;\n\t\tgoto out_free_hash;\n\t}\n\tpr_debug(\"%s: using ctrl hash %s key %*ph\\n\", __func__,\n\t\t ctrl->ctrl_key->hash > 0 ?\n\t\t nvme_auth_hmac_name(ctrl->ctrl_key->hash) : \"none\",\n\t\t (int)ctrl->ctrl_key->len, ctrl->ctrl_key->key);\n\nout_free_hash:\n\tif (ret) {\n\t\tif (ctrl->host_key) {\n\t\t\tnvme_auth_free_key(ctrl->host_key);\n\t\t\tctrl->host_key = NULL;\n\t\t}\n\t\tctrl->shash_id = 0;\n\t}\nout_unlock:\n\tup_read(&nvmet_config_sem);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -72,6 +72,7 @@\n \tif (IS_ERR(ctrl->ctrl_key)) {\n \t\tret = PTR_ERR(ctrl->ctrl_key);\n \t\tctrl->ctrl_key = NULL;\n+\t\tgoto out_free_hash;\n \t}\n \tpr_debug(\"%s: using ctrl hash %s key %*ph\\n\", __func__,\n \t\t ctrl->ctrl_key->hash > 0 ?",
        "function_modified_lines": {
            "added": [
                "\t\tgoto out_free_hash;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference vulnerability in the Linux kernel NVMe functionality, in nvmet_setup_auth(), allows an attacker to perform a Pre-Auth Denial of Service (DoS) attack on a remote machine. Affected versions v6.0-rc1 to v6.0-rc3, fixed in v6.0-rc4.",
        "id": 3810
    },
    {
        "cve_id": "CVE-2023-28466",
        "code_before_change": "static int do_tls_getsockopt_conf(struct sock *sk, char __user *optval,\n\t\t\t\t  int __user *optlen, int tx)\n{\n\tint rc = 0;\n\tstruct tls_context *ctx = tls_get_ctx(sk);\n\tstruct tls_crypto_info *crypto_info;\n\tstruct cipher_context *cctx;\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tif (!optval || (len < sizeof(*crypto_info))) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!ctx) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t/* get user crypto info */\n\tif (tx) {\n\t\tcrypto_info = &ctx->crypto_send.info;\n\t\tcctx = &ctx->tx;\n\t} else {\n\t\tcrypto_info = &ctx->crypto_recv.info;\n\t\tcctx = &ctx->rx;\n\t}\n\n\tif (!TLS_CRYPTO_INFO_READY(crypto_info)) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tif (len == sizeof(*crypto_info)) {\n\t\tif (copy_to_user(optval, crypto_info, sizeof(*crypto_info)))\n\t\t\trc = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tswitch (crypto_info->cipher_type) {\n\tcase TLS_CIPHER_AES_GCM_128: {\n\t\tstruct tls12_crypto_info_aes_gcm_128 *\n\t\t  crypto_info_aes_gcm_128 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aes_gcm_128,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aes_gcm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(crypto_info_aes_gcm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_GCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_GCM_128_IV_SIZE);\n\t\tmemcpy(crypto_info_aes_gcm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_GCM_128_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aes_gcm_128,\n\t\t\t\t sizeof(*crypto_info_aes_gcm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_AES_GCM_256: {\n\t\tstruct tls12_crypto_info_aes_gcm_256 *\n\t\t  crypto_info_aes_gcm_256 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aes_gcm_256,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aes_gcm_256)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(crypto_info_aes_gcm_256->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_GCM_256_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_GCM_256_IV_SIZE);\n\t\tmemcpy(crypto_info_aes_gcm_256->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_GCM_256_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aes_gcm_256,\n\t\t\t\t sizeof(*crypto_info_aes_gcm_256)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_AES_CCM_128: {\n\t\tstruct tls12_crypto_info_aes_ccm_128 *aes_ccm_128 =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_aes_ccm_128, info);\n\n\t\tif (len != sizeof(*aes_ccm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(aes_ccm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_CCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_CCM_128_IV_SIZE);\n\t\tmemcpy(aes_ccm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_CCM_128_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval, aes_ccm_128, sizeof(*aes_ccm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_CHACHA20_POLY1305: {\n\t\tstruct tls12_crypto_info_chacha20_poly1305 *chacha20_poly1305 =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_chacha20_poly1305,\n\t\t\t\tinfo);\n\n\t\tif (len != sizeof(*chacha20_poly1305)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(chacha20_poly1305->iv,\n\t\t       cctx->iv + TLS_CIPHER_CHACHA20_POLY1305_SALT_SIZE,\n\t\t       TLS_CIPHER_CHACHA20_POLY1305_IV_SIZE);\n\t\tmemcpy(chacha20_poly1305->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_CHACHA20_POLY1305_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval, chacha20_poly1305,\n\t\t\t\tsizeof(*chacha20_poly1305)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_SM4_GCM: {\n\t\tstruct tls12_crypto_info_sm4_gcm *sm4_gcm_info =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_sm4_gcm, info);\n\n\t\tif (len != sizeof(*sm4_gcm_info)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(sm4_gcm_info->iv,\n\t\t       cctx->iv + TLS_CIPHER_SM4_GCM_SALT_SIZE,\n\t\t       TLS_CIPHER_SM4_GCM_IV_SIZE);\n\t\tmemcpy(sm4_gcm_info->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_SM4_GCM_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval, sm4_gcm_info, sizeof(*sm4_gcm_info)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_SM4_CCM: {\n\t\tstruct tls12_crypto_info_sm4_ccm *sm4_ccm_info =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_sm4_ccm, info);\n\n\t\tif (len != sizeof(*sm4_ccm_info)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(sm4_ccm_info->iv,\n\t\t       cctx->iv + TLS_CIPHER_SM4_CCM_SALT_SIZE,\n\t\t       TLS_CIPHER_SM4_CCM_IV_SIZE);\n\t\tmemcpy(sm4_ccm_info->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_SM4_CCM_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval, sm4_ccm_info, sizeof(*sm4_ccm_info)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_ARIA_GCM_128: {\n\t\tstruct tls12_crypto_info_aria_gcm_128 *\n\t\t  crypto_info_aria_gcm_128 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aria_gcm_128,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aria_gcm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(crypto_info_aria_gcm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_ARIA_GCM_128_IV_SIZE);\n\t\tmemcpy(crypto_info_aria_gcm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_ARIA_GCM_128_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aria_gcm_128,\n\t\t\t\t sizeof(*crypto_info_aria_gcm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_ARIA_GCM_256: {\n\t\tstruct tls12_crypto_info_aria_gcm_256 *\n\t\t  crypto_info_aria_gcm_256 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aria_gcm_256,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aria_gcm_256)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tlock_sock(sk);\n\t\tmemcpy(crypto_info_aria_gcm_256->iv,\n\t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_256_SALT_SIZE,\n\t\t       TLS_CIPHER_ARIA_GCM_256_IV_SIZE);\n\t\tmemcpy(crypto_info_aria_gcm_256->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_ARIA_GCM_256_REC_SEQ_SIZE);\n\t\trelease_sock(sk);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aria_gcm_256,\n\t\t\t\t sizeof(*crypto_info_aria_gcm_256)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tdefault:\n\t\trc = -EINVAL;\n\t}\n\nout:\n\treturn rc;\n}",
        "code_after_change": "static int do_tls_getsockopt_conf(struct sock *sk, char __user *optval,\n\t\t\t\t  int __user *optlen, int tx)\n{\n\tint rc = 0;\n\tstruct tls_context *ctx = tls_get_ctx(sk);\n\tstruct tls_crypto_info *crypto_info;\n\tstruct cipher_context *cctx;\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tif (!optval || (len < sizeof(*crypto_info))) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!ctx) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t/* get user crypto info */\n\tif (tx) {\n\t\tcrypto_info = &ctx->crypto_send.info;\n\t\tcctx = &ctx->tx;\n\t} else {\n\t\tcrypto_info = &ctx->crypto_recv.info;\n\t\tcctx = &ctx->rx;\n\t}\n\n\tif (!TLS_CRYPTO_INFO_READY(crypto_info)) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tif (len == sizeof(*crypto_info)) {\n\t\tif (copy_to_user(optval, crypto_info, sizeof(*crypto_info)))\n\t\t\trc = -EFAULT;\n\t\tgoto out;\n\t}\n\n\tswitch (crypto_info->cipher_type) {\n\tcase TLS_CIPHER_AES_GCM_128: {\n\t\tstruct tls12_crypto_info_aes_gcm_128 *\n\t\t  crypto_info_aes_gcm_128 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aes_gcm_128,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aes_gcm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(crypto_info_aes_gcm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_GCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_GCM_128_IV_SIZE);\n\t\tmemcpy(crypto_info_aes_gcm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_GCM_128_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aes_gcm_128,\n\t\t\t\t sizeof(*crypto_info_aes_gcm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_AES_GCM_256: {\n\t\tstruct tls12_crypto_info_aes_gcm_256 *\n\t\t  crypto_info_aes_gcm_256 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aes_gcm_256,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aes_gcm_256)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(crypto_info_aes_gcm_256->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_GCM_256_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_GCM_256_IV_SIZE);\n\t\tmemcpy(crypto_info_aes_gcm_256->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_GCM_256_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aes_gcm_256,\n\t\t\t\t sizeof(*crypto_info_aes_gcm_256)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_AES_CCM_128: {\n\t\tstruct tls12_crypto_info_aes_ccm_128 *aes_ccm_128 =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_aes_ccm_128, info);\n\n\t\tif (len != sizeof(*aes_ccm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(aes_ccm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_AES_CCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_AES_CCM_128_IV_SIZE);\n\t\tmemcpy(aes_ccm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_AES_CCM_128_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval, aes_ccm_128, sizeof(*aes_ccm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_CHACHA20_POLY1305: {\n\t\tstruct tls12_crypto_info_chacha20_poly1305 *chacha20_poly1305 =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_chacha20_poly1305,\n\t\t\t\tinfo);\n\n\t\tif (len != sizeof(*chacha20_poly1305)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(chacha20_poly1305->iv,\n\t\t       cctx->iv + TLS_CIPHER_CHACHA20_POLY1305_SALT_SIZE,\n\t\t       TLS_CIPHER_CHACHA20_POLY1305_IV_SIZE);\n\t\tmemcpy(chacha20_poly1305->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_CHACHA20_POLY1305_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval, chacha20_poly1305,\n\t\t\t\tsizeof(*chacha20_poly1305)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_SM4_GCM: {\n\t\tstruct tls12_crypto_info_sm4_gcm *sm4_gcm_info =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_sm4_gcm, info);\n\n\t\tif (len != sizeof(*sm4_gcm_info)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(sm4_gcm_info->iv,\n\t\t       cctx->iv + TLS_CIPHER_SM4_GCM_SALT_SIZE,\n\t\t       TLS_CIPHER_SM4_GCM_IV_SIZE);\n\t\tmemcpy(sm4_gcm_info->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_SM4_GCM_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval, sm4_gcm_info, sizeof(*sm4_gcm_info)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_SM4_CCM: {\n\t\tstruct tls12_crypto_info_sm4_ccm *sm4_ccm_info =\n\t\t\tcontainer_of(crypto_info,\n\t\t\t\tstruct tls12_crypto_info_sm4_ccm, info);\n\n\t\tif (len != sizeof(*sm4_ccm_info)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(sm4_ccm_info->iv,\n\t\t       cctx->iv + TLS_CIPHER_SM4_CCM_SALT_SIZE,\n\t\t       TLS_CIPHER_SM4_CCM_IV_SIZE);\n\t\tmemcpy(sm4_ccm_info->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_SM4_CCM_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval, sm4_ccm_info, sizeof(*sm4_ccm_info)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_ARIA_GCM_128: {\n\t\tstruct tls12_crypto_info_aria_gcm_128 *\n\t\t  crypto_info_aria_gcm_128 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aria_gcm_128,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aria_gcm_128)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(crypto_info_aria_gcm_128->iv,\n\t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_128_SALT_SIZE,\n\t\t       TLS_CIPHER_ARIA_GCM_128_IV_SIZE);\n\t\tmemcpy(crypto_info_aria_gcm_128->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_ARIA_GCM_128_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aria_gcm_128,\n\t\t\t\t sizeof(*crypto_info_aria_gcm_128)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tcase TLS_CIPHER_ARIA_GCM_256: {\n\t\tstruct tls12_crypto_info_aria_gcm_256 *\n\t\t  crypto_info_aria_gcm_256 =\n\t\t  container_of(crypto_info,\n\t\t\t       struct tls12_crypto_info_aria_gcm_256,\n\t\t\t       info);\n\n\t\tif (len != sizeof(*crypto_info_aria_gcm_256)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tmemcpy(crypto_info_aria_gcm_256->iv,\n\t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_256_SALT_SIZE,\n\t\t       TLS_CIPHER_ARIA_GCM_256_IV_SIZE);\n\t\tmemcpy(crypto_info_aria_gcm_256->rec_seq, cctx->rec_seq,\n\t\t       TLS_CIPHER_ARIA_GCM_256_REC_SEQ_SIZE);\n\t\tif (copy_to_user(optval,\n\t\t\t\t crypto_info_aria_gcm_256,\n\t\t\t\t sizeof(*crypto_info_aria_gcm_256)))\n\t\t\trc = -EFAULT;\n\t\tbreak;\n\t}\n\tdefault:\n\t\trc = -EINVAL;\n\t}\n\nout:\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -52,13 +52,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(crypto_info_aes_gcm_128->iv,\n \t\t       cctx->iv + TLS_CIPHER_AES_GCM_128_SALT_SIZE,\n \t\t       TLS_CIPHER_AES_GCM_128_IV_SIZE);\n \t\tmemcpy(crypto_info_aes_gcm_128->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_AES_GCM_128_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval,\n \t\t\t\t crypto_info_aes_gcm_128,\n \t\t\t\t sizeof(*crypto_info_aes_gcm_128)))\n@@ -76,13 +74,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(crypto_info_aes_gcm_256->iv,\n \t\t       cctx->iv + TLS_CIPHER_AES_GCM_256_SALT_SIZE,\n \t\t       TLS_CIPHER_AES_GCM_256_IV_SIZE);\n \t\tmemcpy(crypto_info_aes_gcm_256->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_AES_GCM_256_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval,\n \t\t\t\t crypto_info_aes_gcm_256,\n \t\t\t\t sizeof(*crypto_info_aes_gcm_256)))\n@@ -98,13 +94,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(aes_ccm_128->iv,\n \t\t       cctx->iv + TLS_CIPHER_AES_CCM_128_SALT_SIZE,\n \t\t       TLS_CIPHER_AES_CCM_128_IV_SIZE);\n \t\tmemcpy(aes_ccm_128->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_AES_CCM_128_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval, aes_ccm_128, sizeof(*aes_ccm_128)))\n \t\t\trc = -EFAULT;\n \t\tbreak;\n@@ -119,13 +113,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(chacha20_poly1305->iv,\n \t\t       cctx->iv + TLS_CIPHER_CHACHA20_POLY1305_SALT_SIZE,\n \t\t       TLS_CIPHER_CHACHA20_POLY1305_IV_SIZE);\n \t\tmemcpy(chacha20_poly1305->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_CHACHA20_POLY1305_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval, chacha20_poly1305,\n \t\t\t\tsizeof(*chacha20_poly1305)))\n \t\t\trc = -EFAULT;\n@@ -140,13 +132,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(sm4_gcm_info->iv,\n \t\t       cctx->iv + TLS_CIPHER_SM4_GCM_SALT_SIZE,\n \t\t       TLS_CIPHER_SM4_GCM_IV_SIZE);\n \t\tmemcpy(sm4_gcm_info->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_SM4_GCM_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval, sm4_gcm_info, sizeof(*sm4_gcm_info)))\n \t\t\trc = -EFAULT;\n \t\tbreak;\n@@ -160,13 +150,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(sm4_ccm_info->iv,\n \t\t       cctx->iv + TLS_CIPHER_SM4_CCM_SALT_SIZE,\n \t\t       TLS_CIPHER_SM4_CCM_IV_SIZE);\n \t\tmemcpy(sm4_ccm_info->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_SM4_CCM_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval, sm4_ccm_info, sizeof(*sm4_ccm_info)))\n \t\t\trc = -EFAULT;\n \t\tbreak;\n@@ -182,13 +170,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(crypto_info_aria_gcm_128->iv,\n \t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_128_SALT_SIZE,\n \t\t       TLS_CIPHER_ARIA_GCM_128_IV_SIZE);\n \t\tmemcpy(crypto_info_aria_gcm_128->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_ARIA_GCM_128_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval,\n \t\t\t\t crypto_info_aria_gcm_128,\n \t\t\t\t sizeof(*crypto_info_aria_gcm_128)))\n@@ -206,13 +192,11 @@\n \t\t\trc = -EINVAL;\n \t\t\tgoto out;\n \t\t}\n-\t\tlock_sock(sk);\n \t\tmemcpy(crypto_info_aria_gcm_256->iv,\n \t\t       cctx->iv + TLS_CIPHER_ARIA_GCM_256_SALT_SIZE,\n \t\t       TLS_CIPHER_ARIA_GCM_256_IV_SIZE);\n \t\tmemcpy(crypto_info_aria_gcm_256->rec_seq, cctx->rec_seq,\n \t\t       TLS_CIPHER_ARIA_GCM_256_REC_SEQ_SIZE);\n-\t\trelease_sock(sk);\n \t\tif (copy_to_user(optval,\n \t\t\t\t crypto_info_aria_gcm_256,\n \t\t\t\t sizeof(*crypto_info_aria_gcm_256)))",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);",
                "\t\tlock_sock(sk);",
                "\t\trelease_sock(sk);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "do_tls_getsockopt in net/tls/tls_main.c in the Linux kernel through 6.2.6 lacks a lock_sock call, leading to a race condition (with a resultant use-after-free or NULL pointer dereference).",
        "id": 3982
    },
    {
        "cve_id": "CVE-2019-12818",
        "code_before_change": "int nfc_llcp_send_connect(struct nfc_llcp_sock *sock)\n{\n\tstruct nfc_llcp_local *local;\n\tstruct sk_buff *skb;\n\tu8 *service_name_tlv = NULL, service_name_tlv_length;\n\tu8 *miux_tlv = NULL, miux_tlv_length;\n\tu8 *rw_tlv = NULL, rw_tlv_length, rw;\n\tint err;\n\tu16 size = 0;\n\t__be16 miux;\n\n\tpr_debug(\"Sending CONNECT\\n\");\n\n\tlocal = sock->local;\n\tif (local == NULL)\n\t\treturn -ENODEV;\n\n\tif (sock->service_name != NULL) {\n\t\tservice_name_tlv = nfc_llcp_build_tlv(LLCP_TLV_SN,\n\t\t\t\t\t\t      sock->service_name,\n\t\t\t\t\t\t      sock->service_name_len,\n\t\t\t\t\t\t      &service_name_tlv_length);\n\t\tsize += service_name_tlv_length;\n\t}\n\n\t/* If the socket parameters are not set, use the local ones */\n\tmiux = be16_to_cpu(sock->miux) > LLCP_MAX_MIUX ?\n\t\tlocal->miux : sock->miux;\n\trw = sock->rw > LLCP_MAX_RW ? local->rw : sock->rw;\n\n\tmiux_tlv = nfc_llcp_build_tlv(LLCP_TLV_MIUX, (u8 *)&miux, 0,\n\t\t\t\t      &miux_tlv_length);\n\tsize += miux_tlv_length;\n\n\trw_tlv = nfc_llcp_build_tlv(LLCP_TLV_RW, &rw, 0, &rw_tlv_length);\n\tsize += rw_tlv_length;\n\n\tpr_debug(\"SKB size %d SN length %zu\\n\", size, sock->service_name_len);\n\n\tskb = llcp_allocate_pdu(sock, LLCP_PDU_CONNECT, size);\n\tif (skb == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto error_tlv;\n\t}\n\n\tllcp_add_tlv(skb, service_name_tlv, service_name_tlv_length);\n\tllcp_add_tlv(skb, miux_tlv, miux_tlv_length);\n\tllcp_add_tlv(skb, rw_tlv, rw_tlv_length);\n\n\tskb_queue_tail(&local->tx_queue, skb);\n\n\terr = 0;\n\nerror_tlv:\n\tif (err)\n\t\tpr_err(\"error %d\\n\", err);\n\n\tkfree(service_name_tlv);\n\tkfree(miux_tlv);\n\tkfree(rw_tlv);\n\n\treturn err;\n}",
        "code_after_change": "int nfc_llcp_send_connect(struct nfc_llcp_sock *sock)\n{\n\tstruct nfc_llcp_local *local;\n\tstruct sk_buff *skb;\n\tu8 *service_name_tlv = NULL, service_name_tlv_length;\n\tu8 *miux_tlv = NULL, miux_tlv_length;\n\tu8 *rw_tlv = NULL, rw_tlv_length, rw;\n\tint err;\n\tu16 size = 0;\n\t__be16 miux;\n\n\tpr_debug(\"Sending CONNECT\\n\");\n\n\tlocal = sock->local;\n\tif (local == NULL)\n\t\treturn -ENODEV;\n\n\tif (sock->service_name != NULL) {\n\t\tservice_name_tlv = nfc_llcp_build_tlv(LLCP_TLV_SN,\n\t\t\t\t\t\t      sock->service_name,\n\t\t\t\t\t\t      sock->service_name_len,\n\t\t\t\t\t\t      &service_name_tlv_length);\n\t\tif (!service_name_tlv) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto error_tlv;\n\t\t}\n\t\tsize += service_name_tlv_length;\n\t}\n\n\t/* If the socket parameters are not set, use the local ones */\n\tmiux = be16_to_cpu(sock->miux) > LLCP_MAX_MIUX ?\n\t\tlocal->miux : sock->miux;\n\trw = sock->rw > LLCP_MAX_RW ? local->rw : sock->rw;\n\n\tmiux_tlv = nfc_llcp_build_tlv(LLCP_TLV_MIUX, (u8 *)&miux, 0,\n\t\t\t\t      &miux_tlv_length);\n\tif (!miux_tlv) {\n\t\terr = -ENOMEM;\n\t\tgoto error_tlv;\n\t}\n\tsize += miux_tlv_length;\n\n\trw_tlv = nfc_llcp_build_tlv(LLCP_TLV_RW, &rw, 0, &rw_tlv_length);\n\tif (!rw_tlv) {\n\t\terr = -ENOMEM;\n\t\tgoto error_tlv;\n\t}\n\tsize += rw_tlv_length;\n\n\tpr_debug(\"SKB size %d SN length %zu\\n\", size, sock->service_name_len);\n\n\tskb = llcp_allocate_pdu(sock, LLCP_PDU_CONNECT, size);\n\tif (skb == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto error_tlv;\n\t}\n\n\tllcp_add_tlv(skb, service_name_tlv, service_name_tlv_length);\n\tllcp_add_tlv(skb, miux_tlv, miux_tlv_length);\n\tllcp_add_tlv(skb, rw_tlv, rw_tlv_length);\n\n\tskb_queue_tail(&local->tx_queue, skb);\n\n\terr = 0;\n\nerror_tlv:\n\tif (err)\n\t\tpr_err(\"error %d\\n\", err);\n\n\tkfree(service_name_tlv);\n\tkfree(miux_tlv);\n\tkfree(rw_tlv);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,6 +20,10 @@\n \t\t\t\t\t\t      sock->service_name,\n \t\t\t\t\t\t      sock->service_name_len,\n \t\t\t\t\t\t      &service_name_tlv_length);\n+\t\tif (!service_name_tlv) {\n+\t\t\terr = -ENOMEM;\n+\t\t\tgoto error_tlv;\n+\t\t}\n \t\tsize += service_name_tlv_length;\n \t}\n \n@@ -30,9 +34,17 @@\n \n \tmiux_tlv = nfc_llcp_build_tlv(LLCP_TLV_MIUX, (u8 *)&miux, 0,\n \t\t\t\t      &miux_tlv_length);\n+\tif (!miux_tlv) {\n+\t\terr = -ENOMEM;\n+\t\tgoto error_tlv;\n+\t}\n \tsize += miux_tlv_length;\n \n \trw_tlv = nfc_llcp_build_tlv(LLCP_TLV_RW, &rw, 0, &rw_tlv_length);\n+\tif (!rw_tlv) {\n+\t\terr = -ENOMEM;\n+\t\tgoto error_tlv;\n+\t}\n \tsize += rw_tlv_length;\n \n \tpr_debug(\"SKB size %d SN length %zu\\n\", size, sock->service_name_len);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!service_name_tlv) {",
                "\t\t\terr = -ENOMEM;",
                "\t\t\tgoto error_tlv;",
                "\t\t}",
                "\tif (!miux_tlv) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto error_tlv;",
                "\t}",
                "\tif (!rw_tlv) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto error_tlv;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 4.20.15. The nfc_llcp_build_tlv function in net/nfc/llcp_commands.c may return NULL. If the caller does not check for this, it will trigger a NULL pointer dereference. This will cause denial of service. This affects nfc_llcp_build_gb in net/nfc/llcp_core.c.",
        "id": 1952
    },
    {
        "cve_id": "CVE-2017-18079",
        "code_before_change": "static void i8042_stop(struct serio *serio)\n{\n\tstruct i8042_port *port = serio->port_data;\n\n\tport->exists = false;\n\n\t/*\n\t * We synchronize with both AUX and KBD IRQs because there is\n\t * a (very unlikely) chance that AUX IRQ is raised for KBD port\n\t * and vice versa.\n\t */\n\tsynchronize_irq(I8042_AUX_IRQ);\n\tsynchronize_irq(I8042_KBD_IRQ);\n\tport->serio = NULL;\n}",
        "code_after_change": "static void i8042_stop(struct serio *serio)\n{\n\tstruct i8042_port *port = serio->port_data;\n\n\tspin_lock_irq(&i8042_lock);\n\tport->exists = false;\n\tport->serio = NULL;\n\tspin_unlock_irq(&i8042_lock);\n\n\t/*\n\t * We need to make sure that interrupt handler finishes using\n\t * our serio port before we return from this function.\n\t * We synchronize with both AUX and KBD IRQs because there is\n\t * a (very unlikely) chance that AUX IRQ is raised for KBD port\n\t * and vice versa.\n\t */\n\tsynchronize_irq(I8042_AUX_IRQ);\n\tsynchronize_irq(I8042_KBD_IRQ);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,14 +2,18 @@\n {\n \tstruct i8042_port *port = serio->port_data;\n \n+\tspin_lock_irq(&i8042_lock);\n \tport->exists = false;\n+\tport->serio = NULL;\n+\tspin_unlock_irq(&i8042_lock);\n \n \t/*\n+\t * We need to make sure that interrupt handler finishes using\n+\t * our serio port before we return from this function.\n \t * We synchronize with both AUX and KBD IRQs because there is\n \t * a (very unlikely) chance that AUX IRQ is raised for KBD port\n \t * and vice versa.\n \t */\n \tsynchronize_irq(I8042_AUX_IRQ);\n \tsynchronize_irq(I8042_KBD_IRQ);\n-\tport->serio = NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tspin_lock_irq(&i8042_lock);",
                "\tport->serio = NULL;",
                "\tspin_unlock_irq(&i8042_lock);",
                "\t * We need to make sure that interrupt handler finishes using",
                "\t * our serio port before we return from this function."
            ],
            "deleted": [
                "\tport->serio = NULL;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/input/serio/i8042.c in the Linux kernel before 4.12.4 allows attackers to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact because the port->exists value can change after it is validated.",
        "id": 1390
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "static void destroy_previous_session(struct ksmbd_conn *conn,\n\t\t\t\t     struct ksmbd_user *user, u64 id)\n{\n\tstruct ksmbd_session *prev_sess = ksmbd_session_lookup_slowpath(id);\n\tstruct ksmbd_user *prev_user;\n\tstruct channel *chann;\n\tlong index;\n\n\tif (!prev_sess)\n\t\treturn;\n\n\tprev_user = prev_sess->user;\n\n\tif (!prev_user ||\n\t    strcmp(user->name, prev_user->name) ||\n\t    user->passkey_sz != prev_user->passkey_sz ||\n\t    memcmp(user->passkey, prev_user->passkey, user->passkey_sz))\n\t\treturn;\n\n\tprev_sess->state = SMB2_SESSION_EXPIRED;\n\txa_for_each(&prev_sess->ksmbd_chann_list, index, chann)\n\t\tchann->conn->status = KSMBD_SESS_EXITING;\n}",
        "code_after_change": "static void destroy_previous_session(struct ksmbd_conn *conn,\n\t\t\t\t     struct ksmbd_user *user, u64 id)\n{\n\tstruct ksmbd_session *prev_sess = ksmbd_session_lookup_slowpath(id);\n\tstruct ksmbd_user *prev_user;\n\tstruct channel *chann;\n\tlong index;\n\n\tif (!prev_sess)\n\t\treturn;\n\n\tprev_user = prev_sess->user;\n\n\tif (!prev_user ||\n\t    strcmp(user->name, prev_user->name) ||\n\t    user->passkey_sz != prev_user->passkey_sz ||\n\t    memcmp(user->passkey, prev_user->passkey, user->passkey_sz))\n\t\treturn;\n\n\tprev_sess->state = SMB2_SESSION_EXPIRED;\n\txa_for_each(&prev_sess->ksmbd_chann_list, index, chann)\n\t\tksmbd_conn_set_exiting(chann->conn);\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,5 +19,5 @@\n \n \tprev_sess->state = SMB2_SESSION_EXPIRED;\n \txa_for_each(&prev_sess->ksmbd_chann_list, index, chann)\n-\t\tchann->conn->status = KSMBD_SESS_EXITING;\n+\t\tksmbd_conn_set_exiting(chann->conn);\n }",
        "function_modified_lines": {
            "added": [
                "\t\tksmbd_conn_set_exiting(chann->conn);"
            ],
            "deleted": [
                "\t\tchann->conn->status = KSMBD_SESS_EXITING;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4030
    },
    {
        "cve_id": "CVE-2019-15923",
        "code_before_change": "static int pcd_detect(void)\n{\n\tchar id[18];\n\tint k, unit;\n\tstruct pcd_unit *cd;\n\n\tprintk(\"%s: %s version %s, major %d, nice %d\\n\",\n\t       name, name, PCD_VERSION, major, nice);\n\n\tpar_drv = pi_register_driver(name);\n\tif (!par_drv) {\n\t\tpr_err(\"failed to register %s driver\\n\", name);\n\t\treturn -1;\n\t}\n\n\tk = 0;\n\tif (pcd_drive_count == 0) { /* nothing spec'd - so autoprobe for 1 */\n\t\tcd = pcd;\n\t\tif (pi_init(cd->pi, 1, -1, -1, -1, -1, -1, pcd_buffer,\n\t\t\t    PI_PCD, verbose, cd->name)) {\n\t\t\tif (!pcd_probe(cd, -1, id) && cd->disk) {\n\t\t\t\tcd->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(cd->pi);\n\t\t}\n\t} else {\n\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\t\tint *conf = *drives[unit];\n\t\t\tif (!conf[D_PRT])\n\t\t\t\tcontinue;\n\t\t\tif (!pi_init(cd->pi, 0, conf[D_PRT], conf[D_MOD],\n\t\t\t\t     conf[D_UNI], conf[D_PRO], conf[D_DLY],\n\t\t\t\t     pcd_buffer, PI_PCD, verbose, cd->name)) \n\t\t\t\tcontinue;\n\t\t\tif (!pcd_probe(cd, conf[D_SLV], id) && cd->disk) {\n\t\t\t\tcd->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(cd->pi);\n\t\t}\n\t}\n\tif (k)\n\t\treturn 0;\n\n\tprintk(\"%s: No CD-ROM drive found\\n\", name);\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tblk_cleanup_queue(cd->disk->queue);\n\t\tcd->disk->queue = NULL;\n\t\tblk_mq_free_tag_set(&cd->tag_set);\n\t\tput_disk(cd->disk);\n\t}\n\tpi_unregister_driver(par_drv);\n\treturn -1;\n}",
        "code_after_change": "static int pcd_detect(void)\n{\n\tchar id[18];\n\tint k, unit;\n\tstruct pcd_unit *cd;\n\n\tprintk(\"%s: %s version %s, major %d, nice %d\\n\",\n\t       name, name, PCD_VERSION, major, nice);\n\n\tpar_drv = pi_register_driver(name);\n\tif (!par_drv) {\n\t\tpr_err(\"failed to register %s driver\\n\", name);\n\t\treturn -1;\n\t}\n\n\tk = 0;\n\tif (pcd_drive_count == 0) { /* nothing spec'd - so autoprobe for 1 */\n\t\tcd = pcd;\n\t\tif (pi_init(cd->pi, 1, -1, -1, -1, -1, -1, pcd_buffer,\n\t\t\t    PI_PCD, verbose, cd->name)) {\n\t\t\tif (!pcd_probe(cd, -1, id) && cd->disk) {\n\t\t\t\tcd->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(cd->pi);\n\t\t}\n\t} else {\n\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\t\tint *conf = *drives[unit];\n\t\t\tif (!conf[D_PRT])\n\t\t\t\tcontinue;\n\t\t\tif (!pi_init(cd->pi, 0, conf[D_PRT], conf[D_MOD],\n\t\t\t\t     conf[D_UNI], conf[D_PRO], conf[D_DLY],\n\t\t\t\t     pcd_buffer, PI_PCD, verbose, cd->name)) \n\t\t\t\tcontinue;\n\t\t\tif (!pcd_probe(cd, conf[D_SLV], id) && cd->disk) {\n\t\t\t\tcd->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(cd->pi);\n\t\t}\n\t}\n\tif (k)\n\t\treturn 0;\n\n\tprintk(\"%s: No CD-ROM drive found\\n\", name);\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tif (!cd->disk)\n\t\t\tcontinue;\n\t\tblk_cleanup_queue(cd->disk->queue);\n\t\tcd->disk->queue = NULL;\n\t\tblk_mq_free_tag_set(&cd->tag_set);\n\t\tput_disk(cd->disk);\n\t}\n\tpi_unregister_driver(par_drv);\n\treturn -1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -45,6 +45,8 @@\n \n \tprintk(\"%s: No CD-ROM drive found\\n\", name);\n \tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n+\t\tif (!cd->disk)\n+\t\t\tcontinue;\n \t\tblk_cleanup_queue(cd->disk->queue);\n \t\tcd->disk->queue = NULL;\n \t\tblk_mq_free_tag_set(&cd->tag_set);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!cd->disk)",
                "\t\t\tcontinue;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.9. There is a NULL pointer dereference for a cd data structure if alloc_disk fails in drivers/block/paride/pf.c.",
        "id": 2035
    },
    {
        "cve_id": "CVE-2023-3358",
        "code_before_change": "void *ishtp_cl_get_dma_send_buf(struct ishtp_device *dev,\n\t\t\t\tuint32_t size)\n{\n\tunsigned long\tflags;\n\tint i, j, free;\n\t/* additional slot is needed if there is rem */\n\tint required_slots = (size / DMA_SLOT_SIZE)\n\t\t+ 1 * (size % DMA_SLOT_SIZE != 0);\n\n\tspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\n\tfor (i = 0; i <= (dev->ishtp_dma_num_slots - required_slots); i++) {\n\t\tfree = 1;\n\t\tfor (j = 0; j < required_slots; j++)\n\t\t\tif (dev->ishtp_dma_tx_map[i+j]) {\n\t\t\t\tfree = 0;\n\t\t\t\ti += j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\tif (free) {\n\t\t\t/* mark memory as \"caught\" */\n\t\t\tfor (j = 0; j < required_slots; j++)\n\t\t\t\tdev->ishtp_dma_tx_map[i+j] = 1;\n\t\t\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\t\t\treturn (i * DMA_SLOT_SIZE) +\n\t\t\t\t(unsigned char *)dev->ishtp_host_dma_tx_buf;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\tdev_err(dev->devc, \"No free DMA buffer to send msg\\n\");\n\treturn NULL;\n}",
        "code_after_change": "void *ishtp_cl_get_dma_send_buf(struct ishtp_device *dev,\n\t\t\t\tuint32_t size)\n{\n\tunsigned long\tflags;\n\tint i, j, free;\n\t/* additional slot is needed if there is rem */\n\tint required_slots = (size / DMA_SLOT_SIZE)\n\t\t+ 1 * (size % DMA_SLOT_SIZE != 0);\n\n\tif (!dev->ishtp_dma_tx_map) {\n\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");\n\t\treturn NULL;\n\t}\n\n\tspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\n\tfor (i = 0; i <= (dev->ishtp_dma_num_slots - required_slots); i++) {\n\t\tfree = 1;\n\t\tfor (j = 0; j < required_slots; j++)\n\t\t\tif (dev->ishtp_dma_tx_map[i+j]) {\n\t\t\t\tfree = 0;\n\t\t\t\ti += j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\tif (free) {\n\t\t\t/* mark memory as \"caught\" */\n\t\t\tfor (j = 0; j < required_slots; j++)\n\t\t\t\tdev->ishtp_dma_tx_map[i+j] = 1;\n\t\t\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\t\t\treturn (i * DMA_SLOT_SIZE) +\n\t\t\t\t(unsigned char *)dev->ishtp_host_dma_tx_buf;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\tdev_err(dev->devc, \"No free DMA buffer to send msg\\n\");\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,11 @@\n \t/* additional slot is needed if there is rem */\n \tint required_slots = (size / DMA_SLOT_SIZE)\n \t\t+ 1 * (size % DMA_SLOT_SIZE != 0);\n+\n+\tif (!dev->ishtp_dma_tx_map) {\n+\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");\n+\t\treturn NULL;\n+\t}\n \n \tspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\n \tfor (i = 0; i <= (dev->ishtp_dma_num_slots - required_slots); i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!dev->ishtp_dma_tx_map) {",
                "\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");",
                "\t\treturn NULL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference was found in the Linux kernel's Integrated Sensor Hub (ISH) driver. This issue could allow a local user to crash the system.",
        "id": 4062
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int tfe7090pvr_frontend1_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct i2c_adapter *i2c;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (adap->dev->adapter[0].fe_adap[0].fe == NULL) {\n\t\terr(\"the master dib7090 has to be initialized first\");\n\t\treturn -ENODEV; /* the master device has not been initialized */\n\t}\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\ti2c = state->dib7000p_ops.get_i2c_master(adap->dev->adapter[0].fe_adap[0].fe, DIBX000_I2C_INTERFACE_GPIO_6_7, 1);\n\tif (state->dib7000p_ops.i2c_enumeration(i2c, 1, 0x10, &tfe7090pvr_dib7000p_config[1]) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(i2c, 0x92, &tfe7090pvr_dib7000p_config[1]);\n\tdib0700_set_i2c_speed(adap->dev, 200);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int tfe7090pvr_frontend1_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct i2c_adapter *i2c;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (adap->dev->adapter[0].fe_adap[0].fe == NULL) {\n\t\terr(\"the master dib7090 has to be initialized first\");\n\t\treturn -ENODEV; /* the master device has not been initialized */\n\t}\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\ti2c = state->dib7000p_ops.get_i2c_master(adap->dev->adapter[0].fe_adap[0].fe, DIBX000_I2C_INTERFACE_GPIO_6_7, 1);\n\tif (state->dib7000p_ops.i2c_enumeration(i2c, 1, 0x10, &tfe7090pvr_dib7000p_config[1]) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(i2c, 0x92, &tfe7090pvr_dib7000p_config[1]);\n\tdib0700_set_i2c_speed(adap->dev, 200);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,7 @@\n \ti2c = state->dib7000p_ops.get_i2c_master(adap->dev->adapter[0].fe_adap[0].fe, DIBX000_I2C_INTERFACE_GPIO_6_7, 1);\n \tif (state->dib7000p_ops.i2c_enumeration(i2c, 1, 0x10, &tfe7090pvr_dib7000p_config[1]) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1333
    },
    {
        "cve_id": "CVE-2020-27675",
        "code_before_change": "static void xen_free_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\tlist_del(&info->list);\n\n\tset_info_for_irq(irq, NULL);\n\n\tWARN_ON(info->refcnt > 0);\n\n\tkfree(info);\n\n\t/* Legacy IRQ descriptors are managed by the arch. */\n\tif (irq < nr_legacy_irqs())\n\t\treturn;\n\n\tirq_free_desc(irq);\n}",
        "code_after_change": "static void xen_free_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tunsigned long flags;\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\twrite_lock_irqsave(&evtchn_rwlock, flags);\n\n\tlist_del(&info->list);\n\n\tset_info_for_irq(irq, NULL);\n\n\tWARN_ON(info->refcnt > 0);\n\n\twrite_unlock_irqrestore(&evtchn_rwlock, flags);\n\n\tkfree(info);\n\n\t/* Legacy IRQ descriptors are managed by the arch. */\n\tif (irq < nr_legacy_irqs())\n\t\treturn;\n\n\tirq_free_desc(irq);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,15 +1,20 @@\n static void xen_free_irq(unsigned irq)\n {\n \tstruct irq_info *info = info_for_irq(irq);\n+\tunsigned long flags;\n \n \tif (WARN_ON(!info))\n \t\treturn;\n+\n+\twrite_lock_irqsave(&evtchn_rwlock, flags);\n \n \tlist_del(&info->list);\n \n \tset_info_for_irq(irq, NULL);\n \n \tWARN_ON(info->refcnt > 0);\n+\n+\twrite_unlock_irqrestore(&evtchn_rwlock, flags);\n \n \tkfree(info);\n ",
        "function_modified_lines": {
            "added": [
                "\tunsigned long flags;",
                "",
                "\twrite_lock_irqsave(&evtchn_rwlock, flags);",
                "",
                "\twrite_unlock_irqrestore(&evtchn_rwlock, flags);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-362",
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. drivers/xen/events/events_base.c allows event-channel removal during the event-handling loop (a race condition). This can cause a use-after-free or NULL pointer dereference, as demonstrated by a dom0 crash via events for an in-reconfiguration paravirtualized device, aka CID-073d0552ead5.",
        "id": 2623
    },
    {
        "cve_id": "CVE-2017-12153",
        "code_before_change": "static int nl80211_set_rekey_data(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct cfg80211_registered_device *rdev = info->user_ptr[0];\n\tstruct net_device *dev = info->user_ptr[1];\n\tstruct wireless_dev *wdev = dev->ieee80211_ptr;\n\tstruct nlattr *tb[NUM_NL80211_REKEY_DATA];\n\tstruct cfg80211_gtk_rekey_data rekey_data;\n\tint err;\n\n\tif (!info->attrs[NL80211_ATTR_REKEY_DATA])\n\t\treturn -EINVAL;\n\n\terr = nla_parse_nested(tb, MAX_NL80211_REKEY_DATA,\n\t\t\t       info->attrs[NL80211_ATTR_REKEY_DATA],\n\t\t\t       nl80211_rekey_policy, info->extack);\n\tif (err)\n\t\treturn err;\n\n\tif (nla_len(tb[NL80211_REKEY_DATA_REPLAY_CTR]) != NL80211_REPLAY_CTR_LEN)\n\t\treturn -ERANGE;\n\tif (nla_len(tb[NL80211_REKEY_DATA_KEK]) != NL80211_KEK_LEN)\n\t\treturn -ERANGE;\n\tif (nla_len(tb[NL80211_REKEY_DATA_KCK]) != NL80211_KCK_LEN)\n\t\treturn -ERANGE;\n\n\trekey_data.kek = nla_data(tb[NL80211_REKEY_DATA_KEK]);\n\trekey_data.kck = nla_data(tb[NL80211_REKEY_DATA_KCK]);\n\trekey_data.replay_ctr = nla_data(tb[NL80211_REKEY_DATA_REPLAY_CTR]);\n\n\twdev_lock(wdev);\n\tif (!wdev->current_bss) {\n\t\terr = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tif (!rdev->ops->set_rekey_data) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\terr = rdev_set_rekey_data(rdev, dev, &rekey_data);\n out:\n\twdev_unlock(wdev);\n\treturn err;\n}",
        "code_after_change": "static int nl80211_set_rekey_data(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct cfg80211_registered_device *rdev = info->user_ptr[0];\n\tstruct net_device *dev = info->user_ptr[1];\n\tstruct wireless_dev *wdev = dev->ieee80211_ptr;\n\tstruct nlattr *tb[NUM_NL80211_REKEY_DATA];\n\tstruct cfg80211_gtk_rekey_data rekey_data;\n\tint err;\n\n\tif (!info->attrs[NL80211_ATTR_REKEY_DATA])\n\t\treturn -EINVAL;\n\n\terr = nla_parse_nested(tb, MAX_NL80211_REKEY_DATA,\n\t\t\t       info->attrs[NL80211_ATTR_REKEY_DATA],\n\t\t\t       nl80211_rekey_policy, info->extack);\n\tif (err)\n\t\treturn err;\n\n\tif (!tb[NL80211_REKEY_DATA_REPLAY_CTR] || !tb[NL80211_REKEY_DATA_KEK] ||\n\t    !tb[NL80211_REKEY_DATA_KCK])\n\t\treturn -EINVAL;\n\tif (nla_len(tb[NL80211_REKEY_DATA_REPLAY_CTR]) != NL80211_REPLAY_CTR_LEN)\n\t\treturn -ERANGE;\n\tif (nla_len(tb[NL80211_REKEY_DATA_KEK]) != NL80211_KEK_LEN)\n\t\treturn -ERANGE;\n\tif (nla_len(tb[NL80211_REKEY_DATA_KCK]) != NL80211_KCK_LEN)\n\t\treturn -ERANGE;\n\n\trekey_data.kek = nla_data(tb[NL80211_REKEY_DATA_KEK]);\n\trekey_data.kck = nla_data(tb[NL80211_REKEY_DATA_KCK]);\n\trekey_data.replay_ctr = nla_data(tb[NL80211_REKEY_DATA_REPLAY_CTR]);\n\n\twdev_lock(wdev);\n\tif (!wdev->current_bss) {\n\t\terr = -ENOTCONN;\n\t\tgoto out;\n\t}\n\n\tif (!rdev->ops->set_rekey_data) {\n\t\terr = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\terr = rdev_set_rekey_data(rdev, dev, &rekey_data);\n out:\n\twdev_unlock(wdev);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,6 +16,9 @@\n \tif (err)\n \t\treturn err;\n \n+\tif (!tb[NL80211_REKEY_DATA_REPLAY_CTR] || !tb[NL80211_REKEY_DATA_KEK] ||\n+\t    !tb[NL80211_REKEY_DATA_KCK])\n+\t\treturn -EINVAL;\n \tif (nla_len(tb[NL80211_REKEY_DATA_REPLAY_CTR]) != NL80211_REPLAY_CTR_LEN)\n \t\treturn -ERANGE;\n \tif (nla_len(tb[NL80211_REKEY_DATA_KEK]) != NL80211_KEK_LEN)",
        "function_modified_lines": {
            "added": [
                "\tif (!tb[NL80211_REKEY_DATA_REPLAY_CTR] || !tb[NL80211_REKEY_DATA_KEK] ||",
                "\t    !tb[NL80211_REKEY_DATA_KCK])",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A security flaw was discovered in the nl80211_set_rekey_data() function in net/wireless/nl80211.c in the Linux kernel through 4.13.3. This function does not check whether the required attributes are present in a Netlink request. This request can be issued by a user with the CAP_NET_ADMIN capability and may result in a NULL pointer dereference and system crash.",
        "id": 1256
    },
    {
        "cve_id": "CVE-2020-27675",
        "code_before_change": "static void __xen_evtchn_do_upcall(void)\n{\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\tint cpu = smp_processor_id();\n\n\tdo {\n\t\tvcpu_info->evtchn_upcall_pending = 0;\n\n\t\txen_evtchn_handle_events(cpu);\n\n\t\tBUG_ON(!irqs_disabled());\n\n\t\tvirt_rmb(); /* Hypervisor can set upcall pending. */\n\n\t} while (vcpu_info->evtchn_upcall_pending);\n}",
        "code_after_change": "static void __xen_evtchn_do_upcall(void)\n{\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\tint cpu = smp_processor_id();\n\n\tread_lock(&evtchn_rwlock);\n\n\tdo {\n\t\tvcpu_info->evtchn_upcall_pending = 0;\n\n\t\txen_evtchn_handle_events(cpu);\n\n\t\tBUG_ON(!irqs_disabled());\n\n\t\tvirt_rmb(); /* Hypervisor can set upcall pending. */\n\n\t} while (vcpu_info->evtchn_upcall_pending);\n\n\tread_unlock(&evtchn_rwlock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,8 @@\n {\n \tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n \tint cpu = smp_processor_id();\n+\n+\tread_lock(&evtchn_rwlock);\n \n \tdo {\n \t\tvcpu_info->evtchn_upcall_pending = 0;\n@@ -13,4 +15,6 @@\n \t\tvirt_rmb(); /* Hypervisor can set upcall pending. */\n \n \t} while (vcpu_info->evtchn_upcall_pending);\n+\n+\tread_unlock(&evtchn_rwlock);\n }",
        "function_modified_lines": {
            "added": [
                "",
                "\tread_lock(&evtchn_rwlock);",
                "",
                "\tread_unlock(&evtchn_rwlock);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-362",
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. drivers/xen/events/events_base.c allows event-channel removal during the event-handling loop (a race condition). This can cause a use-after-free or NULL pointer dereference, as demonstrated by a dom0 crash via events for an in-reconfiguration paravirtualized device, aka CID-073d0552ead5.",
        "id": 2625
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int novatd_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *dev = adap->dev;\n\tstruct dib0700_state *st = dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tstk7070pd_init(dev);\n\n\t\t/* turn the power LED on, the other two off (just in case) */\n\t\tdib0700_set_gpio(dev, GPIO0, GPIO_OUT, 0);\n\t\tdib0700_set_gpio(dev, GPIO1, GPIO_OUT, 0);\n\t\tdib0700_set_gpio(dev, GPIO2, GPIO_OUT, 1);\n\n\t\tif (state->dib7000p_ops.i2c_enumeration(&dev->i2c_adap, 2, 18,\n\t\t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t\t    __func__);\n\t\t\tdvb_detach(&state->dib7000p_ops);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&dev->i2c_adap,\n\t\t\tadap->id == 0 ? 0x80 : 0x82,\n\t\t\t&stk7070pd_dib7000p_config[adap->id]);\n\n\tif (adap->fe_adap[0].fe == NULL)\n\t\treturn -ENODEV;\n\n\tst->read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = novatd_read_status_override;\n\tst->sleep = adap->fe_adap[0].fe->ops.sleep;\n\tadap->fe_adap[0].fe->ops.sleep = novatd_sleep_override;\n\n\treturn 0;\n}",
        "code_after_change": "static int novatd_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dvb_usb_device *dev = adap->dev;\n\tstruct dib0700_state *st = dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tstk7070pd_init(dev);\n\n\t\t/* turn the power LED on, the other two off (just in case) */\n\t\tdib0700_set_gpio(dev, GPIO0, GPIO_OUT, 0);\n\t\tdib0700_set_gpio(dev, GPIO1, GPIO_OUT, 0);\n\t\tdib0700_set_gpio(dev, GPIO2, GPIO_OUT, 1);\n\n\t\tif (state->dib7000p_ops.i2c_enumeration(&dev->i2c_adap, 2, 18,\n\t\t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t\t    __func__);\n\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&dev->i2c_adap,\n\t\t\tadap->id == 0 ? 0x80 : 0x82,\n\t\t\t&stk7070pd_dib7000p_config[adap->id]);\n\n\tif (adap->fe_adap[0].fe == NULL)\n\t\treturn -ENODEV;\n\n\tst->read_status = adap->fe_adap[0].fe->ops.read_status;\n\tadap->fe_adap[0].fe->ops.read_status = novatd_read_status_override;\n\tst->sleep = adap->fe_adap[0].fe->ops.sleep;\n\tadap->fe_adap[0].fe->ops.sleep = novatd_sleep_override;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \t\t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n \t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n \t\t\t    __func__);\n-\t\t\tdvb_detach(&state->dib7000p_ops);\n+\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\t\treturn -ENODEV;\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1338
    },
    {
        "cve_id": "CVE-2019-19815",
        "code_before_change": "static inline bool f2fs_force_buffered_io(struct inode *inode,\n\t\t\t\tstruct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tint rw = iov_iter_rw(iter);\n\n\tif (f2fs_post_read_required(inode))\n\t\treturn true;\n\tif (f2fs_is_multi_device(sbi))\n\t\treturn true;\n\t/*\n\t * for blkzoned device, fallback direct IO to buffered IO, so\n\t * all IOs can be serialized by log-structured write.\n\t */\n\tif (f2fs_sb_has_blkzoned(sbi))\n\t\treturn true;\n\tif (test_opt(sbi, LFS) && (rw == WRITE) &&\n\t\t\t\tblock_unaligned_IO(inode, iocb, iter))\n\t\treturn true;\n\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED))\n\t\treturn true;\n\n\treturn false;\n}",
        "code_after_change": "static inline bool f2fs_force_buffered_io(struct inode *inode,\n\t\t\t\tstruct kiocb *iocb, struct iov_iter *iter)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tint rw = iov_iter_rw(iter);\n\n\tif (f2fs_post_read_required(inode))\n\t\treturn true;\n\tif (f2fs_is_multi_device(sbi))\n\t\treturn true;\n\t/*\n\t * for blkzoned device, fallback direct IO to buffered IO, so\n\t * all IOs can be serialized by log-structured write.\n\t */\n\tif (f2fs_sb_has_blkzoned(sbi))\n\t\treturn true;\n\tif (test_opt(sbi, LFS) && (rw == WRITE) &&\n\t\t\t\tblock_unaligned_IO(inode, iocb, iter))\n\t\treturn true;\n\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED) &&\n\t\t\t\t\t!(inode->i_flags & S_SWAPFILE))\n\t\treturn true;\n\n\treturn false;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,7 +17,8 @@\n \tif (test_opt(sbi, LFS) && (rw == WRITE) &&\n \t\t\t\tblock_unaligned_IO(inode, iocb, iter))\n \t\treturn true;\n-\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED))\n+\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED) &&\n+\t\t\t\t\t!(inode->i_flags & S_SWAPFILE))\n \t\treturn true;\n \n \treturn false;",
        "function_modified_lines": {
            "added": [
                "\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED) &&",
                "\t\t\t\t\t!(inode->i_flags & S_SWAPFILE))"
            ],
            "deleted": [
                "\tif (is_sbi_flag_set(F2FS_I_SB(inode), SBI_CP_DISABLED))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted f2fs filesystem image can cause a NULL pointer dereference in f2fs_recover_fsync_data in fs/f2fs/recovery.c. This is related to F2FS_P_SB in fs/f2fs/f2fs.h.",
        "id": 2254
    },
    {
        "cve_id": "CVE-2022-1671",
        "code_before_change": "static void rxrpc_free_preparse_s(struct key_preparsed_payload *prep)\n{\n\tconst struct rxrpc_security *sec = prep->payload.data[1];\n\n\tif (sec)\n\t\tsec->free_preparse_server_key(prep);\n}",
        "code_after_change": "static void rxrpc_free_preparse_s(struct key_preparsed_payload *prep)\n{\n\tconst struct rxrpc_security *sec = prep->payload.data[1];\n\n\tif (sec && sec->free_preparse_server_key)\n\t\tsec->free_preparse_server_key(prep);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,6 @@\n {\n \tconst struct rxrpc_security *sec = prep->payload.data[1];\n \n-\tif (sec)\n+\tif (sec && sec->free_preparse_server_key)\n \t\tsec->free_preparse_server_key(prep);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (sec && sec->free_preparse_server_key)"
            ],
            "deleted": [
                "\tif (sec)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in rxrpc_preparse_s in net/rxrpc/server_key.c in the Linux kernel. This flaw allows a local attacker to crash the system or leak internal kernel information.",
        "id": 3273
    },
    {
        "cve_id": "CVE-2022-3105",
        "code_before_change": "static int uapi_finalize(struct uverbs_api *uapi)\n{\n\tconst struct uverbs_api_write_method **data;\n\tunsigned long max_write_ex = 0;\n\tunsigned long max_write = 0;\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tint rc;\n\tint i;\n\n\tradix_tree_for_each_slot (slot, &uapi->radix, &iter, 0) {\n\t\tstruct uverbs_api_ioctl_method *method_elm =\n\t\t\trcu_dereference_protected(*slot, true);\n\n\t\tif (uapi_key_is_ioctl_method(iter.index)) {\n\t\t\trc = uapi_finalize_ioctl_method(uapi, method_elm,\n\t\t\t\t\t\t\titer.index);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t}\n\n\t\tif (uapi_key_is_write_method(iter.index))\n\t\t\tmax_write = max(max_write,\n\t\t\t\t\titer.index & UVERBS_API_ATTR_KEY_MASK);\n\t\tif (uapi_key_is_write_ex_method(iter.index))\n\t\t\tmax_write_ex =\n\t\t\t\tmax(max_write_ex,\n\t\t\t\t    iter.index & UVERBS_API_ATTR_KEY_MASK);\n\t}\n\n\tuapi->notsupp_method.handler = ib_uverbs_notsupp;\n\tuapi->num_write = max_write + 1;\n\tuapi->num_write_ex = max_write_ex + 1;\n\tdata = kmalloc_array(uapi->num_write + uapi->num_write_ex,\n\t\t\t     sizeof(*uapi->write_methods), GFP_KERNEL);\n\tfor (i = 0; i != uapi->num_write + uapi->num_write_ex; i++)\n\t\tdata[i] = &uapi->notsupp_method;\n\tuapi->write_methods = data;\n\tuapi->write_ex_methods = data + uapi->num_write;\n\n\tradix_tree_for_each_slot (slot, &uapi->radix, &iter, 0) {\n\t\tif (uapi_key_is_write_method(iter.index))\n\t\t\tuapi->write_methods[iter.index &\n\t\t\t\t\t    UVERBS_API_ATTR_KEY_MASK] =\n\t\t\t\trcu_dereference_protected(*slot, true);\n\t\tif (uapi_key_is_write_ex_method(iter.index))\n\t\t\tuapi->write_ex_methods[iter.index &\n\t\t\t\t\t       UVERBS_API_ATTR_KEY_MASK] =\n\t\t\t\trcu_dereference_protected(*slot, true);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int uapi_finalize(struct uverbs_api *uapi)\n{\n\tconst struct uverbs_api_write_method **data;\n\tunsigned long max_write_ex = 0;\n\tunsigned long max_write = 0;\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tint rc;\n\tint i;\n\n\tradix_tree_for_each_slot (slot, &uapi->radix, &iter, 0) {\n\t\tstruct uverbs_api_ioctl_method *method_elm =\n\t\t\trcu_dereference_protected(*slot, true);\n\n\t\tif (uapi_key_is_ioctl_method(iter.index)) {\n\t\t\trc = uapi_finalize_ioctl_method(uapi, method_elm,\n\t\t\t\t\t\t\titer.index);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t}\n\n\t\tif (uapi_key_is_write_method(iter.index))\n\t\t\tmax_write = max(max_write,\n\t\t\t\t\titer.index & UVERBS_API_ATTR_KEY_MASK);\n\t\tif (uapi_key_is_write_ex_method(iter.index))\n\t\t\tmax_write_ex =\n\t\t\t\tmax(max_write_ex,\n\t\t\t\t    iter.index & UVERBS_API_ATTR_KEY_MASK);\n\t}\n\n\tuapi->notsupp_method.handler = ib_uverbs_notsupp;\n\tuapi->num_write = max_write + 1;\n\tuapi->num_write_ex = max_write_ex + 1;\n\tdata = kmalloc_array(uapi->num_write + uapi->num_write_ex,\n\t\t\t     sizeof(*uapi->write_methods), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i != uapi->num_write + uapi->num_write_ex; i++)\n\t\tdata[i] = &uapi->notsupp_method;\n\tuapi->write_methods = data;\n\tuapi->write_ex_methods = data + uapi->num_write;\n\n\tradix_tree_for_each_slot (slot, &uapi->radix, &iter, 0) {\n\t\tif (uapi_key_is_write_method(iter.index))\n\t\t\tuapi->write_methods[iter.index &\n\t\t\t\t\t    UVERBS_API_ATTR_KEY_MASK] =\n\t\t\t\trcu_dereference_protected(*slot, true);\n\t\tif (uapi_key_is_write_ex_method(iter.index))\n\t\t\tuapi->write_ex_methods[iter.index &\n\t\t\t\t\t       UVERBS_API_ATTR_KEY_MASK] =\n\t\t\t\trcu_dereference_protected(*slot, true);\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -33,6 +33,9 @@\n \tuapi->num_write_ex = max_write_ex + 1;\n \tdata = kmalloc_array(uapi->num_write + uapi->num_write_ex,\n \t\t\t     sizeof(*uapi->write_methods), GFP_KERNEL);\n+\tif (!data)\n+\t\treturn -ENOMEM;\n+\n \tfor (i = 0; i != uapi->num_write + uapi->num_write_ex; i++)\n \t\tdata[i] = &uapi->notsupp_method;\n \tuapi->write_methods = data;",
        "function_modified_lines": {
            "added": [
                "\tif (!data)",
                "\t\treturn -ENOMEM;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. uapi_finalize in drivers/infiniband/core/uverbs_uapi.c lacks check of kmalloc_array().",
        "id": 3550
    },
    {
        "cve_id": "CVE-2018-1094",
        "code_before_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct dax_device *dax_dev = fs_dax_get_by_bdev(sb->s_bdev);\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_daxdev = dax_dev;\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb) ||\n\t    ext4_has_feature_ea_inode(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb) || ext4_has_feature_ea_inode(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (ext4_has_feature_encrypt(sb)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"encrypted files will use data=ordered \"\n\t\t\t\t \"instead of data journaling mode\");\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? SB_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\t/*\n\t\t * ea_inode feature uses l_i_version field which is not\n\t\t * available in HURD_COMPAT mode.\n\t\t */\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"ea_inode feature is not supported for Hurd\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext[34] filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext4 filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb_rdonly(sb))))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\tif (ext4_has_feature_inline_data(sb)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot use DAX on a filesystem\"\n\t\t\t\t\t\" that may contain inline data\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"DAX unsupported by block device. Turning off DAX.\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) > db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\t/* Pre-read the descriptors into the buffer cache */\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsb_breadahead(sb, block);\n\t}\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\n\ttimer_setup(&sbi->s_err_report, print_daily_error_info, 0);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tsb->s_cop = &ext4_cryptops;\n#endif\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(&sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !sb_rdonly(sb))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\terr = ext4_load_journal(sb, es, journal_devnum);\n\t\tif (err)\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !sb_rdonly(sb) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\"journal_async_commit in data=ordered mode\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tif (!test_opt(sb, NO_MBCACHE)) {\n\t\tsbi->s_ea_block_cache = ext4_xattr_create_cache();\n\t\tif (!sbi->s_ea_block_cache) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Failed to create ea_block_cache\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\tsbi->s_ea_inode_cache = ext4_xattr_create_cache();\n\t\t\tif (!sbi->s_ea_inode_cache) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Failed to create ea_inode_cache\");\n\t\t\t\tgoto failed_mount_wq;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !sb_rdonly(sb) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb_rdonly(sb)))\n\t\tsb->s_flags |= SB_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    sbi->s_want_extra_isize == 0) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !sb_rdonly(sb)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_ea_inode_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_inode_cache);\n\t\tsbi->s_ea_inode_cache = NULL;\n\t}\n\tif (sbi->s_ea_block_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_block_cache);\n\t\tsbi->s_ea_block_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\tfs_put_dax(dax_dev);\n\treturn err ? err : ret;\n}",
        "code_after_change": "static int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct dax_device *dax_dev = fs_dax_get_by_bdev(sb->s_bdev);\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_daxdev = dax_dev;\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\tsbi->s_chksum_driver = NULL;\n\t\tgoto failed_mount;\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb) || ext4_has_feature_ea_inode(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (ext4_has_feature_encrypt(sb)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"encrypted files will use data=ordered \"\n\t\t\t\t \"instead of data journaling mode\");\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~SB_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? SB_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\t/*\n\t\t * ea_inode feature uses l_i_version field which is not\n\t\t * available in HURD_COMPAT mode.\n\t\t */\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"ea_inode feature is not supported for Hurd\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext[34] filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\t/*\n\t\t\t * If we're probing be silent, if this looks like\n\t\t\t * it's actually an ext4 filesystem.\n\t\t\t */\n\t\t\tif (silent && ext4_feature_set_ok(sb, sb_rdonly(sb)))\n\t\t\t\tgoto failed_mount;\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb_rdonly(sb))))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\tif (ext4_has_feature_inline_data(sb)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot use DAX on a filesystem\"\n\t\t\t\t\t\" that may contain inline data\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\"DAX unsupported by block device. Turning off DAX.\");\n\t\t\tsbi->s_mount_opt &= ~EXT4_MOUNT_DAX;\n\t\t}\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!sb_rdonly(sb))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) > db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\t/* Pre-read the descriptors into the buffer cache */\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsb_breadahead(sb, block);\n\t}\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\n\ttimer_setup(&sbi->s_err_report, print_daily_error_info, 0);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tsb->s_cop = &ext4_cryptops;\n#endif\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(&sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !sb_rdonly(sb))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\terr = ext4_load_journal(sb, es, journal_devnum);\n\t\tif (err)\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !sb_rdonly(sb) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\"journal_async_commit in data=ordered mode\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tif (!test_opt(sb, NO_MBCACHE)) {\n\t\tsbi->s_ea_block_cache = ext4_xattr_create_cache();\n\t\tif (!sbi->s_ea_block_cache) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Failed to create ea_block_cache\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\n\t\tif (ext4_has_feature_ea_inode(sb)) {\n\t\t\tsbi->s_ea_inode_cache = ext4_xattr_create_cache();\n\t\t\tif (!sbi->s_ea_inode_cache) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Failed to create ea_inode_cache\");\n\t\t\t\tgoto failed_mount_wq;\n\t\t\t}\n\t\t}\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !sb_rdonly(sb) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb_rdonly(sb)))\n\t\tsb->s_flags |= SB_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    sbi->s_want_extra_isize == 0) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !sb_rdonly(sb)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_ea_inode_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_inode_cache);\n\t\tsbi->s_ea_inode_cache = NULL;\n\t}\n\tif (sbi->s_ea_block_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_ea_block_cache);\n\t\tsbi->s_ea_block_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\tfs_put_dax(dax_dev);\n\treturn err ? err : ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -92,15 +92,12 @@\n \t}\n \n \t/* Load the checksum driver */\n-\tif (ext4_has_feature_metadata_csum(sb) ||\n-\t    ext4_has_feature_ea_inode(sb)) {\n-\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n-\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n-\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n-\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n-\t\t\tsbi->s_chksum_driver = NULL;\n-\t\t\tgoto failed_mount;\n-\t\t}\n+\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n+\tif (IS_ERR(sbi->s_chksum_driver)) {\n+\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n+\t\tret = PTR_ERR(sbi->s_chksum_driver);\n+\t\tsbi->s_chksum_driver = NULL;\n+\t\tgoto failed_mount;\n \t}\n \n \t/* Check superblock checksum */",
        "function_modified_lines": {
            "added": [
                "\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);",
                "\tif (IS_ERR(sbi->s_chksum_driver)) {",
                "\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");",
                "\t\tret = PTR_ERR(sbi->s_chksum_driver);",
                "\t\tsbi->s_chksum_driver = NULL;",
                "\t\tgoto failed_mount;"
            ],
            "deleted": [
                "\tif (ext4_has_feature_metadata_csum(sb) ||",
                "\t    ext4_has_feature_ea_inode(sb)) {",
                "\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);",
                "\t\tif (IS_ERR(sbi->s_chksum_driver)) {",
                "\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");",
                "\t\t\tret = PTR_ERR(sbi->s_chksum_driver);",
                "\t\t\tsbi->s_chksum_driver = NULL;",
                "\t\t\tgoto failed_mount;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel through 4.15.15 does not always initialize the crc32c checksum driver, which allows attackers to cause a denial of service (ext4_xattr_inode_hash NULL pointer dereference and system crash) via a crafted ext4 image.",
        "id": 1628
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_reg_type(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  const u32 *arg_btf_id)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected, type = reg->type;\n\tconst struct bpf_reg_types *compatible;\n\tint i, j;\n\n\tcompatible = compatible_reg_types[base_type(arg_type)];\n\tif (!compatible) {\n\t\tverbose(env, \"verifier internal error: unsupported arg type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(compatible->types); i++) {\n\t\texpected = compatible->types[i];\n\t\tif (expected == NOT_INIT)\n\t\t\tbreak;\n\n\t\tif (type == expected)\n\t\t\tgoto found;\n\t}\n\n\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str[type]);\n\tfor (j = 0; j + 1 < i; j++)\n\t\tverbose(env, \"%s, \", reg_type_str[compatible->types[j]]);\n\tverbose(env, \"%s\\n\", reg_type_str[compatible->types[j]]);\n\treturn -EACCES;\n\nfound:\n\tif (type == PTR_TO_BTF_ID) {\n\t\tif (!arg_btf_id) {\n\t\t\tif (!compatible->btf_id) {\n\t\t\t\tverbose(env, \"verifier internal error: missing arg compatible BTF ID\\n\");\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\targ_btf_id = compatible->btf_id;\n\t\t}\n\n\t\tif (!btf_struct_ids_match(&env->log, reg->btf, reg->btf_id, reg->off,\n\t\t\t\t\t  btf_vmlinux, *arg_btf_id)) {\n\t\t\tverbose(env, \"R%d is of type %s but %s is expected\\n\",\n\t\t\t\tregno, kernel_type_name(reg->btf, reg->btf_id),\n\t\t\t\tkernel_type_name(btf_vmlinux, *arg_btf_id));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n\t\t\tverbose(env, \"R%d is a pointer to in-kernel struct with non-zero offset\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int check_reg_type(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  const u32 *arg_btf_id)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected, type = reg->type;\n\tconst struct bpf_reg_types *compatible;\n\tint i, j;\n\n\tcompatible = compatible_reg_types[base_type(arg_type)];\n\tif (!compatible) {\n\t\tverbose(env, \"verifier internal error: unsupported arg type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(compatible->types); i++) {\n\t\texpected = compatible->types[i];\n\t\tif (expected == NOT_INIT)\n\t\t\tbreak;\n\n\t\tif (type == expected)\n\t\t\tgoto found;\n\t}\n\n\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str(env, type));\n\tfor (j = 0; j + 1 < i; j++)\n\t\tverbose(env, \"%s, \", reg_type_str(env, compatible->types[j]));\n\tverbose(env, \"%s\\n\", reg_type_str(env, compatible->types[j]));\n\treturn -EACCES;\n\nfound:\n\tif (type == PTR_TO_BTF_ID) {\n\t\tif (!arg_btf_id) {\n\t\t\tif (!compatible->btf_id) {\n\t\t\t\tverbose(env, \"verifier internal error: missing arg compatible BTF ID\\n\");\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\targ_btf_id = compatible->btf_id;\n\t\t}\n\n\t\tif (!btf_struct_ids_match(&env->log, reg->btf, reg->btf_id, reg->off,\n\t\t\t\t\t  btf_vmlinux, *arg_btf_id)) {\n\t\t\tverbose(env, \"R%d is of type %s but %s is expected\\n\",\n\t\t\t\tregno, kernel_type_name(reg->btf, reg->btf_id),\n\t\t\t\tkernel_type_name(btf_vmlinux, *arg_btf_id));\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (!tnum_is_const(reg->var_off) || reg->var_off.value) {\n\t\t\tverbose(env, \"R%d is a pointer to in-kernel struct with non-zero offset\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,10 +22,10 @@\n \t\t\tgoto found;\n \t}\n \n-\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str[type]);\n+\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str(env, type));\n \tfor (j = 0; j + 1 < i; j++)\n-\t\tverbose(env, \"%s, \", reg_type_str[compatible->types[j]]);\n-\tverbose(env, \"%s\\n\", reg_type_str[compatible->types[j]]);\n+\t\tverbose(env, \"%s, \", reg_type_str(env, compatible->types[j]));\n+\tverbose(env, \"%s\\n\", reg_type_str(env, compatible->types[j]));\n \treturn -EACCES;\n \n found:",
        "function_modified_lines": {
            "added": [
                "\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str(env, type));",
                "\t\tverbose(env, \"%s, \", reg_type_str(env, compatible->types[j]));",
                "\tverbose(env, \"%s\\n\", reg_type_str(env, compatible->types[j]));"
            ],
            "deleted": [
                "\tverbose(env, \"R%d type=%s expected=\", regno, reg_type_str[type]);",
                "\t\tverbose(env, \"%s, \", reg_type_str[compatible->types[j]]);",
                "\tverbose(env, \"%s\\n\", reg_type_str[compatible->types[j]]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3450
    },
    {
        "cve_id": "CVE-2020-27830",
        "code_before_change": "static int spk_ttyio_ldisc_open(struct tty_struct *tty)\n{\n\tstruct spk_ldisc_data *ldisc_data;\n\n\tif (!tty->ops->write)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&speakup_tty_mutex);\n\tif (speakup_tty) {\n\t\tmutex_unlock(&speakup_tty_mutex);\n\t\treturn -EBUSY;\n\t}\n\tspeakup_tty = tty;\n\n\tldisc_data = kmalloc(sizeof(*ldisc_data), GFP_KERNEL);\n\tif (!ldisc_data) {\n\t\tspeakup_tty = NULL;\n\t\tmutex_unlock(&speakup_tty_mutex);\n\t\treturn -ENOMEM;\n\t}\n\n\tinit_completion(&ldisc_data->completion);\n\tldisc_data->buf_free = true;\n\tspeakup_tty->disc_data = ldisc_data;\n\tmutex_unlock(&speakup_tty_mutex);\n\n\treturn 0;\n}",
        "code_after_change": "static int spk_ttyio_ldisc_open(struct tty_struct *tty)\n{\n\tstruct spk_ldisc_data *ldisc_data;\n\n\tif (tty != speakup_tty)\n\t\t/* Somebody tried to use this line discipline outside speakup */\n\t\treturn -ENODEV;\n\n\tif (!tty->ops->write)\n\t\treturn -EOPNOTSUPP;\n\n\tldisc_data = kmalloc(sizeof(*ldisc_data), GFP_KERNEL);\n\tif (!ldisc_data)\n\t\treturn -ENOMEM;\n\n\tinit_completion(&ldisc_data->completion);\n\tldisc_data->buf_free = true;\n\ttty->disc_data = ldisc_data;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,27 +2,20 @@\n {\n \tstruct spk_ldisc_data *ldisc_data;\n \n+\tif (tty != speakup_tty)\n+\t\t/* Somebody tried to use this line discipline outside speakup */\n+\t\treturn -ENODEV;\n+\n \tif (!tty->ops->write)\n \t\treturn -EOPNOTSUPP;\n \n-\tmutex_lock(&speakup_tty_mutex);\n-\tif (speakup_tty) {\n-\t\tmutex_unlock(&speakup_tty_mutex);\n-\t\treturn -EBUSY;\n-\t}\n-\tspeakup_tty = tty;\n-\n \tldisc_data = kmalloc(sizeof(*ldisc_data), GFP_KERNEL);\n-\tif (!ldisc_data) {\n-\t\tspeakup_tty = NULL;\n-\t\tmutex_unlock(&speakup_tty_mutex);\n+\tif (!ldisc_data)\n \t\treturn -ENOMEM;\n-\t}\n \n \tinit_completion(&ldisc_data->completion);\n \tldisc_data->buf_free = true;\n-\tspeakup_tty->disc_data = ldisc_data;\n-\tmutex_unlock(&speakup_tty_mutex);\n+\ttty->disc_data = ldisc_data;\n \n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (tty != speakup_tty)",
                "\t\t/* Somebody tried to use this line discipline outside speakup */",
                "\t\treturn -ENODEV;",
                "",
                "\tif (!ldisc_data)",
                "\ttty->disc_data = ldisc_data;"
            ],
            "deleted": [
                "\tmutex_lock(&speakup_tty_mutex);",
                "\tif (speakup_tty) {",
                "\t\tmutex_unlock(&speakup_tty_mutex);",
                "\t\treturn -EBUSY;",
                "\t}",
                "\tspeakup_tty = tty;",
                "",
                "\tif (!ldisc_data) {",
                "\t\tspeakup_tty = NULL;",
                "\t\tmutex_unlock(&speakup_tty_mutex);",
                "\t}",
                "\tspeakup_tty->disc_data = ldisc_data;",
                "\tmutex_unlock(&speakup_tty_mutex);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel where in the spk_ttyio_receive_buf2() function, it would dereference spk_ttyio_synth without checking whether it is NULL or not, and may lead to a NULL-ptr deref crash.",
        "id": 2639
    },
    {
        "cve_id": "CVE-2023-4459",
        "code_before_change": "static void\nvmxnet3_rq_cleanup(struct vmxnet3_rx_queue *rq,\n\t\t   struct vmxnet3_adapter *adapter)\n{\n\tu32 i, ring_idx;\n\tstruct Vmxnet3_RxDesc *rxd;\n\n\tfor (ring_idx = 0; ring_idx < 2; ring_idx++) {\n\t\tfor (i = 0; i < rq->rx_ring[ring_idx].size; i++) {\n#ifdef __BIG_ENDIAN_BITFIELD\n\t\t\tstruct Vmxnet3_RxDesc rxDesc;\n#endif\n\t\t\tvmxnet3_getRxDesc(rxd,\n\t\t\t\t&rq->rx_ring[ring_idx].base[i].rxd, &rxDesc);\n\n\t\t\tif (rxd->btype == VMXNET3_RXD_BTYPE_HEAD &&\n\t\t\t\t\trq->buf_info[ring_idx][i].skb) {\n\t\t\t\tdma_unmap_single(&adapter->pdev->dev, rxd->addr,\n\t\t\t\t\t\t rxd->len, DMA_FROM_DEVICE);\n\t\t\t\tdev_kfree_skb(rq->buf_info[ring_idx][i].skb);\n\t\t\t\trq->buf_info[ring_idx][i].skb = NULL;\n\t\t\t} else if (rxd->btype == VMXNET3_RXD_BTYPE_BODY &&\n\t\t\t\t\trq->buf_info[ring_idx][i].page) {\n\t\t\t\tdma_unmap_page(&adapter->pdev->dev, rxd->addr,\n\t\t\t\t\t       rxd->len, DMA_FROM_DEVICE);\n\t\t\t\tput_page(rq->buf_info[ring_idx][i].page);\n\t\t\t\trq->buf_info[ring_idx][i].page = NULL;\n\t\t\t}\n\t\t}\n\n\t\trq->rx_ring[ring_idx].gen = VMXNET3_INIT_GEN;\n\t\trq->rx_ring[ring_idx].next2fill =\n\t\t\t\t\trq->rx_ring[ring_idx].next2comp = 0;\n\t}\n\n\trq->comp_ring.gen = VMXNET3_INIT_GEN;\n\trq->comp_ring.next2proc = 0;\n}",
        "code_after_change": "static void\nvmxnet3_rq_cleanup(struct vmxnet3_rx_queue *rq,\n\t\t   struct vmxnet3_adapter *adapter)\n{\n\tu32 i, ring_idx;\n\tstruct Vmxnet3_RxDesc *rxd;\n\n\t/* ring has already been cleaned up */\n\tif (!rq->rx_ring[0].base)\n\t\treturn;\n\n\tfor (ring_idx = 0; ring_idx < 2; ring_idx++) {\n\t\tfor (i = 0; i < rq->rx_ring[ring_idx].size; i++) {\n#ifdef __BIG_ENDIAN_BITFIELD\n\t\t\tstruct Vmxnet3_RxDesc rxDesc;\n#endif\n\t\t\tvmxnet3_getRxDesc(rxd,\n\t\t\t\t&rq->rx_ring[ring_idx].base[i].rxd, &rxDesc);\n\n\t\t\tif (rxd->btype == VMXNET3_RXD_BTYPE_HEAD &&\n\t\t\t\t\trq->buf_info[ring_idx][i].skb) {\n\t\t\t\tdma_unmap_single(&adapter->pdev->dev, rxd->addr,\n\t\t\t\t\t\t rxd->len, DMA_FROM_DEVICE);\n\t\t\t\tdev_kfree_skb(rq->buf_info[ring_idx][i].skb);\n\t\t\t\trq->buf_info[ring_idx][i].skb = NULL;\n\t\t\t} else if (rxd->btype == VMXNET3_RXD_BTYPE_BODY &&\n\t\t\t\t\trq->buf_info[ring_idx][i].page) {\n\t\t\t\tdma_unmap_page(&adapter->pdev->dev, rxd->addr,\n\t\t\t\t\t       rxd->len, DMA_FROM_DEVICE);\n\t\t\t\tput_page(rq->buf_info[ring_idx][i].page);\n\t\t\t\trq->buf_info[ring_idx][i].page = NULL;\n\t\t\t}\n\t\t}\n\n\t\trq->rx_ring[ring_idx].gen = VMXNET3_INIT_GEN;\n\t\trq->rx_ring[ring_idx].next2fill =\n\t\t\t\t\trq->rx_ring[ring_idx].next2comp = 0;\n\t}\n\n\trq->comp_ring.gen = VMXNET3_INIT_GEN;\n\trq->comp_ring.next2proc = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,10 @@\n {\n \tu32 i, ring_idx;\n \tstruct Vmxnet3_RxDesc *rxd;\n+\n+\t/* ring has already been cleaned up */\n+\tif (!rq->rx_ring[0].base)\n+\t\treturn;\n \n \tfor (ring_idx = 0; ring_idx < 2; ring_idx++) {\n \t\tfor (i = 0; i < rq->rx_ring[ring_idx].size; i++) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* ring has already been cleaned up */",
                "\tif (!rq->rx_ring[0].base)",
                "\t\treturn;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in vmxnet3_rq_cleanup in drivers/net/vmxnet3/vmxnet3_drv.c in the networking sub-component in vmxnet3 in the Linux Kernel. This issue may allow a local attacker with normal user privilege to cause a denial of service due to a missing sanity check during cleanup.",
        "id": 4216
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int tfe7090pvr_frontend0_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* The TFE7090 requires the dib0700 to not be in master mode */\n\tst->disable_streaming_master_mode = 1;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\t/* initialize IC 0 */\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x20, &tfe7090pvr_dib7000p_config[0]) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tdib0700_set_i2c_speed(adap->dev, 340);\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x90, &tfe7090pvr_dib7000p_config[0]);\n\tif (adap->fe_adap[0].fe == NULL)\n\t\treturn -ENODEV;\n\n\tstate->dib7000p_ops.slave_reset(adap->fe_adap[0].fe);\n\n\treturn 0;\n}",
        "code_after_change": "static int tfe7090pvr_frontend0_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* The TFE7090 requires the dib0700 to not be in master mode */\n\tst->disable_streaming_master_mode = 1;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\t/* initialize IC 0 */\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x20, &tfe7090pvr_dib7000p_config[0]) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tdib0700_set_i2c_speed(adap->dev, 340);\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x90, &tfe7090pvr_dib7000p_config[0]);\n\tif (adap->fe_adap[0].fe == NULL)\n\t\treturn -ENODEV;\n\n\tstate->dib7000p_ops.slave_reset(adap->fe_adap[0].fe);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,7 +24,7 @@\n \t/* initialize IC 0 */\n \tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x20, &tfe7090pvr_dib7000p_config[0]) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1335
    },
    {
        "cve_id": "CVE-2020-10711",
        "code_before_change": "int netlbl_catmap_getlong(struct netlbl_lsm_catmap *catmap,\n\t\t\t  u32 *offset,\n\t\t\t  unsigned long *bitmap)\n{\n\tstruct netlbl_lsm_catmap *iter;\n\tu32 off = *offset;\n\tu32 idx;\n\n\t/* only allow aligned offsets */\n\tif ((off & (BITS_PER_LONG - 1)) != 0)\n\t\treturn -EINVAL;\n\n\tif (off < catmap->startbit) {\n\t\toff = catmap->startbit;\n\t\t*offset = off;\n\t}\n\titer = _netlbl_catmap_getnode(&catmap, off, _CM_F_WALK, 0);\n\tif (iter == NULL) {\n\t\t*offset = (u32)-1;\n\t\treturn 0;\n\t}\n\n\tif (off < iter->startbit) {\n\t\t*offset = iter->startbit;\n\t\toff = 0;\n\t} else\n\t\toff -= iter->startbit;\n\tidx = off / NETLBL_CATMAP_MAPSIZE;\n\t*bitmap = iter->bitmap[idx] >> (off % NETLBL_CATMAP_MAPSIZE);\n\n\treturn 0;\n}",
        "code_after_change": "int netlbl_catmap_getlong(struct netlbl_lsm_catmap *catmap,\n\t\t\t  u32 *offset,\n\t\t\t  unsigned long *bitmap)\n{\n\tstruct netlbl_lsm_catmap *iter;\n\tu32 off = *offset;\n\tu32 idx;\n\n\t/* only allow aligned offsets */\n\tif ((off & (BITS_PER_LONG - 1)) != 0)\n\t\treturn -EINVAL;\n\n\t/* a null catmap is equivalent to an empty one */\n\tif (!catmap) {\n\t\t*offset = (u32)-1;\n\t\treturn 0;\n\t}\n\n\tif (off < catmap->startbit) {\n\t\toff = catmap->startbit;\n\t\t*offset = off;\n\t}\n\titer = _netlbl_catmap_getnode(&catmap, off, _CM_F_WALK, 0);\n\tif (iter == NULL) {\n\t\t*offset = (u32)-1;\n\t\treturn 0;\n\t}\n\n\tif (off < iter->startbit) {\n\t\t*offset = iter->startbit;\n\t\toff = 0;\n\t} else\n\t\toff -= iter->startbit;\n\tidx = off / NETLBL_CATMAP_MAPSIZE;\n\t*bitmap = iter->bitmap[idx] >> (off % NETLBL_CATMAP_MAPSIZE);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,12 @@\n \t/* only allow aligned offsets */\n \tif ((off & (BITS_PER_LONG - 1)) != 0)\n \t\treturn -EINVAL;\n+\n+\t/* a null catmap is equivalent to an empty one */\n+\tif (!catmap) {\n+\t\t*offset = (u32)-1;\n+\t\treturn 0;\n+\t}\n \n \tif (off < catmap->startbit) {\n \t\toff = catmap->startbit;",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* a null catmap is equivalent to an empty one */",
                "\tif (!catmap) {",
                "\t\t*offset = (u32)-1;",
                "\t\treturn 0;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel's SELinux subsystem in versions before 5.7. This flaw occurs while importing the Commercial IP Security Option (CIPSO) protocol's category bitmap into the SELinux extensible bitmap via the' ebitmap_netlbl_import' routine. While processing the CIPSO restricted bitmap tag in the 'cipso_v4_parsetag_rbm' routine, it sets the security attribute to indicate that the category bitmap is present, even if it has not been allocated. This issue leads to a NULL pointer dereference issue while importing the same category bitmap into SELinux. This flaw allows a remote network user to crash the system kernel, resulting in a denial of service.",
        "id": 2406
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "static int ksmbd_tcp_readv(struct tcp_transport *t, struct kvec *iov_orig,\n\t\t\t   unsigned int nr_segs, unsigned int to_read,\n\t\t\t   int max_retries)\n{\n\tint length = 0;\n\tint total_read;\n\tunsigned int segs;\n\tstruct msghdr ksmbd_msg;\n\tstruct kvec *iov;\n\tstruct ksmbd_conn *conn = KSMBD_TRANS(t)->conn;\n\n\tiov = get_conn_iovec(t, nr_segs);\n\tif (!iov)\n\t\treturn -ENOMEM;\n\n\tksmbd_msg.msg_control = NULL;\n\tksmbd_msg.msg_controllen = 0;\n\n\tfor (total_read = 0; to_read; total_read += length, to_read -= length) {\n\t\ttry_to_freeze();\n\n\t\tif (!ksmbd_conn_alive(conn)) {\n\t\t\ttotal_read = -ESHUTDOWN;\n\t\t\tbreak;\n\t\t}\n\t\tsegs = kvec_array_init(iov, iov_orig, nr_segs, total_read);\n\n\t\tlength = kernel_recvmsg(t->sock, &ksmbd_msg,\n\t\t\t\t\tiov, segs, to_read, 0);\n\n\t\tif (length == -EINTR) {\n\t\t\ttotal_read = -ESHUTDOWN;\n\t\t\tbreak;\n\t\t} else if (conn->status == KSMBD_SESS_NEED_RECONNECT) {\n\t\t\ttotal_read = -EAGAIN;\n\t\t\tbreak;\n\t\t} else if (length == -ERESTARTSYS || length == -EAGAIN) {\n\t\t\t/*\n\t\t\t * If max_retries is negative, Allow unlimited\n\t\t\t * retries to keep connection with inactive sessions.\n\t\t\t */\n\t\t\tif (max_retries == 0) {\n\t\t\t\ttotal_read = length;\n\t\t\t\tbreak;\n\t\t\t} else if (max_retries > 0) {\n\t\t\t\tmax_retries--;\n\t\t\t}\n\n\t\t\tusleep_range(1000, 2000);\n\t\t\tlength = 0;\n\t\t\tcontinue;\n\t\t} else if (length <= 0) {\n\t\t\ttotal_read = length;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn total_read;\n}",
        "code_after_change": "static int ksmbd_tcp_readv(struct tcp_transport *t, struct kvec *iov_orig,\n\t\t\t   unsigned int nr_segs, unsigned int to_read,\n\t\t\t   int max_retries)\n{\n\tint length = 0;\n\tint total_read;\n\tunsigned int segs;\n\tstruct msghdr ksmbd_msg;\n\tstruct kvec *iov;\n\tstruct ksmbd_conn *conn = KSMBD_TRANS(t)->conn;\n\n\tiov = get_conn_iovec(t, nr_segs);\n\tif (!iov)\n\t\treturn -ENOMEM;\n\n\tksmbd_msg.msg_control = NULL;\n\tksmbd_msg.msg_controllen = 0;\n\n\tfor (total_read = 0; to_read; total_read += length, to_read -= length) {\n\t\ttry_to_freeze();\n\n\t\tif (!ksmbd_conn_alive(conn)) {\n\t\t\ttotal_read = -ESHUTDOWN;\n\t\t\tbreak;\n\t\t}\n\t\tsegs = kvec_array_init(iov, iov_orig, nr_segs, total_read);\n\n\t\tlength = kernel_recvmsg(t->sock, &ksmbd_msg,\n\t\t\t\t\tiov, segs, to_read, 0);\n\n\t\tif (length == -EINTR) {\n\t\t\ttotal_read = -ESHUTDOWN;\n\t\t\tbreak;\n\t\t} else if (ksmbd_conn_need_reconnect(conn)) {\n\t\t\ttotal_read = -EAGAIN;\n\t\t\tbreak;\n\t\t} else if (length == -ERESTARTSYS || length == -EAGAIN) {\n\t\t\t/*\n\t\t\t * If max_retries is negative, Allow unlimited\n\t\t\t * retries to keep connection with inactive sessions.\n\t\t\t */\n\t\t\tif (max_retries == 0) {\n\t\t\t\ttotal_read = length;\n\t\t\t\tbreak;\n\t\t\t} else if (max_retries > 0) {\n\t\t\t\tmax_retries--;\n\t\t\t}\n\n\t\t\tusleep_range(1000, 2000);\n\t\t\tlength = 0;\n\t\t\tcontinue;\n\t\t} else if (length <= 0) {\n\t\t\ttotal_read = length;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn total_read;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,7 +31,7 @@\n \t\tif (length == -EINTR) {\n \t\t\ttotal_read = -ESHUTDOWN;\n \t\t\tbreak;\n-\t\t} else if (conn->status == KSMBD_SESS_NEED_RECONNECT) {\n+\t\t} else if (ksmbd_conn_need_reconnect(conn)) {\n \t\t\ttotal_read = -EAGAIN;\n \t\t\tbreak;\n \t\t} else if (length == -ERESTARTSYS || length == -EAGAIN) {",
        "function_modified_lines": {
            "added": [
                "\t\t} else if (ksmbd_conn_need_reconnect(conn)) {"
            ],
            "deleted": [
                "\t\t} else if (conn->status == KSMBD_SESS_NEED_RECONNECT) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4032
    },
    {
        "cve_id": "CVE-2022-1671",
        "code_before_change": "static void rxrpc_destroy_s(struct key *key)\n{\n\tconst struct rxrpc_security *sec = key->payload.data[1];\n\n\tif (sec)\n\t\tsec->destroy_server_key(key);\n}",
        "code_after_change": "static void rxrpc_destroy_s(struct key *key)\n{\n\tconst struct rxrpc_security *sec = key->payload.data[1];\n\n\tif (sec && sec->destroy_server_key)\n\t\tsec->destroy_server_key(key);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,6 @@\n {\n \tconst struct rxrpc_security *sec = key->payload.data[1];\n \n-\tif (sec)\n+\tif (sec && sec->destroy_server_key)\n \t\tsec->destroy_server_key(key);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (sec && sec->destroy_server_key)"
            ],
            "deleted": [
                "\tif (sec)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in rxrpc_preparse_s in net/rxrpc/server_key.c in the Linux kernel. This flaw allows a local attacker to crash the system or leak internal kernel information.",
        "id": 3271
    },
    {
        "cve_id": "CVE-2018-14617",
        "code_before_change": "static struct dentry *hfsplus_lookup(struct inode *dir, struct dentry *dentry,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct inode *inode = NULL;\n\tstruct hfs_find_data fd;\n\tstruct super_block *sb;\n\thfsplus_cat_entry entry;\n\tint err;\n\tu32 cnid, linkid = 0;\n\tu16 type;\n\n\tsb = dir->i_sb;\n\n\tdentry->d_fsdata = NULL;\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\terr = hfsplus_cat_build_key(sb, fd.search_key, dir->i_ino,\n\t\t\t&dentry->d_name);\n\tif (unlikely(err < 0))\n\t\tgoto fail;\nagain:\n\terr = hfs_brec_read(&fd, &entry, sizeof(entry));\n\tif (err) {\n\t\tif (err == -ENOENT) {\n\t\t\thfs_find_exit(&fd);\n\t\t\t/* No such entry */\n\t\t\tinode = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\tgoto fail;\n\t}\n\ttype = be16_to_cpu(entry.type);\n\tif (type == HFSPLUS_FOLDER) {\n\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_folder)) {\n\t\t\terr = -EIO;\n\t\t\tgoto fail;\n\t\t}\n\t\tcnid = be32_to_cpu(entry.folder.id);\n\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t} else if (type == HFSPLUS_FILE) {\n\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n\t\t\terr = -EIO;\n\t\t\tgoto fail;\n\t\t}\n\t\tcnid = be32_to_cpu(entry.file.id);\n\t\tif (entry.file.user_info.fdType ==\n\t\t\t\tcpu_to_be32(HFSP_HARDLINK_TYPE) &&\n\t\t\t\tentry.file.user_info.fdCreator ==\n\t\t\t\tcpu_to_be32(HFSP_HFSPLUS_CREATOR) &&\n\t\t\t\t(entry.file.create_date ==\n\t\t\t\t\tHFSPLUS_I(HFSPLUS_SB(sb)->hidden_dir)->\n\t\t\t\t\t\tcreate_date ||\n\t\t\t\tentry.file.create_date ==\n\t\t\t\t\tHFSPLUS_I(d_inode(sb->s_root))->\n\t\t\t\t\t\tcreate_date) &&\n\t\t\t\tHFSPLUS_SB(sb)->hidden_dir) {\n\t\t\tstruct qstr str;\n\t\t\tchar name[32];\n\n\t\t\tif (dentry->d_fsdata) {\n\t\t\t\t/*\n\t\t\t\t * We found a link pointing to another link,\n\t\t\t\t * so ignore it and treat it as regular file.\n\t\t\t\t */\n\t\t\t\tcnid = (unsigned long)dentry->d_fsdata;\n\t\t\t\tlinkid = 0;\n\t\t\t} else {\n\t\t\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t\t\t\tlinkid =\n\t\t\t\t\tbe32_to_cpu(entry.file.permissions.dev);\n\t\t\t\tstr.len = sprintf(name, \"iNode%d\", linkid);\n\t\t\t\tstr.name = name;\n\t\t\t\terr = hfsplus_cat_build_key(sb, fd.search_key,\n\t\t\t\t\tHFSPLUS_SB(sb)->hidden_dir->i_ino,\n\t\t\t\t\t&str);\n\t\t\t\tif (unlikely(err < 0))\n\t\t\t\t\tgoto fail;\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t} else if (!dentry->d_fsdata)\n\t\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t} else {\n\t\tpr_err(\"invalid catalog entry type in lookup\\n\");\n\t\terr = -EIO;\n\t\tgoto fail;\n\t}\n\thfs_find_exit(&fd);\n\tinode = hfsplus_iget(dir->i_sb, cnid);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (S_ISREG(inode->i_mode))\n\t\tHFSPLUS_I(inode)->linkid = linkid;\nout:\n\treturn d_splice_alias(inode, dentry);\nfail:\n\thfs_find_exit(&fd);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "static struct dentry *hfsplus_lookup(struct inode *dir, struct dentry *dentry,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct inode *inode = NULL;\n\tstruct hfs_find_data fd;\n\tstruct super_block *sb;\n\thfsplus_cat_entry entry;\n\tint err;\n\tu32 cnid, linkid = 0;\n\tu16 type;\n\n\tsb = dir->i_sb;\n\n\tdentry->d_fsdata = NULL;\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\terr = hfsplus_cat_build_key(sb, fd.search_key, dir->i_ino,\n\t\t\t&dentry->d_name);\n\tif (unlikely(err < 0))\n\t\tgoto fail;\nagain:\n\terr = hfs_brec_read(&fd, &entry, sizeof(entry));\n\tif (err) {\n\t\tif (err == -ENOENT) {\n\t\t\thfs_find_exit(&fd);\n\t\t\t/* No such entry */\n\t\t\tinode = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\tgoto fail;\n\t}\n\ttype = be16_to_cpu(entry.type);\n\tif (type == HFSPLUS_FOLDER) {\n\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_folder)) {\n\t\t\terr = -EIO;\n\t\t\tgoto fail;\n\t\t}\n\t\tcnid = be32_to_cpu(entry.folder.id);\n\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t} else if (type == HFSPLUS_FILE) {\n\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n\t\t\terr = -EIO;\n\t\t\tgoto fail;\n\t\t}\n\t\tcnid = be32_to_cpu(entry.file.id);\n\t\tif (entry.file.user_info.fdType ==\n\t\t\t\tcpu_to_be32(HFSP_HARDLINK_TYPE) &&\n\t\t\t\tentry.file.user_info.fdCreator ==\n\t\t\t\tcpu_to_be32(HFSP_HFSPLUS_CREATOR) &&\n\t\t\t\tHFSPLUS_SB(sb)->hidden_dir &&\n\t\t\t\t(entry.file.create_date ==\n\t\t\t\t\tHFSPLUS_I(HFSPLUS_SB(sb)->hidden_dir)->\n\t\t\t\t\t\tcreate_date ||\n\t\t\t\tentry.file.create_date ==\n\t\t\t\t\tHFSPLUS_I(d_inode(sb->s_root))->\n\t\t\t\t\t\tcreate_date)) {\n\t\t\tstruct qstr str;\n\t\t\tchar name[32];\n\n\t\t\tif (dentry->d_fsdata) {\n\t\t\t\t/*\n\t\t\t\t * We found a link pointing to another link,\n\t\t\t\t * so ignore it and treat it as regular file.\n\t\t\t\t */\n\t\t\t\tcnid = (unsigned long)dentry->d_fsdata;\n\t\t\t\tlinkid = 0;\n\t\t\t} else {\n\t\t\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t\t\t\tlinkid =\n\t\t\t\t\tbe32_to_cpu(entry.file.permissions.dev);\n\t\t\t\tstr.len = sprintf(name, \"iNode%d\", linkid);\n\t\t\t\tstr.name = name;\n\t\t\t\terr = hfsplus_cat_build_key(sb, fd.search_key,\n\t\t\t\t\tHFSPLUS_SB(sb)->hidden_dir->i_ino,\n\t\t\t\t\t&str);\n\t\t\t\tif (unlikely(err < 0))\n\t\t\t\t\tgoto fail;\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t} else if (!dentry->d_fsdata)\n\t\t\tdentry->d_fsdata = (void *)(unsigned long)cnid;\n\t} else {\n\t\tpr_err(\"invalid catalog entry type in lookup\\n\");\n\t\terr = -EIO;\n\t\tgoto fail;\n\t}\n\thfs_find_exit(&fd);\n\tinode = hfsplus_iget(dir->i_sb, cnid);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (S_ISREG(inode->i_mode))\n\t\tHFSPLUS_I(inode)->linkid = linkid;\nout:\n\treturn d_splice_alias(inode, dentry);\nfail:\n\thfs_find_exit(&fd);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -48,13 +48,13 @@\n \t\t\t\tcpu_to_be32(HFSP_HARDLINK_TYPE) &&\n \t\t\t\tentry.file.user_info.fdCreator ==\n \t\t\t\tcpu_to_be32(HFSP_HFSPLUS_CREATOR) &&\n+\t\t\t\tHFSPLUS_SB(sb)->hidden_dir &&\n \t\t\t\t(entry.file.create_date ==\n \t\t\t\t\tHFSPLUS_I(HFSPLUS_SB(sb)->hidden_dir)->\n \t\t\t\t\t\tcreate_date ||\n \t\t\t\tentry.file.create_date ==\n \t\t\t\t\tHFSPLUS_I(d_inode(sb->s_root))->\n-\t\t\t\t\t\tcreate_date) &&\n-\t\t\t\tHFSPLUS_SB(sb)->hidden_dir) {\n+\t\t\t\t\t\tcreate_date)) {\n \t\t\tstruct qstr str;\n \t\t\tchar name[32];\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tHFSPLUS_SB(sb)->hidden_dir &&",
                "\t\t\t\t\t\tcreate_date)) {"
            ],
            "deleted": [
                "\t\t\t\t\t\tcreate_date) &&",
                "\t\t\t\tHFSPLUS_SB(sb)->hidden_dir) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference and panic in hfsplus_lookup() in fs/hfsplus/dir.c when opening a file (that is purportedly a hard link) in an hfs+ filesystem that has malformed catalog data, and is mounted read-only without a metadata directory.",
        "id": 1690
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,\n\t\t    u64 end, struct btrfs_scrub_progress *progress,\n\t\t    int readonly, int is_dev_replace)\n{\n\tstruct scrub_ctx *sctx;\n\tint ret;\n\tstruct btrfs_device *dev;\n\tunsigned int nofs_flag;\n\n\tif (btrfs_fs_closing(fs_info))\n\t\treturn -EINVAL;\n\n\tif (fs_info->nodesize > BTRFS_STRIPE_LEN) {\n\t\t/*\n\t\t * in this case scrub is unable to calculate the checksum\n\t\t * the way scrub is implemented. Do not handle this\n\t\t * situation at all because it won't ever happen.\n\t\t */\n\t\tbtrfs_err(fs_info,\n\t\t\t   \"scrub: size assumption nodesize <= BTRFS_STRIPE_LEN (%d <= %d) fails\",\n\t\t       fs_info->nodesize,\n\t\t       BTRFS_STRIPE_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fs_info->sectorsize != PAGE_SIZE) {\n\t\t/* not supported for data w/o checksums */\n\t\tbtrfs_err_rl(fs_info,\n\t\t\t   \"scrub: size assumption sectorsize != PAGE_SIZE (%d != %lu) fails\",\n\t\t       fs_info->sectorsize, PAGE_SIZE);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fs_info->nodesize >\n\t    PAGE_SIZE * SCRUB_MAX_PAGES_PER_BLOCK ||\n\t    fs_info->sectorsize > PAGE_SIZE * SCRUB_MAX_PAGES_PER_BLOCK) {\n\t\t/*\n\t\t * would exhaust the array bounds of pagev member in\n\t\t * struct scrub_block\n\t\t */\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"scrub: size assumption nodesize and sectorsize <= SCRUB_MAX_PAGES_PER_BLOCK (%d <= %d && %d <= %d) fails\",\n\t\t       fs_info->nodesize,\n\t\t       SCRUB_MAX_PAGES_PER_BLOCK,\n\t\t       fs_info->sectorsize,\n\t\t       SCRUB_MAX_PAGES_PER_BLOCK);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Allocate outside of device_list_mutex */\n\tsctx = scrub_setup_ctx(fs_info, is_dev_replace);\n\tif (IS_ERR(sctx))\n\t\treturn PTR_ERR(sctx);\n\n\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n\tif (!dev || (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state) &&\n\t\t     !is_dev_replace)) {\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -ENODEV;\n\t\tgoto out_free_ctx;\n\t}\n\n\tif (!is_dev_replace && !readonly &&\n\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state)) {\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tbtrfs_err_in_rcu(fs_info, \"scrub: device %s is not writable\",\n\t\t\t\trcu_str_deref(dev->name));\n\t\tret = -EROFS;\n\t\tgoto out_free_ctx;\n\t}\n\n\tmutex_lock(&fs_info->scrub_lock);\n\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t    test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &dev->dev_state)) {\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -EIO;\n\t\tgoto out_free_ctx;\n\t}\n\n\tdown_read(&fs_info->dev_replace.rwsem);\n\tif (dev->scrub_ctx ||\n\t    (!is_dev_replace &&\n\t     btrfs_dev_replace_is_ongoing(&fs_info->dev_replace))) {\n\t\tup_read(&fs_info->dev_replace.rwsem);\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -EINPROGRESS;\n\t\tgoto out_free_ctx;\n\t}\n\tup_read(&fs_info->dev_replace.rwsem);\n\n\tret = scrub_workers_get(fs_info, is_dev_replace);\n\tif (ret) {\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tgoto out_free_ctx;\n\t}\n\n\tsctx->readonly = readonly;\n\tdev->scrub_ctx = sctx;\n\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\n\t/*\n\t * checking @scrub_pause_req here, we can avoid\n\t * race between committing transaction and scrubbing.\n\t */\n\t__scrub_blocked_if_needed(fs_info);\n\tatomic_inc(&fs_info->scrubs_running);\n\tmutex_unlock(&fs_info->scrub_lock);\n\n\t/*\n\t * In order to avoid deadlock with reclaim when there is a transaction\n\t * trying to pause scrub, make sure we use GFP_NOFS for all the\n\t * allocations done at btrfs_scrub_pages() and scrub_pages_for_parity()\n\t * invoked by our callees. The pausing request is done when the\n\t * transaction commit starts, and it blocks the transaction until scrub\n\t * is paused (done at specific points at scrub_stripe() or right above\n\t * before incrementing fs_info->scrubs_running).\n\t */\n\tnofs_flag = memalloc_nofs_save();\n\tif (!is_dev_replace) {\n\t\t/*\n\t\t * by holding device list mutex, we can\n\t\t * kick off writing super in log tree sync.\n\t\t */\n\t\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = scrub_supers(sctx, dev);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t}\n\n\tif (!ret)\n\t\tret = scrub_enumerate_chunks(sctx, dev, start, end);\n\tmemalloc_nofs_restore(nofs_flag);\n\n\twait_event(sctx->list_wait, atomic_read(&sctx->bios_in_flight) == 0);\n\tatomic_dec(&fs_info->scrubs_running);\n\twake_up(&fs_info->scrub_pause_wait);\n\n\twait_event(sctx->list_wait, atomic_read(&sctx->workers_pending) == 0);\n\n\tif (progress)\n\t\tmemcpy(progress, &sctx->stat, sizeof(*progress));\n\n\tmutex_lock(&fs_info->scrub_lock);\n\tdev->scrub_ctx = NULL;\n\tscrub_workers_put(fs_info);\n\tmutex_unlock(&fs_info->scrub_lock);\n\n\tscrub_put_ctx(sctx);\n\n\treturn ret;\n\nout_free_ctx:\n\tscrub_free_ctx(sctx);\n\n\treturn ret;\n}",
        "code_after_change": "int btrfs_scrub_dev(struct btrfs_fs_info *fs_info, u64 devid, u64 start,\n\t\t    u64 end, struct btrfs_scrub_progress *progress,\n\t\t    int readonly, int is_dev_replace)\n{\n\tstruct scrub_ctx *sctx;\n\tint ret;\n\tstruct btrfs_device *dev;\n\tunsigned int nofs_flag;\n\n\tif (btrfs_fs_closing(fs_info))\n\t\treturn -EINVAL;\n\n\tif (fs_info->nodesize > BTRFS_STRIPE_LEN) {\n\t\t/*\n\t\t * in this case scrub is unable to calculate the checksum\n\t\t * the way scrub is implemented. Do not handle this\n\t\t * situation at all because it won't ever happen.\n\t\t */\n\t\tbtrfs_err(fs_info,\n\t\t\t   \"scrub: size assumption nodesize <= BTRFS_STRIPE_LEN (%d <= %d) fails\",\n\t\t       fs_info->nodesize,\n\t\t       BTRFS_STRIPE_LEN);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fs_info->sectorsize != PAGE_SIZE) {\n\t\t/* not supported for data w/o checksums */\n\t\tbtrfs_err_rl(fs_info,\n\t\t\t   \"scrub: size assumption sectorsize != PAGE_SIZE (%d != %lu) fails\",\n\t\t       fs_info->sectorsize, PAGE_SIZE);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fs_info->nodesize >\n\t    PAGE_SIZE * SCRUB_MAX_PAGES_PER_BLOCK ||\n\t    fs_info->sectorsize > PAGE_SIZE * SCRUB_MAX_PAGES_PER_BLOCK) {\n\t\t/*\n\t\t * would exhaust the array bounds of pagev member in\n\t\t * struct scrub_block\n\t\t */\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"scrub: size assumption nodesize and sectorsize <= SCRUB_MAX_PAGES_PER_BLOCK (%d <= %d && %d <= %d) fails\",\n\t\t       fs_info->nodesize,\n\t\t       SCRUB_MAX_PAGES_PER_BLOCK,\n\t\t       fs_info->sectorsize,\n\t\t       SCRUB_MAX_PAGES_PER_BLOCK);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Allocate outside of device_list_mutex */\n\tsctx = scrub_setup_ctx(fs_info, is_dev_replace);\n\tif (IS_ERR(sctx))\n\t\treturn PTR_ERR(sctx);\n\n\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n\tif (!dev || (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state) &&\n\t\t     !is_dev_replace)) {\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -ENODEV;\n\t\tgoto out_free_ctx;\n\t}\n\n\tif (!is_dev_replace && !readonly &&\n\t    !test_bit(BTRFS_DEV_STATE_WRITEABLE, &dev->dev_state)) {\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tbtrfs_err_in_rcu(fs_info, \"scrub: device %s is not writable\",\n\t\t\t\trcu_str_deref(dev->name));\n\t\tret = -EROFS;\n\t\tgoto out_free_ctx;\n\t}\n\n\tmutex_lock(&fs_info->scrub_lock);\n\tif (!test_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &dev->dev_state) ||\n\t    test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &dev->dev_state)) {\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -EIO;\n\t\tgoto out_free_ctx;\n\t}\n\n\tdown_read(&fs_info->dev_replace.rwsem);\n\tif (dev->scrub_ctx ||\n\t    (!is_dev_replace &&\n\t     btrfs_dev_replace_is_ongoing(&fs_info->dev_replace))) {\n\t\tup_read(&fs_info->dev_replace.rwsem);\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = -EINPROGRESS;\n\t\tgoto out_free_ctx;\n\t}\n\tup_read(&fs_info->dev_replace.rwsem);\n\n\tret = scrub_workers_get(fs_info, is_dev_replace);\n\tif (ret) {\n\t\tmutex_unlock(&fs_info->scrub_lock);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t\tgoto out_free_ctx;\n\t}\n\n\tsctx->readonly = readonly;\n\tdev->scrub_ctx = sctx;\n\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\n\t/*\n\t * checking @scrub_pause_req here, we can avoid\n\t * race between committing transaction and scrubbing.\n\t */\n\t__scrub_blocked_if_needed(fs_info);\n\tatomic_inc(&fs_info->scrubs_running);\n\tmutex_unlock(&fs_info->scrub_lock);\n\n\t/*\n\t * In order to avoid deadlock with reclaim when there is a transaction\n\t * trying to pause scrub, make sure we use GFP_NOFS for all the\n\t * allocations done at btrfs_scrub_pages() and scrub_pages_for_parity()\n\t * invoked by our callees. The pausing request is done when the\n\t * transaction commit starts, and it blocks the transaction until scrub\n\t * is paused (done at specific points at scrub_stripe() or right above\n\t * before incrementing fs_info->scrubs_running).\n\t */\n\tnofs_flag = memalloc_nofs_save();\n\tif (!is_dev_replace) {\n\t\t/*\n\t\t * by holding device list mutex, we can\n\t\t * kick off writing super in log tree sync.\n\t\t */\n\t\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\t\tret = scrub_supers(sctx, dev);\n\t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\t}\n\n\tif (!ret)\n\t\tret = scrub_enumerate_chunks(sctx, dev, start, end);\n\tmemalloc_nofs_restore(nofs_flag);\n\n\twait_event(sctx->list_wait, atomic_read(&sctx->bios_in_flight) == 0);\n\tatomic_dec(&fs_info->scrubs_running);\n\twake_up(&fs_info->scrub_pause_wait);\n\n\twait_event(sctx->list_wait, atomic_read(&sctx->workers_pending) == 0);\n\n\tif (progress)\n\t\tmemcpy(progress, &sctx->stat, sizeof(*progress));\n\n\tmutex_lock(&fs_info->scrub_lock);\n\tdev->scrub_ctx = NULL;\n\tscrub_workers_put(fs_info);\n\tmutex_unlock(&fs_info->scrub_lock);\n\n\tscrub_put_ctx(sctx);\n\n\treturn ret;\n\nout_free_ctx:\n\tscrub_free_ctx(sctx);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -53,7 +53,7 @@\n \t\treturn PTR_ERR(sctx);\n \n \tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n-\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n+\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n \tif (!dev || (test_bit(BTRFS_DEV_STATE_MISSING, &dev->dev_state) &&\n \t\t     !is_dev_replace)) {\n \t\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);",
        "function_modified_lines": {
            "added": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);"
            ],
            "deleted": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2110
    },
    {
        "cve_id": "CVE-2015-8551",
        "code_before_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tpr_warn_ratelimited(\"%s: error enabling MSI for guest %u: err %d\\n\",\n\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n\t\t\t\t    status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
        "code_after_change": "int xen_pcibk_enable_msi(struct xen_pcibk_device *pdev,\n\t\t\t struct pci_dev *dev, struct xen_pci_op *op)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint status;\n\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n\n\tif (dev->msi_enabled)\n\t\tstatus = -EALREADY;\n\telse if (dev->msix_enabled)\n\t\tstatus = -ENXIO;\n\telse\n\t\tstatus = pci_enable_msi(dev);\n\n\tif (status) {\n\t\tpr_warn_ratelimited(\"%s: error enabling MSI for guest %u: err %d\\n\",\n\t\t\t\t    pci_name(dev), pdev->xdev->otherend_id,\n\t\t\t\t    status);\n\t\top->value = 0;\n\t\treturn XEN_PCI_ERR_op_failed;\n\t}\n\n\t/* The value the guest needs is actually the IDT vector, not the\n\t * the local domain's IRQ number. */\n\n\top->value = dev->irq ? xen_pirq_from_irq(dev->irq) : 0;\n\tif (unlikely(verbose_request))\n\t\tprintk(KERN_DEBUG DRV_NAME \": %s: MSI: %d\\n\", pci_name(dev),\n\t\t\top->value);\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (dev_data)\n\t\tdev_data->ack_intr = 0;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,12 @@\n \tif (unlikely(verbose_request))\n \t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable MSI\\n\", pci_name(dev));\n \n-\tstatus = pci_enable_msi(dev);\n+\tif (dev->msi_enabled)\n+\t\tstatus = -EALREADY;\n+\telse if (dev->msix_enabled)\n+\t\tstatus = -ENXIO;\n+\telse\n+\t\tstatus = pci_enable_msi(dev);\n \n \tif (status) {\n \t\tpr_warn_ratelimited(\"%s: error enabling MSI for guest %u: err %d\\n\",",
        "function_modified_lines": {
            "added": [
                "\tif (dev->msi_enabled)",
                "\t\tstatus = -EALREADY;",
                "\telse if (dev->msix_enabled)",
                "\t\tstatus = -ENXIO;",
                "\telse",
                "\t\tstatus = pci_enable_msi(dev);"
            ],
            "deleted": [
                "\tstatus = pci_enable_msi(dev);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The PCI backend driver in Xen, when running on an x86 system and using Linux 3.1.x through 4.3.x as the driver domain, allows local guest administrators to hit BUG conditions and cause a denial of service (NULL pointer dereference and host OS crash) by leveraging a system with access to a passed-through MSI or MSI-X capable physical PCI device and a crafted sequence of XEN_PCI_OP_* operations, aka \"Linux pciback missing sanity checks.\"",
        "id": 829
    },
    {
        "cve_id": "CVE-2015-8970",
        "code_before_change": "static int skcipher_setkey(void *private, const u8 *key, unsigned int keylen)\n{\n\treturn crypto_skcipher_setkey(private, key, keylen);\n}",
        "code_after_change": "static int skcipher_setkey(void *private, const u8 *key, unsigned int keylen)\n{\n\tstruct skcipher_tfm *tfm = private;\n\tint err;\n\n\terr = crypto_skcipher_setkey(tfm->skcipher, key, keylen);\n\ttfm->has_key = !err;\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,10 @@\n static int skcipher_setkey(void *private, const u8 *key, unsigned int keylen)\n {\n-\treturn crypto_skcipher_setkey(private, key, keylen);\n+\tstruct skcipher_tfm *tfm = private;\n+\tint err;\n+\n+\terr = crypto_skcipher_setkey(tfm->skcipher, key, keylen);\n+\ttfm->has_key = !err;\n+\n+\treturn err;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct skcipher_tfm *tfm = private;",
                "\tint err;",
                "",
                "\terr = crypto_skcipher_setkey(tfm->skcipher, key, keylen);",
                "\ttfm->has_key = !err;",
                "",
                "\treturn err;"
            ],
            "deleted": [
                "\treturn crypto_skcipher_setkey(private, key, keylen);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/algif_skcipher.c in the Linux kernel before 4.4.2 does not verify that a setkey operation has been performed on an AF_ALG socket before an accept system call is processed, which allows local users to cause a denial of service (NULL pointer dereference and system crash) via a crafted application that does not supply a key, related to the lrw_crypt function in crypto/lrw.c.",
        "id": 878
    },
    {
        "cve_id": "CVE-2020-11609",
        "code_before_change": "static int stv06xx_isoc_init(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_host_interface *alt;\n\tstruct sd *sd = (struct sd *) gspca_dev;\n\n\t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\talt->endpoint[0].desc.wMaxPacketSize =\n\t\tcpu_to_le16(sd->sensor->max_packet_size[gspca_dev->curr_mode]);\n\n\treturn 0;\n}",
        "code_after_change": "static int stv06xx_isoc_init(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_interface_cache *intfc;\n\tstruct usb_host_interface *alt;\n\tstruct sd *sd = (struct sd *) gspca_dev;\n\n\tintfc = gspca_dev->dev->actconfig->intf_cache[0];\n\n\tif (intfc->num_altsetting < 2)\n\t\treturn -ENODEV;\n\n\talt = &intfc->altsetting[1];\n\n\tif (alt->desc.bNumEndpoints < 1)\n\t\treturn -ENODEV;\n\n\t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n\talt->endpoint[0].desc.wMaxPacketSize =\n\t\tcpu_to_le16(sd->sensor->max_packet_size[gspca_dev->curr_mode]);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,20 @@\n static int stv06xx_isoc_init(struct gspca_dev *gspca_dev)\n {\n+\tstruct usb_interface_cache *intfc;\n \tstruct usb_host_interface *alt;\n \tstruct sd *sd = (struct sd *) gspca_dev;\n \n+\tintfc = gspca_dev->dev->actconfig->intf_cache[0];\n+\n+\tif (intfc->num_altsetting < 2)\n+\t\treturn -ENODEV;\n+\n+\talt = &intfc->altsetting[1];\n+\n+\tif (alt->desc.bNumEndpoints < 1)\n+\t\treturn -ENODEV;\n+\n \t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n-\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n \talt->endpoint[0].desc.wMaxPacketSize =\n \t\tcpu_to_le16(sd->sensor->max_packet_size[gspca_dev->curr_mode]);\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_interface_cache *intfc;",
                "\tintfc = gspca_dev->dev->actconfig->intf_cache[0];",
                "",
                "\tif (intfc->num_altsetting < 2)",
                "\t\treturn -ENODEV;",
                "",
                "\talt = &intfc->altsetting[1];",
                "",
                "\tif (alt->desc.bNumEndpoints < 1)",
                "\t\treturn -ENODEV;",
                ""
            ],
            "deleted": [
                "\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the stv06xx subsystem in the Linux kernel before 5.6.1. drivers/media/usb/gspca/stv06xx/stv06xx.c and drivers/media/usb/gspca/stv06xx/stv06xx_pb0100.c mishandle invalid descriptors, as demonstrated by a NULL pointer dereference, aka CID-485b06aadb93.",
        "id": 2430
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "int check_mem_reg(struct bpf_verifier_env *env, struct bpf_reg_state *reg,\n\t\t   u32 regno, u32 mem_size)\n{\n\tif (register_is_null(reg))\n\t\treturn 0;\n\n\tif (reg_type_may_be_null(reg->type)) {\n\t\t/* Assuming that the register contains a value check if the memory\n\t\t * access is safe. Temporarily save and restore the register's state as\n\t\t * the conversion shouldn't be visible to a caller.\n\t\t */\n\t\tconst struct bpf_reg_state saved_reg = *reg;\n\t\tint rv;\n\n\t\tmark_ptr_not_null_reg(reg);\n\t\trv = check_helper_mem_access(env, regno, mem_size, true, NULL);\n\t\t*reg = saved_reg;\n\t\treturn rv;\n\t}\n\n\treturn check_helper_mem_access(env, regno, mem_size, true, NULL);\n}",
        "code_after_change": "int check_mem_reg(struct bpf_verifier_env *env, struct bpf_reg_state *reg,\n\t\t   u32 regno, u32 mem_size)\n{\n\tif (register_is_null(reg))\n\t\treturn 0;\n\n\tif (type_may_be_null(reg->type)) {\n\t\t/* Assuming that the register contains a value check if the memory\n\t\t * access is safe. Temporarily save and restore the register's state as\n\t\t * the conversion shouldn't be visible to a caller.\n\t\t */\n\t\tconst struct bpf_reg_state saved_reg = *reg;\n\t\tint rv;\n\n\t\tmark_ptr_not_null_reg(reg);\n\t\trv = check_helper_mem_access(env, regno, mem_size, true, NULL);\n\t\t*reg = saved_reg;\n\t\treturn rv;\n\t}\n\n\treturn check_helper_mem_access(env, regno, mem_size, true, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n \tif (register_is_null(reg))\n \t\treturn 0;\n \n-\tif (reg_type_may_be_null(reg->type)) {\n+\tif (type_may_be_null(reg->type)) {\n \t\t/* Assuming that the register contains a value check if the memory\n \t\t * access is safe. Temporarily save and restore the register's state as\n \t\t * the conversion shouldn't be visible to a caller.",
        "function_modified_lines": {
            "added": [
                "\tif (type_may_be_null(reg->type)) {"
            ],
            "deleted": [
                "\tif (reg_type_may_be_null(reg->type)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3453
    },
    {
        "cve_id": "CVE-2017-2647",
        "code_before_change": "struct key *key_get_instantiation_authkey(key_serial_t target_id)\n{\n\tchar description[16];\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= &key_type_request_key_auth,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= user_match,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t};\n\tstruct key *authkey;\n\tkey_ref_t authkey_ref;\n\n\tsprintf(description, \"%x\", target_id);\n\n\tauthkey_ref = search_process_keyrings(&ctx);\n\n\tif (IS_ERR(authkey_ref)) {\n\t\tauthkey = ERR_CAST(authkey_ref);\n\t\tif (authkey == ERR_PTR(-EAGAIN))\n\t\t\tauthkey = ERR_PTR(-ENOKEY);\n\t\tgoto error;\n\t}\n\n\tauthkey = key_ref_to_ptr(authkey_ref);\n\tif (test_bit(KEY_FLAG_REVOKED, &authkey->flags)) {\n\t\tkey_put(authkey);\n\t\tauthkey = ERR_PTR(-EKEYREVOKED);\n\t}\n\nerror:\n\treturn authkey;\n}",
        "code_after_change": "struct key *key_get_instantiation_authkey(key_serial_t target_id)\n{\n\tchar description[16];\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= &key_type_request_key_auth,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= key_default_cmp,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t};\n\tstruct key *authkey;\n\tkey_ref_t authkey_ref;\n\n\tsprintf(description, \"%x\", target_id);\n\n\tauthkey_ref = search_process_keyrings(&ctx);\n\n\tif (IS_ERR(authkey_ref)) {\n\t\tauthkey = ERR_CAST(authkey_ref);\n\t\tif (authkey == ERR_PTR(-EAGAIN))\n\t\t\tauthkey = ERR_PTR(-ENOKEY);\n\t\tgoto error;\n\t}\n\n\tauthkey = key_ref_to_ptr(authkey_ref);\n\tif (test_bit(KEY_FLAG_REVOKED, &authkey->flags)) {\n\t\tkey_put(authkey);\n\t\tauthkey = ERR_PTR(-EKEYREVOKED);\n\t}\n\nerror:\n\treturn authkey;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \t\t.index_key.type\t\t= &key_type_request_key_auth,\n \t\t.index_key.description\t= description,\n \t\t.cred\t\t\t= current_cred(),\n-\t\t.match_data.cmp\t\t= user_match,\n+\t\t.match_data.cmp\t\t= key_default_cmp,\n \t\t.match_data.raw_data\t= description,\n \t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n \t};",
        "function_modified_lines": {
            "added": [
                "\t\t.match_data.cmp\t\t= key_default_cmp,"
            ],
            "deleted": [
                "\t\t.match_data.cmp\t\t= user_match,"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel before 3.18 allows local users to gain privileges or cause a denial of service (NULL pointer dereference and system crash) via vectors involving a NULL value for a certain match field, related to the keyring_search_iterator function in keyring.c.",
        "id": 1454
    },
    {
        "cve_id": "CVE-2014-7826",
        "code_before_change": "static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}",
        "code_after_change": "static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \n \t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the ftrace subsystem, which allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via a crafted application.",
        "id": 595
    },
    {
        "cve_id": "CVE-2018-8043",
        "code_before_change": "static int unimac_mdio_probe(struct platform_device *pdev)\n{\n\tstruct unimac_mdio_pdata *pdata = pdev->dev.platform_data;\n\tstruct unimac_mdio_priv *priv;\n\tstruct device_node *np;\n\tstruct mii_bus *bus;\n\tstruct resource *r;\n\tint ret;\n\n\tnp = pdev->dev.of_node;\n\n\tpriv = devm_kzalloc(&pdev->dev, sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\n\t/* Just ioremap, as this MDIO block is usually integrated into an\n\t * Ethernet MAC controller register range\n\t */\n\tpriv->base = devm_ioremap(&pdev->dev, r->start, resource_size(r));\n\tif (!priv->base) {\n\t\tdev_err(&pdev->dev, \"failed to remap register\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tpriv->mii_bus = mdiobus_alloc();\n\tif (!priv->mii_bus)\n\t\treturn -ENOMEM;\n\n\tbus = priv->mii_bus;\n\tbus->priv = priv;\n\tif (pdata) {\n\t\tbus->name = pdata->bus_name;\n\t\tpriv->wait_func = pdata->wait_func;\n\t\tpriv->wait_func_data = pdata->wait_func_data;\n\t\tbus->phy_mask = ~pdata->phy_mask;\n\t} else {\n\t\tbus->name = \"unimac MII bus\";\n\t\tpriv->wait_func_data = priv;\n\t\tpriv->wait_func = unimac_mdio_poll;\n\t}\n\tbus->parent = &pdev->dev;\n\tbus->read = unimac_mdio_read;\n\tbus->write = unimac_mdio_write;\n\tbus->reset = unimac_mdio_reset;\n\tsnprintf(bus->id, MII_BUS_ID_SIZE, \"%s-%d\", pdev->name, pdev->id);\n\n\tret = of_mdiobus_register(bus, np);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"MDIO bus registration failed\\n\");\n\t\tgoto out_mdio_free;\n\t}\n\n\tplatform_set_drvdata(pdev, priv);\n\n\tdev_info(&pdev->dev, \"Broadcom UniMAC MDIO bus at 0x%p\\n\", priv->base);\n\n\treturn 0;\n\nout_mdio_free:\n\tmdiobus_free(bus);\n\treturn ret;\n}",
        "code_after_change": "static int unimac_mdio_probe(struct platform_device *pdev)\n{\n\tstruct unimac_mdio_pdata *pdata = pdev->dev.platform_data;\n\tstruct unimac_mdio_priv *priv;\n\tstruct device_node *np;\n\tstruct mii_bus *bus;\n\tstruct resource *r;\n\tint ret;\n\n\tnp = pdev->dev.of_node;\n\n\tpriv = devm_kzalloc(&pdev->dev, sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!r)\n\t\treturn -EINVAL;\n\n\t/* Just ioremap, as this MDIO block is usually integrated into an\n\t * Ethernet MAC controller register range\n\t */\n\tpriv->base = devm_ioremap(&pdev->dev, r->start, resource_size(r));\n\tif (!priv->base) {\n\t\tdev_err(&pdev->dev, \"failed to remap register\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tpriv->mii_bus = mdiobus_alloc();\n\tif (!priv->mii_bus)\n\t\treturn -ENOMEM;\n\n\tbus = priv->mii_bus;\n\tbus->priv = priv;\n\tif (pdata) {\n\t\tbus->name = pdata->bus_name;\n\t\tpriv->wait_func = pdata->wait_func;\n\t\tpriv->wait_func_data = pdata->wait_func_data;\n\t\tbus->phy_mask = ~pdata->phy_mask;\n\t} else {\n\t\tbus->name = \"unimac MII bus\";\n\t\tpriv->wait_func_data = priv;\n\t\tpriv->wait_func = unimac_mdio_poll;\n\t}\n\tbus->parent = &pdev->dev;\n\tbus->read = unimac_mdio_read;\n\tbus->write = unimac_mdio_write;\n\tbus->reset = unimac_mdio_reset;\n\tsnprintf(bus->id, MII_BUS_ID_SIZE, \"%s-%d\", pdev->name, pdev->id);\n\n\tret = of_mdiobus_register(bus, np);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"MDIO bus registration failed\\n\");\n\t\tgoto out_mdio_free;\n\t}\n\n\tplatform_set_drvdata(pdev, priv);\n\n\tdev_info(&pdev->dev, \"Broadcom UniMAC MDIO bus at 0x%p\\n\", priv->base);\n\n\treturn 0;\n\nout_mdio_free:\n\tmdiobus_free(bus);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,8 @@\n \t\treturn -ENOMEM;\n \n \tr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n+\tif (!r)\n+\t\treturn -EINVAL;\n \n \t/* Just ioremap, as this MDIO block is usually integrated into an\n \t * Ethernet MAC controller register range",
        "function_modified_lines": {
            "added": [
                "\tif (!r)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The unimac_mdio_probe function in drivers/net/phy/mdio-bcm-unimac.c in the Linux kernel through 4.15.8 does not validate certain resource availability, which allows local users to cause a denial of service (NULL pointer dereference).",
        "id": 1858
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "struct btrfs_device *btrfs_find_device_by_devspec(\n\t\tstruct btrfs_fs_info *fs_info, u64 devid,\n\t\tconst char *device_path)\n{\n\tstruct btrfs_device *device;\n\n\tif (devid) {\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, NULL,\n\t\t\t\t\t   NULL);\n\t\tif (!device)\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\treturn device;\n\t}\n\n\tif (!device_path || !device_path[0])\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (strcmp(device_path, \"missing\") == 0) {\n\t\t/* Find first missing device */\n\t\tlist_for_each_entry(device, &fs_info->fs_devices->devices,\n\t\t\t\t    dev_list) {\n\t\t\tif (test_bit(BTRFS_DEV_STATE_IN_FS_METADATA,\n\t\t\t\t     &device->dev_state) && !device->bdev)\n\t\t\t\treturn device;\n\t\t}\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\treturn btrfs_find_device_by_path(fs_info, device_path);\n}",
        "code_after_change": "struct btrfs_device *btrfs_find_device_by_devspec(\n\t\tstruct btrfs_fs_info *fs_info, u64 devid,\n\t\tconst char *device_path)\n{\n\tstruct btrfs_device *device;\n\n\tif (devid) {\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, NULL,\n\t\t\t\t\t   NULL, true);\n\t\tif (!device)\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\treturn device;\n\t}\n\n\tif (!device_path || !device_path[0])\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (strcmp(device_path, \"missing\") == 0) {\n\t\t/* Find first missing device */\n\t\tlist_for_each_entry(device, &fs_info->fs_devices->devices,\n\t\t\t\t    dev_list) {\n\t\t\tif (test_bit(BTRFS_DEV_STATE_IN_FS_METADATA,\n\t\t\t\t     &device->dev_state) && !device->bdev)\n\t\t\t\treturn device;\n\t\t}\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\treturn btrfs_find_device_by_path(fs_info, device_path);\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \n \tif (devid) {\n \t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, NULL,\n-\t\t\t\t\t   NULL);\n+\t\t\t\t\t   NULL, true);\n \t\tif (!device)\n \t\t\treturn ERR_PTR(-ENOENT);\n \t\treturn device;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t   NULL, true);"
            ],
            "deleted": [
                "\t\t\t\t\t   NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2116
    },
    {
        "cve_id": "CVE-2020-11609",
        "code_before_change": "static int stv06xx_isoc_nego(struct gspca_dev *gspca_dev)\n{\n\tint ret, packet_size, min_packet_size;\n\tstruct usb_host_interface *alt;\n\tstruct sd *sd = (struct sd *) gspca_dev;\n\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\tmin_packet_size = sd->sensor->min_packet_size[gspca_dev->curr_mode];\n\tif (packet_size <= min_packet_size)\n\t\treturn -EIO;\n\n\tpacket_size -= 100;\n\tif (packet_size < min_packet_size)\n\t\tpacket_size = min_packet_size;\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(packet_size);\n\n\tret = usb_set_interface(gspca_dev->dev, gspca_dev->iface, 1);\n\tif (ret < 0)\n\t\tgspca_err(gspca_dev, \"set alt 1 err %d\\n\", ret);\n\n\treturn ret;\n}",
        "code_after_change": "static int stv06xx_isoc_nego(struct gspca_dev *gspca_dev)\n{\n\tint ret, packet_size, min_packet_size;\n\tstruct usb_host_interface *alt;\n\tstruct sd *sd = (struct sd *) gspca_dev;\n\n\t/*\n\t * Existence of altsetting and endpoint was verified in\n\t * stv06xx_isoc_init()\n\t */\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\tmin_packet_size = sd->sensor->min_packet_size[gspca_dev->curr_mode];\n\tif (packet_size <= min_packet_size)\n\t\treturn -EIO;\n\n\tpacket_size -= 100;\n\tif (packet_size < min_packet_size)\n\t\tpacket_size = min_packet_size;\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(packet_size);\n\n\tret = usb_set_interface(gspca_dev->dev, gspca_dev->iface, 1);\n\tif (ret < 0)\n\t\tgspca_err(gspca_dev, \"set alt 1 err %d\\n\", ret);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,10 @@\n \tstruct usb_host_interface *alt;\n \tstruct sd *sd = (struct sd *) gspca_dev;\n \n+\t/*\n+\t * Existence of altsetting and endpoint was verified in\n+\t * stv06xx_isoc_init()\n+\t */\n \talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n \tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n \tmin_packet_size = sd->sensor->min_packet_size[gspca_dev->curr_mode];",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * Existence of altsetting and endpoint was verified in",
                "\t * stv06xx_isoc_init()",
                "\t */"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the stv06xx subsystem in the Linux kernel before 5.6.1. drivers/media/usb/gspca/stv06xx/stv06xx.c and drivers/media/usb/gspca/stv06xx/stv06xx_pb0100.c mishandle invalid descriptors, as demonstrated by a NULL pointer dereference, aka CID-485b06aadb93.",
        "id": 2429
    },
    {
        "cve_id": "CVE-2022-3110",
        "code_before_change": "void rtw_alloc_hwxmits(struct adapter *padapter)\n{\n\tstruct hw_xmit *hwxmits;\n\tstruct xmit_priv *pxmitpriv = &padapter->xmitpriv;\n\n\tpxmitpriv->hwxmit_entry = HWXMIT_ENTRY;\n\n\tpxmitpriv->hwxmits = kzalloc(sizeof(struct hw_xmit) * pxmitpriv->hwxmit_entry, GFP_KERNEL);\n\n\thwxmits = pxmitpriv->hwxmits;\n\n\tif (pxmitpriv->hwxmit_entry == 5) {\n\t\thwxmits[0] .sta_queue = &pxmitpriv->bm_pending;\n\t\thwxmits[1] .sta_queue = &pxmitpriv->vo_pending;\n\t\thwxmits[2] .sta_queue = &pxmitpriv->vi_pending;\n\t\thwxmits[3] .sta_queue = &pxmitpriv->bk_pending;\n\t\thwxmits[4] .sta_queue = &pxmitpriv->be_pending;\n\t} else if (pxmitpriv->hwxmit_entry == 4) {\n\t\thwxmits[0] .sta_queue = &pxmitpriv->vo_pending;\n\t\thwxmits[1] .sta_queue = &pxmitpriv->vi_pending;\n\t\thwxmits[2] .sta_queue = &pxmitpriv->be_pending;\n\t\thwxmits[3] .sta_queue = &pxmitpriv->bk_pending;\n\t} else {\n\t}\n}",
        "code_after_change": "int rtw_alloc_hwxmits(struct adapter *padapter)\n{\n\tstruct hw_xmit *hwxmits;\n\tstruct xmit_priv *pxmitpriv = &padapter->xmitpriv;\n\n\tpxmitpriv->hwxmit_entry = HWXMIT_ENTRY;\n\n\tpxmitpriv->hwxmits = kzalloc(sizeof(struct hw_xmit) * pxmitpriv->hwxmit_entry, GFP_KERNEL);\n\tif (!pxmitpriv->hwxmits)\n\t\treturn -ENOMEM;\n\n\thwxmits = pxmitpriv->hwxmits;\n\n\tif (pxmitpriv->hwxmit_entry == 5) {\n\t\thwxmits[0] .sta_queue = &pxmitpriv->bm_pending;\n\t\thwxmits[1] .sta_queue = &pxmitpriv->vo_pending;\n\t\thwxmits[2] .sta_queue = &pxmitpriv->vi_pending;\n\t\thwxmits[3] .sta_queue = &pxmitpriv->bk_pending;\n\t\thwxmits[4] .sta_queue = &pxmitpriv->be_pending;\n\t} else if (pxmitpriv->hwxmit_entry == 4) {\n\t\thwxmits[0] .sta_queue = &pxmitpriv->vo_pending;\n\t\thwxmits[1] .sta_queue = &pxmitpriv->vi_pending;\n\t\thwxmits[2] .sta_queue = &pxmitpriv->be_pending;\n\t\thwxmits[3] .sta_queue = &pxmitpriv->bk_pending;\n\t} else {\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n-void rtw_alloc_hwxmits(struct adapter *padapter)\n+int rtw_alloc_hwxmits(struct adapter *padapter)\n {\n \tstruct hw_xmit *hwxmits;\n \tstruct xmit_priv *pxmitpriv = &padapter->xmitpriv;\n@@ -6,6 +6,8 @@\n \tpxmitpriv->hwxmit_entry = HWXMIT_ENTRY;\n \n \tpxmitpriv->hwxmits = kzalloc(sizeof(struct hw_xmit) * pxmitpriv->hwxmit_entry, GFP_KERNEL);\n+\tif (!pxmitpriv->hwxmits)\n+\t\treturn -ENOMEM;\n \n \thwxmits = pxmitpriv->hwxmits;\n \n@@ -22,4 +24,6 @@\n \t\thwxmits[3] .sta_queue = &pxmitpriv->bk_pending;\n \t} else {\n \t}\n+\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "int rtw_alloc_hwxmits(struct adapter *padapter)",
                "\tif (!pxmitpriv->hwxmits)",
                "\t\treturn -ENOMEM;",
                "",
                "\treturn 0;"
            ],
            "deleted": [
                "void rtw_alloc_hwxmits(struct adapter *padapter)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. _rtw_init_xmit_priv in drivers/staging/r8188eu/core/rtw_xmit.c lacks check of the return value of rtw_alloc_hwxmits() and will cause the null pointer dereference.",
        "id": 3554
    },
    {
        "cve_id": "CVE-2018-1092",
        "code_before_change": "struct inode *ext4_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct ext4_iloc iloc;\n\tstruct ext4_inode *raw_inode;\n\tstruct ext4_inode_info *ei;\n\tstruct inode *inode;\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\tlong ret;\n\tloff_t size;\n\tint block;\n\tuid_t i_uid;\n\tgid_t i_gid;\n\tprojid_t i_projid;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\tif (!(inode->i_state & I_NEW))\n\t\treturn inode;\n\n\tei = EXT4_I(inode);\n\tiloc.bh = NULL;\n\n\tret = __ext4_get_inode_loc(inode, &iloc, 0);\n\tif (ret < 0)\n\t\tgoto bad_inode;\n\traw_inode = ext4_raw_inode(&iloc);\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tei->i_extra_isize = le16_to_cpu(raw_inode->i_extra_isize);\n\t\tif (EXT4_GOOD_OLD_INODE_SIZE + ei->i_extra_isize >\n\t\t\tEXT4_INODE_SIZE(inode->i_sb) ||\n\t\t    (ei->i_extra_isize & 3)) {\n\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t \"bad extra_isize %u (inode size %u)\",\n\t\t\t\t\t ei->i_extra_isize,\n\t\t\t\t\t EXT4_INODE_SIZE(inode->i_sb));\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto bad_inode;\n\t\t}\n\t} else\n\t\tei->i_extra_isize = 0;\n\n\t/* Precompute checksum seed for inode metadata */\n\tif (ext4_has_metadata_csum(sb)) {\n\t\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\t\t__u32 csum;\n\t\t__le32 inum = cpu_to_le32(inode->i_ino);\n\t\t__le32 gen = raw_inode->i_generation;\n\t\tcsum = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&inum,\n\t\t\t\t   sizeof(inum));\n\t\tei->i_csum_seed = ext4_chksum(sbi, csum, (__u8 *)&gen,\n\t\t\t\t\t      sizeof(gen));\n\t}\n\n\tif (!ext4_inode_csum_verify(inode, raw_inode, ei)) {\n\t\tEXT4_ERROR_INODE(inode, \"checksum invalid\");\n\t\tret = -EFSBADCRC;\n\t\tgoto bad_inode;\n\t}\n\n\tinode->i_mode = le16_to_cpu(raw_inode->i_mode);\n\ti_uid = (uid_t)le16_to_cpu(raw_inode->i_uid_low);\n\ti_gid = (gid_t)le16_to_cpu(raw_inode->i_gid_low);\n\tif (ext4_has_feature_project(sb) &&\n\t    EXT4_INODE_SIZE(sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw_inode, ei, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(raw_inode->i_projid);\n\telse\n\t\ti_projid = EXT4_DEF_PROJID;\n\n\tif (!(test_opt(inode->i_sb, NO_UID32))) {\n\t\ti_uid |= le16_to_cpu(raw_inode->i_uid_high) << 16;\n\t\ti_gid |= le16_to_cpu(raw_inode->i_gid_high) << 16;\n\t}\n\ti_uid_write(inode, i_uid);\n\ti_gid_write(inode, i_gid);\n\tei->i_projid = make_kprojid(&init_user_ns, i_projid);\n\tset_nlink(inode, le16_to_cpu(raw_inode->i_links_count));\n\n\text4_clear_state_flags(ei);\t/* Only relevant on 32-bit archs */\n\tei->i_inline_off = 0;\n\tei->i_dir_start_lookup = 0;\n\tei->i_dtime = le32_to_cpu(raw_inode->i_dtime);\n\t/* We now have enough fields to check if the inode was active or not.\n\t * This is needed because nfsd might try to access dead inodes\n\t * the test is that same one that e2fsck uses\n\t * NeilBrown 1999oct15\n\t */\n\tif (inode->i_nlink == 0) {\n\t\tif ((inode->i_mode == 0 ||\n\t\t     !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS)) &&\n\t\t    ino != EXT4_BOOT_LOADER_INO) {\n\t\t\t/* this inode is deleted */\n\t\t\tret = -ESTALE;\n\t\t\tgoto bad_inode;\n\t\t}\n\t\t/* The only unlinked inodes we let through here have\n\t\t * valid i_mode and are being read by the orphan\n\t\t * recovery code: that's fine, we're about to complete\n\t\t * the process of deleting those.\n\t\t * OR it is the EXT4_BOOT_LOADER_INO which is\n\t\t * not initialized on a new filesystem. */\n\t}\n\tei->i_flags = le32_to_cpu(raw_inode->i_flags);\n\tinode->i_blocks = ext4_inode_blocks(raw_inode, ei);\n\tei->i_file_acl = le32_to_cpu(raw_inode->i_file_acl_lo);\n\tif (ext4_has_feature_64bit(sb))\n\t\tei->i_file_acl |=\n\t\t\t((__u64)le16_to_cpu(raw_inode->i_file_acl_high)) << 32;\n\tinode->i_size = ext4_isize(sb, raw_inode);\n\tif ((size = i_size_read(inode)) < 0) {\n\t\tEXT4_ERROR_INODE(inode, \"bad i_size value: %lld\", size);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\tei->i_disksize = inode->i_size;\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n#endif\n\tinode->i_generation = le32_to_cpu(raw_inode->i_generation);\n\tei->i_block_group = iloc.block_group;\n\tei->i_last_alloc_group = ~0;\n\t/*\n\t * NOTE! The in-memory inode i_data array is in little-endian order\n\t * even on big-endian machines: we do NOT byteswap the block numbers!\n\t */\n\tfor (block = 0; block < EXT4_N_BLOCKS; block++)\n\t\tei->i_data[block] = raw_inode->i_block[block];\n\tINIT_LIST_HEAD(&ei->i_orphan);\n\n\t/*\n\t * Set transaction id's of transactions that have to be committed\n\t * to finish f[data]sync. We set them to currently running transaction\n\t * as we cannot be sure that the inode or some of its metadata isn't\n\t * part of the transaction - the inode could have been reclaimed and\n\t * now it is reread from disk.\n\t */\n\tif (journal) {\n\t\ttransaction_t *transaction;\n\t\ttid_t tid;\n\n\t\tread_lock(&journal->j_state_lock);\n\t\tif (journal->j_running_transaction)\n\t\t\ttransaction = journal->j_running_transaction;\n\t\telse\n\t\t\ttransaction = journal->j_committing_transaction;\n\t\tif (transaction)\n\t\t\ttid = transaction->t_tid;\n\t\telse\n\t\t\ttid = journal->j_commit_sequence;\n\t\tread_unlock(&journal->j_state_lock);\n\t\tei->i_sync_tid = tid;\n\t\tei->i_datasync_tid = tid;\n\t}\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tif (ei->i_extra_isize == 0) {\n\t\t\t/* The extra space is currently unused. Use it. */\n\t\t\tBUILD_BUG_ON(sizeof(struct ext4_inode) & 3);\n\t\t\tei->i_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t    EXT4_GOOD_OLD_INODE_SIZE;\n\t\t} else {\n\t\t\text4_iget_extra_inode(inode, raw_inode, ei);\n\t\t}\n\t}\n\n\tEXT4_INODE_GET_XTIME(i_ctime, inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_mtime, inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_atime, inode, raw_inode);\n\tEXT4_EINODE_GET_XTIME(i_crtime, ei, raw_inode);\n\n\tif (likely(!test_opt2(inode->i_sb, HURD_COMPAT))) {\n\t\tu64 ivers = le32_to_cpu(raw_inode->i_disk_version);\n\n\t\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\t\tif (EXT4_FITS_IN_INODE(raw_inode, ei, i_version_hi))\n\t\t\t\tivers |=\n\t\t    (__u64)(le32_to_cpu(raw_inode->i_version_hi)) << 32;\n\t\t}\n\t\tinode_set_iversion_queried(inode, ivers);\n\t}\n\n\tret = 0;\n\tif (ei->i_file_acl &&\n\t    !ext4_data_block_valid(EXT4_SB(sb), ei->i_file_acl, 1)) {\n\t\tEXT4_ERROR_INODE(inode, \"bad extended attribute block %llu\",\n\t\t\t\t ei->i_file_acl);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t} else if (!ext4_has_inline_data(inode)) {\n\t\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {\n\t\t\tif ((S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t\t    (S_ISLNK(inode->i_mode) &&\n\t\t\t     !ext4_inode_is_fast_symlink(inode))))\n\t\t\t\t/* Validate extent which is part of inode */\n\t\t\t\tret = ext4_ext_check_inode(inode);\n\t\t} else if (S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t\t   (S_ISLNK(inode->i_mode) &&\n\t\t\t    !ext4_inode_is_fast_symlink(inode))) {\n\t\t\t/* Validate block references which are part of inode */\n\t\t\tret = ext4_ind_check_inode(inode);\n\t\t}\n\t}\n\tif (ret)\n\t\tgoto bad_inode;\n\n\tif (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &ext4_file_inode_operations;\n\t\tinode->i_fop = &ext4_file_operations;\n\t\text4_set_aops(inode);\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &ext4_dir_inode_operations;\n\t\tinode->i_fop = &ext4_dir_operations;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (ext4_encrypted_inode(inode)) {\n\t\t\tinode->i_op = &ext4_encrypted_symlink_inode_operations;\n\t\t\text4_set_aops(inode);\n\t\t} else if (ext4_inode_is_fast_symlink(inode)) {\n\t\t\tinode->i_link = (char *)ei->i_data;\n\t\t\tinode->i_op = &ext4_fast_symlink_inode_operations;\n\t\t\tnd_terminate_link(ei->i_data, inode->i_size,\n\t\t\t\tsizeof(ei->i_data) - 1);\n\t\t} else {\n\t\t\tinode->i_op = &ext4_symlink_inode_operations;\n\t\t\text4_set_aops(inode);\n\t\t}\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t      S_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &ext4_special_inode_operations;\n\t\tif (raw_inode->i_block[0])\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   old_decode_dev(le32_to_cpu(raw_inode->i_block[0])));\n\t\telse\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   new_decode_dev(le32_to_cpu(raw_inode->i_block[1])));\n\t} else if (ino == EXT4_BOOT_LOADER_INO) {\n\t\tmake_bad_inode(inode);\n\t} else {\n\t\tret = -EFSCORRUPTED;\n\t\tEXT4_ERROR_INODE(inode, \"bogus i_mode (%o)\", inode->i_mode);\n\t\tgoto bad_inode;\n\t}\n\tbrelse(iloc.bh);\n\text4_set_inode_flags(inode);\n\n\tunlock_new_inode(inode);\n\treturn inode;\n\nbad_inode:\n\tbrelse(iloc.bh);\n\tiget_failed(inode);\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "struct inode *ext4_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct ext4_iloc iloc;\n\tstruct ext4_inode *raw_inode;\n\tstruct ext4_inode_info *ei;\n\tstruct inode *inode;\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\tlong ret;\n\tloff_t size;\n\tint block;\n\tuid_t i_uid;\n\tgid_t i_gid;\n\tprojid_t i_projid;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\tif (!(inode->i_state & I_NEW))\n\t\treturn inode;\n\n\tei = EXT4_I(inode);\n\tiloc.bh = NULL;\n\n\tret = __ext4_get_inode_loc(inode, &iloc, 0);\n\tif (ret < 0)\n\t\tgoto bad_inode;\n\traw_inode = ext4_raw_inode(&iloc);\n\n\tif ((ino == EXT4_ROOT_INO) && (raw_inode->i_links_count == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"root inode unallocated\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tei->i_extra_isize = le16_to_cpu(raw_inode->i_extra_isize);\n\t\tif (EXT4_GOOD_OLD_INODE_SIZE + ei->i_extra_isize >\n\t\t\tEXT4_INODE_SIZE(inode->i_sb) ||\n\t\t    (ei->i_extra_isize & 3)) {\n\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t \"bad extra_isize %u (inode size %u)\",\n\t\t\t\t\t ei->i_extra_isize,\n\t\t\t\t\t EXT4_INODE_SIZE(inode->i_sb));\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto bad_inode;\n\t\t}\n\t} else\n\t\tei->i_extra_isize = 0;\n\n\t/* Precompute checksum seed for inode metadata */\n\tif (ext4_has_metadata_csum(sb)) {\n\t\tstruct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);\n\t\t__u32 csum;\n\t\t__le32 inum = cpu_to_le32(inode->i_ino);\n\t\t__le32 gen = raw_inode->i_generation;\n\t\tcsum = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&inum,\n\t\t\t\t   sizeof(inum));\n\t\tei->i_csum_seed = ext4_chksum(sbi, csum, (__u8 *)&gen,\n\t\t\t\t\t      sizeof(gen));\n\t}\n\n\tif (!ext4_inode_csum_verify(inode, raw_inode, ei)) {\n\t\tEXT4_ERROR_INODE(inode, \"checksum invalid\");\n\t\tret = -EFSBADCRC;\n\t\tgoto bad_inode;\n\t}\n\n\tinode->i_mode = le16_to_cpu(raw_inode->i_mode);\n\ti_uid = (uid_t)le16_to_cpu(raw_inode->i_uid_low);\n\ti_gid = (gid_t)le16_to_cpu(raw_inode->i_gid_low);\n\tif (ext4_has_feature_project(sb) &&\n\t    EXT4_INODE_SIZE(sb) > EXT4_GOOD_OLD_INODE_SIZE &&\n\t    EXT4_FITS_IN_INODE(raw_inode, ei, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(raw_inode->i_projid);\n\telse\n\t\ti_projid = EXT4_DEF_PROJID;\n\n\tif (!(test_opt(inode->i_sb, NO_UID32))) {\n\t\ti_uid |= le16_to_cpu(raw_inode->i_uid_high) << 16;\n\t\ti_gid |= le16_to_cpu(raw_inode->i_gid_high) << 16;\n\t}\n\ti_uid_write(inode, i_uid);\n\ti_gid_write(inode, i_gid);\n\tei->i_projid = make_kprojid(&init_user_ns, i_projid);\n\tset_nlink(inode, le16_to_cpu(raw_inode->i_links_count));\n\n\text4_clear_state_flags(ei);\t/* Only relevant on 32-bit archs */\n\tei->i_inline_off = 0;\n\tei->i_dir_start_lookup = 0;\n\tei->i_dtime = le32_to_cpu(raw_inode->i_dtime);\n\t/* We now have enough fields to check if the inode was active or not.\n\t * This is needed because nfsd might try to access dead inodes\n\t * the test is that same one that e2fsck uses\n\t * NeilBrown 1999oct15\n\t */\n\tif (inode->i_nlink == 0) {\n\t\tif ((inode->i_mode == 0 ||\n\t\t     !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS)) &&\n\t\t    ino != EXT4_BOOT_LOADER_INO) {\n\t\t\t/* this inode is deleted */\n\t\t\tret = -ESTALE;\n\t\t\tgoto bad_inode;\n\t\t}\n\t\t/* The only unlinked inodes we let through here have\n\t\t * valid i_mode and are being read by the orphan\n\t\t * recovery code: that's fine, we're about to complete\n\t\t * the process of deleting those.\n\t\t * OR it is the EXT4_BOOT_LOADER_INO which is\n\t\t * not initialized on a new filesystem. */\n\t}\n\tei->i_flags = le32_to_cpu(raw_inode->i_flags);\n\tinode->i_blocks = ext4_inode_blocks(raw_inode, ei);\n\tei->i_file_acl = le32_to_cpu(raw_inode->i_file_acl_lo);\n\tif (ext4_has_feature_64bit(sb))\n\t\tei->i_file_acl |=\n\t\t\t((__u64)le16_to_cpu(raw_inode->i_file_acl_high)) << 32;\n\tinode->i_size = ext4_isize(sb, raw_inode);\n\tif ((size = i_size_read(inode)) < 0) {\n\t\tEXT4_ERROR_INODE(inode, \"bad i_size value: %lld\", size);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t}\n\tei->i_disksize = inode->i_size;\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n#endif\n\tinode->i_generation = le32_to_cpu(raw_inode->i_generation);\n\tei->i_block_group = iloc.block_group;\n\tei->i_last_alloc_group = ~0;\n\t/*\n\t * NOTE! The in-memory inode i_data array is in little-endian order\n\t * even on big-endian machines: we do NOT byteswap the block numbers!\n\t */\n\tfor (block = 0; block < EXT4_N_BLOCKS; block++)\n\t\tei->i_data[block] = raw_inode->i_block[block];\n\tINIT_LIST_HEAD(&ei->i_orphan);\n\n\t/*\n\t * Set transaction id's of transactions that have to be committed\n\t * to finish f[data]sync. We set them to currently running transaction\n\t * as we cannot be sure that the inode or some of its metadata isn't\n\t * part of the transaction - the inode could have been reclaimed and\n\t * now it is reread from disk.\n\t */\n\tif (journal) {\n\t\ttransaction_t *transaction;\n\t\ttid_t tid;\n\n\t\tread_lock(&journal->j_state_lock);\n\t\tif (journal->j_running_transaction)\n\t\t\ttransaction = journal->j_running_transaction;\n\t\telse\n\t\t\ttransaction = journal->j_committing_transaction;\n\t\tif (transaction)\n\t\t\ttid = transaction->t_tid;\n\t\telse\n\t\t\ttid = journal->j_commit_sequence;\n\t\tread_unlock(&journal->j_state_lock);\n\t\tei->i_sync_tid = tid;\n\t\tei->i_datasync_tid = tid;\n\t}\n\n\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tif (ei->i_extra_isize == 0) {\n\t\t\t/* The extra space is currently unused. Use it. */\n\t\t\tBUILD_BUG_ON(sizeof(struct ext4_inode) & 3);\n\t\t\tei->i_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t    EXT4_GOOD_OLD_INODE_SIZE;\n\t\t} else {\n\t\t\text4_iget_extra_inode(inode, raw_inode, ei);\n\t\t}\n\t}\n\n\tEXT4_INODE_GET_XTIME(i_ctime, inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_mtime, inode, raw_inode);\n\tEXT4_INODE_GET_XTIME(i_atime, inode, raw_inode);\n\tEXT4_EINODE_GET_XTIME(i_crtime, ei, raw_inode);\n\n\tif (likely(!test_opt2(inode->i_sb, HURD_COMPAT))) {\n\t\tu64 ivers = le32_to_cpu(raw_inode->i_disk_version);\n\n\t\tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\t\tif (EXT4_FITS_IN_INODE(raw_inode, ei, i_version_hi))\n\t\t\t\tivers |=\n\t\t    (__u64)(le32_to_cpu(raw_inode->i_version_hi)) << 32;\n\t\t}\n\t\tinode_set_iversion_queried(inode, ivers);\n\t}\n\n\tret = 0;\n\tif (ei->i_file_acl &&\n\t    !ext4_data_block_valid(EXT4_SB(sb), ei->i_file_acl, 1)) {\n\t\tEXT4_ERROR_INODE(inode, \"bad extended attribute block %llu\",\n\t\t\t\t ei->i_file_acl);\n\t\tret = -EFSCORRUPTED;\n\t\tgoto bad_inode;\n\t} else if (!ext4_has_inline_data(inode)) {\n\t\tif (ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {\n\t\t\tif ((S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t\t    (S_ISLNK(inode->i_mode) &&\n\t\t\t     !ext4_inode_is_fast_symlink(inode))))\n\t\t\t\t/* Validate extent which is part of inode */\n\t\t\t\tret = ext4_ext_check_inode(inode);\n\t\t} else if (S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t\t   (S_ISLNK(inode->i_mode) &&\n\t\t\t    !ext4_inode_is_fast_symlink(inode))) {\n\t\t\t/* Validate block references which are part of inode */\n\t\t\tret = ext4_ind_check_inode(inode);\n\t\t}\n\t}\n\tif (ret)\n\t\tgoto bad_inode;\n\n\tif (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &ext4_file_inode_operations;\n\t\tinode->i_fop = &ext4_file_operations;\n\t\text4_set_aops(inode);\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &ext4_dir_inode_operations;\n\t\tinode->i_fop = &ext4_dir_operations;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (ext4_encrypted_inode(inode)) {\n\t\t\tinode->i_op = &ext4_encrypted_symlink_inode_operations;\n\t\t\text4_set_aops(inode);\n\t\t} else if (ext4_inode_is_fast_symlink(inode)) {\n\t\t\tinode->i_link = (char *)ei->i_data;\n\t\t\tinode->i_op = &ext4_fast_symlink_inode_operations;\n\t\t\tnd_terminate_link(ei->i_data, inode->i_size,\n\t\t\t\tsizeof(ei->i_data) - 1);\n\t\t} else {\n\t\t\tinode->i_op = &ext4_symlink_inode_operations;\n\t\t\text4_set_aops(inode);\n\t\t}\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t      S_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &ext4_special_inode_operations;\n\t\tif (raw_inode->i_block[0])\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   old_decode_dev(le32_to_cpu(raw_inode->i_block[0])));\n\t\telse\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t   new_decode_dev(le32_to_cpu(raw_inode->i_block[1])));\n\t} else if (ino == EXT4_BOOT_LOADER_INO) {\n\t\tmake_bad_inode(inode);\n\t} else {\n\t\tret = -EFSCORRUPTED;\n\t\tEXT4_ERROR_INODE(inode, \"bogus i_mode (%o)\", inode->i_mode);\n\t\tgoto bad_inode;\n\t}\n\tbrelse(iloc.bh);\n\text4_set_inode_flags(inode);\n\n\tunlock_new_inode(inode);\n\treturn inode;\n\nbad_inode:\n\tbrelse(iloc.bh);\n\tiget_failed(inode);\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,12 @@\n \tif (ret < 0)\n \t\tgoto bad_inode;\n \traw_inode = ext4_raw_inode(&iloc);\n+\n+\tif ((ino == EXT4_ROOT_INO) && (raw_inode->i_links_count == 0)) {\n+\t\tEXT4_ERROR_INODE(inode, \"root inode unallocated\");\n+\t\tret = -EFSCORRUPTED;\n+\t\tgoto bad_inode;\n+\t}\n \n \tif (EXT4_INODE_SIZE(inode->i_sb) > EXT4_GOOD_OLD_INODE_SIZE) {\n \t\tei->i_extra_isize = le16_to_cpu(raw_inode->i_extra_isize);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif ((ino == EXT4_ROOT_INO) && (raw_inode->i_links_count == 0)) {",
                "\t\tEXT4_ERROR_INODE(inode, \"root inode unallocated\");",
                "\t\tret = -EFSCORRUPTED;",
                "\t\tgoto bad_inode;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The ext4_iget function in fs/ext4/inode.c in the Linux kernel through 4.15.15 mishandles the case of a root directory with a zero i_links_count, which allows attackers to cause a denial of service (ext4_process_freed_data NULL pointer dereference and OOPS) via a crafted ext4 image.",
        "id": 1623
    },
    {
        "cve_id": "CVE-2019-15223",
        "code_before_change": "int line6_probe(struct usb_interface *interface,\n\t\tconst struct usb_device_id *id,\n\t\tconst char *driver_name,\n\t\tconst struct line6_properties *properties,\n\t\tint (*private_init)(struct usb_line6 *, const struct usb_device_id *id),\n\t\tsize_t data_size)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\tstruct snd_card *card;\n\tstruct usb_line6 *line6;\n\tint interface_number;\n\tint ret;\n\n\tif (WARN_ON(data_size < sizeof(*line6)))\n\t\treturn -EINVAL;\n\n\t/* we don't handle multiple configurations */\n\tif (usbdev->descriptor.bNumConfigurations != 1)\n\t\treturn -ENODEV;\n\n\tret = snd_card_new(&interface->dev,\n\t\t\t   SNDRV_DEFAULT_IDX1, SNDRV_DEFAULT_STR1,\n\t\t\t   THIS_MODULE, data_size, &card);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* store basic data: */\n\tline6 = card->private_data;\n\tline6->card = card;\n\tline6->properties = properties;\n\tline6->usbdev = usbdev;\n\tline6->ifcdev = &interface->dev;\n\n\tstrcpy(card->id, properties->id);\n\tstrcpy(card->driver, driver_name);\n\tstrcpy(card->shortname, properties->name);\n\tsprintf(card->longname, \"Line 6 %s at USB %s\", properties->name,\n\t\tdev_name(line6->ifcdev));\n\tcard->private_free = line6_destruct;\n\n\tusb_set_intfdata(interface, line6);\n\n\t/* increment reference counters: */\n\tusb_get_dev(usbdev);\n\n\t/* initialize device info: */\n\tdev_info(&interface->dev, \"Line 6 %s found\\n\", properties->name);\n\n\t/* query interface number */\n\tinterface_number = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* TODO reserves the bus bandwidth even without actual transfer */\n\tret = usb_set_interface(usbdev, interface_number,\n\t\t\t\tproperties->altsetting);\n\tif (ret < 0) {\n\t\tdev_err(&interface->dev, \"set_interface failed\\n\");\n\t\tgoto error;\n\t}\n\n\tline6_get_usb_properties(line6);\n\n\tif (properties->capabilities & LINE6_CAP_CONTROL) {\n\t\tret = line6_init_cap_control(line6);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\t}\n\n\t/* initialize device data based on device: */\n\tret = private_init(line6, id);\n\tif (ret < 0)\n\t\tgoto error;\n\n\t/* creation of additional special files should go here */\n\n\tdev_info(&interface->dev, \"Line 6 %s now attached\\n\",\n\t\t properties->name);\n\n\treturn 0;\n\n error:\n\t/* we can call disconnect callback here because no close-sync is\n\t * needed yet at this point\n\t */\n\tline6_disconnect(interface);\n\treturn ret;\n}",
        "code_after_change": "int line6_probe(struct usb_interface *interface,\n\t\tconst struct usb_device_id *id,\n\t\tconst char *driver_name,\n\t\tconst struct line6_properties *properties,\n\t\tint (*private_init)(struct usb_line6 *, const struct usb_device_id *id),\n\t\tsize_t data_size)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\tstruct snd_card *card;\n\tstruct usb_line6 *line6;\n\tint interface_number;\n\tint ret;\n\n\tif (WARN_ON(data_size < sizeof(*line6)))\n\t\treturn -EINVAL;\n\n\t/* we don't handle multiple configurations */\n\tif (usbdev->descriptor.bNumConfigurations != 1)\n\t\treturn -ENODEV;\n\n\tret = snd_card_new(&interface->dev,\n\t\t\t   SNDRV_DEFAULT_IDX1, SNDRV_DEFAULT_STR1,\n\t\t\t   THIS_MODULE, data_size, &card);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* store basic data: */\n\tline6 = card->private_data;\n\tline6->card = card;\n\tline6->properties = properties;\n\tline6->usbdev = usbdev;\n\tline6->ifcdev = &interface->dev;\n\tINIT_DELAYED_WORK(&line6->startup_work, line6_startup_work);\n\n\tstrcpy(card->id, properties->id);\n\tstrcpy(card->driver, driver_name);\n\tstrcpy(card->shortname, properties->name);\n\tsprintf(card->longname, \"Line 6 %s at USB %s\", properties->name,\n\t\tdev_name(line6->ifcdev));\n\tcard->private_free = line6_destruct;\n\n\tusb_set_intfdata(interface, line6);\n\n\t/* increment reference counters: */\n\tusb_get_dev(usbdev);\n\n\t/* initialize device info: */\n\tdev_info(&interface->dev, \"Line 6 %s found\\n\", properties->name);\n\n\t/* query interface number */\n\tinterface_number = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* TODO reserves the bus bandwidth even without actual transfer */\n\tret = usb_set_interface(usbdev, interface_number,\n\t\t\t\tproperties->altsetting);\n\tif (ret < 0) {\n\t\tdev_err(&interface->dev, \"set_interface failed\\n\");\n\t\tgoto error;\n\t}\n\n\tline6_get_usb_properties(line6);\n\n\tif (properties->capabilities & LINE6_CAP_CONTROL) {\n\t\tret = line6_init_cap_control(line6);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\t}\n\n\t/* initialize device data based on device: */\n\tret = private_init(line6, id);\n\tif (ret < 0)\n\t\tgoto error;\n\n\t/* creation of additional special files should go here */\n\n\tdev_info(&interface->dev, \"Line 6 %s now attached\\n\",\n\t\t properties->name);\n\n\treturn 0;\n\n error:\n\t/* we can call disconnect callback here because no close-sync is\n\t * needed yet at this point\n\t */\n\tline6_disconnect(interface);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,6 +30,7 @@\n \tline6->properties = properties;\n \tline6->usbdev = usbdev;\n \tline6->ifcdev = &interface->dev;\n+\tINIT_DELAYED_WORK(&line6->startup_work, line6_startup_work);\n \n \tstrcpy(card->id, properties->id);\n \tstrcpy(card->driver, driver_name);",
        "function_modified_lines": {
            "added": [
                "\tINIT_DELAYED_WORK(&line6->startup_work, line6_startup_work);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/line6/driver.c driver.",
        "id": 2009
    },
    {
        "cve_id": "CVE-2022-47929",
        "code_before_change": "static int qdisc_graft(struct net_device *dev, struct Qdisc *parent,\n\t\t       struct sk_buff *skb, struct nlmsghdr *n, u32 classid,\n\t\t       struct Qdisc *new, struct Qdisc *old,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct Qdisc *q = old;\n\tstruct net *net = dev_net(dev);\n\n\tif (parent == NULL) {\n\t\tunsigned int i, num_q, ingress;\n\n\t\tingress = 0;\n\t\tnum_q = dev->num_tx_queues;\n\t\tif ((q && q->flags & TCQ_F_INGRESS) ||\n\t\t    (new && new->flags & TCQ_F_INGRESS)) {\n\t\t\tnum_q = 1;\n\t\t\tingress = 1;\n\t\t\tif (!dev_ingress_queue(dev)) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Device does not have an ingress queue\");\n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\t\t}\n\n\t\tif (dev->flags & IFF_UP)\n\t\t\tdev_deactivate(dev);\n\n\t\tqdisc_offload_graft_root(dev, new, old, extack);\n\n\t\tif (new && new->ops->attach && !ingress)\n\t\t\tgoto skip;\n\n\t\tfor (i = 0; i < num_q; i++) {\n\t\t\tstruct netdev_queue *dev_queue = dev_ingress_queue(dev);\n\n\t\t\tif (!ingress)\n\t\t\t\tdev_queue = netdev_get_tx_queue(dev, i);\n\n\t\t\told = dev_graft_qdisc(dev_queue, new);\n\t\t\tif (new && i > 0)\n\t\t\t\tqdisc_refcount_inc(new);\n\n\t\t\tif (!ingress)\n\t\t\t\tqdisc_put(old);\n\t\t}\n\nskip:\n\t\tif (!ingress) {\n\t\t\told = rtnl_dereference(dev->qdisc);\n\t\t\tif (new && !new->ops->attach)\n\t\t\t\tqdisc_refcount_inc(new);\n\t\t\trcu_assign_pointer(dev->qdisc, new ? : &noop_qdisc);\n\n\t\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\n\t\t\tif (new && new->ops->attach)\n\t\t\t\tnew->ops->attach(new);\n\t\t} else {\n\t\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\t\t}\n\n\t\tif (dev->flags & IFF_UP)\n\t\t\tdev_activate(dev);\n\t} else {\n\t\tconst struct Qdisc_class_ops *cops = parent->ops->cl_ops;\n\t\tunsigned long cl;\n\t\tint err;\n\n\t\t/* Only support running class lockless if parent is lockless */\n\t\tif (new && (new->flags & TCQ_F_NOLOCK) && !(parent->flags & TCQ_F_NOLOCK))\n\t\t\tqdisc_clear_nolock(new);\n\n\t\tif (!cops || !cops->graft)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tcl = cops->find(parent, classid);\n\t\tif (!cl) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Specified class not found\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\terr = cops->graft(parent, cl, new, &old, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\t}\n\treturn 0;\n}",
        "code_after_change": "static int qdisc_graft(struct net_device *dev, struct Qdisc *parent,\n\t\t       struct sk_buff *skb, struct nlmsghdr *n, u32 classid,\n\t\t       struct Qdisc *new, struct Qdisc *old,\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct Qdisc *q = old;\n\tstruct net *net = dev_net(dev);\n\n\tif (parent == NULL) {\n\t\tunsigned int i, num_q, ingress;\n\n\t\tingress = 0;\n\t\tnum_q = dev->num_tx_queues;\n\t\tif ((q && q->flags & TCQ_F_INGRESS) ||\n\t\t    (new && new->flags & TCQ_F_INGRESS)) {\n\t\t\tnum_q = 1;\n\t\t\tingress = 1;\n\t\t\tif (!dev_ingress_queue(dev)) {\n\t\t\t\tNL_SET_ERR_MSG(extack, \"Device does not have an ingress queue\");\n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\t\t}\n\n\t\tif (dev->flags & IFF_UP)\n\t\t\tdev_deactivate(dev);\n\n\t\tqdisc_offload_graft_root(dev, new, old, extack);\n\n\t\tif (new && new->ops->attach && !ingress)\n\t\t\tgoto skip;\n\n\t\tfor (i = 0; i < num_q; i++) {\n\t\t\tstruct netdev_queue *dev_queue = dev_ingress_queue(dev);\n\n\t\t\tif (!ingress)\n\t\t\t\tdev_queue = netdev_get_tx_queue(dev, i);\n\n\t\t\told = dev_graft_qdisc(dev_queue, new);\n\t\t\tif (new && i > 0)\n\t\t\t\tqdisc_refcount_inc(new);\n\n\t\t\tif (!ingress)\n\t\t\t\tqdisc_put(old);\n\t\t}\n\nskip:\n\t\tif (!ingress) {\n\t\t\told = rtnl_dereference(dev->qdisc);\n\t\t\tif (new && !new->ops->attach)\n\t\t\t\tqdisc_refcount_inc(new);\n\t\t\trcu_assign_pointer(dev->qdisc, new ? : &noop_qdisc);\n\n\t\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\n\t\t\tif (new && new->ops->attach)\n\t\t\t\tnew->ops->attach(new);\n\t\t} else {\n\t\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\t\t}\n\n\t\tif (dev->flags & IFF_UP)\n\t\t\tdev_activate(dev);\n\t} else {\n\t\tconst struct Qdisc_class_ops *cops = parent->ops->cl_ops;\n\t\tunsigned long cl;\n\t\tint err;\n\n\t\t/* Only support running class lockless if parent is lockless */\n\t\tif (new && (new->flags & TCQ_F_NOLOCK) && !(parent->flags & TCQ_F_NOLOCK))\n\t\t\tqdisc_clear_nolock(new);\n\n\t\tif (!cops || !cops->graft)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tcl = cops->find(parent, classid);\n\t\tif (!cl) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Specified class not found\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tif (new && new->ops == &noqueue_qdisc_ops) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Cannot assign noqueue to a class\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\terr = cops->graft(parent, cl, new, &old, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tnotify_and_destroy(net, skb, n, classid, old, new);\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -78,6 +78,11 @@\n \t\t\treturn -ENOENT;\n \t\t}\n \n+\t\tif (new && new->ops == &noqueue_qdisc_ops) {\n+\t\t\tNL_SET_ERR_MSG(extack, \"Cannot assign noqueue to a class\");\n+\t\t\treturn -EINVAL;\n+\t\t}\n+\n \t\terr = cops->graft(parent, cl, new, &old, extack);\n \t\tif (err)\n \t\t\treturn err;",
        "function_modified_lines": {
            "added": [
                "\t\tif (new && new->ops == &noqueue_qdisc_ops) {",
                "\t\t\tNL_SET_ERR_MSG(extack, \"Cannot assign noqueue to a class\");",
                "\t\t\treturn -EINVAL;",
                "\t\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 6.1.6, a NULL pointer dereference bug in the traffic control subsystem allows an unprivileged user to trigger a denial of service (system crash) via a crafted traffic control configuration that is set up with \"tc qdisc\" and \"tc class\" commands. This affects qdisc_graft in net/sched/sch_api.c.",
        "id": 3766
    },
    {
        "cve_id": "CVE-2019-12984",
        "code_before_change": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}",
        "code_after_change": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,8 @@\n \tu32 device_idx, target_idx;\n \tint rc;\n \n-\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n+\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n+\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n \t\treturn -EINVAL;\n \n \tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);",
        "function_modified_lines": {
            "added": [
                "\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||",
                "\t    !info->attrs[NFC_ATTR_TARGET_INDEX])"
            ],
            "deleted": [
                "\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference vulnerability in the function nfc_genl_deactivate_target() in net/nfc/netlink.c in the Linux kernel before 5.1.13 can be triggered by a malicious user-mode program that omits certain NFC attributes, leading to denial of service.",
        "id": 1956
    },
    {
        "cve_id": "CVE-2019-12381",
        "code_before_change": "int ip_ra_control(struct sock *sk, unsigned char on,\n\t\t  void (*destructor)(struct sock *))\n{\n\tstruct ip_ra_chain *ra, *new_ra;\n\tstruct ip_ra_chain __rcu **rap;\n\tstruct net *net = sock_net(sk);\n\n\tif (sk->sk_type != SOCK_RAW || inet_sk(sk)->inet_num == IPPROTO_RAW)\n\t\treturn -EINVAL;\n\n\tnew_ra = on ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n\n\tmutex_lock(&net->ipv4.ra_mutex);\n\tfor (rap = &net->ipv4.ra_chain;\n\t     (ra = rcu_dereference_protected(*rap,\n\t\t\tlockdep_is_held(&net->ipv4.ra_mutex))) != NULL;\n\t     rap = &ra->next) {\n\t\tif (ra->sk == sk) {\n\t\t\tif (on) {\n\t\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\t\t\tkfree(new_ra);\n\t\t\t\treturn -EADDRINUSE;\n\t\t\t}\n\t\t\t/* dont let ip_call_ra_chain() use sk again */\n\t\t\tra->sk = NULL;\n\t\t\tRCU_INIT_POINTER(*rap, ra->next);\n\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\t\t\tif (ra->destructor)\n\t\t\t\tra->destructor(sk);\n\t\t\t/*\n\t\t\t * Delay sock_put(sk) and kfree(ra) after one rcu grace\n\t\t\t * period. This guarantee ip_call_ra_chain() dont need\n\t\t\t * to mess with socket refcounts.\n\t\t\t */\n\t\t\tra->saved_sk = sk;\n\t\t\tcall_rcu(&ra->rcu, ip_ra_destroy_rcu);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (!new_ra) {\n\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\treturn -ENOBUFS;\n\t}\n\tnew_ra->sk = sk;\n\tnew_ra->destructor = destructor;\n\n\tRCU_INIT_POINTER(new_ra->next, ra);\n\trcu_assign_pointer(*rap, new_ra);\n\tsock_hold(sk);\n\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\treturn 0;\n}",
        "code_after_change": "int ip_ra_control(struct sock *sk, unsigned char on,\n\t\t  void (*destructor)(struct sock *))\n{\n\tstruct ip_ra_chain *ra, *new_ra;\n\tstruct ip_ra_chain __rcu **rap;\n\tstruct net *net = sock_net(sk);\n\n\tif (sk->sk_type != SOCK_RAW || inet_sk(sk)->inet_num == IPPROTO_RAW)\n\t\treturn -EINVAL;\n\n\tnew_ra = on ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n\tif (on && !new_ra)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&net->ipv4.ra_mutex);\n\tfor (rap = &net->ipv4.ra_chain;\n\t     (ra = rcu_dereference_protected(*rap,\n\t\t\tlockdep_is_held(&net->ipv4.ra_mutex))) != NULL;\n\t     rap = &ra->next) {\n\t\tif (ra->sk == sk) {\n\t\t\tif (on) {\n\t\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\t\t\tkfree(new_ra);\n\t\t\t\treturn -EADDRINUSE;\n\t\t\t}\n\t\t\t/* dont let ip_call_ra_chain() use sk again */\n\t\t\tra->sk = NULL;\n\t\t\tRCU_INIT_POINTER(*rap, ra->next);\n\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\t\t\tif (ra->destructor)\n\t\t\t\tra->destructor(sk);\n\t\t\t/*\n\t\t\t * Delay sock_put(sk) and kfree(ra) after one rcu grace\n\t\t\t * period. This guarantee ip_call_ra_chain() dont need\n\t\t\t * to mess with socket refcounts.\n\t\t\t */\n\t\t\tra->saved_sk = sk;\n\t\t\tcall_rcu(&ra->rcu, ip_ra_destroy_rcu);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (!new_ra) {\n\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\treturn -ENOBUFS;\n\t}\n\tnew_ra->sk = sk;\n\tnew_ra->destructor = destructor;\n\n\tRCU_INIT_POINTER(new_ra->next, ra);\n\trcu_assign_pointer(*rap, new_ra);\n\tsock_hold(sk);\n\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,8 @@\n \t\treturn -EINVAL;\n \n \tnew_ra = on ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n+\tif (on && !new_ra)\n+\t\treturn -ENOMEM;\n \n \tmutex_lock(&net->ipv4.ra_mutex);\n \tfor (rap = &net->ipv4.ra_chain;",
        "function_modified_lines": {
            "added": [
                "\tif (on && !new_ra)",
                "\t\treturn -ENOMEM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in ip_ra_control in net/ipv4/ip_sockglue.c in the Linux kernel through 5.1.5. There is an unchecked kmalloc of new_ra, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash). NOTE: this is disputed because new_ra is never used if it is NULL",
        "id": 1943
    },
    {
        "cve_id": "CVE-2019-15924",
        "code_before_change": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}",
        "code_after_change": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\tif (!fm10k_workqueue)\n\t\treturn -ENOMEM;\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,8 @@\n \t/* create driver workqueue */\n \tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n \t\t\t\t\t  fm10k_driver_name);\n+\tif (!fm10k_workqueue)\n+\t\treturn -ENOMEM;\n \n \tfm10k_dbg_init();\n ",
        "function_modified_lines": {
            "added": [
                "\tif (!fm10k_workqueue)",
                "\t\treturn -ENOMEM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.11. fm10k_init_module in drivers/net/ethernet/intel/fm10k/fm10k_main.c has a NULL pointer dereference because there is no -ENOMEM upon an alloc_workqueue failure.",
        "id": 2036
    },
    {
        "cve_id": "CVE-2020-11668",
        "code_before_change": "static int cit_get_packet_size(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_host_interface *alt;\n\tstruct usb_interface *intf;\n\n\tintf = usb_ifnum_to_if(gspca_dev->dev, gspca_dev->iface);\n\talt = usb_altnum_to_altsetting(intf, gspca_dev->alt);\n\tif (!alt) {\n\t\tpr_err(\"Couldn't get altsetting\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n}",
        "code_after_change": "static int cit_get_packet_size(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_host_interface *alt;\n\tstruct usb_interface *intf;\n\n\tintf = usb_ifnum_to_if(gspca_dev->dev, gspca_dev->iface);\n\talt = usb_altnum_to_altsetting(intf, gspca_dev->alt);\n\tif (!alt) {\n\t\tpr_err(\"Couldn't get altsetting\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (alt->desc.bNumEndpoints < 1)\n\t\treturn -ENODEV;\n\n\treturn le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,5 +10,8 @@\n \t\treturn -EIO;\n \t}\n \n+\tif (alt->desc.bNumEndpoints < 1)\n+\t\treturn -ENODEV;\n+\n \treturn le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (alt->desc.bNumEndpoints < 1)",
                "\t\treturn -ENODEV;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.6.1, drivers/media/usb/gspca/xirlink_cit.c (aka the Xirlink camera USB driver) mishandles invalid descriptors, aka CID-a246b4d54770.",
        "id": 2434
    },
    {
        "cve_id": "CVE-2020-11668",
        "code_before_change": "static int sd_isoc_init(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_host_interface *alt;\n\tint max_packet_size;\n\n\tswitch (gspca_dev->pixfmt.width) {\n\tcase 160:\n\t\tmax_packet_size = 450;\n\t\tbreak;\n\tcase 176:\n\t\tmax_packet_size = 600;\n\t\tbreak;\n\tdefault:\n\t\tmax_packet_size = 1022;\n\t\tbreak;\n\t}\n\n\t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(max_packet_size);\n\n\treturn 0;\n}",
        "code_after_change": "static int sd_isoc_init(struct gspca_dev *gspca_dev)\n{\n\tstruct usb_interface_cache *intfc;\n\tstruct usb_host_interface *alt;\n\tint max_packet_size;\n\n\tswitch (gspca_dev->pixfmt.width) {\n\tcase 160:\n\t\tmax_packet_size = 450;\n\t\tbreak;\n\tcase 176:\n\t\tmax_packet_size = 600;\n\t\tbreak;\n\tdefault:\n\t\tmax_packet_size = 1022;\n\t\tbreak;\n\t}\n\n\tintfc = gspca_dev->dev->actconfig->intf_cache[0];\n\n\tif (intfc->num_altsetting < 2)\n\t\treturn -ENODEV;\n\n\talt = &intfc->altsetting[1];\n\n\tif (alt->desc.bNumEndpoints < 1)\n\t\treturn -ENODEV;\n\n\t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(max_packet_size);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,6 @@\n static int sd_isoc_init(struct gspca_dev *gspca_dev)\n {\n+\tstruct usb_interface_cache *intfc;\n \tstruct usb_host_interface *alt;\n \tint max_packet_size;\n \n@@ -15,8 +16,17 @@\n \t\tbreak;\n \t}\n \n+\tintfc = gspca_dev->dev->actconfig->intf_cache[0];\n+\n+\tif (intfc->num_altsetting < 2)\n+\t\treturn -ENODEV;\n+\n+\talt = &intfc->altsetting[1];\n+\n+\tif (alt->desc.bNumEndpoints < 1)\n+\t\treturn -ENODEV;\n+\n \t/* Start isoc bandwidth \"negotiation\" at max isoc bandwidth */\n-\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n \talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(max_packet_size);\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_interface_cache *intfc;",
                "\tintfc = gspca_dev->dev->actconfig->intf_cache[0];",
                "",
                "\tif (intfc->num_altsetting < 2)",
                "\t\treturn -ENODEV;",
                "",
                "\talt = &intfc->altsetting[1];",
                "",
                "\tif (alt->desc.bNumEndpoints < 1)",
                "\t\treturn -ENODEV;",
                ""
            ],
            "deleted": [
                "\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.6.1, drivers/media/usb/gspca/xirlink_cit.c (aka the Xirlink camera USB driver) mishandles invalid descriptors, aka CID-a246b4d54770.",
        "id": 2433
    },
    {
        "cve_id": "CVE-2023-0458",
        "code_before_change": "static int do_prlimit(struct task_struct *tsk, unsigned int resource,\n\t\t      struct rlimit *new_rlim, struct rlimit *old_rlim)\n{\n\tstruct rlimit *rlim;\n\tint retval = 0;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tif (new_rlim) {\n\t\tif (new_rlim->rlim_cur > new_rlim->rlim_max)\n\t\t\treturn -EINVAL;\n\t\tif (resource == RLIMIT_NOFILE &&\n\t\t\t\tnew_rlim->rlim_max > sysctl_nr_open)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Holding a refcount on tsk protects tsk->signal from disappearing. */\n\trlim = tsk->signal->rlim + resource;\n\ttask_lock(tsk->group_leader);\n\tif (new_rlim) {\n\t\t/*\n\t\t * Keep the capable check against init_user_ns until cgroups can\n\t\t * contain all limits.\n\t\t */\n\t\tif (new_rlim->rlim_max > rlim->rlim_max &&\n\t\t\t\t!capable(CAP_SYS_RESOURCE))\n\t\t\tretval = -EPERM;\n\t\tif (!retval)\n\t\t\tretval = security_task_setrlimit(tsk, resource, new_rlim);\n\t}\n\tif (!retval) {\n\t\tif (old_rlim)\n\t\t\t*old_rlim = *rlim;\n\t\tif (new_rlim)\n\t\t\t*rlim = *new_rlim;\n\t}\n\ttask_unlock(tsk->group_leader);\n\n\t/*\n\t * RLIMIT_CPU handling. Arm the posix CPU timer if the limit is not\n\t * infinite. In case of RLIM_INFINITY the posix CPU timer code\n\t * ignores the rlimit.\n\t */\n\tif (!retval && new_rlim && resource == RLIMIT_CPU &&\n\t    new_rlim->rlim_cur != RLIM_INFINITY &&\n\t    IS_ENABLED(CONFIG_POSIX_TIMERS)) {\n\t\t/*\n\t\t * update_rlimit_cpu can fail if the task is exiting, but there\n\t\t * may be other tasks in the thread group that are not exiting,\n\t\t * and they need their cpu timers adjusted.\n\t\t *\n\t\t * The group_leader is the last task to be released, so if we\n\t\t * cannot update_rlimit_cpu on it, then the entire process is\n\t\t * exiting and we do not need to update at all.\n\t\t */\n\t\tupdate_rlimit_cpu(tsk->group_leader, new_rlim->rlim_cur);\n\t}\n\n\treturn retval;\n}",
        "code_after_change": "static int do_prlimit(struct task_struct *tsk, unsigned int resource,\n\t\t      struct rlimit *new_rlim, struct rlimit *old_rlim)\n{\n\tstruct rlimit *rlim;\n\tint retval = 0;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n\n\tif (new_rlim) {\n\t\tif (new_rlim->rlim_cur > new_rlim->rlim_max)\n\t\t\treturn -EINVAL;\n\t\tif (resource == RLIMIT_NOFILE &&\n\t\t\t\tnew_rlim->rlim_max > sysctl_nr_open)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Holding a refcount on tsk protects tsk->signal from disappearing. */\n\trlim = tsk->signal->rlim + resource;\n\ttask_lock(tsk->group_leader);\n\tif (new_rlim) {\n\t\t/*\n\t\t * Keep the capable check against init_user_ns until cgroups can\n\t\t * contain all limits.\n\t\t */\n\t\tif (new_rlim->rlim_max > rlim->rlim_max &&\n\t\t\t\t!capable(CAP_SYS_RESOURCE))\n\t\t\tretval = -EPERM;\n\t\tif (!retval)\n\t\t\tretval = security_task_setrlimit(tsk, resource, new_rlim);\n\t}\n\tif (!retval) {\n\t\tif (old_rlim)\n\t\t\t*old_rlim = *rlim;\n\t\tif (new_rlim)\n\t\t\t*rlim = *new_rlim;\n\t}\n\ttask_unlock(tsk->group_leader);\n\n\t/*\n\t * RLIMIT_CPU handling. Arm the posix CPU timer if the limit is not\n\t * infinite. In case of RLIM_INFINITY the posix CPU timer code\n\t * ignores the rlimit.\n\t */\n\tif (!retval && new_rlim && resource == RLIMIT_CPU &&\n\t    new_rlim->rlim_cur != RLIM_INFINITY &&\n\t    IS_ENABLED(CONFIG_POSIX_TIMERS)) {\n\t\t/*\n\t\t * update_rlimit_cpu can fail if the task is exiting, but there\n\t\t * may be other tasks in the thread group that are not exiting,\n\t\t * and they need their cpu timers adjusted.\n\t\t *\n\t\t * The group_leader is the last task to be released, so if we\n\t\t * cannot update_rlimit_cpu on it, then the entire process is\n\t\t * exiting and we do not need to update at all.\n\t\t */\n\t\tupdate_rlimit_cpu(tsk->group_leader, new_rlim->rlim_cur);\n\t}\n\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,8 @@\n \n \tif (resource >= RLIM_NLIMITS)\n \t\treturn -EINVAL;\n+\tresource = array_index_nospec(resource, RLIM_NLIMITS);\n+\n \tif (new_rlim) {\n \t\tif (new_rlim->rlim_cur > new_rlim->rlim_max)\n \t\t\treturn -EINVAL;",
        "function_modified_lines": {
            "added": [
                "\tresource = array_index_nospec(resource, RLIM_NLIMITS);",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A speculative pointer dereference problem exists in the Linux Kernel on the do_prlimit() function. The resource argument value is controlled and is used in pointer arithmetic for the 'rlim' variable and can be used to leak the contents. We recommend upgrading past version 6.1.8 or commit 739790605705ddcf18f21782b9c99ad7d53a8c11",
        "id": 3825
    },
    {
        "cve_id": "CVE-2020-11609",
        "code_before_change": "static int pb0100_start(struct sd *sd)\n{\n\tint err, packet_size, max_packet_size;\n\tstruct usb_host_interface *alt;\n\tstruct usb_interface *intf;\n\tstruct gspca_dev *gspca_dev = (struct gspca_dev *)sd;\n\tstruct cam *cam = &sd->gspca_dev.cam;\n\tu32 mode = cam->cam_mode[sd->gspca_dev.curr_mode].priv;\n\n\tintf = usb_ifnum_to_if(sd->gspca_dev.dev, sd->gspca_dev.iface);\n\talt = usb_altnum_to_altsetting(intf, sd->gspca_dev.alt);\n\tif (!alt)\n\t\treturn -ENODEV;\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\n\t/* If we don't have enough bandwidth use a lower framerate */\n\tmax_packet_size = sd->sensor->max_packet_size[sd->gspca_dev.curr_mode];\n\tif (packet_size < max_packet_size)\n\t\tstv06xx_write_sensor(sd, PB_ROWSPEED, BIT(4)|BIT(3)|BIT(1));\n\telse\n\t\tstv06xx_write_sensor(sd, PB_ROWSPEED, BIT(5)|BIT(3)|BIT(1));\n\n\t/* Setup sensor window */\n\tif (mode & PB0100_CROP_TO_VGA) {\n\t\tstv06xx_write_sensor(sd, PB_RSTART, 30);\n\t\tstv06xx_write_sensor(sd, PB_CSTART, 20);\n\t\tstv06xx_write_sensor(sd, PB_RWSIZE, 240 - 1);\n\t\tstv06xx_write_sensor(sd, PB_CWSIZE, 320 - 1);\n\t} else {\n\t\tstv06xx_write_sensor(sd, PB_RSTART, 8);\n\t\tstv06xx_write_sensor(sd, PB_CSTART, 4);\n\t\tstv06xx_write_sensor(sd, PB_RWSIZE, 288 - 1);\n\t\tstv06xx_write_sensor(sd, PB_CWSIZE, 352 - 1);\n\t}\n\n\tif (mode & PB0100_SUBSAMPLE) {\n\t\tstv06xx_write_bridge(sd, STV_Y_CTRL, 0x02); /* Wrong, FIXME */\n\t\tstv06xx_write_bridge(sd, STV_X_CTRL, 0x06);\n\n\t\tstv06xx_write_bridge(sd, STV_SCAN_RATE, 0x10);\n\t} else {\n\t\tstv06xx_write_bridge(sd, STV_Y_CTRL, 0x01);\n\t\tstv06xx_write_bridge(sd, STV_X_CTRL, 0x0a);\n\t\t/* larger -> slower */\n\t\tstv06xx_write_bridge(sd, STV_SCAN_RATE, 0x20);\n\t}\n\n\terr = stv06xx_write_sensor(sd, PB_CONTROL, BIT(5)|BIT(3)|BIT(1));\n\tgspca_dbg(gspca_dev, D_STREAM, \"Started stream, status: %d\\n\", err);\n\n\treturn (err < 0) ? err : 0;\n}",
        "code_after_change": "static int pb0100_start(struct sd *sd)\n{\n\tint err, packet_size, max_packet_size;\n\tstruct usb_host_interface *alt;\n\tstruct usb_interface *intf;\n\tstruct gspca_dev *gspca_dev = (struct gspca_dev *)sd;\n\tstruct cam *cam = &sd->gspca_dev.cam;\n\tu32 mode = cam->cam_mode[sd->gspca_dev.curr_mode].priv;\n\n\tintf = usb_ifnum_to_if(sd->gspca_dev.dev, sd->gspca_dev.iface);\n\talt = usb_altnum_to_altsetting(intf, sd->gspca_dev.alt);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\tif (alt->desc.bNumEndpoints < 1)\n\t\treturn -ENODEV;\n\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\n\t/* If we don't have enough bandwidth use a lower framerate */\n\tmax_packet_size = sd->sensor->max_packet_size[sd->gspca_dev.curr_mode];\n\tif (packet_size < max_packet_size)\n\t\tstv06xx_write_sensor(sd, PB_ROWSPEED, BIT(4)|BIT(3)|BIT(1));\n\telse\n\t\tstv06xx_write_sensor(sd, PB_ROWSPEED, BIT(5)|BIT(3)|BIT(1));\n\n\t/* Setup sensor window */\n\tif (mode & PB0100_CROP_TO_VGA) {\n\t\tstv06xx_write_sensor(sd, PB_RSTART, 30);\n\t\tstv06xx_write_sensor(sd, PB_CSTART, 20);\n\t\tstv06xx_write_sensor(sd, PB_RWSIZE, 240 - 1);\n\t\tstv06xx_write_sensor(sd, PB_CWSIZE, 320 - 1);\n\t} else {\n\t\tstv06xx_write_sensor(sd, PB_RSTART, 8);\n\t\tstv06xx_write_sensor(sd, PB_CSTART, 4);\n\t\tstv06xx_write_sensor(sd, PB_RWSIZE, 288 - 1);\n\t\tstv06xx_write_sensor(sd, PB_CWSIZE, 352 - 1);\n\t}\n\n\tif (mode & PB0100_SUBSAMPLE) {\n\t\tstv06xx_write_bridge(sd, STV_Y_CTRL, 0x02); /* Wrong, FIXME */\n\t\tstv06xx_write_bridge(sd, STV_X_CTRL, 0x06);\n\n\t\tstv06xx_write_bridge(sd, STV_SCAN_RATE, 0x10);\n\t} else {\n\t\tstv06xx_write_bridge(sd, STV_Y_CTRL, 0x01);\n\t\tstv06xx_write_bridge(sd, STV_X_CTRL, 0x0a);\n\t\t/* larger -> slower */\n\t\tstv06xx_write_bridge(sd, STV_SCAN_RATE, 0x20);\n\t}\n\n\terr = stv06xx_write_sensor(sd, PB_CONTROL, BIT(5)|BIT(3)|BIT(1));\n\tgspca_dbg(gspca_dev, D_STREAM, \"Started stream, status: %d\\n\", err);\n\n\treturn (err < 0) ? err : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,10 @@\n \talt = usb_altnum_to_altsetting(intf, sd->gspca_dev.alt);\n \tif (!alt)\n \t\treturn -ENODEV;\n+\n+\tif (alt->desc.bNumEndpoints < 1)\n+\t\treturn -ENODEV;\n+\n \tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n \n \t/* If we don't have enough bandwidth use a lower framerate */",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (alt->desc.bNumEndpoints < 1)",
                "\t\treturn -ENODEV;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the stv06xx subsystem in the Linux kernel before 5.6.1. drivers/media/usb/gspca/stv06xx/stv06xx.c and drivers/media/usb/gspca/stv06xx/stv06xx_pb0100.c mishandle invalid descriptors, as demonstrated by a NULL pointer dereference, aka CID-485b06aadb93.",
        "id": 2432
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static int read_one_chunk(struct btrfs_fs_info *fs_info, struct btrfs_key *key,\n\t\t\t  struct extent_buffer *leaf,\n\t\t\t  struct btrfs_chunk *chunk)\n{\n\tstruct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;\n\tstruct map_lookup *map;\n\tstruct extent_map *em;\n\tu64 logical;\n\tu64 length;\n\tu64 devid;\n\tu8 uuid[BTRFS_UUID_SIZE];\n\tint num_stripes;\n\tint ret;\n\tint i;\n\n\tlogical = key->offset;\n\tlength = btrfs_chunk_length(leaf, chunk);\n\tnum_stripes = btrfs_chunk_num_stripes(leaf, chunk);\n\n\tret = btrfs_check_chunk_valid(fs_info, leaf, chunk, logical);\n\tif (ret)\n\t\treturn ret;\n\n\tread_lock(&map_tree->map_tree.lock);\n\tem = lookup_extent_mapping(&map_tree->map_tree, logical, 1);\n\tread_unlock(&map_tree->map_tree.lock);\n\n\t/* already mapped? */\n\tif (em && em->start <= logical && em->start + em->len > logical) {\n\t\tfree_extent_map(em);\n\t\treturn 0;\n\t} else if (em) {\n\t\tfree_extent_map(em);\n\t}\n\n\tem = alloc_extent_map();\n\tif (!em)\n\t\treturn -ENOMEM;\n\tmap = kmalloc(map_lookup_size(num_stripes), GFP_NOFS);\n\tif (!map) {\n\t\tfree_extent_map(em);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_bit(EXTENT_FLAG_FS_MAPPING, &em->flags);\n\tem->map_lookup = map;\n\tem->start = logical;\n\tem->len = length;\n\tem->orig_start = 0;\n\tem->block_start = 0;\n\tem->block_len = em->len;\n\n\tmap->num_stripes = num_stripes;\n\tmap->io_width = btrfs_chunk_io_width(leaf, chunk);\n\tmap->io_align = btrfs_chunk_io_align(leaf, chunk);\n\tmap->stripe_len = btrfs_chunk_stripe_len(leaf, chunk);\n\tmap->type = btrfs_chunk_type(leaf, chunk);\n\tmap->sub_stripes = btrfs_chunk_sub_stripes(leaf, chunk);\n\tmap->verified_stripes = 0;\n\tfor (i = 0; i < num_stripes; i++) {\n\t\tmap->stripes[i].physical =\n\t\t\tbtrfs_stripe_offset_nr(leaf, chunk, i);\n\t\tdevid = btrfs_stripe_devid_nr(leaf, chunk, i);\n\t\tread_extent_buffer(leaf, uuid, (unsigned long)\n\t\t\t\t   btrfs_stripe_dev_uuid_nr(chunk, i),\n\t\t\t\t   BTRFS_UUID_SIZE);\n\t\tmap->stripes[i].dev = btrfs_find_device(fs_info->fs_devices,\n\t\t\t\t\t\t\tdevid, uuid, NULL);\n\t\tif (!map->stripes[i].dev &&\n\t\t    !btrfs_test_opt(fs_info, DEGRADED)) {\n\t\t\tfree_extent_map(em);\n\t\t\tbtrfs_report_missing_device(fs_info, devid, uuid, true);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tif (!map->stripes[i].dev) {\n\t\t\tmap->stripes[i].dev =\n\t\t\t\tadd_missing_dev(fs_info->fs_devices, devid,\n\t\t\t\t\t\tuuid);\n\t\t\tif (IS_ERR(map->stripes[i].dev)) {\n\t\t\t\tfree_extent_map(em);\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t\t\"failed to init missing dev %llu: %ld\",\n\t\t\t\t\tdevid, PTR_ERR(map->stripes[i].dev));\n\t\t\t\treturn PTR_ERR(map->stripes[i].dev);\n\t\t\t}\n\t\t\tbtrfs_report_missing_device(fs_info, devid, uuid, false);\n\t\t}\n\t\tset_bit(BTRFS_DEV_STATE_IN_FS_METADATA,\n\t\t\t\t&(map->stripes[i].dev->dev_state));\n\n\t}\n\n\twrite_lock(&map_tree->map_tree.lock);\n\tret = add_extent_mapping(&map_tree->map_tree, em, 0);\n\twrite_unlock(&map_tree->map_tree.lock);\n\tif (ret < 0) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"failed to add chunk map, start=%llu len=%llu: %d\",\n\t\t\t  em->start, em->len, ret);\n\t}\n\tfree_extent_map(em);\n\n\treturn ret;\n}",
        "code_after_change": "static int read_one_chunk(struct btrfs_fs_info *fs_info, struct btrfs_key *key,\n\t\t\t  struct extent_buffer *leaf,\n\t\t\t  struct btrfs_chunk *chunk)\n{\n\tstruct btrfs_mapping_tree *map_tree = &fs_info->mapping_tree;\n\tstruct map_lookup *map;\n\tstruct extent_map *em;\n\tu64 logical;\n\tu64 length;\n\tu64 devid;\n\tu8 uuid[BTRFS_UUID_SIZE];\n\tint num_stripes;\n\tint ret;\n\tint i;\n\n\tlogical = key->offset;\n\tlength = btrfs_chunk_length(leaf, chunk);\n\tnum_stripes = btrfs_chunk_num_stripes(leaf, chunk);\n\n\tret = btrfs_check_chunk_valid(fs_info, leaf, chunk, logical);\n\tif (ret)\n\t\treturn ret;\n\n\tread_lock(&map_tree->map_tree.lock);\n\tem = lookup_extent_mapping(&map_tree->map_tree, logical, 1);\n\tread_unlock(&map_tree->map_tree.lock);\n\n\t/* already mapped? */\n\tif (em && em->start <= logical && em->start + em->len > logical) {\n\t\tfree_extent_map(em);\n\t\treturn 0;\n\t} else if (em) {\n\t\tfree_extent_map(em);\n\t}\n\n\tem = alloc_extent_map();\n\tif (!em)\n\t\treturn -ENOMEM;\n\tmap = kmalloc(map_lookup_size(num_stripes), GFP_NOFS);\n\tif (!map) {\n\t\tfree_extent_map(em);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_bit(EXTENT_FLAG_FS_MAPPING, &em->flags);\n\tem->map_lookup = map;\n\tem->start = logical;\n\tem->len = length;\n\tem->orig_start = 0;\n\tem->block_start = 0;\n\tem->block_len = em->len;\n\n\tmap->num_stripes = num_stripes;\n\tmap->io_width = btrfs_chunk_io_width(leaf, chunk);\n\tmap->io_align = btrfs_chunk_io_align(leaf, chunk);\n\tmap->stripe_len = btrfs_chunk_stripe_len(leaf, chunk);\n\tmap->type = btrfs_chunk_type(leaf, chunk);\n\tmap->sub_stripes = btrfs_chunk_sub_stripes(leaf, chunk);\n\tmap->verified_stripes = 0;\n\tfor (i = 0; i < num_stripes; i++) {\n\t\tmap->stripes[i].physical =\n\t\t\tbtrfs_stripe_offset_nr(leaf, chunk, i);\n\t\tdevid = btrfs_stripe_devid_nr(leaf, chunk, i);\n\t\tread_extent_buffer(leaf, uuid, (unsigned long)\n\t\t\t\t   btrfs_stripe_dev_uuid_nr(chunk, i),\n\t\t\t\t   BTRFS_UUID_SIZE);\n\t\tmap->stripes[i].dev = btrfs_find_device(fs_info->fs_devices,\n\t\t\t\t\t\t\tdevid, uuid, NULL, true);\n\t\tif (!map->stripes[i].dev &&\n\t\t    !btrfs_test_opt(fs_info, DEGRADED)) {\n\t\t\tfree_extent_map(em);\n\t\t\tbtrfs_report_missing_device(fs_info, devid, uuid, true);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tif (!map->stripes[i].dev) {\n\t\t\tmap->stripes[i].dev =\n\t\t\t\tadd_missing_dev(fs_info->fs_devices, devid,\n\t\t\t\t\t\tuuid);\n\t\t\tif (IS_ERR(map->stripes[i].dev)) {\n\t\t\t\tfree_extent_map(em);\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t\t\"failed to init missing dev %llu: %ld\",\n\t\t\t\t\tdevid, PTR_ERR(map->stripes[i].dev));\n\t\t\t\treturn PTR_ERR(map->stripes[i].dev);\n\t\t\t}\n\t\t\tbtrfs_report_missing_device(fs_info, devid, uuid, false);\n\t\t}\n\t\tset_bit(BTRFS_DEV_STATE_IN_FS_METADATA,\n\t\t\t\t&(map->stripes[i].dev->dev_state));\n\n\t}\n\n\twrite_lock(&map_tree->map_tree.lock);\n\tret = add_extent_mapping(&map_tree->map_tree, em, 0);\n\twrite_unlock(&map_tree->map_tree.lock);\n\tif (ret < 0) {\n\t\tbtrfs_err(fs_info,\n\t\t\t  \"failed to add chunk map, start=%llu len=%llu: %d\",\n\t\t\t  em->start, em->len, ret);\n\t}\n\tfree_extent_map(em);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -65,7 +65,7 @@\n \t\t\t\t   btrfs_stripe_dev_uuid_nr(chunk, i),\n \t\t\t\t   BTRFS_UUID_SIZE);\n \t\tmap->stripes[i].dev = btrfs_find_device(fs_info->fs_devices,\n-\t\t\t\t\t\t\tdevid, uuid, NULL);\n+\t\t\t\t\t\t\tdevid, uuid, NULL, true);\n \t\tif (!map->stripes[i].dev &&\n \t\t    !btrfs_test_opt(fs_info, DEGRADED)) {\n \t\t\tfree_extent_map(em);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t\t\tdevid, uuid, NULL, true);"
            ],
            "deleted": [
                "\t\t\t\t\t\t\tdevid, uuid, NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2115
    },
    {
        "cve_id": "CVE-2015-7515",
        "code_before_change": "static int\naiptek_probe(struct usb_interface *intf, const struct usb_device_id *id)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct usb_endpoint_descriptor *endpoint;\n\tstruct aiptek *aiptek;\n\tstruct input_dev *inputdev;\n\tint i;\n\tint speeds[] = { 0,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_50,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_400,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_25,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_100,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_200,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_300\n\t};\n\tint err = -ENOMEM;\n\n\t/* programmableDelay is where the command-line specified\n\t * delay is kept. We make it the first element of speeds[],\n\t * so therefore, your override speed is tried first, then the\n\t * remainder. Note that the default value of 400ms will be tried\n\t * if you do not specify any command line parameter.\n\t */\n\tspeeds[0] = programmableDelay;\n\n\taiptek = kzalloc(sizeof(struct aiptek), GFP_KERNEL);\n\tinputdev = input_allocate_device();\n\tif (!aiptek || !inputdev) {\n\t\tdev_warn(&intf->dev,\n\t\t\t \"cannot allocate memory or input device\\n\");\n\t\tgoto fail1;\n        }\n\n\taiptek->data = usb_alloc_coherent(usbdev, AIPTEK_PACKET_LENGTH,\n\t\t\t\t\t  GFP_ATOMIC, &aiptek->data_dma);\n        if (!aiptek->data) {\n\t\tdev_warn(&intf->dev, \"cannot allocate usb buffer\\n\");\n\t\tgoto fail1;\n\t}\n\n\taiptek->urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!aiptek->urb) {\n\t        dev_warn(&intf->dev, \"cannot allocate urb\\n\");\n\t\tgoto fail2;\n\t}\n\n\taiptek->inputdev = inputdev;\n\taiptek->usbdev = usbdev;\n\taiptek->intf = intf;\n\taiptek->ifnum = intf->altsetting[0].desc.bInterfaceNumber;\n\taiptek->inDelay = 0;\n\taiptek->endDelay = 0;\n\taiptek->previousJitterable = 0;\n\taiptek->lastMacro = -1;\n\n\t/* Set up the curSettings struct. Said struct contains the current\n\t * programmable parameters. The newSetting struct contains changes\n\t * the user makes to the settings via the sysfs interface. Those\n\t * changes are not \"committed\" to curSettings until the user\n\t * writes to the sysfs/.../execute file.\n\t */\n\taiptek->curSetting.pointerMode = AIPTEK_POINTER_EITHER_MODE;\n\taiptek->curSetting.coordinateMode = AIPTEK_COORDINATE_ABSOLUTE_MODE;\n\taiptek->curSetting.toolMode = AIPTEK_TOOL_BUTTON_PEN_MODE;\n\taiptek->curSetting.xTilt = AIPTEK_TILT_DISABLE;\n\taiptek->curSetting.yTilt = AIPTEK_TILT_DISABLE;\n\taiptek->curSetting.mouseButtonLeft = AIPTEK_MOUSE_LEFT_BUTTON;\n\taiptek->curSetting.mouseButtonMiddle = AIPTEK_MOUSE_MIDDLE_BUTTON;\n\taiptek->curSetting.mouseButtonRight = AIPTEK_MOUSE_RIGHT_BUTTON;\n\taiptek->curSetting.stylusButtonUpper = AIPTEK_STYLUS_UPPER_BUTTON;\n\taiptek->curSetting.stylusButtonLower = AIPTEK_STYLUS_LOWER_BUTTON;\n\taiptek->curSetting.jitterDelay = jitterDelay;\n\taiptek->curSetting.programmableDelay = programmableDelay;\n\n\t/* Both structs should have equivalent settings\n\t */\n\taiptek->newSetting = aiptek->curSetting;\n\n\t/* Determine the usb devices' physical path.\n\t * Asketh not why we always pretend we're using \"../input0\",\n\t * but I suspect this will have to be refactored one\n\t * day if a single USB device can be a keyboard & a mouse\n\t * & a tablet, and the inputX number actually will tell\n\t * us something...\n\t */\n\tusb_make_path(usbdev, aiptek->features.usbPath,\n\t\t\tsizeof(aiptek->features.usbPath));\n\tstrlcat(aiptek->features.usbPath, \"/input0\",\n\t\tsizeof(aiptek->features.usbPath));\n\n\t/* Set up client data, pointers to open and close routines\n\t * for the input device.\n\t */\n\tinputdev->name = \"Aiptek\";\n\tinputdev->phys = aiptek->features.usbPath;\n\tusb_to_input_id(usbdev, &inputdev->id);\n\tinputdev->dev.parent = &intf->dev;\n\n\tinput_set_drvdata(inputdev, aiptek);\n\n\tinputdev->open = aiptek_open;\n\tinputdev->close = aiptek_close;\n\n\t/* Now program the capacities of the tablet, in terms of being\n\t * an input device.\n\t */\n\tfor (i = 0; i < ARRAY_SIZE(eventTypes); ++i)\n\t        __set_bit(eventTypes[i], inputdev->evbit);\n\n\tfor (i = 0; i < ARRAY_SIZE(absEvents); ++i)\n\t        __set_bit(absEvents[i], inputdev->absbit);\n\n\tfor (i = 0; i < ARRAY_SIZE(relEvents); ++i)\n\t        __set_bit(relEvents[i], inputdev->relbit);\n\n\t__set_bit(MSC_SERIAL, inputdev->mscbit);\n\n\t/* Set up key and button codes */\n\tfor (i = 0; i < ARRAY_SIZE(buttonEvents); ++i)\n\t\t__set_bit(buttonEvents[i], inputdev->keybit);\n\n\tfor (i = 0; i < ARRAY_SIZE(macroKeyEvents); ++i)\n\t\t__set_bit(macroKeyEvents[i], inputdev->keybit);\n\n\t/*\n\t * Program the input device coordinate capacities. We do not yet\n\t * know what maximum X, Y, and Z values are, so we're putting fake\n\t * values in. Later, we'll ask the tablet to put in the correct\n\t * values.\n\t */\n\tinput_set_abs_params(inputdev, ABS_X, 0, 2999, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_Y, 0, 2249, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_PRESSURE, 0, 511, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_TILT_X, AIPTEK_TILT_MIN, AIPTEK_TILT_MAX, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_TILT_Y, AIPTEK_TILT_MIN, AIPTEK_TILT_MAX, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_WHEEL, AIPTEK_WHEEL_MIN, AIPTEK_WHEEL_MAX - 1, 0, 0);\n\n\tendpoint = &intf->altsetting[0].endpoint[0].desc;\n\n\t/* Go set up our URB, which is called when the tablet receives\n\t * input.\n\t */\n\tusb_fill_int_urb(aiptek->urb,\n\t\t\t aiptek->usbdev,\n\t\t\t usb_rcvintpipe(aiptek->usbdev,\n\t\t\t\t\tendpoint->bEndpointAddress),\n\t\t\t aiptek->data, 8, aiptek_irq, aiptek,\n\t\t\t endpoint->bInterval);\n\n\taiptek->urb->transfer_dma = aiptek->data_dma;\n\taiptek->urb->transfer_flags |= URB_NO_TRANSFER_DMA_MAP;\n\n\t/* Program the tablet. This sets the tablet up in the mode\n\t * specified in newSetting, and also queries the tablet's\n\t * physical capacities.\n\t *\n\t * Sanity check: if a tablet doesn't like the slow programmatic\n\t * delay, we often get sizes of 0x0. Let's use that as an indicator\n\t * to try faster delays, up to 25 ms. If that logic fails, well, you'll\n\t * have to explain to us how your tablet thinks it's 0x0, and yet that's\n\t * not an error :-)\n\t */\n\n\tfor (i = 0; i < ARRAY_SIZE(speeds); ++i) {\n\t\taiptek->curSetting.programmableDelay = speeds[i];\n\t\t(void)aiptek_program_tablet(aiptek);\n\t\tif (input_abs_get_max(aiptek->inputdev, ABS_X) > 0) {\n\t\t\tdev_info(&intf->dev,\n\t\t\t\t \"Aiptek using %d ms programming speed\\n\",\n\t\t\t\t aiptek->curSetting.programmableDelay);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Murphy says that some day someone will have a tablet that fails the\n\t   above test. That's you, Frederic Rodrigo */\n\tif (i == ARRAY_SIZE(speeds)) {\n\t\tdev_info(&intf->dev,\n\t\t\t \"Aiptek tried all speeds, no sane response\\n\");\n\t\tgoto fail3;\n\t}\n\n\t/* Associate this driver's struct with the usb interface.\n\t */\n\tusb_set_intfdata(intf, aiptek);\n\n\t/* Set up the sysfs files\n\t */\n\terr = sysfs_create_group(&intf->dev.kobj, &aiptek_attribute_group);\n\tif (err) {\n\t\tdev_warn(&intf->dev, \"cannot create sysfs group err: %d\\n\",\n\t\t\t err);\n\t\tgoto fail3;\n        }\n\n\t/* Register the tablet as an Input Device\n\t */\n\terr = input_register_device(aiptek->inputdev);\n\tif (err) {\n\t\tdev_warn(&intf->dev,\n\t\t\t \"input_register_device returned err: %d\\n\", err);\n\t\tgoto fail4;\n        }\n\treturn 0;\n\n fail4:\tsysfs_remove_group(&intf->dev.kobj, &aiptek_attribute_group);\n fail3: usb_free_urb(aiptek->urb);\n fail2:\tusb_free_coherent(usbdev, AIPTEK_PACKET_LENGTH, aiptek->data,\n\t\t\t  aiptek->data_dma);\n fail1: usb_set_intfdata(intf, NULL);\n\tinput_free_device(inputdev);\n\tkfree(aiptek);\n\treturn err;\n}",
        "code_after_change": "static int\naiptek_probe(struct usb_interface *intf, const struct usb_device_id *id)\n{\n\tstruct usb_device *usbdev = interface_to_usbdev(intf);\n\tstruct usb_endpoint_descriptor *endpoint;\n\tstruct aiptek *aiptek;\n\tstruct input_dev *inputdev;\n\tint i;\n\tint speeds[] = { 0,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_50,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_400,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_25,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_100,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_200,\n\t\tAIPTEK_PROGRAMMABLE_DELAY_300\n\t};\n\tint err = -ENOMEM;\n\n\t/* programmableDelay is where the command-line specified\n\t * delay is kept. We make it the first element of speeds[],\n\t * so therefore, your override speed is tried first, then the\n\t * remainder. Note that the default value of 400ms will be tried\n\t * if you do not specify any command line parameter.\n\t */\n\tspeeds[0] = programmableDelay;\n\n\taiptek = kzalloc(sizeof(struct aiptek), GFP_KERNEL);\n\tinputdev = input_allocate_device();\n\tif (!aiptek || !inputdev) {\n\t\tdev_warn(&intf->dev,\n\t\t\t \"cannot allocate memory or input device\\n\");\n\t\tgoto fail1;\n        }\n\n\taiptek->data = usb_alloc_coherent(usbdev, AIPTEK_PACKET_LENGTH,\n\t\t\t\t\t  GFP_ATOMIC, &aiptek->data_dma);\n        if (!aiptek->data) {\n\t\tdev_warn(&intf->dev, \"cannot allocate usb buffer\\n\");\n\t\tgoto fail1;\n\t}\n\n\taiptek->urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!aiptek->urb) {\n\t        dev_warn(&intf->dev, \"cannot allocate urb\\n\");\n\t\tgoto fail2;\n\t}\n\n\taiptek->inputdev = inputdev;\n\taiptek->usbdev = usbdev;\n\taiptek->intf = intf;\n\taiptek->ifnum = intf->altsetting[0].desc.bInterfaceNumber;\n\taiptek->inDelay = 0;\n\taiptek->endDelay = 0;\n\taiptek->previousJitterable = 0;\n\taiptek->lastMacro = -1;\n\n\t/* Set up the curSettings struct. Said struct contains the current\n\t * programmable parameters. The newSetting struct contains changes\n\t * the user makes to the settings via the sysfs interface. Those\n\t * changes are not \"committed\" to curSettings until the user\n\t * writes to the sysfs/.../execute file.\n\t */\n\taiptek->curSetting.pointerMode = AIPTEK_POINTER_EITHER_MODE;\n\taiptek->curSetting.coordinateMode = AIPTEK_COORDINATE_ABSOLUTE_MODE;\n\taiptek->curSetting.toolMode = AIPTEK_TOOL_BUTTON_PEN_MODE;\n\taiptek->curSetting.xTilt = AIPTEK_TILT_DISABLE;\n\taiptek->curSetting.yTilt = AIPTEK_TILT_DISABLE;\n\taiptek->curSetting.mouseButtonLeft = AIPTEK_MOUSE_LEFT_BUTTON;\n\taiptek->curSetting.mouseButtonMiddle = AIPTEK_MOUSE_MIDDLE_BUTTON;\n\taiptek->curSetting.mouseButtonRight = AIPTEK_MOUSE_RIGHT_BUTTON;\n\taiptek->curSetting.stylusButtonUpper = AIPTEK_STYLUS_UPPER_BUTTON;\n\taiptek->curSetting.stylusButtonLower = AIPTEK_STYLUS_LOWER_BUTTON;\n\taiptek->curSetting.jitterDelay = jitterDelay;\n\taiptek->curSetting.programmableDelay = programmableDelay;\n\n\t/* Both structs should have equivalent settings\n\t */\n\taiptek->newSetting = aiptek->curSetting;\n\n\t/* Determine the usb devices' physical path.\n\t * Asketh not why we always pretend we're using \"../input0\",\n\t * but I suspect this will have to be refactored one\n\t * day if a single USB device can be a keyboard & a mouse\n\t * & a tablet, and the inputX number actually will tell\n\t * us something...\n\t */\n\tusb_make_path(usbdev, aiptek->features.usbPath,\n\t\t\tsizeof(aiptek->features.usbPath));\n\tstrlcat(aiptek->features.usbPath, \"/input0\",\n\t\tsizeof(aiptek->features.usbPath));\n\n\t/* Set up client data, pointers to open and close routines\n\t * for the input device.\n\t */\n\tinputdev->name = \"Aiptek\";\n\tinputdev->phys = aiptek->features.usbPath;\n\tusb_to_input_id(usbdev, &inputdev->id);\n\tinputdev->dev.parent = &intf->dev;\n\n\tinput_set_drvdata(inputdev, aiptek);\n\n\tinputdev->open = aiptek_open;\n\tinputdev->close = aiptek_close;\n\n\t/* Now program the capacities of the tablet, in terms of being\n\t * an input device.\n\t */\n\tfor (i = 0; i < ARRAY_SIZE(eventTypes); ++i)\n\t        __set_bit(eventTypes[i], inputdev->evbit);\n\n\tfor (i = 0; i < ARRAY_SIZE(absEvents); ++i)\n\t        __set_bit(absEvents[i], inputdev->absbit);\n\n\tfor (i = 0; i < ARRAY_SIZE(relEvents); ++i)\n\t        __set_bit(relEvents[i], inputdev->relbit);\n\n\t__set_bit(MSC_SERIAL, inputdev->mscbit);\n\n\t/* Set up key and button codes */\n\tfor (i = 0; i < ARRAY_SIZE(buttonEvents); ++i)\n\t\t__set_bit(buttonEvents[i], inputdev->keybit);\n\n\tfor (i = 0; i < ARRAY_SIZE(macroKeyEvents); ++i)\n\t\t__set_bit(macroKeyEvents[i], inputdev->keybit);\n\n\t/*\n\t * Program the input device coordinate capacities. We do not yet\n\t * know what maximum X, Y, and Z values are, so we're putting fake\n\t * values in. Later, we'll ask the tablet to put in the correct\n\t * values.\n\t */\n\tinput_set_abs_params(inputdev, ABS_X, 0, 2999, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_Y, 0, 2249, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_PRESSURE, 0, 511, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_TILT_X, AIPTEK_TILT_MIN, AIPTEK_TILT_MAX, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_TILT_Y, AIPTEK_TILT_MIN, AIPTEK_TILT_MAX, 0, 0);\n\tinput_set_abs_params(inputdev, ABS_WHEEL, AIPTEK_WHEEL_MIN, AIPTEK_WHEEL_MAX - 1, 0, 0);\n\n\t/* Verify that a device really has an endpoint */\n\tif (intf->altsetting[0].desc.bNumEndpoints < 1) {\n\t\tdev_err(&intf->dev,\n\t\t\t\"interface has %d endpoints, but must have minimum 1\\n\",\n\t\t\tintf->altsetting[0].desc.bNumEndpoints);\n\t\terr = -EINVAL;\n\t\tgoto fail3;\n\t}\n\tendpoint = &intf->altsetting[0].endpoint[0].desc;\n\n\t/* Go set up our URB, which is called when the tablet receives\n\t * input.\n\t */\n\tusb_fill_int_urb(aiptek->urb,\n\t\t\t aiptek->usbdev,\n\t\t\t usb_rcvintpipe(aiptek->usbdev,\n\t\t\t\t\tendpoint->bEndpointAddress),\n\t\t\t aiptek->data, 8, aiptek_irq, aiptek,\n\t\t\t endpoint->bInterval);\n\n\taiptek->urb->transfer_dma = aiptek->data_dma;\n\taiptek->urb->transfer_flags |= URB_NO_TRANSFER_DMA_MAP;\n\n\t/* Program the tablet. This sets the tablet up in the mode\n\t * specified in newSetting, and also queries the tablet's\n\t * physical capacities.\n\t *\n\t * Sanity check: if a tablet doesn't like the slow programmatic\n\t * delay, we often get sizes of 0x0. Let's use that as an indicator\n\t * to try faster delays, up to 25 ms. If that logic fails, well, you'll\n\t * have to explain to us how your tablet thinks it's 0x0, and yet that's\n\t * not an error :-)\n\t */\n\n\tfor (i = 0; i < ARRAY_SIZE(speeds); ++i) {\n\t\taiptek->curSetting.programmableDelay = speeds[i];\n\t\t(void)aiptek_program_tablet(aiptek);\n\t\tif (input_abs_get_max(aiptek->inputdev, ABS_X) > 0) {\n\t\t\tdev_info(&intf->dev,\n\t\t\t\t \"Aiptek using %d ms programming speed\\n\",\n\t\t\t\t aiptek->curSetting.programmableDelay);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Murphy says that some day someone will have a tablet that fails the\n\t   above test. That's you, Frederic Rodrigo */\n\tif (i == ARRAY_SIZE(speeds)) {\n\t\tdev_info(&intf->dev,\n\t\t\t \"Aiptek tried all speeds, no sane response\\n\");\n\t\terr = -EINVAL;\n\t\tgoto fail3;\n\t}\n\n\t/* Associate this driver's struct with the usb interface.\n\t */\n\tusb_set_intfdata(intf, aiptek);\n\n\t/* Set up the sysfs files\n\t */\n\terr = sysfs_create_group(&intf->dev.kobj, &aiptek_attribute_group);\n\tif (err) {\n\t\tdev_warn(&intf->dev, \"cannot create sysfs group err: %d\\n\",\n\t\t\t err);\n\t\tgoto fail3;\n        }\n\n\t/* Register the tablet as an Input Device\n\t */\n\terr = input_register_device(aiptek->inputdev);\n\tif (err) {\n\t\tdev_warn(&intf->dev,\n\t\t\t \"input_register_device returned err: %d\\n\", err);\n\t\tgoto fail4;\n        }\n\treturn 0;\n\n fail4:\tsysfs_remove_group(&intf->dev.kobj, &aiptek_attribute_group);\n fail3: usb_free_urb(aiptek->urb);\n fail2:\tusb_free_coherent(usbdev, AIPTEK_PACKET_LENGTH, aiptek->data,\n\t\t\t  aiptek->data_dma);\n fail1: usb_set_intfdata(intf, NULL);\n\tinput_free_device(inputdev);\n\tkfree(aiptek);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -136,6 +136,14 @@\n \tinput_set_abs_params(inputdev, ABS_TILT_Y, AIPTEK_TILT_MIN, AIPTEK_TILT_MAX, 0, 0);\n \tinput_set_abs_params(inputdev, ABS_WHEEL, AIPTEK_WHEEL_MIN, AIPTEK_WHEEL_MAX - 1, 0, 0);\n \n+\t/* Verify that a device really has an endpoint */\n+\tif (intf->altsetting[0].desc.bNumEndpoints < 1) {\n+\t\tdev_err(&intf->dev,\n+\t\t\t\"interface has %d endpoints, but must have minimum 1\\n\",\n+\t\t\tintf->altsetting[0].desc.bNumEndpoints);\n+\t\terr = -EINVAL;\n+\t\tgoto fail3;\n+\t}\n \tendpoint = &intf->altsetting[0].endpoint[0].desc;\n \n \t/* Go set up our URB, which is called when the tablet receives\n@@ -178,6 +186,7 @@\n \tif (i == ARRAY_SIZE(speeds)) {\n \t\tdev_info(&intf->dev,\n \t\t\t \"Aiptek tried all speeds, no sane response\\n\");\n+\t\terr = -EINVAL;\n \t\tgoto fail3;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t/* Verify that a device really has an endpoint */",
                "\tif (intf->altsetting[0].desc.bNumEndpoints < 1) {",
                "\t\tdev_err(&intf->dev,",
                "\t\t\t\"interface has %d endpoints, but must have minimum 1\\n\",",
                "\t\t\tintf->altsetting[0].desc.bNumEndpoints);",
                "\t\terr = -EINVAL;",
                "\t\tgoto fail3;",
                "\t}",
                "\t\terr = -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The aiptek_probe function in drivers/input/tablet/aiptek.c in the Linux kernel before 4.4 allows physically proximate attackers to cause a denial of service (NULL pointer dereference and system crash) via a crafted USB device that lacks endpoints.",
        "id": 785
    },
    {
        "cve_id": "CVE-2023-2177",
        "code_before_change": "static struct sctp_association *sctp_association_init(\n\t\t\t\t\tstruct sctp_association *asoc,\n\t\t\t\t\tconst struct sctp_endpoint *ep,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tenum sctp_scope scope, gfp_t gfp)\n{\n\tstruct sctp_sock *sp;\n\tstruct sctp_paramhdr *p;\n\tint i;\n\n\t/* Retrieve the SCTP per socket area.  */\n\tsp = sctp_sk((struct sock *)sk);\n\n\t/* Discarding const is appropriate here.  */\n\tasoc->ep = (struct sctp_endpoint *)ep;\n\tasoc->base.sk = (struct sock *)sk;\n\tasoc->base.net = sock_net(sk);\n\n\tsctp_endpoint_hold(asoc->ep);\n\tsock_hold(asoc->base.sk);\n\n\t/* Initialize the common base substructure.  */\n\tasoc->base.type = SCTP_EP_TYPE_ASSOCIATION;\n\n\t/* Initialize the object handling fields.  */\n\trefcount_set(&asoc->base.refcnt, 1);\n\n\t/* Initialize the bind addr area.  */\n\tsctp_bind_addr_init(&asoc->base.bind_addr, ep->base.bind_addr.port);\n\n\tasoc->state = SCTP_STATE_CLOSED;\n\tasoc->cookie_life = ms_to_ktime(sp->assocparams.sasoc_cookie_life);\n\tasoc->user_frag = sp->user_frag;\n\n\t/* Set the association max_retrans and RTO values from the\n\t * socket values.\n\t */\n\tasoc->max_retrans = sp->assocparams.sasoc_asocmaxrxt;\n\tasoc->pf_retrans  = sp->pf_retrans;\n\tasoc->ps_retrans  = sp->ps_retrans;\n\tasoc->pf_expose   = sp->pf_expose;\n\n\tasoc->rto_initial = msecs_to_jiffies(sp->rtoinfo.srto_initial);\n\tasoc->rto_max = msecs_to_jiffies(sp->rtoinfo.srto_max);\n\tasoc->rto_min = msecs_to_jiffies(sp->rtoinfo.srto_min);\n\n\t/* Initialize the association's heartbeat interval based on the\n\t * sock configured value.\n\t */\n\tasoc->hbinterval = msecs_to_jiffies(sp->hbinterval);\n\tasoc->probe_interval = msecs_to_jiffies(sp->probe_interval);\n\n\tasoc->encap_port = sp->encap_port;\n\n\t/* Initialize path max retrans value. */\n\tasoc->pathmaxrxt = sp->pathmaxrxt;\n\n\tasoc->flowlabel = sp->flowlabel;\n\tasoc->dscp = sp->dscp;\n\n\t/* Set association default SACK delay */\n\tasoc->sackdelay = msecs_to_jiffies(sp->sackdelay);\n\tasoc->sackfreq = sp->sackfreq;\n\n\t/* Set the association default flags controlling\n\t * Heartbeat, SACK delay, and Path MTU Discovery.\n\t */\n\tasoc->param_flags = sp->param_flags;\n\n\t/* Initialize the maximum number of new data packets that can be sent\n\t * in a burst.\n\t */\n\tasoc->max_burst = sp->max_burst;\n\n\tasoc->subscribe = sp->subscribe;\n\n\t/* initialize association timers */\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T1_COOKIE] = asoc->rto_initial;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T1_INIT] = asoc->rto_initial;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T2_SHUTDOWN] = asoc->rto_initial;\n\n\t/* sctpimpguide Section 2.12.2\n\t * If the 'T5-shutdown-guard' timer is used, it SHOULD be set to the\n\t * recommended value of 5 times 'RTO.Max'.\n\t */\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T5_SHUTDOWN_GUARD]\n\t\t= 5 * asoc->rto_max;\n\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_SACK] = asoc->sackdelay;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_AUTOCLOSE] = sp->autoclose * HZ;\n\n\t/* Initializes the timers */\n\tfor (i = SCTP_EVENT_TIMEOUT_NONE; i < SCTP_NUM_TIMEOUT_TYPES; ++i)\n\t\ttimer_setup(&asoc->timers[i], sctp_timer_events[i], 0);\n\n\t/* Pull default initialization values from the sock options.\n\t * Note: This assumes that the values have already been\n\t * validated in the sock.\n\t */\n\tasoc->c.sinit_max_instreams = sp->initmsg.sinit_max_instreams;\n\tasoc->c.sinit_num_ostreams  = sp->initmsg.sinit_num_ostreams;\n\tasoc->max_init_attempts\t= sp->initmsg.sinit_max_attempts;\n\n\tasoc->max_init_timeo =\n\t\t msecs_to_jiffies(sp->initmsg.sinit_max_init_timeo);\n\n\t/* Set the local window size for receive.\n\t * This is also the rcvbuf space per association.\n\t * RFC 6 - A SCTP receiver MUST be able to receive a minimum of\n\t * 1500 bytes in one SCTP packet.\n\t */\n\tif ((sk->sk_rcvbuf/2) < SCTP_DEFAULT_MINWINDOW)\n\t\tasoc->rwnd = SCTP_DEFAULT_MINWINDOW;\n\telse\n\t\tasoc->rwnd = sk->sk_rcvbuf/2;\n\n\tasoc->a_rwnd = asoc->rwnd;\n\n\t/* Use my own max window until I learn something better.  */\n\tasoc->peer.rwnd = SCTP_DEFAULT_MAXWINDOW;\n\n\t/* Initialize the receive memory counter */\n\tatomic_set(&asoc->rmem_alloc, 0);\n\n\tinit_waitqueue_head(&asoc->wait);\n\n\tasoc->c.my_vtag = sctp_generate_tag(ep);\n\tasoc->c.my_port = ep->base.bind_addr.port;\n\n\tasoc->c.initial_tsn = sctp_generate_tsn(ep);\n\n\tasoc->next_tsn = asoc->c.initial_tsn;\n\n\tasoc->ctsn_ack_point = asoc->next_tsn - 1;\n\tasoc->adv_peer_ack_point = asoc->ctsn_ack_point;\n\tasoc->highest_sacked = asoc->ctsn_ack_point;\n\tasoc->last_cwr_tsn = asoc->ctsn_ack_point;\n\n\t/* ADDIP Section 4.1 Asconf Chunk Procedures\n\t *\n\t * When an endpoint has an ASCONF signaled change to be sent to the\n\t * remote endpoint it should do the following:\n\t * ...\n\t * A2) a serial number should be assigned to the chunk. The serial\n\t * number SHOULD be a monotonically increasing number. The serial\n\t * numbers SHOULD be initialized at the start of the\n\t * association to the same value as the initial TSN.\n\t */\n\tasoc->addip_serial = asoc->c.initial_tsn;\n\tasoc->strreset_outseq = asoc->c.initial_tsn;\n\n\tINIT_LIST_HEAD(&asoc->addip_chunk_list);\n\tINIT_LIST_HEAD(&asoc->asconf_ack_list);\n\n\t/* Make an empty list of remote transport addresses.  */\n\tINIT_LIST_HEAD(&asoc->peer.transport_addr_list);\n\n\t/* RFC 2960 5.1 Normal Establishment of an Association\n\t *\n\t * After the reception of the first data chunk in an\n\t * association the endpoint must immediately respond with a\n\t * sack to acknowledge the data chunk.  Subsequent\n\t * acknowledgements should be done as described in Section\n\t * 6.2.\n\t *\n\t * [We implement this by telling a new association that it\n\t * already received one packet.]\n\t */\n\tasoc->peer.sack_needed = 1;\n\tasoc->peer.sack_generation = 1;\n\n\t/* Create an input queue.  */\n\tsctp_inq_init(&asoc->base.inqueue);\n\tsctp_inq_set_th_handler(&asoc->base.inqueue, sctp_assoc_bh_rcv);\n\n\t/* Create an output queue.  */\n\tsctp_outq_init(asoc, &asoc->outqueue);\n\n\tif (!sctp_ulpq_init(&asoc->ulpq, asoc))\n\t\tgoto fail_init;\n\n\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams,\n\t\t\t     0, gfp))\n\t\tgoto fail_init;\n\n\t/* Initialize default path MTU. */\n\tasoc->pathmtu = sp->pathmtu;\n\tsctp_assoc_update_frag_point(asoc);\n\n\t/* Assume that peer would support both address types unless we are\n\t * told otherwise.\n\t */\n\tasoc->peer.ipv4_address = 1;\n\tif (asoc->base.sk->sk_family == PF_INET6)\n\t\tasoc->peer.ipv6_address = 1;\n\tINIT_LIST_HEAD(&asoc->asocs);\n\n\tasoc->default_stream = sp->default_stream;\n\tasoc->default_ppid = sp->default_ppid;\n\tasoc->default_flags = sp->default_flags;\n\tasoc->default_context = sp->default_context;\n\tasoc->default_timetolive = sp->default_timetolive;\n\tasoc->default_rcv_context = sp->default_rcv_context;\n\n\t/* AUTH related initializations */\n\tINIT_LIST_HEAD(&asoc->endpoint_shared_keys);\n\tif (sctp_auth_asoc_copy_shkeys(ep, asoc, gfp))\n\t\tgoto stream_free;\n\n\tasoc->active_key_id = ep->active_key_id;\n\tasoc->strreset_enable = ep->strreset_enable;\n\n\t/* Save the hmacs and chunks list into this association */\n\tif (ep->auth_hmacs_list)\n\t\tmemcpy(asoc->c.auth_hmacs, ep->auth_hmacs_list,\n\t\t\tntohs(ep->auth_hmacs_list->param_hdr.length));\n\tif (ep->auth_chunk_list)\n\t\tmemcpy(asoc->c.auth_chunks, ep->auth_chunk_list,\n\t\t\tntohs(ep->auth_chunk_list->param_hdr.length));\n\n\t/* Get the AUTH random number for this association */\n\tp = (struct sctp_paramhdr *)asoc->c.auth_random;\n\tp->type = SCTP_PARAM_RANDOM;\n\tp->length = htons(sizeof(*p) + SCTP_AUTH_RANDOM_LENGTH);\n\tget_random_bytes(p+1, SCTP_AUTH_RANDOM_LENGTH);\n\n\treturn asoc;\n\nstream_free:\n\tsctp_stream_free(&asoc->stream);\nfail_init:\n\tsock_put(asoc->base.sk);\n\tsctp_endpoint_put(asoc->ep);\n\treturn NULL;\n}",
        "code_after_change": "static struct sctp_association *sctp_association_init(\n\t\t\t\t\tstruct sctp_association *asoc,\n\t\t\t\t\tconst struct sctp_endpoint *ep,\n\t\t\t\t\tconst struct sock *sk,\n\t\t\t\t\tenum sctp_scope scope, gfp_t gfp)\n{\n\tstruct sctp_sock *sp;\n\tstruct sctp_paramhdr *p;\n\tint i;\n\n\t/* Retrieve the SCTP per socket area.  */\n\tsp = sctp_sk((struct sock *)sk);\n\n\t/* Discarding const is appropriate here.  */\n\tasoc->ep = (struct sctp_endpoint *)ep;\n\tasoc->base.sk = (struct sock *)sk;\n\tasoc->base.net = sock_net(sk);\n\n\tsctp_endpoint_hold(asoc->ep);\n\tsock_hold(asoc->base.sk);\n\n\t/* Initialize the common base substructure.  */\n\tasoc->base.type = SCTP_EP_TYPE_ASSOCIATION;\n\n\t/* Initialize the object handling fields.  */\n\trefcount_set(&asoc->base.refcnt, 1);\n\n\t/* Initialize the bind addr area.  */\n\tsctp_bind_addr_init(&asoc->base.bind_addr, ep->base.bind_addr.port);\n\n\tasoc->state = SCTP_STATE_CLOSED;\n\tasoc->cookie_life = ms_to_ktime(sp->assocparams.sasoc_cookie_life);\n\tasoc->user_frag = sp->user_frag;\n\n\t/* Set the association max_retrans and RTO values from the\n\t * socket values.\n\t */\n\tasoc->max_retrans = sp->assocparams.sasoc_asocmaxrxt;\n\tasoc->pf_retrans  = sp->pf_retrans;\n\tasoc->ps_retrans  = sp->ps_retrans;\n\tasoc->pf_expose   = sp->pf_expose;\n\n\tasoc->rto_initial = msecs_to_jiffies(sp->rtoinfo.srto_initial);\n\tasoc->rto_max = msecs_to_jiffies(sp->rtoinfo.srto_max);\n\tasoc->rto_min = msecs_to_jiffies(sp->rtoinfo.srto_min);\n\n\t/* Initialize the association's heartbeat interval based on the\n\t * sock configured value.\n\t */\n\tasoc->hbinterval = msecs_to_jiffies(sp->hbinterval);\n\tasoc->probe_interval = msecs_to_jiffies(sp->probe_interval);\n\n\tasoc->encap_port = sp->encap_port;\n\n\t/* Initialize path max retrans value. */\n\tasoc->pathmaxrxt = sp->pathmaxrxt;\n\n\tasoc->flowlabel = sp->flowlabel;\n\tasoc->dscp = sp->dscp;\n\n\t/* Set association default SACK delay */\n\tasoc->sackdelay = msecs_to_jiffies(sp->sackdelay);\n\tasoc->sackfreq = sp->sackfreq;\n\n\t/* Set the association default flags controlling\n\t * Heartbeat, SACK delay, and Path MTU Discovery.\n\t */\n\tasoc->param_flags = sp->param_flags;\n\n\t/* Initialize the maximum number of new data packets that can be sent\n\t * in a burst.\n\t */\n\tasoc->max_burst = sp->max_burst;\n\n\tasoc->subscribe = sp->subscribe;\n\n\t/* initialize association timers */\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T1_COOKIE] = asoc->rto_initial;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T1_INIT] = asoc->rto_initial;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T2_SHUTDOWN] = asoc->rto_initial;\n\n\t/* sctpimpguide Section 2.12.2\n\t * If the 'T5-shutdown-guard' timer is used, it SHOULD be set to the\n\t * recommended value of 5 times 'RTO.Max'.\n\t */\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_T5_SHUTDOWN_GUARD]\n\t\t= 5 * asoc->rto_max;\n\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_SACK] = asoc->sackdelay;\n\tasoc->timeouts[SCTP_EVENT_TIMEOUT_AUTOCLOSE] = sp->autoclose * HZ;\n\n\t/* Initializes the timers */\n\tfor (i = SCTP_EVENT_TIMEOUT_NONE; i < SCTP_NUM_TIMEOUT_TYPES; ++i)\n\t\ttimer_setup(&asoc->timers[i], sctp_timer_events[i], 0);\n\n\t/* Pull default initialization values from the sock options.\n\t * Note: This assumes that the values have already been\n\t * validated in the sock.\n\t */\n\tasoc->c.sinit_max_instreams = sp->initmsg.sinit_max_instreams;\n\tasoc->c.sinit_num_ostreams  = sp->initmsg.sinit_num_ostreams;\n\tasoc->max_init_attempts\t= sp->initmsg.sinit_max_attempts;\n\n\tasoc->max_init_timeo =\n\t\t msecs_to_jiffies(sp->initmsg.sinit_max_init_timeo);\n\n\t/* Set the local window size for receive.\n\t * This is also the rcvbuf space per association.\n\t * RFC 6 - A SCTP receiver MUST be able to receive a minimum of\n\t * 1500 bytes in one SCTP packet.\n\t */\n\tif ((sk->sk_rcvbuf/2) < SCTP_DEFAULT_MINWINDOW)\n\t\tasoc->rwnd = SCTP_DEFAULT_MINWINDOW;\n\telse\n\t\tasoc->rwnd = sk->sk_rcvbuf/2;\n\n\tasoc->a_rwnd = asoc->rwnd;\n\n\t/* Use my own max window until I learn something better.  */\n\tasoc->peer.rwnd = SCTP_DEFAULT_MAXWINDOW;\n\n\t/* Initialize the receive memory counter */\n\tatomic_set(&asoc->rmem_alloc, 0);\n\n\tinit_waitqueue_head(&asoc->wait);\n\n\tasoc->c.my_vtag = sctp_generate_tag(ep);\n\tasoc->c.my_port = ep->base.bind_addr.port;\n\n\tasoc->c.initial_tsn = sctp_generate_tsn(ep);\n\n\tasoc->next_tsn = asoc->c.initial_tsn;\n\n\tasoc->ctsn_ack_point = asoc->next_tsn - 1;\n\tasoc->adv_peer_ack_point = asoc->ctsn_ack_point;\n\tasoc->highest_sacked = asoc->ctsn_ack_point;\n\tasoc->last_cwr_tsn = asoc->ctsn_ack_point;\n\n\t/* ADDIP Section 4.1 Asconf Chunk Procedures\n\t *\n\t * When an endpoint has an ASCONF signaled change to be sent to the\n\t * remote endpoint it should do the following:\n\t * ...\n\t * A2) a serial number should be assigned to the chunk. The serial\n\t * number SHOULD be a monotonically increasing number. The serial\n\t * numbers SHOULD be initialized at the start of the\n\t * association to the same value as the initial TSN.\n\t */\n\tasoc->addip_serial = asoc->c.initial_tsn;\n\tasoc->strreset_outseq = asoc->c.initial_tsn;\n\n\tINIT_LIST_HEAD(&asoc->addip_chunk_list);\n\tINIT_LIST_HEAD(&asoc->asconf_ack_list);\n\n\t/* Make an empty list of remote transport addresses.  */\n\tINIT_LIST_HEAD(&asoc->peer.transport_addr_list);\n\n\t/* RFC 2960 5.1 Normal Establishment of an Association\n\t *\n\t * After the reception of the first data chunk in an\n\t * association the endpoint must immediately respond with a\n\t * sack to acknowledge the data chunk.  Subsequent\n\t * acknowledgements should be done as described in Section\n\t * 6.2.\n\t *\n\t * [We implement this by telling a new association that it\n\t * already received one packet.]\n\t */\n\tasoc->peer.sack_needed = 1;\n\tasoc->peer.sack_generation = 1;\n\n\t/* Create an input queue.  */\n\tsctp_inq_init(&asoc->base.inqueue);\n\tsctp_inq_set_th_handler(&asoc->base.inqueue, sctp_assoc_bh_rcv);\n\n\t/* Create an output queue.  */\n\tsctp_outq_init(asoc, &asoc->outqueue);\n\n\tif (!sctp_ulpq_init(&asoc->ulpq, asoc))\n\t\tgoto fail_init;\n\n\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams, 0, gfp))\n\t\tgoto stream_free;\n\n\t/* Initialize default path MTU. */\n\tasoc->pathmtu = sp->pathmtu;\n\tsctp_assoc_update_frag_point(asoc);\n\n\t/* Assume that peer would support both address types unless we are\n\t * told otherwise.\n\t */\n\tasoc->peer.ipv4_address = 1;\n\tif (asoc->base.sk->sk_family == PF_INET6)\n\t\tasoc->peer.ipv6_address = 1;\n\tINIT_LIST_HEAD(&asoc->asocs);\n\n\tasoc->default_stream = sp->default_stream;\n\tasoc->default_ppid = sp->default_ppid;\n\tasoc->default_flags = sp->default_flags;\n\tasoc->default_context = sp->default_context;\n\tasoc->default_timetolive = sp->default_timetolive;\n\tasoc->default_rcv_context = sp->default_rcv_context;\n\n\t/* AUTH related initializations */\n\tINIT_LIST_HEAD(&asoc->endpoint_shared_keys);\n\tif (sctp_auth_asoc_copy_shkeys(ep, asoc, gfp))\n\t\tgoto stream_free;\n\n\tasoc->active_key_id = ep->active_key_id;\n\tasoc->strreset_enable = ep->strreset_enable;\n\n\t/* Save the hmacs and chunks list into this association */\n\tif (ep->auth_hmacs_list)\n\t\tmemcpy(asoc->c.auth_hmacs, ep->auth_hmacs_list,\n\t\t\tntohs(ep->auth_hmacs_list->param_hdr.length));\n\tif (ep->auth_chunk_list)\n\t\tmemcpy(asoc->c.auth_chunks, ep->auth_chunk_list,\n\t\t\tntohs(ep->auth_chunk_list->param_hdr.length));\n\n\t/* Get the AUTH random number for this association */\n\tp = (struct sctp_paramhdr *)asoc->c.auth_random;\n\tp->type = SCTP_PARAM_RANDOM;\n\tp->length = htons(sizeof(*p) + SCTP_AUTH_RANDOM_LENGTH);\n\tget_random_bytes(p+1, SCTP_AUTH_RANDOM_LENGTH);\n\n\treturn asoc;\n\nstream_free:\n\tsctp_stream_free(&asoc->stream);\nfail_init:\n\tsock_put(asoc->base.sk);\n\tsctp_endpoint_put(asoc->ep);\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -179,9 +179,8 @@\n \tif (!sctp_ulpq_init(&asoc->ulpq, asoc))\n \t\tgoto fail_init;\n \n-\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams,\n-\t\t\t     0, gfp))\n-\t\tgoto fail_init;\n+\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams, 0, gfp))\n+\t\tgoto stream_free;\n \n \t/* Initialize default path MTU. */\n \tasoc->pathmtu = sp->pathmtu;",
        "function_modified_lines": {
            "added": [
                "\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams, 0, gfp))",
                "\t\tgoto stream_free;"
            ],
            "deleted": [
                "\tif (sctp_stream_init(&asoc->stream, asoc->c.sinit_num_ostreams,",
                "\t\t\t     0, gfp))",
                "\t\tgoto fail_init;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference issue was found in the sctp network protocol in net/sctp/stream_sched.c in Linux Kernel. If stream_in allocation is failed, stream_out is freed which would further be accessed. A local user could use this flaw to crash the system or potentially cause a denial of service.",
        "id": 3932
    },
    {
        "cve_id": "CVE-2022-1852",
        "code_before_change": "int x86_emulate_instruction(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t    int emulation_type, void *insn, int insn_len)\n{\n\tint r;\n\tstruct x86_emulate_ctxt *ctxt = vcpu->arch.emulate_ctxt;\n\tbool writeback = true;\n\tbool write_fault_to_spt;\n\n\tif (unlikely(!kvm_can_emulate_insn(vcpu, emulation_type, insn, insn_len)))\n\t\treturn 1;\n\n\tvcpu->arch.l1tf_flush_l1d = true;\n\n\t/*\n\t * Clear write_fault_to_shadow_pgtable here to ensure it is\n\t * never reused.\n\t */\n\twrite_fault_to_spt = vcpu->arch.write_fault_to_shadow_pgtable;\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tif (!(emulation_type & EMULTYPE_NO_DECODE)) {\n\t\tkvm_clear_exception_queue(vcpu);\n\n\t\tr = x86_decode_emulated_instruction(vcpu, emulation_type,\n\t\t\t\t\t\t    insn, insn_len);\n\t\tif (r != EMULATION_OK)  {\n\t\t\tif ((emulation_type & EMULTYPE_TRAP_UD) ||\n\t\t\t    (emulation_type & EMULTYPE_TRAP_UD_FORCED)) {\n\t\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tif (reexecute_instruction(vcpu, cr2_or_gpa,\n\t\t\t\t\t\t  write_fault_to_spt,\n\t\t\t\t\t\t  emulation_type))\n\t\t\t\treturn 1;\n\t\t\tif (ctxt->have_exception) {\n\t\t\t\t/*\n\t\t\t\t * #UD should result in just EMULATION_FAILED, and trap-like\n\t\t\t\t * exception should not be encountered during decode.\n\t\t\t\t */\n\t\t\t\tWARN_ON_ONCE(ctxt->exception.vector == UD_VECTOR ||\n\t\t\t\t\t     exception_type(ctxt->exception.vector) == EXCPT_TRAP);\n\t\t\t\tinject_emulated_exception(vcpu);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\treturn handle_emulation_failure(vcpu, emulation_type);\n\t\t}\n\t}\n\n\tif ((emulation_type & EMULTYPE_VMWARE_GP) &&\n\t    !is_vmware_backdoor_opcode(ctxt)) {\n\t\tkvm_queue_exception_e(vcpu, GP_VECTOR, 0);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * EMULTYPE_SKIP without EMULTYPE_COMPLETE_USER_EXIT is intended for\n\t * use *only* by vendor callbacks for kvm_skip_emulated_instruction().\n\t * The caller is responsible for updating interruptibility state and\n\t * injecting single-step #DBs.\n\t */\n\tif (emulation_type & EMULTYPE_SKIP) {\n\t\tif (ctxt->mode != X86EMUL_MODE_PROT64)\n\t\t\tctxt->eip = (u32)ctxt->_eip;\n\t\telse\n\t\t\tctxt->eip = ctxt->_eip;\n\n\t\tif (emulation_type & EMULTYPE_COMPLETE_USER_EXIT) {\n\t\t\tr = 1;\n\t\t\tgoto writeback;\n\t\t}\n\n\t\tkvm_rip_write(vcpu, ctxt->eip);\n\t\tif (ctxt->eflags & X86_EFLAGS_RF)\n\t\t\tkvm_set_rflags(vcpu, ctxt->eflags & ~X86_EFLAGS_RF);\n\t\treturn 1;\n\t}\n\n\tif (retry_instruction(ctxt, cr2_or_gpa, emulation_type))\n\t\treturn 1;\n\n\t/* this is needed for vmware backdoor interface to work since it\n\t   changes registers values  during IO operation */\n\tif (vcpu->arch.emulate_regs_need_sync_from_vcpu) {\n\t\tvcpu->arch.emulate_regs_need_sync_from_vcpu = false;\n\t\temulator_invalidate_register_cache(ctxt);\n\t}\n\nrestart:\n\tif (emulation_type & EMULTYPE_PF) {\n\t\t/* Save the faulting GPA (cr2) in the address field */\n\t\tctxt->exception.address = cr2_or_gpa;\n\n\t\t/* With shadow page tables, cr2 contains a GVA or nGPA. */\n\t\tif (vcpu->arch.mmu->root_role.direct) {\n\t\t\tctxt->gpa_available = true;\n\t\t\tctxt->gpa_val = cr2_or_gpa;\n\t\t}\n\t} else {\n\t\t/* Sanitize the address out of an abundance of paranoia. */\n\t\tctxt->exception.address = 0;\n\t}\n\n\tr = x86_emulate_insn(ctxt);\n\n\tif (r == EMULATION_INTERCEPTED)\n\t\treturn 1;\n\n\tif (r == EMULATION_FAILED) {\n\t\tif (reexecute_instruction(vcpu, cr2_or_gpa, write_fault_to_spt,\n\t\t\t\t\temulation_type))\n\t\t\treturn 1;\n\n\t\treturn handle_emulation_failure(vcpu, emulation_type);\n\t}\n\n\tif (ctxt->have_exception) {\n\t\tr = 1;\n\t\tif (inject_emulated_exception(vcpu))\n\t\t\treturn r;\n\t} else if (vcpu->arch.pio.count) {\n\t\tif (!vcpu->arch.pio.in) {\n\t\t\t/* FIXME: return into emulator if single-stepping.  */\n\t\t\tvcpu->arch.pio.count = 0;\n\t\t} else {\n\t\t\twriteback = false;\n\t\t\tvcpu->arch.complete_userspace_io = complete_emulated_pio;\n\t\t}\n\t\tr = 0;\n\t} else if (vcpu->mmio_needed) {\n\t\t++vcpu->stat.mmio_exits;\n\n\t\tif (!vcpu->mmio_is_write)\n\t\t\twriteback = false;\n\t\tr = 0;\n\t\tvcpu->arch.complete_userspace_io = complete_emulated_mmio;\n\t} else if (vcpu->arch.complete_userspace_io) {\n\t\twriteback = false;\n\t\tr = 0;\n\t} else if (r == EMULATION_RESTART)\n\t\tgoto restart;\n\telse\n\t\tr = 1;\n\nwriteback:\n\tif (writeback) {\n\t\tunsigned long rflags = static_call(kvm_x86_get_rflags)(vcpu);\n\t\ttoggle_interruptibility(vcpu, ctxt->interruptibility);\n\t\tvcpu->arch.emulate_regs_need_sync_to_vcpu = false;\n\t\tif (!ctxt->have_exception ||\n\t\t    exception_type(ctxt->exception.vector) == EXCPT_TRAP) {\n\t\t\tkvm_pmu_trigger_event(vcpu, PERF_COUNT_HW_INSTRUCTIONS);\n\t\t\tif (ctxt->is_branch)\n\t\t\t\tkvm_pmu_trigger_event(vcpu, PERF_COUNT_HW_BRANCH_INSTRUCTIONS);\n\t\t\tkvm_rip_write(vcpu, ctxt->eip);\n\t\t\tif (r && (ctxt->tf || (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)))\n\t\t\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\t\t\tstatic_call_cond(kvm_x86_update_emulated_instruction)(vcpu);\n\t\t\t__kvm_set_rflags(vcpu, ctxt->eflags);\n\t\t}\n\n\t\t/*\n\t\t * For STI, interrupts are shadowed; so KVM_REQ_EVENT will\n\t\t * do nothing, and it will be requested again as soon as\n\t\t * the shadow expires.  But we still need to check here,\n\t\t * because POPF has no interrupt shadow.\n\t\t */\n\t\tif (unlikely((ctxt->eflags & ~rflags) & X86_EFLAGS_IF))\n\t\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\t} else\n\t\tvcpu->arch.emulate_regs_need_sync_to_vcpu = true;\n\n\treturn r;\n}",
        "code_after_change": "int x86_emulate_instruction(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t    int emulation_type, void *insn, int insn_len)\n{\n\tint r;\n\tstruct x86_emulate_ctxt *ctxt = vcpu->arch.emulate_ctxt;\n\tbool writeback = true;\n\tbool write_fault_to_spt;\n\n\tif (unlikely(!kvm_can_emulate_insn(vcpu, emulation_type, insn, insn_len)))\n\t\treturn 1;\n\n\tvcpu->arch.l1tf_flush_l1d = true;\n\n\t/*\n\t * Clear write_fault_to_shadow_pgtable here to ensure it is\n\t * never reused.\n\t */\n\twrite_fault_to_spt = vcpu->arch.write_fault_to_shadow_pgtable;\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tif (!(emulation_type & EMULTYPE_NO_DECODE)) {\n\t\tkvm_clear_exception_queue(vcpu);\n\n\t\t/*\n\t\t * Return immediately if RIP hits a code breakpoint, such #DBs\n\t\t * are fault-like and are higher priority than any faults on\n\t\t * the code fetch itself.\n\t\t */\n\t\tif (!(emulation_type & EMULTYPE_SKIP) &&\n\t\t    kvm_vcpu_check_code_breakpoint(vcpu, &r))\n\t\t\treturn r;\n\n\t\tr = x86_decode_emulated_instruction(vcpu, emulation_type,\n\t\t\t\t\t\t    insn, insn_len);\n\t\tif (r != EMULATION_OK)  {\n\t\t\tif ((emulation_type & EMULTYPE_TRAP_UD) ||\n\t\t\t    (emulation_type & EMULTYPE_TRAP_UD_FORCED)) {\n\t\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tif (reexecute_instruction(vcpu, cr2_or_gpa,\n\t\t\t\t\t\t  write_fault_to_spt,\n\t\t\t\t\t\t  emulation_type))\n\t\t\t\treturn 1;\n\t\t\tif (ctxt->have_exception) {\n\t\t\t\t/*\n\t\t\t\t * #UD should result in just EMULATION_FAILED, and trap-like\n\t\t\t\t * exception should not be encountered during decode.\n\t\t\t\t */\n\t\t\t\tWARN_ON_ONCE(ctxt->exception.vector == UD_VECTOR ||\n\t\t\t\t\t     exception_type(ctxt->exception.vector) == EXCPT_TRAP);\n\t\t\t\tinject_emulated_exception(vcpu);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\treturn handle_emulation_failure(vcpu, emulation_type);\n\t\t}\n\t}\n\n\tif ((emulation_type & EMULTYPE_VMWARE_GP) &&\n\t    !is_vmware_backdoor_opcode(ctxt)) {\n\t\tkvm_queue_exception_e(vcpu, GP_VECTOR, 0);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * EMULTYPE_SKIP without EMULTYPE_COMPLETE_USER_EXIT is intended for\n\t * use *only* by vendor callbacks for kvm_skip_emulated_instruction().\n\t * The caller is responsible for updating interruptibility state and\n\t * injecting single-step #DBs.\n\t */\n\tif (emulation_type & EMULTYPE_SKIP) {\n\t\tif (ctxt->mode != X86EMUL_MODE_PROT64)\n\t\t\tctxt->eip = (u32)ctxt->_eip;\n\t\telse\n\t\t\tctxt->eip = ctxt->_eip;\n\n\t\tif (emulation_type & EMULTYPE_COMPLETE_USER_EXIT) {\n\t\t\tr = 1;\n\t\t\tgoto writeback;\n\t\t}\n\n\t\tkvm_rip_write(vcpu, ctxt->eip);\n\t\tif (ctxt->eflags & X86_EFLAGS_RF)\n\t\t\tkvm_set_rflags(vcpu, ctxt->eflags & ~X86_EFLAGS_RF);\n\t\treturn 1;\n\t}\n\n\tif (retry_instruction(ctxt, cr2_or_gpa, emulation_type))\n\t\treturn 1;\n\n\t/* this is needed for vmware backdoor interface to work since it\n\t   changes registers values  during IO operation */\n\tif (vcpu->arch.emulate_regs_need_sync_from_vcpu) {\n\t\tvcpu->arch.emulate_regs_need_sync_from_vcpu = false;\n\t\temulator_invalidate_register_cache(ctxt);\n\t}\n\nrestart:\n\tif (emulation_type & EMULTYPE_PF) {\n\t\t/* Save the faulting GPA (cr2) in the address field */\n\t\tctxt->exception.address = cr2_or_gpa;\n\n\t\t/* With shadow page tables, cr2 contains a GVA or nGPA. */\n\t\tif (vcpu->arch.mmu->root_role.direct) {\n\t\t\tctxt->gpa_available = true;\n\t\t\tctxt->gpa_val = cr2_or_gpa;\n\t\t}\n\t} else {\n\t\t/* Sanitize the address out of an abundance of paranoia. */\n\t\tctxt->exception.address = 0;\n\t}\n\n\tr = x86_emulate_insn(ctxt);\n\n\tif (r == EMULATION_INTERCEPTED)\n\t\treturn 1;\n\n\tif (r == EMULATION_FAILED) {\n\t\tif (reexecute_instruction(vcpu, cr2_or_gpa, write_fault_to_spt,\n\t\t\t\t\temulation_type))\n\t\t\treturn 1;\n\n\t\treturn handle_emulation_failure(vcpu, emulation_type);\n\t}\n\n\tif (ctxt->have_exception) {\n\t\tr = 1;\n\t\tif (inject_emulated_exception(vcpu))\n\t\t\treturn r;\n\t} else if (vcpu->arch.pio.count) {\n\t\tif (!vcpu->arch.pio.in) {\n\t\t\t/* FIXME: return into emulator if single-stepping.  */\n\t\t\tvcpu->arch.pio.count = 0;\n\t\t} else {\n\t\t\twriteback = false;\n\t\t\tvcpu->arch.complete_userspace_io = complete_emulated_pio;\n\t\t}\n\t\tr = 0;\n\t} else if (vcpu->mmio_needed) {\n\t\t++vcpu->stat.mmio_exits;\n\n\t\tif (!vcpu->mmio_is_write)\n\t\t\twriteback = false;\n\t\tr = 0;\n\t\tvcpu->arch.complete_userspace_io = complete_emulated_mmio;\n\t} else if (vcpu->arch.complete_userspace_io) {\n\t\twriteback = false;\n\t\tr = 0;\n\t} else if (r == EMULATION_RESTART)\n\t\tgoto restart;\n\telse\n\t\tr = 1;\n\nwriteback:\n\tif (writeback) {\n\t\tunsigned long rflags = static_call(kvm_x86_get_rflags)(vcpu);\n\t\ttoggle_interruptibility(vcpu, ctxt->interruptibility);\n\t\tvcpu->arch.emulate_regs_need_sync_to_vcpu = false;\n\t\tif (!ctxt->have_exception ||\n\t\t    exception_type(ctxt->exception.vector) == EXCPT_TRAP) {\n\t\t\tkvm_pmu_trigger_event(vcpu, PERF_COUNT_HW_INSTRUCTIONS);\n\t\t\tif (ctxt->is_branch)\n\t\t\t\tkvm_pmu_trigger_event(vcpu, PERF_COUNT_HW_BRANCH_INSTRUCTIONS);\n\t\t\tkvm_rip_write(vcpu, ctxt->eip);\n\t\t\tif (r && (ctxt->tf || (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)))\n\t\t\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\t\t\tstatic_call_cond(kvm_x86_update_emulated_instruction)(vcpu);\n\t\t\t__kvm_set_rflags(vcpu, ctxt->eflags);\n\t\t}\n\n\t\t/*\n\t\t * For STI, interrupts are shadowed; so KVM_REQ_EVENT will\n\t\t * do nothing, and it will be requested again as soon as\n\t\t * the shadow expires.  But we still need to check here,\n\t\t * because POPF has no interrupt shadow.\n\t\t */\n\t\tif (unlikely((ctxt->eflags & ~rflags) & X86_EFLAGS_IF))\n\t\t\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n\t} else\n\t\tvcpu->arch.emulate_regs_need_sync_to_vcpu = true;\n\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,6 +20,15 @@\n \n \tif (!(emulation_type & EMULTYPE_NO_DECODE)) {\n \t\tkvm_clear_exception_queue(vcpu);\n+\n+\t\t/*\n+\t\t * Return immediately if RIP hits a code breakpoint, such #DBs\n+\t\t * are fault-like and are higher priority than any faults on\n+\t\t * the code fetch itself.\n+\t\t */\n+\t\tif (!(emulation_type & EMULTYPE_SKIP) &&\n+\t\t    kvm_vcpu_check_code_breakpoint(vcpu, &r))\n+\t\t\treturn r;\n \n \t\tr = x86_decode_emulated_instruction(vcpu, emulation_type,\n \t\t\t\t\t\t    insn, insn_len);",
        "function_modified_lines": {
            "added": [
                "",
                "\t\t/*",
                "\t\t * Return immediately if RIP hits a code breakpoint, such #DBs",
                "\t\t * are fault-like and are higher priority than any faults on",
                "\t\t * the code fetch itself.",
                "\t\t */",
                "\t\tif (!(emulation_type & EMULTYPE_SKIP) &&",
                "\t\t    kvm_vcpu_check_code_breakpoint(vcpu, &r))",
                "\t\t\treturn r;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s KVM module, which can lead to a denial of service in the x86_emulate_insn in arch/x86/kvm/emulate.c. This flaw occurs while executing an illegal instruction in guest in the Intel CPU.",
        "id": 3294
    },
    {
        "cve_id": "CVE-2020-15437",
        "code_before_change": "static void __init serial8250_isa_init_ports(void)\n{\n\tstruct uart_8250_port *up;\n\tstatic int first = 1;\n\tint i, irqflag = 0;\n\n\tif (!first)\n\t\treturn;\n\tfirst = 0;\n\n\tif (nr_uarts > UART_NR)\n\t\tnr_uarts = UART_NR;\n\n\tfor (i = 0; i < nr_uarts; i++) {\n\t\tstruct uart_8250_port *up = &serial8250_ports[i];\n\t\tstruct uart_port *port = &up->port;\n\n\t\tport->line = i;\n\t\tserial8250_init_port(up);\n\t\tif (!base_ops)\n\t\t\tbase_ops = port->ops;\n\t\tport->ops = &univ8250_port_ops;\n\n\t\ttimer_setup(&up->timer, serial8250_timeout, 0);\n\n\t\tup->ops = &univ8250_driver_ops;\n\n\t\t/*\n\t\t * ALPHA_KLUDGE_MCR needs to be killed.\n\t\t */\n\t\tup->mcr_mask = ~ALPHA_KLUDGE_MCR;\n\t\tup->mcr_force = ALPHA_KLUDGE_MCR;\n\t}\n\n\t/* chain base port ops to support Remote Supervisor Adapter */\n\tuniv8250_port_ops = *base_ops;\n\tuniv8250_rsa_support(&univ8250_port_ops);\n\n\tif (share_irqs)\n\t\tirqflag = IRQF_SHARED;\n\n\tfor (i = 0, up = serial8250_ports;\n\t     i < ARRAY_SIZE(old_serial_port) && i < nr_uarts;\n\t     i++, up++) {\n\t\tstruct uart_port *port = &up->port;\n\n\t\tport->iobase   = old_serial_port[i].port;\n\t\tport->irq      = irq_canonicalize(old_serial_port[i].irq);\n\t\tport->irqflags = 0;\n\t\tport->uartclk  = old_serial_port[i].baud_base * 16;\n\t\tport->flags    = old_serial_port[i].flags;\n\t\tport->hub6     = 0;\n\t\tport->membase  = old_serial_port[i].iomem_base;\n\t\tport->iotype   = old_serial_port[i].io_type;\n\t\tport->regshift = old_serial_port[i].iomem_reg_shift;\n\t\tserial8250_set_defaults(up);\n\n\t\tport->irqflags |= irqflag;\n\t\tif (serial8250_isa_config != NULL)\n\t\t\tserial8250_isa_config(i, &up->port, &up->capabilities);\n\t}\n}",
        "code_after_change": "static void __init serial8250_isa_init_ports(void)\n{\n\tstruct uart_8250_port *up;\n\tstatic int first = 1;\n\tint i, irqflag = 0;\n\n\tif (!first)\n\t\treturn;\n\tfirst = 0;\n\n\tif (nr_uarts > UART_NR)\n\t\tnr_uarts = UART_NR;\n\n\tfor (i = 0; i < nr_uarts; i++) {\n\t\tstruct uart_8250_port *up = &serial8250_ports[i];\n\t\tstruct uart_port *port = &up->port;\n\n\t\tport->line = i;\n\t\tserial8250_init_port(up);\n\t\tif (!base_ops)\n\t\t\tbase_ops = port->ops;\n\t\tport->ops = &univ8250_port_ops;\n\n\t\ttimer_setup(&up->timer, serial8250_timeout, 0);\n\n\t\tup->ops = &univ8250_driver_ops;\n\n\t\t/*\n\t\t * ALPHA_KLUDGE_MCR needs to be killed.\n\t\t */\n\t\tup->mcr_mask = ~ALPHA_KLUDGE_MCR;\n\t\tup->mcr_force = ALPHA_KLUDGE_MCR;\n\t\tserial8250_set_defaults(up);\n\t}\n\n\t/* chain base port ops to support Remote Supervisor Adapter */\n\tuniv8250_port_ops = *base_ops;\n\tuniv8250_rsa_support(&univ8250_port_ops);\n\n\tif (share_irqs)\n\t\tirqflag = IRQF_SHARED;\n\n\tfor (i = 0, up = serial8250_ports;\n\t     i < ARRAY_SIZE(old_serial_port) && i < nr_uarts;\n\t     i++, up++) {\n\t\tstruct uart_port *port = &up->port;\n\n\t\tport->iobase   = old_serial_port[i].port;\n\t\tport->irq      = irq_canonicalize(old_serial_port[i].irq);\n\t\tport->irqflags = 0;\n\t\tport->uartclk  = old_serial_port[i].baud_base * 16;\n\t\tport->flags    = old_serial_port[i].flags;\n\t\tport->hub6     = 0;\n\t\tport->membase  = old_serial_port[i].iomem_base;\n\t\tport->iotype   = old_serial_port[i].io_type;\n\t\tport->regshift = old_serial_port[i].iomem_reg_shift;\n\n\t\tport->irqflags |= irqflag;\n\t\tif (serial8250_isa_config != NULL)\n\t\t\tserial8250_isa_config(i, &up->port, &up->capabilities);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,6 +30,7 @@\n \t\t */\n \t\tup->mcr_mask = ~ALPHA_KLUDGE_MCR;\n \t\tup->mcr_force = ALPHA_KLUDGE_MCR;\n+\t\tserial8250_set_defaults(up);\n \t}\n \n \t/* chain base port ops to support Remote Supervisor Adapter */\n@@ -53,7 +54,6 @@\n \t\tport->membase  = old_serial_port[i].iomem_base;\n \t\tport->iotype   = old_serial_port[i].io_type;\n \t\tport->regshift = old_serial_port[i].iomem_reg_shift;\n-\t\tserial8250_set_defaults(up);\n \n \t\tport->irqflags |= irqflag;\n \t\tif (serial8250_isa_config != NULL)",
        "function_modified_lines": {
            "added": [
                "\t\tserial8250_set_defaults(up);"
            ],
            "deleted": [
                "\t\tserial8250_set_defaults(up);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux kernel before version 5.8 is vulnerable to a NULL pointer dereference in drivers/tty/serial/8250/8250_core.c:serial8250_isa_init_ports() that allows local users to cause a denial of service by using the p->serial_in pointer which uninitialized.",
        "id": 2545
    },
    {
        "cve_id": "CVE-2020-12364",
        "code_before_change": "static void guc_init_params(struct intel_guc *guc)\n{\n\tu32 *params = guc->params;\n\tint i;\n\n\tBUILD_BUG_ON(sizeof(guc->params) != GUC_CTL_MAX_DWORDS * sizeof(u32));\n\n\tparams[GUC_CTL_CTXINFO] = guc_ctl_ctxinfo_flags(guc);\n\tparams[GUC_CTL_LOG_PARAMS] = guc_ctl_log_params_flags(guc);\n\tparams[GUC_CTL_FEATURE] = guc_ctl_feature_flags(guc);\n\tparams[GUC_CTL_DEBUG] = guc_ctl_debug_flags(guc);\n\tparams[GUC_CTL_ADS] = guc_ctl_ads_flags(guc);\n\n\tfor (i = 0; i < GUC_CTL_MAX_DWORDS; i++)\n\t\tDRM_DEBUG_DRIVER(\"param[%2d] = %#x\\n\", i, params[i]);\n}",
        "code_after_change": "static void guc_init_params(struct intel_guc *guc)\n{\n\tu32 *params = guc->params;\n\tint i;\n\n\tBUILD_BUG_ON(sizeof(guc->params) != GUC_CTL_MAX_DWORDS * sizeof(u32));\n\n\tparams[GUC_CTL_LOG_PARAMS] = guc_ctl_log_params_flags(guc);\n\tparams[GUC_CTL_FEATURE] = guc_ctl_feature_flags(guc);\n\tparams[GUC_CTL_DEBUG] = guc_ctl_debug_flags(guc);\n\tparams[GUC_CTL_ADS] = guc_ctl_ads_flags(guc);\n\n\tfor (i = 0; i < GUC_CTL_MAX_DWORDS; i++)\n\t\tDRM_DEBUG_DRIVER(\"param[%2d] = %#x\\n\", i, params[i]);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,6 @@\n \n \tBUILD_BUG_ON(sizeof(guc->params) != GUC_CTL_MAX_DWORDS * sizeof(u32));\n \n-\tparams[GUC_CTL_CTXINFO] = guc_ctl_ctxinfo_flags(guc);\n \tparams[GUC_CTL_LOG_PARAMS] = guc_ctl_log_params_flags(guc);\n \tparams[GUC_CTL_FEATURE] = guc_ctl_feature_flags(guc);\n \tparams[GUC_CTL_DEBUG] = guc_ctl_debug_flags(guc);",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tparams[GUC_CTL_CTXINFO] = guc_ctl_ctxinfo_flags(guc);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Null pointer reference in some Intel(R) Graphics Drivers for Windows* before version 26.20.100.7212 and before version Linux kernel version 5.5 may allow a privileged user to potentially enable a denial of service via local access.",
        "id": 2465
    },
    {
        "cve_id": "CVE-2018-1130",
        "code_before_change": "int dccp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tconst struct dccp_sock *dp = dccp_sk(sk);\n\tconst int flags = msg->msg_flags;\n\tconst int noblock = flags & MSG_DONTWAIT;\n\tstruct sk_buff *skb;\n\tint rc, size;\n\tlong timeo;\n\n\ttrace_dccp_probe(sk, len);\n\n\tif (len > dp->dccps_mss_cache)\n\t\treturn -EMSGSIZE;\n\n\tlock_sock(sk);\n\n\tif (dccp_qpolicy_full(sk)) {\n\t\trc = -EAGAIN;\n\t\tgoto out_release;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, noblock);\n\n\t/*\n\t * We have to use sk_stream_wait_connect here to set sk_write_pending,\n\t * so that the trick in dccp_rcv_request_sent_state_process.\n\t */\n\t/* Wait for a connection to finish. */\n\tif ((1 << sk->sk_state) & ~(DCCPF_OPEN | DCCPF_PARTOPEN))\n\t\tif ((rc = sk_stream_wait_connect(sk, &timeo)) != 0)\n\t\t\tgoto out_release;\n\n\tsize = sk->sk_prot->max_header + len;\n\trelease_sock(sk);\n\tskb = sock_alloc_send_skb(sk, size, noblock, &rc);\n\tlock_sock(sk);\n\tif (skb == NULL)\n\t\tgoto out_release;\n\n\tskb_reserve(skb, sk->sk_prot->max_header);\n\trc = memcpy_from_msg(skb_put(skb, len), msg, len);\n\tif (rc != 0)\n\t\tgoto out_discard;\n\n\trc = dccp_msghdr_parse(msg, skb);\n\tif (rc != 0)\n\t\tgoto out_discard;\n\n\tdccp_qpolicy_push(sk, skb);\n\t/*\n\t * The xmit_timer is set if the TX CCID is rate-based and will expire\n\t * when congestion control permits to release further packets into the\n\t * network. Window-based CCIDs do not use this timer.\n\t */\n\tif (!timer_pending(&dp->dccps_xmit_timer))\n\t\tdccp_write_xmit(sk);\nout_release:\n\trelease_sock(sk);\n\treturn rc ? : len;\nout_discard:\n\tkfree_skb(skb);\n\tgoto out_release;\n}",
        "code_after_change": "int dccp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tconst struct dccp_sock *dp = dccp_sk(sk);\n\tconst int flags = msg->msg_flags;\n\tconst int noblock = flags & MSG_DONTWAIT;\n\tstruct sk_buff *skb;\n\tint rc, size;\n\tlong timeo;\n\n\ttrace_dccp_probe(sk, len);\n\n\tif (len > dp->dccps_mss_cache)\n\t\treturn -EMSGSIZE;\n\n\tlock_sock(sk);\n\n\tif (dccp_qpolicy_full(sk)) {\n\t\trc = -EAGAIN;\n\t\tgoto out_release;\n\t}\n\n\ttimeo = sock_sndtimeo(sk, noblock);\n\n\t/*\n\t * We have to use sk_stream_wait_connect here to set sk_write_pending,\n\t * so that the trick in dccp_rcv_request_sent_state_process.\n\t */\n\t/* Wait for a connection to finish. */\n\tif ((1 << sk->sk_state) & ~(DCCPF_OPEN | DCCPF_PARTOPEN))\n\t\tif ((rc = sk_stream_wait_connect(sk, &timeo)) != 0)\n\t\t\tgoto out_release;\n\n\tsize = sk->sk_prot->max_header + len;\n\trelease_sock(sk);\n\tskb = sock_alloc_send_skb(sk, size, noblock, &rc);\n\tlock_sock(sk);\n\tif (skb == NULL)\n\t\tgoto out_release;\n\n\tif (sk->sk_state == DCCP_CLOSED) {\n\t\trc = -ENOTCONN;\n\t\tgoto out_discard;\n\t}\n\n\tskb_reserve(skb, sk->sk_prot->max_header);\n\trc = memcpy_from_msg(skb_put(skb, len), msg, len);\n\tif (rc != 0)\n\t\tgoto out_discard;\n\n\trc = dccp_msghdr_parse(msg, skb);\n\tif (rc != 0)\n\t\tgoto out_discard;\n\n\tdccp_qpolicy_push(sk, skb);\n\t/*\n\t * The xmit_timer is set if the TX CCID is rate-based and will expire\n\t * when congestion control permits to release further packets into the\n\t * network. Window-based CCIDs do not use this timer.\n\t */\n\tif (!timer_pending(&dp->dccps_xmit_timer))\n\t\tdccp_write_xmit(sk);\nout_release:\n\trelease_sock(sk);\n\treturn rc ? : len;\nout_discard:\n\tkfree_skb(skb);\n\tgoto out_release;\n}",
        "patch": "--- code before\n+++ code after\n@@ -37,6 +37,11 @@\n \tif (skb == NULL)\n \t\tgoto out_release;\n \n+\tif (sk->sk_state == DCCP_CLOSED) {\n+\t\trc = -ENOTCONN;\n+\t\tgoto out_discard;\n+\t}\n+\n \tskb_reserve(skb, sk->sk_prot->max_header);\n \trc = memcpy_from_msg(skb_put(skb, len), msg, len);\n \tif (rc != 0)",
        "function_modified_lines": {
            "added": [
                "\tif (sk->sk_state == DCCP_CLOSED) {",
                "\t\trc = -ENOTCONN;",
                "\t\tgoto out_discard;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Linux kernel before version 4.16-rc7 is vulnerable to a null pointer dereference in dccp_write_xmit() function in net/dccp/output.c in that allows a local user to cause a denial of service by a number of certain crafted system calls.",
        "id": 1642
    },
    {
        "cve_id": "CVE-2021-3739",
        "code_before_change": "int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n\t\t    u64 devid)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *cur_devices;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tu64 num_devices;\n\tint ret = 0;\n\n\tmutex_lock(&uuid_mutex);\n\n\tnum_devices = btrfs_num_devices(fs_info);\n\n\tret = btrfs_check_raid_min_devices(fs_info, num_devices - 1);\n\tif (ret)\n\t\tgoto out;\n\n\tdevice = btrfs_find_device_by_devspec(fs_info, devid, device_path);\n\n\tif (IS_ERR(device)) {\n\t\tif (PTR_ERR(device) == -ENOENT &&\n\t\t    strcmp(device_path, \"missing\") == 0)\n\t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n\t\telse\n\t\t\tret = PTR_ERR(device);\n\t\tgoto out;\n\t}\n\n\tif (btrfs_pinned_by_swapfile(fs_info, device)) {\n\t\tbtrfs_warn_in_rcu(fs_info,\n\t\t  \"cannot remove device %s (devid %llu) due to active swapfile\",\n\t\t\t\t  rcu_str_deref(device->name), device->devid);\n\t\tret = -ETXTBSY;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &device->dev_state)) {\n\t\tret = BTRFS_ERROR_DEV_TGT_REPLACE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state) &&\n\t    fs_info->fs_devices->rw_devices == 1) {\n\t\tret = BTRFS_ERROR_DEV_ONLY_WRITABLE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_del_init(&device->dev_alloc_list);\n\t\tdevice->fs_devices->rw_devices--;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\n\tmutex_unlock(&uuid_mutex);\n\tret = btrfs_shrink_device(device, 0);\n\tif (!ret)\n\t\tbtrfs_reada_remove_dev(device);\n\tmutex_lock(&uuid_mutex);\n\tif (ret)\n\t\tgoto error_undo;\n\n\t/*\n\t * TODO: the superblock still includes this device in its num_devices\n\t * counter although write_all_supers() is not locked out. This\n\t * could give a filesystem state which requires a degraded mount.\n\t */\n\tret = btrfs_rm_dev_item(device);\n\tif (ret)\n\t\tgoto error_undo;\n\n\tclear_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &device->dev_state);\n\tbtrfs_scrub_cancel_dev(device);\n\n\t/*\n\t * the device list mutex makes sure that we don't change\n\t * the device list while someone else is writing out all\n\t * the device supers. Whoever is writing all supers, should\n\t * lock the device list mutex before getting the number of\n\t * devices in the super block (super_copy). Conversely,\n\t * whoever updates the number of devices in the super block\n\t * (super_copy) should hold the device list mutex.\n\t */\n\n\t/*\n\t * In normal cases the cur_devices == fs_devices. But in case\n\t * of deleting a seed device, the cur_devices should point to\n\t * its own fs_devices listed under the fs_devices->seed.\n\t */\n\tcur_devices = device->fs_devices;\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tlist_del_rcu(&device->dev_list);\n\n\tcur_devices->num_devices--;\n\tcur_devices->total_devices--;\n\t/* Update total_devices of the parent fs_devices if it's seed */\n\tif (cur_devices != fs_devices)\n\t\tfs_devices->total_devices--;\n\n\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state))\n\t\tcur_devices->missing_devices--;\n\n\tbtrfs_assign_next_active_device(device, NULL);\n\n\tif (device->bdev) {\n\t\tcur_devices->open_devices--;\n\t\t/* remove sysfs entry */\n\t\tbtrfs_sysfs_remove_device(device);\n\t}\n\n\tnum_devices = btrfs_super_num_devices(fs_info->super_copy) - 1;\n\tbtrfs_set_super_num_devices(fs_info->super_copy, num_devices);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\t/*\n\t * at this point, the device is zero sized and detached from\n\t * the devices list.  All that's left is to zero out the old\n\t * supers and free the device.\n\t */\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state))\n\t\tbtrfs_scratch_superblocks(fs_info, device->bdev,\n\t\t\t\t\t  device->name->str);\n\n\tbtrfs_close_bdev(device);\n\tsynchronize_rcu();\n\tbtrfs_free_device(device);\n\n\tif (cur_devices->open_devices == 0) {\n\t\tlist_del_init(&cur_devices->seed_list);\n\t\tclose_fs_devices(cur_devices);\n\t\tfree_fs_devices(cur_devices);\n\t}\n\nout:\n\tmutex_unlock(&uuid_mutex);\n\treturn ret;\n\nerror_undo:\n\tbtrfs_reada_undo_remove_dev(device);\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_add(&device->dev_alloc_list,\n\t\t\t &fs_devices->alloc_list);\n\t\tdevice->fs_devices->rw_devices++;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\tgoto out;\n}",
        "code_after_change": "int btrfs_rm_device(struct btrfs_fs_info *fs_info, const char *device_path,\n\t\t    u64 devid)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *cur_devices;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tu64 num_devices;\n\tint ret = 0;\n\n\tmutex_lock(&uuid_mutex);\n\n\tnum_devices = btrfs_num_devices(fs_info);\n\n\tret = btrfs_check_raid_min_devices(fs_info, num_devices - 1);\n\tif (ret)\n\t\tgoto out;\n\n\tdevice = btrfs_find_device_by_devspec(fs_info, devid, device_path);\n\n\tif (IS_ERR(device)) {\n\t\tif (PTR_ERR(device) == -ENOENT &&\n\t\t    device_path && strcmp(device_path, \"missing\") == 0)\n\t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n\t\telse\n\t\t\tret = PTR_ERR(device);\n\t\tgoto out;\n\t}\n\n\tif (btrfs_pinned_by_swapfile(fs_info, device)) {\n\t\tbtrfs_warn_in_rcu(fs_info,\n\t\t  \"cannot remove device %s (devid %llu) due to active swapfile\",\n\t\t\t\t  rcu_str_deref(device->name), device->devid);\n\t\tret = -ETXTBSY;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_REPLACE_TGT, &device->dev_state)) {\n\t\tret = BTRFS_ERROR_DEV_TGT_REPLACE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state) &&\n\t    fs_info->fs_devices->rw_devices == 1) {\n\t\tret = BTRFS_ERROR_DEV_ONLY_WRITABLE;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_del_init(&device->dev_alloc_list);\n\t\tdevice->fs_devices->rw_devices--;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\n\tmutex_unlock(&uuid_mutex);\n\tret = btrfs_shrink_device(device, 0);\n\tif (!ret)\n\t\tbtrfs_reada_remove_dev(device);\n\tmutex_lock(&uuid_mutex);\n\tif (ret)\n\t\tgoto error_undo;\n\n\t/*\n\t * TODO: the superblock still includes this device in its num_devices\n\t * counter although write_all_supers() is not locked out. This\n\t * could give a filesystem state which requires a degraded mount.\n\t */\n\tret = btrfs_rm_dev_item(device);\n\tif (ret)\n\t\tgoto error_undo;\n\n\tclear_bit(BTRFS_DEV_STATE_IN_FS_METADATA, &device->dev_state);\n\tbtrfs_scrub_cancel_dev(device);\n\n\t/*\n\t * the device list mutex makes sure that we don't change\n\t * the device list while someone else is writing out all\n\t * the device supers. Whoever is writing all supers, should\n\t * lock the device list mutex before getting the number of\n\t * devices in the super block (super_copy). Conversely,\n\t * whoever updates the number of devices in the super block\n\t * (super_copy) should hold the device list mutex.\n\t */\n\n\t/*\n\t * In normal cases the cur_devices == fs_devices. But in case\n\t * of deleting a seed device, the cur_devices should point to\n\t * its own fs_devices listed under the fs_devices->seed.\n\t */\n\tcur_devices = device->fs_devices;\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tlist_del_rcu(&device->dev_list);\n\n\tcur_devices->num_devices--;\n\tcur_devices->total_devices--;\n\t/* Update total_devices of the parent fs_devices if it's seed */\n\tif (cur_devices != fs_devices)\n\t\tfs_devices->total_devices--;\n\n\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state))\n\t\tcur_devices->missing_devices--;\n\n\tbtrfs_assign_next_active_device(device, NULL);\n\n\tif (device->bdev) {\n\t\tcur_devices->open_devices--;\n\t\t/* remove sysfs entry */\n\t\tbtrfs_sysfs_remove_device(device);\n\t}\n\n\tnum_devices = btrfs_super_num_devices(fs_info->super_copy) - 1;\n\tbtrfs_set_super_num_devices(fs_info->super_copy, num_devices);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\t/*\n\t * at this point, the device is zero sized and detached from\n\t * the devices list.  All that's left is to zero out the old\n\t * supers and free the device.\n\t */\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state))\n\t\tbtrfs_scratch_superblocks(fs_info, device->bdev,\n\t\t\t\t\t  device->name->str);\n\n\tbtrfs_close_bdev(device);\n\tsynchronize_rcu();\n\tbtrfs_free_device(device);\n\n\tif (cur_devices->open_devices == 0) {\n\t\tlist_del_init(&cur_devices->seed_list);\n\t\tclose_fs_devices(cur_devices);\n\t\tfree_fs_devices(cur_devices);\n\t}\n\nout:\n\tmutex_unlock(&uuid_mutex);\n\treturn ret;\n\nerror_undo:\n\tbtrfs_reada_undo_remove_dev(device);\n\tif (test_bit(BTRFS_DEV_STATE_WRITEABLE, &device->dev_state)) {\n\t\tmutex_lock(&fs_info->chunk_mutex);\n\t\tlist_add(&device->dev_alloc_list,\n\t\t\t &fs_devices->alloc_list);\n\t\tdevice->fs_devices->rw_devices++;\n\t\tmutex_unlock(&fs_info->chunk_mutex);\n\t}\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \n \tif (IS_ERR(device)) {\n \t\tif (PTR_ERR(device) == -ENOENT &&\n-\t\t    strcmp(device_path, \"missing\") == 0)\n+\t\t    device_path && strcmp(device_path, \"missing\") == 0)\n \t\t\tret = BTRFS_ERROR_DEV_MISSING_NOT_FOUND;\n \t\telse\n \t\t\tret = PTR_ERR(device);",
        "function_modified_lines": {
            "added": [
                "\t\t    device_path && strcmp(device_path, \"missing\") == 0)"
            ],
            "deleted": [
                "\t\t    strcmp(device_path, \"missing\") == 0)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the btrfs_rm_device function in fs/btrfs/volumes.c in the Linux Kernel, where triggering the bug requires ‘CAP_SYS_ADMIN’. This flaw allows a local attacker to crash the system or leak kernel internal information. The highest threat from this vulnerability is to system availability.",
        "id": 3050
    },
    {
        "cve_id": "CVE-2022-1205",
        "code_before_change": "void ax25_disconnect(ax25_cb *ax25, int reason)\n{\n\tax25_clear_queues(ax25);\n\n\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))\n\t\tax25_stop_heartbeat(ax25);\n\tax25_stop_t1timer(ax25);\n\tax25_stop_t2timer(ax25);\n\tax25_stop_t3timer(ax25);\n\tax25_stop_idletimer(ax25);\n\n\tax25->state = AX25_STATE_0;\n\n\tax25_link_failed(ax25, reason);\n\n\tif (ax25->sk != NULL) {\n\t\tlocal_bh_disable();\n\t\tbh_lock_sock(ax25->sk);\n\t\tax25->sk->sk_state     = TCP_CLOSE;\n\t\tax25->sk->sk_err       = reason;\n\t\tax25->sk->sk_shutdown |= SEND_SHUTDOWN;\n\t\tif (!sock_flag(ax25->sk, SOCK_DEAD)) {\n\t\t\tax25->sk->sk_state_change(ax25->sk);\n\t\t\tsock_set_flag(ax25->sk, SOCK_DEAD);\n\t\t}\n\t\tbh_unlock_sock(ax25->sk);\n\t\tlocal_bh_enable();\n\t}\n}",
        "code_after_change": "void ax25_disconnect(ax25_cb *ax25, int reason)\n{\n\tax25_clear_queues(ax25);\n\n\tif (reason == ENETUNREACH) {\n\t\tdel_timer_sync(&ax25->timer);\n\t\tdel_timer_sync(&ax25->t1timer);\n\t\tdel_timer_sync(&ax25->t2timer);\n\t\tdel_timer_sync(&ax25->t3timer);\n\t\tdel_timer_sync(&ax25->idletimer);\n\t} else {\n\t\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))\n\t\t\tax25_stop_heartbeat(ax25);\n\t\tax25_stop_t1timer(ax25);\n\t\tax25_stop_t2timer(ax25);\n\t\tax25_stop_t3timer(ax25);\n\t\tax25_stop_idletimer(ax25);\n\t}\n\n\tax25->state = AX25_STATE_0;\n\n\tax25_link_failed(ax25, reason);\n\n\tif (ax25->sk != NULL) {\n\t\tlocal_bh_disable();\n\t\tbh_lock_sock(ax25->sk);\n\t\tax25->sk->sk_state     = TCP_CLOSE;\n\t\tax25->sk->sk_err       = reason;\n\t\tax25->sk->sk_shutdown |= SEND_SHUTDOWN;\n\t\tif (!sock_flag(ax25->sk, SOCK_DEAD)) {\n\t\t\tax25->sk->sk_state_change(ax25->sk);\n\t\t\tsock_set_flag(ax25->sk, SOCK_DEAD);\n\t\t}\n\t\tbh_unlock_sock(ax25->sk);\n\t\tlocal_bh_enable();\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,12 +2,20 @@\n {\n \tax25_clear_queues(ax25);\n \n-\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))\n-\t\tax25_stop_heartbeat(ax25);\n-\tax25_stop_t1timer(ax25);\n-\tax25_stop_t2timer(ax25);\n-\tax25_stop_t3timer(ax25);\n-\tax25_stop_idletimer(ax25);\n+\tif (reason == ENETUNREACH) {\n+\t\tdel_timer_sync(&ax25->timer);\n+\t\tdel_timer_sync(&ax25->t1timer);\n+\t\tdel_timer_sync(&ax25->t2timer);\n+\t\tdel_timer_sync(&ax25->t3timer);\n+\t\tdel_timer_sync(&ax25->idletimer);\n+\t} else {\n+\t\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))\n+\t\t\tax25_stop_heartbeat(ax25);\n+\t\tax25_stop_t1timer(ax25);\n+\t\tax25_stop_t2timer(ax25);\n+\t\tax25_stop_t3timer(ax25);\n+\t\tax25_stop_idletimer(ax25);\n+\t}\n \n \tax25->state = AX25_STATE_0;\n ",
        "function_modified_lines": {
            "added": [
                "\tif (reason == ENETUNREACH) {",
                "\t\tdel_timer_sync(&ax25->timer);",
                "\t\tdel_timer_sync(&ax25->t1timer);",
                "\t\tdel_timer_sync(&ax25->t2timer);",
                "\t\tdel_timer_sync(&ax25->t3timer);",
                "\t\tdel_timer_sync(&ax25->idletimer);",
                "\t} else {",
                "\t\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))",
                "\t\t\tax25_stop_heartbeat(ax25);",
                "\t\tax25_stop_t1timer(ax25);",
                "\t\tax25_stop_t2timer(ax25);",
                "\t\tax25_stop_t3timer(ax25);",
                "\t\tax25_stop_idletimer(ax25);",
                "\t}"
            ],
            "deleted": [
                "\tif (!ax25->sk || !sock_flag(ax25->sk, SOCK_DESTROY))",
                "\t\tax25_stop_heartbeat(ax25);",
                "\tax25_stop_t1timer(ax25);",
                "\tax25_stop_t2timer(ax25);",
                "\tax25_stop_t3timer(ax25);",
                "\tax25_stop_idletimer(ax25);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s Amateur Radio AX.25 protocol functionality in the way a user connects with the protocol. This flaw allows a local user to crash the system.",
        "id": 3256
    },
    {
        "cve_id": "CVE-2017-2647",
        "code_before_change": "key_ref_t keyring_search(key_ref_t keyring,\n\t\t\t struct key_type *type,\n\t\t\t const char *description)\n{\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= type,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= type->match,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_DO_STATE_CHECK,\n\t};\n\tkey_ref_t key;\n\tint ret;\n\n\tif (!ctx.match_data.cmp)\n\t\treturn ERR_PTR(-ENOKEY);\n\n\tif (type->match_preparse) {\n\t\tret = type->match_preparse(&ctx.match_data);\n\t\tif (ret < 0)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\n\tkey = keyring_search_aux(keyring, &ctx);\n\n\tif (type->match_free)\n\t\ttype->match_free(&ctx.match_data);\n\treturn key;\n}",
        "code_after_change": "key_ref_t keyring_search(key_ref_t keyring,\n\t\t\t struct key_type *type,\n\t\t\t const char *description)\n{\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= type,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= key_default_cmp,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t\t.flags\t\t\t= KEYRING_SEARCH_DO_STATE_CHECK,\n\t};\n\tkey_ref_t key;\n\tint ret;\n\n\tif (type->match_preparse) {\n\t\tret = type->match_preparse(&ctx.match_data);\n\t\tif (ret < 0)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\n\tkey = keyring_search_aux(keyring, &ctx);\n\n\tif (type->match_free)\n\t\ttype->match_free(&ctx.match_data);\n\treturn key;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,16 +6,13 @@\n \t\t.index_key.type\t\t= type,\n \t\t.index_key.description\t= description,\n \t\t.cred\t\t\t= current_cred(),\n-\t\t.match_data.cmp\t\t= type->match,\n+\t\t.match_data.cmp\t\t= key_default_cmp,\n \t\t.match_data.raw_data\t= description,\n \t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n \t\t.flags\t\t\t= KEYRING_SEARCH_DO_STATE_CHECK,\n \t};\n \tkey_ref_t key;\n \tint ret;\n-\n-\tif (!ctx.match_data.cmp)\n-\t\treturn ERR_PTR(-ENOKEY);\n \n \tif (type->match_preparse) {\n \t\tret = type->match_preparse(&ctx.match_data);",
        "function_modified_lines": {
            "added": [
                "\t\t.match_data.cmp\t\t= key_default_cmp,"
            ],
            "deleted": [
                "\t\t.match_data.cmp\t\t= type->match,",
                "",
                "\tif (!ctx.match_data.cmp)",
                "\t\treturn ERR_PTR(-ENOKEY);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel before 3.18 allows local users to gain privileges or cause a denial of service (NULL pointer dereference and system crash) via vectors involving a NULL value for a certain match field, related to the keyring_search_iterator function in keyring.c.",
        "id": 1452
    },
    {
        "cve_id": "CVE-2019-15218",
        "code_before_change": "static int smsusb_init_device(struct usb_interface *intf, int board_id)\n{\n\tstruct smsdevice_params_t params;\n\tstruct smsusb_device_t *dev;\n\tvoid *mdev;\n\tint i, rc;\n\n\t/* create device object */\n\tdev = kzalloc(sizeof(struct smsusb_device_t), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tmemset(&params, 0, sizeof(params));\n\tusb_set_intfdata(intf, dev);\n\tdev->udev = interface_to_usbdev(intf);\n\tdev->state = SMSUSB_DISCONNECTED;\n\n\tparams.device_type = sms_get_board(board_id)->type;\n\n\tswitch (params.device_type) {\n\tcase SMS_STELLAR:\n\t\tdev->buffer_size = USB1_BUFFER_SIZE;\n\n\t\tparams.setmode_handler = smsusb1_setmode;\n\t\tparams.detectmode_handler = smsusb1_detectmode;\n\t\tbreak;\n\tcase SMS_UNKNOWN_TYPE:\n\t\tpr_err(\"Unspecified sms device type!\\n\");\n\t\t/* fall-thru */\n\tdefault:\n\t\tdev->buffer_size = USB2_BUFFER_SIZE;\n\t\tdev->response_alignment =\n\t\t    le16_to_cpu(dev->udev->ep_in[1]->desc.wMaxPacketSize) -\n\t\t    sizeof(struct sms_msg_hdr);\n\n\t\tparams.flags |= SMS_DEVICE_FAMILY2;\n\t\tbreak;\n\t}\n\n\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {\n\t\tif (intf->cur_altsetting->endpoint[i].desc. bEndpointAddress & USB_DIR_IN)\n\t\t\tdev->in_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;\n\t\telse\n\t\t\tdev->out_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;\n\t}\n\n\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\",\n\t\tdev->in_ep, dev->out_ep);\n\n\tparams.device = &dev->udev->dev;\n\tparams.usb_device = dev->udev;\n\tparams.buffer_size = dev->buffer_size;\n\tparams.num_buffers = MAX_BUFFERS;\n\tparams.sendrequest_handler = smsusb_sendrequest;\n\tparams.context = dev;\n\tusb_make_path(dev->udev, params.devpath, sizeof(params.devpath));\n\n\tmdev = siano_media_device_register(dev, board_id);\n\n\t/* register in smscore */\n\trc = smscore_register_device(&params, &dev->coredev, 0, mdev);\n\tif (rc < 0) {\n\t\tpr_err(\"smscore_register_device(...) failed, rc %d\\n\", rc);\n\t\tsmsusb_term_device(intf);\n#ifdef CONFIG_MEDIA_CONTROLLER_DVB\n\t\tmedia_device_unregister(mdev);\n#endif\n\t\tkfree(mdev);\n\t\treturn rc;\n\t}\n\n\tsmscore_set_board_id(dev->coredev, board_id);\n\n\tdev->coredev->is_usb_device = true;\n\n\t/* initialize urbs */\n\tfor (i = 0; i < MAX_URBS; i++) {\n\t\tdev->surbs[i].dev = dev;\n\t\tusb_init_urb(&dev->surbs[i].urb);\n\t}\n\n\tpr_debug(\"smsusb_start_streaming(...).\\n\");\n\trc = smsusb_start_streaming(dev);\n\tif (rc < 0) {\n\t\tpr_err(\"smsusb_start_streaming(...) failed\\n\");\n\t\tsmsusb_term_device(intf);\n\t\treturn rc;\n\t}\n\n\tdev->state = SMSUSB_ACTIVE;\n\n\trc = smscore_start_device(dev->coredev);\n\tif (rc < 0) {\n\t\tpr_err(\"smscore_start_device(...) failed\\n\");\n\t\tsmsusb_term_device(intf);\n\t\treturn rc;\n\t}\n\n\tpr_debug(\"device 0x%p created\\n\", dev);\n\n\treturn rc;\n}",
        "code_after_change": "static int smsusb_init_device(struct usb_interface *intf, int board_id)\n{\n\tstruct smsdevice_params_t params;\n\tstruct smsusb_device_t *dev;\n\tvoid *mdev;\n\tint i, rc;\n\tint in_maxp;\n\n\t/* create device object */\n\tdev = kzalloc(sizeof(struct smsusb_device_t), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tmemset(&params, 0, sizeof(params));\n\tusb_set_intfdata(intf, dev);\n\tdev->udev = interface_to_usbdev(intf);\n\tdev->state = SMSUSB_DISCONNECTED;\n\n\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {\n\t\tstruct usb_endpoint_descriptor *desc =\n\t\t\t\t&intf->cur_altsetting->endpoint[i].desc;\n\n\t\tif (desc->bEndpointAddress & USB_DIR_IN) {\n\t\t\tdev->in_ep = desc->bEndpointAddress;\n\t\t\tin_maxp = usb_endpoint_maxp(desc);\n\t\t} else {\n\t\t\tdev->out_ep = desc->bEndpointAddress;\n\t\t}\n\t}\n\n\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\", dev->in_ep, dev->out_ep);\n\tif (!dev->in_ep || !dev->out_ep) {\t/* Missing endpoints? */\n\t\tsmsusb_term_device(intf);\n\t\treturn -ENODEV;\n\t}\n\n\tparams.device_type = sms_get_board(board_id)->type;\n\n\tswitch (params.device_type) {\n\tcase SMS_STELLAR:\n\t\tdev->buffer_size = USB1_BUFFER_SIZE;\n\n\t\tparams.setmode_handler = smsusb1_setmode;\n\t\tparams.detectmode_handler = smsusb1_detectmode;\n\t\tbreak;\n\tcase SMS_UNKNOWN_TYPE:\n\t\tpr_err(\"Unspecified sms device type!\\n\");\n\t\t/* fall-thru */\n\tdefault:\n\t\tdev->buffer_size = USB2_BUFFER_SIZE;\n\t\tdev->response_alignment = in_maxp - sizeof(struct sms_msg_hdr);\n\n\t\tparams.flags |= SMS_DEVICE_FAMILY2;\n\t\tbreak;\n\t}\n\n\tparams.device = &dev->udev->dev;\n\tparams.usb_device = dev->udev;\n\tparams.buffer_size = dev->buffer_size;\n\tparams.num_buffers = MAX_BUFFERS;\n\tparams.sendrequest_handler = smsusb_sendrequest;\n\tparams.context = dev;\n\tusb_make_path(dev->udev, params.devpath, sizeof(params.devpath));\n\n\tmdev = siano_media_device_register(dev, board_id);\n\n\t/* register in smscore */\n\trc = smscore_register_device(&params, &dev->coredev, 0, mdev);\n\tif (rc < 0) {\n\t\tpr_err(\"smscore_register_device(...) failed, rc %d\\n\", rc);\n\t\tsmsusb_term_device(intf);\n#ifdef CONFIG_MEDIA_CONTROLLER_DVB\n\t\tmedia_device_unregister(mdev);\n#endif\n\t\tkfree(mdev);\n\t\treturn rc;\n\t}\n\n\tsmscore_set_board_id(dev->coredev, board_id);\n\n\tdev->coredev->is_usb_device = true;\n\n\t/* initialize urbs */\n\tfor (i = 0; i < MAX_URBS; i++) {\n\t\tdev->surbs[i].dev = dev;\n\t\tusb_init_urb(&dev->surbs[i].urb);\n\t}\n\n\tpr_debug(\"smsusb_start_streaming(...).\\n\");\n\trc = smsusb_start_streaming(dev);\n\tif (rc < 0) {\n\t\tpr_err(\"smsusb_start_streaming(...) failed\\n\");\n\t\tsmsusb_term_device(intf);\n\t\treturn rc;\n\t}\n\n\tdev->state = SMSUSB_ACTIVE;\n\n\trc = smscore_start_device(dev->coredev);\n\tif (rc < 0) {\n\t\tpr_err(\"smscore_start_device(...) failed\\n\");\n\t\tsmsusb_term_device(intf);\n\t\treturn rc;\n\t}\n\n\tpr_debug(\"device 0x%p created\\n\", dev);\n\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,7 @@\n \tstruct smsusb_device_t *dev;\n \tvoid *mdev;\n \tint i, rc;\n+\tint in_maxp;\n \n \t/* create device object */\n \tdev = kzalloc(sizeof(struct smsusb_device_t), GFP_KERNEL);\n@@ -14,6 +15,24 @@\n \tusb_set_intfdata(intf, dev);\n \tdev->udev = interface_to_usbdev(intf);\n \tdev->state = SMSUSB_DISCONNECTED;\n+\n+\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {\n+\t\tstruct usb_endpoint_descriptor *desc =\n+\t\t\t\t&intf->cur_altsetting->endpoint[i].desc;\n+\n+\t\tif (desc->bEndpointAddress & USB_DIR_IN) {\n+\t\t\tdev->in_ep = desc->bEndpointAddress;\n+\t\t\tin_maxp = usb_endpoint_maxp(desc);\n+\t\t} else {\n+\t\t\tdev->out_ep = desc->bEndpointAddress;\n+\t\t}\n+\t}\n+\n+\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\", dev->in_ep, dev->out_ep);\n+\tif (!dev->in_ep || !dev->out_ep) {\t/* Missing endpoints? */\n+\t\tsmsusb_term_device(intf);\n+\t\treturn -ENODEV;\n+\t}\n \n \tparams.device_type = sms_get_board(board_id)->type;\n \n@@ -29,23 +48,11 @@\n \t\t/* fall-thru */\n \tdefault:\n \t\tdev->buffer_size = USB2_BUFFER_SIZE;\n-\t\tdev->response_alignment =\n-\t\t    le16_to_cpu(dev->udev->ep_in[1]->desc.wMaxPacketSize) -\n-\t\t    sizeof(struct sms_msg_hdr);\n+\t\tdev->response_alignment = in_maxp - sizeof(struct sms_msg_hdr);\n \n \t\tparams.flags |= SMS_DEVICE_FAMILY2;\n \t\tbreak;\n \t}\n-\n-\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {\n-\t\tif (intf->cur_altsetting->endpoint[i].desc. bEndpointAddress & USB_DIR_IN)\n-\t\t\tdev->in_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;\n-\t\telse\n-\t\t\tdev->out_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;\n-\t}\n-\n-\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\",\n-\t\tdev->in_ep, dev->out_ep);\n \n \tparams.device = &dev->udev->dev;\n \tparams.usb_device = dev->udev;",
        "function_modified_lines": {
            "added": [
                "\tint in_maxp;",
                "",
                "\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {",
                "\t\tstruct usb_endpoint_descriptor *desc =",
                "\t\t\t\t&intf->cur_altsetting->endpoint[i].desc;",
                "",
                "\t\tif (desc->bEndpointAddress & USB_DIR_IN) {",
                "\t\t\tdev->in_ep = desc->bEndpointAddress;",
                "\t\t\tin_maxp = usb_endpoint_maxp(desc);",
                "\t\t} else {",
                "\t\t\tdev->out_ep = desc->bEndpointAddress;",
                "\t\t}",
                "\t}",
                "",
                "\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\", dev->in_ep, dev->out_ep);",
                "\tif (!dev->in_ep || !dev->out_ep) {\t/* Missing endpoints? */",
                "\t\tsmsusb_term_device(intf);",
                "\t\treturn -ENODEV;",
                "\t}",
                "\t\tdev->response_alignment = in_maxp - sizeof(struct sms_msg_hdr);"
            ],
            "deleted": [
                "\t\tdev->response_alignment =",
                "\t\t    le16_to_cpu(dev->udev->ep_in[1]->desc.wMaxPacketSize) -",
                "\t\t    sizeof(struct sms_msg_hdr);",
                "",
                "\tfor (i = 0; i < intf->cur_altsetting->desc.bNumEndpoints; i++) {",
                "\t\tif (intf->cur_altsetting->endpoint[i].desc. bEndpointAddress & USB_DIR_IN)",
                "\t\t\tdev->in_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;",
                "\t\telse",
                "\t\t\tdev->out_ep = intf->cur_altsetting->endpoint[i].desc.bEndpointAddress;",
                "\t}",
                "",
                "\tpr_debug(\"in_ep = %02x, out_ep = %02x\\n\",",
                "\t\tdev->in_ep, dev->out_ep);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the drivers/media/usb/siano/smsusb.c driver.",
        "id": 2000
    },
    {
        "cve_id": "CVE-2019-15219",
        "code_before_change": "static int sisusb_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tstruct sisusb_usb_data *sisusb;\n\tint retval = 0, i;\n\n\tdev_info(&dev->dev, \"USB2VGA dongle found at address %d\\n\",\n\t\t\tdev->devnum);\n\n\t/* Allocate memory for our private */\n\tsisusb = kzalloc(sizeof(*sisusb), GFP_KERNEL);\n\tif (!sisusb)\n\t\treturn -ENOMEM;\n\n\tkref_init(&sisusb->kref);\n\n\tmutex_init(&(sisusb->lock));\n\n\t/* Register device */\n\tretval = usb_register_dev(intf, &usb_sisusb_class);\n\tif (retval) {\n\t\tdev_err(&sisusb->sisusb_dev->dev,\n\t\t\t\t\"Failed to get a minor for device %d\\n\",\n\t\t\t\tdev->devnum);\n\t\tretval = -ENODEV;\n\t\tgoto error_1;\n\t}\n\n\tsisusb->sisusb_dev = dev;\n\tsisusb->minor      = intf->minor;\n\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;\n\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;\n\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;\n\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;\n\t/* Everything else is zero */\n\n\t/* Allocate buffers */\n\tsisusb->ibufsize = SISUSB_IBUF_SIZE;\n\tsisusb->ibuf = kmalloc(SISUSB_IBUF_SIZE, GFP_KERNEL);\n\tif (!sisusb->ibuf) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_2;\n\t}\n\n\tsisusb->numobufs = 0;\n\tsisusb->obufsize = SISUSB_OBUF_SIZE;\n\tfor (i = 0; i < NUMOBUFS; i++) {\n\t\tsisusb->obuf[i] = kmalloc(SISUSB_OBUF_SIZE, GFP_KERNEL);\n\t\tif (!sisusb->obuf[i]) {\n\t\t\tif (i == 0) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto error_3;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tsisusb->numobufs++;\n\t}\n\n\t/* Allocate URBs */\n\tsisusb->sisurbin = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!sisusb->sisurbin) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_3;\n\t}\n\tsisusb->completein = 1;\n\n\tfor (i = 0; i < sisusb->numobufs; i++) {\n\t\tsisusb->sisurbout[i] = usb_alloc_urb(0, GFP_KERNEL);\n\t\tif (!sisusb->sisurbout[i]) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto error_4;\n\t\t}\n\t\tsisusb->urbout_context[i].sisusb = (void *)sisusb;\n\t\tsisusb->urbout_context[i].urbindex = i;\n\t\tsisusb->urbstatus[i] = 0;\n\t}\n\n\tdev_info(&sisusb->sisusb_dev->dev, \"Allocated %d output buffers\\n\",\n\t\t\tsisusb->numobufs);\n\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\t/* Allocate our SiS_Pr */\n\tsisusb->SiS_Pr = kmalloc(sizeof(struct SiS_Private), GFP_KERNEL);\n\tif (!sisusb->SiS_Pr) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_4;\n\t}\n#endif\n\n\t/* Do remaining init stuff */\n\n\tinit_waitqueue_head(&sisusb->wait_q);\n\n\tusb_set_intfdata(intf, sisusb);\n\n\tusb_get_dev(sisusb->sisusb_dev);\n\n\tsisusb->present = 1;\n\n\tif (dev->speed == USB_SPEED_HIGH || dev->speed >= USB_SPEED_SUPER) {\n\t\tint initscreen = 1;\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\t\tif (sisusb_first_vc > 0 && sisusb_last_vc > 0 &&\n\t\t\t\tsisusb_first_vc <= sisusb_last_vc &&\n\t\t\t\tsisusb_last_vc <= MAX_NR_CONSOLES)\n\t\t\tinitscreen = 0;\n#endif\n\t\tif (sisusb_init_gfxdevice(sisusb, initscreen))\n\t\t\tdev_err(&sisusb->sisusb_dev->dev,\n\t\t\t\t\t\"Failed to early initialize device\\n\");\n\n\t} else\n\t\tdev_info(&sisusb->sisusb_dev->dev,\n\t\t\t\t\"Not attached to USB 2.0 hub, deferring init\\n\");\n\n\tsisusb->ready = 1;\n\n#ifdef SISUSBENDIANTEST\n\tdev_dbg(&sisusb->sisusb_dev->dev, \"*** RWTEST ***\\n\");\n\tsisusb_testreadwrite(sisusb);\n\tdev_dbg(&sisusb->sisusb_dev->dev, \"*** RWTEST END ***\\n\");\n#endif\n\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\tsisusb_console_init(sisusb, sisusb_first_vc, sisusb_last_vc);\n#endif\n\n\treturn 0;\n\nerror_4:\n\tsisusb_free_urbs(sisusb);\nerror_3:\n\tsisusb_free_buffers(sisusb);\nerror_2:\n\tusb_deregister_dev(intf, &usb_sisusb_class);\nerror_1:\n\tkfree(sisusb);\n\treturn retval;\n}",
        "code_after_change": "static int sisusb_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tstruct sisusb_usb_data *sisusb;\n\tint retval = 0, i;\n\n\tdev_info(&dev->dev, \"USB2VGA dongle found at address %d\\n\",\n\t\t\tdev->devnum);\n\n\t/* Allocate memory for our private */\n\tsisusb = kzalloc(sizeof(*sisusb), GFP_KERNEL);\n\tif (!sisusb)\n\t\treturn -ENOMEM;\n\n\tkref_init(&sisusb->kref);\n\n\tmutex_init(&(sisusb->lock));\n\n\tsisusb->sisusb_dev = dev;\n\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;\n\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;\n\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;\n\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;\n\t/* Everything else is zero */\n\n\t/* Register device */\n\tretval = usb_register_dev(intf, &usb_sisusb_class);\n\tif (retval) {\n\t\tdev_err(&sisusb->sisusb_dev->dev,\n\t\t\t\t\"Failed to get a minor for device %d\\n\",\n\t\t\t\tdev->devnum);\n\t\tretval = -ENODEV;\n\t\tgoto error_1;\n\t}\n\n\tsisusb->minor = intf->minor;\n\n\t/* Allocate buffers */\n\tsisusb->ibufsize = SISUSB_IBUF_SIZE;\n\tsisusb->ibuf = kmalloc(SISUSB_IBUF_SIZE, GFP_KERNEL);\n\tif (!sisusb->ibuf) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_2;\n\t}\n\n\tsisusb->numobufs = 0;\n\tsisusb->obufsize = SISUSB_OBUF_SIZE;\n\tfor (i = 0; i < NUMOBUFS; i++) {\n\t\tsisusb->obuf[i] = kmalloc(SISUSB_OBUF_SIZE, GFP_KERNEL);\n\t\tif (!sisusb->obuf[i]) {\n\t\t\tif (i == 0) {\n\t\t\t\tretval = -ENOMEM;\n\t\t\t\tgoto error_3;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tsisusb->numobufs++;\n\t}\n\n\t/* Allocate URBs */\n\tsisusb->sisurbin = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!sisusb->sisurbin) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_3;\n\t}\n\tsisusb->completein = 1;\n\n\tfor (i = 0; i < sisusb->numobufs; i++) {\n\t\tsisusb->sisurbout[i] = usb_alloc_urb(0, GFP_KERNEL);\n\t\tif (!sisusb->sisurbout[i]) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto error_4;\n\t\t}\n\t\tsisusb->urbout_context[i].sisusb = (void *)sisusb;\n\t\tsisusb->urbout_context[i].urbindex = i;\n\t\tsisusb->urbstatus[i] = 0;\n\t}\n\n\tdev_info(&sisusb->sisusb_dev->dev, \"Allocated %d output buffers\\n\",\n\t\t\tsisusb->numobufs);\n\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\t/* Allocate our SiS_Pr */\n\tsisusb->SiS_Pr = kmalloc(sizeof(struct SiS_Private), GFP_KERNEL);\n\tif (!sisusb->SiS_Pr) {\n\t\tretval = -ENOMEM;\n\t\tgoto error_4;\n\t}\n#endif\n\n\t/* Do remaining init stuff */\n\n\tinit_waitqueue_head(&sisusb->wait_q);\n\n\tusb_set_intfdata(intf, sisusb);\n\n\tusb_get_dev(sisusb->sisusb_dev);\n\n\tsisusb->present = 1;\n\n\tif (dev->speed == USB_SPEED_HIGH || dev->speed >= USB_SPEED_SUPER) {\n\t\tint initscreen = 1;\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\t\tif (sisusb_first_vc > 0 && sisusb_last_vc > 0 &&\n\t\t\t\tsisusb_first_vc <= sisusb_last_vc &&\n\t\t\t\tsisusb_last_vc <= MAX_NR_CONSOLES)\n\t\t\tinitscreen = 0;\n#endif\n\t\tif (sisusb_init_gfxdevice(sisusb, initscreen))\n\t\t\tdev_err(&sisusb->sisusb_dev->dev,\n\t\t\t\t\t\"Failed to early initialize device\\n\");\n\n\t} else\n\t\tdev_info(&sisusb->sisusb_dev->dev,\n\t\t\t\t\"Not attached to USB 2.0 hub, deferring init\\n\");\n\n\tsisusb->ready = 1;\n\n#ifdef SISUSBENDIANTEST\n\tdev_dbg(&sisusb->sisusb_dev->dev, \"*** RWTEST ***\\n\");\n\tsisusb_testreadwrite(sisusb);\n\tdev_dbg(&sisusb->sisusb_dev->dev, \"*** RWTEST END ***\\n\");\n#endif\n\n#ifdef CONFIG_USB_SISUSBVGA_CON\n\tsisusb_console_init(sisusb, sisusb_first_vc, sisusb_last_vc);\n#endif\n\n\treturn 0;\n\nerror_4:\n\tsisusb_free_urbs(sisusb);\nerror_3:\n\tsisusb_free_buffers(sisusb);\nerror_2:\n\tusb_deregister_dev(intf, &usb_sisusb_class);\nerror_1:\n\tkfree(sisusb);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,13 @@\n \n \tmutex_init(&(sisusb->lock));\n \n+\tsisusb->sisusb_dev = dev;\n+\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;\n+\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;\n+\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;\n+\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;\n+\t/* Everything else is zero */\n+\n \t/* Register device */\n \tretval = usb_register_dev(intf, &usb_sisusb_class);\n \tif (retval) {\n@@ -27,13 +34,7 @@\n \t\tgoto error_1;\n \t}\n \n-\tsisusb->sisusb_dev = dev;\n-\tsisusb->minor      = intf->minor;\n-\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;\n-\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;\n-\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;\n-\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;\n-\t/* Everything else is zero */\n+\tsisusb->minor = intf->minor;\n \n \t/* Allocate buffers */\n \tsisusb->ibufsize = SISUSB_IBUF_SIZE;",
        "function_modified_lines": {
            "added": [
                "\tsisusb->sisusb_dev = dev;",
                "\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;",
                "\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;",
                "\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;",
                "\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;",
                "\t/* Everything else is zero */",
                "",
                "\tsisusb->minor = intf->minor;"
            ],
            "deleted": [
                "\tsisusb->sisusb_dev = dev;",
                "\tsisusb->minor      = intf->minor;",
                "\tsisusb->vrambase   = SISUSB_PCI_MEMBASE;",
                "\tsisusb->mmiobase   = SISUSB_PCI_MMIOBASE;",
                "\tsisusb->mmiosize   = SISUSB_PCI_MMIOSIZE;",
                "\tsisusb->ioportbase = SISUSB_PCI_IOPORTBASE;",
                "\t/* Everything else is zero */"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the drivers/usb/misc/sisusbvga/sisusb.c driver.",
        "id": 2001
    },
    {
        "cve_id": "CVE-2022-3202",
        "code_before_change": "void jfs_evict_inode(struct inode *inode)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\n\tjfs_info(\"In jfs_evict_inode, inode = 0x%p\", inode);\n\n\tif (!inode->i_nlink && !is_bad_inode(inode)) {\n\t\tdquot_initialize(inode);\n\n\t\tif (JFS_IP(inode)->fileset == FILESYSTEM_I) {\n\t\t\ttruncate_inode_pages_final(&inode->i_data);\n\n\t\t\tif (test_cflag(COMMIT_Freewmap, inode))\n\t\t\t\tjfs_free_zero_link(inode);\n\n\t\t\tif (JFS_SBI(inode->i_sb)->ipimap)\n\t\t\t\tdiFree(inode);\n\n\t\t\t/*\n\t\t\t * Free the inode from the quota allocation.\n\t\t\t */\n\t\t\tdquot_free_inode(inode);\n\t\t}\n\t} else {\n\t\ttruncate_inode_pages_final(&inode->i_data);\n\t}\n\tclear_inode(inode);\n\tdquot_drop(inode);\n\n\tBUG_ON(!list_empty(&ji->anon_inode_list));\n\n\tspin_lock_irq(&ji->ag_lock);\n\tif (ji->active_ag != -1) {\n\t\tstruct bmap *bmap = JFS_SBI(inode->i_sb)->bmap;\n\t\tatomic_dec(&bmap->db_active[ji->active_ag]);\n\t\tji->active_ag = -1;\n\t}\n\tspin_unlock_irq(&ji->ag_lock);\n}",
        "code_after_change": "void jfs_evict_inode(struct inode *inode)\n{\n\tstruct jfs_inode_info *ji = JFS_IP(inode);\n\n\tjfs_info(\"In jfs_evict_inode, inode = 0x%p\", inode);\n\n\tif (!inode->i_nlink && !is_bad_inode(inode)) {\n\t\tdquot_initialize(inode);\n\n\t\tif (JFS_IP(inode)->fileset == FILESYSTEM_I) {\n\t\t\tstruct inode *ipimap = JFS_SBI(inode->i_sb)->ipimap;\n\t\t\ttruncate_inode_pages_final(&inode->i_data);\n\n\t\t\tif (test_cflag(COMMIT_Freewmap, inode))\n\t\t\t\tjfs_free_zero_link(inode);\n\n\t\t\tif (ipimap && JFS_IP(ipimap)->i_imap)\n\t\t\t\tdiFree(inode);\n\n\t\t\t/*\n\t\t\t * Free the inode from the quota allocation.\n\t\t\t */\n\t\t\tdquot_free_inode(inode);\n\t\t}\n\t} else {\n\t\ttruncate_inode_pages_final(&inode->i_data);\n\t}\n\tclear_inode(inode);\n\tdquot_drop(inode);\n\n\tBUG_ON(!list_empty(&ji->anon_inode_list));\n\n\tspin_lock_irq(&ji->ag_lock);\n\tif (ji->active_ag != -1) {\n\t\tstruct bmap *bmap = JFS_SBI(inode->i_sb)->bmap;\n\t\tatomic_dec(&bmap->db_active[ji->active_ag]);\n\t\tji->active_ag = -1;\n\t}\n\tspin_unlock_irq(&ji->ag_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,12 +8,13 @@\n \t\tdquot_initialize(inode);\n \n \t\tif (JFS_IP(inode)->fileset == FILESYSTEM_I) {\n+\t\t\tstruct inode *ipimap = JFS_SBI(inode->i_sb)->ipimap;\n \t\t\ttruncate_inode_pages_final(&inode->i_data);\n \n \t\t\tif (test_cflag(COMMIT_Freewmap, inode))\n \t\t\t\tjfs_free_zero_link(inode);\n \n-\t\t\tif (JFS_SBI(inode->i_sb)->ipimap)\n+\t\t\tif (ipimap && JFS_IP(ipimap)->i_imap)\n \t\t\t\tdiFree(inode);\n \n \t\t\t/*",
        "function_modified_lines": {
            "added": [
                "\t\t\tstruct inode *ipimap = JFS_SBI(inode->i_sb)->ipimap;",
                "\t\t\tif (ipimap && JFS_IP(ipimap)->i_imap)"
            ],
            "deleted": [
                "\t\t\tif (JFS_SBI(inode->i_sb)->ipimap)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw in diFree in fs/jfs/inode.c in Journaled File System (JFS)in the Linux kernel. This could allow a local attacker to crash the system or leak kernel internal information.",
        "id": 3567
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static bool is_spillable_regtype(enum bpf_reg_type type)\n{\n\tswitch (type) {\n\tcase PTR_TO_MAP_VALUE:\n\tcase PTR_TO_MAP_VALUE_OR_NULL:\n\tcase PTR_TO_STACK:\n\tcase PTR_TO_CTX:\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_FLOW_KEYS:\n\tcase CONST_PTR_TO_MAP:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\tcase PTR_TO_BTF_ID:\n\tcase PTR_TO_BTF_ID_OR_NULL:\n\tcase PTR_TO_RDONLY_BUF:\n\tcase PTR_TO_RDONLY_BUF_OR_NULL:\n\tcase PTR_TO_RDWR_BUF:\n\tcase PTR_TO_RDWR_BUF_OR_NULL:\n\tcase PTR_TO_PERCPU_BTF_ID:\n\tcase PTR_TO_MEM:\n\tcase PTR_TO_MEM_OR_NULL:\n\tcase PTR_TO_FUNC:\n\tcase PTR_TO_MAP_KEY:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}",
        "code_after_change": "static bool is_spillable_regtype(enum bpf_reg_type type)\n{\n\tswitch (base_type(type)) {\n\tcase PTR_TO_MAP_VALUE:\n\tcase PTR_TO_STACK:\n\tcase PTR_TO_CTX:\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_FLOW_KEYS:\n\tcase CONST_PTR_TO_MAP:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_XDP_SOCK:\n\tcase PTR_TO_BTF_ID:\n\tcase PTR_TO_RDONLY_BUF:\n\tcase PTR_TO_RDWR_BUF:\n\tcase PTR_TO_PERCPU_BTF_ID:\n\tcase PTR_TO_MEM:\n\tcase PTR_TO_FUNC:\n\tcase PTR_TO_MAP_KEY:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,7 @@\n static bool is_spillable_regtype(enum bpf_reg_type type)\n {\n-\tswitch (type) {\n+\tswitch (base_type(type)) {\n \tcase PTR_TO_MAP_VALUE:\n-\tcase PTR_TO_MAP_VALUE_OR_NULL:\n \tcase PTR_TO_STACK:\n \tcase PTR_TO_CTX:\n \tcase PTR_TO_PACKET:\n@@ -11,21 +10,14 @@\n \tcase PTR_TO_FLOW_KEYS:\n \tcase CONST_PTR_TO_MAP:\n \tcase PTR_TO_SOCKET:\n-\tcase PTR_TO_SOCKET_OR_NULL:\n \tcase PTR_TO_SOCK_COMMON:\n-\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n \tcase PTR_TO_TCP_SOCK:\n-\tcase PTR_TO_TCP_SOCK_OR_NULL:\n \tcase PTR_TO_XDP_SOCK:\n \tcase PTR_TO_BTF_ID:\n-\tcase PTR_TO_BTF_ID_OR_NULL:\n \tcase PTR_TO_RDONLY_BUF:\n-\tcase PTR_TO_RDONLY_BUF_OR_NULL:\n \tcase PTR_TO_RDWR_BUF:\n-\tcase PTR_TO_RDWR_BUF_OR_NULL:\n \tcase PTR_TO_PERCPU_BTF_ID:\n \tcase PTR_TO_MEM:\n-\tcase PTR_TO_MEM_OR_NULL:\n \tcase PTR_TO_FUNC:\n \tcase PTR_TO_MAP_KEY:\n \t\treturn true;",
        "function_modified_lines": {
            "added": [
                "\tswitch (base_type(type)) {"
            ],
            "deleted": [
                "\tswitch (type) {",
                "\tcase PTR_TO_MAP_VALUE_OR_NULL:",
                "\tcase PTR_TO_SOCKET_OR_NULL:",
                "\tcase PTR_TO_SOCK_COMMON_OR_NULL:",
                "\tcase PTR_TO_TCP_SOCK_OR_NULL:",
                "\tcase PTR_TO_BTF_ID_OR_NULL:",
                "\tcase PTR_TO_RDONLY_BUF_OR_NULL:",
                "\tcase PTR_TO_RDWR_BUF_OR_NULL:",
                "\tcase PTR_TO_MEM_OR_NULL:"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3442
    },
    {
        "cve_id": "CVE-2016-10147",
        "code_before_change": "static inline void mcryptd_check_internal(struct rtattr **tb, u32 *type,\n\t\t\t\t\t  u32 *mask)\n{\n\tstruct crypto_attr_type *algt;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn;\n\tif ((algt->type & CRYPTO_ALG_INTERNAL))\n\t\t*type |= CRYPTO_ALG_INTERNAL;\n\tif ((algt->mask & CRYPTO_ALG_INTERNAL))\n\t\t*mask |= CRYPTO_ALG_INTERNAL;\n}",
        "code_after_change": "static inline bool mcryptd_check_internal(struct rtattr **tb, u32 *type,\n\t\t\t\t\t  u32 *mask)\n{\n\tstruct crypto_attr_type *algt;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn false;\n\n\t*type |= algt->type & CRYPTO_ALG_INTERNAL;\n\t*mask |= algt->mask & CRYPTO_ALG_INTERNAL;\n\n\tif (*type & *mask & CRYPTO_ALG_INTERNAL)\n\t\treturn true;\n\telse\n\t\treturn false;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,13 +1,17 @@\n-static inline void mcryptd_check_internal(struct rtattr **tb, u32 *type,\n+static inline bool mcryptd_check_internal(struct rtattr **tb, u32 *type,\n \t\t\t\t\t  u32 *mask)\n {\n \tstruct crypto_attr_type *algt;\n \n \talgt = crypto_get_attr_type(tb);\n \tif (IS_ERR(algt))\n-\t\treturn;\n-\tif ((algt->type & CRYPTO_ALG_INTERNAL))\n-\t\t*type |= CRYPTO_ALG_INTERNAL;\n-\tif ((algt->mask & CRYPTO_ALG_INTERNAL))\n-\t\t*mask |= CRYPTO_ALG_INTERNAL;\n+\t\treturn false;\n+\n+\t*type |= algt->type & CRYPTO_ALG_INTERNAL;\n+\t*mask |= algt->mask & CRYPTO_ALG_INTERNAL;\n+\n+\tif (*type & *mask & CRYPTO_ALG_INTERNAL)\n+\t\treturn true;\n+\telse\n+\t\treturn false;\n }",
        "function_modified_lines": {
            "added": [
                "static inline bool mcryptd_check_internal(struct rtattr **tb, u32 *type,",
                "\t\treturn false;",
                "",
                "\t*type |= algt->type & CRYPTO_ALG_INTERNAL;",
                "\t*mask |= algt->mask & CRYPTO_ALG_INTERNAL;",
                "",
                "\tif (*type & *mask & CRYPTO_ALG_INTERNAL)",
                "\t\treturn true;",
                "\telse",
                "\t\treturn false;"
            ],
            "deleted": [
                "static inline void mcryptd_check_internal(struct rtattr **tb, u32 *type,",
                "\t\treturn;",
                "\tif ((algt->type & CRYPTO_ALG_INTERNAL))",
                "\t\t*type |= CRYPTO_ALG_INTERNAL;",
                "\tif ((algt->mask & CRYPTO_ALG_INTERNAL))",
                "\t\t*mask |= CRYPTO_ALG_INTERNAL;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/mcryptd.c in the Linux kernel before 4.8.15 allows local users to cause a denial of service (NULL pointer dereference and system crash) by using an AF_ALG socket with an incompatible algorithm, as demonstrated by mcryptd(md5).",
        "id": 896
    },
    {
        "cve_id": "CVE-2023-3106",
        "code_before_change": "static int xfrm_dump_sa_done(struct netlink_callback *cb)\n{\n\tstruct xfrm_state_walk *walk = (struct xfrm_state_walk *) &cb->args[1];\n\tstruct sock *sk = cb->skb->sk;\n\tstruct net *net = sock_net(sk);\n\n\txfrm_state_walk_done(walk, net);\n\treturn 0;\n}",
        "code_after_change": "static int xfrm_dump_sa_done(struct netlink_callback *cb)\n{\n\tstruct xfrm_state_walk *walk = (struct xfrm_state_walk *) &cb->args[1];\n\tstruct sock *sk = cb->skb->sk;\n\tstruct net *net = sock_net(sk);\n\n\tif (cb->args[0])\n\t\txfrm_state_walk_done(walk, net);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,7 @@\n \tstruct sock *sk = cb->skb->sk;\n \tstruct net *net = sock_net(sk);\n \n-\txfrm_state_walk_done(walk, net);\n+\tif (cb->args[0])\n+\t\txfrm_state_walk_done(walk, net);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (cb->args[0])",
                "\t\txfrm_state_walk_done(walk, net);"
            ],
            "deleted": [
                "\txfrm_state_walk_done(walk, net);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference vulnerability was found in netlink_dump. This issue can occur when the Netlink socket receives the message(sendmsg) for the XFRM_MSG_GETSA, XFRM_MSG_GETPOLICY type message, and the DUMP flag is set and can cause a denial of service or possibly another unspecified impact. Due to the nature of the flaw, privilege escalation cannot be fully ruled out, although it is unlikely.",
        "id": 3991
    },
    {
        "cve_id": "CVE-2020-12364",
        "code_before_change": "int intel_guc_ads_create(struct intel_guc *guc)\n{\n\tconst u32 size = PAGE_ALIGN(sizeof(struct __guc_ads_blob));\n\tint ret;\n\n\tGEM_BUG_ON(guc->ads_vma);\n\n\tret = intel_guc_allocate_and_map_vma(guc, size, &guc->ads_vma,\n\t\t\t\t\t     (void **)&guc->ads_blob);\n\n\tif (ret)\n\t\treturn ret;\n\n\t__guc_ads_init(guc);\n\n\treturn 0;\n}",
        "code_after_change": "int intel_guc_ads_create(struct intel_guc *guc)\n{\n\tu32 size;\n\tint ret;\n\n\tGEM_BUG_ON(guc->ads_vma);\n\n\tsize = guc_ads_blob_size(guc);\n\n\tret = intel_guc_allocate_and_map_vma(guc, size, &guc->ads_vma,\n\t\t\t\t\t     (void **)&guc->ads_blob);\n\tif (ret)\n\t\treturn ret;\n\n\t__guc_ads_init(guc);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,13 +1,14 @@\n int intel_guc_ads_create(struct intel_guc *guc)\n {\n-\tconst u32 size = PAGE_ALIGN(sizeof(struct __guc_ads_blob));\n+\tu32 size;\n \tint ret;\n \n \tGEM_BUG_ON(guc->ads_vma);\n \n+\tsize = guc_ads_blob_size(guc);\n+\n \tret = intel_guc_allocate_and_map_vma(guc, size, &guc->ads_vma,\n \t\t\t\t\t     (void **)&guc->ads_blob);\n-\n \tif (ret)\n \t\treturn ret;\n ",
        "function_modified_lines": {
            "added": [
                "\tu32 size;",
                "\tsize = guc_ads_blob_size(guc);",
                ""
            ],
            "deleted": [
                "\tconst u32 size = PAGE_ALIGN(sizeof(struct __guc_ads_blob));",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Null pointer reference in some Intel(R) Graphics Drivers for Windows* before version 26.20.100.7212 and before version Linux kernel version 5.5 may allow a privileged user to potentially enable a denial of service via local access.",
        "id": 2467
    },
    {
        "cve_id": "CVE-2021-4095",
        "code_before_change": "void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)\n{\n\tint version;\n\tint r;\n\tstruct pvclock_wall_clock wc;\n\tu32 wc_sec_hi;\n\tu64 wall_nsec;\n\n\tif (!wall_clock)\n\t\treturn;\n\n\tr = kvm_read_guest(kvm, wall_clock, &version, sizeof(version));\n\tif (r)\n\t\treturn;\n\n\tif (version & 1)\n\t\t++version;  /* first time write, random junk */\n\n\t++version;\n\n\tif (kvm_write_guest(kvm, wall_clock, &version, sizeof(version)))\n\t\treturn;\n\n\t/*\n\t * The guest calculates current wall clock time by adding\n\t * system time (updated by kvm_guest_time_update below) to the\n\t * wall clock specified here.  We do the reverse here.\n\t */\n\twall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);\n\n\twc.nsec = do_div(wall_nsec, 1000000000);\n\twc.sec = (u32)wall_nsec; /* overflow in 2106 guest time */\n\twc.version = version;\n\n\tkvm_write_guest(kvm, wall_clock, &wc, sizeof(wc));\n\n\tif (sec_hi_ofs) {\n\t\twc_sec_hi = wall_nsec >> 32;\n\t\tkvm_write_guest(kvm, wall_clock + sec_hi_ofs,\n\t\t\t\t&wc_sec_hi, sizeof(wc_sec_hi));\n\t}\n\n\tversion++;\n\tkvm_write_guest(kvm, wall_clock, &version, sizeof(version));\n}",
        "code_after_change": "static void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)\n{\n\tint version;\n\tint r;\n\tstruct pvclock_wall_clock wc;\n\tu32 wc_sec_hi;\n\tu64 wall_nsec;\n\n\tif (!wall_clock)\n\t\treturn;\n\n\tr = kvm_read_guest(kvm, wall_clock, &version, sizeof(version));\n\tif (r)\n\t\treturn;\n\n\tif (version & 1)\n\t\t++version;  /* first time write, random junk */\n\n\t++version;\n\n\tif (kvm_write_guest(kvm, wall_clock, &version, sizeof(version)))\n\t\treturn;\n\n\t/*\n\t * The guest calculates current wall clock time by adding\n\t * system time (updated by kvm_guest_time_update below) to the\n\t * wall clock specified here.  We do the reverse here.\n\t */\n\twall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);\n\n\twc.nsec = do_div(wall_nsec, 1000000000);\n\twc.sec = (u32)wall_nsec; /* overflow in 2106 guest time */\n\twc.version = version;\n\n\tkvm_write_guest(kvm, wall_clock, &wc, sizeof(wc));\n\n\tif (sec_hi_ofs) {\n\t\twc_sec_hi = wall_nsec >> 32;\n\t\tkvm_write_guest(kvm, wall_clock + sec_hi_ofs,\n\t\t\t\t&wc_sec_hi, sizeof(wc_sec_hi));\n\t}\n\n\tversion++;\n\tkvm_write_guest(kvm, wall_clock, &version, sizeof(version));\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n-void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)\n+static void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)\n {\n \tint version;\n \tint r;",
        "function_modified_lines": {
            "added": [
                "static void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)"
            ],
            "deleted": [
                "void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference was found in the Linux kernel's KVM when dirty ring logging is enabled without an active vCPU context. An unprivileged local attacker on the host may use this flaw to cause a kernel oops condition and thus a denial of service by issuing a KVM_XEN_HVM_SET_ATTR ioctl. This flaw affects Linux kernel versions prior to 5.17-rc1.",
        "id": 3132
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_sock_access(struct bpf_verifier_env *env, int insn_idx,\n\t\t\t     u32 regno, int off, int size,\n\t\t\t     enum bpf_access_type t)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = &regs[regno];\n\tstruct bpf_insn_access_aux info = {};\n\tbool valid;\n\n\tif (reg->smin_value < 0) {\n\t\tverbose(env, \"R%d min value is negative, either use unsigned index or do a if (index >=0) check.\\n\",\n\t\t\tregno);\n\t\treturn -EACCES;\n\t}\n\n\tswitch (reg->type) {\n\tcase PTR_TO_SOCK_COMMON:\n\t\tvalid = bpf_sock_common_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_SOCKET:\n\t\tvalid = bpf_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_TCP_SOCK:\n\t\tvalid = bpf_tcp_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_XDP_SOCK:\n\t\tvalid = bpf_xdp_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tdefault:\n\t\tvalid = false;\n\t}\n\n\n\tif (valid) {\n\t\tenv->insn_aux_data[insn_idx].ctx_field_size =\n\t\t\tinfo.ctx_field_size;\n\t\treturn 0;\n\t}\n\n\tverbose(env, \"R%d invalid %s access off=%d size=%d\\n\",\n\t\tregno, reg_type_str[reg->type], off, size);\n\n\treturn -EACCES;\n}",
        "code_after_change": "static int check_sock_access(struct bpf_verifier_env *env, int insn_idx,\n\t\t\t     u32 regno, int off, int size,\n\t\t\t     enum bpf_access_type t)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = &regs[regno];\n\tstruct bpf_insn_access_aux info = {};\n\tbool valid;\n\n\tif (reg->smin_value < 0) {\n\t\tverbose(env, \"R%d min value is negative, either use unsigned index or do a if (index >=0) check.\\n\",\n\t\t\tregno);\n\t\treturn -EACCES;\n\t}\n\n\tswitch (reg->type) {\n\tcase PTR_TO_SOCK_COMMON:\n\t\tvalid = bpf_sock_common_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_SOCKET:\n\t\tvalid = bpf_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_TCP_SOCK:\n\t\tvalid = bpf_tcp_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tcase PTR_TO_XDP_SOCK:\n\t\tvalid = bpf_xdp_sock_is_valid_access(off, size, t, &info);\n\t\tbreak;\n\tdefault:\n\t\tvalid = false;\n\t}\n\n\n\tif (valid) {\n\t\tenv->insn_aux_data[insn_idx].ctx_field_size =\n\t\t\tinfo.ctx_field_size;\n\t\treturn 0;\n\t}\n\n\tverbose(env, \"R%d invalid %s access off=%d size=%d\\n\",\n\t\tregno, reg_type_str(env, reg->type), off, size);\n\n\treturn -EACCES;\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,7 +38,7 @@\n \t}\n \n \tverbose(env, \"R%d invalid %s access off=%d size=%d\\n\",\n-\t\tregno, reg_type_str[reg->type], off, size);\n+\t\tregno, reg_type_str(env, reg->type), off, size);\n \n \treturn -EACCES;\n }",
        "function_modified_lines": {
            "added": [
                "\t\tregno, reg_type_str(env, reg->type), off, size);"
            ],
            "deleted": [
                "\t\tregno, reg_type_str[reg->type], off, size);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3446
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static void print_verifier_state(struct bpf_verifier_env *env,\n\t\t\t\t const struct bpf_func_state *state,\n\t\t\t\t bool print_all)\n{\n\tconst struct bpf_reg_state *reg;\n\tenum bpf_reg_type t;\n\tint i;\n\n\tif (state->frameno)\n\t\tverbose(env, \" frame%d:\", state->frameno);\n\tfor (i = 0; i < MAX_BPF_REG; i++) {\n\t\treg = &state->regs[i];\n\t\tt = reg->type;\n\t\tif (t == NOT_INIT)\n\t\t\tcontinue;\n\t\tif (!print_all && !reg_scratched(env, i))\n\t\t\tcontinue;\n\t\tverbose(env, \" R%d\", i);\n\t\tprint_liveness(env, reg->live);\n\t\tverbose(env, \"=%s\", reg_type_str[t]);\n\t\tif (t == SCALAR_VALUE && reg->precise)\n\t\t\tverbose(env, \"P\");\n\t\tif ((t == SCALAR_VALUE || t == PTR_TO_STACK) &&\n\t\t    tnum_is_const(reg->var_off)) {\n\t\t\t/* reg->off should be 0 for SCALAR_VALUE */\n\t\t\tverbose(env, \"%lld\", reg->var_off.value + reg->off);\n\t\t} else {\n\t\t\tif (t == PTR_TO_BTF_ID ||\n\t\t\t    t == PTR_TO_BTF_ID_OR_NULL ||\n\t\t\t    t == PTR_TO_PERCPU_BTF_ID)\n\t\t\t\tverbose(env, \"%s\", kernel_type_name(reg->btf, reg->btf_id));\n\t\t\tverbose(env, \"(id=%d\", reg->id);\n\t\t\tif (reg_type_may_be_refcounted_or_null(t))\n\t\t\t\tverbose(env, \",ref_obj_id=%d\", reg->ref_obj_id);\n\t\t\tif (t != SCALAR_VALUE)\n\t\t\t\tverbose(env, \",off=%d\", reg->off);\n\t\t\tif (type_is_pkt_pointer(t))\n\t\t\t\tverbose(env, \",r=%d\", reg->range);\n\t\t\telse if (t == CONST_PTR_TO_MAP ||\n\t\t\t\t t == PTR_TO_MAP_KEY ||\n\t\t\t\t t == PTR_TO_MAP_VALUE ||\n\t\t\t\t t == PTR_TO_MAP_VALUE_OR_NULL)\n\t\t\t\tverbose(env, \",ks=%d,vs=%d\",\n\t\t\t\t\treg->map_ptr->key_size,\n\t\t\t\t\treg->map_ptr->value_size);\n\t\t\tif (tnum_is_const(reg->var_off)) {\n\t\t\t\t/* Typically an immediate SCALAR_VALUE, but\n\t\t\t\t * could be a pointer whose offset is too big\n\t\t\t\t * for reg->off\n\t\t\t\t */\n\t\t\t\tverbose(env, \",imm=%llx\", reg->var_off.value);\n\t\t\t} else {\n\t\t\t\tif (reg->smin_value != reg->umin_value &&\n\t\t\t\t    reg->smin_value != S64_MIN)\n\t\t\t\t\tverbose(env, \",smin_value=%lld\",\n\t\t\t\t\t\t(long long)reg->smin_value);\n\t\t\t\tif (reg->smax_value != reg->umax_value &&\n\t\t\t\t    reg->smax_value != S64_MAX)\n\t\t\t\t\tverbose(env, \",smax_value=%lld\",\n\t\t\t\t\t\t(long long)reg->smax_value);\n\t\t\t\tif (reg->umin_value != 0)\n\t\t\t\t\tverbose(env, \",umin_value=%llu\",\n\t\t\t\t\t\t(unsigned long long)reg->umin_value);\n\t\t\t\tif (reg->umax_value != U64_MAX)\n\t\t\t\t\tverbose(env, \",umax_value=%llu\",\n\t\t\t\t\t\t(unsigned long long)reg->umax_value);\n\t\t\t\tif (!tnum_is_unknown(reg->var_off)) {\n\t\t\t\t\tchar tn_buf[48];\n\n\t\t\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\t\t\tverbose(env, \",var_off=%s\", tn_buf);\n\t\t\t\t}\n\t\t\t\tif (reg->s32_min_value != reg->smin_value &&\n\t\t\t\t    reg->s32_min_value != S32_MIN)\n\t\t\t\t\tverbose(env, \",s32_min_value=%d\",\n\t\t\t\t\t\t(int)(reg->s32_min_value));\n\t\t\t\tif (reg->s32_max_value != reg->smax_value &&\n\t\t\t\t    reg->s32_max_value != S32_MAX)\n\t\t\t\t\tverbose(env, \",s32_max_value=%d\",\n\t\t\t\t\t\t(int)(reg->s32_max_value));\n\t\t\t\tif (reg->u32_min_value != reg->umin_value &&\n\t\t\t\t    reg->u32_min_value != U32_MIN)\n\t\t\t\t\tverbose(env, \",u32_min_value=%d\",\n\t\t\t\t\t\t(int)(reg->u32_min_value));\n\t\t\t\tif (reg->u32_max_value != reg->umax_value &&\n\t\t\t\t    reg->u32_max_value != U32_MAX)\n\t\t\t\t\tverbose(env, \",u32_max_value=%d\",\n\t\t\t\t\t\t(int)(reg->u32_max_value));\n\t\t\t}\n\t\t\tverbose(env, \")\");\n\t\t}\n\t}\n\tfor (i = 0; i < state->allocated_stack / BPF_REG_SIZE; i++) {\n\t\tchar types_buf[BPF_REG_SIZE + 1];\n\t\tbool valid = false;\n\t\tint j;\n\n\t\tfor (j = 0; j < BPF_REG_SIZE; j++) {\n\t\t\tif (state->stack[i].slot_type[j] != STACK_INVALID)\n\t\t\t\tvalid = true;\n\t\t\ttypes_buf[j] = slot_type_char[\n\t\t\t\t\tstate->stack[i].slot_type[j]];\n\t\t}\n\t\ttypes_buf[BPF_REG_SIZE] = 0;\n\t\tif (!valid)\n\t\t\tcontinue;\n\t\tif (!print_all && !stack_slot_scratched(env, i))\n\t\t\tcontinue;\n\t\tverbose(env, \" fp%d\", (-i - 1) * BPF_REG_SIZE);\n\t\tprint_liveness(env, state->stack[i].spilled_ptr.live);\n\t\tif (is_spilled_reg(&state->stack[i])) {\n\t\t\treg = &state->stack[i].spilled_ptr;\n\t\t\tt = reg->type;\n\t\t\tverbose(env, \"=%s\", reg_type_str[t]);\n\t\t\tif (t == SCALAR_VALUE && reg->precise)\n\t\t\t\tverbose(env, \"P\");\n\t\t\tif (t == SCALAR_VALUE && tnum_is_const(reg->var_off))\n\t\t\t\tverbose(env, \"%lld\", reg->var_off.value + reg->off);\n\t\t} else {\n\t\t\tverbose(env, \"=%s\", types_buf);\n\t\t}\n\t}\n\tif (state->acquired_refs && state->refs[0].id) {\n\t\tverbose(env, \" refs=%d\", state->refs[0].id);\n\t\tfor (i = 1; i < state->acquired_refs; i++)\n\t\t\tif (state->refs[i].id)\n\t\t\t\tverbose(env, \",%d\", state->refs[i].id);\n\t}\n\tif (state->in_callback_fn)\n\t\tverbose(env, \" cb\");\n\tif (state->in_async_callback_fn)\n\t\tverbose(env, \" async_cb\");\n\tverbose(env, \"\\n\");\n\tmark_verifier_state_clean(env);\n}",
        "code_after_change": "static void print_verifier_state(struct bpf_verifier_env *env,\n\t\t\t\t const struct bpf_func_state *state,\n\t\t\t\t bool print_all)\n{\n\tconst struct bpf_reg_state *reg;\n\tenum bpf_reg_type t;\n\tint i;\n\n\tif (state->frameno)\n\t\tverbose(env, \" frame%d:\", state->frameno);\n\tfor (i = 0; i < MAX_BPF_REG; i++) {\n\t\treg = &state->regs[i];\n\t\tt = reg->type;\n\t\tif (t == NOT_INIT)\n\t\t\tcontinue;\n\t\tif (!print_all && !reg_scratched(env, i))\n\t\t\tcontinue;\n\t\tverbose(env, \" R%d\", i);\n\t\tprint_liveness(env, reg->live);\n\t\tverbose(env, \"=%s\", reg_type_str(env, t));\n\t\tif (t == SCALAR_VALUE && reg->precise)\n\t\t\tverbose(env, \"P\");\n\t\tif ((t == SCALAR_VALUE || t == PTR_TO_STACK) &&\n\t\t    tnum_is_const(reg->var_off)) {\n\t\t\t/* reg->off should be 0 for SCALAR_VALUE */\n\t\t\tverbose(env, \"%lld\", reg->var_off.value + reg->off);\n\t\t} else {\n\t\t\tif (base_type(t) == PTR_TO_BTF_ID ||\n\t\t\t    base_type(t) == PTR_TO_PERCPU_BTF_ID)\n\t\t\t\tverbose(env, \"%s\", kernel_type_name(reg->btf, reg->btf_id));\n\t\t\tverbose(env, \"(id=%d\", reg->id);\n\t\t\tif (reg_type_may_be_refcounted_or_null(t))\n\t\t\t\tverbose(env, \",ref_obj_id=%d\", reg->ref_obj_id);\n\t\t\tif (t != SCALAR_VALUE)\n\t\t\t\tverbose(env, \",off=%d\", reg->off);\n\t\t\tif (type_is_pkt_pointer(t))\n\t\t\t\tverbose(env, \",r=%d\", reg->range);\n\t\t\telse if (base_type(t) == CONST_PTR_TO_MAP ||\n\t\t\t\t base_type(t) == PTR_TO_MAP_KEY ||\n\t\t\t\t base_type(t) == PTR_TO_MAP_VALUE)\n\t\t\t\tverbose(env, \",ks=%d,vs=%d\",\n\t\t\t\t\treg->map_ptr->key_size,\n\t\t\t\t\treg->map_ptr->value_size);\n\t\t\tif (tnum_is_const(reg->var_off)) {\n\t\t\t\t/* Typically an immediate SCALAR_VALUE, but\n\t\t\t\t * could be a pointer whose offset is too big\n\t\t\t\t * for reg->off\n\t\t\t\t */\n\t\t\t\tverbose(env, \",imm=%llx\", reg->var_off.value);\n\t\t\t} else {\n\t\t\t\tif (reg->smin_value != reg->umin_value &&\n\t\t\t\t    reg->smin_value != S64_MIN)\n\t\t\t\t\tverbose(env, \",smin_value=%lld\",\n\t\t\t\t\t\t(long long)reg->smin_value);\n\t\t\t\tif (reg->smax_value != reg->umax_value &&\n\t\t\t\t    reg->smax_value != S64_MAX)\n\t\t\t\t\tverbose(env, \",smax_value=%lld\",\n\t\t\t\t\t\t(long long)reg->smax_value);\n\t\t\t\tif (reg->umin_value != 0)\n\t\t\t\t\tverbose(env, \",umin_value=%llu\",\n\t\t\t\t\t\t(unsigned long long)reg->umin_value);\n\t\t\t\tif (reg->umax_value != U64_MAX)\n\t\t\t\t\tverbose(env, \",umax_value=%llu\",\n\t\t\t\t\t\t(unsigned long long)reg->umax_value);\n\t\t\t\tif (!tnum_is_unknown(reg->var_off)) {\n\t\t\t\t\tchar tn_buf[48];\n\n\t\t\t\t\ttnum_strn(tn_buf, sizeof(tn_buf), reg->var_off);\n\t\t\t\t\tverbose(env, \",var_off=%s\", tn_buf);\n\t\t\t\t}\n\t\t\t\tif (reg->s32_min_value != reg->smin_value &&\n\t\t\t\t    reg->s32_min_value != S32_MIN)\n\t\t\t\t\tverbose(env, \",s32_min_value=%d\",\n\t\t\t\t\t\t(int)(reg->s32_min_value));\n\t\t\t\tif (reg->s32_max_value != reg->smax_value &&\n\t\t\t\t    reg->s32_max_value != S32_MAX)\n\t\t\t\t\tverbose(env, \",s32_max_value=%d\",\n\t\t\t\t\t\t(int)(reg->s32_max_value));\n\t\t\t\tif (reg->u32_min_value != reg->umin_value &&\n\t\t\t\t    reg->u32_min_value != U32_MIN)\n\t\t\t\t\tverbose(env, \",u32_min_value=%d\",\n\t\t\t\t\t\t(int)(reg->u32_min_value));\n\t\t\t\tif (reg->u32_max_value != reg->umax_value &&\n\t\t\t\t    reg->u32_max_value != U32_MAX)\n\t\t\t\t\tverbose(env, \",u32_max_value=%d\",\n\t\t\t\t\t\t(int)(reg->u32_max_value));\n\t\t\t}\n\t\t\tverbose(env, \")\");\n\t\t}\n\t}\n\tfor (i = 0; i < state->allocated_stack / BPF_REG_SIZE; i++) {\n\t\tchar types_buf[BPF_REG_SIZE + 1];\n\t\tbool valid = false;\n\t\tint j;\n\n\t\tfor (j = 0; j < BPF_REG_SIZE; j++) {\n\t\t\tif (state->stack[i].slot_type[j] != STACK_INVALID)\n\t\t\t\tvalid = true;\n\t\t\ttypes_buf[j] = slot_type_char[\n\t\t\t\t\tstate->stack[i].slot_type[j]];\n\t\t}\n\t\ttypes_buf[BPF_REG_SIZE] = 0;\n\t\tif (!valid)\n\t\t\tcontinue;\n\t\tif (!print_all && !stack_slot_scratched(env, i))\n\t\t\tcontinue;\n\t\tverbose(env, \" fp%d\", (-i - 1) * BPF_REG_SIZE);\n\t\tprint_liveness(env, state->stack[i].spilled_ptr.live);\n\t\tif (is_spilled_reg(&state->stack[i])) {\n\t\t\treg = &state->stack[i].spilled_ptr;\n\t\t\tt = reg->type;\n\t\t\tverbose(env, \"=%s\", reg_type_str(env, t));\n\t\t\tif (t == SCALAR_VALUE && reg->precise)\n\t\t\t\tverbose(env, \"P\");\n\t\t\tif (t == SCALAR_VALUE && tnum_is_const(reg->var_off))\n\t\t\t\tverbose(env, \"%lld\", reg->var_off.value + reg->off);\n\t\t} else {\n\t\t\tverbose(env, \"=%s\", types_buf);\n\t\t}\n\t}\n\tif (state->acquired_refs && state->refs[0].id) {\n\t\tverbose(env, \" refs=%d\", state->refs[0].id);\n\t\tfor (i = 1; i < state->acquired_refs; i++)\n\t\t\tif (state->refs[i].id)\n\t\t\t\tverbose(env, \",%d\", state->refs[i].id);\n\t}\n\tif (state->in_callback_fn)\n\t\tverbose(env, \" cb\");\n\tif (state->in_async_callback_fn)\n\t\tverbose(env, \" async_cb\");\n\tverbose(env, \"\\n\");\n\tmark_verifier_state_clean(env);\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,7 +17,7 @@\n \t\t\tcontinue;\n \t\tverbose(env, \" R%d\", i);\n \t\tprint_liveness(env, reg->live);\n-\t\tverbose(env, \"=%s\", reg_type_str[t]);\n+\t\tverbose(env, \"=%s\", reg_type_str(env, t));\n \t\tif (t == SCALAR_VALUE && reg->precise)\n \t\t\tverbose(env, \"P\");\n \t\tif ((t == SCALAR_VALUE || t == PTR_TO_STACK) &&\n@@ -25,9 +25,8 @@\n \t\t\t/* reg->off should be 0 for SCALAR_VALUE */\n \t\t\tverbose(env, \"%lld\", reg->var_off.value + reg->off);\n \t\t} else {\n-\t\t\tif (t == PTR_TO_BTF_ID ||\n-\t\t\t    t == PTR_TO_BTF_ID_OR_NULL ||\n-\t\t\t    t == PTR_TO_PERCPU_BTF_ID)\n+\t\t\tif (base_type(t) == PTR_TO_BTF_ID ||\n+\t\t\t    base_type(t) == PTR_TO_PERCPU_BTF_ID)\n \t\t\t\tverbose(env, \"%s\", kernel_type_name(reg->btf, reg->btf_id));\n \t\t\tverbose(env, \"(id=%d\", reg->id);\n \t\t\tif (reg_type_may_be_refcounted_or_null(t))\n@@ -36,10 +35,9 @@\n \t\t\t\tverbose(env, \",off=%d\", reg->off);\n \t\t\tif (type_is_pkt_pointer(t))\n \t\t\t\tverbose(env, \",r=%d\", reg->range);\n-\t\t\telse if (t == CONST_PTR_TO_MAP ||\n-\t\t\t\t t == PTR_TO_MAP_KEY ||\n-\t\t\t\t t == PTR_TO_MAP_VALUE ||\n-\t\t\t\t t == PTR_TO_MAP_VALUE_OR_NULL)\n+\t\t\telse if (base_type(t) == CONST_PTR_TO_MAP ||\n+\t\t\t\t base_type(t) == PTR_TO_MAP_KEY ||\n+\t\t\t\t base_type(t) == PTR_TO_MAP_VALUE)\n \t\t\t\tverbose(env, \",ks=%d,vs=%d\",\n \t\t\t\t\treg->map_ptr->key_size,\n \t\t\t\t\treg->map_ptr->value_size);\n@@ -111,7 +109,7 @@\n \t\tif (is_spilled_reg(&state->stack[i])) {\n \t\t\treg = &state->stack[i].spilled_ptr;\n \t\t\tt = reg->type;\n-\t\t\tverbose(env, \"=%s\", reg_type_str[t]);\n+\t\t\tverbose(env, \"=%s\", reg_type_str(env, t));\n \t\t\tif (t == SCALAR_VALUE && reg->precise)\n \t\t\t\tverbose(env, \"P\");\n \t\t\tif (t == SCALAR_VALUE && tnum_is_const(reg->var_off))",
        "function_modified_lines": {
            "added": [
                "\t\tverbose(env, \"=%s\", reg_type_str(env, t));",
                "\t\t\tif (base_type(t) == PTR_TO_BTF_ID ||",
                "\t\t\t    base_type(t) == PTR_TO_PERCPU_BTF_ID)",
                "\t\t\telse if (base_type(t) == CONST_PTR_TO_MAP ||",
                "\t\t\t\t base_type(t) == PTR_TO_MAP_KEY ||",
                "\t\t\t\t base_type(t) == PTR_TO_MAP_VALUE)",
                "\t\t\tverbose(env, \"=%s\", reg_type_str(env, t));"
            ],
            "deleted": [
                "\t\tverbose(env, \"=%s\", reg_type_str[t]);",
                "\t\t\tif (t == PTR_TO_BTF_ID ||",
                "\t\t\t    t == PTR_TO_BTF_ID_OR_NULL ||",
                "\t\t\t    t == PTR_TO_PERCPU_BTF_ID)",
                "\t\t\telse if (t == CONST_PTR_TO_MAP ||",
                "\t\t\t\t t == PTR_TO_MAP_KEY ||",
                "\t\t\t\t t == PTR_TO_MAP_VALUE ||",
                "\t\t\t\t t == PTR_TO_MAP_VALUE_OR_NULL)",
                "\t\t\tverbose(env, \"=%s\", reg_type_str[t]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3455
    },
    {
        "cve_id": "CVE-2018-5333",
        "code_before_change": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}",
        "code_after_change": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -87,6 +87,7 @@\n err:\n \tif (page)\n \t\tput_page(page);\n+\trm->atomic.op_active = 0;\n \tkfree(rm->atomic.op_notifier);\n \n \treturn ret;",
        "function_modified_lines": {
            "added": [
                "\trm->atomic.op_active = 0;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel through 4.14.13, the rds_cmsg_atomic function in net/rds/rdma.c mishandles cases where page pinning fails or an invalid address is supplied, leading to an rds_atomic_free_op NULL pointer dereference.",
        "id": 1820
    },
    {
        "cve_id": "CVE-2017-16647",
        "code_before_change": "static int asix_resume(struct usb_interface *intf)\n{\n\tstruct usbnet *dev = usb_get_intfdata(intf);\n\tstruct asix_common_private *priv = dev->driver_priv;\n\n\tif (priv->resume)\n\t\tpriv->resume(dev);\n\n\treturn usbnet_resume(intf);\n}",
        "code_after_change": "static int asix_resume(struct usb_interface *intf)\n{\n\tstruct usbnet *dev = usb_get_intfdata(intf);\n\tstruct asix_common_private *priv = dev->driver_priv;\n\n\tif (priv && priv->resume)\n\t\tpriv->resume(dev);\n\n\treturn usbnet_resume(intf);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct usbnet *dev = usb_get_intfdata(intf);\n \tstruct asix_common_private *priv = dev->driver_priv;\n \n-\tif (priv->resume)\n+\tif (priv && priv->resume)\n \t\tpriv->resume(dev);\n \n \treturn usbnet_resume(intf);",
        "function_modified_lines": {
            "added": [
                "\tif (priv && priv->resume)"
            ],
            "deleted": [
                "\tif (priv->resume)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/usb/asix_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1341
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static bool regsafe(struct bpf_verifier_env *env, struct bpf_reg_state *rold,\n\t\t    struct bpf_reg_state *rcur, struct bpf_id_pair *idmap)\n{\n\tbool equal;\n\n\tif (!(rold->live & REG_LIVE_READ))\n\t\t/* explored state didn't use this */\n\t\treturn true;\n\n\tequal = memcmp(rold, rcur, offsetof(struct bpf_reg_state, parent)) == 0;\n\n\tif (rold->type == PTR_TO_STACK)\n\t\t/* two stack pointers are equal only if they're pointing to\n\t\t * the same stack frame, since fp-8 in foo != fp-8 in bar\n\t\t */\n\t\treturn equal && rold->frameno == rcur->frameno;\n\n\tif (equal)\n\t\treturn true;\n\n\tif (rold->type == NOT_INIT)\n\t\t/* explored state can't have used this */\n\t\treturn true;\n\tif (rcur->type == NOT_INIT)\n\t\treturn false;\n\tswitch (rold->type) {\n\tcase SCALAR_VALUE:\n\t\tif (env->explore_alu_limits)\n\t\t\treturn false;\n\t\tif (rcur->type == SCALAR_VALUE) {\n\t\t\tif (!rold->precise && !rcur->precise)\n\t\t\t\treturn true;\n\t\t\t/* new val must satisfy old val knowledge */\n\t\t\treturn range_within(rold, rcur) &&\n\t\t\t       tnum_in(rold->var_off, rcur->var_off);\n\t\t} else {\n\t\t\t/* We're trying to use a pointer in place of a scalar.\n\t\t\t * Even if the scalar was unbounded, this could lead to\n\t\t\t * pointer leaks because scalars are allowed to leak\n\t\t\t * while pointers are not. We could make this safe in\n\t\t\t * special cases if root is calling us, but it's\n\t\t\t * probably not worth the hassle.\n\t\t\t */\n\t\t\treturn false;\n\t\t}\n\tcase PTR_TO_MAP_KEY:\n\tcase PTR_TO_MAP_VALUE:\n\t\t/* If the new min/max/var_off satisfy the old ones and\n\t\t * everything else matches, we are OK.\n\t\t * 'id' is not compared, since it's only used for maps with\n\t\t * bpf_spin_lock inside map element and in such cases if\n\t\t * the rest of the prog is valid for one map element then\n\t\t * it's valid for all map elements regardless of the key\n\t\t * used in bpf_map_lookup()\n\t\t */\n\t\treturn memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)) == 0 &&\n\t\t       range_within(rold, rcur) &&\n\t\t       tnum_in(rold->var_off, rcur->var_off);\n\tcase PTR_TO_MAP_VALUE_OR_NULL:\n\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a\n\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.\n\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-\n\t\t * checked, doing so could have affected others with the same\n\t\t * id, and we can't check for that because we lost the id when\n\t\t * we converted to a PTR_TO_MAP_VALUE.\n\t\t */\n\t\tif (rcur->type != PTR_TO_MAP_VALUE_OR_NULL)\n\t\t\treturn false;\n\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))\n\t\t\treturn false;\n\t\t/* Check our ids match any regs they're supposed to */\n\t\treturn check_ids(rold->id, rcur->id, idmap);\n\tcase PTR_TO_PACKET_META:\n\tcase PTR_TO_PACKET:\n\t\tif (rcur->type != rold->type)\n\t\t\treturn false;\n\t\t/* We must have at least as much range as the old ptr\n\t\t * did, so that any accesses which were safe before are\n\t\t * still safe.  This is true even if old range < old off,\n\t\t * since someone could have accessed through (ptr - k), or\n\t\t * even done ptr -= k in a register, to get a safe access.\n\t\t */\n\t\tif (rold->range > rcur->range)\n\t\t\treturn false;\n\t\t/* If the offsets don't match, we can't trust our alignment;\n\t\t * nor can we be sure that we won't fall out of range.\n\t\t */\n\t\tif (rold->off != rcur->off)\n\t\t\treturn false;\n\t\t/* id relations must be preserved */\n\t\tif (rold->id && !check_ids(rold->id, rcur->id, idmap))\n\t\t\treturn false;\n\t\t/* new val must satisfy old val knowledge */\n\t\treturn range_within(rold, rcur) &&\n\t\t       tnum_in(rold->var_off, rcur->var_off);\n\tcase PTR_TO_CTX:\n\tcase CONST_PTR_TO_MAP:\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_FLOW_KEYS:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\t\t/* Only valid matches are exact, which memcmp() above\n\t\t * would have accepted\n\t\t */\n\tdefault:\n\t\t/* Don't know what's going on, just say it's not safe */\n\t\treturn false;\n\t}\n\n\t/* Shouldn't get here; if we do, say it's not safe */\n\tWARN_ON_ONCE(1);\n\treturn false;\n}",
        "code_after_change": "static bool regsafe(struct bpf_verifier_env *env, struct bpf_reg_state *rold,\n\t\t    struct bpf_reg_state *rcur, struct bpf_id_pair *idmap)\n{\n\tbool equal;\n\n\tif (!(rold->live & REG_LIVE_READ))\n\t\t/* explored state didn't use this */\n\t\treturn true;\n\n\tequal = memcmp(rold, rcur, offsetof(struct bpf_reg_state, parent)) == 0;\n\n\tif (rold->type == PTR_TO_STACK)\n\t\t/* two stack pointers are equal only if they're pointing to\n\t\t * the same stack frame, since fp-8 in foo != fp-8 in bar\n\t\t */\n\t\treturn equal && rold->frameno == rcur->frameno;\n\n\tif (equal)\n\t\treturn true;\n\n\tif (rold->type == NOT_INIT)\n\t\t/* explored state can't have used this */\n\t\treturn true;\n\tif (rcur->type == NOT_INIT)\n\t\treturn false;\n\tswitch (base_type(rold->type)) {\n\tcase SCALAR_VALUE:\n\t\tif (env->explore_alu_limits)\n\t\t\treturn false;\n\t\tif (rcur->type == SCALAR_VALUE) {\n\t\t\tif (!rold->precise && !rcur->precise)\n\t\t\t\treturn true;\n\t\t\t/* new val must satisfy old val knowledge */\n\t\t\treturn range_within(rold, rcur) &&\n\t\t\t       tnum_in(rold->var_off, rcur->var_off);\n\t\t} else {\n\t\t\t/* We're trying to use a pointer in place of a scalar.\n\t\t\t * Even if the scalar was unbounded, this could lead to\n\t\t\t * pointer leaks because scalars are allowed to leak\n\t\t\t * while pointers are not. We could make this safe in\n\t\t\t * special cases if root is calling us, but it's\n\t\t\t * probably not worth the hassle.\n\t\t\t */\n\t\t\treturn false;\n\t\t}\n\tcase PTR_TO_MAP_KEY:\n\tcase PTR_TO_MAP_VALUE:\n\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a\n\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.\n\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-\n\t\t * checked, doing so could have affected others with the same\n\t\t * id, and we can't check for that because we lost the id when\n\t\t * we converted to a PTR_TO_MAP_VALUE.\n\t\t */\n\t\tif (type_may_be_null(rold->type)) {\n\t\t\tif (!type_may_be_null(rcur->type))\n\t\t\t\treturn false;\n\t\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))\n\t\t\t\treturn false;\n\t\t\t/* Check our ids match any regs they're supposed to */\n\t\t\treturn check_ids(rold->id, rcur->id, idmap);\n\t\t}\n\n\t\t/* If the new min/max/var_off satisfy the old ones and\n\t\t * everything else matches, we are OK.\n\t\t * 'id' is not compared, since it's only used for maps with\n\t\t * bpf_spin_lock inside map element and in such cases if\n\t\t * the rest of the prog is valid for one map element then\n\t\t * it's valid for all map elements regardless of the key\n\t\t * used in bpf_map_lookup()\n\t\t */\n\t\treturn memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)) == 0 &&\n\t\t       range_within(rold, rcur) &&\n\t\t       tnum_in(rold->var_off, rcur->var_off);\n\tcase PTR_TO_PACKET_META:\n\tcase PTR_TO_PACKET:\n\t\tif (rcur->type != rold->type)\n\t\t\treturn false;\n\t\t/* We must have at least as much range as the old ptr\n\t\t * did, so that any accesses which were safe before are\n\t\t * still safe.  This is true even if old range < old off,\n\t\t * since someone could have accessed through (ptr - k), or\n\t\t * even done ptr -= k in a register, to get a safe access.\n\t\t */\n\t\tif (rold->range > rcur->range)\n\t\t\treturn false;\n\t\t/* If the offsets don't match, we can't trust our alignment;\n\t\t * nor can we be sure that we won't fall out of range.\n\t\t */\n\t\tif (rold->off != rcur->off)\n\t\t\treturn false;\n\t\t/* id relations must be preserved */\n\t\tif (rold->id && !check_ids(rold->id, rcur->id, idmap))\n\t\t\treturn false;\n\t\t/* new val must satisfy old val knowledge */\n\t\treturn range_within(rold, rcur) &&\n\t\t       tnum_in(rold->var_off, rcur->var_off);\n\tcase PTR_TO_CTX:\n\tcase CONST_PTR_TO_MAP:\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_FLOW_KEYS:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_XDP_SOCK:\n\t\t/* Only valid matches are exact, which memcmp() above\n\t\t * would have accepted\n\t\t */\n\tdefault:\n\t\t/* Don't know what's going on, just say it's not safe */\n\t\treturn false;\n\t}\n\n\t/* Shouldn't get here; if we do, say it's not safe */\n\tWARN_ON_ONCE(1);\n\treturn false;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,7 +23,7 @@\n \t\treturn true;\n \tif (rcur->type == NOT_INIT)\n \t\treturn false;\n-\tswitch (rold->type) {\n+\tswitch (base_type(rold->type)) {\n \tcase SCALAR_VALUE:\n \t\tif (env->explore_alu_limits)\n \t\t\treturn false;\n@@ -45,6 +45,22 @@\n \t\t}\n \tcase PTR_TO_MAP_KEY:\n \tcase PTR_TO_MAP_VALUE:\n+\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a\n+\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.\n+\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-\n+\t\t * checked, doing so could have affected others with the same\n+\t\t * id, and we can't check for that because we lost the id when\n+\t\t * we converted to a PTR_TO_MAP_VALUE.\n+\t\t */\n+\t\tif (type_may_be_null(rold->type)) {\n+\t\t\tif (!type_may_be_null(rcur->type))\n+\t\t\t\treturn false;\n+\t\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))\n+\t\t\t\treturn false;\n+\t\t\t/* Check our ids match any regs they're supposed to */\n+\t\t\treturn check_ids(rold->id, rcur->id, idmap);\n+\t\t}\n+\n \t\t/* If the new min/max/var_off satisfy the old ones and\n \t\t * everything else matches, we are OK.\n \t\t * 'id' is not compared, since it's only used for maps with\n@@ -56,20 +72,6 @@\n \t\treturn memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)) == 0 &&\n \t\t       range_within(rold, rcur) &&\n \t\t       tnum_in(rold->var_off, rcur->var_off);\n-\tcase PTR_TO_MAP_VALUE_OR_NULL:\n-\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a\n-\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.\n-\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-\n-\t\t * checked, doing so could have affected others with the same\n-\t\t * id, and we can't check for that because we lost the id when\n-\t\t * we converted to a PTR_TO_MAP_VALUE.\n-\t\t */\n-\t\tif (rcur->type != PTR_TO_MAP_VALUE_OR_NULL)\n-\t\t\treturn false;\n-\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))\n-\t\t\treturn false;\n-\t\t/* Check our ids match any regs they're supposed to */\n-\t\treturn check_ids(rold->id, rcur->id, idmap);\n \tcase PTR_TO_PACKET_META:\n \tcase PTR_TO_PACKET:\n \t\tif (rcur->type != rold->type)\n@@ -98,11 +100,8 @@\n \tcase PTR_TO_PACKET_END:\n \tcase PTR_TO_FLOW_KEYS:\n \tcase PTR_TO_SOCKET:\n-\tcase PTR_TO_SOCKET_OR_NULL:\n \tcase PTR_TO_SOCK_COMMON:\n-\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n \tcase PTR_TO_TCP_SOCK:\n-\tcase PTR_TO_TCP_SOCK_OR_NULL:\n \tcase PTR_TO_XDP_SOCK:\n \t\t/* Only valid matches are exact, which memcmp() above\n \t\t * would have accepted",
        "function_modified_lines": {
            "added": [
                "\tswitch (base_type(rold->type)) {",
                "\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a",
                "\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.",
                "\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-",
                "\t\t * checked, doing so could have affected others with the same",
                "\t\t * id, and we can't check for that because we lost the id when",
                "\t\t * we converted to a PTR_TO_MAP_VALUE.",
                "\t\t */",
                "\t\tif (type_may_be_null(rold->type)) {",
                "\t\t\tif (!type_may_be_null(rcur->type))",
                "\t\t\t\treturn false;",
                "\t\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))",
                "\t\t\t\treturn false;",
                "\t\t\t/* Check our ids match any regs they're supposed to */",
                "\t\t\treturn check_ids(rold->id, rcur->id, idmap);",
                "\t\t}",
                ""
            ],
            "deleted": [
                "\tswitch (rold->type) {",
                "\tcase PTR_TO_MAP_VALUE_OR_NULL:",
                "\t\t/* a PTR_TO_MAP_VALUE could be safe to use as a",
                "\t\t * PTR_TO_MAP_VALUE_OR_NULL into the same map.",
                "\t\t * However, if the old PTR_TO_MAP_VALUE_OR_NULL then got NULL-",
                "\t\t * checked, doing so could have affected others with the same",
                "\t\t * id, and we can't check for that because we lost the id when",
                "\t\t * we converted to a PTR_TO_MAP_VALUE.",
                "\t\t */",
                "\t\tif (rcur->type != PTR_TO_MAP_VALUE_OR_NULL)",
                "\t\t\treturn false;",
                "\t\tif (memcmp(rold, rcur, offsetof(struct bpf_reg_state, id)))",
                "\t\t\treturn false;",
                "\t\t/* Check our ids match any regs they're supposed to */",
                "\t\treturn check_ids(rold->id, rcur->id, idmap);",
                "\tcase PTR_TO_SOCKET_OR_NULL:",
                "\tcase PTR_TO_SOCK_COMMON_OR_NULL:",
                "\tcase PTR_TO_TCP_SOCK_OR_NULL:"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3451
    },
    {
        "cve_id": "CVE-2017-15116",
        "code_before_change": "static inline int crypto_rng_seedsize(struct crypto_rng *tfm)\n{\n\treturn tfm->seedsize;\n}",
        "code_after_change": "static inline int crypto_rng_seedsize(struct crypto_rng *tfm)\n{\n\treturn crypto_rng_alg(tfm)->seedsize;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n static inline int crypto_rng_seedsize(struct crypto_rng *tfm)\n {\n-\treturn tfm->seedsize;\n+\treturn crypto_rng_alg(tfm)->seedsize;\n }",
        "function_modified_lines": {
            "added": [
                "\treturn crypto_rng_alg(tfm)->seedsize;"
            ],
            "deleted": [
                "\treturn tfm->seedsize;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The rngapi_reset function in crypto/rng.c in the Linux kernel before 4.2 allows attackers to cause a denial of service (NULL pointer dereference).",
        "id": 1293
    },
    {
        "cve_id": "CVE-2019-19815",
        "code_before_change": "static enum count_type __read_io_type(struct page *page)\n{\n\tstruct address_space *mapping = page->mapping;\n\n\tif (mapping) {\n\t\tstruct inode *inode = mapping->host;\n\t\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\t\tif (inode->i_ino == F2FS_META_INO(sbi))\n\t\t\treturn F2FS_RD_META;\n\n\t\tif (inode->i_ino == F2FS_NODE_INO(sbi))\n\t\t\treturn F2FS_RD_NODE;\n\t}\n\treturn F2FS_RD_DATA;\n}",
        "code_after_change": "static enum count_type __read_io_type(struct page *page)\n{\n\tstruct address_space *mapping = page_file_mapping(page);\n\n\tif (mapping) {\n\t\tstruct inode *inode = mapping->host;\n\t\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\n\t\tif (inode->i_ino == F2FS_META_INO(sbi))\n\t\t\treturn F2FS_RD_META;\n\n\t\tif (inode->i_ino == F2FS_NODE_INO(sbi))\n\t\t\treturn F2FS_RD_NODE;\n\t}\n\treturn F2FS_RD_DATA;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static enum count_type __read_io_type(struct page *page)\n {\n-\tstruct address_space *mapping = page->mapping;\n+\tstruct address_space *mapping = page_file_mapping(page);\n \n \tif (mapping) {\n \t\tstruct inode *inode = mapping->host;",
        "function_modified_lines": {
            "added": [
                "\tstruct address_space *mapping = page_file_mapping(page);"
            ],
            "deleted": [
                "\tstruct address_space *mapping = page->mapping;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted f2fs filesystem image can cause a NULL pointer dereference in f2fs_recover_fsync_data in fs/f2fs/recovery.c. This is related to F2FS_P_SB in fs/f2fs/f2fs.h.",
        "id": 2248
    },
    {
        "cve_id": "CVE-2020-27675",
        "code_before_change": "static int set_evtchn_to_irq(evtchn_port_t evtchn, unsigned int irq)\n{\n\tunsigned row;\n\tunsigned col;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\trow = EVTCHN_ROW(evtchn);\n\tcol = EVTCHN_COL(evtchn);\n\n\tif (evtchn_to_irq[row] == NULL) {\n\t\t/* Unallocated irq entries return -1 anyway */\n\t\tif (irq == -1)\n\t\t\treturn 0;\n\n\t\tevtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n\n\tevtchn_to_irq[row][col] = irq;\n\treturn 0;\n}",
        "code_after_change": "static int set_evtchn_to_irq(evtchn_port_t evtchn, unsigned int irq)\n{\n\tunsigned row;\n\tunsigned col;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\trow = EVTCHN_ROW(evtchn);\n\tcol = EVTCHN_COL(evtchn);\n\n\tif (evtchn_to_irq[row] == NULL) {\n\t\t/* Unallocated irq entries return -1 anyway */\n\t\tif (irq == -1)\n\t\t\treturn 0;\n\n\t\tevtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n\n\tWRITE_ONCE(evtchn_to_irq[row][col], irq);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,6 @@\n \t\tclear_evtchn_to_irq_row(row);\n \t}\n \n-\tevtchn_to_irq[row][col] = irq;\n+\tWRITE_ONCE(evtchn_to_irq[row][col], irq);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tWRITE_ONCE(evtchn_to_irq[row][col], irq);"
            ],
            "deleted": [
                "\tevtchn_to_irq[row][col] = irq;"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. drivers/xen/events/events_base.c allows event-channel removal during the event-handling loop (a race condition). This can cause a use-after-free or NULL pointer dereference, as demonstrated by a dom0 crash via events for an in-reconfiguration paravirtualized device, aka CID-073d0552ead5.",
        "id": 2624
    },
    {
        "cve_id": "CVE-2019-20054",
        "code_before_change": "static void drop_sysctl_table(struct ctl_table_header *header)\n{\n\tstruct ctl_dir *parent = header->parent;\n\n\tif (--header->nreg)\n\t\treturn;\n\n\tput_links(header);\n\tstart_unregistering(header);\n\tif (!--header->count)\n\t\tkfree_rcu(header, rcu);\n\n\tif (parent)\n\t\tdrop_sysctl_table(&parent->header);\n}",
        "code_after_change": "static void drop_sysctl_table(struct ctl_table_header *header)\n{\n\tstruct ctl_dir *parent = header->parent;\n\n\tif (--header->nreg)\n\t\treturn;\n\n\tif (parent)\n\t\tput_links(header);\n\tstart_unregistering(header);\n\tif (!--header->count)\n\t\tkfree_rcu(header, rcu);\n\n\tif (parent)\n\t\tdrop_sysctl_table(&parent->header);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,8 @@\n \tif (--header->nreg)\n \t\treturn;\n \n-\tput_links(header);\n+\tif (parent)\n+\t\tput_links(header);\n \tstart_unregistering(header);\n \tif (!--header->count)\n \t\tkfree_rcu(header, rcu);",
        "function_modified_lines": {
            "added": [
                "\tif (parent)",
                "\t\tput_links(header);"
            ],
            "deleted": [
                "\tput_links(header);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.0.6, there is a NULL pointer dereference in drop_sysctl_table() in fs/proc/proc_sysctl.c, related to put_links, aka CID-23da9588037e.",
        "id": 2272
    },
    {
        "cve_id": "CVE-2023-3212",
        "code_before_change": "static void gfs2_evict_inode(struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_holder gh;\n\tint ret;\n\n\tif (inode->i_nlink || sb_rdonly(sb) || !ip->i_no_addr)\n\t\tgoto out;\n\n\tgfs2_holder_mark_uninitialized(&gh);\n\tret = evict_should_delete(inode, &gh);\n\tif (ret == SHOULD_DEFER_EVICTION)\n\t\tgoto out;\n\tif (ret == SHOULD_DELETE_DINODE)\n\t\tret = evict_unlinked_inode(inode);\n\telse\n\t\tret = evict_linked_inode(inode);\n\n\tif (gfs2_rs_active(&ip->i_res))\n\t\tgfs2_rs_deltree(&ip->i_res);\n\n\tif (gfs2_holder_initialized(&gh))\n\t\tgfs2_glock_dq_uninit(&gh);\n\tif (ret && ret != GLR_TRYFAILED && ret != -EROFS)\n\t\tfs_warn(sdp, \"gfs2_evict_inode: %d\\n\", ret);\nout:\n\ttruncate_inode_pages_final(&inode->i_data);\n\tif (ip->i_qadata)\n\t\tgfs2_assert_warn(sdp, ip->i_qadata->qa_ref == 0);\n\tgfs2_rs_deltree(&ip->i_res);\n\tgfs2_ordered_del_inode(ip);\n\tclear_inode(inode);\n\tgfs2_dir_hash_inval(ip);\n\tif (gfs2_holder_initialized(&ip->i_iopen_gh)) {\n\t\tstruct gfs2_glock *gl = ip->i_iopen_gh.gh_gl;\n\n\t\tglock_clear_object(gl, ip);\n\t\tgfs2_glock_hold(gl);\n\t\tip->i_iopen_gh.gh_flags |= GL_NOCACHE;\n\t\tgfs2_glock_dq_uninit(&ip->i_iopen_gh);\n\t\tgfs2_glock_put_eventually(gl);\n\t}\n\tif (ip->i_gl) {\n\t\tglock_clear_object(ip->i_gl, ip);\n\t\twait_on_bit_io(&ip->i_flags, GIF_GLOP_PENDING, TASK_UNINTERRUPTIBLE);\n\t\tgfs2_glock_add_to_lru(ip->i_gl);\n\t\tgfs2_glock_put_eventually(ip->i_gl);\n\t\tip->i_gl = NULL;\n\t}\n}",
        "code_after_change": "static void gfs2_evict_inode(struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct gfs2_sbd *sdp = sb->s_fs_info;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_holder gh;\n\tint ret;\n\n\tif (inode->i_nlink || sb_rdonly(sb) || !ip->i_no_addr)\n\t\tgoto out;\n\n\t/*\n\t * In case of an incomplete mount, gfs2_evict_inode() may be called for\n\t * system files without having an active journal to write to.  In that\n\t * case, skip the filesystem evict.\n\t */\n\tif (!sdp->sd_jdesc)\n\t\tgoto out;\n\n\tgfs2_holder_mark_uninitialized(&gh);\n\tret = evict_should_delete(inode, &gh);\n\tif (ret == SHOULD_DEFER_EVICTION)\n\t\tgoto out;\n\tif (ret == SHOULD_DELETE_DINODE)\n\t\tret = evict_unlinked_inode(inode);\n\telse\n\t\tret = evict_linked_inode(inode);\n\n\tif (gfs2_rs_active(&ip->i_res))\n\t\tgfs2_rs_deltree(&ip->i_res);\n\n\tif (gfs2_holder_initialized(&gh))\n\t\tgfs2_glock_dq_uninit(&gh);\n\tif (ret && ret != GLR_TRYFAILED && ret != -EROFS)\n\t\tfs_warn(sdp, \"gfs2_evict_inode: %d\\n\", ret);\nout:\n\ttruncate_inode_pages_final(&inode->i_data);\n\tif (ip->i_qadata)\n\t\tgfs2_assert_warn(sdp, ip->i_qadata->qa_ref == 0);\n\tgfs2_rs_deltree(&ip->i_res);\n\tgfs2_ordered_del_inode(ip);\n\tclear_inode(inode);\n\tgfs2_dir_hash_inval(ip);\n\tif (gfs2_holder_initialized(&ip->i_iopen_gh)) {\n\t\tstruct gfs2_glock *gl = ip->i_iopen_gh.gh_gl;\n\n\t\tglock_clear_object(gl, ip);\n\t\tgfs2_glock_hold(gl);\n\t\tip->i_iopen_gh.gh_flags |= GL_NOCACHE;\n\t\tgfs2_glock_dq_uninit(&ip->i_iopen_gh);\n\t\tgfs2_glock_put_eventually(gl);\n\t}\n\tif (ip->i_gl) {\n\t\tglock_clear_object(ip->i_gl, ip);\n\t\twait_on_bit_io(&ip->i_flags, GIF_GLOP_PENDING, TASK_UNINTERRUPTIBLE);\n\t\tgfs2_glock_add_to_lru(ip->i_gl);\n\t\tgfs2_glock_put_eventually(ip->i_gl);\n\t\tip->i_gl = NULL;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,14 @@\n \tint ret;\n \n \tif (inode->i_nlink || sb_rdonly(sb) || !ip->i_no_addr)\n+\t\tgoto out;\n+\n+\t/*\n+\t * In case of an incomplete mount, gfs2_evict_inode() may be called for\n+\t * system files without having an active journal to write to.  In that\n+\t * case, skip the filesystem evict.\n+\t */\n+\tif (!sdp->sd_jdesc)\n \t\tgoto out;\n \n \tgfs2_holder_mark_uninitialized(&gh);",
        "function_modified_lines": {
            "added": [
                "\t\tgoto out;",
                "",
                "\t/*",
                "\t * In case of an incomplete mount, gfs2_evict_inode() may be called for",
                "\t * system files without having an active journal to write to.  In that",
                "\t * case, skip the filesystem evict.",
                "\t */",
                "\tif (!sdp->sd_jdesc)"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference issue was found in the gfs2 file system in the Linux kernel. It occurs on corrupt gfs2 file systems when the evict code tries to reference the journal descriptor structure after it has been freed and set to NULL. A privileged local user could use this flaw to cause a kernel panic.",
        "id": 4004
    },
    {
        "cve_id": "CVE-2017-18216",
        "code_before_change": "static ssize_t o2nm_node_num_store(struct config_item *item, const char *page,\n\t\t\t\t   size_t count)\n{\n\tstruct o2nm_node *node = to_o2nm_node(item);\n\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);\n\tunsigned long tmp;\n\tchar *p = (char *)page;\n\tint ret = 0;\n\n\ttmp = simple_strtoul(p, &p, 0);\n\tif (!p || (*p && (*p != '\\n')))\n\t\treturn -EINVAL;\n\n\tif (tmp >= O2NM_MAX_NODES)\n\t\treturn -ERANGE;\n\n\t/* once we're in the cl_nodes tree networking can look us up by\n\t * node number and try to use our address and port attributes\n\t * to connect to this node.. make sure that they've been set\n\t * before writing the node attribute? */\n\tif (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n\t\treturn -EINVAL; /* XXX */\n\n\twrite_lock(&cluster->cl_nodes_lock);\n\tif (cluster->cl_nodes[tmp])\n\t\tret = -EEXIST;\n\telse if (test_and_set_bit(O2NM_NODE_ATTR_NUM,\n\t\t\t&node->nd_set_attributes))\n\t\tret = -EBUSY;\n\telse  {\n\t\tcluster->cl_nodes[tmp] = node;\n\t\tnode->nd_num = tmp;\n\t\tset_bit(tmp, cluster->cl_nodes_bitmap);\n\t}\n\twrite_unlock(&cluster->cl_nodes_lock);\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}",
        "code_after_change": "static ssize_t o2nm_node_num_store(struct config_item *item, const char *page,\n\t\t\t\t   size_t count)\n{\n\tstruct o2nm_node *node = to_o2nm_node(item);\n\tstruct o2nm_cluster *cluster;\n\tunsigned long tmp;\n\tchar *p = (char *)page;\n\tint ret = 0;\n\n\ttmp = simple_strtoul(p, &p, 0);\n\tif (!p || (*p && (*p != '\\n')))\n\t\treturn -EINVAL;\n\n\tif (tmp >= O2NM_MAX_NODES)\n\t\treturn -ERANGE;\n\n\t/* once we're in the cl_nodes tree networking can look us up by\n\t * node number and try to use our address and port attributes\n\t * to connect to this node.. make sure that they've been set\n\t * before writing the node attribute? */\n\tif (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n\t\treturn -EINVAL; /* XXX */\n\n\to2nm_lock_subsystem();\n\tcluster = to_o2nm_cluster_from_node(node);\n\tif (!cluster) {\n\t\to2nm_unlock_subsystem();\n\t\treturn -EINVAL;\n\t}\n\n\twrite_lock(&cluster->cl_nodes_lock);\n\tif (cluster->cl_nodes[tmp])\n\t\tret = -EEXIST;\n\telse if (test_and_set_bit(O2NM_NODE_ATTR_NUM,\n\t\t\t&node->nd_set_attributes))\n\t\tret = -EBUSY;\n\telse  {\n\t\tcluster->cl_nodes[tmp] = node;\n\t\tnode->nd_num = tmp;\n\t\tset_bit(tmp, cluster->cl_nodes_bitmap);\n\t}\n\twrite_unlock(&cluster->cl_nodes_lock);\n\to2nm_unlock_subsystem();\n\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t\t   size_t count)\n {\n \tstruct o2nm_node *node = to_o2nm_node(item);\n-\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);\n+\tstruct o2nm_cluster *cluster;\n \tunsigned long tmp;\n \tchar *p = (char *)page;\n \tint ret = 0;\n@@ -22,6 +22,13 @@\n \t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n \t\treturn -EINVAL; /* XXX */\n \n+\to2nm_lock_subsystem();\n+\tcluster = to_o2nm_cluster_from_node(node);\n+\tif (!cluster) {\n+\t\to2nm_unlock_subsystem();\n+\t\treturn -EINVAL;\n+\t}\n+\n \twrite_lock(&cluster->cl_nodes_lock);\n \tif (cluster->cl_nodes[tmp])\n \t\tret = -EEXIST;\n@@ -34,6 +41,8 @@\n \t\tset_bit(tmp, cluster->cl_nodes_bitmap);\n \t}\n \twrite_unlock(&cluster->cl_nodes_lock);\n+\to2nm_unlock_subsystem();\n+\n \tif (ret)\n \t\treturn ret;\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct o2nm_cluster *cluster;",
                "\to2nm_lock_subsystem();",
                "\tcluster = to_o2nm_cluster_from_node(node);",
                "\tif (!cluster) {",
                "\t\to2nm_unlock_subsystem();",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\to2nm_unlock_subsystem();",
                ""
            ],
            "deleted": [
                "\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In fs/ocfs2/cluster/nodemanager.c in the Linux kernel before 4.15, local users can cause a denial of service (NULL pointer dereference and BUG) because a required mutex is not used.",
        "id": 1401
    },
    {
        "cve_id": "CVE-2017-7374",
        "code_before_change": "static int fscrypt_d_revalidate(struct dentry *dentry, unsigned int flags)\n{\n\tstruct dentry *dir;\n\tstruct fscrypt_info *ci;\n\tint dir_has_key, cached_with_key;\n\n\tif (flags & LOOKUP_RCU)\n\t\treturn -ECHILD;\n\n\tdir = dget_parent(dentry);\n\tif (!d_inode(dir)->i_sb->s_cop->is_encrypted(d_inode(dir))) {\n\t\tdput(dir);\n\t\treturn 0;\n\t}\n\n\tci = d_inode(dir)->i_crypt_info;\n\tif (ci && ci->ci_keyring_key &&\n\t    (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |\n\t\t\t\t\t  (1 << KEY_FLAG_REVOKED) |\n\t\t\t\t\t  (1 << KEY_FLAG_DEAD))))\n\t\tci = NULL;\n\n\t/* this should eventually be an flag in d_flags */\n\tspin_lock(&dentry->d_lock);\n\tcached_with_key = dentry->d_flags & DCACHE_ENCRYPTED_WITH_KEY;\n\tspin_unlock(&dentry->d_lock);\n\tdir_has_key = (ci != NULL);\n\tdput(dir);\n\n\t/*\n\t * If the dentry was cached without the key, and it is a\n\t * negative dentry, it might be a valid name.  We can't check\n\t * if the key has since been made available due to locking\n\t * reasons, so we fail the validation so ext4_lookup() can do\n\t * this check.\n\t *\n\t * We also fail the validation if the dentry was created with\n\t * the key present, but we no longer have the key, or vice versa.\n\t */\n\tif ((!cached_with_key && d_is_negative(dentry)) ||\n\t\t\t(!cached_with_key && dir_has_key) ||\n\t\t\t(cached_with_key && !dir_has_key))\n\t\treturn 0;\n\treturn 1;\n}",
        "code_after_change": "static int fscrypt_d_revalidate(struct dentry *dentry, unsigned int flags)\n{\n\tstruct dentry *dir;\n\tint dir_has_key, cached_with_key;\n\n\tif (flags & LOOKUP_RCU)\n\t\treturn -ECHILD;\n\n\tdir = dget_parent(dentry);\n\tif (!d_inode(dir)->i_sb->s_cop->is_encrypted(d_inode(dir))) {\n\t\tdput(dir);\n\t\treturn 0;\n\t}\n\n\t/* this should eventually be an flag in d_flags */\n\tspin_lock(&dentry->d_lock);\n\tcached_with_key = dentry->d_flags & DCACHE_ENCRYPTED_WITH_KEY;\n\tspin_unlock(&dentry->d_lock);\n\tdir_has_key = (d_inode(dir)->i_crypt_info != NULL);\n\tdput(dir);\n\n\t/*\n\t * If the dentry was cached without the key, and it is a\n\t * negative dentry, it might be a valid name.  We can't check\n\t * if the key has since been made available due to locking\n\t * reasons, so we fail the validation so ext4_lookup() can do\n\t * this check.\n\t *\n\t * We also fail the validation if the dentry was created with\n\t * the key present, but we no longer have the key, or vice versa.\n\t */\n\tif ((!cached_with_key && d_is_negative(dentry)) ||\n\t\t\t(!cached_with_key && dir_has_key) ||\n\t\t\t(cached_with_key && !dir_has_key))\n\t\treturn 0;\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,6 @@\n static int fscrypt_d_revalidate(struct dentry *dentry, unsigned int flags)\n {\n \tstruct dentry *dir;\n-\tstruct fscrypt_info *ci;\n \tint dir_has_key, cached_with_key;\n \n \tif (flags & LOOKUP_RCU)\n@@ -13,18 +12,11 @@\n \t\treturn 0;\n \t}\n \n-\tci = d_inode(dir)->i_crypt_info;\n-\tif (ci && ci->ci_keyring_key &&\n-\t    (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |\n-\t\t\t\t\t  (1 << KEY_FLAG_REVOKED) |\n-\t\t\t\t\t  (1 << KEY_FLAG_DEAD))))\n-\t\tci = NULL;\n-\n \t/* this should eventually be an flag in d_flags */\n \tspin_lock(&dentry->d_lock);\n \tcached_with_key = dentry->d_flags & DCACHE_ENCRYPTED_WITH_KEY;\n \tspin_unlock(&dentry->d_lock);\n-\tdir_has_key = (ci != NULL);\n+\tdir_has_key = (d_inode(dir)->i_crypt_info != NULL);\n \tdput(dir);\n \n \t/*",
        "function_modified_lines": {
            "added": [
                "\tdir_has_key = (d_inode(dir)->i_crypt_info != NULL);"
            ],
            "deleted": [
                "\tstruct fscrypt_info *ci;",
                "\tci = d_inode(dir)->i_crypt_info;",
                "\tif (ci && ci->ci_keyring_key &&",
                "\t    (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |",
                "\t\t\t\t\t  (1 << KEY_FLAG_REVOKED) |",
                "\t\t\t\t\t  (1 << KEY_FLAG_DEAD))))",
                "\t\tci = NULL;",
                "",
                "\tdir_has_key = (ci != NULL);"
            ]
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "Use-after-free vulnerability in fs/crypto/ in the Linux kernel before 4.10.7 allows local users to cause a denial of service (NULL pointer dereference) or possibly gain privileges by revoking keyring keys being used for ext4, f2fs, or ubifs encryption, causing cryptographic transform objects to be freed prematurely.",
        "id": 1497
    },
    {
        "cve_id": "CVE-2022-3104",
        "code_before_change": "void lkdtm_ARRAY_BOUNDS(void)\n{\n\tstruct array_bounds_flex_array *not_checked;\n\tstruct array_bounds *checked;\n\tvolatile int i;\n\n\tnot_checked = kmalloc(sizeof(*not_checked) * 2, GFP_KERNEL);\n\tchecked = kmalloc(sizeof(*checked) * 2, GFP_KERNEL);\n\n\tpr_info(\"Array access within bounds ...\\n\");\n\t/* For both, touch all bytes in the actual member size. */\n\tfor (i = 0; i < sizeof(checked->data); i++)\n\t\tchecked->data[i] = 'A';\n\t/*\n\t * For the uninstrumented flex array member, also touch 1 byte\n\t * beyond to verify it is correctly uninstrumented.\n\t */\n\tfor (i = 0; i < sizeof(not_checked->data) + 1; i++)\n\t\tnot_checked->data[i] = 'A';\n\n\tpr_info(\"Array access beyond bounds ...\\n\");\n\tfor (i = 0; i < sizeof(checked->data) + 1; i++)\n\t\tchecked->data[i] = 'B';\n\n\tkfree(not_checked);\n\tkfree(checked);\n\tpr_err(\"FAIL: survived array bounds overflow!\\n\");\n\tpr_expected_config(CONFIG_UBSAN_BOUNDS);\n}",
        "code_after_change": "void lkdtm_ARRAY_BOUNDS(void)\n{\n\tstruct array_bounds_flex_array *not_checked;\n\tstruct array_bounds *checked;\n\tvolatile int i;\n\n\tnot_checked = kmalloc(sizeof(*not_checked) * 2, GFP_KERNEL);\n\tchecked = kmalloc(sizeof(*checked) * 2, GFP_KERNEL);\n\tif (!not_checked || !checked) {\n\t\tkfree(not_checked);\n\t\tkfree(checked);\n\t\treturn;\n\t}\n\n\tpr_info(\"Array access within bounds ...\\n\");\n\t/* For both, touch all bytes in the actual member size. */\n\tfor (i = 0; i < sizeof(checked->data); i++)\n\t\tchecked->data[i] = 'A';\n\t/*\n\t * For the uninstrumented flex array member, also touch 1 byte\n\t * beyond to verify it is correctly uninstrumented.\n\t */\n\tfor (i = 0; i < sizeof(not_checked->data) + 1; i++)\n\t\tnot_checked->data[i] = 'A';\n\n\tpr_info(\"Array access beyond bounds ...\\n\");\n\tfor (i = 0; i < sizeof(checked->data) + 1; i++)\n\t\tchecked->data[i] = 'B';\n\n\tkfree(not_checked);\n\tkfree(checked);\n\tpr_err(\"FAIL: survived array bounds overflow!\\n\");\n\tpr_expected_config(CONFIG_UBSAN_BOUNDS);\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,11 @@\n \n \tnot_checked = kmalloc(sizeof(*not_checked) * 2, GFP_KERNEL);\n \tchecked = kmalloc(sizeof(*checked) * 2, GFP_KERNEL);\n+\tif (!not_checked || !checked) {\n+\t\tkfree(not_checked);\n+\t\tkfree(checked);\n+\t\treturn;\n+\t}\n \n \tpr_info(\"Array access within bounds ...\\n\");\n \t/* For both, touch all bytes in the actual member size. */",
        "function_modified_lines": {
            "added": [
                "\tif (!not_checked || !checked) {",
                "\t\tkfree(not_checked);",
                "\t\tkfree(checked);",
                "\t\treturn;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. lkdtm_ARRAY_BOUNDS in drivers/misc/lkdtm/bugs.c lacks check of the return value of kmalloc() and will cause the null pointer dereference.",
        "id": 3549
    },
    {
        "cve_id": "CVE-2021-3543",
        "code_before_change": "static long ne_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase NE_CREATE_VM: {\n\t\tint enclave_fd = -1;\n\t\tstruct file *enclave_file = NULL;\n\t\tstruct ne_pci_dev *ne_pci_dev = ne_devs.ne_pci_dev;\n\t\tint rc = -EINVAL;\n\t\tu64 slot_uid = 0;\n\n\t\tmutex_lock(&ne_pci_dev->enclaves_list_mutex);\n\n\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, &slot_uid);\n\t\tif (enclave_fd < 0) {\n\t\t\trc = enclave_fd;\n\n\t\t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n\n\t\t\treturn rc;\n\t\t}\n\n\t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n\n\t\tif (copy_to_user((void __user *)arg, &slot_uid, sizeof(slot_uid))) {\n\t\t\tenclave_file = fget(enclave_fd);\n\t\t\t/* Decrement file refs to have release() called. */\n\t\t\tfput(enclave_file);\n\t\t\tfput(enclave_file);\n\t\t\tput_unused_fd(enclave_fd);\n\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\treturn enclave_fd;\n\t}\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static long ne_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase NE_CREATE_VM: {\n\t\tint enclave_fd = -1;\n\t\tstruct ne_pci_dev *ne_pci_dev = ne_devs.ne_pci_dev;\n\t\tu64 __user *slot_uid = (void __user *)arg;\n\n\t\tmutex_lock(&ne_pci_dev->enclaves_list_mutex);\n\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, slot_uid);\n\t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n\n\t\treturn enclave_fd;\n\t}\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,33 +3,12 @@\n \tswitch (cmd) {\n \tcase NE_CREATE_VM: {\n \t\tint enclave_fd = -1;\n-\t\tstruct file *enclave_file = NULL;\n \t\tstruct ne_pci_dev *ne_pci_dev = ne_devs.ne_pci_dev;\n-\t\tint rc = -EINVAL;\n-\t\tu64 slot_uid = 0;\n+\t\tu64 __user *slot_uid = (void __user *)arg;\n \n \t\tmutex_lock(&ne_pci_dev->enclaves_list_mutex);\n-\n-\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, &slot_uid);\n-\t\tif (enclave_fd < 0) {\n-\t\t\trc = enclave_fd;\n-\n-\t\t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n-\n-\t\t\treturn rc;\n-\t\t}\n-\n+\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, slot_uid);\n \t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n-\n-\t\tif (copy_to_user((void __user *)arg, &slot_uid, sizeof(slot_uid))) {\n-\t\t\tenclave_file = fget(enclave_fd);\n-\t\t\t/* Decrement file refs to have release() called. */\n-\t\t\tfput(enclave_file);\n-\t\t\tfput(enclave_file);\n-\t\t\tput_unused_fd(enclave_fd);\n-\n-\t\t\treturn -EFAULT;\n-\t\t}\n \n \t\treturn enclave_fd;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\tu64 __user *slot_uid = (void __user *)arg;",
                "\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, slot_uid);"
            ],
            "deleted": [
                "\t\tstruct file *enclave_file = NULL;",
                "\t\tint rc = -EINVAL;",
                "\t\tu64 slot_uid = 0;",
                "",
                "\t\tenclave_fd = ne_create_vm_ioctl(ne_pci_dev, &slot_uid);",
                "\t\tif (enclave_fd < 0) {",
                "\t\t\trc = enclave_fd;",
                "",
                "\t\t\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);",
                "",
                "\t\t\treturn rc;",
                "\t\t}",
                "",
                "",
                "\t\tif (copy_to_user((void __user *)arg, &slot_uid, sizeof(slot_uid))) {",
                "\t\t\tenclave_file = fget(enclave_fd);",
                "\t\t\t/* Decrement file refs to have release() called. */",
                "\t\t\tfput(enclave_file);",
                "\t\t\tfput(enclave_file);",
                "\t\t\tput_unused_fd(enclave_fd);",
                "",
                "\t\t\treturn -EFAULT;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "A flaw null pointer dereference in the Nitro Enclaves kernel driver was found in the way that Enclaves VMs forces closures on the enclave file descriptor. A local user of a host machine could use this flaw to crash the system or escalate their privileges on the system.",
        "id": 3017
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int mark_reg_read(struct bpf_verifier_env *env,\n\t\t\t const struct bpf_reg_state *state,\n\t\t\t struct bpf_reg_state *parent, u8 flag)\n{\n\tbool writes = parent == state->parent; /* Observe write marks */\n\tint cnt = 0;\n\n\twhile (parent) {\n\t\t/* if read wasn't screened by an earlier write ... */\n\t\tif (writes && state->live & REG_LIVE_WRITTEN)\n\t\t\tbreak;\n\t\tif (parent->live & REG_LIVE_DONE) {\n\t\t\tverbose(env, \"verifier BUG type %s var_off %lld off %d\\n\",\n\t\t\t\treg_type_str[parent->type],\n\t\t\t\tparent->var_off.value, parent->off);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\t/* The first condition is more likely to be true than the\n\t\t * second, checked it first.\n\t\t */\n\t\tif ((parent->live & REG_LIVE_READ) == flag ||\n\t\t    parent->live & REG_LIVE_READ64)\n\t\t\t/* The parentage chain never changes and\n\t\t\t * this parent was already marked as LIVE_READ.\n\t\t\t * There is no need to keep walking the chain again and\n\t\t\t * keep re-marking all parents as LIVE_READ.\n\t\t\t * This case happens when the same register is read\n\t\t\t * multiple times without writes into it in-between.\n\t\t\t * Also, if parent has the stronger REG_LIVE_READ64 set,\n\t\t\t * then no need to set the weak REG_LIVE_READ32.\n\t\t\t */\n\t\t\tbreak;\n\t\t/* ... then we depend on parent's value */\n\t\tparent->live |= flag;\n\t\t/* REG_LIVE_READ64 overrides REG_LIVE_READ32. */\n\t\tif (flag == REG_LIVE_READ64)\n\t\t\tparent->live &= ~REG_LIVE_READ32;\n\t\tstate = parent;\n\t\tparent = state->parent;\n\t\twrites = true;\n\t\tcnt++;\n\t}\n\n\tif (env->longest_mark_read_walk < cnt)\n\t\tenv->longest_mark_read_walk = cnt;\n\treturn 0;\n}",
        "code_after_change": "static int mark_reg_read(struct bpf_verifier_env *env,\n\t\t\t const struct bpf_reg_state *state,\n\t\t\t struct bpf_reg_state *parent, u8 flag)\n{\n\tbool writes = parent == state->parent; /* Observe write marks */\n\tint cnt = 0;\n\n\twhile (parent) {\n\t\t/* if read wasn't screened by an earlier write ... */\n\t\tif (writes && state->live & REG_LIVE_WRITTEN)\n\t\t\tbreak;\n\t\tif (parent->live & REG_LIVE_DONE) {\n\t\t\tverbose(env, \"verifier BUG type %s var_off %lld off %d\\n\",\n\t\t\t\treg_type_str(env, parent->type),\n\t\t\t\tparent->var_off.value, parent->off);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\t/* The first condition is more likely to be true than the\n\t\t * second, checked it first.\n\t\t */\n\t\tif ((parent->live & REG_LIVE_READ) == flag ||\n\t\t    parent->live & REG_LIVE_READ64)\n\t\t\t/* The parentage chain never changes and\n\t\t\t * this parent was already marked as LIVE_READ.\n\t\t\t * There is no need to keep walking the chain again and\n\t\t\t * keep re-marking all parents as LIVE_READ.\n\t\t\t * This case happens when the same register is read\n\t\t\t * multiple times without writes into it in-between.\n\t\t\t * Also, if parent has the stronger REG_LIVE_READ64 set,\n\t\t\t * then no need to set the weak REG_LIVE_READ32.\n\t\t\t */\n\t\t\tbreak;\n\t\t/* ... then we depend on parent's value */\n\t\tparent->live |= flag;\n\t\t/* REG_LIVE_READ64 overrides REG_LIVE_READ32. */\n\t\tif (flag == REG_LIVE_READ64)\n\t\t\tparent->live &= ~REG_LIVE_READ32;\n\t\tstate = parent;\n\t\tparent = state->parent;\n\t\twrites = true;\n\t\tcnt++;\n\t}\n\n\tif (env->longest_mark_read_walk < cnt)\n\t\tenv->longest_mark_read_walk = cnt;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \t\t\tbreak;\n \t\tif (parent->live & REG_LIVE_DONE) {\n \t\t\tverbose(env, \"verifier BUG type %s var_off %lld off %d\\n\",\n-\t\t\t\treg_type_str[parent->type],\n+\t\t\t\treg_type_str(env, parent->type),\n \t\t\t\tparent->var_off.value, parent->off);\n \t\t\treturn -EFAULT;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t\treg_type_str(env, parent->type),"
            ],
            "deleted": [
                "\t\t\t\treg_type_str[parent->type],"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3444
    },
    {
        "cve_id": "CVE-2023-22997",
        "code_before_change": "static ssize_t module_gzip_decompress(struct load_info *info,\n\t\t\t\t      const void *buf, size_t size)\n{\n\tstruct z_stream_s s = { 0 };\n\tsize_t new_size = 0;\n\tsize_t gzip_hdr_len;\n\tssize_t retval;\n\tint rc;\n\n\tgzip_hdr_len = module_gzip_header_len(buf, size);\n\tif (!gzip_hdr_len) {\n\t\tpr_err(\"not a gzip compressed module\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ts.next_in = buf + gzip_hdr_len;\n\ts.avail_in = size - gzip_hdr_len;\n\n\ts.workspace = kmalloc(zlib_inflate_workspacesize(), GFP_KERNEL);\n\tif (!s.workspace)\n\t\treturn -ENOMEM;\n\n\trc = zlib_inflateInit2(&s, -MAX_WBITS);\n\tif (rc != Z_OK) {\n\t\tpr_err(\"failed to initialize decompressor: %d\\n\", rc);\n\t\tretval = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tdo {\n\t\tstruct page *page = module_get_next_page(info);\n\n\t\tif (!page) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto out_inflate_end;\n\t\t}\n\n\t\ts.next_out = kmap_local_page(page);\n\t\ts.avail_out = PAGE_SIZE;\n\t\trc = zlib_inflate(&s, 0);\n\t\tkunmap_local(s.next_out);\n\n\t\tnew_size += PAGE_SIZE - s.avail_out;\n\t} while (rc == Z_OK);\n\n\tif (rc != Z_STREAM_END) {\n\t\tpr_err(\"decompression failed with status %d\\n\", rc);\n\t\tretval = -EINVAL;\n\t\tgoto out_inflate_end;\n\t}\n\n\tretval = new_size;\n\nout_inflate_end:\n\tzlib_inflateEnd(&s);\nout:\n\tkfree(s.workspace);\n\treturn retval;\n}",
        "code_after_change": "static ssize_t module_gzip_decompress(struct load_info *info,\n\t\t\t\t      const void *buf, size_t size)\n{\n\tstruct z_stream_s s = { 0 };\n\tsize_t new_size = 0;\n\tsize_t gzip_hdr_len;\n\tssize_t retval;\n\tint rc;\n\n\tgzip_hdr_len = module_gzip_header_len(buf, size);\n\tif (!gzip_hdr_len) {\n\t\tpr_err(\"not a gzip compressed module\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ts.next_in = buf + gzip_hdr_len;\n\ts.avail_in = size - gzip_hdr_len;\n\n\ts.workspace = kmalloc(zlib_inflate_workspacesize(), GFP_KERNEL);\n\tif (!s.workspace)\n\t\treturn -ENOMEM;\n\n\trc = zlib_inflateInit2(&s, -MAX_WBITS);\n\tif (rc != Z_OK) {\n\t\tpr_err(\"failed to initialize decompressor: %d\\n\", rc);\n\t\tretval = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tdo {\n\t\tstruct page *page = module_get_next_page(info);\n\n\t\tif (IS_ERR(page)) {\n\t\t\tretval = PTR_ERR(page);\n\t\t\tgoto out_inflate_end;\n\t\t}\n\n\t\ts.next_out = kmap_local_page(page);\n\t\ts.avail_out = PAGE_SIZE;\n\t\trc = zlib_inflate(&s, 0);\n\t\tkunmap_local(s.next_out);\n\n\t\tnew_size += PAGE_SIZE - s.avail_out;\n\t} while (rc == Z_OK);\n\n\tif (rc != Z_STREAM_END) {\n\t\tpr_err(\"decompression failed with status %d\\n\", rc);\n\t\tretval = -EINVAL;\n\t\tgoto out_inflate_end;\n\t}\n\n\tretval = new_size;\n\nout_inflate_end:\n\tzlib_inflateEnd(&s);\nout:\n\tkfree(s.workspace);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,8 +30,8 @@\n \tdo {\n \t\tstruct page *page = module_get_next_page(info);\n \n-\t\tif (!page) {\n-\t\t\tretval = -ENOMEM;\n+\t\tif (IS_ERR(page)) {\n+\t\t\tretval = PTR_ERR(page);\n \t\t\tgoto out_inflate_end;\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (IS_ERR(page)) {",
                "\t\t\tretval = PTR_ERR(page);"
            ],
            "deleted": [
                "\t\tif (!page) {",
                "\t\t\tretval = -ENOMEM;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 6.1.2, kernel/module/decompress.c misinterprets the module_get_next_page return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3939
    },
    {
        "cve_id": "CVE-2015-8787",
        "code_before_change": "unsigned int\nnf_nat_redirect_ipv4(struct sk_buff *skb,\n\t\t     const struct nf_nat_ipv4_multi_range_compat *mr,\n\t\t     unsigned int hooknum)\n{\n\tstruct nf_conn *ct;\n\tenum ip_conntrack_info ctinfo;\n\t__be32 newdst;\n\tstruct nf_nat_range newrange;\n\n\tNF_CT_ASSERT(hooknum == NF_INET_PRE_ROUTING ||\n\t\t     hooknum == NF_INET_LOCAL_OUT);\n\n\tct = nf_ct_get(skb, &ctinfo);\n\tNF_CT_ASSERT(ct && (ctinfo == IP_CT_NEW || ctinfo == IP_CT_RELATED));\n\n\t/* Local packets: make them go to loopback */\n\tif (hooknum == NF_INET_LOCAL_OUT) {\n\t\tnewdst = htonl(0x7F000001);\n\t} else {\n\t\tstruct in_device *indev;\n\t\tstruct in_ifaddr *ifa;\n\n\t\tnewdst = 0;\n\n\t\trcu_read_lock();\n\t\tindev = __in_dev_get_rcu(skb->dev);\n\t\tif (indev != NULL) {\n\t\t\tifa = indev->ifa_list;\n\t\t\tnewdst = ifa->ifa_local;\n\t\t}\n\t\trcu_read_unlock();\n\n\t\tif (!newdst)\n\t\t\treturn NF_DROP;\n\t}\n\n\t/* Transfer from original range. */\n\tmemset(&newrange.min_addr, 0, sizeof(newrange.min_addr));\n\tmemset(&newrange.max_addr, 0, sizeof(newrange.max_addr));\n\tnewrange.flags\t     = mr->range[0].flags | NF_NAT_RANGE_MAP_IPS;\n\tnewrange.min_addr.ip = newdst;\n\tnewrange.max_addr.ip = newdst;\n\tnewrange.min_proto   = mr->range[0].min;\n\tnewrange.max_proto   = mr->range[0].max;\n\n\t/* Hand modified range to generic setup. */\n\treturn nf_nat_setup_info(ct, &newrange, NF_NAT_MANIP_DST);\n}",
        "code_after_change": "unsigned int\nnf_nat_redirect_ipv4(struct sk_buff *skb,\n\t\t     const struct nf_nat_ipv4_multi_range_compat *mr,\n\t\t     unsigned int hooknum)\n{\n\tstruct nf_conn *ct;\n\tenum ip_conntrack_info ctinfo;\n\t__be32 newdst;\n\tstruct nf_nat_range newrange;\n\n\tNF_CT_ASSERT(hooknum == NF_INET_PRE_ROUTING ||\n\t\t     hooknum == NF_INET_LOCAL_OUT);\n\n\tct = nf_ct_get(skb, &ctinfo);\n\tNF_CT_ASSERT(ct && (ctinfo == IP_CT_NEW || ctinfo == IP_CT_RELATED));\n\n\t/* Local packets: make them go to loopback */\n\tif (hooknum == NF_INET_LOCAL_OUT) {\n\t\tnewdst = htonl(0x7F000001);\n\t} else {\n\t\tstruct in_device *indev;\n\t\tstruct in_ifaddr *ifa;\n\n\t\tnewdst = 0;\n\n\t\trcu_read_lock();\n\t\tindev = __in_dev_get_rcu(skb->dev);\n\t\tif (indev && indev->ifa_list) {\n\t\t\tifa = indev->ifa_list;\n\t\t\tnewdst = ifa->ifa_local;\n\t\t}\n\t\trcu_read_unlock();\n\n\t\tif (!newdst)\n\t\t\treturn NF_DROP;\n\t}\n\n\t/* Transfer from original range. */\n\tmemset(&newrange.min_addr, 0, sizeof(newrange.min_addr));\n\tmemset(&newrange.max_addr, 0, sizeof(newrange.max_addr));\n\tnewrange.flags\t     = mr->range[0].flags | NF_NAT_RANGE_MAP_IPS;\n\tnewrange.min_addr.ip = newdst;\n\tnewrange.max_addr.ip = newdst;\n\tnewrange.min_proto   = mr->range[0].min;\n\tnewrange.max_proto   = mr->range[0].max;\n\n\t/* Hand modified range to generic setup. */\n\treturn nf_nat_setup_info(ct, &newrange, NF_NAT_MANIP_DST);\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,7 +25,7 @@\n \n \t\trcu_read_lock();\n \t\tindev = __in_dev_get_rcu(skb->dev);\n-\t\tif (indev != NULL) {\n+\t\tif (indev && indev->ifa_list) {\n \t\t\tifa = indev->ifa_list;\n \t\t\tnewdst = ifa->ifa_local;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (indev && indev->ifa_list) {"
            ],
            "deleted": [
                "\t\tif (indev != NULL) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The nf_nat_redirect_ipv4 function in net/netfilter/nf_nat_redirect.c in the Linux kernel before 4.4 allows remote attackers to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact by sending certain IPv4 packets to an incompletely configured interface, a related issue to CVE-2003-1604.",
        "id": 845
    },
    {
        "cve_id": "CVE-2023-23001",
        "code_before_change": "static void ufs_mtk_init_va09_pwr_ctrl(struct ufs_hba *hba)\n{\n\tstruct ufs_mtk_host *host = ufshcd_get_variant(hba);\n\n\thost->reg_va09 = regulator_get(hba->dev, \"va09\");\n\tif (!host->reg_va09)\n\t\tdev_info(hba->dev, \"failed to get va09\");\n\telse\n\t\thost->caps |= UFS_MTK_CAP_VA09_PWR_CTRL;\n}",
        "code_after_change": "static void ufs_mtk_init_va09_pwr_ctrl(struct ufs_hba *hba)\n{\n\tstruct ufs_mtk_host *host = ufshcd_get_variant(hba);\n\n\thost->reg_va09 = regulator_get(hba->dev, \"va09\");\n\tif (IS_ERR(host->reg_va09))\n\t\tdev_info(hba->dev, \"failed to get va09\");\n\telse\n\t\thost->caps |= UFS_MTK_CAP_VA09_PWR_CTRL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct ufs_mtk_host *host = ufshcd_get_variant(hba);\n \n \thost->reg_va09 = regulator_get(hba->dev, \"va09\");\n-\tif (!host->reg_va09)\n+\tif (IS_ERR(host->reg_va09))\n \t\tdev_info(hba->dev, \"failed to get va09\");\n \telse\n \t\thost->caps |= UFS_MTK_CAP_VA09_PWR_CTRL;",
        "function_modified_lines": {
            "added": [
                "\tif (IS_ERR(host->reg_va09))"
            ],
            "deleted": [
                "\tif (!host->reg_va09)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.16.3, drivers/scsi/ufs/ufs-mediatek.c misinterprets the regulator_get return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3944
    },
    {
        "cve_id": "CVE-2018-14616",
        "code_before_change": "static bool __written_first_block(struct f2fs_sb_info *sbi,\n\t\t\t\t\tstruct f2fs_inode *ri)\n{\n\tblock_t addr = le32_to_cpu(ri->i_addr[offset_in_addr(ri)]);\n\n\tif (is_valid_data_blkaddr(sbi, addr))\n\t\treturn true;\n\treturn false;\n}",
        "code_after_change": "static int __written_first_block(struct f2fs_sb_info *sbi,\n\t\t\t\t\tstruct f2fs_inode *ri)\n{\n\tblock_t addr = le32_to_cpu(ri->i_addr[offset_in_addr(ri)]);\n\n\tif (!__is_valid_data_blkaddr(addr))\n\t\treturn 1;\n\tif (!f2fs_is_valid_blkaddr(sbi, addr, DATA_GENERIC))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,11 @@\n-static bool __written_first_block(struct f2fs_sb_info *sbi,\n+static int __written_first_block(struct f2fs_sb_info *sbi,\n \t\t\t\t\tstruct f2fs_inode *ri)\n {\n \tblock_t addr = le32_to_cpu(ri->i_addr[offset_in_addr(ri)]);\n \n-\tif (is_valid_data_blkaddr(sbi, addr))\n-\t\treturn true;\n-\treturn false;\n+\tif (!__is_valid_data_blkaddr(addr))\n+\t\treturn 1;\n+\tif (!f2fs_is_valid_blkaddr(sbi, addr, DATA_GENERIC))\n+\t\treturn -EFAULT;\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "static int __written_first_block(struct f2fs_sb_info *sbi,",
                "\tif (!__is_valid_data_blkaddr(addr))",
                "\t\treturn 1;",
                "\tif (!f2fs_is_valid_blkaddr(sbi, addr, DATA_GENERIC))",
                "\t\treturn -EFAULT;",
                "\treturn 0;"
            ],
            "deleted": [
                "static bool __written_first_block(struct f2fs_sb_info *sbi,",
                "\tif (is_valid_data_blkaddr(sbi, addr))",
                "\t\treturn true;",
                "\treturn false;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference in fscrypt_do_page_crypto() in fs/crypto/crypto.c when operating on a file in a corrupted f2fs image.",
        "id": 1689
    },
    {
        "cve_id": "CVE-2018-19406",
        "code_before_change": "int kvm_pv_send_ipi(struct kvm *kvm, unsigned long ipi_bitmap_low,\n\t\t    unsigned long ipi_bitmap_high, u32 min,\n\t\t    unsigned long icr, int op_64_bit)\n{\n\tint i;\n\tstruct kvm_apic_map *map;\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_lapic_irq irq = {0};\n\tint cluster_size = op_64_bit ? 64 : 32;\n\tint count = 0;\n\n\tirq.vector = icr & APIC_VECTOR_MASK;\n\tirq.delivery_mode = icr & APIC_MODE_MASK;\n\tirq.level = (icr & APIC_INT_ASSERT) != 0;\n\tirq.trig_mode = icr & APIC_INT_LEVELTRIG;\n\n\tif (icr & APIC_DEST_MASK)\n\t\treturn -KVM_EINVAL;\n\tif (icr & APIC_SHORT_MASK)\n\t\treturn -KVM_EINVAL;\n\n\trcu_read_lock();\n\tmap = rcu_dereference(kvm->arch.apic_map);\n\n\tif (min > map->max_apic_id)\n\t\tgoto out;\n\t/* Bits above cluster_size are masked in the caller.  */\n\tfor_each_set_bit(i, &ipi_bitmap_low,\n\t\tmin((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {\n\t\tif (map->phys_map[min + i]) {\n\t\t\tvcpu = map->phys_map[min + i]->vcpu;\n\t\t\tcount += kvm_apic_set_irq(vcpu, &irq, NULL);\n\t\t}\n\t}\n\n\tmin += cluster_size;\n\n\tif (min > map->max_apic_id)\n\t\tgoto out;\n\n\tfor_each_set_bit(i, &ipi_bitmap_high,\n\t\tmin((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {\n\t\tif (map->phys_map[min + i]) {\n\t\t\tvcpu = map->phys_map[min + i]->vcpu;\n\t\t\tcount += kvm_apic_set_irq(vcpu, &irq, NULL);\n\t\t}\n\t}\n\nout:\n\trcu_read_unlock();\n\treturn count;\n}",
        "code_after_change": "int kvm_pv_send_ipi(struct kvm *kvm, unsigned long ipi_bitmap_low,\n\t\t    unsigned long ipi_bitmap_high, u32 min,\n\t\t    unsigned long icr, int op_64_bit)\n{\n\tint i;\n\tstruct kvm_apic_map *map;\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_lapic_irq irq = {0};\n\tint cluster_size = op_64_bit ? 64 : 32;\n\tint count = 0;\n\n\tirq.vector = icr & APIC_VECTOR_MASK;\n\tirq.delivery_mode = icr & APIC_MODE_MASK;\n\tirq.level = (icr & APIC_INT_ASSERT) != 0;\n\tirq.trig_mode = icr & APIC_INT_LEVELTRIG;\n\n\tif (icr & APIC_DEST_MASK)\n\t\treturn -KVM_EINVAL;\n\tif (icr & APIC_SHORT_MASK)\n\t\treturn -KVM_EINVAL;\n\n\trcu_read_lock();\n\tmap = rcu_dereference(kvm->arch.apic_map);\n\n\tif (unlikely(!map)) {\n\t\tcount = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tif (min > map->max_apic_id)\n\t\tgoto out;\n\t/* Bits above cluster_size are masked in the caller.  */\n\tfor_each_set_bit(i, &ipi_bitmap_low,\n\t\tmin((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {\n\t\tif (map->phys_map[min + i]) {\n\t\t\tvcpu = map->phys_map[min + i]->vcpu;\n\t\t\tcount += kvm_apic_set_irq(vcpu, &irq, NULL);\n\t\t}\n\t}\n\n\tmin += cluster_size;\n\n\tif (min > map->max_apic_id)\n\t\tgoto out;\n\n\tfor_each_set_bit(i, &ipi_bitmap_high,\n\t\tmin((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {\n\t\tif (map->phys_map[min + i]) {\n\t\t\tvcpu = map->phys_map[min + i]->vcpu;\n\t\t\tcount += kvm_apic_set_irq(vcpu, &irq, NULL);\n\t\t}\n\t}\n\nout:\n\trcu_read_unlock();\n\treturn count;\n}",
        "patch": "--- code before\n+++ code after\n@@ -21,6 +21,11 @@\n \n \trcu_read_lock();\n \tmap = rcu_dereference(kvm->arch.apic_map);\n+\n+\tif (unlikely(!map)) {\n+\t\tcount = -EOPNOTSUPP;\n+\t\tgoto out;\n+\t}\n \n \tif (min > map->max_apic_id)\n \t\tgoto out;",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (unlikely(!map)) {",
                "\t\tcount = -EOPNOTSUPP;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kvm_pv_send_ipi in arch/x86/kvm/lapic.c in the Linux kernel through 4.19.2 allows local users to cause a denial of service (NULL pointer dereference and BUG) via crafted system calls that reach a situation where the apic map is uninitialized.",
        "id": 1743
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "int smb2_handle_negotiate(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct smb2_negotiate_req *req = smb2_get_msg(work->request_buf);\n\tstruct smb2_negotiate_rsp *rsp = smb2_get_msg(work->response_buf);\n\tint rc = 0;\n\tunsigned int smb2_buf_len, smb2_neg_size;\n\t__le32 status;\n\n\tksmbd_debug(SMB, \"Received negotiate request\\n\");\n\tconn->need_neg = false;\n\tif (ksmbd_conn_good(work)) {\n\t\tpr_err(\"conn->tcp_status is already in CifsGood State\\n\");\n\t\twork->send_no_response = 1;\n\t\treturn rc;\n\t}\n\n\tif (req->DialectCount == 0) {\n\t\tpr_err(\"malformed packet\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tsmb2_buf_len = get_rfc1002_len(work->request_buf);\n\tsmb2_neg_size = offsetof(struct smb2_negotiate_req, Dialects);\n\tif (smb2_neg_size > smb2_buf_len) {\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tif (conn->dialect == SMB311_PROT_ID) {\n\t\tunsigned int nego_ctxt_off = le32_to_cpu(req->NegotiateContextOffset);\n\n\t\tif (smb2_buf_len < nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (smb2_neg_size > nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (smb2_neg_size + le16_to_cpu(req->DialectCount) * sizeof(__le16) >\n\t\t    nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (smb2_neg_size + le16_to_cpu(req->DialectCount) * sizeof(__le16) >\n\t\t    smb2_buf_len) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tconn->cli_cap = le32_to_cpu(req->Capabilities);\n\tswitch (conn->dialect) {\n\tcase SMB311_PROT_ID:\n\t\tconn->preauth_info =\n\t\t\tkzalloc(sizeof(struct preauth_integrity_info),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!conn->preauth_info) {\n\t\t\trc = -ENOMEM;\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tstatus = deassemble_neg_contexts(conn, req,\n\t\t\t\t\t\t get_rfc1002_len(work->request_buf));\n\t\tif (status != STATUS_SUCCESS) {\n\t\t\tpr_err(\"deassemble_neg_contexts error(0x%x)\\n\",\n\t\t\t       status);\n\t\t\trsp->hdr.Status = status;\n\t\t\trc = -EINVAL;\n\t\t\tkfree(conn->preauth_info);\n\t\t\tconn->preauth_info = NULL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\trc = init_smb3_11_server(conn);\n\t\tif (rc < 0) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\tkfree(conn->preauth_info);\n\t\t\tconn->preauth_info = NULL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tksmbd_gen_preauth_integrity_hash(conn,\n\t\t\t\t\t\t work->request_buf,\n\t\t\t\t\t\t conn->preauth_info->Preauth_HashValue);\n\t\trsp->NegotiateContextOffset =\n\t\t\t\tcpu_to_le32(OFFSET_OF_NEG_CONTEXT);\n\t\tassemble_neg_contexts(conn, rsp, work->response_buf);\n\t\tbreak;\n\tcase SMB302_PROT_ID:\n\t\tinit_smb3_02_server(conn);\n\t\tbreak;\n\tcase SMB30_PROT_ID:\n\t\tinit_smb3_0_server(conn);\n\t\tbreak;\n\tcase SMB21_PROT_ID:\n\t\tinit_smb2_1_server(conn);\n\t\tbreak;\n\tcase SMB2X_PROT_ID:\n\tcase BAD_PROT_ID:\n\tdefault:\n\t\tksmbd_debug(SMB, \"Server dialect :0x%x not supported\\n\",\n\t\t\t    conn->dialect);\n\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\trsp->Capabilities = cpu_to_le32(conn->vals->capabilities);\n\n\t/* For stats */\n\tconn->connection_type = conn->dialect;\n\n\trsp->MaxTransactSize = cpu_to_le32(conn->vals->max_trans_size);\n\trsp->MaxReadSize = cpu_to_le32(conn->vals->max_read_size);\n\trsp->MaxWriteSize = cpu_to_le32(conn->vals->max_write_size);\n\n\tmemcpy(conn->ClientGUID, req->ClientGUID,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\tconn->cli_sec_mode = le16_to_cpu(req->SecurityMode);\n\n\trsp->StructureSize = cpu_to_le16(65);\n\trsp->DialectRevision = cpu_to_le16(conn->dialect);\n\t/* Not setting conn guid rsp->ServerGUID, as it\n\t * not used by client for identifying server\n\t */\n\tmemset(rsp->ServerGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\n\trsp->SystemTime = cpu_to_le64(ksmbd_systime());\n\trsp->ServerStartTime = 0;\n\tksmbd_debug(SMB, \"negotiate context offset %d, count %d\\n\",\n\t\t    le32_to_cpu(rsp->NegotiateContextOffset),\n\t\t    le16_to_cpu(rsp->NegotiateContextCount));\n\n\trsp->SecurityBufferOffset = cpu_to_le16(128);\n\trsp->SecurityBufferLength = cpu_to_le16(AUTH_GSS_LENGTH);\n\tksmbd_copy_gss_neg_header((char *)(&rsp->hdr) +\n\t\t\t\t  le16_to_cpu(rsp->SecurityBufferOffset));\n\tinc_rfc1001_len(work->response_buf, sizeof(struct smb2_negotiate_rsp) -\n\t\t\tsizeof(struct smb2_hdr) + AUTH_GSS_LENGTH);\n\trsp->SecurityMode = SMB2_NEGOTIATE_SIGNING_ENABLED_LE;\n\tconn->use_spnego = true;\n\n\tif ((server_conf.signing == KSMBD_CONFIG_OPT_AUTO ||\n\t     server_conf.signing == KSMBD_CONFIG_OPT_DISABLED) &&\n\t    req->SecurityMode & SMB2_NEGOTIATE_SIGNING_REQUIRED_LE)\n\t\tconn->sign = true;\n\telse if (server_conf.signing == KSMBD_CONFIG_OPT_MANDATORY) {\n\t\tserver_conf.enforced_signing = true;\n\t\trsp->SecurityMode |= SMB2_NEGOTIATE_SIGNING_REQUIRED_LE;\n\t\tconn->sign = true;\n\t}\n\n\tconn->srv_sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tksmbd_conn_set_need_negotiate(work);\n\nerr_out:\n\tif (rc < 0)\n\t\tsmb2_set_err_rsp(work);\n\n\treturn rc;\n}",
        "code_after_change": "int smb2_handle_negotiate(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct smb2_negotiate_req *req = smb2_get_msg(work->request_buf);\n\tstruct smb2_negotiate_rsp *rsp = smb2_get_msg(work->response_buf);\n\tint rc = 0;\n\tunsigned int smb2_buf_len, smb2_neg_size;\n\t__le32 status;\n\n\tksmbd_debug(SMB, \"Received negotiate request\\n\");\n\tconn->need_neg = false;\n\tif (ksmbd_conn_good(conn)) {\n\t\tpr_err(\"conn->tcp_status is already in CifsGood State\\n\");\n\t\twork->send_no_response = 1;\n\t\treturn rc;\n\t}\n\n\tif (req->DialectCount == 0) {\n\t\tpr_err(\"malformed packet\\n\");\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tsmb2_buf_len = get_rfc1002_len(work->request_buf);\n\tsmb2_neg_size = offsetof(struct smb2_negotiate_req, Dialects);\n\tif (smb2_neg_size > smb2_buf_len) {\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tif (conn->dialect == SMB311_PROT_ID) {\n\t\tunsigned int nego_ctxt_off = le32_to_cpu(req->NegotiateContextOffset);\n\n\t\tif (smb2_buf_len < nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (smb2_neg_size > nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (smb2_neg_size + le16_to_cpu(req->DialectCount) * sizeof(__le16) >\n\t\t    nego_ctxt_off) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\t} else {\n\t\tif (smb2_neg_size + le16_to_cpu(req->DialectCount) * sizeof(__le16) >\n\t\t    smb2_buf_len) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\trc = -EINVAL;\n\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tconn->cli_cap = le32_to_cpu(req->Capabilities);\n\tswitch (conn->dialect) {\n\tcase SMB311_PROT_ID:\n\t\tconn->preauth_info =\n\t\t\tkzalloc(sizeof(struct preauth_integrity_info),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!conn->preauth_info) {\n\t\t\trc = -ENOMEM;\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tstatus = deassemble_neg_contexts(conn, req,\n\t\t\t\t\t\t get_rfc1002_len(work->request_buf));\n\t\tif (status != STATUS_SUCCESS) {\n\t\t\tpr_err(\"deassemble_neg_contexts error(0x%x)\\n\",\n\t\t\t       status);\n\t\t\trsp->hdr.Status = status;\n\t\t\trc = -EINVAL;\n\t\t\tkfree(conn->preauth_info);\n\t\t\tconn->preauth_info = NULL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\trc = init_smb3_11_server(conn);\n\t\tif (rc < 0) {\n\t\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\t\t\tkfree(conn->preauth_info);\n\t\t\tconn->preauth_info = NULL;\n\t\t\tgoto err_out;\n\t\t}\n\n\t\tksmbd_gen_preauth_integrity_hash(conn,\n\t\t\t\t\t\t work->request_buf,\n\t\t\t\t\t\t conn->preauth_info->Preauth_HashValue);\n\t\trsp->NegotiateContextOffset =\n\t\t\t\tcpu_to_le32(OFFSET_OF_NEG_CONTEXT);\n\t\tassemble_neg_contexts(conn, rsp, work->response_buf);\n\t\tbreak;\n\tcase SMB302_PROT_ID:\n\t\tinit_smb3_02_server(conn);\n\t\tbreak;\n\tcase SMB30_PROT_ID:\n\t\tinit_smb3_0_server(conn);\n\t\tbreak;\n\tcase SMB21_PROT_ID:\n\t\tinit_smb2_1_server(conn);\n\t\tbreak;\n\tcase SMB2X_PROT_ID:\n\tcase BAD_PROT_ID:\n\tdefault:\n\t\tksmbd_debug(SMB, \"Server dialect :0x%x not supported\\n\",\n\t\t\t    conn->dialect);\n\t\trsp->hdr.Status = STATUS_NOT_SUPPORTED;\n\t\trc = -EINVAL;\n\t\tgoto err_out;\n\t}\n\trsp->Capabilities = cpu_to_le32(conn->vals->capabilities);\n\n\t/* For stats */\n\tconn->connection_type = conn->dialect;\n\n\trsp->MaxTransactSize = cpu_to_le32(conn->vals->max_trans_size);\n\trsp->MaxReadSize = cpu_to_le32(conn->vals->max_read_size);\n\trsp->MaxWriteSize = cpu_to_le32(conn->vals->max_write_size);\n\n\tmemcpy(conn->ClientGUID, req->ClientGUID,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\tconn->cli_sec_mode = le16_to_cpu(req->SecurityMode);\n\n\trsp->StructureSize = cpu_to_le16(65);\n\trsp->DialectRevision = cpu_to_le16(conn->dialect);\n\t/* Not setting conn guid rsp->ServerGUID, as it\n\t * not used by client for identifying server\n\t */\n\tmemset(rsp->ServerGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\n\trsp->SystemTime = cpu_to_le64(ksmbd_systime());\n\trsp->ServerStartTime = 0;\n\tksmbd_debug(SMB, \"negotiate context offset %d, count %d\\n\",\n\t\t    le32_to_cpu(rsp->NegotiateContextOffset),\n\t\t    le16_to_cpu(rsp->NegotiateContextCount));\n\n\trsp->SecurityBufferOffset = cpu_to_le16(128);\n\trsp->SecurityBufferLength = cpu_to_le16(AUTH_GSS_LENGTH);\n\tksmbd_copy_gss_neg_header((char *)(&rsp->hdr) +\n\t\t\t\t  le16_to_cpu(rsp->SecurityBufferOffset));\n\tinc_rfc1001_len(work->response_buf, sizeof(struct smb2_negotiate_rsp) -\n\t\t\tsizeof(struct smb2_hdr) + AUTH_GSS_LENGTH);\n\trsp->SecurityMode = SMB2_NEGOTIATE_SIGNING_ENABLED_LE;\n\tconn->use_spnego = true;\n\n\tif ((server_conf.signing == KSMBD_CONFIG_OPT_AUTO ||\n\t     server_conf.signing == KSMBD_CONFIG_OPT_DISABLED) &&\n\t    req->SecurityMode & SMB2_NEGOTIATE_SIGNING_REQUIRED_LE)\n\t\tconn->sign = true;\n\telse if (server_conf.signing == KSMBD_CONFIG_OPT_MANDATORY) {\n\t\tserver_conf.enforced_signing = true;\n\t\trsp->SecurityMode |= SMB2_NEGOTIATE_SIGNING_REQUIRED_LE;\n\t\tconn->sign = true;\n\t}\n\n\tconn->srv_sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tksmbd_conn_set_need_negotiate(conn);\n\nerr_out:\n\tif (rc < 0)\n\t\tsmb2_set_err_rsp(work);\n\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,7 @@\n \n \tksmbd_debug(SMB, \"Received negotiate request\\n\");\n \tconn->need_neg = false;\n-\tif (ksmbd_conn_good(work)) {\n+\tif (ksmbd_conn_good(conn)) {\n \t\tpr_err(\"conn->tcp_status is already in CifsGood State\\n\");\n \t\twork->send_no_response = 1;\n \t\treturn rc;\n@@ -163,7 +163,7 @@\n \t}\n \n \tconn->srv_sec_mode = le16_to_cpu(rsp->SecurityMode);\n-\tksmbd_conn_set_need_negotiate(work);\n+\tksmbd_conn_set_need_negotiate(conn);\n \n err_out:\n \tif (rc < 0)",
        "function_modified_lines": {
            "added": [
                "\tif (ksmbd_conn_good(conn)) {",
                "\tksmbd_conn_set_need_negotiate(conn);"
            ],
            "deleted": [
                "\tif (ksmbd_conn_good(work)) {",
                "\tksmbd_conn_set_need_negotiate(work);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4029
    },
    {
        "cve_id": "CVE-2021-4095",
        "code_before_change": "static int kvm_xen_shared_info_init(struct kvm *kvm, gfn_t gfn)\n{\n\tstruct gfn_to_pfn_cache *gpc = &kvm->arch.xen.shinfo_cache;\n\tgpa_t gpa = gfn_to_gpa(gfn);\n\tint wc_ofs, sec_hi_ofs;\n\tint ret = 0;\n\tint idx = srcu_read_lock(&kvm->srcu);\n\n\tif (gfn == GPA_INVALID) {\n\t\tkvm_gfn_to_pfn_cache_destroy(kvm, gpc);\n\t\tgoto out;\n\t}\n\n\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true, gpa,\n\t\t\t\t\tPAGE_SIZE, false);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Paranoia checks on the 32-bit struct layout */\n\tBUILD_BUG_ON(offsetof(struct compat_shared_info, wc) != 0x900);\n\tBUILD_BUG_ON(offsetof(struct compat_shared_info, arch.wc_sec_hi) != 0x924);\n\tBUILD_BUG_ON(offsetof(struct pvclock_vcpu_time_info, version) != 0);\n\n\t/* 32-bit location by default */\n\twc_ofs = offsetof(struct compat_shared_info, wc);\n\tsec_hi_ofs = offsetof(struct compat_shared_info, arch.wc_sec_hi);\n\n#ifdef CONFIG_X86_64\n\t/* Paranoia checks on the 64-bit struct layout */\n\tBUILD_BUG_ON(offsetof(struct shared_info, wc) != 0xc00);\n\tBUILD_BUG_ON(offsetof(struct shared_info, wc_sec_hi) != 0xc0c);\n\n\tif (kvm->arch.xen.long_mode) {\n\t\twc_ofs = offsetof(struct shared_info, wc);\n\t\tsec_hi_ofs = offsetof(struct shared_info, wc_sec_hi);\n\t}\n#endif\n\n\tkvm_write_wall_clock(kvm, gpa + wc_ofs, sec_hi_ofs - wc_ofs);\n\tkvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);\n\nout:\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\treturn ret;\n}",
        "code_after_change": "static int kvm_xen_shared_info_init(struct kvm *kvm, gfn_t gfn)\n{\n\tstruct gfn_to_pfn_cache *gpc = &kvm->arch.xen.shinfo_cache;\n\tstruct pvclock_wall_clock *wc;\n\tgpa_t gpa = gfn_to_gpa(gfn);\n\tu32 *wc_sec_hi;\n\tu32 wc_version;\n\tu64 wall_nsec;\n\tint ret = 0;\n\tint idx = srcu_read_lock(&kvm->srcu);\n\n\tif (gfn == GPA_INVALID) {\n\t\tkvm_gfn_to_pfn_cache_destroy(kvm, gpc);\n\t\tgoto out;\n\t}\n\n\tdo {\n\t\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true,\n\t\t\t\t\t\tgpa, PAGE_SIZE, false);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * This code mirrors kvm_write_wall_clock() except that it writes\n\t\t * directly through the pfn cache and doesn't mark the page dirty.\n\t\t */\n\t\twall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);\n\n\t\t/* It could be invalid again already, so we need to check */\n\t\tread_lock_irq(&gpc->lock);\n\n\t\tif (gpc->valid)\n\t\t\tbreak;\n\n\t\tread_unlock_irq(&gpc->lock);\n\t} while (1);\n\n\t/* Paranoia checks on the 32-bit struct layout */\n\tBUILD_BUG_ON(offsetof(struct compat_shared_info, wc) != 0x900);\n\tBUILD_BUG_ON(offsetof(struct compat_shared_info, arch.wc_sec_hi) != 0x924);\n\tBUILD_BUG_ON(offsetof(struct pvclock_vcpu_time_info, version) != 0);\n\n#ifdef CONFIG_X86_64\n\t/* Paranoia checks on the 64-bit struct layout */\n\tBUILD_BUG_ON(offsetof(struct shared_info, wc) != 0xc00);\n\tBUILD_BUG_ON(offsetof(struct shared_info, wc_sec_hi) != 0xc0c);\n\n\tif (IS_ENABLED(CONFIG_64BIT) && kvm->arch.xen.long_mode) {\n\t\tstruct shared_info *shinfo = gpc->khva;\n\n\t\twc_sec_hi = &shinfo->wc_sec_hi;\n\t\twc = &shinfo->wc;\n\t} else\n#endif\n\t{\n\t\tstruct compat_shared_info *shinfo = gpc->khva;\n\n\t\twc_sec_hi = &shinfo->arch.wc_sec_hi;\n\t\twc = &shinfo->wc;\n\t}\n\n\t/* Increment and ensure an odd value */\n\twc_version = wc->version = (wc->version + 1) | 1;\n\tsmp_wmb();\n\n\twc->nsec = do_div(wall_nsec,  1000000000);\n\twc->sec = (u32)wall_nsec;\n\t*wc_sec_hi = wall_nsec >> 32;\n\tsmp_wmb();\n\n\twc->version = wc_version + 1;\n\tread_unlock_irq(&gpc->lock);\n\n\tkvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);\n\nout:\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,11 @@\n static int kvm_xen_shared_info_init(struct kvm *kvm, gfn_t gfn)\n {\n \tstruct gfn_to_pfn_cache *gpc = &kvm->arch.xen.shinfo_cache;\n+\tstruct pvclock_wall_clock *wc;\n \tgpa_t gpa = gfn_to_gpa(gfn);\n-\tint wc_ofs, sec_hi_ofs;\n+\tu32 *wc_sec_hi;\n+\tu32 wc_version;\n+\tu64 wall_nsec;\n \tint ret = 0;\n \tint idx = srcu_read_lock(&kvm->srcu);\n \n@@ -11,32 +14,63 @@\n \t\tgoto out;\n \t}\n \n-\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true, gpa,\n-\t\t\t\t\tPAGE_SIZE, false);\n-\tif (ret)\n-\t\tgoto out;\n+\tdo {\n+\t\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true,\n+\t\t\t\t\t\tgpa, PAGE_SIZE, false);\n+\t\tif (ret)\n+\t\t\tgoto out;\n+\n+\t\t/*\n+\t\t * This code mirrors kvm_write_wall_clock() except that it writes\n+\t\t * directly through the pfn cache and doesn't mark the page dirty.\n+\t\t */\n+\t\twall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);\n+\n+\t\t/* It could be invalid again already, so we need to check */\n+\t\tread_lock_irq(&gpc->lock);\n+\n+\t\tif (gpc->valid)\n+\t\t\tbreak;\n+\n+\t\tread_unlock_irq(&gpc->lock);\n+\t} while (1);\n \n \t/* Paranoia checks on the 32-bit struct layout */\n \tBUILD_BUG_ON(offsetof(struct compat_shared_info, wc) != 0x900);\n \tBUILD_BUG_ON(offsetof(struct compat_shared_info, arch.wc_sec_hi) != 0x924);\n \tBUILD_BUG_ON(offsetof(struct pvclock_vcpu_time_info, version) != 0);\n \n-\t/* 32-bit location by default */\n-\twc_ofs = offsetof(struct compat_shared_info, wc);\n-\tsec_hi_ofs = offsetof(struct compat_shared_info, arch.wc_sec_hi);\n-\n #ifdef CONFIG_X86_64\n \t/* Paranoia checks on the 64-bit struct layout */\n \tBUILD_BUG_ON(offsetof(struct shared_info, wc) != 0xc00);\n \tBUILD_BUG_ON(offsetof(struct shared_info, wc_sec_hi) != 0xc0c);\n \n-\tif (kvm->arch.xen.long_mode) {\n-\t\twc_ofs = offsetof(struct shared_info, wc);\n-\t\tsec_hi_ofs = offsetof(struct shared_info, wc_sec_hi);\n+\tif (IS_ENABLED(CONFIG_64BIT) && kvm->arch.xen.long_mode) {\n+\t\tstruct shared_info *shinfo = gpc->khva;\n+\n+\t\twc_sec_hi = &shinfo->wc_sec_hi;\n+\t\twc = &shinfo->wc;\n+\t} else\n+#endif\n+\t{\n+\t\tstruct compat_shared_info *shinfo = gpc->khva;\n+\n+\t\twc_sec_hi = &shinfo->arch.wc_sec_hi;\n+\t\twc = &shinfo->wc;\n \t}\n-#endif\n \n-\tkvm_write_wall_clock(kvm, gpa + wc_ofs, sec_hi_ofs - wc_ofs);\n+\t/* Increment and ensure an odd value */\n+\twc_version = wc->version = (wc->version + 1) | 1;\n+\tsmp_wmb();\n+\n+\twc->nsec = do_div(wall_nsec,  1000000000);\n+\twc->sec = (u32)wall_nsec;\n+\t*wc_sec_hi = wall_nsec >> 32;\n+\tsmp_wmb();\n+\n+\twc->version = wc_version + 1;\n+\tread_unlock_irq(&gpc->lock);\n+\n \tkvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);\n \n out:",
        "function_modified_lines": {
            "added": [
                "\tstruct pvclock_wall_clock *wc;",
                "\tu32 *wc_sec_hi;",
                "\tu32 wc_version;",
                "\tu64 wall_nsec;",
                "\tdo {",
                "\t\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true,",
                "\t\t\t\t\t\tgpa, PAGE_SIZE, false);",
                "\t\tif (ret)",
                "\t\t\tgoto out;",
                "",
                "\t\t/*",
                "\t\t * This code mirrors kvm_write_wall_clock() except that it writes",
                "\t\t * directly through the pfn cache and doesn't mark the page dirty.",
                "\t\t */",
                "\t\twall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);",
                "",
                "\t\t/* It could be invalid again already, so we need to check */",
                "\t\tread_lock_irq(&gpc->lock);",
                "",
                "\t\tif (gpc->valid)",
                "\t\t\tbreak;",
                "",
                "\t\tread_unlock_irq(&gpc->lock);",
                "\t} while (1);",
                "\tif (IS_ENABLED(CONFIG_64BIT) && kvm->arch.xen.long_mode) {",
                "\t\tstruct shared_info *shinfo = gpc->khva;",
                "",
                "\t\twc_sec_hi = &shinfo->wc_sec_hi;",
                "\t\twc = &shinfo->wc;",
                "\t} else",
                "#endif",
                "\t{",
                "\t\tstruct compat_shared_info *shinfo = gpc->khva;",
                "",
                "\t\twc_sec_hi = &shinfo->arch.wc_sec_hi;",
                "\t\twc = &shinfo->wc;",
                "\t/* Increment and ensure an odd value */",
                "\twc_version = wc->version = (wc->version + 1) | 1;",
                "\tsmp_wmb();",
                "",
                "\twc->nsec = do_div(wall_nsec,  1000000000);",
                "\twc->sec = (u32)wall_nsec;",
                "\t*wc_sec_hi = wall_nsec >> 32;",
                "\tsmp_wmb();",
                "",
                "\twc->version = wc_version + 1;",
                "\tread_unlock_irq(&gpc->lock);",
                ""
            ],
            "deleted": [
                "\tint wc_ofs, sec_hi_ofs;",
                "\tret = kvm_gfn_to_pfn_cache_init(kvm, gpc, NULL, false, true, gpa,",
                "\t\t\t\t\tPAGE_SIZE, false);",
                "\tif (ret)",
                "\t\tgoto out;",
                "\t/* 32-bit location by default */",
                "\twc_ofs = offsetof(struct compat_shared_info, wc);",
                "\tsec_hi_ofs = offsetof(struct compat_shared_info, arch.wc_sec_hi);",
                "",
                "\tif (kvm->arch.xen.long_mode) {",
                "\t\twc_ofs = offsetof(struct shared_info, wc);",
                "\t\tsec_hi_ofs = offsetof(struct shared_info, wc_sec_hi);",
                "#endif",
                "\tkvm_write_wall_clock(kvm, gpa + wc_ofs, sec_hi_ofs - wc_ofs);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference was found in the Linux kernel's KVM when dirty ring logging is enabled without an active vCPU context. An unprivileged local attacker on the host may use this flaw to cause a kernel oops condition and thus a denial of service by issuing a KVM_XEN_HVM_SET_ATTR ioctl. This flaw affects Linux kernel versions prior to 5.17-rc1.",
        "id": 3133
    },
    {
        "cve_id": "CVE-2019-9213",
        "code_before_change": "int expand_downwards(struct vm_area_struct *vma,\n\t\t\t\t   unsigned long address)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct vm_area_struct *prev;\n\tint error;\n\n\taddress &= PAGE_MASK;\n\terror = security_mmap_addr(address);\n\tif (error)\n\t\treturn error;\n\n\t/* Enforce stack_guard_gap */\n\tprev = vma->vm_prev;\n\t/* Check that both stack segments have the same anon_vma? */\n\tif (prev && !(prev->vm_flags & VM_GROWSDOWN) &&\n\t\t\t(prev->vm_flags & (VM_WRITE|VM_READ|VM_EXEC))) {\n\t\tif (address - prev->vm_end < stack_guard_gap)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* We must make sure the anon_vma is allocated. */\n\tif (unlikely(anon_vma_prepare(vma)))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * vma->vm_start/vm_end cannot change under us because the caller\n\t * is required to hold the mmap_sem in read mode.  We need the\n\t * anon_vma lock to serialize against concurrent expand_stacks.\n\t */\n\tanon_vma_lock_write(vma->anon_vma);\n\n\t/* Somebody else might have raced and expanded it already */\n\tif (address < vma->vm_start) {\n\t\tunsigned long size, grow;\n\n\t\tsize = vma->vm_end - address;\n\t\tgrow = (vma->vm_start - address) >> PAGE_SHIFT;\n\n\t\terror = -ENOMEM;\n\t\tif (grow <= vma->vm_pgoff) {\n\t\t\terror = acct_stack_growth(vma, size, grow);\n\t\t\tif (!error) {\n\t\t\t\t/*\n\t\t\t\t * vma_gap_update() doesn't support concurrent\n\t\t\t\t * updates, but we only hold a shared mmap_sem\n\t\t\t\t * lock here, so we need to protect against\n\t\t\t\t * concurrent vma expansions.\n\t\t\t\t * anon_vma_lock_write() doesn't help here, as\n\t\t\t\t * we don't guarantee that all growable vmas\n\t\t\t\t * in a mm share the same root anon vma.\n\t\t\t\t * So, we reuse mm->page_table_lock to guard\n\t\t\t\t * against concurrent vma expansions.\n\t\t\t\t */\n\t\t\t\tspin_lock(&mm->page_table_lock);\n\t\t\t\tif (vma->vm_flags & VM_LOCKED)\n\t\t\t\t\tmm->locked_vm += grow;\n\t\t\t\tvm_stat_account(mm, vma->vm_flags, grow);\n\t\t\t\tanon_vma_interval_tree_pre_update_vma(vma);\n\t\t\t\tvma->vm_start = address;\n\t\t\t\tvma->vm_pgoff -= grow;\n\t\t\t\tanon_vma_interval_tree_post_update_vma(vma);\n\t\t\t\tvma_gap_update(vma);\n\t\t\t\tspin_unlock(&mm->page_table_lock);\n\n\t\t\t\tperf_event_mmap(vma);\n\t\t\t}\n\t\t}\n\t}\n\tanon_vma_unlock_write(vma->anon_vma);\n\tkhugepaged_enter_vma_merge(vma, vma->vm_flags);\n\tvalidate_mm(mm);\n\treturn error;\n}",
        "code_after_change": "int expand_downwards(struct vm_area_struct *vma,\n\t\t\t\t   unsigned long address)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct vm_area_struct *prev;\n\tint error = 0;\n\n\taddress &= PAGE_MASK;\n\tif (address < mmap_min_addr)\n\t\treturn -EPERM;\n\n\t/* Enforce stack_guard_gap */\n\tprev = vma->vm_prev;\n\t/* Check that both stack segments have the same anon_vma? */\n\tif (prev && !(prev->vm_flags & VM_GROWSDOWN) &&\n\t\t\t(prev->vm_flags & (VM_WRITE|VM_READ|VM_EXEC))) {\n\t\tif (address - prev->vm_end < stack_guard_gap)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/* We must make sure the anon_vma is allocated. */\n\tif (unlikely(anon_vma_prepare(vma)))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * vma->vm_start/vm_end cannot change under us because the caller\n\t * is required to hold the mmap_sem in read mode.  We need the\n\t * anon_vma lock to serialize against concurrent expand_stacks.\n\t */\n\tanon_vma_lock_write(vma->anon_vma);\n\n\t/* Somebody else might have raced and expanded it already */\n\tif (address < vma->vm_start) {\n\t\tunsigned long size, grow;\n\n\t\tsize = vma->vm_end - address;\n\t\tgrow = (vma->vm_start - address) >> PAGE_SHIFT;\n\n\t\terror = -ENOMEM;\n\t\tif (grow <= vma->vm_pgoff) {\n\t\t\terror = acct_stack_growth(vma, size, grow);\n\t\t\tif (!error) {\n\t\t\t\t/*\n\t\t\t\t * vma_gap_update() doesn't support concurrent\n\t\t\t\t * updates, but we only hold a shared mmap_sem\n\t\t\t\t * lock here, so we need to protect against\n\t\t\t\t * concurrent vma expansions.\n\t\t\t\t * anon_vma_lock_write() doesn't help here, as\n\t\t\t\t * we don't guarantee that all growable vmas\n\t\t\t\t * in a mm share the same root anon vma.\n\t\t\t\t * So, we reuse mm->page_table_lock to guard\n\t\t\t\t * against concurrent vma expansions.\n\t\t\t\t */\n\t\t\t\tspin_lock(&mm->page_table_lock);\n\t\t\t\tif (vma->vm_flags & VM_LOCKED)\n\t\t\t\t\tmm->locked_vm += grow;\n\t\t\t\tvm_stat_account(mm, vma->vm_flags, grow);\n\t\t\t\tanon_vma_interval_tree_pre_update_vma(vma);\n\t\t\t\tvma->vm_start = address;\n\t\t\t\tvma->vm_pgoff -= grow;\n\t\t\t\tanon_vma_interval_tree_post_update_vma(vma);\n\t\t\t\tvma_gap_update(vma);\n\t\t\t\tspin_unlock(&mm->page_table_lock);\n\n\t\t\t\tperf_event_mmap(vma);\n\t\t\t}\n\t\t}\n\t}\n\tanon_vma_unlock_write(vma->anon_vma);\n\tkhugepaged_enter_vma_merge(vma, vma->vm_flags);\n\tvalidate_mm(mm);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,12 +3,11 @@\n {\n \tstruct mm_struct *mm = vma->vm_mm;\n \tstruct vm_area_struct *prev;\n-\tint error;\n+\tint error = 0;\n \n \taddress &= PAGE_MASK;\n-\terror = security_mmap_addr(address);\n-\tif (error)\n-\t\treturn error;\n+\tif (address < mmap_min_addr)\n+\t\treturn -EPERM;\n \n \t/* Enforce stack_guard_gap */\n \tprev = vma->vm_prev;",
        "function_modified_lines": {
            "added": [
                "\tint error = 0;",
                "\tif (address < mmap_min_addr)",
                "\t\treturn -EPERM;"
            ],
            "deleted": [
                "\tint error;",
                "\terror = security_mmap_addr(address);",
                "\tif (error)",
                "\t\treturn error;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 4.20.14, expand_downwards in mm/mmap.c lacks a check for the mmap minimum address, which makes it easier for attackers to exploit kernel NULL pointer dereferences on non-SMAP platforms. This is related to a capability check for the wrong task.",
        "id": 2354
    },
    {
        "cve_id": "CVE-2015-8970",
        "code_before_change": "static void *skcipher_bind(const char *name, u32 type, u32 mask)\n{\n\treturn crypto_alloc_skcipher(name, type, mask);\n}",
        "code_after_change": "static void *skcipher_bind(const char *name, u32 type, u32 mask)\n{\n\tstruct skcipher_tfm *tfm;\n\tstruct crypto_skcipher *skcipher;\n\n\ttfm = kzalloc(sizeof(*tfm), GFP_KERNEL);\n\tif (!tfm)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tskcipher = crypto_alloc_skcipher(name, type, mask);\n\tif (IS_ERR(skcipher)) {\n\t\tkfree(tfm);\n\t\treturn ERR_CAST(skcipher);\n\t}\n\n\ttfm->skcipher = skcipher;\n\n\treturn tfm;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,19 @@\n static void *skcipher_bind(const char *name, u32 type, u32 mask)\n {\n-\treturn crypto_alloc_skcipher(name, type, mask);\n+\tstruct skcipher_tfm *tfm;\n+\tstruct crypto_skcipher *skcipher;\n+\n+\ttfm = kzalloc(sizeof(*tfm), GFP_KERNEL);\n+\tif (!tfm)\n+\t\treturn ERR_PTR(-ENOMEM);\n+\n+\tskcipher = crypto_alloc_skcipher(name, type, mask);\n+\tif (IS_ERR(skcipher)) {\n+\t\tkfree(tfm);\n+\t\treturn ERR_CAST(skcipher);\n+\t}\n+\n+\ttfm->skcipher = skcipher;\n+\n+\treturn tfm;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct skcipher_tfm *tfm;",
                "\tstruct crypto_skcipher *skcipher;",
                "",
                "\ttfm = kzalloc(sizeof(*tfm), GFP_KERNEL);",
                "\tif (!tfm)",
                "\t\treturn ERR_PTR(-ENOMEM);",
                "",
                "\tskcipher = crypto_alloc_skcipher(name, type, mask);",
                "\tif (IS_ERR(skcipher)) {",
                "\t\tkfree(tfm);",
                "\t\treturn ERR_CAST(skcipher);",
                "\t}",
                "",
                "\ttfm->skcipher = skcipher;",
                "",
                "\treturn tfm;"
            ],
            "deleted": [
                "\treturn crypto_alloc_skcipher(name, type, mask);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/algif_skcipher.c in the Linux kernel before 4.4.2 does not verify that a setkey operation has been performed on an AF_ALG socket before an accept system call is processed, which allows local users to cause a denial of service (NULL pointer dereference and system crash) via a crafted application that does not supply a key, related to the lrw_crypt function in crypto/lrw.c.",
        "id": 879
    },
    {
        "cve_id": "CVE-2014-2678",
        "code_before_change": "static int rds_iw_laddr_check(__be32 addr)\n{\n\tint ret;\n\tstruct rdma_cm_id *cm_id;\n\tstruct sockaddr_in sin;\n\n\t/* Create a CMA ID and try to bind it. This catches both\n\t * IB and iWARP capable NICs.\n\t */\n\tcm_id = rdma_create_id(NULL, NULL, RDMA_PS_TCP, IB_QPT_RC);\n\tif (IS_ERR(cm_id))\n\t\treturn PTR_ERR(cm_id);\n\n\tmemset(&sin, 0, sizeof(sin));\n\tsin.sin_family = AF_INET;\n\tsin.sin_addr.s_addr = addr;\n\n\t/* rdma_bind_addr will only succeed for IB & iWARP devices */\n\tret = rdma_bind_addr(cm_id, (struct sockaddr *)&sin);\n\t/* due to this, we will claim to support IB devices unless we\n\t   check node_type. */\n\tif (ret || cm_id->device->node_type != RDMA_NODE_RNIC)\n\t\tret = -EADDRNOTAVAIL;\n\n\trdsdebug(\"addr %pI4 ret %d node type %d\\n\",\n\t\t&addr, ret,\n\t\tcm_id->device ? cm_id->device->node_type : -1);\n\n\trdma_destroy_id(cm_id);\n\n\treturn ret;\n}",
        "code_after_change": "static int rds_iw_laddr_check(__be32 addr)\n{\n\tint ret;\n\tstruct rdma_cm_id *cm_id;\n\tstruct sockaddr_in sin;\n\n\t/* Create a CMA ID and try to bind it. This catches both\n\t * IB and iWARP capable NICs.\n\t */\n\tcm_id = rdma_create_id(NULL, NULL, RDMA_PS_TCP, IB_QPT_RC);\n\tif (IS_ERR(cm_id))\n\t\treturn PTR_ERR(cm_id);\n\n\tmemset(&sin, 0, sizeof(sin));\n\tsin.sin_family = AF_INET;\n\tsin.sin_addr.s_addr = addr;\n\n\t/* rdma_bind_addr will only succeed for IB & iWARP devices */\n\tret = rdma_bind_addr(cm_id, (struct sockaddr *)&sin);\n\t/* due to this, we will claim to support IB devices unless we\n\t   check node_type. */\n\tif (ret || !cm_id->device ||\n\t    cm_id->device->node_type != RDMA_NODE_RNIC)\n\t\tret = -EADDRNOTAVAIL;\n\n\trdsdebug(\"addr %pI4 ret %d node type %d\\n\",\n\t\t&addr, ret,\n\t\tcm_id->device ? cm_id->device->node_type : -1);\n\n\trdma_destroy_id(cm_id);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,8 @@\n \tret = rdma_bind_addr(cm_id, (struct sockaddr *)&sin);\n \t/* due to this, we will claim to support IB devices unless we\n \t   check node_type. */\n-\tif (ret || cm_id->device->node_type != RDMA_NODE_RNIC)\n+\tif (ret || !cm_id->device ||\n+\t    cm_id->device->node_type != RDMA_NODE_RNIC)\n \t\tret = -EADDRNOTAVAIL;\n \n \trdsdebug(\"addr %pI4 ret %d node type %d\\n\",",
        "function_modified_lines": {
            "added": [
                "\tif (ret || !cm_id->device ||",
                "\t    cm_id->device->node_type != RDMA_NODE_RNIC)"
            ],
            "deleted": [
                "\tif (ret || cm_id->device->node_type != RDMA_NODE_RNIC)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "id": 493
    },
    {
        "cve_id": "CVE-2017-9211",
        "code_before_change": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = alg->setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}",
        "code_after_change": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = skcipher_setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n \t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n \n-\tskcipher->setkey = alg->setkey;\n+\tskcipher->setkey = skcipher_setkey;\n \tskcipher->encrypt = alg->encrypt;\n \tskcipher->decrypt = alg->decrypt;\n \tskcipher->ivsize = alg->ivsize;",
        "function_modified_lines": {
            "added": [
                "\tskcipher->setkey = skcipher_setkey;"
            ],
            "deleted": [
                "\tskcipher->setkey = alg->setkey;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The crypto_skcipher_init_tfm function in crypto/skcipher.c in the Linux kernel through 4.11.2 relies on a setkey function that lacks a key-size check, which allows local users to cause a denial of service (NULL pointer dereference) via a crafted application.",
        "id": 1568
    },
    {
        "cve_id": "CVE-2019-15291",
        "code_before_change": "static int flexcop_usb_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct usb_device *udev = interface_to_usbdev(intf);\n\tstruct flexcop_usb *fc_usb = NULL;\n\tstruct flexcop_device *fc = NULL;\n\tint ret;\n\n\tif ((fc = flexcop_device_kmalloc(sizeof(struct flexcop_usb))) == NULL) {\n\t\terr(\"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t/* general flexcop init */\n\tfc_usb = fc->bus_specific;\n\tfc_usb->fc_dev = fc;\n\tmutex_init(&fc_usb->data_mutex);\n\n\tfc->read_ibi_reg  = flexcop_usb_read_ibi_reg;\n\tfc->write_ibi_reg = flexcop_usb_write_ibi_reg;\n\tfc->i2c_request = flexcop_usb_i2c_request;\n\tfc->get_mac_addr = flexcop_usb_get_mac_addr;\n\n\tfc->stream_control = flexcop_usb_stream_control;\n\n\tfc->pid_filtering = 1;\n\tfc->bus_type = FC_USB;\n\n\tfc->dev = &udev->dev;\n\tfc->owner = THIS_MODULE;\n\n\t/* bus specific part */\n\tfc_usb->udev = udev;\n\tfc_usb->uintf = intf;\n\tif ((ret = flexcop_usb_init(fc_usb)) != 0)\n\t\tgoto err_kfree;\n\n\t/* init flexcop */\n\tif ((ret = flexcop_device_initialize(fc)) != 0)\n\t\tgoto err_usb_exit;\n\n\t/* xfer init */\n\tif ((ret = flexcop_usb_transfer_init(fc_usb)) != 0)\n\t\tgoto err_fc_exit;\n\n\tinfo(\"%s successfully initialized and connected.\", DRIVER_NAME);\n\treturn 0;\n\nerr_fc_exit:\n\tflexcop_device_exit(fc);\nerr_usb_exit:\n\tflexcop_usb_exit(fc_usb);\nerr_kfree:\n\tflexcop_device_kfree(fc);\n\treturn ret;\n}",
        "code_after_change": "static int flexcop_usb_probe(struct usb_interface *intf,\n\t\tconst struct usb_device_id *id)\n{\n\tstruct usb_device *udev = interface_to_usbdev(intf);\n\tstruct flexcop_usb *fc_usb = NULL;\n\tstruct flexcop_device *fc = NULL;\n\tint ret;\n\n\tif (intf->cur_altsetting->desc.bNumEndpoints < 1)\n\t\treturn -ENODEV;\n\n\tif ((fc = flexcop_device_kmalloc(sizeof(struct flexcop_usb))) == NULL) {\n\t\terr(\"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t/* general flexcop init */\n\tfc_usb = fc->bus_specific;\n\tfc_usb->fc_dev = fc;\n\tmutex_init(&fc_usb->data_mutex);\n\n\tfc->read_ibi_reg  = flexcop_usb_read_ibi_reg;\n\tfc->write_ibi_reg = flexcop_usb_write_ibi_reg;\n\tfc->i2c_request = flexcop_usb_i2c_request;\n\tfc->get_mac_addr = flexcop_usb_get_mac_addr;\n\n\tfc->stream_control = flexcop_usb_stream_control;\n\n\tfc->pid_filtering = 1;\n\tfc->bus_type = FC_USB;\n\n\tfc->dev = &udev->dev;\n\tfc->owner = THIS_MODULE;\n\n\t/* bus specific part */\n\tfc_usb->udev = udev;\n\tfc_usb->uintf = intf;\n\tif ((ret = flexcop_usb_init(fc_usb)) != 0)\n\t\tgoto err_kfree;\n\n\t/* init flexcop */\n\tif ((ret = flexcop_device_initialize(fc)) != 0)\n\t\tgoto err_usb_exit;\n\n\t/* xfer init */\n\tif ((ret = flexcop_usb_transfer_init(fc_usb)) != 0)\n\t\tgoto err_fc_exit;\n\n\tinfo(\"%s successfully initialized and connected.\", DRIVER_NAME);\n\treturn 0;\n\nerr_fc_exit:\n\tflexcop_device_exit(fc);\nerr_usb_exit:\n\tflexcop_usb_exit(fc_usb);\nerr_kfree:\n\tflexcop_device_kfree(fc);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tstruct flexcop_usb *fc_usb = NULL;\n \tstruct flexcop_device *fc = NULL;\n \tint ret;\n+\n+\tif (intf->cur_altsetting->desc.bNumEndpoints < 1)\n+\t\treturn -ENODEV;\n \n \tif ((fc = flexcop_device_kmalloc(sizeof(struct flexcop_usb))) == NULL) {\n \t\terr(\"out of memory\\n\");",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (intf->cur_altsetting->desc.bNumEndpoints < 1)",
                "\t\treturn -ENODEV;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.2.9. There is a NULL pointer dereference caused by a malicious USB device in the flexcop_usb_probe function in the drivers/media/usb/b2c2/flexcop-usb.c driver.",
        "id": 2014
    },
    {
        "cve_id": "CVE-2019-12378",
        "code_before_change": "int ip6_ra_control(struct sock *sk, int sel)\n{\n\tstruct ip6_ra_chain *ra, *new_ra, **rap;\n\n\t/* RA packet may be delivered ONLY to IPPROTO_RAW socket */\n\tif (sk->sk_type != SOCK_RAW || inet_sk(sk)->inet_num != IPPROTO_RAW)\n\t\treturn -ENOPROTOOPT;\n\n\tnew_ra = (sel >= 0) ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n\n\twrite_lock_bh(&ip6_ra_lock);\n\tfor (rap = &ip6_ra_chain; (ra = *rap) != NULL; rap = &ra->next) {\n\t\tif (ra->sk == sk) {\n\t\t\tif (sel >= 0) {\n\t\t\t\twrite_unlock_bh(&ip6_ra_lock);\n\t\t\t\tkfree(new_ra);\n\t\t\t\treturn -EADDRINUSE;\n\t\t\t}\n\n\t\t\t*rap = ra->next;\n\t\t\twrite_unlock_bh(&ip6_ra_lock);\n\n\t\t\tsock_put(sk);\n\t\t\tkfree(ra);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (!new_ra) {\n\t\twrite_unlock_bh(&ip6_ra_lock);\n\t\treturn -ENOBUFS;\n\t}\n\tnew_ra->sk = sk;\n\tnew_ra->sel = sel;\n\tnew_ra->next = ra;\n\t*rap = new_ra;\n\tsock_hold(sk);\n\twrite_unlock_bh(&ip6_ra_lock);\n\treturn 0;\n}",
        "code_after_change": "int ip6_ra_control(struct sock *sk, int sel)\n{\n\tstruct ip6_ra_chain *ra, *new_ra, **rap;\n\n\t/* RA packet may be delivered ONLY to IPPROTO_RAW socket */\n\tif (sk->sk_type != SOCK_RAW || inet_sk(sk)->inet_num != IPPROTO_RAW)\n\t\treturn -ENOPROTOOPT;\n\n\tnew_ra = (sel >= 0) ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n\tif (sel >= 0 && !new_ra)\n\t\treturn -ENOMEM;\n\n\twrite_lock_bh(&ip6_ra_lock);\n\tfor (rap = &ip6_ra_chain; (ra = *rap) != NULL; rap = &ra->next) {\n\t\tif (ra->sk == sk) {\n\t\t\tif (sel >= 0) {\n\t\t\t\twrite_unlock_bh(&ip6_ra_lock);\n\t\t\t\tkfree(new_ra);\n\t\t\t\treturn -EADDRINUSE;\n\t\t\t}\n\n\t\t\t*rap = ra->next;\n\t\t\twrite_unlock_bh(&ip6_ra_lock);\n\n\t\t\tsock_put(sk);\n\t\t\tkfree(ra);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (!new_ra) {\n\t\twrite_unlock_bh(&ip6_ra_lock);\n\t\treturn -ENOBUFS;\n\t}\n\tnew_ra->sk = sk;\n\tnew_ra->sel = sel;\n\tnew_ra->next = ra;\n\t*rap = new_ra;\n\tsock_hold(sk);\n\twrite_unlock_bh(&ip6_ra_lock);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,8 @@\n \t\treturn -ENOPROTOOPT;\n \n \tnew_ra = (sel >= 0) ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n+\tif (sel >= 0 && !new_ra)\n+\t\treturn -ENOMEM;\n \n \twrite_lock_bh(&ip6_ra_lock);\n \tfor (rap = &ip6_ra_chain; (ra = *rap) != NULL; rap = &ra->next) {",
        "function_modified_lines": {
            "added": [
                "\tif (sel >= 0 && !new_ra)",
                "\t\treturn -ENOMEM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in ip6_ra_control in net/ipv6/ipv6_sockglue.c in the Linux kernel through 5.1.5. There is an unchecked kmalloc of new_ra, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash). NOTE: This has been disputed as not an issue",
        "id": 1939
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "int btrfs_scrub_progress(struct btrfs_fs_info *fs_info, u64 devid,\n\t\t\t struct btrfs_scrub_progress *progress)\n{\n\tstruct btrfs_device *dev;\n\tstruct scrub_ctx *sctx = NULL;\n\n\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n\tif (dev)\n\t\tsctx = dev->scrub_ctx;\n\tif (sctx)\n\t\tmemcpy(progress, &sctx->stat, sizeof(*progress));\n\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\n\treturn dev ? (sctx ? 0 : -ENOTCONN) : -ENODEV;\n}",
        "code_after_change": "int btrfs_scrub_progress(struct btrfs_fs_info *fs_info, u64 devid,\n\t\t\t struct btrfs_scrub_progress *progress)\n{\n\tstruct btrfs_device *dev;\n\tstruct scrub_ctx *sctx = NULL;\n\n\tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n\tif (dev)\n\t\tsctx = dev->scrub_ctx;\n\tif (sctx)\n\t\tmemcpy(progress, &sctx->stat, sizeof(*progress));\n\tmutex_unlock(&fs_info->fs_devices->device_list_mutex);\n\n\treturn dev ? (sctx ? 0 : -ENOTCONN) : -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tstruct scrub_ctx *sctx = NULL;\n \n \tmutex_lock(&fs_info->fs_devices->device_list_mutex);\n-\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n+\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n \tif (dev)\n \t\tsctx = dev->scrub_ctx;\n \tif (sctx)",
        "function_modified_lines": {
            "added": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);"
            ],
            "deleted": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2111
    },
    {
        "cve_id": "CVE-2019-19227",
        "code_before_change": "void __init aarp_proto_init(void)\n{\n\taarp_dl = register_snap_client(aarp_snap_id, aarp_rcv);\n\tif (!aarp_dl)\n\t\tprintk(KERN_CRIT \"Unable to register AARP with SNAP.\\n\");\n\ttimer_setup(&aarp_timer, aarp_expire_timeout, 0);\n\taarp_timer.expires  = jiffies + sysctl_aarp_expiry_time;\n\tadd_timer(&aarp_timer);\n\tregister_netdevice_notifier(&aarp_notifier);\n}",
        "code_after_change": "int __init aarp_proto_init(void)\n{\n\tint rc;\n\n\taarp_dl = register_snap_client(aarp_snap_id, aarp_rcv);\n\tif (!aarp_dl) {\n\t\tprintk(KERN_CRIT \"Unable to register AARP with SNAP.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\ttimer_setup(&aarp_timer, aarp_expire_timeout, 0);\n\taarp_timer.expires  = jiffies + sysctl_aarp_expiry_time;\n\tadd_timer(&aarp_timer);\n\trc = register_netdevice_notifier(&aarp_notifier);\n\tif (rc) {\n\t\tdel_timer_sync(&aarp_timer);\n\t\tunregister_snap_client(aarp_dl);\n\t}\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,19 @@\n-void __init aarp_proto_init(void)\n+int __init aarp_proto_init(void)\n {\n+\tint rc;\n+\n \taarp_dl = register_snap_client(aarp_snap_id, aarp_rcv);\n-\tif (!aarp_dl)\n+\tif (!aarp_dl) {\n \t\tprintk(KERN_CRIT \"Unable to register AARP with SNAP.\\n\");\n+\t\treturn -ENOMEM;\n+\t}\n \ttimer_setup(&aarp_timer, aarp_expire_timeout, 0);\n \taarp_timer.expires  = jiffies + sysctl_aarp_expiry_time;\n \tadd_timer(&aarp_timer);\n-\tregister_netdevice_notifier(&aarp_notifier);\n+\trc = register_netdevice_notifier(&aarp_notifier);\n+\tif (rc) {\n+\t\tdel_timer_sync(&aarp_timer);\n+\t\tunregister_snap_client(aarp_dl);\n+\t}\n+\treturn rc;\n }",
        "function_modified_lines": {
            "added": [
                "int __init aarp_proto_init(void)",
                "\tint rc;",
                "",
                "\tif (!aarp_dl) {",
                "\t\treturn -ENOMEM;",
                "\t}",
                "\trc = register_netdevice_notifier(&aarp_notifier);",
                "\tif (rc) {",
                "\t\tdel_timer_sync(&aarp_timer);",
                "\t\tunregister_snap_client(aarp_dl);",
                "\t}",
                "\treturn rc;"
            ],
            "deleted": [
                "void __init aarp_proto_init(void)",
                "\tif (!aarp_dl)",
                "\tregister_netdevice_notifier(&aarp_notifier);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the AppleTalk subsystem in the Linux kernel before 5.1, there is a potential NULL pointer dereference because register_snap_client may return NULL. This will lead to denial of service in net/appletalk/aarp.c and net/appletalk/ddp.c, as demonstrated by unregister_snap_client, aka CID-9804501fa122.",
        "id": 2177
    },
    {
        "cve_id": "CVE-2019-15223",
        "code_before_change": "static int toneport_init(struct usb_line6 *line6,\n\t\t\t const struct usb_device_id *id)\n{\n\tint err;\n\tstruct usb_line6_toneport *toneport =  (struct usb_line6_toneport *) line6;\n\n\ttoneport->type = id->driver_info;\n\tINIT_DELAYED_WORK(&toneport->pcm_work, toneport_start_pcm);\n\n\tline6->disconnect = line6_toneport_disconnect;\n\n\t/* initialize PCM subsystem: */\n\terr = line6_init_pcm(line6, &toneport_pcm_properties);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* register monitor control: */\n\terr = snd_ctl_add(line6->card,\n\t\t\t  snd_ctl_new1(&toneport_control_monitor,\n\t\t\t\t       line6->line6pcm));\n\tif (err < 0)\n\t\treturn err;\n\n\t/* register source select control: */\n\tif (toneport_has_source_select(toneport)) {\n\t\terr =\n\t\t    snd_ctl_add(line6->card,\n\t\t\t\tsnd_ctl_new1(&toneport_control_source,\n\t\t\t\t\t     line6->line6pcm));\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tline6_read_serial_number(line6, &toneport->serial_number);\n\tline6_read_data(line6, 0x80c2, &toneport->firmware_version, 1);\n\n\tif (toneport_has_led(toneport)) {\n\t\terr = toneport_init_leds(toneport);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\terr = toneport_setup(toneport);\n\tif (err)\n\t\treturn err;\n\n\t/* register audio system: */\n\treturn snd_card_register(line6->card);\n}",
        "code_after_change": "static int toneport_init(struct usb_line6 *line6,\n\t\t\t const struct usb_device_id *id)\n{\n\tint err;\n\tstruct usb_line6_toneport *toneport =  (struct usb_line6_toneport *) line6;\n\n\ttoneport->type = id->driver_info;\n\n\tline6->disconnect = line6_toneport_disconnect;\n\tline6->startup = toneport_startup;\n\n\t/* initialize PCM subsystem: */\n\terr = line6_init_pcm(line6, &toneport_pcm_properties);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* register monitor control: */\n\terr = snd_ctl_add(line6->card,\n\t\t\t  snd_ctl_new1(&toneport_control_monitor,\n\t\t\t\t       line6->line6pcm));\n\tif (err < 0)\n\t\treturn err;\n\n\t/* register source select control: */\n\tif (toneport_has_source_select(toneport)) {\n\t\terr =\n\t\t    snd_ctl_add(line6->card,\n\t\t\t\tsnd_ctl_new1(&toneport_control_source,\n\t\t\t\t\t     line6->line6pcm));\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\tline6_read_serial_number(line6, &toneport->serial_number);\n\tline6_read_data(line6, 0x80c2, &toneport->firmware_version, 1);\n\n\tif (toneport_has_led(toneport)) {\n\t\terr = toneport_init_leds(toneport);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\terr = toneport_setup(toneport);\n\tif (err)\n\t\treturn err;\n\n\t/* register audio system: */\n\treturn snd_card_register(line6->card);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,9 +5,9 @@\n \tstruct usb_line6_toneport *toneport =  (struct usb_line6_toneport *) line6;\n \n \ttoneport->type = id->driver_info;\n-\tINIT_DELAYED_WORK(&toneport->pcm_work, toneport_start_pcm);\n \n \tline6->disconnect = line6_toneport_disconnect;\n+\tline6->startup = toneport_startup;\n \n \t/* initialize PCM subsystem: */\n \terr = line6_init_pcm(line6, &toneport_pcm_properties);",
        "function_modified_lines": {
            "added": [
                "\tline6->startup = toneport_startup;"
            ],
            "deleted": [
                "\tINIT_DELAYED_WORK(&toneport->pcm_work, toneport_start_pcm);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/line6/driver.c driver.",
        "id": 2011
    },
    {
        "cve_id": "CVE-2017-12192",
        "code_before_change": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}",
        "code_after_change": "long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)\n{\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tlong ret;\n\n\t/* find the key first */\n\tkey_ref = lookup_user_key(keyid, 0, 0);\n\tif (IS_ERR(key_ref)) {\n\t\tret = -ENOKEY;\n\t\tgoto error;\n\t}\n\n\tkey = key_ref_to_ptr(key_ref);\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {\n\t\tret = -ENOKEY;\n\t\tgoto error2;\n\t}\n\n\t/* see if we can read it directly */\n\tret = key_permission(key_ref, KEY_NEED_READ);\n\tif (ret == 0)\n\t\tgoto can_read_key;\n\tif (ret != -EACCES)\n\t\tgoto error2;\n\n\t/* we can't; see if it's searchable from this process's keyrings\n\t * - we automatically take account of the fact that it may be\n\t *   dangling off an instantiation key\n\t */\n\tif (!is_key_possessed(key_ref)) {\n\t\tret = -EACCES;\n\t\tgoto error2;\n\t}\n\n\t/* the key is probably readable - now try to read it */\ncan_read_key:\n\tret = -EOPNOTSUPP;\n\tif (key->type->read) {\n\t\t/* Read the data with the semaphore held (since we might sleep)\n\t\t * to protect against the key being updated or revoked.\n\t\t */\n\t\tdown_read(&key->sem);\n\t\tret = key_validate(key);\n\t\tif (ret == 0)\n\t\t\tret = key->type->read(key, buffer, buflen);\n\t\tup_read(&key->sem);\n\t}\n\nerror2:\n\tkey_put(key);\nerror:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,6 +12,11 @@\n \t}\n \n \tkey = key_ref_to_ptr(key_ref);\n+\n+\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {\n+\t\tret = -ENOKEY;\n+\t\tgoto error2;\n+\t}\n \n \t/* see if we can read it directly */\n \tret = key_permission(key_ref, KEY_NEED_READ);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags)) {",
                "\t\tret = -ENOKEY;",
                "\t\tgoto error2;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The keyctl_read_key function in security/keys/keyctl.c in the Key Management subcomponent in the Linux kernel before 4.13.5 does not properly consider that a key may be possessed but negatively instantiated, which allows local users to cause a denial of service (OOPS and system crash) via a crafted KEYCTL_READ operation.",
        "id": 1261
    },
    {
        "cve_id": "CVE-2020-25285",
        "code_before_change": "static int hugetlb_sysctl_handler_common(bool obey_mempolicy,\n\t\t\t struct ctl_table *table, int write,\n\t\t\t void *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp = h->max_huge_pages;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttable->data = &tmp;\n\ttable->maxlen = sizeof(unsigned long);\n\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write)\n\t\tret = __nr_hugepages_store_common(obey_mempolicy, h,\n\t\t\t\t\t\t  NUMA_NO_NODE, tmp, *length);\nout:\n\treturn ret;\n}",
        "code_after_change": "static int hugetlb_sysctl_handler_common(bool obey_mempolicy,\n\t\t\t struct ctl_table *table, int write,\n\t\t\t void *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp = h->max_huge_pages;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n\t\t\t\t\t     &tmp);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write)\n\t\tret = __nr_hugepages_store_common(obey_mempolicy, h,\n\t\t\t\t\t\t  NUMA_NO_NODE, tmp, *length);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,9 +9,8 @@\n \tif (!hugepages_supported())\n \t\treturn -EOPNOTSUPP;\n \n-\ttable->data = &tmp;\n-\ttable->maxlen = sizeof(unsigned long);\n-\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n+\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n+\t\t\t\t\t     &tmp);\n \tif (ret)\n \t\tgoto out;\n ",
        "function_modified_lines": {
            "added": [
                "\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,",
                "\t\t\t\t\t     &tmp);"
            ],
            "deleted": [
                "\ttable->data = &tmp;",
                "\ttable->maxlen = sizeof(unsigned long);",
                "\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-787",
            "CWE-476"
        ],
        "cve_description": "A race condition between hugetlb sysctl handlers in mm/hugetlb.c in the Linux kernel before 5.8.8 could be used by local attackers to corrupt memory, cause a NULL pointer dereference, or possibly have unspecified other impact, aka CID-17743798d812.",
        "id": 2587
    },
    {
        "cve_id": "CVE-2023-28327",
        "code_before_change": "static int unix_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tint num, s_num, slot, s_slot;\n\tstruct unix_diag_req *req;\n\n\treq = nlmsg_data(cb->nlh);\n\n\ts_slot = cb->args[0];\n\tnum = s_num = cb->args[1];\n\n\tfor (slot = s_slot; slot < UNIX_HASH_SIZE; s_num = 0, slot++) {\n\t\tstruct sock *sk;\n\n\t\tnum = 0;\n\t\tspin_lock(&net->unx.table.locks[slot]);\n\t\tsk_for_each(sk, &net->unx.table.buckets[slot]) {\n\t\t\tif (num < s_num)\n\t\t\t\tgoto next;\n\t\t\tif (!(req->udiag_states & (1 << sk->sk_state)))\n\t\t\t\tgoto next;\n\t\t\tif (sk_diag_dump(sk, skb, req,\n\t\t\t\t\t NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t cb->nlh->nlmsg_seq,\n\t\t\t\t\t NLM_F_MULTI) < 0) {\n\t\t\t\tspin_unlock(&net->unx.table.locks[slot]);\n\t\t\t\tgoto done;\n\t\t\t}\nnext:\n\t\t\tnum++;\n\t\t}\n\t\tspin_unlock(&net->unx.table.locks[slot]);\n\t}\ndone:\n\tcb->args[0] = slot;\n\tcb->args[1] = num;\n\n\treturn skb->len;\n}",
        "code_after_change": "static int unix_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tint num, s_num, slot, s_slot;\n\tstruct unix_diag_req *req;\n\n\treq = nlmsg_data(cb->nlh);\n\n\ts_slot = cb->args[0];\n\tnum = s_num = cb->args[1];\n\n\tfor (slot = s_slot; slot < UNIX_HASH_SIZE; s_num = 0, slot++) {\n\t\tstruct sock *sk;\n\n\t\tnum = 0;\n\t\tspin_lock(&net->unx.table.locks[slot]);\n\t\tsk_for_each(sk, &net->unx.table.buckets[slot]) {\n\t\t\tif (num < s_num)\n\t\t\t\tgoto next;\n\t\t\tif (!(req->udiag_states & (1 << sk->sk_state)))\n\t\t\t\tgoto next;\n\t\t\tif (sk_diag_dump(sk, skb, req, sk_user_ns(skb->sk),\n\t\t\t\t\t NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t cb->nlh->nlmsg_seq,\n\t\t\t\t\t NLM_F_MULTI) < 0) {\n\t\t\t\tspin_unlock(&net->unx.table.locks[slot]);\n\t\t\t\tgoto done;\n\t\t\t}\nnext:\n\t\t\tnum++;\n\t\t}\n\t\tspin_unlock(&net->unx.table.locks[slot]);\n\t}\ndone:\n\tcb->args[0] = slot;\n\tcb->args[1] = num;\n\n\treturn skb->len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \t\t\t\tgoto next;\n \t\t\tif (!(req->udiag_states & (1 << sk->sk_state)))\n \t\t\t\tgoto next;\n-\t\t\tif (sk_diag_dump(sk, skb, req,\n+\t\t\tif (sk_diag_dump(sk, skb, req, sk_user_ns(skb->sk),\n \t\t\t\t\t NETLINK_CB(cb->skb).portid,\n \t\t\t\t\t cb->nlh->nlmsg_seq,\n \t\t\t\t\t NLM_F_MULTI) < 0) {",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (sk_diag_dump(sk, skb, req, sk_user_ns(skb->sk),"
            ],
            "deleted": [
                "\t\t\tif (sk_diag_dump(sk, skb, req,"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the UNIX protocol in net/unix/diag.c In unix_diag_get_exact in the Linux Kernel. The newly allocated skb does not have sk, leading to a NULL pointer. This flaw allows a local user to crash or potentially cause a denial of service.",
        "id": 3974
    },
    {
        "cve_id": "CVE-2017-12193",
        "code_before_change": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (assoc_array_ptr_is_leaf(ptr) &&\n\t\t    ops->compare_object(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\tindex_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}",
        "code_after_change": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (assoc_array_ptr_is_leaf(ptr) &&\n\t\t    ops->compare_object(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\tindex_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise all the old leaves cluster in the same slot, but\n\t\t * the new leaf wants to go into a different slot - so we\n\t\t * create a new node (n0) to hold the new leaf and a pointer to\n\t\t * a new node (n1) holding all the old leaves.\n\t\t *\n\t\t * This can be done by falling through to the node splitting\n\t\t * path.\n\t\t */\n\t\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node.  The node must contain anything\n\t * from a single leaf (in the one leaf case, this leaf will cluster\n\t * with the new leaf) and the rest meta-pointers, to all leaves, some\n\t * of which may cluster.\n\t *\n\t * It won't contain the case in which all the current leaves plus the\n\t * new leaves want to cluster in the same slot.\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.  The current meta pointers can\n\t * just be copied as they shouldn't cluster with any of the leaves.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}",
        "patch": "--- code before\n+++ code after\n@@ -108,21 +108,31 @@\n \t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n \t\t\tgoto all_leaves_cluster_together;\n \n-\t\t/* Otherwise we can just insert a new node ahead of the old\n-\t\t * one.\n+\t\t/* Otherwise all the old leaves cluster in the same slot, but\n+\t\t * the new leaf wants to go into a different slot - so we\n+\t\t * create a new node (n0) to hold the new leaf and a pointer to\n+\t\t * a new node (n1) holding all the old leaves.\n+\t\t *\n+\t\t * This can be done by falling through to the node splitting\n+\t\t * path.\n \t\t */\n-\t\tgoto present_leaves_cluster_but_not_new_leaf;\n+\t\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n \t}\n \n split_node:\n \tpr_devel(\"split node\\n\");\n \n-\t/* We need to split the current node; we know that the node doesn't\n-\t * simply contain a full set of leaves that cluster together (it\n-\t * contains meta pointers and/or non-clustering leaves).\n+\t/* We need to split the current node.  The node must contain anything\n+\t * from a single leaf (in the one leaf case, this leaf will cluster\n+\t * with the new leaf) and the rest meta-pointers, to all leaves, some\n+\t * of which may cluster.\n+\t *\n+\t * It won't contain the case in which all the current leaves plus the\n+\t * new leaves want to cluster in the same slot.\n \t *\n \t * We need to expel at least two leaves out of a set consisting of the\n-\t * leaves in the node and the new leaf.\n+\t * leaves in the node and the new leaf.  The current meta pointers can\n+\t * just be copied as they shouldn't cluster with any of the leaves.\n \t *\n \t * We need a new node (n0) to replace the current one and a new node to\n \t * take the expelled nodes (n1).\n@@ -227,33 +237,6 @@\n \tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n \treturn true;\n \n-present_leaves_cluster_but_not_new_leaf:\n-\t/* All the old leaves cluster in the same slot, but the new leaf wants\n-\t * to go into a different slot, so we create a new node to hold the new\n-\t * leaf and a pointer to a new node holding all the old leaves.\n-\t */\n-\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n-\n-\tnew_n0->back_pointer = node->back_pointer;\n-\tnew_n0->parent_slot = node->parent_slot;\n-\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n-\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n-\tnew_n1->parent_slot = edit->segment_cache[0];\n-\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n-\tedit->adjust_count_on = new_n0;\n-\n-\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n-\t\tnew_n1->slots[i] = node->slots[i];\n-\n-\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n-\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n-\n-\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n-\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n-\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n-\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n-\treturn true;\n-\n all_leaves_cluster_together:\n \t/* All the leaves, new and old, want to cluster together in this node\n \t * in the same slot, so we have to replace this node with a shortcut to",
        "function_modified_lines": {
            "added": [
                "\t\t/* Otherwise all the old leaves cluster in the same slot, but",
                "\t\t * the new leaf wants to go into a different slot - so we",
                "\t\t * create a new node (n0) to hold the new leaf and a pointer to",
                "\t\t * a new node (n1) holding all the old leaves.",
                "\t\t *",
                "\t\t * This can be done by falling through to the node splitting",
                "\t\t * path.",
                "\t\tpr_devel(\"present leaves cluster but not new leaf\\n\");",
                "\t/* We need to split the current node.  The node must contain anything",
                "\t * from a single leaf (in the one leaf case, this leaf will cluster",
                "\t * with the new leaf) and the rest meta-pointers, to all leaves, some",
                "\t * of which may cluster.",
                "\t *",
                "\t * It won't contain the case in which all the current leaves plus the",
                "\t * new leaves want to cluster in the same slot.",
                "\t * leaves in the node and the new leaf.  The current meta pointers can",
                "\t * just be copied as they shouldn't cluster with any of the leaves."
            ],
            "deleted": [
                "\t\t/* Otherwise we can just insert a new node ahead of the old",
                "\t\t * one.",
                "\t\tgoto present_leaves_cluster_but_not_new_leaf;",
                "\t/* We need to split the current node; we know that the node doesn't",
                "\t * simply contain a full set of leaves that cluster together (it",
                "\t * contains meta pointers and/or non-clustering leaves).",
                "\t * leaves in the node and the new leaf.",
                "present_leaves_cluster_but_not_new_leaf:",
                "\t/* All the old leaves cluster in the same slot, but the new leaf wants",
                "\t * to go into a different slot, so we create a new node to hold the new",
                "\t * leaf and a pointer to a new node holding all the old leaves.",
                "\t */",
                "\tpr_devel(\"present leaves cluster but not new leaf\\n\");",
                "",
                "\tnew_n0->back_pointer = node->back_pointer;",
                "\tnew_n0->parent_slot = node->parent_slot;",
                "\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;",
                "\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);",
                "\tnew_n1->parent_slot = edit->segment_cache[0];",
                "\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;",
                "\tedit->adjust_count_on = new_n0;",
                "",
                "\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)",
                "\t\tnew_n1->slots[i] = node->slots[i];",
                "",
                "\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);",
                "\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];",
                "",
                "\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];",
                "\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);",
                "\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);",
                "\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);",
                "\treturn true;",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The assoc_array_insert_into_terminal_node function in lib/assoc_array.c in the Linux kernel before 4.13.11 mishandles node splitting, which allows local users to cause a denial of service (NULL pointer dereference and panic) via a crafted application, as demonstrated by the keyring key type, and key addition and link creation operations.",
        "id": 1262
    },
    {
        "cve_id": "CVE-2022-3110",
        "code_before_change": "s32\t_rtw_init_xmit_priv(struct xmit_priv *pxmitpriv, struct adapter *padapter)\n{\n\tint i;\n\tstruct xmit_buf *pxmitbuf;\n\tstruct xmit_frame *pxframe;\n\tint\tres = _SUCCESS;\n\tu32 max_xmit_extbuf_size = MAX_XMIT_EXTBUF_SZ;\n\tu32 num_xmit_extbuf = NR_XMIT_EXTBUFF;\n\n\t/*  We don't need to memset padapter->XXX to zero, because adapter is allocated by vzalloc(). */\n\n\tspin_lock_init(&pxmitpriv->lock);\n\tsema_init(&pxmitpriv->terminate_xmitthread_sema, 0);\n\n\t/*\n\t * Please insert all the queue initializaiton using rtw_init_queue below\n\t */\n\n\tpxmitpriv->adapter = padapter;\n\n\trtw_init_queue(&pxmitpriv->be_pending);\n\trtw_init_queue(&pxmitpriv->bk_pending);\n\trtw_init_queue(&pxmitpriv->vi_pending);\n\trtw_init_queue(&pxmitpriv->vo_pending);\n\trtw_init_queue(&pxmitpriv->bm_pending);\n\n\trtw_init_queue(&pxmitpriv->free_xmit_queue);\n\n\t/*\n\t * Please allocate memory with the sz = (struct xmit_frame) * NR_XMITFRAME,\n\t * and initialize free_xmit_frame below.\n\t * Please also apply  free_txobj to link_up all the xmit_frames...\n\t */\n\n\tpxmitpriv->pallocated_frame_buf = vzalloc(NR_XMITFRAME * sizeof(struct xmit_frame) + 4);\n\n\tif (!pxmitpriv->pallocated_frame_buf) {\n\t\tpxmitpriv->pxmit_frame_buf = NULL;\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\tpxmitpriv->pxmit_frame_buf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_frame_buf), 4);\n\t/* pxmitpriv->pxmit_frame_buf = pxmitpriv->pallocated_frame_buf + 4 - */\n\t/* \t\t\t\t\t\t((size_t) (pxmitpriv->pallocated_frame_buf) &3); */\n\n\tpxframe = (struct xmit_frame *)pxmitpriv->pxmit_frame_buf;\n\n\tfor (i = 0; i < NR_XMITFRAME; i++) {\n\t\tINIT_LIST_HEAD(&pxframe->list);\n\n\t\tpxframe->padapter = padapter;\n\t\tpxframe->frame_tag = NULL_FRAMETAG;\n\n\t\tpxframe->pkt = NULL;\n\n\t\tpxframe->buf_addr = NULL;\n\t\tpxframe->pxmitbuf = NULL;\n\n\t\tlist_add_tail(&pxframe->list, &pxmitpriv->free_xmit_queue.queue);\n\n\t\tpxframe++;\n\t}\n\n\tpxmitpriv->free_xmitframe_cnt = NR_XMITFRAME;\n\n\tpxmitpriv->frag_len = MAX_FRAG_THRESHOLD;\n\n\t/* init xmit_buf */\n\trtw_init_queue(&pxmitpriv->free_xmitbuf_queue);\n\trtw_init_queue(&pxmitpriv->pending_xmitbuf_queue);\n\n\tpxmitpriv->pallocated_xmitbuf = vzalloc(NR_XMITBUFF * sizeof(struct xmit_buf) + 4);\n\n\tif (!pxmitpriv->pallocated_xmitbuf) {\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\n\tpxmitpriv->pxmitbuf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_xmitbuf), 4);\n\t/* pxmitpriv->pxmitbuf = pxmitpriv->pallocated_xmitbuf + 4 - */\n\t/* \t\t\t\t\t\t((size_t) (pxmitpriv->pallocated_xmitbuf) &3); */\n\n\tpxmitbuf = (struct xmit_buf *)pxmitpriv->pxmitbuf;\n\n\tfor (i = 0; i < NR_XMITBUFF; i++) {\n\t\tINIT_LIST_HEAD(&pxmitbuf->list);\n\n\t\tpxmitbuf->priv_data = NULL;\n\t\tpxmitbuf->padapter = padapter;\n\t\tpxmitbuf->ext_tag = false;\n\n\t\t/* Tx buf allocation may fail sometimes, so sleep and retry. */\n\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, (MAX_XMITBUF_SZ + XMITBUF_ALIGN_SZ));\n\t\tif (res == _FAIL) {\n\t\t\tmsleep(10);\n\t\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, (MAX_XMITBUF_SZ + XMITBUF_ALIGN_SZ));\n\t\t\tif (res == _FAIL)\n\t\t\t\tgoto exit;\n\t\t}\n\n\t\tpxmitbuf->flags = XMIT_VO_QUEUE;\n\n\t\tlist_add_tail(&pxmitbuf->list, &pxmitpriv->free_xmitbuf_queue.queue);\n\t\tpxmitbuf++;\n\t}\n\n\tpxmitpriv->free_xmitbuf_cnt = NR_XMITBUFF;\n\n\t/*  Init xmit extension buff */\n\trtw_init_queue(&pxmitpriv->free_xmit_extbuf_queue);\n\n\tpxmitpriv->pallocated_xmit_extbuf = vzalloc(num_xmit_extbuf * sizeof(struct xmit_buf) + 4);\n\n\tif (!pxmitpriv->pallocated_xmit_extbuf) {\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\n\tpxmitpriv->pxmit_extbuf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_xmit_extbuf), 4);\n\n\tpxmitbuf = (struct xmit_buf *)pxmitpriv->pxmit_extbuf;\n\n\tfor (i = 0; i < num_xmit_extbuf; i++) {\n\t\tINIT_LIST_HEAD(&pxmitbuf->list);\n\n\t\tpxmitbuf->priv_data = NULL;\n\t\tpxmitbuf->padapter = padapter;\n\t\tpxmitbuf->ext_tag = true;\n\n\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, max_xmit_extbuf_size + XMITBUF_ALIGN_SZ);\n\t\tif (res == _FAIL) {\n\t\t\tres = _FAIL;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tlist_add_tail(&pxmitbuf->list, &pxmitpriv->free_xmit_extbuf_queue.queue);\n\t\tpxmitbuf++;\n\t}\n\n\tpxmitpriv->free_xmit_extbuf_cnt = num_xmit_extbuf;\n\n\trtw_alloc_hwxmits(padapter);\n\trtw_init_hwxmits(pxmitpriv->hwxmits, pxmitpriv->hwxmit_entry);\n\n\tfor (i = 0; i < 4; i++)\n\t\tpxmitpriv->wmm_para_seq[i] = i;\n\n\tpxmitpriv->txirp_cnt = 1;\n\n\tsema_init(&pxmitpriv->tx_retevt, 0);\n\n\t/* per AC pending irp */\n\tpxmitpriv->beq_cnt = 0;\n\tpxmitpriv->bkq_cnt = 0;\n\tpxmitpriv->viq_cnt = 0;\n\tpxmitpriv->voq_cnt = 0;\n\n\tpxmitpriv->ack_tx = false;\n\tmutex_init(&pxmitpriv->ack_tx_mutex);\n\trtw_sctx_init(&pxmitpriv->ack_tx_ops, 0);\n\n\trtl8188eu_init_xmit_priv(padapter);\n\nexit:\n\n\treturn res;\n}",
        "code_after_change": "s32\t_rtw_init_xmit_priv(struct xmit_priv *pxmitpriv, struct adapter *padapter)\n{\n\tint i;\n\tstruct xmit_buf *pxmitbuf;\n\tstruct xmit_frame *pxframe;\n\tint\tres = _SUCCESS;\n\tu32 max_xmit_extbuf_size = MAX_XMIT_EXTBUF_SZ;\n\tu32 num_xmit_extbuf = NR_XMIT_EXTBUFF;\n\n\t/*  We don't need to memset padapter->XXX to zero, because adapter is allocated by vzalloc(). */\n\n\tspin_lock_init(&pxmitpriv->lock);\n\tsema_init(&pxmitpriv->terminate_xmitthread_sema, 0);\n\n\t/*\n\t * Please insert all the queue initializaiton using rtw_init_queue below\n\t */\n\n\tpxmitpriv->adapter = padapter;\n\n\trtw_init_queue(&pxmitpriv->be_pending);\n\trtw_init_queue(&pxmitpriv->bk_pending);\n\trtw_init_queue(&pxmitpriv->vi_pending);\n\trtw_init_queue(&pxmitpriv->vo_pending);\n\trtw_init_queue(&pxmitpriv->bm_pending);\n\n\trtw_init_queue(&pxmitpriv->free_xmit_queue);\n\n\t/*\n\t * Please allocate memory with the sz = (struct xmit_frame) * NR_XMITFRAME,\n\t * and initialize free_xmit_frame below.\n\t * Please also apply  free_txobj to link_up all the xmit_frames...\n\t */\n\n\tpxmitpriv->pallocated_frame_buf = vzalloc(NR_XMITFRAME * sizeof(struct xmit_frame) + 4);\n\n\tif (!pxmitpriv->pallocated_frame_buf) {\n\t\tpxmitpriv->pxmit_frame_buf = NULL;\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\tpxmitpriv->pxmit_frame_buf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_frame_buf), 4);\n\t/* pxmitpriv->pxmit_frame_buf = pxmitpriv->pallocated_frame_buf + 4 - */\n\t/* \t\t\t\t\t\t((size_t) (pxmitpriv->pallocated_frame_buf) &3); */\n\n\tpxframe = (struct xmit_frame *)pxmitpriv->pxmit_frame_buf;\n\n\tfor (i = 0; i < NR_XMITFRAME; i++) {\n\t\tINIT_LIST_HEAD(&pxframe->list);\n\n\t\tpxframe->padapter = padapter;\n\t\tpxframe->frame_tag = NULL_FRAMETAG;\n\n\t\tpxframe->pkt = NULL;\n\n\t\tpxframe->buf_addr = NULL;\n\t\tpxframe->pxmitbuf = NULL;\n\n\t\tlist_add_tail(&pxframe->list, &pxmitpriv->free_xmit_queue.queue);\n\n\t\tpxframe++;\n\t}\n\n\tpxmitpriv->free_xmitframe_cnt = NR_XMITFRAME;\n\n\tpxmitpriv->frag_len = MAX_FRAG_THRESHOLD;\n\n\t/* init xmit_buf */\n\trtw_init_queue(&pxmitpriv->free_xmitbuf_queue);\n\trtw_init_queue(&pxmitpriv->pending_xmitbuf_queue);\n\n\tpxmitpriv->pallocated_xmitbuf = vzalloc(NR_XMITBUFF * sizeof(struct xmit_buf) + 4);\n\n\tif (!pxmitpriv->pallocated_xmitbuf) {\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\n\tpxmitpriv->pxmitbuf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_xmitbuf), 4);\n\t/* pxmitpriv->pxmitbuf = pxmitpriv->pallocated_xmitbuf + 4 - */\n\t/* \t\t\t\t\t\t((size_t) (pxmitpriv->pallocated_xmitbuf) &3); */\n\n\tpxmitbuf = (struct xmit_buf *)pxmitpriv->pxmitbuf;\n\n\tfor (i = 0; i < NR_XMITBUFF; i++) {\n\t\tINIT_LIST_HEAD(&pxmitbuf->list);\n\n\t\tpxmitbuf->priv_data = NULL;\n\t\tpxmitbuf->padapter = padapter;\n\t\tpxmitbuf->ext_tag = false;\n\n\t\t/* Tx buf allocation may fail sometimes, so sleep and retry. */\n\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, (MAX_XMITBUF_SZ + XMITBUF_ALIGN_SZ));\n\t\tif (res == _FAIL) {\n\t\t\tmsleep(10);\n\t\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, (MAX_XMITBUF_SZ + XMITBUF_ALIGN_SZ));\n\t\t\tif (res == _FAIL)\n\t\t\t\tgoto exit;\n\t\t}\n\n\t\tpxmitbuf->flags = XMIT_VO_QUEUE;\n\n\t\tlist_add_tail(&pxmitbuf->list, &pxmitpriv->free_xmitbuf_queue.queue);\n\t\tpxmitbuf++;\n\t}\n\n\tpxmitpriv->free_xmitbuf_cnt = NR_XMITBUFF;\n\n\t/*  Init xmit extension buff */\n\trtw_init_queue(&pxmitpriv->free_xmit_extbuf_queue);\n\n\tpxmitpriv->pallocated_xmit_extbuf = vzalloc(num_xmit_extbuf * sizeof(struct xmit_buf) + 4);\n\n\tif (!pxmitpriv->pallocated_xmit_extbuf) {\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\n\tpxmitpriv->pxmit_extbuf = (u8 *)N_BYTE_ALIGMENT((size_t)(pxmitpriv->pallocated_xmit_extbuf), 4);\n\n\tpxmitbuf = (struct xmit_buf *)pxmitpriv->pxmit_extbuf;\n\n\tfor (i = 0; i < num_xmit_extbuf; i++) {\n\t\tINIT_LIST_HEAD(&pxmitbuf->list);\n\n\t\tpxmitbuf->priv_data = NULL;\n\t\tpxmitbuf->padapter = padapter;\n\t\tpxmitbuf->ext_tag = true;\n\n\t\tres = rtw_os_xmit_resource_alloc(padapter, pxmitbuf, max_xmit_extbuf_size + XMITBUF_ALIGN_SZ);\n\t\tif (res == _FAIL) {\n\t\t\tres = _FAIL;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tlist_add_tail(&pxmitbuf->list, &pxmitpriv->free_xmit_extbuf_queue.queue);\n\t\tpxmitbuf++;\n\t}\n\n\tpxmitpriv->free_xmit_extbuf_cnt = num_xmit_extbuf;\n\n\tres = rtw_alloc_hwxmits(padapter);\n\tif (res) {\n\t\tres = _FAIL;\n\t\tgoto exit;\n\t}\n\n\trtw_init_hwxmits(pxmitpriv->hwxmits, pxmitpriv->hwxmit_entry);\n\n\tfor (i = 0; i < 4; i++)\n\t\tpxmitpriv->wmm_para_seq[i] = i;\n\n\tpxmitpriv->txirp_cnt = 1;\n\n\tsema_init(&pxmitpriv->tx_retevt, 0);\n\n\t/* per AC pending irp */\n\tpxmitpriv->beq_cnt = 0;\n\tpxmitpriv->bkq_cnt = 0;\n\tpxmitpriv->viq_cnt = 0;\n\tpxmitpriv->voq_cnt = 0;\n\n\tpxmitpriv->ack_tx = false;\n\tmutex_init(&pxmitpriv->ack_tx_mutex);\n\trtw_sctx_init(&pxmitpriv->ack_tx_ops, 0);\n\n\trtl8188eu_init_xmit_priv(padapter);\n\nexit:\n\n\treturn res;\n}",
        "patch": "--- code before\n+++ code after\n@@ -139,7 +139,12 @@\n \n \tpxmitpriv->free_xmit_extbuf_cnt = num_xmit_extbuf;\n \n-\trtw_alloc_hwxmits(padapter);\n+\tres = rtw_alloc_hwxmits(padapter);\n+\tif (res) {\n+\t\tres = _FAIL;\n+\t\tgoto exit;\n+\t}\n+\n \trtw_init_hwxmits(pxmitpriv->hwxmits, pxmitpriv->hwxmit_entry);\n \n \tfor (i = 0; i < 4; i++)",
        "function_modified_lines": {
            "added": [
                "\tres = rtw_alloc_hwxmits(padapter);",
                "\tif (res) {",
                "\t\tres = _FAIL;",
                "\t\tgoto exit;",
                "\t}",
                ""
            ],
            "deleted": [
                "\trtw_alloc_hwxmits(padapter);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. _rtw_init_xmit_priv in drivers/staging/r8188eu/core/rtw_xmit.c lacks check of the return value of rtw_alloc_hwxmits() and will cause the null pointer dereference.",
        "id": 3555
    },
    {
        "cve_id": "CVE-2023-1382",
        "code_before_change": "bool tipc_topsrv_kern_subscr(struct net *net, u32 port, u32 type, u32 lower,\n\t\t\t     u32 upper, u32 filter, int *conid)\n{\n\tstruct tipc_subscr sub;\n\tstruct tipc_conn *con;\n\tint rc;\n\n\tsub.seq.type = type;\n\tsub.seq.lower = lower;\n\tsub.seq.upper = upper;\n\tsub.timeout = TIPC_WAIT_FOREVER;\n\tsub.filter = filter;\n\t*(u64 *)&sub.usr_handle = (u64)port;\n\n\tcon = tipc_conn_alloc(tipc_topsrv(net));\n\tif (IS_ERR(con))\n\t\treturn false;\n\n\t*conid = con->conid;\n\tcon->sock = NULL;\n\trc = tipc_conn_rcv_sub(tipc_topsrv(net), con, &sub);\n\tif (rc >= 0)\n\t\treturn true;\n\tconn_put(con);\n\treturn false;\n}",
        "code_after_change": "bool tipc_topsrv_kern_subscr(struct net *net, u32 port, u32 type, u32 lower,\n\t\t\t     u32 upper, u32 filter, int *conid)\n{\n\tstruct tipc_subscr sub;\n\tstruct tipc_conn *con;\n\tint rc;\n\n\tsub.seq.type = type;\n\tsub.seq.lower = lower;\n\tsub.seq.upper = upper;\n\tsub.timeout = TIPC_WAIT_FOREVER;\n\tsub.filter = filter;\n\t*(u64 *)&sub.usr_handle = (u64)port;\n\n\tcon = tipc_conn_alloc(tipc_topsrv(net), NULL);\n\tif (IS_ERR(con))\n\t\treturn false;\n\n\t*conid = con->conid;\n\trc = tipc_conn_rcv_sub(tipc_topsrv(net), con, &sub);\n\tif (rc >= 0)\n\t\treturn true;\n\tconn_put(con);\n\treturn false;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,12 +12,11 @@\n \tsub.filter = filter;\n \t*(u64 *)&sub.usr_handle = (u64)port;\n \n-\tcon = tipc_conn_alloc(tipc_topsrv(net));\n+\tcon = tipc_conn_alloc(tipc_topsrv(net), NULL);\n \tif (IS_ERR(con))\n \t\treturn false;\n \n \t*conid = con->conid;\n-\tcon->sock = NULL;\n \trc = tipc_conn_rcv_sub(tipc_topsrv(net), con, &sub);\n \tif (rc >= 0)\n \t\treturn true;",
        "function_modified_lines": {
            "added": [
                "\tcon = tipc_conn_alloc(tipc_topsrv(net), NULL);"
            ],
            "deleted": [
                "\tcon = tipc_conn_alloc(tipc_topsrv(net));",
                "\tcon->sock = NULL;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A data race flaw was found in the Linux kernel, between where con is allocated and con->sock is set. This issue leads to a NULL pointer dereference when accessing con->sock->sk in net/tipc/topsrv.c in the tipc protocol in the Linux kernel.",
        "id": 3865
    },
    {
        "cve_id": "CVE-2023-22999",
        "code_before_change": "static int dwc3_qcom_probe(struct platform_device *pdev)\n{\n\tstruct device_node\t*np = pdev->dev.of_node;\n\tstruct device\t\t*dev = &pdev->dev;\n\tstruct dwc3_qcom\t*qcom;\n\tstruct resource\t\t*res, *parent_res = NULL;\n\tint\t\t\tret, i;\n\tbool\t\t\tignore_pipe_clk;\n\n\tqcom = devm_kzalloc(&pdev->dev, sizeof(*qcom), GFP_KERNEL);\n\tif (!qcom)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, qcom);\n\tqcom->dev = &pdev->dev;\n\n\tif (has_acpi_companion(dev)) {\n\t\tqcom->acpi_pdata = acpi_device_get_match_data(dev);\n\t\tif (!qcom->acpi_pdata) {\n\t\t\tdev_err(&pdev->dev, \"no supporting ACPI device data\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tqcom->resets = devm_reset_control_array_get_optional_exclusive(dev);\n\tif (IS_ERR(qcom->resets)) {\n\t\tret = PTR_ERR(qcom->resets);\n\t\tdev_err(&pdev->dev, \"failed to get resets, err=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = reset_control_assert(qcom->resets);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to assert resets, err=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tusleep_range(10, 1000);\n\n\tret = reset_control_deassert(qcom->resets);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to deassert resets, err=%d\\n\", ret);\n\t\tgoto reset_assert;\n\t}\n\n\tret = dwc3_qcom_clk_init(qcom, of_clk_get_parent_count(np));\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get clocks\\n\");\n\t\tgoto reset_assert;\n\t}\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\n\tif (np) {\n\t\tparent_res = res;\n\t} else {\n\t\tparent_res = kmemdup(res, sizeof(struct resource), GFP_KERNEL);\n\t\tif (!parent_res)\n\t\t\treturn -ENOMEM;\n\n\t\tparent_res->start = res->start +\n\t\t\tqcom->acpi_pdata->qscratch_base_offset;\n\t\tparent_res->end = parent_res->start +\n\t\t\tqcom->acpi_pdata->qscratch_base_size;\n\n\t\tif (qcom->acpi_pdata->is_urs) {\n\t\t\tqcom->urs_usb = dwc3_qcom_create_urs_usb_platdev(dev);\n\t\t\tif (!qcom->urs_usb) {\n\t\t\t\tdev_err(dev, \"failed to create URS USB platdev\\n\");\n\t\t\t\treturn -ENODEV;\n\t\t\t}\n\t\t}\n\t}\n\n\tqcom->qscratch_base = devm_ioremap_resource(dev, parent_res);\n\tif (IS_ERR(qcom->qscratch_base)) {\n\t\tret = PTR_ERR(qcom->qscratch_base);\n\t\tgoto clk_disable;\n\t}\n\n\tret = dwc3_qcom_setup_irq(pdev);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to setup IRQs, err=%d\\n\", ret);\n\t\tgoto clk_disable;\n\t}\n\n\t/*\n\t * Disable pipe_clk requirement if specified. Used when dwc3\n\t * operates without SSPHY and only HS/FS/LS modes are supported.\n\t */\n\tignore_pipe_clk = device_property_read_bool(dev,\n\t\t\t\t\"qcom,select-utmi-as-pipe-clk\");\n\tif (ignore_pipe_clk)\n\t\tdwc3_qcom_select_utmi_clk(qcom);\n\n\tif (np)\n\t\tret = dwc3_qcom_of_register_core(pdev);\n\telse\n\t\tret = dwc3_qcom_acpi_register_core(pdev);\n\n\tif (ret) {\n\t\tdev_err(dev, \"failed to register DWC3 Core, err=%d\\n\", ret);\n\t\tgoto depopulate;\n\t}\n\n\tret = dwc3_qcom_interconnect_init(qcom);\n\tif (ret)\n\t\tgoto depopulate;\n\n\tqcom->mode = usb_get_dr_mode(&qcom->dwc3->dev);\n\n\t/* enable vbus override for device mode */\n\tif (qcom->mode == USB_DR_MODE_PERIPHERAL)\n\t\tdwc3_qcom_vbus_override_enable(qcom, true);\n\n\t/* register extcon to override sw_vbus on Vbus change later */\n\tret = dwc3_qcom_register_extcon(qcom);\n\tif (ret)\n\t\tgoto interconnect_exit;\n\n\tdevice_init_wakeup(&pdev->dev, 1);\n\tqcom->is_suspended = false;\n\tpm_runtime_set_active(dev);\n\tpm_runtime_enable(dev);\n\tpm_runtime_forbid(dev);\n\n\treturn 0;\n\ninterconnect_exit:\n\tdwc3_qcom_interconnect_exit(qcom);\ndepopulate:\n\tif (np)\n\t\tof_platform_depopulate(&pdev->dev);\n\telse\n\t\tplatform_device_put(pdev);\nclk_disable:\n\tfor (i = qcom->num_clocks - 1; i >= 0; i--) {\n\t\tclk_disable_unprepare(qcom->clks[i]);\n\t\tclk_put(qcom->clks[i]);\n\t}\nreset_assert:\n\treset_control_assert(qcom->resets);\n\n\treturn ret;\n}",
        "code_after_change": "static int dwc3_qcom_probe(struct platform_device *pdev)\n{\n\tstruct device_node\t*np = pdev->dev.of_node;\n\tstruct device\t\t*dev = &pdev->dev;\n\tstruct dwc3_qcom\t*qcom;\n\tstruct resource\t\t*res, *parent_res = NULL;\n\tint\t\t\tret, i;\n\tbool\t\t\tignore_pipe_clk;\n\n\tqcom = devm_kzalloc(&pdev->dev, sizeof(*qcom), GFP_KERNEL);\n\tif (!qcom)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, qcom);\n\tqcom->dev = &pdev->dev;\n\n\tif (has_acpi_companion(dev)) {\n\t\tqcom->acpi_pdata = acpi_device_get_match_data(dev);\n\t\tif (!qcom->acpi_pdata) {\n\t\t\tdev_err(&pdev->dev, \"no supporting ACPI device data\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tqcom->resets = devm_reset_control_array_get_optional_exclusive(dev);\n\tif (IS_ERR(qcom->resets)) {\n\t\tret = PTR_ERR(qcom->resets);\n\t\tdev_err(&pdev->dev, \"failed to get resets, err=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = reset_control_assert(qcom->resets);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to assert resets, err=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tusleep_range(10, 1000);\n\n\tret = reset_control_deassert(qcom->resets);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"failed to deassert resets, err=%d\\n\", ret);\n\t\tgoto reset_assert;\n\t}\n\n\tret = dwc3_qcom_clk_init(qcom, of_clk_get_parent_count(np));\n\tif (ret) {\n\t\tdev_err(dev, \"failed to get clocks\\n\");\n\t\tgoto reset_assert;\n\t}\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\n\tif (np) {\n\t\tparent_res = res;\n\t} else {\n\t\tparent_res = kmemdup(res, sizeof(struct resource), GFP_KERNEL);\n\t\tif (!parent_res)\n\t\t\treturn -ENOMEM;\n\n\t\tparent_res->start = res->start +\n\t\t\tqcom->acpi_pdata->qscratch_base_offset;\n\t\tparent_res->end = parent_res->start +\n\t\t\tqcom->acpi_pdata->qscratch_base_size;\n\n\t\tif (qcom->acpi_pdata->is_urs) {\n\t\t\tqcom->urs_usb = dwc3_qcom_create_urs_usb_platdev(dev);\n\t\t\tif (IS_ERR_OR_NULL(qcom->urs_usb)) {\n\t\t\t\tdev_err(dev, \"failed to create URS USB platdev\\n\");\n\t\t\t\tif (!qcom->urs_usb)\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\telse\n\t\t\t\t\treturn PTR_ERR(qcom->urs_usb);\n\t\t\t}\n\t\t}\n\t}\n\n\tqcom->qscratch_base = devm_ioremap_resource(dev, parent_res);\n\tif (IS_ERR(qcom->qscratch_base)) {\n\t\tret = PTR_ERR(qcom->qscratch_base);\n\t\tgoto clk_disable;\n\t}\n\n\tret = dwc3_qcom_setup_irq(pdev);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to setup IRQs, err=%d\\n\", ret);\n\t\tgoto clk_disable;\n\t}\n\n\t/*\n\t * Disable pipe_clk requirement if specified. Used when dwc3\n\t * operates without SSPHY and only HS/FS/LS modes are supported.\n\t */\n\tignore_pipe_clk = device_property_read_bool(dev,\n\t\t\t\t\"qcom,select-utmi-as-pipe-clk\");\n\tif (ignore_pipe_clk)\n\t\tdwc3_qcom_select_utmi_clk(qcom);\n\n\tif (np)\n\t\tret = dwc3_qcom_of_register_core(pdev);\n\telse\n\t\tret = dwc3_qcom_acpi_register_core(pdev);\n\n\tif (ret) {\n\t\tdev_err(dev, \"failed to register DWC3 Core, err=%d\\n\", ret);\n\t\tgoto depopulate;\n\t}\n\n\tret = dwc3_qcom_interconnect_init(qcom);\n\tif (ret)\n\t\tgoto depopulate;\n\n\tqcom->mode = usb_get_dr_mode(&qcom->dwc3->dev);\n\n\t/* enable vbus override for device mode */\n\tif (qcom->mode == USB_DR_MODE_PERIPHERAL)\n\t\tdwc3_qcom_vbus_override_enable(qcom, true);\n\n\t/* register extcon to override sw_vbus on Vbus change later */\n\tret = dwc3_qcom_register_extcon(qcom);\n\tif (ret)\n\t\tgoto interconnect_exit;\n\n\tdevice_init_wakeup(&pdev->dev, 1);\n\tqcom->is_suspended = false;\n\tpm_runtime_set_active(dev);\n\tpm_runtime_enable(dev);\n\tpm_runtime_forbid(dev);\n\n\treturn 0;\n\ninterconnect_exit:\n\tdwc3_qcom_interconnect_exit(qcom);\ndepopulate:\n\tif (np)\n\t\tof_platform_depopulate(&pdev->dev);\n\telse\n\t\tplatform_device_put(pdev);\nclk_disable:\n\tfor (i = qcom->num_clocks - 1; i >= 0; i--) {\n\t\tclk_disable_unprepare(qcom->clks[i]);\n\t\tclk_put(qcom->clks[i]);\n\t}\nreset_assert:\n\treset_control_assert(qcom->resets);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -65,9 +65,12 @@\n \n \t\tif (qcom->acpi_pdata->is_urs) {\n \t\t\tqcom->urs_usb = dwc3_qcom_create_urs_usb_platdev(dev);\n-\t\t\tif (!qcom->urs_usb) {\n+\t\t\tif (IS_ERR_OR_NULL(qcom->urs_usb)) {\n \t\t\t\tdev_err(dev, \"failed to create URS USB platdev\\n\");\n-\t\t\t\treturn -ENODEV;\n+\t\t\t\tif (!qcom->urs_usb)\n+\t\t\t\t\treturn -ENODEV;\n+\t\t\t\telse\n+\t\t\t\t\treturn PTR_ERR(qcom->urs_usb);\n \t\t\t}\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (IS_ERR_OR_NULL(qcom->urs_usb)) {",
                "\t\t\t\tif (!qcom->urs_usb)",
                "\t\t\t\t\treturn -ENODEV;",
                "\t\t\t\telse",
                "\t\t\t\t\treturn PTR_ERR(qcom->urs_usb);"
            ],
            "deleted": [
                "\t\t\tif (!qcom->urs_usb) {",
                "\t\t\t\treturn -ENODEV;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.16.3, drivers/usb/dwc3/dwc3-qcom.c misinterprets the dwc3_qcom_create_urs_usb_platdev return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3942
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "int btrfs_get_dev_stats(struct btrfs_fs_info *fs_info,\n\t\t\tstruct btrfs_ioctl_get_dev_stats *stats)\n{\n\tstruct btrfs_device *dev;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tint i;\n\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\tif (!dev) {\n\t\tbtrfs_warn(fs_info, \"get dev_stats failed, device not found\");\n\t\treturn -ENODEV;\n\t} else if (!dev->dev_stats_valid) {\n\t\tbtrfs_warn(fs_info, \"get dev_stats failed, not yet valid\");\n\t\treturn -ENODEV;\n\t} else if (stats->flags & BTRFS_DEV_STATS_RESET) {\n\t\tfor (i = 0; i < BTRFS_DEV_STAT_VALUES_MAX; i++) {\n\t\t\tif (stats->nr_items > i)\n\t\t\t\tstats->values[i] =\n\t\t\t\t\tbtrfs_dev_stat_read_and_reset(dev, i);\n\t\t\telse\n\t\t\t\tbtrfs_dev_stat_reset(dev, i);\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < BTRFS_DEV_STAT_VALUES_MAX; i++)\n\t\t\tif (stats->nr_items > i)\n\t\t\t\tstats->values[i] = btrfs_dev_stat_read(dev, i);\n\t}\n\tif (stats->nr_items > BTRFS_DEV_STAT_VALUES_MAX)\n\t\tstats->nr_items = BTRFS_DEV_STAT_VALUES_MAX;\n\treturn 0;\n}",
        "code_after_change": "int btrfs_get_dev_stats(struct btrfs_fs_info *fs_info,\n\t\t\tstruct btrfs_ioctl_get_dev_stats *stats)\n{\n\tstruct btrfs_device *dev;\n\tstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\n\tint i;\n\n\tmutex_lock(&fs_devices->device_list_mutex);\n\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL,\n\t\t\t\ttrue);\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\n\tif (!dev) {\n\t\tbtrfs_warn(fs_info, \"get dev_stats failed, device not found\");\n\t\treturn -ENODEV;\n\t} else if (!dev->dev_stats_valid) {\n\t\tbtrfs_warn(fs_info, \"get dev_stats failed, not yet valid\");\n\t\treturn -ENODEV;\n\t} else if (stats->flags & BTRFS_DEV_STATS_RESET) {\n\t\tfor (i = 0; i < BTRFS_DEV_STAT_VALUES_MAX; i++) {\n\t\t\tif (stats->nr_items > i)\n\t\t\t\tstats->values[i] =\n\t\t\t\t\tbtrfs_dev_stat_read_and_reset(dev, i);\n\t\t\telse\n\t\t\t\tbtrfs_dev_stat_reset(dev, i);\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < BTRFS_DEV_STAT_VALUES_MAX; i++)\n\t\t\tif (stats->nr_items > i)\n\t\t\t\tstats->values[i] = btrfs_dev_stat_read(dev, i);\n\t}\n\tif (stats->nr_items > BTRFS_DEV_STAT_VALUES_MAX)\n\t\tstats->nr_items = BTRFS_DEV_STAT_VALUES_MAX;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,8 @@\n \tint i;\n \n \tmutex_lock(&fs_devices->device_list_mutex);\n-\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL);\n+\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL,\n+\t\t\t\ttrue);\n \tmutex_unlock(&fs_devices->device_list_mutex);\n \n \tif (!dev) {",
        "function_modified_lines": {
            "added": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL,",
                "\t\t\t\ttrue);"
            ],
            "deleted": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, stats->devid, NULL, NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2112
    },
    {
        "cve_id": "CVE-2018-1066",
        "code_before_change": "void build_ntlmssp_negotiate_blob(unsigned char *pbuffer,\n\t\t\t\t\t struct cifs_ses *ses)\n{\n\tNEGOTIATE_MESSAGE *sec_blob = (NEGOTIATE_MESSAGE *)pbuffer;\n\t__u32 flags;\n\n\tmemset(pbuffer, 0, sizeof(NEGOTIATE_MESSAGE));\n\tmemcpy(sec_blob->Signature, NTLMSSP_SIGNATURE, 8);\n\tsec_blob->MessageType = NtLmNegotiate;\n\n\t/* BB is NTLMV2 session security format easier to use here? */\n\tflags = NTLMSSP_NEGOTIATE_56 |\tNTLMSSP_REQUEST_TARGET |\n\t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;\n\tif (ses->server->sign) {\n\t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n\t\tif (!ses->server->session_estab ||\n\t\t\t\tses->ntlmssp->sesskey_per_smbsess)\n\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n\t}\n\n\tsec_blob->NegotiateFlags = cpu_to_le32(flags);\n\n\tsec_blob->WorkstationName.BufferOffset = 0;\n\tsec_blob->WorkstationName.Length = 0;\n\tsec_blob->WorkstationName.MaximumLength = 0;\n\n\t/* Domain name is sent on the Challenge not Negotiate NTLMSSP request */\n\tsec_blob->DomainName.BufferOffset = 0;\n\tsec_blob->DomainName.Length = 0;\n\tsec_blob->DomainName.MaximumLength = 0;\n}",
        "code_after_change": "void build_ntlmssp_negotiate_blob(unsigned char *pbuffer,\n\t\t\t\t\t struct cifs_ses *ses)\n{\n\tNEGOTIATE_MESSAGE *sec_blob = (NEGOTIATE_MESSAGE *)pbuffer;\n\t__u32 flags;\n\n\tmemset(pbuffer, 0, sizeof(NEGOTIATE_MESSAGE));\n\tmemcpy(sec_blob->Signature, NTLMSSP_SIGNATURE, 8);\n\tsec_blob->MessageType = NtLmNegotiate;\n\n\t/* BB is NTLMV2 session security format easier to use here? */\n\tflags = NTLMSSP_NEGOTIATE_56 |\tNTLMSSP_REQUEST_TARGET |\n\t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |\n\t\tNTLMSSP_NEGOTIATE_SEAL;\n\tif (ses->server->sign)\n\t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)\n\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n\n\tsec_blob->NegotiateFlags = cpu_to_le32(flags);\n\n\tsec_blob->WorkstationName.BufferOffset = 0;\n\tsec_blob->WorkstationName.Length = 0;\n\tsec_blob->WorkstationName.MaximumLength = 0;\n\n\t/* Domain name is sent on the Challenge not Negotiate NTLMSSP request */\n\tsec_blob->DomainName.BufferOffset = 0;\n\tsec_blob->DomainName.Length = 0;\n\tsec_blob->DomainName.MaximumLength = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,13 +11,12 @@\n \t/* BB is NTLMV2 session security format easier to use here? */\n \tflags = NTLMSSP_NEGOTIATE_56 |\tNTLMSSP_REQUEST_TARGET |\n \t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n-\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;\n-\tif (ses->server->sign) {\n+\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |\n+\t\tNTLMSSP_NEGOTIATE_SEAL;\n+\tif (ses->server->sign)\n \t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n-\t\tif (!ses->server->session_estab ||\n-\t\t\t\tses->ntlmssp->sesskey_per_smbsess)\n-\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n-\t}\n+\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)\n+\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n \n \tsec_blob->NegotiateFlags = cpu_to_le32(flags);\n ",
        "function_modified_lines": {
            "added": [
                "\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |",
                "\t\tNTLMSSP_NEGOTIATE_SEAL;",
                "\tif (ses->server->sign)",
                "\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)",
                "\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;"
            ],
            "deleted": [
                "\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;",
                "\tif (ses->server->sign) {",
                "\t\tif (!ses->server->session_estab ||",
                "\t\t\t\tses->ntlmssp->sesskey_per_smbsess)",
                "\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux kernel before version 4.11 is vulnerable to a NULL pointer dereference in fs/cifs/cifsencrypt.c:setup_ntlmv2_rsp() that allows an attacker controlling a CIFS server to kernel panic a client that has this server mounted, because an empty TargetInfo field in an NTLMSSP setup negotiation response is mishandled during session recovery.",
        "id": 1591
    },
    {
        "cve_id": "CVE-2023-28466",
        "code_before_change": "static int do_tls_getsockopt_no_pad(struct sock *sk, char __user *optval,\n\t\t\t\t    int __user *optlen)\n{\n\tstruct tls_context *ctx = tls_get_ctx(sk);\n\tint value, len;\n\n\tif (ctx->prot_info.version != TLS_1_3_VERSION)\n\t\treturn -EINVAL;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < sizeof(value))\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\tvalue = -EINVAL;\n\tif (ctx->rx_conf == TLS_SW || ctx->rx_conf == TLS_HW)\n\t\tvalue = ctx->rx_no_pad;\n\trelease_sock(sk);\n\tif (value < 0)\n\t\treturn value;\n\n\tif (put_user(sizeof(value), optlen))\n\t\treturn -EFAULT;\n\tif (copy_to_user(optval, &value, sizeof(value)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}",
        "code_after_change": "static int do_tls_getsockopt_no_pad(struct sock *sk, char __user *optval,\n\t\t\t\t    int __user *optlen)\n{\n\tstruct tls_context *ctx = tls_get_ctx(sk);\n\tint value, len;\n\n\tif (ctx->prot_info.version != TLS_1_3_VERSION)\n\t\treturn -EINVAL;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < sizeof(value))\n\t\treturn -EINVAL;\n\n\tvalue = -EINVAL;\n\tif (ctx->rx_conf == TLS_SW || ctx->rx_conf == TLS_HW)\n\t\tvalue = ctx->rx_no_pad;\n\tif (value < 0)\n\t\treturn value;\n\n\tif (put_user(sizeof(value), optlen))\n\t\treturn -EFAULT;\n\tif (copy_to_user(optval, &value, sizeof(value)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,11 +12,9 @@\n \tif (len < sizeof(value))\n \t\treturn -EINVAL;\n \n-\tlock_sock(sk);\n \tvalue = -EINVAL;\n \tif (ctx->rx_conf == TLS_SW || ctx->rx_conf == TLS_HW)\n \t\tvalue = ctx->rx_no_pad;\n-\trelease_sock(sk);\n \tif (value < 0)\n \t\treturn value;\n ",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tlock_sock(sk);",
                "\trelease_sock(sk);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "do_tls_getsockopt in net/tls/tls_main.c in the Linux kernel through 6.2.6 lacks a lock_sock call, leading to a race condition (with a resultant use-after-free or NULL pointer dereference).",
        "id": 3980
    },
    {
        "cve_id": "CVE-2022-42722",
        "code_before_change": "static ieee80211_rx_result debug_noinline\nieee80211_rx_h_decrypt(struct ieee80211_rx_data *rx)\n{\n\tstruct sk_buff *skb = rx->skb;\n\tstruct ieee80211_rx_status *status = IEEE80211_SKB_RXCB(skb);\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tint keyidx;\n\tieee80211_rx_result result = RX_DROP_UNUSABLE;\n\tstruct ieee80211_key *sta_ptk = NULL;\n\tstruct ieee80211_key *ptk_idx = NULL;\n\tint mmie_keyidx = -1;\n\t__le16 fc;\n\n\tif (ieee80211_is_ext(hdr->frame_control))\n\t\treturn RX_CONTINUE;\n\n\t/*\n\t * Key selection 101\n\t *\n\t * There are five types of keys:\n\t *  - GTK (group keys)\n\t *  - IGTK (group keys for management frames)\n\t *  - BIGTK (group keys for Beacon frames)\n\t *  - PTK (pairwise keys)\n\t *  - STK (station-to-station pairwise keys)\n\t *\n\t * When selecting a key, we have to distinguish between multicast\n\t * (including broadcast) and unicast frames, the latter can only\n\t * use PTKs and STKs while the former always use GTKs, IGTKs, and\n\t * BIGTKs. Unless, of course, actual WEP keys (\"pre-RSNA\") are used,\n\t * then unicast frames can also use key indices like GTKs. Hence, if we\n\t * don't have a PTK/STK we check the key index for a WEP key.\n\t *\n\t * Note that in a regular BSS, multicast frames are sent by the\n\t * AP only, associated stations unicast the frame to the AP first\n\t * which then multicasts it on their behalf.\n\t *\n\t * There is also a slight problem in IBSS mode: GTKs are negotiated\n\t * with each station, that is something we don't currently handle.\n\t * The spec seems to expect that one negotiates the same key with\n\t * every station but there's no such requirement; VLANs could be\n\t * possible.\n\t */\n\n\t/* start without a key */\n\trx->key = NULL;\n\tfc = hdr->frame_control;\n\n\tif (rx->sta) {\n\t\tint keyid = rx->sta->ptk_idx;\n\t\tsta_ptk = rcu_dereference(rx->sta->ptk[keyid]);\n\n\t\tif (ieee80211_has_protected(fc) &&\n\t\t    !(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\t\tkeyid = ieee80211_get_keyid(rx->skb);\n\n\t\t\tif (unlikely(keyid < 0))\n\t\t\t\treturn RX_DROP_UNUSABLE;\n\n\t\t\tptk_idx = rcu_dereference(rx->sta->ptk[keyid]);\n\t\t}\n\t}\n\n\tif (!ieee80211_has_protected(fc))\n\t\tmmie_keyidx = ieee80211_get_mmie_keyidx(rx->skb);\n\n\tif (!is_multicast_ether_addr(hdr->addr1) && sta_ptk) {\n\t\trx->key = ptk_idx ? ptk_idx : sta_ptk;\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\t\t/* Skip decryption if the frame is not protected. */\n\t\tif (!ieee80211_has_protected(fc))\n\t\t\treturn RX_CONTINUE;\n\t} else if (mmie_keyidx >= 0 && ieee80211_is_beacon(fc)) {\n\t\t/* Broadcast/multicast robust management frame / BIP */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tif (mmie_keyidx < NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS ||\n\t\t    mmie_keyidx >= NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS +\n\t\t    NUM_DEFAULT_BEACON_KEYS) {\n\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n\t\t\t\t\t\t     skb->data,\n\t\t\t\t\t\t     skb->len);\n\t\t\treturn RX_DROP_MONITOR; /* unexpected BIP keyidx */\n\t\t}\n\n\t\trx->key = ieee80211_rx_get_bigtk(rx, mmie_keyidx);\n\t\tif (!rx->key)\n\t\t\treturn RX_CONTINUE; /* Beacon protection not in use */\n\t} else if (mmie_keyidx >= 0) {\n\t\t/* Broadcast/multicast robust management frame / BIP */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tif (mmie_keyidx < NUM_DEFAULT_KEYS ||\n\t\t    mmie_keyidx >= NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS)\n\t\t\treturn RX_DROP_MONITOR; /* unexpected BIP keyidx */\n\t\tif (rx->link_sta) {\n\t\t\tif (ieee80211_is_group_privacy_action(skb) &&\n\t\t\t    test_sta_flag(rx->sta, WLAN_STA_MFP))\n\t\t\t\treturn RX_DROP_MONITOR;\n\n\t\t\trx->key = rcu_dereference(rx->link_sta->gtk[mmie_keyidx]);\n\t\t}\n\t\tif (!rx->key)\n\t\t\trx->key = rcu_dereference(rx->link->gtk[mmie_keyidx]);\n\t} else if (!ieee80211_has_protected(fc)) {\n\t\t/*\n\t\t * The frame was not protected, so skip decryption. However, we\n\t\t * need to set rx->key if there is a key that could have been\n\t\t * used so that the frame may be dropped if encryption would\n\t\t * have been expected.\n\t\t */\n\t\tstruct ieee80211_key *key = NULL;\n\t\tint i;\n\n\t\tif (ieee80211_is_beacon(fc)) {\n\t\t\tkey = ieee80211_rx_get_bigtk(rx, -1);\n\t\t} else if (ieee80211_is_mgmt(fc) &&\n\t\t\t   is_multicast_ether_addr(hdr->addr1)) {\n\t\t\tkey = rcu_dereference(rx->link->default_mgmt_key);\n\t\t} else {\n\t\t\tif (rx->link_sta) {\n\t\t\t\tfor (i = 0; i < NUM_DEFAULT_KEYS; i++) {\n\t\t\t\t\tkey = rcu_dereference(rx->link_sta->gtk[i]);\n\t\t\t\t\tif (key)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!key) {\n\t\t\t\tfor (i = 0; i < NUM_DEFAULT_KEYS; i++) {\n\t\t\t\t\tkey = rcu_dereference(rx->link->gtk[i]);\n\t\t\t\t\tif (key)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (key)\n\t\t\trx->key = key;\n\t\treturn RX_CONTINUE;\n\t} else {\n\t\t/*\n\t\t * The device doesn't give us the IV so we won't be\n\t\t * able to look up the key. That's ok though, we\n\t\t * don't need to decrypt the frame, we just won't\n\t\t * be able to keep statistics accurate.\n\t\t * Except for key threshold notifications, should\n\t\t * we somehow allow the driver to tell us which key\n\t\t * the hardware used if this flag is set?\n\t\t */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tkeyidx = ieee80211_get_keyid(rx->skb);\n\n\t\tif (unlikely(keyidx < 0))\n\t\t\treturn RX_DROP_UNUSABLE;\n\n\t\t/* check per-station GTK first, if multicast packet */\n\t\tif (is_multicast_ether_addr(hdr->addr1) && rx->link_sta)\n\t\t\trx->key = rcu_dereference(rx->link_sta->gtk[keyidx]);\n\n\t\t/* if not found, try default key */\n\t\tif (!rx->key) {\n\t\t\tif (is_multicast_ether_addr(hdr->addr1))\n\t\t\t\trx->key = rcu_dereference(rx->link->gtk[keyidx]);\n\t\t\tif (!rx->key)\n\t\t\t\trx->key = rcu_dereference(rx->sdata->keys[keyidx]);\n\n\t\t\t/*\n\t\t\t * RSNA-protected unicast frames should always be\n\t\t\t * sent with pairwise or station-to-station keys,\n\t\t\t * but for WEP we allow using a key index as well.\n\t\t\t */\n\t\t\tif (rx->key &&\n\t\t\t    rx->key->conf.cipher != WLAN_CIPHER_SUITE_WEP40 &&\n\t\t\t    rx->key->conf.cipher != WLAN_CIPHER_SUITE_WEP104 &&\n\t\t\t    !is_multicast_ether_addr(hdr->addr1))\n\t\t\t\trx->key = NULL;\n\t\t}\n\t}\n\n\tif (rx->key) {\n\t\tif (unlikely(rx->key->flags & KEY_FLAG_TAINTED))\n\t\t\treturn RX_DROP_MONITOR;\n\n\t\t/* TODO: add threshold stuff again */\n\t} else {\n\t\treturn RX_DROP_MONITOR;\n\t}\n\n\tswitch (rx->key->conf.cipher) {\n\tcase WLAN_CIPHER_SUITE_WEP40:\n\tcase WLAN_CIPHER_SUITE_WEP104:\n\t\tresult = ieee80211_crypto_wep_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_TKIP:\n\t\tresult = ieee80211_crypto_tkip_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_CCMP:\n\t\tresult = ieee80211_crypto_ccmp_decrypt(\n\t\t\trx, IEEE80211_CCMP_MIC_LEN);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_CCMP_256:\n\t\tresult = ieee80211_crypto_ccmp_decrypt(\n\t\t\trx, IEEE80211_CCMP_256_MIC_LEN);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_AES_CMAC:\n\t\tresult = ieee80211_crypto_aes_cmac_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_BIP_CMAC_256:\n\t\tresult = ieee80211_crypto_aes_cmac_256_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_BIP_GMAC_128:\n\tcase WLAN_CIPHER_SUITE_BIP_GMAC_256:\n\t\tresult = ieee80211_crypto_aes_gmac_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_GCMP:\n\tcase WLAN_CIPHER_SUITE_GCMP_256:\n\t\tresult = ieee80211_crypto_gcmp_decrypt(rx);\n\t\tbreak;\n\tdefault:\n\t\tresult = RX_DROP_UNUSABLE;\n\t}\n\n\t/* the hdr variable is invalid after the decrypt handlers */\n\n\t/* either the frame has been decrypted or will be dropped */\n\tstatus->flag |= RX_FLAG_DECRYPTED;\n\n\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE))\n\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n\t\t\t\t\t     skb->data, skb->len);\n\n\treturn result;\n}",
        "code_after_change": "static ieee80211_rx_result debug_noinline\nieee80211_rx_h_decrypt(struct ieee80211_rx_data *rx)\n{\n\tstruct sk_buff *skb = rx->skb;\n\tstruct ieee80211_rx_status *status = IEEE80211_SKB_RXCB(skb);\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tint keyidx;\n\tieee80211_rx_result result = RX_DROP_UNUSABLE;\n\tstruct ieee80211_key *sta_ptk = NULL;\n\tstruct ieee80211_key *ptk_idx = NULL;\n\tint mmie_keyidx = -1;\n\t__le16 fc;\n\n\tif (ieee80211_is_ext(hdr->frame_control))\n\t\treturn RX_CONTINUE;\n\n\t/*\n\t * Key selection 101\n\t *\n\t * There are five types of keys:\n\t *  - GTK (group keys)\n\t *  - IGTK (group keys for management frames)\n\t *  - BIGTK (group keys for Beacon frames)\n\t *  - PTK (pairwise keys)\n\t *  - STK (station-to-station pairwise keys)\n\t *\n\t * When selecting a key, we have to distinguish between multicast\n\t * (including broadcast) and unicast frames, the latter can only\n\t * use PTKs and STKs while the former always use GTKs, IGTKs, and\n\t * BIGTKs. Unless, of course, actual WEP keys (\"pre-RSNA\") are used,\n\t * then unicast frames can also use key indices like GTKs. Hence, if we\n\t * don't have a PTK/STK we check the key index for a WEP key.\n\t *\n\t * Note that in a regular BSS, multicast frames are sent by the\n\t * AP only, associated stations unicast the frame to the AP first\n\t * which then multicasts it on their behalf.\n\t *\n\t * There is also a slight problem in IBSS mode: GTKs are negotiated\n\t * with each station, that is something we don't currently handle.\n\t * The spec seems to expect that one negotiates the same key with\n\t * every station but there's no such requirement; VLANs could be\n\t * possible.\n\t */\n\n\t/* start without a key */\n\trx->key = NULL;\n\tfc = hdr->frame_control;\n\n\tif (rx->sta) {\n\t\tint keyid = rx->sta->ptk_idx;\n\t\tsta_ptk = rcu_dereference(rx->sta->ptk[keyid]);\n\n\t\tif (ieee80211_has_protected(fc) &&\n\t\t    !(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\t\tkeyid = ieee80211_get_keyid(rx->skb);\n\n\t\t\tif (unlikely(keyid < 0))\n\t\t\t\treturn RX_DROP_UNUSABLE;\n\n\t\t\tptk_idx = rcu_dereference(rx->sta->ptk[keyid]);\n\t\t}\n\t}\n\n\tif (!ieee80211_has_protected(fc))\n\t\tmmie_keyidx = ieee80211_get_mmie_keyidx(rx->skb);\n\n\tif (!is_multicast_ether_addr(hdr->addr1) && sta_ptk) {\n\t\trx->key = ptk_idx ? ptk_idx : sta_ptk;\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\t\t/* Skip decryption if the frame is not protected. */\n\t\tif (!ieee80211_has_protected(fc))\n\t\t\treturn RX_CONTINUE;\n\t} else if (mmie_keyidx >= 0 && ieee80211_is_beacon(fc)) {\n\t\t/* Broadcast/multicast robust management frame / BIP */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tif (mmie_keyidx < NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS ||\n\t\t    mmie_keyidx >= NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS +\n\t\t\t\t   NUM_DEFAULT_BEACON_KEYS) {\n\t\t\tif (rx->sdata->dev)\n\t\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n\t\t\t\t\t\t\t     skb->data,\n\t\t\t\t\t\t\t     skb->len);\n\t\t\treturn RX_DROP_MONITOR; /* unexpected BIP keyidx */\n\t\t}\n\n\t\trx->key = ieee80211_rx_get_bigtk(rx, mmie_keyidx);\n\t\tif (!rx->key)\n\t\t\treturn RX_CONTINUE; /* Beacon protection not in use */\n\t} else if (mmie_keyidx >= 0) {\n\t\t/* Broadcast/multicast robust management frame / BIP */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tif (mmie_keyidx < NUM_DEFAULT_KEYS ||\n\t\t    mmie_keyidx >= NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS)\n\t\t\treturn RX_DROP_MONITOR; /* unexpected BIP keyidx */\n\t\tif (rx->link_sta) {\n\t\t\tif (ieee80211_is_group_privacy_action(skb) &&\n\t\t\t    test_sta_flag(rx->sta, WLAN_STA_MFP))\n\t\t\t\treturn RX_DROP_MONITOR;\n\n\t\t\trx->key = rcu_dereference(rx->link_sta->gtk[mmie_keyidx]);\n\t\t}\n\t\tif (!rx->key)\n\t\t\trx->key = rcu_dereference(rx->link->gtk[mmie_keyidx]);\n\t} else if (!ieee80211_has_protected(fc)) {\n\t\t/*\n\t\t * The frame was not protected, so skip decryption. However, we\n\t\t * need to set rx->key if there is a key that could have been\n\t\t * used so that the frame may be dropped if encryption would\n\t\t * have been expected.\n\t\t */\n\t\tstruct ieee80211_key *key = NULL;\n\t\tint i;\n\n\t\tif (ieee80211_is_beacon(fc)) {\n\t\t\tkey = ieee80211_rx_get_bigtk(rx, -1);\n\t\t} else if (ieee80211_is_mgmt(fc) &&\n\t\t\t   is_multicast_ether_addr(hdr->addr1)) {\n\t\t\tkey = rcu_dereference(rx->link->default_mgmt_key);\n\t\t} else {\n\t\t\tif (rx->link_sta) {\n\t\t\t\tfor (i = 0; i < NUM_DEFAULT_KEYS; i++) {\n\t\t\t\t\tkey = rcu_dereference(rx->link_sta->gtk[i]);\n\t\t\t\t\tif (key)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!key) {\n\t\t\t\tfor (i = 0; i < NUM_DEFAULT_KEYS; i++) {\n\t\t\t\t\tkey = rcu_dereference(rx->link->gtk[i]);\n\t\t\t\t\tif (key)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (key)\n\t\t\trx->key = key;\n\t\treturn RX_CONTINUE;\n\t} else {\n\t\t/*\n\t\t * The device doesn't give us the IV so we won't be\n\t\t * able to look up the key. That's ok though, we\n\t\t * don't need to decrypt the frame, we just won't\n\t\t * be able to keep statistics accurate.\n\t\t * Except for key threshold notifications, should\n\t\t * we somehow allow the driver to tell us which key\n\t\t * the hardware used if this flag is set?\n\t\t */\n\t\tif ((status->flag & RX_FLAG_DECRYPTED) &&\n\t\t    (status->flag & RX_FLAG_IV_STRIPPED))\n\t\t\treturn RX_CONTINUE;\n\n\t\tkeyidx = ieee80211_get_keyid(rx->skb);\n\n\t\tif (unlikely(keyidx < 0))\n\t\t\treturn RX_DROP_UNUSABLE;\n\n\t\t/* check per-station GTK first, if multicast packet */\n\t\tif (is_multicast_ether_addr(hdr->addr1) && rx->link_sta)\n\t\t\trx->key = rcu_dereference(rx->link_sta->gtk[keyidx]);\n\n\t\t/* if not found, try default key */\n\t\tif (!rx->key) {\n\t\t\tif (is_multicast_ether_addr(hdr->addr1))\n\t\t\t\trx->key = rcu_dereference(rx->link->gtk[keyidx]);\n\t\t\tif (!rx->key)\n\t\t\t\trx->key = rcu_dereference(rx->sdata->keys[keyidx]);\n\n\t\t\t/*\n\t\t\t * RSNA-protected unicast frames should always be\n\t\t\t * sent with pairwise or station-to-station keys,\n\t\t\t * but for WEP we allow using a key index as well.\n\t\t\t */\n\t\t\tif (rx->key &&\n\t\t\t    rx->key->conf.cipher != WLAN_CIPHER_SUITE_WEP40 &&\n\t\t\t    rx->key->conf.cipher != WLAN_CIPHER_SUITE_WEP104 &&\n\t\t\t    !is_multicast_ether_addr(hdr->addr1))\n\t\t\t\trx->key = NULL;\n\t\t}\n\t}\n\n\tif (rx->key) {\n\t\tif (unlikely(rx->key->flags & KEY_FLAG_TAINTED))\n\t\t\treturn RX_DROP_MONITOR;\n\n\t\t/* TODO: add threshold stuff again */\n\t} else {\n\t\treturn RX_DROP_MONITOR;\n\t}\n\n\tswitch (rx->key->conf.cipher) {\n\tcase WLAN_CIPHER_SUITE_WEP40:\n\tcase WLAN_CIPHER_SUITE_WEP104:\n\t\tresult = ieee80211_crypto_wep_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_TKIP:\n\t\tresult = ieee80211_crypto_tkip_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_CCMP:\n\t\tresult = ieee80211_crypto_ccmp_decrypt(\n\t\t\trx, IEEE80211_CCMP_MIC_LEN);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_CCMP_256:\n\t\tresult = ieee80211_crypto_ccmp_decrypt(\n\t\t\trx, IEEE80211_CCMP_256_MIC_LEN);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_AES_CMAC:\n\t\tresult = ieee80211_crypto_aes_cmac_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_BIP_CMAC_256:\n\t\tresult = ieee80211_crypto_aes_cmac_256_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_BIP_GMAC_128:\n\tcase WLAN_CIPHER_SUITE_BIP_GMAC_256:\n\t\tresult = ieee80211_crypto_aes_gmac_decrypt(rx);\n\t\tbreak;\n\tcase WLAN_CIPHER_SUITE_GCMP:\n\tcase WLAN_CIPHER_SUITE_GCMP_256:\n\t\tresult = ieee80211_crypto_gcmp_decrypt(rx);\n\t\tbreak;\n\tdefault:\n\t\tresult = RX_DROP_UNUSABLE;\n\t}\n\n\t/* the hdr variable is invalid after the decrypt handlers */\n\n\t/* either the frame has been decrypted or will be dropped */\n\tstatus->flag |= RX_FLAG_DECRYPTED;\n\n\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE &&\n\t\t     rx->sdata->dev))\n\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n\t\t\t\t\t     skb->data, skb->len);\n\n\treturn result;\n}",
        "patch": "--- code before\n+++ code after\n@@ -80,10 +80,11 @@\n \n \t\tif (mmie_keyidx < NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS ||\n \t\t    mmie_keyidx >= NUM_DEFAULT_KEYS + NUM_DEFAULT_MGMT_KEYS +\n-\t\t    NUM_DEFAULT_BEACON_KEYS) {\n-\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n-\t\t\t\t\t\t     skb->data,\n-\t\t\t\t\t\t     skb->len);\n+\t\t\t\t   NUM_DEFAULT_BEACON_KEYS) {\n+\t\t\tif (rx->sdata->dev)\n+\t\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n+\t\t\t\t\t\t\t     skb->data,\n+\t\t\t\t\t\t\t     skb->len);\n \t\t\treturn RX_DROP_MONITOR; /* unexpected BIP keyidx */\n \t\t}\n \n@@ -233,7 +234,8 @@\n \t/* either the frame has been decrypted or will be dropped */\n \tstatus->flag |= RX_FLAG_DECRYPTED;\n \n-\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE))\n+\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE &&\n+\t\t     rx->sdata->dev))\n \t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,\n \t\t\t\t\t     skb->data, skb->len);\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t   NUM_DEFAULT_BEACON_KEYS) {",
                "\t\t\tif (rx->sdata->dev)",
                "\t\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,",
                "\t\t\t\t\t\t\t     skb->data,",
                "\t\t\t\t\t\t\t     skb->len);",
                "\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE &&",
                "\t\t     rx->sdata->dev))"
            ],
            "deleted": [
                "\t\t    NUM_DEFAULT_BEACON_KEYS) {",
                "\t\t\tcfg80211_rx_unprot_mlme_mgmt(rx->sdata->dev,",
                "\t\t\t\t\t\t     skb->data,",
                "\t\t\t\t\t\t     skb->len);",
                "\tif (unlikely(ieee80211_is_beacon(fc) && result == RX_DROP_UNUSABLE))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel 5.8 through 5.19.x before 5.19.16, local attackers able to inject WLAN frames into the mac80211 stack could cause a NULL pointer dereference denial-of-service attack against the beacon protection of P2P devices.",
        "id": 3737
    },
    {
        "cve_id": "CVE-2022-3078",
        "code_before_change": "*vidtv_s302m_encoder_init(struct vidtv_s302m_encoder_init_args args)\n{\n\tu32 priv_sz = sizeof(struct vidtv_s302m_ctx);\n\tstruct vidtv_s302m_ctx *ctx;\n\tstruct vidtv_encoder *e;\n\n\te = kzalloc(sizeof(*e), GFP_KERNEL);\n\tif (!e)\n\t\treturn NULL;\n\n\te->id = S302M;\n\n\tif (args.name)\n\t\te->name = kstrdup(args.name, GFP_KERNEL);\n\n\te->encoder_buf = vzalloc(VIDTV_S302M_BUF_SZ);\n\te->encoder_buf_sz = VIDTV_S302M_BUF_SZ;\n\te->encoder_buf_offset = 0;\n\n\te->sample_count = 0;\n\n\te->src_buf = (args.src_buf) ? args.src_buf : NULL;\n\te->src_buf_sz = (args.src_buf) ? args.src_buf_sz : 0;\n\te->src_buf_offset = 0;\n\n\te->is_video_encoder = false;\n\n\tctx = kzalloc(priv_sz, GFP_KERNEL);\n\tif (!ctx) {\n\t\tkfree(e);\n\t\treturn NULL;\n\t}\n\n\te->ctx = ctx;\n\tctx->last_duration = 0;\n\n\te->encode = vidtv_s302m_encode;\n\te->clear = vidtv_s302m_clear;\n\n\te->es_pid = cpu_to_be16(args.es_pid);\n\te->stream_id = cpu_to_be16(PES_PRIVATE_STREAM_1);\n\n\te->sync = args.sync;\n\te->sampling_rate_hz = S302M_SAMPLING_RATE_HZ;\n\n\te->last_sample_cb = args.last_sample_cb;\n\n\te->destroy = vidtv_s302m_encoder_destroy;\n\n\tif (args.head) {\n\t\twhile (args.head->next)\n\t\t\targs.head = args.head->next;\n\n\t\targs.head->next = e;\n\t}\n\n\te->next = NULL;\n\n\treturn e;\n}",
        "code_after_change": "*vidtv_s302m_encoder_init(struct vidtv_s302m_encoder_init_args args)\n{\n\tu32 priv_sz = sizeof(struct vidtv_s302m_ctx);\n\tstruct vidtv_s302m_ctx *ctx;\n\tstruct vidtv_encoder *e;\n\n\te = kzalloc(sizeof(*e), GFP_KERNEL);\n\tif (!e)\n\t\treturn NULL;\n\n\te->id = S302M;\n\n\tif (args.name)\n\t\te->name = kstrdup(args.name, GFP_KERNEL);\n\n\te->encoder_buf = vzalloc(VIDTV_S302M_BUF_SZ);\n\tif (!e->encoder_buf)\n\t\tgoto out_kfree_e;\n\n\te->encoder_buf_sz = VIDTV_S302M_BUF_SZ;\n\te->encoder_buf_offset = 0;\n\n\te->sample_count = 0;\n\n\te->src_buf = (args.src_buf) ? args.src_buf : NULL;\n\te->src_buf_sz = (args.src_buf) ? args.src_buf_sz : 0;\n\te->src_buf_offset = 0;\n\n\te->is_video_encoder = false;\n\n\tctx = kzalloc(priv_sz, GFP_KERNEL);\n\tif (!ctx)\n\t\tgoto out_kfree_buf;\n\n\te->ctx = ctx;\n\tctx->last_duration = 0;\n\n\te->encode = vidtv_s302m_encode;\n\te->clear = vidtv_s302m_clear;\n\n\te->es_pid = cpu_to_be16(args.es_pid);\n\te->stream_id = cpu_to_be16(PES_PRIVATE_STREAM_1);\n\n\te->sync = args.sync;\n\te->sampling_rate_hz = S302M_SAMPLING_RATE_HZ;\n\n\te->last_sample_cb = args.last_sample_cb;\n\n\te->destroy = vidtv_s302m_encoder_destroy;\n\n\tif (args.head) {\n\t\twhile (args.head->next)\n\t\t\targs.head = args.head->next;\n\n\t\targs.head->next = e;\n\t}\n\n\te->next = NULL;\n\n\treturn e;\n\nout_kfree_buf:\n\tkfree(e->encoder_buf);\n\nout_kfree_e:\n\tkfree(e->name);\n\tkfree(e);\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,6 +14,9 @@\n \t\te->name = kstrdup(args.name, GFP_KERNEL);\n \n \te->encoder_buf = vzalloc(VIDTV_S302M_BUF_SZ);\n+\tif (!e->encoder_buf)\n+\t\tgoto out_kfree_e;\n+\n \te->encoder_buf_sz = VIDTV_S302M_BUF_SZ;\n \te->encoder_buf_offset = 0;\n \n@@ -26,10 +29,8 @@\n \te->is_video_encoder = false;\n \n \tctx = kzalloc(priv_sz, GFP_KERNEL);\n-\tif (!ctx) {\n-\t\tkfree(e);\n-\t\treturn NULL;\n-\t}\n+\tif (!ctx)\n+\t\tgoto out_kfree_buf;\n \n \te->ctx = ctx;\n \tctx->last_duration = 0;\n@@ -57,4 +58,12 @@\n \te->next = NULL;\n \n \treturn e;\n+\n+out_kfree_buf:\n+\tkfree(e->encoder_buf);\n+\n+out_kfree_e:\n+\tkfree(e->name);\n+\tkfree(e);\n+\treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!e->encoder_buf)",
                "\t\tgoto out_kfree_e;",
                "",
                "\tif (!ctx)",
                "\t\tgoto out_kfree_buf;",
                "",
                "out_kfree_buf:",
                "\tkfree(e->encoder_buf);",
                "",
                "out_kfree_e:",
                "\tkfree(e->name);",
                "\tkfree(e);",
                "\treturn NULL;"
            ],
            "deleted": [
                "\tif (!ctx) {",
                "\t\tkfree(e);",
                "\t\treturn NULL;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. There is a lack of check after calling vzalloc() and lack of free after allocation in drivers/media/test-drivers/vidtv/vidtv_s302m.c.",
        "id": 3547
    },
    {
        "cve_id": "CVE-2022-1789",
        "code_before_change": "void kvm_mmu_invpcid_gva(struct kvm_vcpu *vcpu, gva_t gva, unsigned long pcid)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\tbool tlb_flush = false;\n\tuint i;\n\n\tif (pcid == kvm_get_active_pcid(vcpu)) {\n\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);\n\t\ttlb_flush = true;\n\t}\n\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n\t\tif (VALID_PAGE(mmu->prev_roots[i].hpa) &&\n\t\t    pcid == kvm_get_pcid(vcpu, mmu->prev_roots[i].pgd)) {\n\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n\t\t\ttlb_flush = true;\n\t\t}\n\t}\n\n\tif (tlb_flush)\n\t\tstatic_call(kvm_x86_flush_tlb_gva)(vcpu, gva);\n\n\t++vcpu->stat.invlpg;\n\n\t/*\n\t * Mappings not reachable via the current cr3 or the prev_roots will be\n\t * synced when switching to that cr3, so nothing needs to be done here\n\t * for them.\n\t */\n}",
        "code_after_change": "void kvm_mmu_invpcid_gva(struct kvm_vcpu *vcpu, gva_t gva, unsigned long pcid)\n{\n\tstruct kvm_mmu *mmu = vcpu->arch.mmu;\n\tbool tlb_flush = false;\n\tuint i;\n\n\tif (pcid == kvm_get_active_pcid(vcpu)) {\n\t\tif (mmu->invlpg)\n\t\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);\n\t\ttlb_flush = true;\n\t}\n\n\tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n\t\tif (VALID_PAGE(mmu->prev_roots[i].hpa) &&\n\t\t    pcid == kvm_get_pcid(vcpu, mmu->prev_roots[i].pgd)) {\n\t\t\tif (mmu->invlpg)\n\t\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n\t\t\ttlb_flush = true;\n\t\t}\n\t}\n\n\tif (tlb_flush)\n\t\tstatic_call(kvm_x86_flush_tlb_gva)(vcpu, gva);\n\n\t++vcpu->stat.invlpg;\n\n\t/*\n\t * Mappings not reachable via the current cr3 or the prev_roots will be\n\t * synced when switching to that cr3, so nothing needs to be done here\n\t * for them.\n\t */\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,14 +5,16 @@\n \tuint i;\n \n \tif (pcid == kvm_get_active_pcid(vcpu)) {\n-\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);\n+\t\tif (mmu->invlpg)\n+\t\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);\n \t\ttlb_flush = true;\n \t}\n \n \tfor (i = 0; i < KVM_MMU_NUM_PREV_ROOTS; i++) {\n \t\tif (VALID_PAGE(mmu->prev_roots[i].hpa) &&\n \t\t    pcid == kvm_get_pcid(vcpu, mmu->prev_roots[i].pgd)) {\n-\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n+\t\t\tif (mmu->invlpg)\n+\t\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);\n \t\t\ttlb_flush = true;\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (mmu->invlpg)",
                "\t\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);",
                "\t\t\tif (mmu->invlpg)",
                "\t\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);"
            ],
            "deleted": [
                "\t\tmmu->invlpg(vcpu, gva, mmu->root.hpa);",
                "\t\t\tmmu->invlpg(vcpu, gva, mmu->prev_roots[i].hpa);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "With shadow paging enabled, the INVPCID instruction results in a call to kvm_mmu_invpcid_gva. If INVPCID is executed with CR0.PG=0, the invlpg callback is not set and the result is a NULL pointer dereference.",
        "id": 3292
    },
    {
        "cve_id": "CVE-2023-1095",
        "code_before_change": "static struct nft_trans *nft_trans_alloc_gfp(const struct nft_ctx *ctx,\n\t\t\t\t\t     int msg_type, u32 size, gfp_t gfp)\n{\n\tstruct nft_trans *trans;\n\n\ttrans = kzalloc(sizeof(struct nft_trans) + size, gfp);\n\tif (trans == NULL)\n\t\treturn NULL;\n\n\ttrans->msg_type = msg_type;\n\ttrans->ctx\t= *ctx;\n\n\treturn trans;\n}",
        "code_after_change": "static struct nft_trans *nft_trans_alloc_gfp(const struct nft_ctx *ctx,\n\t\t\t\t\t     int msg_type, u32 size, gfp_t gfp)\n{\n\tstruct nft_trans *trans;\n\n\ttrans = kzalloc(sizeof(struct nft_trans) + size, gfp);\n\tif (trans == NULL)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&trans->list);\n\ttrans->msg_type = msg_type;\n\ttrans->ctx\t= *ctx;\n\n\treturn trans;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,7 @@\n \tif (trans == NULL)\n \t\treturn NULL;\n \n+\tINIT_LIST_HEAD(&trans->list);\n \ttrans->msg_type = msg_type;\n \ttrans->ctx\t= *ctx;\n ",
        "function_modified_lines": {
            "added": [
                "\tINIT_LIST_HEAD(&trans->list);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In nf_tables_updtable, if nf_tables_table_enable returns an error, nft_trans_destroy is called to free the transaction object. nft_trans_destroy() calls list_del(), but the transaction was never placed on a list -- the list head is all zeroes, this results in a NULL pointer dereference.",
        "id": 3848
    },
    {
        "cve_id": "CVE-2017-2634",
        "code_before_change": "int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)\n{\n\tstruct sk_buff *skb;\n\t/*\n\t * FIXME: what if rebuild_header fails?\n\t * Should we be doing a rebuild_header here?\n\t */\n\tint err = inet_sk_rebuild_header(sk);\n\n\tif (err != 0)\n\t\treturn err;\n\n\tskb = sock_wmalloc(sk, sk->sk_prot->max_header, 1, GFP_ATOMIC);\n\tif (skb == NULL)\n\t\treturn -ENOBUFS;\n\n\t/* Reserve space for headers and prepare control bits. */\n\tskb_reserve(skb, sk->sk_prot->max_header);\n\tDCCP_SKB_CB(skb)->dccpd_type\t   = DCCP_PKT_RESET;\n\tDCCP_SKB_CB(skb)->dccpd_reset_code = code;\n\n\treturn dccp_transmit_skb(sk, skb);\n}",
        "code_after_change": "int dccp_send_reset(struct sock *sk, enum dccp_reset_codes code)\n{\n\tstruct sk_buff *skb;\n\t/*\n\t * FIXME: what if rebuild_header fails?\n\t * Should we be doing a rebuild_header here?\n\t */\n\tint err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);\n\n\tif (err != 0)\n\t\treturn err;\n\n\tskb = sock_wmalloc(sk, sk->sk_prot->max_header, 1, GFP_ATOMIC);\n\tif (skb == NULL)\n\t\treturn -ENOBUFS;\n\n\t/* Reserve space for headers and prepare control bits. */\n\tskb_reserve(skb, sk->sk_prot->max_header);\n\tDCCP_SKB_CB(skb)->dccpd_type\t   = DCCP_PKT_RESET;\n\tDCCP_SKB_CB(skb)->dccpd_reset_code = code;\n\n\treturn dccp_transmit_skb(sk, skb);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \t * FIXME: what if rebuild_header fails?\n \t * Should we be doing a rebuild_header here?\n \t */\n-\tint err = inet_sk_rebuild_header(sk);\n+\tint err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);\n \n \tif (err != 0)\n \t\treturn err;",
        "function_modified_lines": {
            "added": [
                "\tint err = inet_csk(sk)->icsk_af_ops->rebuild_header(sk);"
            ],
            "deleted": [
                "\tint err = inet_sk_rebuild_header(sk);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "It was found that the Linux kernel's Datagram Congestion Control Protocol (DCCP) implementation before 2.6.22.17 used the IPv4-only inet_sk_rebuild_header() function for both IPv4 and IPv6 DCCP connections, which could result in memory corruptions. A remote attacker could use this flaw to crash the system.",
        "id": 1449
    },
    {
        "cve_id": "CVE-2018-14614",
        "code_before_change": "int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_checkpoint *cp_block;\n\tstruct f2fs_super_block *fsb = sbi->raw_super;\n\tstruct page *cp1, *cp2, *cur_page;\n\tunsigned long blk_size = sbi->blocksize;\n\tunsigned long long cp1_version = 0, cp2_version = 0;\n\tunsigned long long cp_start_blk_no;\n\tunsigned int cp_blks = 1 + __cp_payload(sbi);\n\tblock_t cp_blk_no;\n\tint i;\n\n\tsbi->ckpt = f2fs_kzalloc(sbi, array_size(blk_size, cp_blks),\n\t\t\t\t GFP_KERNEL);\n\tif (!sbi->ckpt)\n\t\treturn -ENOMEM;\n\t/*\n\t * Finding out valid cp block involves read both\n\t * sets( cp pack1 and cp pack 2)\n\t */\n\tcp_start_blk_no = le32_to_cpu(fsb->cp_blkaddr);\n\tcp1 = validate_checkpoint(sbi, cp_start_blk_no, &cp1_version);\n\n\t/* The second checkpoint pack should start at the next segment */\n\tcp_start_blk_no += ((unsigned long long)1) <<\n\t\t\t\tle32_to_cpu(fsb->log_blocks_per_seg);\n\tcp2 = validate_checkpoint(sbi, cp_start_blk_no, &cp2_version);\n\n\tif (cp1 && cp2) {\n\t\tif (ver_after(cp2_version, cp1_version))\n\t\t\tcur_page = cp2;\n\t\telse\n\t\t\tcur_page = cp1;\n\t} else if (cp1) {\n\t\tcur_page = cp1;\n\t} else if (cp2) {\n\t\tcur_page = cp2;\n\t} else {\n\t\tgoto fail_no_cp;\n\t}\n\n\tcp_block = (struct f2fs_checkpoint *)page_address(cur_page);\n\tmemcpy(sbi->ckpt, cp_block, blk_size);\n\n\t/* Sanity checking of checkpoint */\n\tif (f2fs_sanity_check_ckpt(sbi))\n\t\tgoto free_fail_no_cp;\n\n\tif (cur_page == cp1)\n\t\tsbi->cur_cp_pack = 1;\n\telse\n\t\tsbi->cur_cp_pack = 2;\n\n\tif (cp_blks <= 1)\n\t\tgoto done;\n\n\tcp_blk_no = le32_to_cpu(fsb->cp_blkaddr);\n\tif (cur_page == cp2)\n\t\tcp_blk_no += 1 << le32_to_cpu(fsb->log_blocks_per_seg);\n\n\tfor (i = 1; i < cp_blks; i++) {\n\t\tvoid *sit_bitmap_ptr;\n\t\tunsigned char *ckpt = (unsigned char *)sbi->ckpt;\n\n\t\tcur_page = f2fs_get_meta_page(sbi, cp_blk_no + i);\n\t\tif (IS_ERR(cur_page))\n\t\t\tgoto free_fail_no_cp;\n\t\tsit_bitmap_ptr = page_address(cur_page);\n\t\tmemcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);\n\t\tf2fs_put_page(cur_page, 1);\n\t}\ndone:\n\tf2fs_put_page(cp1, 1);\n\tf2fs_put_page(cp2, 1);\n\treturn 0;\n\nfree_fail_no_cp:\n\tf2fs_put_page(cp1, 1);\n\tf2fs_put_page(cp2, 1);\nfail_no_cp:\n\tkfree(sbi->ckpt);\n\treturn -EINVAL;\n}",
        "code_after_change": "int f2fs_get_valid_checkpoint(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_checkpoint *cp_block;\n\tstruct f2fs_super_block *fsb = sbi->raw_super;\n\tstruct page *cp1, *cp2, *cur_page;\n\tunsigned long blk_size = sbi->blocksize;\n\tunsigned long long cp1_version = 0, cp2_version = 0;\n\tunsigned long long cp_start_blk_no;\n\tunsigned int cp_blks = 1 + __cp_payload(sbi);\n\tblock_t cp_blk_no;\n\tint i;\n\n\tsbi->ckpt = f2fs_kzalloc(sbi, array_size(blk_size, cp_blks),\n\t\t\t\t GFP_KERNEL);\n\tif (!sbi->ckpt)\n\t\treturn -ENOMEM;\n\t/*\n\t * Finding out valid cp block involves read both\n\t * sets( cp pack1 and cp pack 2)\n\t */\n\tcp_start_blk_no = le32_to_cpu(fsb->cp_blkaddr);\n\tcp1 = validate_checkpoint(sbi, cp_start_blk_no, &cp1_version);\n\n\t/* The second checkpoint pack should start at the next segment */\n\tcp_start_blk_no += ((unsigned long long)1) <<\n\t\t\t\tle32_to_cpu(fsb->log_blocks_per_seg);\n\tcp2 = validate_checkpoint(sbi, cp_start_blk_no, &cp2_version);\n\n\tif (cp1 && cp2) {\n\t\tif (ver_after(cp2_version, cp1_version))\n\t\t\tcur_page = cp2;\n\t\telse\n\t\t\tcur_page = cp1;\n\t} else if (cp1) {\n\t\tcur_page = cp1;\n\t} else if (cp2) {\n\t\tcur_page = cp2;\n\t} else {\n\t\tgoto fail_no_cp;\n\t}\n\n\tcp_block = (struct f2fs_checkpoint *)page_address(cur_page);\n\tmemcpy(sbi->ckpt, cp_block, blk_size);\n\n\tif (cur_page == cp1)\n\t\tsbi->cur_cp_pack = 1;\n\telse\n\t\tsbi->cur_cp_pack = 2;\n\n\t/* Sanity checking of checkpoint */\n\tif (f2fs_sanity_check_ckpt(sbi))\n\t\tgoto free_fail_no_cp;\n\n\tif (cp_blks <= 1)\n\t\tgoto done;\n\n\tcp_blk_no = le32_to_cpu(fsb->cp_blkaddr);\n\tif (cur_page == cp2)\n\t\tcp_blk_no += 1 << le32_to_cpu(fsb->log_blocks_per_seg);\n\n\tfor (i = 1; i < cp_blks; i++) {\n\t\tvoid *sit_bitmap_ptr;\n\t\tunsigned char *ckpt = (unsigned char *)sbi->ckpt;\n\n\t\tcur_page = f2fs_get_meta_page(sbi, cp_blk_no + i);\n\t\tif (IS_ERR(cur_page))\n\t\t\tgoto free_fail_no_cp;\n\t\tsit_bitmap_ptr = page_address(cur_page);\n\t\tmemcpy(ckpt + i * blk_size, sit_bitmap_ptr, blk_size);\n\t\tf2fs_put_page(cur_page, 1);\n\t}\ndone:\n\tf2fs_put_page(cp1, 1);\n\tf2fs_put_page(cp2, 1);\n\treturn 0;\n\nfree_fail_no_cp:\n\tf2fs_put_page(cp1, 1);\n\tf2fs_put_page(cp2, 1);\nfail_no_cp:\n\tkfree(sbi->ckpt);\n\treturn -EINVAL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,14 +42,14 @@\n \tcp_block = (struct f2fs_checkpoint *)page_address(cur_page);\n \tmemcpy(sbi->ckpt, cp_block, blk_size);\n \n-\t/* Sanity checking of checkpoint */\n-\tif (f2fs_sanity_check_ckpt(sbi))\n-\t\tgoto free_fail_no_cp;\n-\n \tif (cur_page == cp1)\n \t\tsbi->cur_cp_pack = 1;\n \telse\n \t\tsbi->cur_cp_pack = 2;\n+\n+\t/* Sanity checking of checkpoint */\n+\tif (f2fs_sanity_check_ckpt(sbi))\n+\t\tgoto free_fail_no_cp;\n \n \tif (cp_blks <= 1)\n \t\tgoto done;",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* Sanity checking of checkpoint */",
                "\tif (f2fs_sanity_check_ckpt(sbi))",
                "\t\tgoto free_fail_no_cp;"
            ],
            "deleted": [
                "\t/* Sanity checking of checkpoint */",
                "\tif (f2fs_sanity_check_ckpt(sbi))",
                "\t\tgoto free_fail_no_cp;",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is an out-of-bounds access in __remove_dirty_segment() in fs/f2fs/segment.c when mounting an f2fs image.",
        "id": 1684
    },
    {
        "cve_id": "CVE-2022-3106",
        "code_before_change": "static size_t ef100_update_stats(struct efx_nic *efx,\n\t\t\t\t u64 *full_stats,\n\t\t\t\t struct rtnl_link_stats64 *core_stats)\n{\n\t__le64 *mc_stats = kmalloc(array_size(efx->num_mac_stats, sizeof(__le64)), GFP_ATOMIC);\n\tstruct ef100_nic_data *nic_data = efx->nic_data;\n\tDECLARE_BITMAP(mask, EF100_STAT_COUNT) = {};\n\tu64 *stats = nic_data->stats;\n\n\tef100_common_stat_mask(mask);\n\tef100_ethtool_stat_mask(mask);\n\n\tefx_nic_copy_stats(efx, mc_stats);\n\tefx_nic_update_stats(ef100_stat_desc, EF100_STAT_COUNT, mask,\n\t\t\t     stats, mc_stats, false);\n\n\tkfree(mc_stats);\n\n\treturn ef100_update_stats_common(efx, full_stats, core_stats);\n}",
        "code_after_change": "static size_t ef100_update_stats(struct efx_nic *efx,\n\t\t\t\t u64 *full_stats,\n\t\t\t\t struct rtnl_link_stats64 *core_stats)\n{\n\t__le64 *mc_stats = kmalloc(array_size(efx->num_mac_stats, sizeof(__le64)), GFP_ATOMIC);\n\tstruct ef100_nic_data *nic_data = efx->nic_data;\n\tDECLARE_BITMAP(mask, EF100_STAT_COUNT) = {};\n\tu64 *stats = nic_data->stats;\n\n\tef100_common_stat_mask(mask);\n\tef100_ethtool_stat_mask(mask);\n\n\tif (!mc_stats)\n\t\treturn 0;\n\n\tefx_nic_copy_stats(efx, mc_stats);\n\tefx_nic_update_stats(ef100_stat_desc, EF100_STAT_COUNT, mask,\n\t\t\t     stats, mc_stats, false);\n\n\tkfree(mc_stats);\n\n\treturn ef100_update_stats_common(efx, full_stats, core_stats);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,9 @@\n \tef100_common_stat_mask(mask);\n \tef100_ethtool_stat_mask(mask);\n \n+\tif (!mc_stats)\n+\t\treturn 0;\n+\n \tefx_nic_copy_stats(efx, mc_stats);\n \tefx_nic_update_stats(ef100_stat_desc, EF100_STAT_COUNT, mask,\n \t\t\t     stats, mc_stats, false);",
        "function_modified_lines": {
            "added": [
                "\tif (!mc_stats)",
                "\t\treturn 0;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. ef100_update_stats in drivers/net/ethernet/sfc/ef100_nic.c lacks check of the return value of kmalloc().",
        "id": 3551
    },
    {
        "cve_id": "CVE-2019-10207",
        "code_before_change": "static int mrvl_open(struct hci_uart *hu)\n{\n\tstruct mrvl_data *mrvl;\n\tint ret;\n\n\tBT_DBG(\"hu %p\", hu);\n\n\tmrvl = kzalloc(sizeof(*mrvl), GFP_KERNEL);\n\tif (!mrvl)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&mrvl->txq);\n\tskb_queue_head_init(&mrvl->rawq);\n\n\tset_bit(STATE_CHIP_VER_PENDING, &mrvl->flags);\n\n\thu->priv = mrvl;\n\n\tif (hu->serdev) {\n\t\tret = serdev_device_open(hu->serdev);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tkfree(mrvl);\n\n\treturn ret;\n}",
        "code_after_change": "static int mrvl_open(struct hci_uart *hu)\n{\n\tstruct mrvl_data *mrvl;\n\tint ret;\n\n\tBT_DBG(\"hu %p\", hu);\n\n\tif (!hci_uart_has_flow_control(hu))\n\t\treturn -EOPNOTSUPP;\n\n\tmrvl = kzalloc(sizeof(*mrvl), GFP_KERNEL);\n\tif (!mrvl)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&mrvl->txq);\n\tskb_queue_head_init(&mrvl->rawq);\n\n\tset_bit(STATE_CHIP_VER_PENDING, &mrvl->flags);\n\n\thu->priv = mrvl;\n\n\tif (hu->serdev) {\n\t\tret = serdev_device_open(hu->serdev);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tkfree(mrvl);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tint ret;\n \n \tBT_DBG(\"hu %p\", hu);\n+\n+\tif (!hci_uart_has_flow_control(hu))\n+\t\treturn -EOPNOTSUPP;\n \n \tmrvl = kzalloc(sizeof(*mrvl), GFP_KERNEL);\n \tif (!mrvl)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!hci_uart_has_flow_control(hu))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's Bluetooth implementation of UART, all versions kernel 3.x.x before 4.18.0 and kernel 5.x.x. An attacker with local access and write permissions to the Bluetooth hardware could use this flaw to issue a specially crafted ioctl function call and cause the system to crash.",
        "id": 1899
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_helper_call(struct bpf_verifier_env *env, struct bpf_insn *insn,\n\t\t\t     int *insn_idx_p)\n{\n\tconst struct bpf_func_proto *fn = NULL;\n\tenum bpf_return_type ret_type;\n\tstruct bpf_reg_state *regs;\n\tstruct bpf_call_arg_meta meta;\n\tint insn_idx = *insn_idx_p;\n\tbool changes_data;\n\tint i, err, func_id;\n\n\t/* find function prototype */\n\tfunc_id = insn->imm;\n\tif (func_id < 0 || func_id >= __BPF_FUNC_MAX_ID) {\n\t\tverbose(env, \"invalid func %s#%d\\n\", func_id_name(func_id),\n\t\t\tfunc_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (env->ops->get_func_proto)\n\t\tfn = env->ops->get_func_proto(func_id, env->prog);\n\tif (!fn) {\n\t\tverbose(env, \"unknown func %s#%d\\n\", func_id_name(func_id),\n\t\t\tfunc_id);\n\t\treturn -EINVAL;\n\t}\n\n\t/* eBPF programs must be GPL compatible to use GPL-ed functions */\n\tif (!env->prog->gpl_compatible && fn->gpl_only) {\n\t\tverbose(env, \"cannot call GPL-restricted function from non-GPL compatible program\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (fn->allowed && !fn->allowed(env->prog)) {\n\t\tverbose(env, \"helper call is not allowed in probe\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* With LD_ABS/IND some JITs save/restore skb from r1. */\n\tchanges_data = bpf_helper_changes_pkt_data(fn->func);\n\tif (changes_data && fn->arg1_type != ARG_PTR_TO_CTX) {\n\t\tverbose(env, \"kernel subsystem misconfigured func %s#%d: r1 != ctx\\n\",\n\t\t\tfunc_id_name(func_id), func_id);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&meta, 0, sizeof(meta));\n\tmeta.pkt_access = fn->pkt_access;\n\n\terr = check_func_proto(fn, func_id);\n\tif (err) {\n\t\tverbose(env, \"kernel subsystem misconfigured func %s#%d\\n\",\n\t\t\tfunc_id_name(func_id), func_id);\n\t\treturn err;\n\t}\n\n\tmeta.func_id = func_id;\n\t/* check args */\n\tfor (i = 0; i < MAX_BPF_FUNC_REG_ARGS; i++) {\n\t\terr = check_func_arg(env, i, &meta, fn);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = record_func_map(env, &meta, func_id, insn_idx);\n\tif (err)\n\t\treturn err;\n\n\terr = record_func_key(env, &meta, func_id, insn_idx);\n\tif (err)\n\t\treturn err;\n\n\t/* Mark slots with STACK_MISC in case of raw mode, stack offset\n\t * is inferred from register state.\n\t */\n\tfor (i = 0; i < meta.access_size; i++) {\n\t\terr = check_mem_access(env, insn_idx, meta.regno, i, BPF_B,\n\t\t\t\t       BPF_WRITE, -1, false);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (is_release_function(func_id)) {\n\t\terr = release_reference(env, meta.ref_obj_id);\n\t\tif (err) {\n\t\t\tverbose(env, \"func %s#%d reference has not been acquired before\\n\",\n\t\t\t\tfunc_id_name(func_id), func_id);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tregs = cur_regs(env);\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_tail_call:\n\t\terr = check_reference_leak(env);\n\t\tif (err) {\n\t\t\tverbose(env, \"tail_call would lead to reference leak\\n\");\n\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\tcase BPF_FUNC_get_local_storage:\n\t\t/* check that flags argument in get_local_storage(map, flags) is 0,\n\t\t * this is required because get_local_storage() can't return an error.\n\t\t */\n\t\tif (!register_is_null(&regs[BPF_REG_2])) {\n\t\t\tverbose(env, \"get_local_storage() doesn't support non-zero flags\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_map_elem_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_timer_set_callback:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_timer_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_find_vma:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_find_vma_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_snprintf:\n\t\terr = check_bpf_snprintf_call(env, regs);\n\t\tbreak;\n\tcase BPF_FUNC_loop:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_loop_callback_state);\n\t\tbreak;\n\t}\n\n\tif (err)\n\t\treturn err;\n\n\t/* reset caller saved regs */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* helper call returns 64-bit value. */\n\tregs[BPF_REG_0].subreg_def = DEF_NOT_SUBREG;\n\n\t/* update return register (already marked as written above) */\n\tret_type = fn->ret_type;\n\tif (ret_type == RET_INTEGER) {\n\t\t/* sets type to SCALAR_VALUE */\n\t\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t} else if (ret_type == RET_VOID) {\n\t\tregs[BPF_REG_0].type = NOT_INIT;\n\t} else if (base_type(ret_type) == RET_PTR_TO_MAP_VALUE) {\n\t\t/* There is no offset yet applied, variable or fixed */\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\t/* remember map_ptr, so that check_map_access()\n\t\t * can check 'value_size' boundary of memory access\n\t\t * to map element returned from bpf_map_lookup_elem()\n\t\t */\n\t\tif (meta.map_ptr == NULL) {\n\t\t\tverbose(env,\n\t\t\t\t\"kernel subsystem misconfigured verifier\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tregs[BPF_REG_0].map_ptr = meta.map_ptr;\n\t\tregs[BPF_REG_0].map_uid = meta.map_uid;\n\t\tif (type_may_be_null(ret_type)) {\n\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE_OR_NULL;\n\t\t} else {\n\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE;\n\t\t\tif (map_value_has_spin_lock(meta.map_ptr))\n\t\t\t\tregs[BPF_REG_0].id = ++env->id_gen;\n\t\t}\n\t} else if (base_type(ret_type) == RET_PTR_TO_SOCKET) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET_OR_NULL;\n\t} else if (base_type(ret_type) == RET_PTR_TO_SOCK_COMMON) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON_OR_NULL;\n\t} else if (base_type(ret_type) == RET_PTR_TO_TCP_SOCK) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK_OR_NULL;\n\t} else if (base_type(ret_type) == RET_PTR_TO_ALLOC_MEM) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;\n\t\tregs[BPF_REG_0].mem_size = meta.mem_size;\n\t} else if (base_type(ret_type) == RET_PTR_TO_MEM_OR_BTF_ID) {\n\t\tconst struct btf_type *t;\n\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tt = btf_type_skip_modifiers(meta.ret_btf, meta.ret_btf_id, NULL);\n\t\tif (!btf_type_is_struct(t)) {\n\t\t\tu32 tsize;\n\t\t\tconst struct btf_type *ret;\n\t\t\tconst char *tname;\n\n\t\t\t/* resolve the type size of ksym. */\n\t\t\tret = btf_resolve_size(meta.ret_btf, t, &tsize);\n\t\t\tif (IS_ERR(ret)) {\n\t\t\t\ttname = btf_name_by_offset(meta.ret_btf, t->name_off);\n\t\t\t\tverbose(env, \"unable to resolve the size of type '%s': %ld\\n\",\n\t\t\t\t\ttname, PTR_ERR(ret));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tregs[BPF_REG_0].type =\n\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?\n\t\t\t\tPTR_TO_MEM_OR_NULL : PTR_TO_MEM;\n\t\t\tregs[BPF_REG_0].mem_size = tsize;\n\t\t} else {\n\t\t\tregs[BPF_REG_0].type =\n\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?\n\t\t\t\tPTR_TO_BTF_ID_OR_NULL : PTR_TO_BTF_ID;\n\t\t\tregs[BPF_REG_0].btf = meta.ret_btf;\n\t\t\tregs[BPF_REG_0].btf_id = meta.ret_btf_id;\n\t\t}\n\t} else if (base_type(ret_type) == RET_PTR_TO_BTF_ID) {\n\t\tint ret_btf_id;\n\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = (ret_type & PTR_MAYBE_NULL) ?\n\t\t\t\t\t\t     PTR_TO_BTF_ID_OR_NULL :\n\t\t\t\t\t\t     PTR_TO_BTF_ID;\n\t\tret_btf_id = *fn->ret_btf_id;\n\t\tif (ret_btf_id == 0) {\n\t\t\tverbose(env, \"invalid return type %u of func %s#%d\\n\",\n\t\t\t\tbase_type(ret_type), func_id_name(func_id),\n\t\t\t\tfunc_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* current BPF helper definitions are only coming from\n\t\t * built-in code with type IDs from  vmlinux BTF\n\t\t */\n\t\tregs[BPF_REG_0].btf = btf_vmlinux;\n\t\tregs[BPF_REG_0].btf_id = ret_btf_id;\n\t} else {\n\t\tverbose(env, \"unknown return type %u of func %s#%d\\n\",\n\t\t\tbase_type(ret_type), func_id_name(func_id), func_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (reg_type_may_be_null(regs[BPF_REG_0].type))\n\t\tregs[BPF_REG_0].id = ++env->id_gen;\n\n\tif (is_ptr_cast_function(func_id)) {\n\t\t/* For release_reference() */\n\t\tregs[BPF_REG_0].ref_obj_id = meta.ref_obj_id;\n\t} else if (is_acquire_function(func_id, meta.map_ptr)) {\n\t\tint id = acquire_reference_state(env, insn_idx);\n\n\t\tif (id < 0)\n\t\t\treturn id;\n\t\t/* For mark_ptr_or_null_reg() */\n\t\tregs[BPF_REG_0].id = id;\n\t\t/* For release_reference() */\n\t\tregs[BPF_REG_0].ref_obj_id = id;\n\t}\n\n\tdo_refine_retval_range(regs, fn->ret_type, func_id, &meta);\n\n\terr = check_map_func_compatibility(env, meta.map_ptr, func_id);\n\tif (err)\n\t\treturn err;\n\n\tif ((func_id == BPF_FUNC_get_stack ||\n\t     func_id == BPF_FUNC_get_task_stack) &&\n\t    !env->prog->has_callchain_buf) {\n\t\tconst char *err_str;\n\n#ifdef CONFIG_PERF_EVENTS\n\t\terr = get_callchain_buffers(sysctl_perf_event_max_stack);\n\t\terr_str = \"cannot get callchain buffer for func %s#%d\\n\";\n#else\n\t\terr = -ENOTSUPP;\n\t\terr_str = \"func %s#%d not supported without CONFIG_PERF_EVENTS\\n\";\n#endif\n\t\tif (err) {\n\t\t\tverbose(env, err_str, func_id_name(func_id), func_id);\n\t\t\treturn err;\n\t\t}\n\n\t\tenv->prog->has_callchain_buf = true;\n\t}\n\n\tif (func_id == BPF_FUNC_get_stackid || func_id == BPF_FUNC_get_stack)\n\t\tenv->prog->call_get_stack = true;\n\n\tif (func_id == BPF_FUNC_get_func_ip) {\n\t\tif (check_get_func_ip(env))\n\t\t\treturn -ENOTSUPP;\n\t\tenv->prog->call_get_func_ip = true;\n\t}\n\n\tif (changes_data)\n\t\tclear_all_pkt_pointers(env);\n\treturn 0;\n}",
        "code_after_change": "static int check_helper_call(struct bpf_verifier_env *env, struct bpf_insn *insn,\n\t\t\t     int *insn_idx_p)\n{\n\tconst struct bpf_func_proto *fn = NULL;\n\tenum bpf_return_type ret_type;\n\tenum bpf_type_flag ret_flag;\n\tstruct bpf_reg_state *regs;\n\tstruct bpf_call_arg_meta meta;\n\tint insn_idx = *insn_idx_p;\n\tbool changes_data;\n\tint i, err, func_id;\n\n\t/* find function prototype */\n\tfunc_id = insn->imm;\n\tif (func_id < 0 || func_id >= __BPF_FUNC_MAX_ID) {\n\t\tverbose(env, \"invalid func %s#%d\\n\", func_id_name(func_id),\n\t\t\tfunc_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (env->ops->get_func_proto)\n\t\tfn = env->ops->get_func_proto(func_id, env->prog);\n\tif (!fn) {\n\t\tverbose(env, \"unknown func %s#%d\\n\", func_id_name(func_id),\n\t\t\tfunc_id);\n\t\treturn -EINVAL;\n\t}\n\n\t/* eBPF programs must be GPL compatible to use GPL-ed functions */\n\tif (!env->prog->gpl_compatible && fn->gpl_only) {\n\t\tverbose(env, \"cannot call GPL-restricted function from non-GPL compatible program\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (fn->allowed && !fn->allowed(env->prog)) {\n\t\tverbose(env, \"helper call is not allowed in probe\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* With LD_ABS/IND some JITs save/restore skb from r1. */\n\tchanges_data = bpf_helper_changes_pkt_data(fn->func);\n\tif (changes_data && fn->arg1_type != ARG_PTR_TO_CTX) {\n\t\tverbose(env, \"kernel subsystem misconfigured func %s#%d: r1 != ctx\\n\",\n\t\t\tfunc_id_name(func_id), func_id);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&meta, 0, sizeof(meta));\n\tmeta.pkt_access = fn->pkt_access;\n\n\terr = check_func_proto(fn, func_id);\n\tif (err) {\n\t\tverbose(env, \"kernel subsystem misconfigured func %s#%d\\n\",\n\t\t\tfunc_id_name(func_id), func_id);\n\t\treturn err;\n\t}\n\n\tmeta.func_id = func_id;\n\t/* check args */\n\tfor (i = 0; i < MAX_BPF_FUNC_REG_ARGS; i++) {\n\t\terr = check_func_arg(env, i, &meta, fn);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = record_func_map(env, &meta, func_id, insn_idx);\n\tif (err)\n\t\treturn err;\n\n\terr = record_func_key(env, &meta, func_id, insn_idx);\n\tif (err)\n\t\treturn err;\n\n\t/* Mark slots with STACK_MISC in case of raw mode, stack offset\n\t * is inferred from register state.\n\t */\n\tfor (i = 0; i < meta.access_size; i++) {\n\t\terr = check_mem_access(env, insn_idx, meta.regno, i, BPF_B,\n\t\t\t\t       BPF_WRITE, -1, false);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (is_release_function(func_id)) {\n\t\terr = release_reference(env, meta.ref_obj_id);\n\t\tif (err) {\n\t\t\tverbose(env, \"func %s#%d reference has not been acquired before\\n\",\n\t\t\t\tfunc_id_name(func_id), func_id);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tregs = cur_regs(env);\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_tail_call:\n\t\terr = check_reference_leak(env);\n\t\tif (err) {\n\t\t\tverbose(env, \"tail_call would lead to reference leak\\n\");\n\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\tcase BPF_FUNC_get_local_storage:\n\t\t/* check that flags argument in get_local_storage(map, flags) is 0,\n\t\t * this is required because get_local_storage() can't return an error.\n\t\t */\n\t\tif (!register_is_null(&regs[BPF_REG_2])) {\n\t\t\tverbose(env, \"get_local_storage() doesn't support non-zero flags\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_map_elem_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_timer_set_callback:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_timer_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_find_vma:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_find_vma_callback_state);\n\t\tbreak;\n\tcase BPF_FUNC_snprintf:\n\t\terr = check_bpf_snprintf_call(env, regs);\n\t\tbreak;\n\tcase BPF_FUNC_loop:\n\t\terr = __check_func_call(env, insn, insn_idx_p, meta.subprogno,\n\t\t\t\t\tset_loop_callback_state);\n\t\tbreak;\n\t}\n\n\tif (err)\n\t\treturn err;\n\n\t/* reset caller saved regs */\n\tfor (i = 0; i < CALLER_SAVED_REGS; i++) {\n\t\tmark_reg_not_init(env, regs, caller_saved[i]);\n\t\tcheck_reg_arg(env, caller_saved[i], DST_OP_NO_MARK);\n\t}\n\n\t/* helper call returns 64-bit value. */\n\tregs[BPF_REG_0].subreg_def = DEF_NOT_SUBREG;\n\n\t/* update return register (already marked as written above) */\n\tret_type = fn->ret_type;\n\tret_flag = type_flag(fn->ret_type);\n\tif (ret_type == RET_INTEGER) {\n\t\t/* sets type to SCALAR_VALUE */\n\t\tmark_reg_unknown(env, regs, BPF_REG_0);\n\t} else if (ret_type == RET_VOID) {\n\t\tregs[BPF_REG_0].type = NOT_INIT;\n\t} else if (base_type(ret_type) == RET_PTR_TO_MAP_VALUE) {\n\t\t/* There is no offset yet applied, variable or fixed */\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\t/* remember map_ptr, so that check_map_access()\n\t\t * can check 'value_size' boundary of memory access\n\t\t * to map element returned from bpf_map_lookup_elem()\n\t\t */\n\t\tif (meta.map_ptr == NULL) {\n\t\t\tverbose(env,\n\t\t\t\t\"kernel subsystem misconfigured verifier\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tregs[BPF_REG_0].map_ptr = meta.map_ptr;\n\t\tregs[BPF_REG_0].map_uid = meta.map_uid;\n\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE | ret_flag;\n\t\tif (!type_may_be_null(ret_type) &&\n\t\t    map_value_has_spin_lock(meta.map_ptr)) {\n\t\t\tregs[BPF_REG_0].id = ++env->id_gen;\n\t\t}\n\t} else if (base_type(ret_type) == RET_PTR_TO_SOCKET) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET | ret_flag;\n\t} else if (base_type(ret_type) == RET_PTR_TO_SOCK_COMMON) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON | ret_flag;\n\t} else if (base_type(ret_type) == RET_PTR_TO_TCP_SOCK) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK | ret_flag;\n\t} else if (base_type(ret_type) == RET_PTR_TO_ALLOC_MEM) {\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;\n\t\tregs[BPF_REG_0].mem_size = meta.mem_size;\n\t} else if (base_type(ret_type) == RET_PTR_TO_MEM_OR_BTF_ID) {\n\t\tconst struct btf_type *t;\n\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tt = btf_type_skip_modifiers(meta.ret_btf, meta.ret_btf_id, NULL);\n\t\tif (!btf_type_is_struct(t)) {\n\t\t\tu32 tsize;\n\t\t\tconst struct btf_type *ret;\n\t\t\tconst char *tname;\n\n\t\t\t/* resolve the type size of ksym. */\n\t\t\tret = btf_resolve_size(meta.ret_btf, t, &tsize);\n\t\t\tif (IS_ERR(ret)) {\n\t\t\t\ttname = btf_name_by_offset(meta.ret_btf, t->name_off);\n\t\t\t\tverbose(env, \"unable to resolve the size of type '%s': %ld\\n\",\n\t\t\t\t\ttname, PTR_ERR(ret));\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;\n\t\t\tregs[BPF_REG_0].mem_size = tsize;\n\t\t} else {\n\t\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;\n\t\t\tregs[BPF_REG_0].btf = meta.ret_btf;\n\t\t\tregs[BPF_REG_0].btf_id = meta.ret_btf_id;\n\t\t}\n\t} else if (base_type(ret_type) == RET_PTR_TO_BTF_ID) {\n\t\tint ret_btf_id;\n\n\t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;\n\t\tret_btf_id = *fn->ret_btf_id;\n\t\tif (ret_btf_id == 0) {\n\t\t\tverbose(env, \"invalid return type %u of func %s#%d\\n\",\n\t\t\t\tbase_type(ret_type), func_id_name(func_id),\n\t\t\t\tfunc_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* current BPF helper definitions are only coming from\n\t\t * built-in code with type IDs from  vmlinux BTF\n\t\t */\n\t\tregs[BPF_REG_0].btf = btf_vmlinux;\n\t\tregs[BPF_REG_0].btf_id = ret_btf_id;\n\t} else {\n\t\tverbose(env, \"unknown return type %u of func %s#%d\\n\",\n\t\t\tbase_type(ret_type), func_id_name(func_id), func_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (type_may_be_null(regs[BPF_REG_0].type))\n\t\tregs[BPF_REG_0].id = ++env->id_gen;\n\n\tif (is_ptr_cast_function(func_id)) {\n\t\t/* For release_reference() */\n\t\tregs[BPF_REG_0].ref_obj_id = meta.ref_obj_id;\n\t} else if (is_acquire_function(func_id, meta.map_ptr)) {\n\t\tint id = acquire_reference_state(env, insn_idx);\n\n\t\tif (id < 0)\n\t\t\treturn id;\n\t\t/* For mark_ptr_or_null_reg() */\n\t\tregs[BPF_REG_0].id = id;\n\t\t/* For release_reference() */\n\t\tregs[BPF_REG_0].ref_obj_id = id;\n\t}\n\n\tdo_refine_retval_range(regs, fn->ret_type, func_id, &meta);\n\n\terr = check_map_func_compatibility(env, meta.map_ptr, func_id);\n\tif (err)\n\t\treturn err;\n\n\tif ((func_id == BPF_FUNC_get_stack ||\n\t     func_id == BPF_FUNC_get_task_stack) &&\n\t    !env->prog->has_callchain_buf) {\n\t\tconst char *err_str;\n\n#ifdef CONFIG_PERF_EVENTS\n\t\terr = get_callchain_buffers(sysctl_perf_event_max_stack);\n\t\terr_str = \"cannot get callchain buffer for func %s#%d\\n\";\n#else\n\t\terr = -ENOTSUPP;\n\t\terr_str = \"func %s#%d not supported without CONFIG_PERF_EVENTS\\n\";\n#endif\n\t\tif (err) {\n\t\t\tverbose(env, err_str, func_id_name(func_id), func_id);\n\t\t\treturn err;\n\t\t}\n\n\t\tenv->prog->has_callchain_buf = true;\n\t}\n\n\tif (func_id == BPF_FUNC_get_stackid || func_id == BPF_FUNC_get_stack)\n\t\tenv->prog->call_get_stack = true;\n\n\tif (func_id == BPF_FUNC_get_func_ip) {\n\t\tif (check_get_func_ip(env))\n\t\t\treturn -ENOTSUPP;\n\t\tenv->prog->call_get_func_ip = true;\n\t}\n\n\tif (changes_data)\n\t\tclear_all_pkt_pointers(env);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,7 @@\n {\n \tconst struct bpf_func_proto *fn = NULL;\n \tenum bpf_return_type ret_type;\n+\tenum bpf_type_flag ret_flag;\n \tstruct bpf_reg_state *regs;\n \tstruct bpf_call_arg_meta meta;\n \tint insn_idx = *insn_idx_p;\n@@ -143,6 +144,7 @@\n \n \t/* update return register (already marked as written above) */\n \tret_type = fn->ret_type;\n+\tret_flag = type_flag(fn->ret_type);\n \tif (ret_type == RET_INTEGER) {\n \t\t/* sets type to SCALAR_VALUE */\n \t\tmark_reg_unknown(env, regs, BPF_REG_0);\n@@ -162,25 +164,23 @@\n \t\t}\n \t\tregs[BPF_REG_0].map_ptr = meta.map_ptr;\n \t\tregs[BPF_REG_0].map_uid = meta.map_uid;\n-\t\tif (type_may_be_null(ret_type)) {\n-\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE_OR_NULL;\n-\t\t} else {\n-\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE;\n-\t\t\tif (map_value_has_spin_lock(meta.map_ptr))\n-\t\t\t\tregs[BPF_REG_0].id = ++env->id_gen;\n+\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE | ret_flag;\n+\t\tif (!type_may_be_null(ret_type) &&\n+\t\t    map_value_has_spin_lock(meta.map_ptr)) {\n+\t\t\tregs[BPF_REG_0].id = ++env->id_gen;\n \t\t}\n \t} else if (base_type(ret_type) == RET_PTR_TO_SOCKET) {\n \t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n-\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET_OR_NULL;\n+\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET | ret_flag;\n \t} else if (base_type(ret_type) == RET_PTR_TO_SOCK_COMMON) {\n \t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n-\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON_OR_NULL;\n+\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON | ret_flag;\n \t} else if (base_type(ret_type) == RET_PTR_TO_TCP_SOCK) {\n \t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n-\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK_OR_NULL;\n+\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK | ret_flag;\n \t} else if (base_type(ret_type) == RET_PTR_TO_ALLOC_MEM) {\n \t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n-\t\tregs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;\n+\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;\n \t\tregs[BPF_REG_0].mem_size = meta.mem_size;\n \t} else if (base_type(ret_type) == RET_PTR_TO_MEM_OR_BTF_ID) {\n \t\tconst struct btf_type *t;\n@@ -200,14 +200,10 @@\n \t\t\t\t\ttname, PTR_ERR(ret));\n \t\t\t\treturn -EINVAL;\n \t\t\t}\n-\t\t\tregs[BPF_REG_0].type =\n-\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?\n-\t\t\t\tPTR_TO_MEM_OR_NULL : PTR_TO_MEM;\n+\t\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;\n \t\t\tregs[BPF_REG_0].mem_size = tsize;\n \t\t} else {\n-\t\t\tregs[BPF_REG_0].type =\n-\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?\n-\t\t\t\tPTR_TO_BTF_ID_OR_NULL : PTR_TO_BTF_ID;\n+\t\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;\n \t\t\tregs[BPF_REG_0].btf = meta.ret_btf;\n \t\t\tregs[BPF_REG_0].btf_id = meta.ret_btf_id;\n \t\t}\n@@ -215,9 +211,7 @@\n \t\tint ret_btf_id;\n \n \t\tmark_reg_known_zero(env, regs, BPF_REG_0);\n-\t\tregs[BPF_REG_0].type = (ret_type & PTR_MAYBE_NULL) ?\n-\t\t\t\t\t\t     PTR_TO_BTF_ID_OR_NULL :\n-\t\t\t\t\t\t     PTR_TO_BTF_ID;\n+\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;\n \t\tret_btf_id = *fn->ret_btf_id;\n \t\tif (ret_btf_id == 0) {\n \t\t\tverbose(env, \"invalid return type %u of func %s#%d\\n\",\n@@ -236,7 +230,7 @@\n \t\treturn -EINVAL;\n \t}\n \n-\tif (reg_type_may_be_null(regs[BPF_REG_0].type))\n+\tif (type_may_be_null(regs[BPF_REG_0].type))\n \t\tregs[BPF_REG_0].id = ++env->id_gen;\n \n \tif (is_ptr_cast_function(func_id)) {",
        "function_modified_lines": {
            "added": [
                "\tenum bpf_type_flag ret_flag;",
                "\tret_flag = type_flag(fn->ret_type);",
                "\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE | ret_flag;",
                "\t\tif (!type_may_be_null(ret_type) &&",
                "\t\t    map_value_has_spin_lock(meta.map_ptr)) {",
                "\t\t\tregs[BPF_REG_0].id = ++env->id_gen;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET | ret_flag;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON | ret_flag;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK | ret_flag;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;",
                "\t\t\tregs[BPF_REG_0].type = PTR_TO_MEM | ret_flag;",
                "\t\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_BTF_ID | ret_flag;",
                "\tif (type_may_be_null(regs[BPF_REG_0].type))"
            ],
            "deleted": [
                "\t\tif (type_may_be_null(ret_type)) {",
                "\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE_OR_NULL;",
                "\t\t} else {",
                "\t\t\tregs[BPF_REG_0].type = PTR_TO_MAP_VALUE;",
                "\t\t\tif (map_value_has_spin_lock(meta.map_ptr))",
                "\t\t\t\tregs[BPF_REG_0].id = ++env->id_gen;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_SOCKET_OR_NULL;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_SOCK_COMMON_OR_NULL;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_TCP_SOCK_OR_NULL;",
                "\t\tregs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;",
                "\t\t\tregs[BPF_REG_0].type =",
                "\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?",
                "\t\t\t\tPTR_TO_MEM_OR_NULL : PTR_TO_MEM;",
                "\t\t\tregs[BPF_REG_0].type =",
                "\t\t\t\t(ret_type & PTR_MAYBE_NULL) ?",
                "\t\t\t\tPTR_TO_BTF_ID_OR_NULL : PTR_TO_BTF_ID;",
                "\t\tregs[BPF_REG_0].type = (ret_type & PTR_MAYBE_NULL) ?",
                "\t\t\t\t\t\t     PTR_TO_BTF_ID_OR_NULL :",
                "\t\t\t\t\t\t     PTR_TO_BTF_ID;",
                "\tif (reg_type_may_be_null(regs[BPF_REG_0].type))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3443
    },
    {
        "cve_id": "CVE-2015-8970",
        "code_before_change": "static int skcipher_accept_parent(void *private, struct sock *sk)\n{\n\tstruct skcipher_ctx *ctx;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(private);\n\n\tctx = sock_kmalloc(sk, len, GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(private),\n\t\t\t       GFP_KERNEL);\n\tif (!ctx->iv) {\n\t\tsock_kfree_s(sk, ctx, len);\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(private));\n\n\tINIT_LIST_HEAD(&ctx->tsgl);\n\tctx->len = len;\n\tctx->used = 0;\n\tctx->more = 0;\n\tctx->merge = 0;\n\tctx->enc = 0;\n\tatomic_set(&ctx->inflight, 0);\n\taf_alg_init_completion(&ctx->completion);\n\n\task->private = ctx;\n\n\tskcipher_request_set_tfm(&ctx->req, private);\n\tskcipher_request_set_callback(&ctx->req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t      af_alg_complete, &ctx->completion);\n\n\tsk->sk_destruct = skcipher_sock_destruct;\n\n\treturn 0;\n}",
        "code_after_change": "static int skcipher_accept_parent(void *private, struct sock *sk)\n{\n\tstruct skcipher_ctx *ctx;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct skcipher_tfm *tfm = private;\n\tstruct crypto_skcipher *skcipher = tfm->skcipher;\n\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(skcipher);\n\n\tif (!tfm->has_key)\n\t\treturn -ENOKEY;\n\n\tctx = sock_kmalloc(sk, len, GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(skcipher),\n\t\t\t       GFP_KERNEL);\n\tif (!ctx->iv) {\n\t\tsock_kfree_s(sk, ctx, len);\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(skcipher));\n\n\tINIT_LIST_HEAD(&ctx->tsgl);\n\tctx->len = len;\n\tctx->used = 0;\n\tctx->more = 0;\n\tctx->merge = 0;\n\tctx->enc = 0;\n\tatomic_set(&ctx->inflight, 0);\n\taf_alg_init_completion(&ctx->completion);\n\n\task->private = ctx;\n\n\tskcipher_request_set_tfm(&ctx->req, skcipher);\n\tskcipher_request_set_callback(&ctx->req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n\t\t\t\t      af_alg_complete, &ctx->completion);\n\n\tsk->sk_destruct = skcipher_sock_destruct;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,20 +2,25 @@\n {\n \tstruct skcipher_ctx *ctx;\n \tstruct alg_sock *ask = alg_sk(sk);\n-\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(private);\n+\tstruct skcipher_tfm *tfm = private;\n+\tstruct crypto_skcipher *skcipher = tfm->skcipher;\n+\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(skcipher);\n+\n+\tif (!tfm->has_key)\n+\t\treturn -ENOKEY;\n \n \tctx = sock_kmalloc(sk, len, GFP_KERNEL);\n \tif (!ctx)\n \t\treturn -ENOMEM;\n \n-\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(private),\n+\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(skcipher),\n \t\t\t       GFP_KERNEL);\n \tif (!ctx->iv) {\n \t\tsock_kfree_s(sk, ctx, len);\n \t\treturn -ENOMEM;\n \t}\n \n-\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(private));\n+\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(skcipher));\n \n \tINIT_LIST_HEAD(&ctx->tsgl);\n \tctx->len = len;\n@@ -28,7 +33,7 @@\n \n \task->private = ctx;\n \n-\tskcipher_request_set_tfm(&ctx->req, private);\n+\tskcipher_request_set_tfm(&ctx->req, skcipher);\n \tskcipher_request_set_callback(&ctx->req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n \t\t\t\t      af_alg_complete, &ctx->completion);\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct skcipher_tfm *tfm = private;",
                "\tstruct crypto_skcipher *skcipher = tfm->skcipher;",
                "\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(skcipher);",
                "",
                "\tif (!tfm->has_key)",
                "\t\treturn -ENOKEY;",
                "\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(skcipher),",
                "\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(skcipher));",
                "\tskcipher_request_set_tfm(&ctx->req, skcipher);"
            ],
            "deleted": [
                "\tunsigned int len = sizeof(*ctx) + crypto_skcipher_reqsize(private);",
                "\tctx->iv = sock_kmalloc(sk, crypto_skcipher_ivsize(private),",
                "\tmemset(ctx->iv, 0, crypto_skcipher_ivsize(private));",
                "\tskcipher_request_set_tfm(&ctx->req, private);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/algif_skcipher.c in the Linux kernel before 4.4.2 does not verify that a setkey operation has been performed on an AF_ALG socket before an accept system call is processed, which allows local users to cause a denial of service (NULL pointer dereference and system crash) via a crafted application that does not supply a key, related to the lrw_crypt function in crypto/lrw.c.",
        "id": 876
    },
    {
        "cve_id": "CVE-2019-15216",
        "code_before_change": "static void yurex_disconnect(struct usb_interface *interface)\n{\n\tstruct usb_yurex *dev;\n\tint minor = interface->minor;\n\n\tdev = usb_get_intfdata(interface);\n\tusb_set_intfdata(interface, NULL);\n\n\t/* give back our minor */\n\tusb_deregister_dev(interface, &yurex_class);\n\n\t/* prevent more I/O from starting */\n\tmutex_lock(&dev->io_mutex);\n\tdev->interface = NULL;\n\tmutex_unlock(&dev->io_mutex);\n\n\t/* wakeup waiters */\n\tkill_fasync(&dev->async_queue, SIGIO, POLL_IN);\n\twake_up_interruptible(&dev->waitq);\n\n\t/* decrement our usage count */\n\tkref_put(&dev->kref, yurex_delete);\n\n\tdev_info(&interface->dev, \"USB YUREX #%d now disconnected\\n\", minor);\n}",
        "code_after_change": "static void yurex_disconnect(struct usb_interface *interface)\n{\n\tstruct usb_yurex *dev;\n\tint minor = interface->minor;\n\n\tdev = usb_get_intfdata(interface);\n\tusb_set_intfdata(interface, NULL);\n\n\t/* give back our minor */\n\tusb_deregister_dev(interface, &yurex_class);\n\n\t/* prevent more I/O from starting */\n\tusb_poison_urb(dev->urb);\n\tmutex_lock(&dev->io_mutex);\n\tdev->interface = NULL;\n\tmutex_unlock(&dev->io_mutex);\n\n\t/* wakeup waiters */\n\tkill_fasync(&dev->async_queue, SIGIO, POLL_IN);\n\twake_up_interruptible(&dev->waitq);\n\n\t/* decrement our usage count */\n\tkref_put(&dev->kref, yurex_delete);\n\n\tdev_info(&interface->dev, \"USB YUREX #%d now disconnected\\n\", minor);\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,7 @@\n \tusb_deregister_dev(interface, &yurex_class);\n \n \t/* prevent more I/O from starting */\n+\tusb_poison_urb(dev->urb);\n \tmutex_lock(&dev->io_mutex);\n \tdev->interface = NULL;\n \tmutex_unlock(&dev->io_mutex);",
        "function_modified_lines": {
            "added": [
                "\tusb_poison_urb(dev->urb);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.14. There is a NULL pointer dereference caused by a malicious USB device in the drivers/usb/misc/yurex.c driver.",
        "id": 1998
    },
    {
        "cve_id": "CVE-2022-3111",
        "code_before_change": "static void free_charger_irq(struct wm8350 *wm8350)\n{\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_HOT, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_COLD, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_FAIL, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_TO, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_END, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_START, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P9, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P1, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_2P85, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_USB_FB, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_WALL_FB, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_BAT_FB, wm8350);\n}",
        "code_after_change": "static void free_charger_irq(struct wm8350 *wm8350)\n{\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_HOT, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_COLD, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_BAT_FAIL, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_TO, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_END, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_START, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_FAST_RDY, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P9, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P1, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_2P85, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_USB_FB, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_WALL_FB, wm8350);\n\twm8350_free_irq(wm8350, WM8350_IRQ_EXT_BAT_FB, wm8350);\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,6 +6,7 @@\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_TO, wm8350);\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_END, wm8350);\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_START, wm8350);\n+\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_FAST_RDY, wm8350);\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P9, wm8350);\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_3P1, wm8350);\n \twm8350_free_irq(wm8350, WM8350_IRQ_CHG_VBATT_LT_2P85, wm8350);",
        "function_modified_lines": {
            "added": [
                "\twm8350_free_irq(wm8350, WM8350_IRQ_CHG_FAST_RDY, wm8350);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. free_charger_irq() in drivers/power/supply/wm8350_power.c lacks free of WM8350_IRQ_CHG_FAST_RDY, which is registered in wm8350_init_charger().",
        "id": 3556
    },
    {
        "cve_id": "CVE-2016-10147",
        "code_before_change": "static int mcryptd_create_hash(struct crypto_template *tmpl, struct rtattr **tb,\n\t\t\t      struct mcryptd_queue *queue)\n{\n\tstruct hashd_instance_ctx *ctx;\n\tstruct ahash_instance *inst;\n\tstruct hash_alg_common *halg;\n\tstruct crypto_alg *alg;\n\tu32 type = 0;\n\tu32 mask = 0;\n\tint err;\n\n\tmcryptd_check_internal(tb, &type, &mask);\n\n\thalg = ahash_attr_alg(tb[1], type, mask);\n\tif (IS_ERR(halg))\n\t\treturn PTR_ERR(halg);\n\n\talg = &halg->base;\n\tpr_debug(\"crypto: mcryptd hash alg: %s\\n\", alg->cra_name);\n\tinst = mcryptd_alloc_instance(alg, ahash_instance_headroom(),\n\t\t\t\t\tsizeof(*ctx));\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\tctx = ahash_instance_ctx(inst);\n\tctx->queue = queue;\n\n\terr = crypto_init_ahash_spawn(&ctx->spawn, halg,\n\t\t\t\t      ahash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\ttype = CRYPTO_ALG_ASYNC;\n\tif (alg->cra_flags & CRYPTO_ALG_INTERNAL)\n\t\ttype |= CRYPTO_ALG_INTERNAL;\n\tinst->alg.halg.base.cra_flags = type;\n\n\tinst->alg.halg.digestsize = halg->digestsize;\n\tinst->alg.halg.statesize = halg->statesize;\n\tinst->alg.halg.base.cra_ctxsize = sizeof(struct mcryptd_hash_ctx);\n\n\tinst->alg.halg.base.cra_init = mcryptd_hash_init_tfm;\n\tinst->alg.halg.base.cra_exit = mcryptd_hash_exit_tfm;\n\n\tinst->alg.init   = mcryptd_hash_init_enqueue;\n\tinst->alg.update = mcryptd_hash_update_enqueue;\n\tinst->alg.final  = mcryptd_hash_final_enqueue;\n\tinst->alg.finup  = mcryptd_hash_finup_enqueue;\n\tinst->alg.export = mcryptd_hash_export;\n\tinst->alg.import = mcryptd_hash_import;\n\tinst->alg.setkey = mcryptd_hash_setkey;\n\tinst->alg.digest = mcryptd_hash_digest_enqueue;\n\n\terr = ahash_register_instance(tmpl, inst);\n\tif (err) {\n\t\tcrypto_drop_ahash(&ctx->spawn);\nout_free_inst:\n\t\tkfree(inst);\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}",
        "code_after_change": "static int mcryptd_create_hash(struct crypto_template *tmpl, struct rtattr **tb,\n\t\t\t      struct mcryptd_queue *queue)\n{\n\tstruct hashd_instance_ctx *ctx;\n\tstruct ahash_instance *inst;\n\tstruct hash_alg_common *halg;\n\tstruct crypto_alg *alg;\n\tu32 type = 0;\n\tu32 mask = 0;\n\tint err;\n\n\tif (!mcryptd_check_internal(tb, &type, &mask))\n\t\treturn -EINVAL;\n\n\thalg = ahash_attr_alg(tb[1], type, mask);\n\tif (IS_ERR(halg))\n\t\treturn PTR_ERR(halg);\n\n\talg = &halg->base;\n\tpr_debug(\"crypto: mcryptd hash alg: %s\\n\", alg->cra_name);\n\tinst = mcryptd_alloc_instance(alg, ahash_instance_headroom(),\n\t\t\t\t\tsizeof(*ctx));\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\tctx = ahash_instance_ctx(inst);\n\tctx->queue = queue;\n\n\terr = crypto_init_ahash_spawn(&ctx->spawn, halg,\n\t\t\t\t      ahash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\ttype = CRYPTO_ALG_ASYNC;\n\tif (alg->cra_flags & CRYPTO_ALG_INTERNAL)\n\t\ttype |= CRYPTO_ALG_INTERNAL;\n\tinst->alg.halg.base.cra_flags = type;\n\n\tinst->alg.halg.digestsize = halg->digestsize;\n\tinst->alg.halg.statesize = halg->statesize;\n\tinst->alg.halg.base.cra_ctxsize = sizeof(struct mcryptd_hash_ctx);\n\n\tinst->alg.halg.base.cra_init = mcryptd_hash_init_tfm;\n\tinst->alg.halg.base.cra_exit = mcryptd_hash_exit_tfm;\n\n\tinst->alg.init   = mcryptd_hash_init_enqueue;\n\tinst->alg.update = mcryptd_hash_update_enqueue;\n\tinst->alg.final  = mcryptd_hash_final_enqueue;\n\tinst->alg.finup  = mcryptd_hash_finup_enqueue;\n\tinst->alg.export = mcryptd_hash_export;\n\tinst->alg.import = mcryptd_hash_import;\n\tinst->alg.setkey = mcryptd_hash_setkey;\n\tinst->alg.digest = mcryptd_hash_digest_enqueue;\n\n\terr = ahash_register_instance(tmpl, inst);\n\tif (err) {\n\t\tcrypto_drop_ahash(&ctx->spawn);\nout_free_inst:\n\t\tkfree(inst);\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,8 @@\n \tu32 mask = 0;\n \tint err;\n \n-\tmcryptd_check_internal(tb, &type, &mask);\n+\tif (!mcryptd_check_internal(tb, &type, &mask))\n+\t\treturn -EINVAL;\n \n \thalg = ahash_attr_alg(tb[1], type, mask);\n \tif (IS_ERR(halg))",
        "function_modified_lines": {
            "added": [
                "\tif (!mcryptd_check_internal(tb, &type, &mask))",
                "\t\treturn -EINVAL;"
            ],
            "deleted": [
                "\tmcryptd_check_internal(tb, &type, &mask);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/mcryptd.c in the Linux kernel before 4.8.15 allows local users to cause a denial of service (NULL pointer dereference and system crash) by using an AF_ALG socket with an incompatible algorithm, as demonstrated by mcryptd(md5).",
        "id": 895
    },
    {
        "cve_id": "CVE-2017-18216",
        "code_before_change": "static struct o2nm_cluster *to_o2nm_cluster_from_node(struct o2nm_node *node)\n{\n\t/* through the first node_set .parent\n\t * mycluster/nodes/mynode == o2nm_cluster->o2nm_node_group->o2nm_node */\n\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);\n}",
        "code_after_change": "static struct o2nm_cluster *to_o2nm_cluster_from_node(struct o2nm_node *node)\n{\n\t/* through the first node_set .parent\n\t * mycluster/nodes/mynode == o2nm_cluster->o2nm_node_group->o2nm_node */\n\tif (node->nd_item.ci_parent)\n\t\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);\n\telse\n\t\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,5 +2,8 @@\n {\n \t/* through the first node_set .parent\n \t * mycluster/nodes/mynode == o2nm_cluster->o2nm_node_group->o2nm_node */\n-\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);\n+\tif (node->nd_item.ci_parent)\n+\t\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);\n+\telse\n+\t\treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (node->nd_item.ci_parent)",
                "\t\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);",
                "\telse",
                "\t\treturn NULL;"
            ],
            "deleted": [
                "\treturn to_o2nm_cluster(node->nd_item.ci_parent->ci_parent);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In fs/ocfs2/cluster/nodemanager.c in the Linux kernel before 4.15, local users can cause a denial of service (NULL pointer dereference and BUG) because a required mutex is not used.",
        "id": 1403
    },
    {
        "cve_id": "CVE-2022-1671",
        "code_before_change": "static int rxrpc_preparse_s(struct key_preparsed_payload *prep)\n{\n\tconst struct rxrpc_security *sec;\n\tunsigned int service, sec_class;\n\tint n;\n\n\t_enter(\"%zu\", prep->datalen);\n\n\tif (!prep->orig_description)\n\t\treturn -EINVAL;\n\n\tif (sscanf(prep->orig_description, \"%u:%u%n\", &service, &sec_class, &n) != 2)\n\t\treturn -EINVAL;\n\n\tsec = rxrpc_security_lookup(sec_class);\n\tif (!sec)\n\t\treturn -ENOPKG;\n\n\tprep->payload.data[1] = (struct rxrpc_security *)sec;\n\n\treturn sec->preparse_server_key(prep);\n}",
        "code_after_change": "static int rxrpc_preparse_s(struct key_preparsed_payload *prep)\n{\n\tconst struct rxrpc_security *sec;\n\tunsigned int service, sec_class;\n\tint n;\n\n\t_enter(\"%zu\", prep->datalen);\n\n\tif (!prep->orig_description)\n\t\treturn -EINVAL;\n\n\tif (sscanf(prep->orig_description, \"%u:%u%n\", &service, &sec_class, &n) != 2)\n\t\treturn -EINVAL;\n\n\tsec = rxrpc_security_lookup(sec_class);\n\tif (!sec)\n\t\treturn -ENOPKG;\n\n\tprep->payload.data[1] = (struct rxrpc_security *)sec;\n\n\tif (!sec->preparse_server_key)\n\t\treturn -EINVAL;\n\n\treturn sec->preparse_server_key(prep);\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,5 +18,8 @@\n \n \tprep->payload.data[1] = (struct rxrpc_security *)sec;\n \n+\tif (!sec->preparse_server_key)\n+\t\treturn -EINVAL;\n+\n \treturn sec->preparse_server_key(prep);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!sec->preparse_server_key)",
                "\t\treturn -EINVAL;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in rxrpc_preparse_s in net/rxrpc/server_key.c in the Linux kernel. This flaw allows a local attacker to crash the system or leak internal kernel information.",
        "id": 3272
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_return_code(struct bpf_verifier_env *env)\n{\n\tstruct tnum enforce_attach_type_range = tnum_unknown;\n\tconst struct bpf_prog *prog = env->prog;\n\tstruct bpf_reg_state *reg;\n\tstruct tnum range = tnum_range(0, 1);\n\tenum bpf_prog_type prog_type = resolve_prog_type(env->prog);\n\tint err;\n\tstruct bpf_func_state *frame = env->cur_state->frame[0];\n\tconst bool is_subprog = frame->subprogno;\n\n\t/* LSM and struct_ops func-ptr's return type could be \"void\" */\n\tif (!is_subprog &&\n\t    (prog_type == BPF_PROG_TYPE_STRUCT_OPS ||\n\t     prog_type == BPF_PROG_TYPE_LSM) &&\n\t    !prog->aux->attach_func_proto->type)\n\t\treturn 0;\n\n\t/* eBPF calling convention is such that R0 is used\n\t * to return the value from eBPF program.\n\t * Make sure that it's readable at this time\n\t * of bpf_exit, which means that program wrote\n\t * something into it earlier\n\t */\n\terr = check_reg_arg(env, BPF_REG_0, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (is_pointer_value(env, BPF_REG_0)) {\n\t\tverbose(env, \"R0 leaks addr as return value\\n\");\n\t\treturn -EACCES;\n\t}\n\n\treg = cur_regs(env) + BPF_REG_0;\n\n\tif (frame->in_async_callback_fn) {\n\t\t/* enforce return zero from async callbacks like timer */\n\t\tif (reg->type != SCALAR_VALUE) {\n\t\t\tverbose(env, \"In async callback the register R0 is not a known value (%s)\\n\",\n\t\t\t\treg_type_str[reg->type]);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!tnum_in(tnum_const(0), reg->var_off)) {\n\t\t\tverbose_invalid_scalar(env, reg, &range, \"async callback\", \"R0\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_subprog) {\n\t\tif (reg->type != SCALAR_VALUE) {\n\t\t\tverbose(env, \"At subprogram exit the register R0 is not a scalar value (%s)\\n\",\n\t\t\t\treg_type_str[reg->type]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tswitch (prog_type) {\n\tcase BPF_PROG_TYPE_CGROUP_SOCK_ADDR:\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_UDP4_RECVMSG ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_UDP6_RECVMSG ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET4_GETPEERNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_GETPEERNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET4_GETSOCKNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_GETSOCKNAME)\n\t\t\trange = tnum_range(1, 1);\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_INET4_BIND ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_BIND)\n\t\t\trange = tnum_range(0, 3);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_CGROUP_SKB:\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_INET_EGRESS) {\n\t\t\trange = tnum_range(0, 3);\n\t\t\tenforce_attach_type_range = tnum_range(2, 3);\n\t\t}\n\t\tbreak;\n\tcase BPF_PROG_TYPE_CGROUP_SOCK:\n\tcase BPF_PROG_TYPE_SOCK_OPS:\n\tcase BPF_PROG_TYPE_CGROUP_DEVICE:\n\tcase BPF_PROG_TYPE_CGROUP_SYSCTL:\n\tcase BPF_PROG_TYPE_CGROUP_SOCKOPT:\n\t\tbreak;\n\tcase BPF_PROG_TYPE_RAW_TRACEPOINT:\n\t\tif (!env->prog->aux->attach_btf_id)\n\t\t\treturn 0;\n\t\trange = tnum_const(0);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_TRACING:\n\t\tswitch (env->prog->expected_attach_type) {\n\t\tcase BPF_TRACE_FENTRY:\n\t\tcase BPF_TRACE_FEXIT:\n\t\t\trange = tnum_const(0);\n\t\t\tbreak;\n\t\tcase BPF_TRACE_RAW_TP:\n\t\tcase BPF_MODIFY_RETURN:\n\t\t\treturn 0;\n\t\tcase BPF_TRACE_ITER:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -ENOTSUPP;\n\t\t}\n\t\tbreak;\n\tcase BPF_PROG_TYPE_SK_LOOKUP:\n\t\trange = tnum_range(SK_DROP, SK_PASS);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_EXT:\n\t\t/* freplace program can return anything as its return value\n\t\t * depends on the to-be-replaced kernel func or bpf program.\n\t\t */\n\tdefault:\n\t\treturn 0;\n\t}\n\n\tif (reg->type != SCALAR_VALUE) {\n\t\tverbose(env, \"At program exit the register R0 is not a known value (%s)\\n\",\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!tnum_in(range, reg->var_off)) {\n\t\tverbose_invalid_scalar(env, reg, &range, \"program exit\", \"R0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!tnum_is_unknown(enforce_attach_type_range) &&\n\t    tnum_in(enforce_attach_type_range, reg->var_off))\n\t\tenv->prog->enforce_expected_attach_type = 1;\n\treturn 0;\n}",
        "code_after_change": "static int check_return_code(struct bpf_verifier_env *env)\n{\n\tstruct tnum enforce_attach_type_range = tnum_unknown;\n\tconst struct bpf_prog *prog = env->prog;\n\tstruct bpf_reg_state *reg;\n\tstruct tnum range = tnum_range(0, 1);\n\tenum bpf_prog_type prog_type = resolve_prog_type(env->prog);\n\tint err;\n\tstruct bpf_func_state *frame = env->cur_state->frame[0];\n\tconst bool is_subprog = frame->subprogno;\n\n\t/* LSM and struct_ops func-ptr's return type could be \"void\" */\n\tif (!is_subprog &&\n\t    (prog_type == BPF_PROG_TYPE_STRUCT_OPS ||\n\t     prog_type == BPF_PROG_TYPE_LSM) &&\n\t    !prog->aux->attach_func_proto->type)\n\t\treturn 0;\n\n\t/* eBPF calling convention is such that R0 is used\n\t * to return the value from eBPF program.\n\t * Make sure that it's readable at this time\n\t * of bpf_exit, which means that program wrote\n\t * something into it earlier\n\t */\n\terr = check_reg_arg(env, BPF_REG_0, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (is_pointer_value(env, BPF_REG_0)) {\n\t\tverbose(env, \"R0 leaks addr as return value\\n\");\n\t\treturn -EACCES;\n\t}\n\n\treg = cur_regs(env) + BPF_REG_0;\n\n\tif (frame->in_async_callback_fn) {\n\t\t/* enforce return zero from async callbacks like timer */\n\t\tif (reg->type != SCALAR_VALUE) {\n\t\t\tverbose(env, \"In async callback the register R0 is not a known value (%s)\\n\",\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!tnum_in(tnum_const(0), reg->var_off)) {\n\t\t\tverbose_invalid_scalar(env, reg, &range, \"async callback\", \"R0\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_subprog) {\n\t\tif (reg->type != SCALAR_VALUE) {\n\t\t\tverbose(env, \"At subprogram exit the register R0 is not a scalar value (%s)\\n\",\n\t\t\t\treg_type_str(env, reg->type));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tswitch (prog_type) {\n\tcase BPF_PROG_TYPE_CGROUP_SOCK_ADDR:\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_UDP4_RECVMSG ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_UDP6_RECVMSG ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET4_GETPEERNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_GETPEERNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET4_GETSOCKNAME ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_GETSOCKNAME)\n\t\t\trange = tnum_range(1, 1);\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_INET4_BIND ||\n\t\t    env->prog->expected_attach_type == BPF_CGROUP_INET6_BIND)\n\t\t\trange = tnum_range(0, 3);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_CGROUP_SKB:\n\t\tif (env->prog->expected_attach_type == BPF_CGROUP_INET_EGRESS) {\n\t\t\trange = tnum_range(0, 3);\n\t\t\tenforce_attach_type_range = tnum_range(2, 3);\n\t\t}\n\t\tbreak;\n\tcase BPF_PROG_TYPE_CGROUP_SOCK:\n\tcase BPF_PROG_TYPE_SOCK_OPS:\n\tcase BPF_PROG_TYPE_CGROUP_DEVICE:\n\tcase BPF_PROG_TYPE_CGROUP_SYSCTL:\n\tcase BPF_PROG_TYPE_CGROUP_SOCKOPT:\n\t\tbreak;\n\tcase BPF_PROG_TYPE_RAW_TRACEPOINT:\n\t\tif (!env->prog->aux->attach_btf_id)\n\t\t\treturn 0;\n\t\trange = tnum_const(0);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_TRACING:\n\t\tswitch (env->prog->expected_attach_type) {\n\t\tcase BPF_TRACE_FENTRY:\n\t\tcase BPF_TRACE_FEXIT:\n\t\t\trange = tnum_const(0);\n\t\t\tbreak;\n\t\tcase BPF_TRACE_RAW_TP:\n\t\tcase BPF_MODIFY_RETURN:\n\t\t\treturn 0;\n\t\tcase BPF_TRACE_ITER:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -ENOTSUPP;\n\t\t}\n\t\tbreak;\n\tcase BPF_PROG_TYPE_SK_LOOKUP:\n\t\trange = tnum_range(SK_DROP, SK_PASS);\n\t\tbreak;\n\tcase BPF_PROG_TYPE_EXT:\n\t\t/* freplace program can return anything as its return value\n\t\t * depends on the to-be-replaced kernel func or bpf program.\n\t\t */\n\tdefault:\n\t\treturn 0;\n\t}\n\n\tif (reg->type != SCALAR_VALUE) {\n\t\tverbose(env, \"At program exit the register R0 is not a known value (%s)\\n\",\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EINVAL;\n\t}\n\n\tif (!tnum_in(range, reg->var_off)) {\n\t\tverbose_invalid_scalar(env, reg, &range, \"program exit\", \"R0\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!tnum_is_unknown(enforce_attach_type_range) &&\n\t    tnum_in(enforce_attach_type_range, reg->var_off))\n\t\tenv->prog->enforce_expected_attach_type = 1;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -37,7 +37,7 @@\n \t\t/* enforce return zero from async callbacks like timer */\n \t\tif (reg->type != SCALAR_VALUE) {\n \t\t\tverbose(env, \"In async callback the register R0 is not a known value (%s)\\n\",\n-\t\t\t\treg_type_str[reg->type]);\n+\t\t\t\treg_type_str(env, reg->type));\n \t\t\treturn -EINVAL;\n \t\t}\n \n@@ -51,7 +51,7 @@\n \tif (is_subprog) {\n \t\tif (reg->type != SCALAR_VALUE) {\n \t\t\tverbose(env, \"At subprogram exit the register R0 is not a scalar value (%s)\\n\",\n-\t\t\t\treg_type_str[reg->type]);\n+\t\t\t\treg_type_str(env, reg->type));\n \t\t\treturn -EINVAL;\n \t\t}\n \t\treturn 0;\n@@ -115,7 +115,7 @@\n \n \tif (reg->type != SCALAR_VALUE) {\n \t\tverbose(env, \"At program exit the register R0 is not a known value (%s)\\n\",\n-\t\t\treg_type_str[reg->type]);\n+\t\t\treg_type_str(env, reg->type));\n \t\treturn -EINVAL;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\treg_type_str(env, reg->type));",
                "\t\t\t\treg_type_str(env, reg->type));",
                "\t\t\treg_type_str(env, reg->type));"
            ],
            "deleted": [
                "\t\t\t\treg_type_str[reg->type]);",
                "\t\t\t\treg_type_str[reg->type]);",
                "\t\t\treg_type_str[reg->type]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3459
    },
    {
        "cve_id": "CVE-2020-12364",
        "code_before_change": "static void __guc_ads_init(struct intel_guc *guc)\n{\n\tstruct intel_gt *gt = guc_to_gt(guc);\n\tstruct __guc_ads_blob *blob = guc->ads_blob;\n\tconst u32 skipped_size = LRC_PPHWSP_SZ * PAGE_SIZE + LR_HW_CONTEXT_SIZE;\n\tu32 base;\n\tu8 engine_class;\n\n\t/* GuC scheduling policies */\n\tguc_policies_init(&blob->policies);\n\n\t/*\n\t * GuC expects a per-engine-class context image and size\n\t * (minus hwsp and ring context). The context image will be\n\t * used to reinitialize engines after a reset. It must exist\n\t * and be pinned in the GGTT, so that the address won't change after\n\t * we have told GuC where to find it. The context size will be used\n\t * to validate that the LRC base + size fall within allowed GGTT.\n\t */\n\tfor (engine_class = 0; engine_class <= MAX_ENGINE_CLASS; ++engine_class) {\n\t\tif (engine_class == OTHER_CLASS)\n\t\t\tcontinue;\n\t\t/*\n\t\t * TODO: Set context pointer to default state to allow\n\t\t * GuC to re-init guilty contexts after internal reset.\n\t\t */\n\t\tblob->ads.golden_context_lrca[engine_class] = 0;\n\t\tblob->ads.eng_state_size[engine_class] =\n\t\t\tintel_engine_context_size(guc_to_gt(guc),\n\t\t\t\t\t\t  engine_class) -\n\t\t\tskipped_size;\n\t}\n\n\t/* System info */\n\tblob->system_info.slice_enabled = hweight8(gt->info.sseu.slice_mask);\n\tblob->system_info.rcs_enabled = 1;\n\tblob->system_info.bcs_enabled = 1;\n\n\tblob->system_info.vdbox_enable_mask = VDBOX_MASK(gt);\n\tblob->system_info.vebox_enable_mask = VEBOX_MASK(gt);\n\tblob->system_info.vdbox_sfc_support_mask = gt->info.vdbox_sfc_access;\n\n\tbase = intel_guc_ggtt_offset(guc, guc->ads_vma);\n\n\t/* Clients info  */\n\tguc_ct_pool_entries_init(blob->ct_pool, ARRAY_SIZE(blob->ct_pool));\n\n\tblob->clients_info.clients_num = 1;\n\tblob->clients_info.ct_pool_addr = base + ptr_offset(blob, ct_pool);\n\tblob->clients_info.ct_pool_count = ARRAY_SIZE(blob->ct_pool);\n\n\t/* ADS */\n\tblob->ads.scheduler_policies = base + ptr_offset(blob, policies);\n\tblob->ads.reg_state_buffer = base + ptr_offset(blob, reg_state_buffer);\n\tblob->ads.reg_state_addr = base + ptr_offset(blob, reg_state);\n\tblob->ads.gt_system_info = base + ptr_offset(blob, system_info);\n\tblob->ads.clients_info = base + ptr_offset(blob, clients_info);\n\n\ti915_gem_object_flush_map(guc->ads_vma->obj);\n}",
        "code_after_change": "static void __guc_ads_init(struct intel_guc *guc)\n{\n\tstruct intel_gt *gt = guc_to_gt(guc);\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct __guc_ads_blob *blob = guc->ads_blob;\n\tconst u32 skipped_size = LRC_PPHWSP_SZ * PAGE_SIZE + LR_HW_CONTEXT_SIZE;\n\tu32 base;\n\tu8 engine_class;\n\n\t/* GuC scheduling policies */\n\tguc_policies_init(&blob->policies);\n\n\t/*\n\t * GuC expects a per-engine-class context image and size\n\t * (minus hwsp and ring context). The context image will be\n\t * used to reinitialize engines after a reset. It must exist\n\t * and be pinned in the GGTT, so that the address won't change after\n\t * we have told GuC where to find it. The context size will be used\n\t * to validate that the LRC base + size fall within allowed GGTT.\n\t */\n\tfor (engine_class = 0; engine_class <= MAX_ENGINE_CLASS; ++engine_class) {\n\t\tif (engine_class == OTHER_CLASS)\n\t\t\tcontinue;\n\t\t/*\n\t\t * TODO: Set context pointer to default state to allow\n\t\t * GuC to re-init guilty contexts after internal reset.\n\t\t */\n\t\tblob->ads.golden_context_lrca[engine_class] = 0;\n\t\tblob->ads.eng_state_size[engine_class] =\n\t\t\tintel_engine_context_size(guc_to_gt(guc),\n\t\t\t\t\t\t  engine_class) -\n\t\t\tskipped_size;\n\t}\n\n\t/* System info */\n\tblob->system_info.engine_enabled_masks[RENDER_CLASS] = 1;\n\tblob->system_info.engine_enabled_masks[COPY_ENGINE_CLASS] = 1;\n\tblob->system_info.engine_enabled_masks[VIDEO_DECODE_CLASS] = VDBOX_MASK(gt);\n\tblob->system_info.engine_enabled_masks[VIDEO_ENHANCEMENT_CLASS] = VEBOX_MASK(gt);\n\n\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_SLICE_ENABLED] =\n\t\thweight8(gt->info.sseu.slice_mask);\n\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_VDBOX_SFC_SUPPORT_MASK] =\n\t\tgt->info.vdbox_sfc_access;\n\n\tif (INTEL_GEN(i915) >= 12 && !IS_DGFX(i915)) {\n\t\tu32 distdbreg = intel_uncore_read(gt->uncore,\n\t\t\t\t\t\t  GEN12_DIST_DBS_POPULATED);\n\t\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_DOORBELL_COUNT_PER_SQIDI] =\n\t\t\t((distdbreg >> GEN12_DOORBELLS_PER_SQIDI_SHIFT) &\n\t\t\t GEN12_DOORBELLS_PER_SQIDI) + 1;\n\t}\n\n\tguc_mapping_table_init(guc_to_gt(guc), &blob->system_info);\n\n\tbase = intel_guc_ggtt_offset(guc, guc->ads_vma);\n\n\t/* Clients info  */\n\tguc_ct_pool_entries_init(blob->ct_pool, ARRAY_SIZE(blob->ct_pool));\n\n\tblob->clients_info.clients_num = 1;\n\tblob->clients_info.ct_pool_addr = base + ptr_offset(blob, ct_pool);\n\tblob->clients_info.ct_pool_count = ARRAY_SIZE(blob->ct_pool);\n\n\t/* ADS */\n\tblob->ads.scheduler_policies = base + ptr_offset(blob, policies);\n\tblob->ads.gt_system_info = base + ptr_offset(blob, system_info);\n\tblob->ads.clients_info = base + ptr_offset(blob, clients_info);\n\n\t/* Private Data */\n\tblob->ads.private_data = base + guc_ads_private_data_offset(guc);\n\n\ti915_gem_object_flush_map(guc->ads_vma->obj);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,7 @@\n static void __guc_ads_init(struct intel_guc *guc)\n {\n \tstruct intel_gt *gt = guc_to_gt(guc);\n+\tstruct drm_i915_private *i915 = gt->i915;\n \tstruct __guc_ads_blob *blob = guc->ads_blob;\n \tconst u32 skipped_size = LRC_PPHWSP_SZ * PAGE_SIZE + LR_HW_CONTEXT_SIZE;\n \tu32 base;\n@@ -32,13 +33,25 @@\n \t}\n \n \t/* System info */\n-\tblob->system_info.slice_enabled = hweight8(gt->info.sseu.slice_mask);\n-\tblob->system_info.rcs_enabled = 1;\n-\tblob->system_info.bcs_enabled = 1;\n+\tblob->system_info.engine_enabled_masks[RENDER_CLASS] = 1;\n+\tblob->system_info.engine_enabled_masks[COPY_ENGINE_CLASS] = 1;\n+\tblob->system_info.engine_enabled_masks[VIDEO_DECODE_CLASS] = VDBOX_MASK(gt);\n+\tblob->system_info.engine_enabled_masks[VIDEO_ENHANCEMENT_CLASS] = VEBOX_MASK(gt);\n \n-\tblob->system_info.vdbox_enable_mask = VDBOX_MASK(gt);\n-\tblob->system_info.vebox_enable_mask = VEBOX_MASK(gt);\n-\tblob->system_info.vdbox_sfc_support_mask = gt->info.vdbox_sfc_access;\n+\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_SLICE_ENABLED] =\n+\t\thweight8(gt->info.sseu.slice_mask);\n+\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_VDBOX_SFC_SUPPORT_MASK] =\n+\t\tgt->info.vdbox_sfc_access;\n+\n+\tif (INTEL_GEN(i915) >= 12 && !IS_DGFX(i915)) {\n+\t\tu32 distdbreg = intel_uncore_read(gt->uncore,\n+\t\t\t\t\t\t  GEN12_DIST_DBS_POPULATED);\n+\t\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_DOORBELL_COUNT_PER_SQIDI] =\n+\t\t\t((distdbreg >> GEN12_DOORBELLS_PER_SQIDI_SHIFT) &\n+\t\t\t GEN12_DOORBELLS_PER_SQIDI) + 1;\n+\t}\n+\n+\tguc_mapping_table_init(guc_to_gt(guc), &blob->system_info);\n \n \tbase = intel_guc_ggtt_offset(guc, guc->ads_vma);\n \n@@ -51,10 +64,11 @@\n \n \t/* ADS */\n \tblob->ads.scheduler_policies = base + ptr_offset(blob, policies);\n-\tblob->ads.reg_state_buffer = base + ptr_offset(blob, reg_state_buffer);\n-\tblob->ads.reg_state_addr = base + ptr_offset(blob, reg_state);\n \tblob->ads.gt_system_info = base + ptr_offset(blob, system_info);\n \tblob->ads.clients_info = base + ptr_offset(blob, clients_info);\n \n+\t/* Private Data */\n+\tblob->ads.private_data = base + guc_ads_private_data_offset(guc);\n+\n \ti915_gem_object_flush_map(guc->ads_vma->obj);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct drm_i915_private *i915 = gt->i915;",
                "\tblob->system_info.engine_enabled_masks[RENDER_CLASS] = 1;",
                "\tblob->system_info.engine_enabled_masks[COPY_ENGINE_CLASS] = 1;",
                "\tblob->system_info.engine_enabled_masks[VIDEO_DECODE_CLASS] = VDBOX_MASK(gt);",
                "\tblob->system_info.engine_enabled_masks[VIDEO_ENHANCEMENT_CLASS] = VEBOX_MASK(gt);",
                "\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_SLICE_ENABLED] =",
                "\t\thweight8(gt->info.sseu.slice_mask);",
                "\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_VDBOX_SFC_SUPPORT_MASK] =",
                "\t\tgt->info.vdbox_sfc_access;",
                "",
                "\tif (INTEL_GEN(i915) >= 12 && !IS_DGFX(i915)) {",
                "\t\tu32 distdbreg = intel_uncore_read(gt->uncore,",
                "\t\t\t\t\t\t  GEN12_DIST_DBS_POPULATED);",
                "\t\tblob->system_info.generic_gt_sysinfo[GUC_GENERIC_GT_SYSINFO_DOORBELL_COUNT_PER_SQIDI] =",
                "\t\t\t((distdbreg >> GEN12_DOORBELLS_PER_SQIDI_SHIFT) &",
                "\t\t\t GEN12_DOORBELLS_PER_SQIDI) + 1;",
                "\t}",
                "",
                "\tguc_mapping_table_init(guc_to_gt(guc), &blob->system_info);",
                "\t/* Private Data */",
                "\tblob->ads.private_data = base + guc_ads_private_data_offset(guc);",
                ""
            ],
            "deleted": [
                "\tblob->system_info.slice_enabled = hweight8(gt->info.sseu.slice_mask);",
                "\tblob->system_info.rcs_enabled = 1;",
                "\tblob->system_info.bcs_enabled = 1;",
                "\tblob->system_info.vdbox_enable_mask = VDBOX_MASK(gt);",
                "\tblob->system_info.vebox_enable_mask = VEBOX_MASK(gt);",
                "\tblob->system_info.vdbox_sfc_support_mask = gt->info.vdbox_sfc_access;",
                "\tblob->ads.reg_state_buffer = base + ptr_offset(blob, reg_state_buffer);",
                "\tblob->ads.reg_state_addr = base + ptr_offset(blob, reg_state);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Null pointer reference in some Intel(R) Graphics Drivers for Windows* before version 26.20.100.7212 and before version Linux kernel version 5.5 may allow a privileged user to potentially enable a denial of service via local access.",
        "id": 2466
    },
    {
        "cve_id": "CVE-2022-0168",
        "code_before_change": "static int\nsmb2_ioctl_query_info(const unsigned int xid,\n\t\t      struct cifs_tcon *tcon,\n\t\t      struct cifs_sb_info *cifs_sb,\n\t\t      __le16 *path, int is_dir,\n\t\t      unsigned long p)\n{\n\tstruct iqi_vars *vars;\n\tstruct smb_rqst *rqst;\n\tstruct kvec *rsp_iov;\n\tstruct cifs_ses *ses = tcon->ses;\n\tstruct TCP_Server_Info *server = cifs_pick_channel(ses);\n\tchar __user *arg = (char __user *)p;\n\tstruct smb_query_info qi;\n\tstruct smb_query_info __user *pqi;\n\tint rc = 0;\n\tint flags = CIFS_CP_CREATE_CLOSE_OP;\n\tstruct smb2_query_info_rsp *qi_rsp = NULL;\n\tstruct smb2_ioctl_rsp *io_rsp = NULL;\n\tvoid *buffer = NULL;\n\tint resp_buftype[3];\n\tstruct cifs_open_parms oparms;\n\tu8 oplock = SMB2_OPLOCK_LEVEL_NONE;\n\tstruct cifs_fid fid;\n\tunsigned int size[2];\n\tvoid *data[2];\n\tint create_options = is_dir ? CREATE_NOT_FILE : CREATE_NOT_DIR;\n\n\tvars = kzalloc(sizeof(*vars), GFP_ATOMIC);\n\tif (vars == NULL)\n\t\treturn -ENOMEM;\n\trqst = &vars->rqst[0];\n\trsp_iov = &vars->rsp_iov[0];\n\n\tresp_buftype[0] = resp_buftype[1] = resp_buftype[2] = CIFS_NO_BUFFER;\n\n\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info)))\n\t\tgoto e_fault;\n\n\tif (qi.output_buffer_length > 1024) {\n\t\tkfree(vars);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ses || !server) {\n\t\tkfree(vars);\n\t\treturn -EIO;\n\t}\n\n\tif (smb3_encryption_required(tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tif (qi.output_buffer_length) {\n\t\tbuffer = memdup_user(arg + sizeof(struct smb_query_info), qi.output_buffer_length);\n\t\tif (IS_ERR(buffer)) {\n\t\t\tkfree(vars);\n\t\t\treturn PTR_ERR(buffer);\n\t\t}\n\t}\n\n\t/* Open */\n\trqst[0].rq_iov = &vars->open_iov[0];\n\trqst[0].rq_nvec = SMB2_CREATE_IOV_SIZE;\n\n\tmemset(&oparms, 0, sizeof(oparms));\n\toparms.tcon = tcon;\n\toparms.disposition = FILE_OPEN;\n\toparms.create_options = cifs_create_options(cifs_sb, create_options);\n\toparms.fid = &fid;\n\toparms.reconnect = false;\n\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\tswitch (qi.info_type & FSCTL_DEVICE_ACCESS_MASK) {\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_READ_WRITE_ACCESS:\n\t\t\toparms.desired_access = FILE_READ_DATA | FILE_WRITE_DATA | FILE_READ_ATTRIBUTES | SYNCHRONIZE;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_ANY_ACCESS:\n\t\t\toparms.desired_access = GENERIC_ALL;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_READ_ACCESS:\n\t\t\toparms.desired_access = GENERIC_READ;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_WRITE_ACCESS:\n\t\t\toparms.desired_access = GENERIC_WRITE;\n\t\t\tbreak;\n\t\t}\n\t} else if (qi.flags & PASSTHRU_SET_INFO) {\n\t\toparms.desired_access = GENERIC_WRITE;\n\t} else {\n\t\toparms.desired_access = FILE_READ_ATTRIBUTES | READ_CONTROL;\n\t}\n\n\trc = SMB2_open_init(tcon, server,\n\t\t\t    &rqst[0], &oplock, &oparms, path);\n\tif (rc)\n\t\tgoto iqinf_exit;\n\tsmb2_set_next_command(tcon, &rqst[0]);\n\n\t/* Query */\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\t/* Can eventually relax perm check since server enforces too */\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\trc = -EPERM;\n\t\telse  {\n\t\t\trqst[1].rq_iov = &vars->io_iov[0];\n\t\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;\n\n\t\t\trc = SMB2_ioctl_init(tcon, server,\n\t\t\t\t\t     &rqst[1],\n\t\t\t\t\t     COMPOUND_FID, COMPOUND_FID,\n\t\t\t\t\t     qi.info_type, true, buffer,\n\t\t\t\t\t     qi.output_buffer_length,\n\t\t\t\t\t     CIFSMaxBufSize -\n\t\t\t\t\t     MAX_SMB2_CREATE_RESPONSE_SIZE -\n\t\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);\n\t\t}\n\t} else if (qi.flags == PASSTHRU_SET_INFO) {\n\t\t/* Can eventually relax perm check since server enforces too */\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\trc = -EPERM;\n\t\telse if (qi.output_buffer_length < 8)\n\t\t\trc = -EINVAL;\n\t\telse {\n\t\t\trqst[1].rq_iov = &vars->si_iov[0];\n\t\t\trqst[1].rq_nvec = 1;\n\n\t\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */\n\t\t\tsize[0] = 8;\n\t\t\tdata[0] = buffer;\n\n\t\t\trc = SMB2_set_info_init(tcon, server,\n\t\t\t\t\t&rqst[1],\n\t\t\t\t\tCOMPOUND_FID, COMPOUND_FID,\n\t\t\t\t\tcurrent->tgid,\n\t\t\t\t\tFILE_END_OF_FILE_INFORMATION,\n\t\t\t\t\tSMB2_O_INFO_FILE, 0, data, size);\n\t\t}\n\t} else if (qi.flags == PASSTHRU_QUERY_INFO) {\n\t\trqst[1].rq_iov = &vars->qi_iov[0];\n\t\trqst[1].rq_nvec = 1;\n\n\t\trc = SMB2_query_info_init(tcon, server,\n\t\t\t\t  &rqst[1], COMPOUND_FID,\n\t\t\t\t  COMPOUND_FID, qi.file_info_class,\n\t\t\t\t  qi.info_type, qi.additional_information,\n\t\t\t\t  qi.input_buffer_length,\n\t\t\t\t  qi.output_buffer_length, buffer);\n\t} else { /* unknown flags */\n\t\tcifs_tcon_dbg(VFS, \"Invalid passthru query flags: 0x%x\\n\",\n\t\t\t      qi.flags);\n\t\trc = -EINVAL;\n\t}\n\n\tif (rc)\n\t\tgoto iqinf_exit;\n\tsmb2_set_next_command(tcon, &rqst[1]);\n\tsmb2_set_related(&rqst[1]);\n\n\t/* Close */\n\trqst[2].rq_iov = &vars->close_iov[0];\n\trqst[2].rq_nvec = 1;\n\n\trc = SMB2_close_init(tcon, server,\n\t\t\t     &rqst[2], COMPOUND_FID, COMPOUND_FID, false);\n\tif (rc)\n\t\tgoto iqinf_exit;\n\tsmb2_set_related(&rqst[2]);\n\n\trc = compound_send_recv(xid, ses, server,\n\t\t\t\tflags, 3, rqst,\n\t\t\t\tresp_buftype, rsp_iov);\n\tif (rc)\n\t\tgoto iqinf_exit;\n\n\t/* No need to bump num_remote_opens since handle immediately closed */\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\tpqi = (struct smb_query_info __user *)arg;\n\t\tio_rsp = (struct smb2_ioctl_rsp *)rsp_iov[1].iov_base;\n\t\tif (le32_to_cpu(io_rsp->OutputCount) < qi.input_buffer_length)\n\t\t\tqi.input_buffer_length = le32_to_cpu(io_rsp->OutputCount);\n\t\tif (qi.input_buffer_length > 0 &&\n\t\t    le32_to_cpu(io_rsp->OutputOffset) + qi.input_buffer_length\n\t\t    > rsp_iov[1].iov_len)\n\t\t\tgoto e_fault;\n\n\t\tif (copy_to_user(&pqi->input_buffer_length,\n\t\t\t\t &qi.input_buffer_length,\n\t\t\t\t sizeof(qi.input_buffer_length)))\n\t\t\tgoto e_fault;\n\n\t\tif (copy_to_user((void __user *)pqi + sizeof(struct smb_query_info),\n\t\t\t\t (const void *)io_rsp + le32_to_cpu(io_rsp->OutputOffset),\n\t\t\t\t qi.input_buffer_length))\n\t\t\tgoto e_fault;\n\t} else {\n\t\tpqi = (struct smb_query_info __user *)arg;\n\t\tqi_rsp = (struct smb2_query_info_rsp *)rsp_iov[1].iov_base;\n\t\tif (le32_to_cpu(qi_rsp->OutputBufferLength) < qi.input_buffer_length)\n\t\t\tqi.input_buffer_length = le32_to_cpu(qi_rsp->OutputBufferLength);\n\t\tif (copy_to_user(&pqi->input_buffer_length,\n\t\t\t\t &qi.input_buffer_length,\n\t\t\t\t sizeof(qi.input_buffer_length)))\n\t\t\tgoto e_fault;\n\n\t\tif (copy_to_user(pqi + 1, qi_rsp->Buffer,\n\t\t\t\t qi.input_buffer_length))\n\t\t\tgoto e_fault;\n\t}\n\n iqinf_exit:\n\tcifs_small_buf_release(rqst[0].rq_iov[0].iov_base);\n\tcifs_small_buf_release(rqst[1].rq_iov[0].iov_base);\n\tcifs_small_buf_release(rqst[2].rq_iov[0].iov_base);\n\tfree_rsp_buf(resp_buftype[0], rsp_iov[0].iov_base);\n\tfree_rsp_buf(resp_buftype[1], rsp_iov[1].iov_base);\n\tfree_rsp_buf(resp_buftype[2], rsp_iov[2].iov_base);\n\tkfree(vars);\n\tkfree(buffer);\n\treturn rc;\n\ne_fault:\n\trc = -EFAULT;\n\tgoto iqinf_exit;\n}",
        "code_after_change": "static int\nsmb2_ioctl_query_info(const unsigned int xid,\n\t\t      struct cifs_tcon *tcon,\n\t\t      struct cifs_sb_info *cifs_sb,\n\t\t      __le16 *path, int is_dir,\n\t\t      unsigned long p)\n{\n\tstruct iqi_vars *vars;\n\tstruct smb_rqst *rqst;\n\tstruct kvec *rsp_iov;\n\tstruct cifs_ses *ses = tcon->ses;\n\tstruct TCP_Server_Info *server = cifs_pick_channel(ses);\n\tchar __user *arg = (char __user *)p;\n\tstruct smb_query_info qi;\n\tstruct smb_query_info __user *pqi;\n\tint rc = 0;\n\tint flags = CIFS_CP_CREATE_CLOSE_OP;\n\tstruct smb2_query_info_rsp *qi_rsp = NULL;\n\tstruct smb2_ioctl_rsp *io_rsp = NULL;\n\tvoid *buffer = NULL;\n\tint resp_buftype[3];\n\tstruct cifs_open_parms oparms;\n\tu8 oplock = SMB2_OPLOCK_LEVEL_NONE;\n\tstruct cifs_fid fid;\n\tunsigned int size[2];\n\tvoid *data[2];\n\tint create_options = is_dir ? CREATE_NOT_FILE : CREATE_NOT_DIR;\n\tvoid (*free_req1_func)(struct smb_rqst *r);\n\n\tvars = kzalloc(sizeof(*vars), GFP_ATOMIC);\n\tif (vars == NULL)\n\t\treturn -ENOMEM;\n\trqst = &vars->rqst[0];\n\trsp_iov = &vars->rsp_iov[0];\n\n\tresp_buftype[0] = resp_buftype[1] = resp_buftype[2] = CIFS_NO_BUFFER;\n\n\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info))) {\n\t\trc = -EFAULT;\n\t\tgoto free_vars;\n\t}\n\tif (qi.output_buffer_length > 1024) {\n\t\trc = -EINVAL;\n\t\tgoto free_vars;\n\t}\n\n\tif (!ses || !server) {\n\t\trc = -EIO;\n\t\tgoto free_vars;\n\t}\n\n\tif (smb3_encryption_required(tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tif (qi.output_buffer_length) {\n\t\tbuffer = memdup_user(arg + sizeof(struct smb_query_info), qi.output_buffer_length);\n\t\tif (IS_ERR(buffer)) {\n\t\t\trc = PTR_ERR(buffer);\n\t\t\tgoto free_vars;\n\t\t}\n\t}\n\n\t/* Open */\n\trqst[0].rq_iov = &vars->open_iov[0];\n\trqst[0].rq_nvec = SMB2_CREATE_IOV_SIZE;\n\n\tmemset(&oparms, 0, sizeof(oparms));\n\toparms.tcon = tcon;\n\toparms.disposition = FILE_OPEN;\n\toparms.create_options = cifs_create_options(cifs_sb, create_options);\n\toparms.fid = &fid;\n\toparms.reconnect = false;\n\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\tswitch (qi.info_type & FSCTL_DEVICE_ACCESS_MASK) {\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_READ_WRITE_ACCESS:\n\t\t\toparms.desired_access = FILE_READ_DATA | FILE_WRITE_DATA | FILE_READ_ATTRIBUTES | SYNCHRONIZE;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_ANY_ACCESS:\n\t\t\toparms.desired_access = GENERIC_ALL;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_READ_ACCESS:\n\t\t\toparms.desired_access = GENERIC_READ;\n\t\t\tbreak;\n\t\tcase FSCTL_DEVICE_ACCESS_FILE_WRITE_ACCESS:\n\t\t\toparms.desired_access = GENERIC_WRITE;\n\t\t\tbreak;\n\t\t}\n\t} else if (qi.flags & PASSTHRU_SET_INFO) {\n\t\toparms.desired_access = GENERIC_WRITE;\n\t} else {\n\t\toparms.desired_access = FILE_READ_ATTRIBUTES | READ_CONTROL;\n\t}\n\n\trc = SMB2_open_init(tcon, server,\n\t\t\t    &rqst[0], &oplock, &oparms, path);\n\tif (rc)\n\t\tgoto free_output_buffer;\n\tsmb2_set_next_command(tcon, &rqst[0]);\n\n\t/* Query */\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\t/* Can eventually relax perm check since server enforces too */\n\t\tif (!capable(CAP_SYS_ADMIN)) {\n\t\t\trc = -EPERM;\n\t\t\tgoto free_open_req;\n\t\t}\n\t\trqst[1].rq_iov = &vars->io_iov[0];\n\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;\n\n\t\trc = SMB2_ioctl_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,\n\t\t\t\t     qi.info_type, true, buffer, qi.output_buffer_length,\n\t\t\t\t     CIFSMaxBufSize - MAX_SMB2_CREATE_RESPONSE_SIZE -\n\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);\n\t\tfree_req1_func = SMB2_ioctl_free;\n\t} else if (qi.flags == PASSTHRU_SET_INFO) {\n\t\t/* Can eventually relax perm check since server enforces too */\n\t\tif (!capable(CAP_SYS_ADMIN)) {\n\t\t\trc = -EPERM;\n\t\t\tgoto free_open_req;\n\t\t}\n\t\tif (qi.output_buffer_length < 8) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto free_open_req;\n\t\t}\n\t\trqst[1].rq_iov = &vars->si_iov[0];\n\t\trqst[1].rq_nvec = 1;\n\n\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */\n\t\tsize[0] = 8;\n\t\tdata[0] = buffer;\n\n\t\trc = SMB2_set_info_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,\n\t\t\t\t\tcurrent->tgid, FILE_END_OF_FILE_INFORMATION,\n\t\t\t\t\tSMB2_O_INFO_FILE, 0, data, size);\n\t\tfree_req1_func = SMB2_set_info_free;\n\t} else if (qi.flags == PASSTHRU_QUERY_INFO) {\n\t\trqst[1].rq_iov = &vars->qi_iov[0];\n\t\trqst[1].rq_nvec = 1;\n\n\t\trc = SMB2_query_info_init(tcon, server,\n\t\t\t\t  &rqst[1], COMPOUND_FID,\n\t\t\t\t  COMPOUND_FID, qi.file_info_class,\n\t\t\t\t  qi.info_type, qi.additional_information,\n\t\t\t\t  qi.input_buffer_length,\n\t\t\t\t  qi.output_buffer_length, buffer);\n\t\tfree_req1_func = SMB2_query_info_free;\n\t} else { /* unknown flags */\n\t\tcifs_tcon_dbg(VFS, \"Invalid passthru query flags: 0x%x\\n\",\n\t\t\t      qi.flags);\n\t\trc = -EINVAL;\n\t}\n\n\tif (rc)\n\t\tgoto free_open_req;\n\tsmb2_set_next_command(tcon, &rqst[1]);\n\tsmb2_set_related(&rqst[1]);\n\n\t/* Close */\n\trqst[2].rq_iov = &vars->close_iov[0];\n\trqst[2].rq_nvec = 1;\n\n\trc = SMB2_close_init(tcon, server,\n\t\t\t     &rqst[2], COMPOUND_FID, COMPOUND_FID, false);\n\tif (rc)\n\t\tgoto free_req_1;\n\tsmb2_set_related(&rqst[2]);\n\n\trc = compound_send_recv(xid, ses, server,\n\t\t\t\tflags, 3, rqst,\n\t\t\t\tresp_buftype, rsp_iov);\n\tif (rc)\n\t\tgoto out;\n\n\t/* No need to bump num_remote_opens since handle immediately closed */\n\tif (qi.flags & PASSTHRU_FSCTL) {\n\t\tpqi = (struct smb_query_info __user *)arg;\n\t\tio_rsp = (struct smb2_ioctl_rsp *)rsp_iov[1].iov_base;\n\t\tif (le32_to_cpu(io_rsp->OutputCount) < qi.input_buffer_length)\n\t\t\tqi.input_buffer_length = le32_to_cpu(io_rsp->OutputCount);\n\t\tif (qi.input_buffer_length > 0 &&\n\t\t    le32_to_cpu(io_rsp->OutputOffset) + qi.input_buffer_length\n\t\t    > rsp_iov[1].iov_len) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (copy_to_user(&pqi->input_buffer_length,\n\t\t\t\t &qi.input_buffer_length,\n\t\t\t\t sizeof(qi.input_buffer_length))) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (copy_to_user((void __user *)pqi + sizeof(struct smb_query_info),\n\t\t\t\t (const void *)io_rsp + le32_to_cpu(io_rsp->OutputOffset),\n\t\t\t\t qi.input_buffer_length))\n\t\t\trc = -EFAULT;\n\t} else {\n\t\tpqi = (struct smb_query_info __user *)arg;\n\t\tqi_rsp = (struct smb2_query_info_rsp *)rsp_iov[1].iov_base;\n\t\tif (le32_to_cpu(qi_rsp->OutputBufferLength) < qi.input_buffer_length)\n\t\t\tqi.input_buffer_length = le32_to_cpu(qi_rsp->OutputBufferLength);\n\t\tif (copy_to_user(&pqi->input_buffer_length,\n\t\t\t\t &qi.input_buffer_length,\n\t\t\t\t sizeof(qi.input_buffer_length))) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (copy_to_user(pqi + 1, qi_rsp->Buffer,\n\t\t\t\t qi.input_buffer_length))\n\t\t\trc = -EFAULT;\n\t}\n\nout:\n\tfree_rsp_buf(resp_buftype[0], rsp_iov[0].iov_base);\n\tfree_rsp_buf(resp_buftype[1], rsp_iov[1].iov_base);\n\tfree_rsp_buf(resp_buftype[2], rsp_iov[2].iov_base);\n\tSMB2_close_free(&rqst[2]);\nfree_req_1:\n\tfree_req1_func(&rqst[1]);\nfree_open_req:\n\tSMB2_open_free(&rqst[0]);\nfree_output_buffer:\n\tkfree(buffer);\nfree_vars:\n\tkfree(vars);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,7 @@\n \tunsigned int size[2];\n \tvoid *data[2];\n \tint create_options = is_dir ? CREATE_NOT_FILE : CREATE_NOT_DIR;\n+\tvoid (*free_req1_func)(struct smb_rqst *r);\n \n \tvars = kzalloc(sizeof(*vars), GFP_ATOMIC);\n \tif (vars == NULL)\n@@ -34,17 +35,18 @@\n \n \tresp_buftype[0] = resp_buftype[1] = resp_buftype[2] = CIFS_NO_BUFFER;\n \n-\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info)))\n-\t\tgoto e_fault;\n-\n+\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info))) {\n+\t\trc = -EFAULT;\n+\t\tgoto free_vars;\n+\t}\n \tif (qi.output_buffer_length > 1024) {\n-\t\tkfree(vars);\n-\t\treturn -EINVAL;\n+\t\trc = -EINVAL;\n+\t\tgoto free_vars;\n \t}\n \n \tif (!ses || !server) {\n-\t\tkfree(vars);\n-\t\treturn -EIO;\n+\t\trc = -EIO;\n+\t\tgoto free_vars;\n \t}\n \n \tif (smb3_encryption_required(tcon))\n@@ -53,8 +55,8 @@\n \tif (qi.output_buffer_length) {\n \t\tbuffer = memdup_user(arg + sizeof(struct smb_query_info), qi.output_buffer_length);\n \t\tif (IS_ERR(buffer)) {\n-\t\t\tkfree(vars);\n-\t\t\treturn PTR_ERR(buffer);\n+\t\t\trc = PTR_ERR(buffer);\n+\t\t\tgoto free_vars;\n \t\t}\n \t}\n \n@@ -93,48 +95,45 @@\n \trc = SMB2_open_init(tcon, server,\n \t\t\t    &rqst[0], &oplock, &oparms, path);\n \tif (rc)\n-\t\tgoto iqinf_exit;\n+\t\tgoto free_output_buffer;\n \tsmb2_set_next_command(tcon, &rqst[0]);\n \n \t/* Query */\n \tif (qi.flags & PASSTHRU_FSCTL) {\n \t\t/* Can eventually relax perm check since server enforces too */\n-\t\tif (!capable(CAP_SYS_ADMIN))\n+\t\tif (!capable(CAP_SYS_ADMIN)) {\n \t\t\trc = -EPERM;\n-\t\telse  {\n-\t\t\trqst[1].rq_iov = &vars->io_iov[0];\n-\t\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;\n-\n-\t\t\trc = SMB2_ioctl_init(tcon, server,\n-\t\t\t\t\t     &rqst[1],\n-\t\t\t\t\t     COMPOUND_FID, COMPOUND_FID,\n-\t\t\t\t\t     qi.info_type, true, buffer,\n-\t\t\t\t\t     qi.output_buffer_length,\n-\t\t\t\t\t     CIFSMaxBufSize -\n-\t\t\t\t\t     MAX_SMB2_CREATE_RESPONSE_SIZE -\n-\t\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);\n-\t\t}\n+\t\t\tgoto free_open_req;\n+\t\t}\n+\t\trqst[1].rq_iov = &vars->io_iov[0];\n+\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;\n+\n+\t\trc = SMB2_ioctl_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,\n+\t\t\t\t     qi.info_type, true, buffer, qi.output_buffer_length,\n+\t\t\t\t     CIFSMaxBufSize - MAX_SMB2_CREATE_RESPONSE_SIZE -\n+\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);\n+\t\tfree_req1_func = SMB2_ioctl_free;\n \t} else if (qi.flags == PASSTHRU_SET_INFO) {\n \t\t/* Can eventually relax perm check since server enforces too */\n-\t\tif (!capable(CAP_SYS_ADMIN))\n+\t\tif (!capable(CAP_SYS_ADMIN)) {\n \t\t\trc = -EPERM;\n-\t\telse if (qi.output_buffer_length < 8)\n+\t\t\tgoto free_open_req;\n+\t\t}\n+\t\tif (qi.output_buffer_length < 8) {\n \t\t\trc = -EINVAL;\n-\t\telse {\n-\t\t\trqst[1].rq_iov = &vars->si_iov[0];\n-\t\t\trqst[1].rq_nvec = 1;\n-\n-\t\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */\n-\t\t\tsize[0] = 8;\n-\t\t\tdata[0] = buffer;\n-\n-\t\t\trc = SMB2_set_info_init(tcon, server,\n-\t\t\t\t\t&rqst[1],\n-\t\t\t\t\tCOMPOUND_FID, COMPOUND_FID,\n-\t\t\t\t\tcurrent->tgid,\n-\t\t\t\t\tFILE_END_OF_FILE_INFORMATION,\n+\t\t\tgoto free_open_req;\n+\t\t}\n+\t\trqst[1].rq_iov = &vars->si_iov[0];\n+\t\trqst[1].rq_nvec = 1;\n+\n+\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */\n+\t\tsize[0] = 8;\n+\t\tdata[0] = buffer;\n+\n+\t\trc = SMB2_set_info_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,\n+\t\t\t\t\tcurrent->tgid, FILE_END_OF_FILE_INFORMATION,\n \t\t\t\t\tSMB2_O_INFO_FILE, 0, data, size);\n-\t\t}\n+\t\tfree_req1_func = SMB2_set_info_free;\n \t} else if (qi.flags == PASSTHRU_QUERY_INFO) {\n \t\trqst[1].rq_iov = &vars->qi_iov[0];\n \t\trqst[1].rq_nvec = 1;\n@@ -145,6 +144,7 @@\n \t\t\t\t  qi.info_type, qi.additional_information,\n \t\t\t\t  qi.input_buffer_length,\n \t\t\t\t  qi.output_buffer_length, buffer);\n+\t\tfree_req1_func = SMB2_query_info_free;\n \t} else { /* unknown flags */\n \t\tcifs_tcon_dbg(VFS, \"Invalid passthru query flags: 0x%x\\n\",\n \t\t\t      qi.flags);\n@@ -152,7 +152,7 @@\n \t}\n \n \tif (rc)\n-\t\tgoto iqinf_exit;\n+\t\tgoto free_open_req;\n \tsmb2_set_next_command(tcon, &rqst[1]);\n \tsmb2_set_related(&rqst[1]);\n \n@@ -163,14 +163,14 @@\n \trc = SMB2_close_init(tcon, server,\n \t\t\t     &rqst[2], COMPOUND_FID, COMPOUND_FID, false);\n \tif (rc)\n-\t\tgoto iqinf_exit;\n+\t\tgoto free_req_1;\n \tsmb2_set_related(&rqst[2]);\n \n \trc = compound_send_recv(xid, ses, server,\n \t\t\t\tflags, 3, rqst,\n \t\t\t\tresp_buftype, rsp_iov);\n \tif (rc)\n-\t\tgoto iqinf_exit;\n+\t\tgoto out;\n \n \t/* No need to bump num_remote_opens since handle immediately closed */\n \tif (qi.flags & PASSTHRU_FSCTL) {\n@@ -180,18 +180,22 @@\n \t\t\tqi.input_buffer_length = le32_to_cpu(io_rsp->OutputCount);\n \t\tif (qi.input_buffer_length > 0 &&\n \t\t    le32_to_cpu(io_rsp->OutputOffset) + qi.input_buffer_length\n-\t\t    > rsp_iov[1].iov_len)\n-\t\t\tgoto e_fault;\n+\t\t    > rsp_iov[1].iov_len) {\n+\t\t\trc = -EFAULT;\n+\t\t\tgoto out;\n+\t\t}\n \n \t\tif (copy_to_user(&pqi->input_buffer_length,\n \t\t\t\t &qi.input_buffer_length,\n-\t\t\t\t sizeof(qi.input_buffer_length)))\n-\t\t\tgoto e_fault;\n+\t\t\t\t sizeof(qi.input_buffer_length))) {\n+\t\t\trc = -EFAULT;\n+\t\t\tgoto out;\n+\t\t}\n \n \t\tif (copy_to_user((void __user *)pqi + sizeof(struct smb_query_info),\n \t\t\t\t (const void *)io_rsp + le32_to_cpu(io_rsp->OutputOffset),\n \t\t\t\t qi.input_buffer_length))\n-\t\t\tgoto e_fault;\n+\t\t\trc = -EFAULT;\n \t} else {\n \t\tpqi = (struct smb_query_info __user *)arg;\n \t\tqi_rsp = (struct smb2_query_info_rsp *)rsp_iov[1].iov_base;\n@@ -199,26 +203,28 @@\n \t\t\tqi.input_buffer_length = le32_to_cpu(qi_rsp->OutputBufferLength);\n \t\tif (copy_to_user(&pqi->input_buffer_length,\n \t\t\t\t &qi.input_buffer_length,\n-\t\t\t\t sizeof(qi.input_buffer_length)))\n-\t\t\tgoto e_fault;\n+\t\t\t\t sizeof(qi.input_buffer_length))) {\n+\t\t\trc = -EFAULT;\n+\t\t\tgoto out;\n+\t\t}\n \n \t\tif (copy_to_user(pqi + 1, qi_rsp->Buffer,\n \t\t\t\t qi.input_buffer_length))\n-\t\t\tgoto e_fault;\n-\t}\n-\n- iqinf_exit:\n-\tcifs_small_buf_release(rqst[0].rq_iov[0].iov_base);\n-\tcifs_small_buf_release(rqst[1].rq_iov[0].iov_base);\n-\tcifs_small_buf_release(rqst[2].rq_iov[0].iov_base);\n+\t\t\trc = -EFAULT;\n+\t}\n+\n+out:\n \tfree_rsp_buf(resp_buftype[0], rsp_iov[0].iov_base);\n \tfree_rsp_buf(resp_buftype[1], rsp_iov[1].iov_base);\n \tfree_rsp_buf(resp_buftype[2], rsp_iov[2].iov_base);\n+\tSMB2_close_free(&rqst[2]);\n+free_req_1:\n+\tfree_req1_func(&rqst[1]);\n+free_open_req:\n+\tSMB2_open_free(&rqst[0]);\n+free_output_buffer:\n+\tkfree(buffer);\n+free_vars:\n \tkfree(vars);\n-\tkfree(buffer);\n \treturn rc;\n-\n-e_fault:\n-\trc = -EFAULT;\n-\tgoto iqinf_exit;\n }",
        "function_modified_lines": {
            "added": [
                "\tvoid (*free_req1_func)(struct smb_rqst *r);",
                "\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info))) {",
                "\t\trc = -EFAULT;",
                "\t\tgoto free_vars;",
                "\t}",
                "\t\trc = -EINVAL;",
                "\t\tgoto free_vars;",
                "\t\trc = -EIO;",
                "\t\tgoto free_vars;",
                "\t\t\trc = PTR_ERR(buffer);",
                "\t\t\tgoto free_vars;",
                "\t\tgoto free_output_buffer;",
                "\t\tif (!capable(CAP_SYS_ADMIN)) {",
                "\t\t\tgoto free_open_req;",
                "\t\t}",
                "\t\trqst[1].rq_iov = &vars->io_iov[0];",
                "\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;",
                "",
                "\t\trc = SMB2_ioctl_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,",
                "\t\t\t\t     qi.info_type, true, buffer, qi.output_buffer_length,",
                "\t\t\t\t     CIFSMaxBufSize - MAX_SMB2_CREATE_RESPONSE_SIZE -",
                "\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);",
                "\t\tfree_req1_func = SMB2_ioctl_free;",
                "\t\tif (!capable(CAP_SYS_ADMIN)) {",
                "\t\t\tgoto free_open_req;",
                "\t\t}",
                "\t\tif (qi.output_buffer_length < 8) {",
                "\t\t\tgoto free_open_req;",
                "\t\t}",
                "\t\trqst[1].rq_iov = &vars->si_iov[0];",
                "\t\trqst[1].rq_nvec = 1;",
                "",
                "\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */",
                "\t\tsize[0] = 8;",
                "\t\tdata[0] = buffer;",
                "",
                "\t\trc = SMB2_set_info_init(tcon, server, &rqst[1], COMPOUND_FID, COMPOUND_FID,",
                "\t\t\t\t\tcurrent->tgid, FILE_END_OF_FILE_INFORMATION,",
                "\t\tfree_req1_func = SMB2_set_info_free;",
                "\t\tfree_req1_func = SMB2_query_info_free;",
                "\t\tgoto free_open_req;",
                "\t\tgoto free_req_1;",
                "\t\tgoto out;",
                "\t\t    > rsp_iov[1].iov_len) {",
                "\t\t\trc = -EFAULT;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t\t\t\t sizeof(qi.input_buffer_length))) {",
                "\t\t\trc = -EFAULT;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t\t\trc = -EFAULT;",
                "\t\t\t\t sizeof(qi.input_buffer_length))) {",
                "\t\t\trc = -EFAULT;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t\t\trc = -EFAULT;",
                "\t}",
                "",
                "out:",
                "\tSMB2_close_free(&rqst[2]);",
                "free_req_1:",
                "\tfree_req1_func(&rqst[1]);",
                "free_open_req:",
                "\tSMB2_open_free(&rqst[0]);",
                "free_output_buffer:",
                "\tkfree(buffer);",
                "free_vars:"
            ],
            "deleted": [
                "\tif (copy_from_user(&qi, arg, sizeof(struct smb_query_info)))",
                "\t\tgoto e_fault;",
                "",
                "\t\tkfree(vars);",
                "\t\treturn -EINVAL;",
                "\t\tkfree(vars);",
                "\t\treturn -EIO;",
                "\t\t\tkfree(vars);",
                "\t\t\treturn PTR_ERR(buffer);",
                "\t\tgoto iqinf_exit;",
                "\t\tif (!capable(CAP_SYS_ADMIN))",
                "\t\telse  {",
                "\t\t\trqst[1].rq_iov = &vars->io_iov[0];",
                "\t\t\trqst[1].rq_nvec = SMB2_IOCTL_IOV_SIZE;",
                "",
                "\t\t\trc = SMB2_ioctl_init(tcon, server,",
                "\t\t\t\t\t     &rqst[1],",
                "\t\t\t\t\t     COMPOUND_FID, COMPOUND_FID,",
                "\t\t\t\t\t     qi.info_type, true, buffer,",
                "\t\t\t\t\t     qi.output_buffer_length,",
                "\t\t\t\t\t     CIFSMaxBufSize -",
                "\t\t\t\t\t     MAX_SMB2_CREATE_RESPONSE_SIZE -",
                "\t\t\t\t\t     MAX_SMB2_CLOSE_RESPONSE_SIZE);",
                "\t\t}",
                "\t\tif (!capable(CAP_SYS_ADMIN))",
                "\t\telse if (qi.output_buffer_length < 8)",
                "\t\telse {",
                "\t\t\trqst[1].rq_iov = &vars->si_iov[0];",
                "\t\t\trqst[1].rq_nvec = 1;",
                "",
                "\t\t\t/* MS-FSCC 2.4.13 FileEndOfFileInformation */",
                "\t\t\tsize[0] = 8;",
                "\t\t\tdata[0] = buffer;",
                "",
                "\t\t\trc = SMB2_set_info_init(tcon, server,",
                "\t\t\t\t\t&rqst[1],",
                "\t\t\t\t\tCOMPOUND_FID, COMPOUND_FID,",
                "\t\t\t\t\tcurrent->tgid,",
                "\t\t\t\t\tFILE_END_OF_FILE_INFORMATION,",
                "\t\t}",
                "\t\tgoto iqinf_exit;",
                "\t\tgoto iqinf_exit;",
                "\t\tgoto iqinf_exit;",
                "\t\t    > rsp_iov[1].iov_len)",
                "\t\t\tgoto e_fault;",
                "\t\t\t\t sizeof(qi.input_buffer_length)))",
                "\t\t\tgoto e_fault;",
                "\t\t\tgoto e_fault;",
                "\t\t\t\t sizeof(qi.input_buffer_length)))",
                "\t\t\tgoto e_fault;",
                "\t\t\tgoto e_fault;",
                "\t}",
                "",
                " iqinf_exit:",
                "\tcifs_small_buf_release(rqst[0].rq_iov[0].iov_base);",
                "\tcifs_small_buf_release(rqst[1].rq_iov[0].iov_base);",
                "\tcifs_small_buf_release(rqst[2].rq_iov[0].iov_base);",
                "\tkfree(buffer);",
                "",
                "e_fault:",
                "\trc = -EFAULT;",
                "\tgoto iqinf_exit;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A denial of service (DOS) issue was found in the Linux kernel’s smb2_ioctl_query_info function in the fs/cifs/smb2ops.c Common Internet File System (CIFS) due to an incorrect return from the memdup_user function. This flaw allows a local, privileged (CAP_SYS_ADMIN) attacker to crash the system.",
        "id": 3190
    },
    {
        "cve_id": "CVE-2019-15923",
        "code_before_change": "static int __init pcd_init(void)\n{\n\tstruct pcd_unit *cd;\n\tint unit;\n\n\tif (disable)\n\t\treturn -EINVAL;\n\n\tpcd_init_units();\n\n\tif (pcd_detect())\n\t\treturn -ENODEV;\n\n\t/* get the atapi capabilities page */\n\tpcd_probe_capabilities();\n\n\tif (register_blkdev(major, name)) {\n\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++)\n\t\t\tput_disk(cd->disk);\n\t\treturn -EBUSY;\n\t}\n\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tif (cd->present) {\n\t\t\tregister_cdrom(&cd->info);\n\t\t\tcd->disk->private_data = cd;\n\t\t\tadd_disk(cd->disk);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int __init pcd_init(void)\n{\n\tstruct pcd_unit *cd;\n\tint unit;\n\n\tif (disable)\n\t\treturn -EINVAL;\n\n\tpcd_init_units();\n\n\tif (pcd_detect())\n\t\treturn -ENODEV;\n\n\t/* get the atapi capabilities page */\n\tpcd_probe_capabilities();\n\n\tif (register_blkdev(major, name)) {\n\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\t\tif (!cd->disk)\n\t\t\t\tcontinue;\n\n\t\t\tblk_cleanup_queue(cd->disk->queue);\n\t\t\tblk_mq_free_tag_set(&cd->tag_set);\n\t\t\tput_disk(cd->disk);\n\t\t}\n\t\treturn -EBUSY;\n\t}\n\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tif (cd->present) {\n\t\t\tregister_cdrom(&cd->info);\n\t\t\tcd->disk->private_data = cd;\n\t\t\tadd_disk(cd->disk);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,8 +15,14 @@\n \tpcd_probe_capabilities();\n \n \tif (register_blkdev(major, name)) {\n-\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++)\n+\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n+\t\t\tif (!cd->disk)\n+\t\t\t\tcontinue;\n+\n+\t\t\tblk_cleanup_queue(cd->disk->queue);\n+\t\t\tblk_mq_free_tag_set(&cd->tag_set);\n \t\t\tput_disk(cd->disk);\n+\t\t}\n \t\treturn -EBUSY;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {",
                "\t\t\tif (!cd->disk)",
                "\t\t\t\tcontinue;",
                "",
                "\t\t\tblk_cleanup_queue(cd->disk->queue);",
                "\t\t\tblk_mq_free_tag_set(&cd->tag_set);",
                "\t\t}"
            ],
            "deleted": [
                "\t\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.9. There is a NULL pointer dereference for a cd data structure if alloc_disk fails in drivers/block/paride/pf.c.",
        "id": 2034
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "static void ksmbd_conn_unlock(struct ksmbd_conn *conn)\n{\n\tmutex_unlock(&conn->srv_mutex);\n}",
        "code_after_change": "void ksmbd_conn_unlock(struct ksmbd_conn *conn)\n{\n\tmutex_unlock(&conn->srv_mutex);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,4 @@\n-static void ksmbd_conn_unlock(struct ksmbd_conn *conn)\n+void ksmbd_conn_unlock(struct ksmbd_conn *conn)\n {\n \tmutex_unlock(&conn->srv_mutex);\n }",
        "function_modified_lines": {
            "added": [
                "void ksmbd_conn_unlock(struct ksmbd_conn *conn)"
            ],
            "deleted": [
                "static void ksmbd_conn_unlock(struct ksmbd_conn *conn)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4025
    },
    {
        "cve_id": "CVE-2020-14356",
        "code_before_change": "void cgroup_sk_alloc(struct sock_cgroup_data *skcd)\n{\n\tif (cgroup_sk_alloc_disabled)\n\t\treturn;\n\n\t/* Socket clone path */\n\tif (skcd->val) {\n\t\t/*\n\t\t * We might be cloning a socket which is left in an empty\n\t\t * cgroup and the cgroup might have already been rmdir'd.\n\t\t * Don't use cgroup_get_live().\n\t\t */\n\t\tcgroup_get(sock_cgroup_ptr(skcd));\n\t\tcgroup_bpf_get(sock_cgroup_ptr(skcd));\n\t\treturn;\n\t}\n\n\t/* Don't associate the sock with unrelated interrupted task's cgroup. */\n\tif (in_interrupt())\n\t\treturn;\n\n\trcu_read_lock();\n\n\twhile (true) {\n\t\tstruct css_set *cset;\n\n\t\tcset = task_css_set(current);\n\t\tif (likely(cgroup_tryget(cset->dfl_cgrp))) {\n\t\t\tskcd->val = (unsigned long)cset->dfl_cgrp;\n\t\t\tcgroup_bpf_get(cset->dfl_cgrp);\n\t\t\tbreak;\n\t\t}\n\t\tcpu_relax();\n\t}\n\n\trcu_read_unlock();\n}",
        "code_after_change": "void cgroup_sk_alloc(struct sock_cgroup_data *skcd)\n{\n\tif (cgroup_sk_alloc_disabled) {\n\t\tskcd->no_refcnt = 1;\n\t\treturn;\n\t}\n\n\t/* Don't associate the sock with unrelated interrupted task's cgroup. */\n\tif (in_interrupt())\n\t\treturn;\n\n\trcu_read_lock();\n\n\twhile (true) {\n\t\tstruct css_set *cset;\n\n\t\tcset = task_css_set(current);\n\t\tif (likely(cgroup_tryget(cset->dfl_cgrp))) {\n\t\t\tskcd->val = (unsigned long)cset->dfl_cgrp;\n\t\t\tcgroup_bpf_get(cset->dfl_cgrp);\n\t\t\tbreak;\n\t\t}\n\t\tcpu_relax();\n\t}\n\n\trcu_read_unlock();\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,17 +1,7 @@\n void cgroup_sk_alloc(struct sock_cgroup_data *skcd)\n {\n-\tif (cgroup_sk_alloc_disabled)\n-\t\treturn;\n-\n-\t/* Socket clone path */\n-\tif (skcd->val) {\n-\t\t/*\n-\t\t * We might be cloning a socket which is left in an empty\n-\t\t * cgroup and the cgroup might have already been rmdir'd.\n-\t\t * Don't use cgroup_get_live().\n-\t\t */\n-\t\tcgroup_get(sock_cgroup_ptr(skcd));\n-\t\tcgroup_bpf_get(sock_cgroup_ptr(skcd));\n+\tif (cgroup_sk_alloc_disabled) {\n+\t\tskcd->no_refcnt = 1;\n \t\treturn;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tif (cgroup_sk_alloc_disabled) {",
                "\t\tskcd->no_refcnt = 1;"
            ],
            "deleted": [
                "\tif (cgroup_sk_alloc_disabled)",
                "\t\treturn;",
                "",
                "\t/* Socket clone path */",
                "\tif (skcd->val) {",
                "\t\t/*",
                "\t\t * We might be cloning a socket which is left in an empty",
                "\t\t * cgroup and the cgroup might have already been rmdir'd.",
                "\t\t * Don't use cgroup_get_live().",
                "\t\t */",
                "\t\tcgroup_get(sock_cgroup_ptr(skcd));",
                "\t\tcgroup_bpf_get(sock_cgroup_ptr(skcd));"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw null pointer dereference in the Linux kernel cgroupv2 subsystem in versions before 5.7.10 was found in the way when reboot the system. A local user could use this flaw to crash the system or escalate their privileges on the system.",
        "id": 2517
    },
    {
        "cve_id": "CVE-2023-32248",
        "code_before_change": "static int smb2_get_info_filesystem(struct ksmbd_work *work,\n\t\t\t\t    struct smb2_query_info_req *req,\n\t\t\t\t    struct smb2_query_info_rsp *rsp)\n{\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_share_config *share = work->tcon->share_conf;\n\tint fsinfoclass = 0;\n\tstruct kstatfs stfs;\n\tstruct path path;\n\tint rc = 0, len;\n\tint fs_infoclass_size = 0;\n\n\trc = kern_path(share->path, LOOKUP_NO_SYMLINKS, &path);\n\tif (rc) {\n\t\tpr_err(\"cannot create vfs path\\n\");\n\t\treturn -EIO;\n\t}\n\n\trc = vfs_statfs(&path, &stfs);\n\tif (rc) {\n\t\tpr_err(\"cannot do stat of path %s\\n\", share->path);\n\t\tpath_put(&path);\n\t\treturn -EIO;\n\t}\n\n\tfsinfoclass = req->FileInfoClass;\n\n\tswitch (fsinfoclass) {\n\tcase FS_DEVICE_INFORMATION:\n\t{\n\t\tstruct filesystem_device_info *info;\n\n\t\tinfo = (struct filesystem_device_info *)rsp->Buffer;\n\n\t\tinfo->DeviceType = cpu_to_le32(stfs.f_type);\n\t\tinfo->DeviceCharacteristics = cpu_to_le32(0x00000020);\n\t\trsp->OutputBufferLength = cpu_to_le32(8);\n\t\tinc_rfc1001_len(work->response_buf, 8);\n\t\tfs_infoclass_size = FS_DEVICE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_ATTRIBUTE_INFORMATION:\n\t{\n\t\tstruct filesystem_attribute_info *info;\n\t\tsize_t sz;\n\n\t\tinfo = (struct filesystem_attribute_info *)rsp->Buffer;\n\t\tinfo->Attributes = cpu_to_le32(FILE_SUPPORTS_OBJECT_IDS |\n\t\t\t\t\t       FILE_PERSISTENT_ACLS |\n\t\t\t\t\t       FILE_UNICODE_ON_DISK |\n\t\t\t\t\t       FILE_CASE_PRESERVED_NAMES |\n\t\t\t\t\t       FILE_CASE_SENSITIVE_SEARCH |\n\t\t\t\t\t       FILE_SUPPORTS_BLOCK_REFCOUNTING);\n\n\t\tinfo->Attributes |= cpu_to_le32(server_conf.share_fake_fscaps);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t    KSMBD_SHARE_FLAG_STREAMS))\n\t\t\tinfo->Attributes |= cpu_to_le32(FILE_NAMED_STREAMS);\n\n\t\tinfo->MaxPathNameComponentLength = cpu_to_le32(stfs.f_namelen);\n\t\tlen = smbConvertToUTF16((__le16 *)info->FileSystemName,\n\t\t\t\t\t\"NTFS\", PATH_MAX, conn->local_nls, 0);\n\t\tlen = len * 2;\n\t\tinfo->FileSystemNameLen = cpu_to_le32(len);\n\t\tsz = sizeof(struct filesystem_attribute_info) - 2 + len;\n\t\trsp->OutputBufferLength = cpu_to_le32(sz);\n\t\tinc_rfc1001_len(work->response_buf, sz);\n\t\tfs_infoclass_size = FS_ATTRIBUTE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_VOLUME_INFORMATION:\n\t{\n\t\tstruct filesystem_vol_info *info;\n\t\tsize_t sz;\n\t\tunsigned int serial_crc = 0;\n\n\t\tinfo = (struct filesystem_vol_info *)(rsp->Buffer);\n\t\tinfo->VolumeCreationTime = 0;\n\t\tserial_crc = crc32_le(serial_crc, share->name,\n\t\t\t\t      strlen(share->name));\n\t\tserial_crc = crc32_le(serial_crc, share->path,\n\t\t\t\t      strlen(share->path));\n\t\tserial_crc = crc32_le(serial_crc, ksmbd_netbios_name(),\n\t\t\t\t      strlen(ksmbd_netbios_name()));\n\t\t/* Taking dummy value of serial number*/\n\t\tinfo->SerialNumber = cpu_to_le32(serial_crc);\n\t\tlen = smbConvertToUTF16((__le16 *)info->VolumeLabel,\n\t\t\t\t\tshare->name, PATH_MAX,\n\t\t\t\t\tconn->local_nls, 0);\n\t\tlen = len * 2;\n\t\tinfo->VolumeLabelSize = cpu_to_le32(len);\n\t\tinfo->Reserved = 0;\n\t\tsz = sizeof(struct filesystem_vol_info) - 2 + len;\n\t\trsp->OutputBufferLength = cpu_to_le32(sz);\n\t\tinc_rfc1001_len(work->response_buf, sz);\n\t\tfs_infoclass_size = FS_VOLUME_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_SIZE_INFORMATION:\n\t{\n\t\tstruct filesystem_info *info;\n\n\t\tinfo = (struct filesystem_info *)(rsp->Buffer);\n\t\tinfo->TotalAllocationUnits = cpu_to_le64(stfs.f_blocks);\n\t\tinfo->FreeAllocationUnits = cpu_to_le64(stfs.f_bfree);\n\t\tinfo->SectorsPerAllocationUnit = cpu_to_le32(1);\n\t\tinfo->BytesPerSector = cpu_to_le32(stfs.f_bsize);\n\t\trsp->OutputBufferLength = cpu_to_le32(24);\n\t\tinc_rfc1001_len(work->response_buf, 24);\n\t\tfs_infoclass_size = FS_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_FULL_SIZE_INFORMATION:\n\t{\n\t\tstruct smb2_fs_full_size_info *info;\n\n\t\tinfo = (struct smb2_fs_full_size_info *)(rsp->Buffer);\n\t\tinfo->TotalAllocationUnits = cpu_to_le64(stfs.f_blocks);\n\t\tinfo->CallerAvailableAllocationUnits =\n\t\t\t\t\tcpu_to_le64(stfs.f_bavail);\n\t\tinfo->ActualAvailableAllocationUnits =\n\t\t\t\t\tcpu_to_le64(stfs.f_bfree);\n\t\tinfo->SectorsPerAllocationUnit = cpu_to_le32(1);\n\t\tinfo->BytesPerSector = cpu_to_le32(stfs.f_bsize);\n\t\trsp->OutputBufferLength = cpu_to_le32(32);\n\t\tinc_rfc1001_len(work->response_buf, 32);\n\t\tfs_infoclass_size = FS_FULL_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_OBJECT_ID_INFORMATION:\n\t{\n\t\tstruct object_id_info *info;\n\n\t\tinfo = (struct object_id_info *)(rsp->Buffer);\n\n\t\tif (!user_guest(sess->user))\n\t\t\tmemcpy(info->objid, user_passkey(sess->user), 16);\n\t\telse\n\t\t\tmemset(info->objid, 0, 16);\n\n\t\tinfo->extended_info.magic = cpu_to_le32(EXTENDED_INFO_MAGIC);\n\t\tinfo->extended_info.version = cpu_to_le32(1);\n\t\tinfo->extended_info.release = cpu_to_le32(1);\n\t\tinfo->extended_info.rel_date = 0;\n\t\tmemcpy(info->extended_info.version_string, \"1.1.0\", strlen(\"1.1.0\"));\n\t\trsp->OutputBufferLength = cpu_to_le32(64);\n\t\tinc_rfc1001_len(work->response_buf, 64);\n\t\tfs_infoclass_size = FS_OBJECT_ID_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_SECTOR_SIZE_INFORMATION:\n\t{\n\t\tstruct smb3_fs_ss_info *info;\n\t\tunsigned int sector_size =\n\t\t\tmin_t(unsigned int, path.mnt->mnt_sb->s_blocksize, 4096);\n\n\t\tinfo = (struct smb3_fs_ss_info *)(rsp->Buffer);\n\n\t\tinfo->LogicalBytesPerSector = cpu_to_le32(sector_size);\n\t\tinfo->PhysicalBytesPerSectorForAtomicity =\n\t\t\t\tcpu_to_le32(sector_size);\n\t\tinfo->PhysicalBytesPerSectorForPerf = cpu_to_le32(sector_size);\n\t\tinfo->FSEffPhysicalBytesPerSectorForAtomicity =\n\t\t\t\tcpu_to_le32(sector_size);\n\t\tinfo->Flags = cpu_to_le32(SSINFO_FLAGS_ALIGNED_DEVICE |\n\t\t\t\t    SSINFO_FLAGS_PARTITION_ALIGNED_ON_DEVICE);\n\t\tinfo->ByteOffsetForSectorAlignment = 0;\n\t\tinfo->ByteOffsetForPartitionAlignment = 0;\n\t\trsp->OutputBufferLength = cpu_to_le32(28);\n\t\tinc_rfc1001_len(work->response_buf, 28);\n\t\tfs_infoclass_size = FS_SECTOR_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_CONTROL_INFORMATION:\n\t{\n\t\t/*\n\t\t * TODO : The current implementation is based on\n\t\t * test result with win7(NTFS) server. It's need to\n\t\t * modify this to get valid Quota values\n\t\t * from Linux kernel\n\t\t */\n\t\tstruct smb2_fs_control_info *info;\n\n\t\tinfo = (struct smb2_fs_control_info *)(rsp->Buffer);\n\t\tinfo->FreeSpaceStartFiltering = 0;\n\t\tinfo->FreeSpaceThreshold = 0;\n\t\tinfo->FreeSpaceStopFiltering = 0;\n\t\tinfo->DefaultQuotaThreshold = cpu_to_le64(SMB2_NO_FID);\n\t\tinfo->DefaultQuotaLimit = cpu_to_le64(SMB2_NO_FID);\n\t\tinfo->Padding = 0;\n\t\trsp->OutputBufferLength = cpu_to_le32(48);\n\t\tinc_rfc1001_len(work->response_buf, 48);\n\t\tfs_infoclass_size = FS_CONTROL_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_POSIX_INFORMATION:\n\t{\n\t\tstruct filesystem_posix_info *info;\n\n\t\tif (!work->tcon->posix_extensions) {\n\t\t\tpr_err(\"client doesn't negotiate with SMB3.1.1 POSIX Extensions\\n\");\n\t\t\trc = -EOPNOTSUPP;\n\t\t} else {\n\t\t\tinfo = (struct filesystem_posix_info *)(rsp->Buffer);\n\t\t\tinfo->OptimalTransferSize = cpu_to_le32(stfs.f_bsize);\n\t\t\tinfo->BlockSize = cpu_to_le32(stfs.f_bsize);\n\t\t\tinfo->TotalBlocks = cpu_to_le64(stfs.f_blocks);\n\t\t\tinfo->BlocksAvail = cpu_to_le64(stfs.f_bfree);\n\t\t\tinfo->UserBlocksAvail = cpu_to_le64(stfs.f_bavail);\n\t\t\tinfo->TotalFileNodes = cpu_to_le64(stfs.f_files);\n\t\t\tinfo->FreeFileNodes = cpu_to_le64(stfs.f_ffree);\n\t\t\trsp->OutputBufferLength = cpu_to_le32(56);\n\t\t\tinc_rfc1001_len(work->response_buf, 56);\n\t\t\tfs_infoclass_size = FS_POSIX_INFORMATION_SIZE;\n\t\t}\n\t\tbreak;\n\t}\n\tdefault:\n\t\tpath_put(&path);\n\t\treturn -EOPNOTSUPP;\n\t}\n\trc = buffer_check_err(le32_to_cpu(req->OutputBufferLength),\n\t\t\t      rsp, work->response_buf,\n\t\t\t      fs_infoclass_size);\n\tpath_put(&path);\n\treturn rc;\n}",
        "code_after_change": "static int smb2_get_info_filesystem(struct ksmbd_work *work,\n\t\t\t\t    struct smb2_query_info_req *req,\n\t\t\t\t    struct smb2_query_info_rsp *rsp)\n{\n\tstruct ksmbd_session *sess = work->sess;\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct ksmbd_share_config *share = work->tcon->share_conf;\n\tint fsinfoclass = 0;\n\tstruct kstatfs stfs;\n\tstruct path path;\n\tint rc = 0, len;\n\tint fs_infoclass_size = 0;\n\n\tif (!share->path)\n\t\treturn -EIO;\n\n\trc = kern_path(share->path, LOOKUP_NO_SYMLINKS, &path);\n\tif (rc) {\n\t\tpr_err(\"cannot create vfs path\\n\");\n\t\treturn -EIO;\n\t}\n\n\trc = vfs_statfs(&path, &stfs);\n\tif (rc) {\n\t\tpr_err(\"cannot do stat of path %s\\n\", share->path);\n\t\tpath_put(&path);\n\t\treturn -EIO;\n\t}\n\n\tfsinfoclass = req->FileInfoClass;\n\n\tswitch (fsinfoclass) {\n\tcase FS_DEVICE_INFORMATION:\n\t{\n\t\tstruct filesystem_device_info *info;\n\n\t\tinfo = (struct filesystem_device_info *)rsp->Buffer;\n\n\t\tinfo->DeviceType = cpu_to_le32(stfs.f_type);\n\t\tinfo->DeviceCharacteristics = cpu_to_le32(0x00000020);\n\t\trsp->OutputBufferLength = cpu_to_le32(8);\n\t\tinc_rfc1001_len(work->response_buf, 8);\n\t\tfs_infoclass_size = FS_DEVICE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_ATTRIBUTE_INFORMATION:\n\t{\n\t\tstruct filesystem_attribute_info *info;\n\t\tsize_t sz;\n\n\t\tinfo = (struct filesystem_attribute_info *)rsp->Buffer;\n\t\tinfo->Attributes = cpu_to_le32(FILE_SUPPORTS_OBJECT_IDS |\n\t\t\t\t\t       FILE_PERSISTENT_ACLS |\n\t\t\t\t\t       FILE_UNICODE_ON_DISK |\n\t\t\t\t\t       FILE_CASE_PRESERVED_NAMES |\n\t\t\t\t\t       FILE_CASE_SENSITIVE_SEARCH |\n\t\t\t\t\t       FILE_SUPPORTS_BLOCK_REFCOUNTING);\n\n\t\tinfo->Attributes |= cpu_to_le32(server_conf.share_fake_fscaps);\n\n\t\tif (test_share_config_flag(work->tcon->share_conf,\n\t\t    KSMBD_SHARE_FLAG_STREAMS))\n\t\t\tinfo->Attributes |= cpu_to_le32(FILE_NAMED_STREAMS);\n\n\t\tinfo->MaxPathNameComponentLength = cpu_to_le32(stfs.f_namelen);\n\t\tlen = smbConvertToUTF16((__le16 *)info->FileSystemName,\n\t\t\t\t\t\"NTFS\", PATH_MAX, conn->local_nls, 0);\n\t\tlen = len * 2;\n\t\tinfo->FileSystemNameLen = cpu_to_le32(len);\n\t\tsz = sizeof(struct filesystem_attribute_info) - 2 + len;\n\t\trsp->OutputBufferLength = cpu_to_le32(sz);\n\t\tinc_rfc1001_len(work->response_buf, sz);\n\t\tfs_infoclass_size = FS_ATTRIBUTE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_VOLUME_INFORMATION:\n\t{\n\t\tstruct filesystem_vol_info *info;\n\t\tsize_t sz;\n\t\tunsigned int serial_crc = 0;\n\n\t\tinfo = (struct filesystem_vol_info *)(rsp->Buffer);\n\t\tinfo->VolumeCreationTime = 0;\n\t\tserial_crc = crc32_le(serial_crc, share->name,\n\t\t\t\t      strlen(share->name));\n\t\tserial_crc = crc32_le(serial_crc, share->path,\n\t\t\t\t      strlen(share->path));\n\t\tserial_crc = crc32_le(serial_crc, ksmbd_netbios_name(),\n\t\t\t\t      strlen(ksmbd_netbios_name()));\n\t\t/* Taking dummy value of serial number*/\n\t\tinfo->SerialNumber = cpu_to_le32(serial_crc);\n\t\tlen = smbConvertToUTF16((__le16 *)info->VolumeLabel,\n\t\t\t\t\tshare->name, PATH_MAX,\n\t\t\t\t\tconn->local_nls, 0);\n\t\tlen = len * 2;\n\t\tinfo->VolumeLabelSize = cpu_to_le32(len);\n\t\tinfo->Reserved = 0;\n\t\tsz = sizeof(struct filesystem_vol_info) - 2 + len;\n\t\trsp->OutputBufferLength = cpu_to_le32(sz);\n\t\tinc_rfc1001_len(work->response_buf, sz);\n\t\tfs_infoclass_size = FS_VOLUME_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_SIZE_INFORMATION:\n\t{\n\t\tstruct filesystem_info *info;\n\n\t\tinfo = (struct filesystem_info *)(rsp->Buffer);\n\t\tinfo->TotalAllocationUnits = cpu_to_le64(stfs.f_blocks);\n\t\tinfo->FreeAllocationUnits = cpu_to_le64(stfs.f_bfree);\n\t\tinfo->SectorsPerAllocationUnit = cpu_to_le32(1);\n\t\tinfo->BytesPerSector = cpu_to_le32(stfs.f_bsize);\n\t\trsp->OutputBufferLength = cpu_to_le32(24);\n\t\tinc_rfc1001_len(work->response_buf, 24);\n\t\tfs_infoclass_size = FS_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_FULL_SIZE_INFORMATION:\n\t{\n\t\tstruct smb2_fs_full_size_info *info;\n\n\t\tinfo = (struct smb2_fs_full_size_info *)(rsp->Buffer);\n\t\tinfo->TotalAllocationUnits = cpu_to_le64(stfs.f_blocks);\n\t\tinfo->CallerAvailableAllocationUnits =\n\t\t\t\t\tcpu_to_le64(stfs.f_bavail);\n\t\tinfo->ActualAvailableAllocationUnits =\n\t\t\t\t\tcpu_to_le64(stfs.f_bfree);\n\t\tinfo->SectorsPerAllocationUnit = cpu_to_le32(1);\n\t\tinfo->BytesPerSector = cpu_to_le32(stfs.f_bsize);\n\t\trsp->OutputBufferLength = cpu_to_le32(32);\n\t\tinc_rfc1001_len(work->response_buf, 32);\n\t\tfs_infoclass_size = FS_FULL_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_OBJECT_ID_INFORMATION:\n\t{\n\t\tstruct object_id_info *info;\n\n\t\tinfo = (struct object_id_info *)(rsp->Buffer);\n\n\t\tif (!user_guest(sess->user))\n\t\t\tmemcpy(info->objid, user_passkey(sess->user), 16);\n\t\telse\n\t\t\tmemset(info->objid, 0, 16);\n\n\t\tinfo->extended_info.magic = cpu_to_le32(EXTENDED_INFO_MAGIC);\n\t\tinfo->extended_info.version = cpu_to_le32(1);\n\t\tinfo->extended_info.release = cpu_to_le32(1);\n\t\tinfo->extended_info.rel_date = 0;\n\t\tmemcpy(info->extended_info.version_string, \"1.1.0\", strlen(\"1.1.0\"));\n\t\trsp->OutputBufferLength = cpu_to_le32(64);\n\t\tinc_rfc1001_len(work->response_buf, 64);\n\t\tfs_infoclass_size = FS_OBJECT_ID_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_SECTOR_SIZE_INFORMATION:\n\t{\n\t\tstruct smb3_fs_ss_info *info;\n\t\tunsigned int sector_size =\n\t\t\tmin_t(unsigned int, path.mnt->mnt_sb->s_blocksize, 4096);\n\n\t\tinfo = (struct smb3_fs_ss_info *)(rsp->Buffer);\n\n\t\tinfo->LogicalBytesPerSector = cpu_to_le32(sector_size);\n\t\tinfo->PhysicalBytesPerSectorForAtomicity =\n\t\t\t\tcpu_to_le32(sector_size);\n\t\tinfo->PhysicalBytesPerSectorForPerf = cpu_to_le32(sector_size);\n\t\tinfo->FSEffPhysicalBytesPerSectorForAtomicity =\n\t\t\t\tcpu_to_le32(sector_size);\n\t\tinfo->Flags = cpu_to_le32(SSINFO_FLAGS_ALIGNED_DEVICE |\n\t\t\t\t    SSINFO_FLAGS_PARTITION_ALIGNED_ON_DEVICE);\n\t\tinfo->ByteOffsetForSectorAlignment = 0;\n\t\tinfo->ByteOffsetForPartitionAlignment = 0;\n\t\trsp->OutputBufferLength = cpu_to_le32(28);\n\t\tinc_rfc1001_len(work->response_buf, 28);\n\t\tfs_infoclass_size = FS_SECTOR_SIZE_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_CONTROL_INFORMATION:\n\t{\n\t\t/*\n\t\t * TODO : The current implementation is based on\n\t\t * test result with win7(NTFS) server. It's need to\n\t\t * modify this to get valid Quota values\n\t\t * from Linux kernel\n\t\t */\n\t\tstruct smb2_fs_control_info *info;\n\n\t\tinfo = (struct smb2_fs_control_info *)(rsp->Buffer);\n\t\tinfo->FreeSpaceStartFiltering = 0;\n\t\tinfo->FreeSpaceThreshold = 0;\n\t\tinfo->FreeSpaceStopFiltering = 0;\n\t\tinfo->DefaultQuotaThreshold = cpu_to_le64(SMB2_NO_FID);\n\t\tinfo->DefaultQuotaLimit = cpu_to_le64(SMB2_NO_FID);\n\t\tinfo->Padding = 0;\n\t\trsp->OutputBufferLength = cpu_to_le32(48);\n\t\tinc_rfc1001_len(work->response_buf, 48);\n\t\tfs_infoclass_size = FS_CONTROL_INFORMATION_SIZE;\n\t\tbreak;\n\t}\n\tcase FS_POSIX_INFORMATION:\n\t{\n\t\tstruct filesystem_posix_info *info;\n\n\t\tif (!work->tcon->posix_extensions) {\n\t\t\tpr_err(\"client doesn't negotiate with SMB3.1.1 POSIX Extensions\\n\");\n\t\t\trc = -EOPNOTSUPP;\n\t\t} else {\n\t\t\tinfo = (struct filesystem_posix_info *)(rsp->Buffer);\n\t\t\tinfo->OptimalTransferSize = cpu_to_le32(stfs.f_bsize);\n\t\t\tinfo->BlockSize = cpu_to_le32(stfs.f_bsize);\n\t\t\tinfo->TotalBlocks = cpu_to_le64(stfs.f_blocks);\n\t\t\tinfo->BlocksAvail = cpu_to_le64(stfs.f_bfree);\n\t\t\tinfo->UserBlocksAvail = cpu_to_le64(stfs.f_bavail);\n\t\t\tinfo->TotalFileNodes = cpu_to_le64(stfs.f_files);\n\t\t\tinfo->FreeFileNodes = cpu_to_le64(stfs.f_ffree);\n\t\t\trsp->OutputBufferLength = cpu_to_le32(56);\n\t\t\tinc_rfc1001_len(work->response_buf, 56);\n\t\t\tfs_infoclass_size = FS_POSIX_INFORMATION_SIZE;\n\t\t}\n\t\tbreak;\n\t}\n\tdefault:\n\t\tpath_put(&path);\n\t\treturn -EOPNOTSUPP;\n\t}\n\trc = buffer_check_err(le32_to_cpu(req->OutputBufferLength),\n\t\t\t      rsp, work->response_buf,\n\t\t\t      fs_infoclass_size);\n\tpath_put(&path);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,9 @@\n \tstruct path path;\n \tint rc = 0, len;\n \tint fs_infoclass_size = 0;\n+\n+\tif (!share->path)\n+\t\treturn -EIO;\n \n \trc = kern_path(share->path, LOOKUP_NO_SYMLINKS, &path);\n \tif (rc) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!share->path)",
                "\t\treturn -EIO;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_TREE_CONNECT and SMB2_QUERY_INFO commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4016
    },
    {
        "cve_id": "CVE-2019-16231",
        "code_before_change": "static int fjes_probe(struct platform_device *plat_dev)\n{\n\tstruct fjes_adapter *adapter;\n\tstruct net_device *netdev;\n\tstruct resource *res;\n\tstruct fjes_hw *hw;\n\tint err;\n\n\terr = -ENOMEM;\n\tnetdev = alloc_netdev_mq(sizeof(struct fjes_adapter), \"es%d\",\n\t\t\t\t NET_NAME_UNKNOWN, fjes_netdev_setup,\n\t\t\t\t FJES_MAX_QUEUES);\n\n\tif (!netdev)\n\t\tgoto err_out;\n\n\tSET_NETDEV_DEV(netdev, &plat_dev->dev);\n\n\tdev_set_drvdata(&plat_dev->dev, netdev);\n\tadapter = netdev_priv(netdev);\n\tadapter->netdev = netdev;\n\tadapter->plat_dev = plat_dev;\n\thw = &adapter->hw;\n\thw->back = adapter;\n\n\t/* setup the private structure */\n\terr = fjes_sw_init(adapter);\n\tif (err)\n\t\tgoto err_free_netdev;\n\n\tINIT_WORK(&adapter->force_close_task, fjes_force_close_task);\n\tadapter->force_reset = false;\n\tadapter->open_guard = false;\n\n\tadapter->txrx_wq = alloc_workqueue(DRV_NAME \"/txrx\", WQ_MEM_RECLAIM, 0);\n\tadapter->control_wq = alloc_workqueue(DRV_NAME \"/control\",\n\t\t\t\t\t      WQ_MEM_RECLAIM, 0);\n\n\tINIT_WORK(&adapter->tx_stall_task, fjes_tx_stall_task);\n\tINIT_WORK(&adapter->raise_intr_rxdata_task,\n\t\t  fjes_raise_intr_rxdata_task);\n\tINIT_WORK(&adapter->unshare_watch_task, fjes_watch_unshare_task);\n\tadapter->unshare_watch_bitmask = 0;\n\n\tINIT_DELAYED_WORK(&adapter->interrupt_watch_task, fjes_irq_watch_task);\n\tadapter->interrupt_watch_enable = false;\n\n\tres = platform_get_resource(plat_dev, IORESOURCE_MEM, 0);\n\thw->hw_res.start = res->start;\n\thw->hw_res.size = resource_size(res);\n\thw->hw_res.irq = platform_get_irq(plat_dev, 0);\n\terr = fjes_hw_init(&adapter->hw);\n\tif (err)\n\t\tgoto err_free_netdev;\n\n\t/* setup MAC address (02:00:00:00:00:[epid])*/\n\tnetdev->dev_addr[0] = 2;\n\tnetdev->dev_addr[1] = 0;\n\tnetdev->dev_addr[2] = 0;\n\tnetdev->dev_addr[3] = 0;\n\tnetdev->dev_addr[4] = 0;\n\tnetdev->dev_addr[5] = hw->my_epid; /* EPID */\n\n\terr = register_netdev(netdev);\n\tif (err)\n\t\tgoto err_hw_exit;\n\n\tnetif_carrier_off(netdev);\n\n\tfjes_dbg_adapter_init(adapter);\n\n\treturn 0;\n\nerr_hw_exit:\n\tfjes_hw_exit(&adapter->hw);\nerr_free_netdev:\n\tfree_netdev(netdev);\nerr_out:\n\treturn err;\n}",
        "code_after_change": "static int fjes_probe(struct platform_device *plat_dev)\n{\n\tstruct fjes_adapter *adapter;\n\tstruct net_device *netdev;\n\tstruct resource *res;\n\tstruct fjes_hw *hw;\n\tint err;\n\n\terr = -ENOMEM;\n\tnetdev = alloc_netdev_mq(sizeof(struct fjes_adapter), \"es%d\",\n\t\t\t\t NET_NAME_UNKNOWN, fjes_netdev_setup,\n\t\t\t\t FJES_MAX_QUEUES);\n\n\tif (!netdev)\n\t\tgoto err_out;\n\n\tSET_NETDEV_DEV(netdev, &plat_dev->dev);\n\n\tdev_set_drvdata(&plat_dev->dev, netdev);\n\tadapter = netdev_priv(netdev);\n\tadapter->netdev = netdev;\n\tadapter->plat_dev = plat_dev;\n\thw = &adapter->hw;\n\thw->back = adapter;\n\n\t/* setup the private structure */\n\terr = fjes_sw_init(adapter);\n\tif (err)\n\t\tgoto err_free_netdev;\n\n\tINIT_WORK(&adapter->force_close_task, fjes_force_close_task);\n\tadapter->force_reset = false;\n\tadapter->open_guard = false;\n\n\tadapter->txrx_wq = alloc_workqueue(DRV_NAME \"/txrx\", WQ_MEM_RECLAIM, 0);\n\tif (unlikely(!adapter->txrx_wq)) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_netdev;\n\t}\n\n\tadapter->control_wq = alloc_workqueue(DRV_NAME \"/control\",\n\t\t\t\t\t      WQ_MEM_RECLAIM, 0);\n\tif (unlikely(!adapter->control_wq)) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_txrx_wq;\n\t}\n\n\tINIT_WORK(&adapter->tx_stall_task, fjes_tx_stall_task);\n\tINIT_WORK(&adapter->raise_intr_rxdata_task,\n\t\t  fjes_raise_intr_rxdata_task);\n\tINIT_WORK(&adapter->unshare_watch_task, fjes_watch_unshare_task);\n\tadapter->unshare_watch_bitmask = 0;\n\n\tINIT_DELAYED_WORK(&adapter->interrupt_watch_task, fjes_irq_watch_task);\n\tadapter->interrupt_watch_enable = false;\n\n\tres = platform_get_resource(plat_dev, IORESOURCE_MEM, 0);\n\thw->hw_res.start = res->start;\n\thw->hw_res.size = resource_size(res);\n\thw->hw_res.irq = platform_get_irq(plat_dev, 0);\n\terr = fjes_hw_init(&adapter->hw);\n\tif (err)\n\t\tgoto err_free_control_wq;\n\n\t/* setup MAC address (02:00:00:00:00:[epid])*/\n\tnetdev->dev_addr[0] = 2;\n\tnetdev->dev_addr[1] = 0;\n\tnetdev->dev_addr[2] = 0;\n\tnetdev->dev_addr[3] = 0;\n\tnetdev->dev_addr[4] = 0;\n\tnetdev->dev_addr[5] = hw->my_epid; /* EPID */\n\n\terr = register_netdev(netdev);\n\tif (err)\n\t\tgoto err_hw_exit;\n\n\tnetif_carrier_off(netdev);\n\n\tfjes_dbg_adapter_init(adapter);\n\n\treturn 0;\n\nerr_hw_exit:\n\tfjes_hw_exit(&adapter->hw);\nerr_free_control_wq:\n\tdestroy_workqueue(adapter->control_wq);\nerr_free_txrx_wq:\n\tdestroy_workqueue(adapter->txrx_wq);\nerr_free_netdev:\n\tfree_netdev(netdev);\nerr_out:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -33,8 +33,17 @@\n \tadapter->open_guard = false;\n \n \tadapter->txrx_wq = alloc_workqueue(DRV_NAME \"/txrx\", WQ_MEM_RECLAIM, 0);\n+\tif (unlikely(!adapter->txrx_wq)) {\n+\t\terr = -ENOMEM;\n+\t\tgoto err_free_netdev;\n+\t}\n+\n \tadapter->control_wq = alloc_workqueue(DRV_NAME \"/control\",\n \t\t\t\t\t      WQ_MEM_RECLAIM, 0);\n+\tif (unlikely(!adapter->control_wq)) {\n+\t\terr = -ENOMEM;\n+\t\tgoto err_free_txrx_wq;\n+\t}\n \n \tINIT_WORK(&adapter->tx_stall_task, fjes_tx_stall_task);\n \tINIT_WORK(&adapter->raise_intr_rxdata_task,\n@@ -51,7 +60,7 @@\n \thw->hw_res.irq = platform_get_irq(plat_dev, 0);\n \terr = fjes_hw_init(&adapter->hw);\n \tif (err)\n-\t\tgoto err_free_netdev;\n+\t\tgoto err_free_control_wq;\n \n \t/* setup MAC address (02:00:00:00:00:[epid])*/\n \tnetdev->dev_addr[0] = 2;\n@@ -73,6 +82,10 @@\n \n err_hw_exit:\n \tfjes_hw_exit(&adapter->hw);\n+err_free_control_wq:\n+\tdestroy_workqueue(adapter->control_wq);\n+err_free_txrx_wq:\n+\tdestroy_workqueue(adapter->txrx_wq);\n err_free_netdev:\n \tfree_netdev(netdev);\n err_out:",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(!adapter->txrx_wq)) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto err_free_netdev;",
                "\t}",
                "",
                "\tif (unlikely(!adapter->control_wq)) {",
                "\t\terr = -ENOMEM;",
                "\t\tgoto err_free_txrx_wq;",
                "\t}",
                "\t\tgoto err_free_control_wq;",
                "err_free_control_wq:",
                "\tdestroy_workqueue(adapter->control_wq);",
                "err_free_txrx_wq:",
                "\tdestroy_workqueue(adapter->txrx_wq);"
            ],
            "deleted": [
                "\t\tgoto err_free_netdev;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/fjes/fjes_main.c in the Linux kernel 5.2.14 does not check the alloc_workqueue return value, leading to a NULL pointer dereference.",
        "id": 2044
    },
    {
        "cve_id": "CVE-2019-12881",
        "code_before_change": "int\ni915_gem_userptr_ioctl(struct drm_device *dev,\n\t\t       void *data,\n\t\t       struct drm_file *file)\n{\n\tstruct drm_i915_private *dev_priv = to_i915(dev);\n\tstruct drm_i915_gem_userptr *args = data;\n\tstruct drm_i915_gem_object *obj;\n\tint ret;\n\tu32 handle;\n\n\tif (!HAS_LLC(dev_priv) && !HAS_SNOOP(dev_priv)) {\n\t\t/* We cannot support coherent userptr objects on hw without\n\t\t * LLC and broken snooping.\n\t\t */\n\t\treturn -ENODEV;\n\t}\n\n\tif (args->flags & ~(I915_USERPTR_READ_ONLY |\n\t\t\t    I915_USERPTR_UNSYNCHRONIZED))\n\t\treturn -EINVAL;\n\n\tif (offset_in_page(args->user_ptr | args->user_size))\n\t\treturn -EINVAL;\n\n\tif (!access_ok(args->flags & I915_USERPTR_READ_ONLY ? VERIFY_READ : VERIFY_WRITE,\n\t\t       (char __user *)(unsigned long)args->user_ptr, args->user_size))\n\t\treturn -EFAULT;\n\n\tif (args->flags & I915_USERPTR_READ_ONLY) {\n\t\t/* On almost all of the current hw, we cannot tell the GPU that a\n\t\t * page is readonly, so this is just a placeholder in the uAPI.\n\t\t */\n\t\treturn -ENODEV;\n\t}\n\n\tobj = i915_gem_object_alloc(dev_priv);\n\tif (obj == NULL)\n\t\treturn -ENOMEM;\n\n\tdrm_gem_private_object_init(dev, &obj->base, args->user_size);\n\ti915_gem_object_init(obj, &i915_gem_userptr_ops);\n\tobj->read_domains = I915_GEM_DOMAIN_CPU;\n\tobj->write_domain = I915_GEM_DOMAIN_CPU;\n\ti915_gem_object_set_cache_coherency(obj, I915_CACHE_LLC);\n\n\tobj->userptr.ptr = args->user_ptr;\n\tobj->userptr.read_only = !!(args->flags & I915_USERPTR_READ_ONLY);\n\n\t/* And keep a pointer to the current->mm for resolving the user pages\n\t * at binding. This means that we need to hook into the mmu_notifier\n\t * in order to detect if the mmu is destroyed.\n\t */\n\tret = i915_gem_userptr_init__mm_struct(obj);\n\tif (ret == 0)\n\t\tret = i915_gem_userptr_init__mmu_notifier(obj, args->flags);\n\tif (ret == 0)\n\t\tret = drm_gem_handle_create(file, &obj->base, &handle);\n\n\t/* drop reference from allocate - handle holds it now */\n\ti915_gem_object_put(obj);\n\tif (ret)\n\t\treturn ret;\n\n\targs->handle = handle;\n\treturn 0;\n}",
        "code_after_change": "int\ni915_gem_userptr_ioctl(struct drm_device *dev,\n\t\t       void *data,\n\t\t       struct drm_file *file)\n{\n\tstruct drm_i915_private *dev_priv = to_i915(dev);\n\tstruct drm_i915_gem_userptr *args = data;\n\tstruct drm_i915_gem_object *obj;\n\tint ret;\n\tu32 handle;\n\n\tif (!HAS_LLC(dev_priv) && !HAS_SNOOP(dev_priv)) {\n\t\t/* We cannot support coherent userptr objects on hw without\n\t\t * LLC and broken snooping.\n\t\t */\n\t\treturn -ENODEV;\n\t}\n\n\tif (args->flags & ~(I915_USERPTR_READ_ONLY |\n\t\t\t    I915_USERPTR_UNSYNCHRONIZED))\n\t\treturn -EINVAL;\n\n\tif (!args->user_size)\n\t\treturn -EINVAL;\n\n\tif (offset_in_page(args->user_ptr | args->user_size))\n\t\treturn -EINVAL;\n\n\tif (!access_ok(args->flags & I915_USERPTR_READ_ONLY ? VERIFY_READ : VERIFY_WRITE,\n\t\t       (char __user *)(unsigned long)args->user_ptr, args->user_size))\n\t\treturn -EFAULT;\n\n\tif (args->flags & I915_USERPTR_READ_ONLY) {\n\t\t/* On almost all of the current hw, we cannot tell the GPU that a\n\t\t * page is readonly, so this is just a placeholder in the uAPI.\n\t\t */\n\t\treturn -ENODEV;\n\t}\n\n\tobj = i915_gem_object_alloc(dev_priv);\n\tif (obj == NULL)\n\t\treturn -ENOMEM;\n\n\tdrm_gem_private_object_init(dev, &obj->base, args->user_size);\n\ti915_gem_object_init(obj, &i915_gem_userptr_ops);\n\tobj->read_domains = I915_GEM_DOMAIN_CPU;\n\tobj->write_domain = I915_GEM_DOMAIN_CPU;\n\ti915_gem_object_set_cache_coherency(obj, I915_CACHE_LLC);\n\n\tobj->userptr.ptr = args->user_ptr;\n\tobj->userptr.read_only = !!(args->flags & I915_USERPTR_READ_ONLY);\n\n\t/* And keep a pointer to the current->mm for resolving the user pages\n\t * at binding. This means that we need to hook into the mmu_notifier\n\t * in order to detect if the mmu is destroyed.\n\t */\n\tret = i915_gem_userptr_init__mm_struct(obj);\n\tif (ret == 0)\n\t\tret = i915_gem_userptr_init__mmu_notifier(obj, args->flags);\n\tif (ret == 0)\n\t\tret = drm_gem_handle_create(file, &obj->base, &handle);\n\n\t/* drop reference from allocate - handle holds it now */\n\ti915_gem_object_put(obj);\n\tif (ret)\n\t\treturn ret;\n\n\targs->handle = handle;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,6 +18,9 @@\n \n \tif (args->flags & ~(I915_USERPTR_READ_ONLY |\n \t\t\t    I915_USERPTR_UNSYNCHRONIZED))\n+\t\treturn -EINVAL;\n+\n+\tif (!args->user_size)\n \t\treturn -EINVAL;\n \n \tif (offset_in_page(args->user_ptr | args->user_size))",
        "function_modified_lines": {
            "added": [
                "\t\treturn -EINVAL;",
                "",
                "\tif (!args->user_size)"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "i915_gem_userptr_get_pages in drivers/gpu/drm/i915/i915_gem_userptr.c in the Linux kernel 4.15.0 on Ubuntu 18.04.2 allows local users to cause a denial of service (NULL pointer dereference and BUG) or possibly have unspecified other impact via crafted ioctl calls to /dev/dri/card0.",
        "id": 1955
    },
    {
        "cve_id": "CVE-2019-12614",
        "code_before_change": "static struct property *dlpar_parse_cc_property(struct cc_workarea *ccwa)\n{\n\tstruct property *prop;\n\tchar *name;\n\tchar *value;\n\n\tprop = kzalloc(sizeof(*prop), GFP_KERNEL);\n\tif (!prop)\n\t\treturn NULL;\n\n\tname = (char *)ccwa + be32_to_cpu(ccwa->name_offset);\n\tprop->name = kstrdup(name, GFP_KERNEL);\n\n\tprop->length = be32_to_cpu(ccwa->prop_length);\n\tvalue = (char *)ccwa + be32_to_cpu(ccwa->prop_offset);\n\tprop->value = kmemdup(value, prop->length, GFP_KERNEL);\n\tif (!prop->value) {\n\t\tdlpar_free_cc_property(prop);\n\t\treturn NULL;\n\t}\n\n\treturn prop;\n}",
        "code_after_change": "static struct property *dlpar_parse_cc_property(struct cc_workarea *ccwa)\n{\n\tstruct property *prop;\n\tchar *name;\n\tchar *value;\n\n\tprop = kzalloc(sizeof(*prop), GFP_KERNEL);\n\tif (!prop)\n\t\treturn NULL;\n\n\tname = (char *)ccwa + be32_to_cpu(ccwa->name_offset);\n\tprop->name = kstrdup(name, GFP_KERNEL);\n\tif (!prop->name) {\n\t\tdlpar_free_cc_property(prop);\n\t\treturn NULL;\n\t}\n\n\tprop->length = be32_to_cpu(ccwa->prop_length);\n\tvalue = (char *)ccwa + be32_to_cpu(ccwa->prop_offset);\n\tprop->value = kmemdup(value, prop->length, GFP_KERNEL);\n\tif (!prop->value) {\n\t\tdlpar_free_cc_property(prop);\n\t\treturn NULL;\n\t}\n\n\treturn prop;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,6 +10,10 @@\n \n \tname = (char *)ccwa + be32_to_cpu(ccwa->name_offset);\n \tprop->name = kstrdup(name, GFP_KERNEL);\n+\tif (!prop->name) {\n+\t\tdlpar_free_cc_property(prop);\n+\t\treturn NULL;\n+\t}\n \n \tprop->length = be32_to_cpu(ccwa->prop_length);\n \tvalue = (char *)ccwa + be32_to_cpu(ccwa->prop_offset);",
        "function_modified_lines": {
            "added": [
                "\tif (!prop->name) {",
                "\t\tdlpar_free_cc_property(prop);",
                "\t\treturn NULL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in dlpar_parse_cc_property in arch/powerpc/platforms/pseries/dlpar.c in the Linux kernel through 5.1.6. There is an unchecked kstrdup of prop->name, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash).",
        "id": 1948
    },
    {
        "cve_id": "CVE-2019-15217",
        "code_before_change": "static int zr364xx_vidioc_querycap(struct file *file, void *priv,\n\t\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct zr364xx_camera *cam = video_drvdata(file);\n\n\tstrscpy(cap->driver, DRIVER_DESC, sizeof(cap->driver));\n\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));\n\tstrscpy(cap->bus_info, dev_name(&cam->udev->dev),\n\t\tsizeof(cap->bus_info));\n\tcap->device_caps = V4L2_CAP_VIDEO_CAPTURE |\n\t\t\t    V4L2_CAP_READWRITE |\n\t\t\t    V4L2_CAP_STREAMING;\n\tcap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;\n\n\treturn 0;\n}",
        "code_after_change": "static int zr364xx_vidioc_querycap(struct file *file, void *priv,\n\t\t\t\t   struct v4l2_capability *cap)\n{\n\tstruct zr364xx_camera *cam = video_drvdata(file);\n\n\tstrscpy(cap->driver, DRIVER_DESC, sizeof(cap->driver));\n\tif (cam->udev->product)\n\t\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));\n\tstrscpy(cap->bus_info, dev_name(&cam->udev->dev),\n\t\tsizeof(cap->bus_info));\n\tcap->device_caps = V4L2_CAP_VIDEO_CAPTURE |\n\t\t\t    V4L2_CAP_READWRITE |\n\t\t\t    V4L2_CAP_STREAMING;\n\tcap->capabilities = cap->device_caps | V4L2_CAP_DEVICE_CAPS;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,8 @@\n \tstruct zr364xx_camera *cam = video_drvdata(file);\n \n \tstrscpy(cap->driver, DRIVER_DESC, sizeof(cap->driver));\n-\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));\n+\tif (cam->udev->product)\n+\t\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));\n \tstrscpy(cap->bus_info, dev_name(&cam->udev->dev),\n \t\tsizeof(cap->bus_info));\n \tcap->device_caps = V4L2_CAP_VIDEO_CAPTURE |",
        "function_modified_lines": {
            "added": [
                "\tif (cam->udev->product)",
                "\t\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));"
            ],
            "deleted": [
                "\tstrscpy(cap->card, cam->udev->product, sizeof(cap->card));"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. There is a NULL pointer dereference caused by a malicious USB device in the drivers/media/usb/zr364xx/zr364xx.c driver.",
        "id": 1999
    },
    {
        "cve_id": "CVE-2017-16914",
        "code_before_change": "static int stub_send_ret_submit(struct stub_device *sdev)\n{\n\tunsigned long flags;\n\tstruct stub_priv *priv, *tmp;\n\n\tstruct msghdr msg;\n\tsize_t txsize;\n\n\tsize_t total_size = 0;\n\n\twhile ((priv = dequeue_from_priv_tx(sdev)) != NULL) {\n\t\tint ret;\n\t\tstruct urb *urb = priv->urb;\n\t\tstruct usbip_header pdu_header;\n\t\tstruct usbip_iso_packet_descriptor *iso_buffer = NULL;\n\t\tstruct kvec *iov = NULL;\n\t\tint iovnum = 0;\n\n\t\ttxsize = 0;\n\t\tmemset(&pdu_header, 0, sizeof(pdu_header));\n\t\tmemset(&msg, 0, sizeof(msg));\n\n\t\tif (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS)\n\t\t\tiovnum = 2 + urb->number_of_packets;\n\t\telse\n\t\t\tiovnum = 2;\n\n\t\tiov = kcalloc(iovnum, sizeof(struct kvec), GFP_KERNEL);\n\n\t\tif (!iov) {\n\t\t\tusbip_event_add(&sdev->ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn -1;\n\t\t}\n\n\t\tiovnum = 0;\n\n\t\t/* 1. setup usbip_header */\n\t\tsetup_ret_submit_pdu(&pdu_header, urb);\n\t\tusbip_dbg_stub_tx(\"setup txdata seqnum: %d urb: %p\\n\",\n\t\t\t\t  pdu_header.base.seqnum, urb);\n\t\tusbip_header_correct_endian(&pdu_header, 1);\n\n\t\tiov[iovnum].iov_base = &pdu_header;\n\t\tiov[iovnum].iov_len  = sizeof(pdu_header);\n\t\tiovnum++;\n\t\ttxsize += sizeof(pdu_header);\n\n\t\t/* 2. setup transfer buffer */\n\t\tif (usb_pipein(urb->pipe) &&\n\t\t    usb_pipetype(urb->pipe) != PIPE_ISOCHRONOUS &&\n\t\t    urb->actual_length > 0) {\n\t\t\tiov[iovnum].iov_base = urb->transfer_buffer;\n\t\t\tiov[iovnum].iov_len  = urb->actual_length;\n\t\t\tiovnum++;\n\t\t\ttxsize += urb->actual_length;\n\t\t} else if (usb_pipein(urb->pipe) &&\n\t\t\t   usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {\n\t\t\t/*\n\t\t\t * For isochronous packets: actual length is the sum of\n\t\t\t * the actual length of the individual, packets, but as\n\t\t\t * the packet offsets are not changed there will be\n\t\t\t * padding between the packets. To optimally use the\n\t\t\t * bandwidth the padding is not transmitted.\n\t\t\t */\n\n\t\t\tint i;\n\n\t\t\tfor (i = 0; i < urb->number_of_packets; i++) {\n\t\t\t\tiov[iovnum].iov_base = urb->transfer_buffer +\n\t\t\t\t\turb->iso_frame_desc[i].offset;\n\t\t\t\tiov[iovnum].iov_len =\n\t\t\t\t\turb->iso_frame_desc[i].actual_length;\n\t\t\t\tiovnum++;\n\t\t\t\ttxsize += urb->iso_frame_desc[i].actual_length;\n\t\t\t}\n\n\t\t\tif (txsize != sizeof(pdu_header) + urb->actual_length) {\n\t\t\t\tdev_err(&sdev->udev->dev,\n\t\t\t\t\t\"actual length of urb %d does not match iso packet sizes %zu\\n\",\n\t\t\t\t\turb->actual_length,\n\t\t\t\t\ttxsize-sizeof(pdu_header));\n\t\t\t\tkfree(iov);\n\t\t\t\tusbip_event_add(&sdev->ud,\n\t\t\t\t\t\tSDEV_EVENT_ERROR_TCP);\n\t\t\t   return -1;\n\t\t\t}\n\t\t}\n\n\t\t/* 3. setup iso_packet_descriptor */\n\t\tif (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {\n\t\t\tssize_t len = 0;\n\n\t\t\tiso_buffer = usbip_alloc_iso_desc_pdu(urb, &len);\n\t\t\tif (!iso_buffer) {\n\t\t\t\tusbip_event_add(&sdev->ud,\n\t\t\t\t\t\tSDEV_EVENT_ERROR_MALLOC);\n\t\t\t\tkfree(iov);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tiov[iovnum].iov_base = iso_buffer;\n\t\t\tiov[iovnum].iov_len  = len;\n\t\t\ttxsize += len;\n\t\t\tiovnum++;\n\t\t}\n\n\t\tret = kernel_sendmsg(sdev->ud.tcp_socket, &msg,\n\t\t\t\t\t\tiov,  iovnum, txsize);\n\t\tif (ret != txsize) {\n\t\t\tdev_err(&sdev->udev->dev,\n\t\t\t\t\"sendmsg failed!, retval %d for %zd\\n\",\n\t\t\t\tret, txsize);\n\t\t\tkfree(iov);\n\t\t\tkfree(iso_buffer);\n\t\t\tusbip_event_add(&sdev->ud, SDEV_EVENT_ERROR_TCP);\n\t\t\treturn -1;\n\t\t}\n\n\t\tkfree(iov);\n\t\tkfree(iso_buffer);\n\n\t\ttotal_size += txsize;\n\t}\n\n\tspin_lock_irqsave(&sdev->priv_lock, flags);\n\tlist_for_each_entry_safe(priv, tmp, &sdev->priv_free, list) {\n\t\tstub_free_priv_and_urb(priv);\n\t}\n\tspin_unlock_irqrestore(&sdev->priv_lock, flags);\n\n\treturn total_size;\n}",
        "code_after_change": "static int stub_send_ret_submit(struct stub_device *sdev)\n{\n\tunsigned long flags;\n\tstruct stub_priv *priv, *tmp;\n\n\tstruct msghdr msg;\n\tsize_t txsize;\n\n\tsize_t total_size = 0;\n\n\twhile ((priv = dequeue_from_priv_tx(sdev)) != NULL) {\n\t\tint ret;\n\t\tstruct urb *urb = priv->urb;\n\t\tstruct usbip_header pdu_header;\n\t\tstruct usbip_iso_packet_descriptor *iso_buffer = NULL;\n\t\tstruct kvec *iov = NULL;\n\t\tint iovnum = 0;\n\n\t\ttxsize = 0;\n\t\tmemset(&pdu_header, 0, sizeof(pdu_header));\n\t\tmemset(&msg, 0, sizeof(msg));\n\n\t\tif (urb->actual_length > 0 && !urb->transfer_buffer) {\n\t\t\tdev_err(&sdev->udev->dev,\n\t\t\t\t\"urb: actual_length %d transfer_buffer null\\n\",\n\t\t\t\turb->actual_length);\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS)\n\t\t\tiovnum = 2 + urb->number_of_packets;\n\t\telse\n\t\t\tiovnum = 2;\n\n\t\tiov = kcalloc(iovnum, sizeof(struct kvec), GFP_KERNEL);\n\n\t\tif (!iov) {\n\t\t\tusbip_event_add(&sdev->ud, SDEV_EVENT_ERROR_MALLOC);\n\t\t\treturn -1;\n\t\t}\n\n\t\tiovnum = 0;\n\n\t\t/* 1. setup usbip_header */\n\t\tsetup_ret_submit_pdu(&pdu_header, urb);\n\t\tusbip_dbg_stub_tx(\"setup txdata seqnum: %d urb: %p\\n\",\n\t\t\t\t  pdu_header.base.seqnum, urb);\n\t\tusbip_header_correct_endian(&pdu_header, 1);\n\n\t\tiov[iovnum].iov_base = &pdu_header;\n\t\tiov[iovnum].iov_len  = sizeof(pdu_header);\n\t\tiovnum++;\n\t\ttxsize += sizeof(pdu_header);\n\n\t\t/* 2. setup transfer buffer */\n\t\tif (usb_pipein(urb->pipe) &&\n\t\t    usb_pipetype(urb->pipe) != PIPE_ISOCHRONOUS &&\n\t\t    urb->actual_length > 0) {\n\t\t\tiov[iovnum].iov_base = urb->transfer_buffer;\n\t\t\tiov[iovnum].iov_len  = urb->actual_length;\n\t\t\tiovnum++;\n\t\t\ttxsize += urb->actual_length;\n\t\t} else if (usb_pipein(urb->pipe) &&\n\t\t\t   usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {\n\t\t\t/*\n\t\t\t * For isochronous packets: actual length is the sum of\n\t\t\t * the actual length of the individual, packets, but as\n\t\t\t * the packet offsets are not changed there will be\n\t\t\t * padding between the packets. To optimally use the\n\t\t\t * bandwidth the padding is not transmitted.\n\t\t\t */\n\n\t\t\tint i;\n\n\t\t\tfor (i = 0; i < urb->number_of_packets; i++) {\n\t\t\t\tiov[iovnum].iov_base = urb->transfer_buffer +\n\t\t\t\t\turb->iso_frame_desc[i].offset;\n\t\t\t\tiov[iovnum].iov_len =\n\t\t\t\t\turb->iso_frame_desc[i].actual_length;\n\t\t\t\tiovnum++;\n\t\t\t\ttxsize += urb->iso_frame_desc[i].actual_length;\n\t\t\t}\n\n\t\t\tif (txsize != sizeof(pdu_header) + urb->actual_length) {\n\t\t\t\tdev_err(&sdev->udev->dev,\n\t\t\t\t\t\"actual length of urb %d does not match iso packet sizes %zu\\n\",\n\t\t\t\t\turb->actual_length,\n\t\t\t\t\ttxsize-sizeof(pdu_header));\n\t\t\t\tkfree(iov);\n\t\t\t\tusbip_event_add(&sdev->ud,\n\t\t\t\t\t\tSDEV_EVENT_ERROR_TCP);\n\t\t\t   return -1;\n\t\t\t}\n\t\t}\n\n\t\t/* 3. setup iso_packet_descriptor */\n\t\tif (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {\n\t\t\tssize_t len = 0;\n\n\t\t\tiso_buffer = usbip_alloc_iso_desc_pdu(urb, &len);\n\t\t\tif (!iso_buffer) {\n\t\t\t\tusbip_event_add(&sdev->ud,\n\t\t\t\t\t\tSDEV_EVENT_ERROR_MALLOC);\n\t\t\t\tkfree(iov);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tiov[iovnum].iov_base = iso_buffer;\n\t\t\tiov[iovnum].iov_len  = len;\n\t\t\ttxsize += len;\n\t\t\tiovnum++;\n\t\t}\n\n\t\tret = kernel_sendmsg(sdev->ud.tcp_socket, &msg,\n\t\t\t\t\t\tiov,  iovnum, txsize);\n\t\tif (ret != txsize) {\n\t\t\tdev_err(&sdev->udev->dev,\n\t\t\t\t\"sendmsg failed!, retval %d for %zd\\n\",\n\t\t\t\tret, txsize);\n\t\t\tkfree(iov);\n\t\t\tkfree(iso_buffer);\n\t\t\tusbip_event_add(&sdev->ud, SDEV_EVENT_ERROR_TCP);\n\t\t\treturn -1;\n\t\t}\n\n\t\tkfree(iov);\n\t\tkfree(iso_buffer);\n\n\t\ttotal_size += txsize;\n\t}\n\n\tspin_lock_irqsave(&sdev->priv_lock, flags);\n\tlist_for_each_entry_safe(priv, tmp, &sdev->priv_free, list) {\n\t\tstub_free_priv_and_urb(priv);\n\t}\n\tspin_unlock_irqrestore(&sdev->priv_lock, flags);\n\n\treturn total_size;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,6 +19,13 @@\n \t\ttxsize = 0;\n \t\tmemset(&pdu_header, 0, sizeof(pdu_header));\n \t\tmemset(&msg, 0, sizeof(msg));\n+\n+\t\tif (urb->actual_length > 0 && !urb->transfer_buffer) {\n+\t\t\tdev_err(&sdev->udev->dev,\n+\t\t\t\t\"urb: actual_length %d transfer_buffer null\\n\",\n+\t\t\t\turb->actual_length);\n+\t\t\treturn -1;\n+\t\t}\n \n \t\tif (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS)\n \t\t\tiovnum = 2 + urb->number_of_packets;",
        "function_modified_lines": {
            "added": [
                "",
                "\t\tif (urb->actual_length > 0 && !urb->transfer_buffer) {",
                "\t\t\tdev_err(&sdev->udev->dev,",
                "\t\t\t\t\"urb: actual_length %d transfer_buffer null\\n\",",
                "\t\t\t\turb->actual_length);",
                "\t\t\treturn -1;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The \"stub_send_ret_submit()\" function (drivers/usb/usbip/stub_tx.c) in the Linux Kernel before version 4.14.8, 4.9.71, 4.1.49, and 4.4.107 allows attackers to cause a denial of service (NULL pointer dereference) via a specially crafted USB over IP packet.",
        "id": 1351
    },
    {
        "cve_id": "CVE-2020-12364",
        "code_before_change": "int intel_uc_fw_fetch(struct intel_uc_fw *uc_fw)\n{\n\tstruct drm_i915_private *i915 = __uc_fw_to_gt(uc_fw)->i915;\n\tstruct device *dev = i915->drm.dev;\n\tstruct drm_i915_gem_object *obj;\n\tconst struct firmware *fw = NULL;\n\tstruct uc_css_header *css;\n\tsize_t size;\n\tint err;\n\n\tGEM_BUG_ON(!i915->wopcm.size);\n\tGEM_BUG_ON(!intel_uc_fw_is_enabled(uc_fw));\n\n\terr = i915_inject_probe_error(i915, -ENXIO);\n\tif (err)\n\t\tgoto fail;\n\n\t__force_fw_fetch_failures(uc_fw, -EINVAL);\n\t__force_fw_fetch_failures(uc_fw, -ESTALE);\n\n\terr = request_firmware(&fw, uc_fw->path, dev);\n\tif (err)\n\t\tgoto fail;\n\n\t/* Check the size of the blob before examining buffer contents */\n\tif (unlikely(fw->size < sizeof(struct uc_css_header))) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu < %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, sizeof(struct uc_css_header));\n\t\terr = -ENODATA;\n\t\tgoto fail;\n\t}\n\n\tcss = (struct uc_css_header *)fw->data;\n\n\t/* Check integrity of size values inside CSS header */\n\tsize = (css->header_size_dw - css->key_size_dw - css->modulus_size_dw -\n\t\tcss->exponent_size_dw) * sizeof(u32);\n\tif (unlikely(size != sizeof(struct uc_css_header))) {\n\t\tdrm_warn(&i915->drm,\n\t\t\t \"%s firmware %s: unexpected header size: %zu != %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, sizeof(struct uc_css_header));\n\t\terr = -EPROTO;\n\t\tgoto fail;\n\t}\n\n\t/* uCode size must calculated from other sizes */\n\tuc_fw->ucode_size = (css->size_dw - css->header_size_dw) * sizeof(u32);\n\n\t/* now RSA */\n\tif (unlikely(css->key_size_dw != UOS_RSA_SCRATCH_COUNT)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: unexpected key size: %u != %u\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t css->key_size_dw, UOS_RSA_SCRATCH_COUNT);\n\t\terr = -EPROTO;\n\t\tgoto fail;\n\t}\n\tuc_fw->rsa_size = css->key_size_dw * sizeof(u32);\n\n\t/* At least, it should have header, uCode and RSA. Size of all three. */\n\tsize = sizeof(struct uc_css_header) + uc_fw->ucode_size + uc_fw->rsa_size;\n\tif (unlikely(fw->size < size)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu < %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, size);\n\t\terr = -ENOEXEC;\n\t\tgoto fail;\n\t}\n\n\t/* Sanity check whether this fw is not larger than whole WOPCM memory */\n\tsize = __intel_uc_fw_get_upload_size(uc_fw);\n\tif (unlikely(size >= i915->wopcm.size)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu > %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t size, (size_t)i915->wopcm.size);\n\t\terr = -E2BIG;\n\t\tgoto fail;\n\t}\n\n\t/* Get version numbers from the CSS header */\n\tuc_fw->major_ver_found = FIELD_GET(CSS_SW_VERSION_UC_MAJOR,\n\t\t\t\t\t   css->sw_version);\n\tuc_fw->minor_ver_found = FIELD_GET(CSS_SW_VERSION_UC_MINOR,\n\t\t\t\t\t   css->sw_version);\n\n\tif (uc_fw->major_ver_found != uc_fw->major_ver_wanted ||\n\t    uc_fw->minor_ver_found < uc_fw->minor_ver_wanted) {\n\t\tdrm_notice(&i915->drm, \"%s firmware %s: unexpected version: %u.%u != %u.%u\\n\",\n\t\t\t   intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t   uc_fw->major_ver_found, uc_fw->minor_ver_found,\n\t\t\t   uc_fw->major_ver_wanted, uc_fw->minor_ver_wanted);\n\t\tif (!intel_uc_fw_is_overridden(uc_fw)) {\n\t\t\terr = -ENOEXEC;\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tobj = i915_gem_object_create_shmem_from_data(i915, fw->data, fw->size);\n\tif (IS_ERR(obj)) {\n\t\terr = PTR_ERR(obj);\n\t\tgoto fail;\n\t}\n\n\tuc_fw->obj = obj;\n\tuc_fw->size = fw->size;\n\tintel_uc_fw_change_status(uc_fw, INTEL_UC_FIRMWARE_AVAILABLE);\n\n\trelease_firmware(fw);\n\treturn 0;\n\nfail:\n\tintel_uc_fw_change_status(uc_fw, err == -ENOENT ?\n\t\t\t\t  INTEL_UC_FIRMWARE_MISSING :\n\t\t\t\t  INTEL_UC_FIRMWARE_ERROR);\n\n\tdrm_notice(&i915->drm, \"%s firmware %s: fetch failed with error %d\\n\",\n\t\t   intel_uc_fw_type_repr(uc_fw->type), uc_fw->path, err);\n\tdrm_info(&i915->drm, \"%s firmware(s) can be downloaded from %s\\n\",\n\t\t intel_uc_fw_type_repr(uc_fw->type), INTEL_UC_FIRMWARE_URL);\n\n\trelease_firmware(fw);\t\t/* OK even if fw is NULL */\n\treturn err;\n}",
        "code_after_change": "int intel_uc_fw_fetch(struct intel_uc_fw *uc_fw)\n{\n\tstruct drm_i915_private *i915 = __uc_fw_to_gt(uc_fw)->i915;\n\tstruct device *dev = i915->drm.dev;\n\tstruct drm_i915_gem_object *obj;\n\tconst struct firmware *fw = NULL;\n\tstruct uc_css_header *css;\n\tsize_t size;\n\tint err;\n\n\tGEM_BUG_ON(!i915->wopcm.size);\n\tGEM_BUG_ON(!intel_uc_fw_is_enabled(uc_fw));\n\n\terr = i915_inject_probe_error(i915, -ENXIO);\n\tif (err)\n\t\tgoto fail;\n\n\t__force_fw_fetch_failures(uc_fw, -EINVAL);\n\t__force_fw_fetch_failures(uc_fw, -ESTALE);\n\n\terr = request_firmware(&fw, uc_fw->path, dev);\n\tif (err)\n\t\tgoto fail;\n\n\t/* Check the size of the blob before examining buffer contents */\n\tif (unlikely(fw->size < sizeof(struct uc_css_header))) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu < %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, sizeof(struct uc_css_header));\n\t\terr = -ENODATA;\n\t\tgoto fail;\n\t}\n\n\tcss = (struct uc_css_header *)fw->data;\n\n\t/* Check integrity of size values inside CSS header */\n\tsize = (css->header_size_dw - css->key_size_dw - css->modulus_size_dw -\n\t\tcss->exponent_size_dw) * sizeof(u32);\n\tif (unlikely(size != sizeof(struct uc_css_header))) {\n\t\tdrm_warn(&i915->drm,\n\t\t\t \"%s firmware %s: unexpected header size: %zu != %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, sizeof(struct uc_css_header));\n\t\terr = -EPROTO;\n\t\tgoto fail;\n\t}\n\n\t/* uCode size must calculated from other sizes */\n\tuc_fw->ucode_size = (css->size_dw - css->header_size_dw) * sizeof(u32);\n\n\t/* now RSA */\n\tif (unlikely(css->key_size_dw != UOS_RSA_SCRATCH_COUNT)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: unexpected key size: %u != %u\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t css->key_size_dw, UOS_RSA_SCRATCH_COUNT);\n\t\terr = -EPROTO;\n\t\tgoto fail;\n\t}\n\tuc_fw->rsa_size = css->key_size_dw * sizeof(u32);\n\n\t/* At least, it should have header, uCode and RSA. Size of all three. */\n\tsize = sizeof(struct uc_css_header) + uc_fw->ucode_size + uc_fw->rsa_size;\n\tif (unlikely(fw->size < size)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu < %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t fw->size, size);\n\t\terr = -ENOEXEC;\n\t\tgoto fail;\n\t}\n\n\t/* Sanity check whether this fw is not larger than whole WOPCM memory */\n\tsize = __intel_uc_fw_get_upload_size(uc_fw);\n\tif (unlikely(size >= i915->wopcm.size)) {\n\t\tdrm_warn(&i915->drm, \"%s firmware %s: invalid size: %zu > %zu\\n\",\n\t\t\t intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t size, (size_t)i915->wopcm.size);\n\t\terr = -E2BIG;\n\t\tgoto fail;\n\t}\n\n\t/* Get version numbers from the CSS header */\n\tuc_fw->major_ver_found = FIELD_GET(CSS_SW_VERSION_UC_MAJOR,\n\t\t\t\t\t   css->sw_version);\n\tuc_fw->minor_ver_found = FIELD_GET(CSS_SW_VERSION_UC_MINOR,\n\t\t\t\t\t   css->sw_version);\n\n\tif (uc_fw->major_ver_found != uc_fw->major_ver_wanted ||\n\t    uc_fw->minor_ver_found < uc_fw->minor_ver_wanted) {\n\t\tdrm_notice(&i915->drm, \"%s firmware %s: unexpected version: %u.%u != %u.%u\\n\",\n\t\t\t   intel_uc_fw_type_repr(uc_fw->type), uc_fw->path,\n\t\t\t   uc_fw->major_ver_found, uc_fw->minor_ver_found,\n\t\t\t   uc_fw->major_ver_wanted, uc_fw->minor_ver_wanted);\n\t\tif (!intel_uc_fw_is_overridden(uc_fw)) {\n\t\t\terr = -ENOEXEC;\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (uc_fw->type == INTEL_UC_FW_TYPE_GUC)\n\t\tuc_fw->private_data_size = css->private_data_size;\n\n\tobj = i915_gem_object_create_shmem_from_data(i915, fw->data, fw->size);\n\tif (IS_ERR(obj)) {\n\t\terr = PTR_ERR(obj);\n\t\tgoto fail;\n\t}\n\n\tuc_fw->obj = obj;\n\tuc_fw->size = fw->size;\n\tintel_uc_fw_change_status(uc_fw, INTEL_UC_FIRMWARE_AVAILABLE);\n\n\trelease_firmware(fw);\n\treturn 0;\n\nfail:\n\tintel_uc_fw_change_status(uc_fw, err == -ENOENT ?\n\t\t\t\t  INTEL_UC_FIRMWARE_MISSING :\n\t\t\t\t  INTEL_UC_FIRMWARE_ERROR);\n\n\tdrm_notice(&i915->drm, \"%s firmware %s: fetch failed with error %d\\n\",\n\t\t   intel_uc_fw_type_repr(uc_fw->type), uc_fw->path, err);\n\tdrm_info(&i915->drm, \"%s firmware(s) can be downloaded from %s\\n\",\n\t\t intel_uc_fw_type_repr(uc_fw->type), INTEL_UC_FIRMWARE_URL);\n\n\trelease_firmware(fw);\t\t/* OK even if fw is NULL */\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -96,6 +96,9 @@\n \t\t}\n \t}\n \n+\tif (uc_fw->type == INTEL_UC_FW_TYPE_GUC)\n+\t\tuc_fw->private_data_size = css->private_data_size;\n+\n \tobj = i915_gem_object_create_shmem_from_data(i915, fw->data, fw->size);\n \tif (IS_ERR(obj)) {\n \t\terr = PTR_ERR(obj);",
        "function_modified_lines": {
            "added": [
                "\tif (uc_fw->type == INTEL_UC_FW_TYPE_GUC)",
                "\t\tuc_fw->private_data_size = css->private_data_size;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Null pointer reference in some Intel(R) Graphics Drivers for Windows* before version 26.20.100.7212 and before version Linux kernel version 5.5 may allow a privileged user to potentially enable a denial of service via local access.",
        "id": 2469
    },
    {
        "cve_id": "CVE-2021-3659",
        "code_before_change": "static struct mac802154_llsec_key*\nllsec_key_alloc(const struct ieee802154_llsec_key *template)\n{\n\tconst int authsizes[3] = { 4, 8, 16 };\n\tstruct mac802154_llsec_key *key;\n\tint i;\n\n\tkey = kzalloc(sizeof(*key), GFP_KERNEL);\n\tif (!key)\n\t\treturn NULL;\n\n\tkref_init(&key->ref);\n\tkey->key = *template;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(authsizes) != ARRAY_SIZE(key->tfm));\n\n\tfor (i = 0; i < ARRAY_SIZE(key->tfm); i++) {\n\t\tkey->tfm[i] = crypto_alloc_aead(\"ccm(aes)\", 0,\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC);\n\t\tif (IS_ERR(key->tfm[i]))\n\t\t\tgoto err_tfm;\n\t\tif (crypto_aead_setkey(key->tfm[i], template->key,\n\t\t\t\t       IEEE802154_LLSEC_KEY_SIZE))\n\t\t\tgoto err_tfm;\n\t\tif (crypto_aead_setauthsize(key->tfm[i], authsizes[i]))\n\t\t\tgoto err_tfm;\n\t}\n\n\tkey->tfm0 = crypto_alloc_sync_skcipher(\"ctr(aes)\", 0, 0);\n\tif (IS_ERR(key->tfm0))\n\t\tgoto err_tfm;\n\n\tif (crypto_sync_skcipher_setkey(key->tfm0, template->key,\n\t\t\t\t   IEEE802154_LLSEC_KEY_SIZE))\n\t\tgoto err_tfm0;\n\n\treturn key;\n\nerr_tfm0:\n\tcrypto_free_sync_skcipher(key->tfm0);\nerr_tfm:\n\tfor (i = 0; i < ARRAY_SIZE(key->tfm); i++)\n\t\tif (key->tfm[i])\n\t\t\tcrypto_free_aead(key->tfm[i]);\n\n\tkfree_sensitive(key);\n\treturn NULL;\n}",
        "code_after_change": "static struct mac802154_llsec_key*\nllsec_key_alloc(const struct ieee802154_llsec_key *template)\n{\n\tconst int authsizes[3] = { 4, 8, 16 };\n\tstruct mac802154_llsec_key *key;\n\tint i;\n\n\tkey = kzalloc(sizeof(*key), GFP_KERNEL);\n\tif (!key)\n\t\treturn NULL;\n\n\tkref_init(&key->ref);\n\tkey->key = *template;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(authsizes) != ARRAY_SIZE(key->tfm));\n\n\tfor (i = 0; i < ARRAY_SIZE(key->tfm); i++) {\n\t\tkey->tfm[i] = crypto_alloc_aead(\"ccm(aes)\", 0,\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC);\n\t\tif (IS_ERR(key->tfm[i]))\n\t\t\tgoto err_tfm;\n\t\tif (crypto_aead_setkey(key->tfm[i], template->key,\n\t\t\t\t       IEEE802154_LLSEC_KEY_SIZE))\n\t\t\tgoto err_tfm;\n\t\tif (crypto_aead_setauthsize(key->tfm[i], authsizes[i]))\n\t\t\tgoto err_tfm;\n\t}\n\n\tkey->tfm0 = crypto_alloc_sync_skcipher(\"ctr(aes)\", 0, 0);\n\tif (IS_ERR(key->tfm0))\n\t\tgoto err_tfm;\n\n\tif (crypto_sync_skcipher_setkey(key->tfm0, template->key,\n\t\t\t\t   IEEE802154_LLSEC_KEY_SIZE))\n\t\tgoto err_tfm0;\n\n\treturn key;\n\nerr_tfm0:\n\tcrypto_free_sync_skcipher(key->tfm0);\nerr_tfm:\n\tfor (i = 0; i < ARRAY_SIZE(key->tfm); i++)\n\t\tif (!IS_ERR_OR_NULL(key->tfm[i]))\n\t\t\tcrypto_free_aead(key->tfm[i]);\n\n\tkfree_sensitive(key);\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -40,7 +40,7 @@\n \tcrypto_free_sync_skcipher(key->tfm0);\n err_tfm:\n \tfor (i = 0; i < ARRAY_SIZE(key->tfm); i++)\n-\t\tif (key->tfm[i])\n+\t\tif (!IS_ERR_OR_NULL(key->tfm[i]))\n \t\t\tcrypto_free_aead(key->tfm[i]);\n \n \tkfree_sensitive(key);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!IS_ERR_OR_NULL(key->tfm[i]))"
            ],
            "deleted": [
                "\t\tif (key->tfm[i])"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s IEEE 802.15.4 wireless networking subsystem in the way the user closes the LR-WPAN connection. This flaw allows a local user to crash the system. The highest threat from this vulnerability is to system availability.",
        "id": 3039
    },
    {
        "cve_id": "CVE-2023-2166",
        "code_before_change": "static int canxl_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t     struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canxl_skb(skb)))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN XL skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "code_after_change": "static int canxl_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t     struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canxl_skb(skb))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN XL skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static int canxl_rcv(struct sk_buff *skb, struct net_device *dev,\n \t\t     struct packet_type *pt, struct net_device *orig_dev)\n {\n-\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canxl_skb(skb)))) {\n+\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canxl_skb(skb))) {\n \t\tpr_warn_once(\"PF_CAN: dropped non conform CAN XL skbuff: dev type %d, len %d\\n\",\n \t\t\t     dev->type, skb->len);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canxl_skb(skb))) {"
            ],
            "deleted": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canxl_skb(skb)))) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference issue was found in can protocol in net/can/af_can.c in the Linux before Linux. ml_priv may not be initialized in the receive path of CAN frames. A local user could use this flaw to crash the system or potentially cause a denial of service.",
        "id": 3928
    },
    {
        "cve_id": "CVE-2019-15923",
        "code_before_change": "static void pcd_init_units(void)\n{\n\tstruct pcd_unit *cd;\n\tint unit;\n\n\tpcd_drive_count = 0;\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tstruct gendisk *disk = alloc_disk(1);\n\n\t\tif (!disk)\n\t\t\tcontinue;\n\n\t\tdisk->queue = blk_mq_init_sq_queue(&cd->tag_set, &pcd_mq_ops,\n\t\t\t\t\t\t   1, BLK_MQ_F_SHOULD_MERGE);\n\t\tif (IS_ERR(disk->queue)) {\n\t\t\tdisk->queue = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&cd->rq_list);\n\t\tdisk->queue->queuedata = cd;\n\t\tblk_queue_bounce_limit(disk->queue, BLK_BOUNCE_HIGH);\n\t\tcd->disk = disk;\n\t\tcd->pi = &cd->pia;\n\t\tcd->present = 0;\n\t\tcd->last_sense = 0;\n\t\tcd->changed = 1;\n\t\tcd->drive = (*drives[unit])[D_SLV];\n\t\tif ((*drives[unit])[D_PRT])\n\t\t\tpcd_drive_count++;\n\n\t\tcd->name = &cd->info.name[0];\n\t\tsnprintf(cd->name, sizeof(cd->info.name), \"%s%d\", name, unit);\n\t\tcd->info.ops = &pcd_dops;\n\t\tcd->info.handle = cd;\n\t\tcd->info.speed = 0;\n\t\tcd->info.capacity = 1;\n\t\tcd->info.mask = 0;\n\t\tdisk->major = major;\n\t\tdisk->first_minor = unit;\n\t\tstrcpy(disk->disk_name, cd->name);\t/* umm... */\n\t\tdisk->fops = &pcd_bdops;\n\t\tdisk->flags = GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE;\n\t}\n}",
        "code_after_change": "static void pcd_init_units(void)\n{\n\tstruct pcd_unit *cd;\n\tint unit;\n\n\tpcd_drive_count = 0;\n\tfor (unit = 0, cd = pcd; unit < PCD_UNITS; unit++, cd++) {\n\t\tstruct gendisk *disk = alloc_disk(1);\n\n\t\tif (!disk)\n\t\t\tcontinue;\n\n\t\tdisk->queue = blk_mq_init_sq_queue(&cd->tag_set, &pcd_mq_ops,\n\t\t\t\t\t\t   1, BLK_MQ_F_SHOULD_MERGE);\n\t\tif (IS_ERR(disk->queue)) {\n\t\t\tput_disk(disk);\n\t\t\tdisk->queue = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tINIT_LIST_HEAD(&cd->rq_list);\n\t\tdisk->queue->queuedata = cd;\n\t\tblk_queue_bounce_limit(disk->queue, BLK_BOUNCE_HIGH);\n\t\tcd->disk = disk;\n\t\tcd->pi = &cd->pia;\n\t\tcd->present = 0;\n\t\tcd->last_sense = 0;\n\t\tcd->changed = 1;\n\t\tcd->drive = (*drives[unit])[D_SLV];\n\t\tif ((*drives[unit])[D_PRT])\n\t\t\tpcd_drive_count++;\n\n\t\tcd->name = &cd->info.name[0];\n\t\tsnprintf(cd->name, sizeof(cd->info.name), \"%s%d\", name, unit);\n\t\tcd->info.ops = &pcd_dops;\n\t\tcd->info.handle = cd;\n\t\tcd->info.speed = 0;\n\t\tcd->info.capacity = 1;\n\t\tcd->info.mask = 0;\n\t\tdisk->major = major;\n\t\tdisk->first_minor = unit;\n\t\tstrcpy(disk->disk_name, cd->name);\t/* umm... */\n\t\tdisk->fops = &pcd_bdops;\n\t\tdisk->flags = GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,6 +13,7 @@\n \t\tdisk->queue = blk_mq_init_sq_queue(&cd->tag_set, &pcd_mq_ops,\n \t\t\t\t\t\t   1, BLK_MQ_F_SHOULD_MERGE);\n \t\tif (IS_ERR(disk->queue)) {\n+\t\t\tput_disk(disk);\n \t\t\tdisk->queue = NULL;\n \t\t\tcontinue;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\tput_disk(disk);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.9. There is a NULL pointer dereference for a cd data structure if alloc_disk fails in drivers/block/paride/pf.c.",
        "id": 2033
    },
    {
        "cve_id": "CVE-2019-10207",
        "code_before_change": "static int ath_open(struct hci_uart *hu)\n{\n\tstruct ath_struct *ath;\n\n\tBT_DBG(\"hu %p\", hu);\n\n\tath = kzalloc(sizeof(*ath), GFP_KERNEL);\n\tif (!ath)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&ath->txq);\n\n\thu->priv = ath;\n\tath->hu = hu;\n\n\tINIT_WORK(&ath->ctxtsw, ath_hci_uart_work);\n\n\treturn 0;\n}",
        "code_after_change": "static int ath_open(struct hci_uart *hu)\n{\n\tstruct ath_struct *ath;\n\n\tBT_DBG(\"hu %p\", hu);\n\n\tif (!hci_uart_has_flow_control(hu))\n\t\treturn -EOPNOTSUPP;\n\n\tath = kzalloc(sizeof(*ath), GFP_KERNEL);\n\tif (!ath)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&ath->txq);\n\n\thu->priv = ath;\n\tath->hu = hu;\n\n\tINIT_WORK(&ath->ctxtsw, ath_hci_uart_work);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,9 @@\n \tstruct ath_struct *ath;\n \n \tBT_DBG(\"hu %p\", hu);\n+\n+\tif (!hci_uart_has_flow_control(hu))\n+\t\treturn -EOPNOTSUPP;\n \n \tath = kzalloc(sizeof(*ath), GFP_KERNEL);\n \tif (!ath)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!hci_uart_has_flow_control(hu))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's Bluetooth implementation of UART, all versions kernel 3.x.x before 4.18.0 and kernel 5.x.x. An attacker with local access and write permissions to the Bluetooth hardware could use this flaw to issue a specially crafted ioctl function call and cause the system to crash.",
        "id": 1896
    },
    {
        "cve_id": "CVE-2023-2898",
        "code_before_change": "static int f2fs_ioc_resize_fs(struct file *filp, unsigned long arg)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(file_inode(filp));\n\t__u64 block_count;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (f2fs_readonly(sbi->sb))\n\t\treturn -EROFS;\n\n\tif (copy_from_user(&block_count, (void __user *)arg,\n\t\t\t   sizeof(block_count)))\n\t\treturn -EFAULT;\n\n\treturn f2fs_resize_fs(sbi, block_count);\n}",
        "code_after_change": "static int f2fs_ioc_resize_fs(struct file *filp, unsigned long arg)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(file_inode(filp));\n\t__u64 block_count;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (f2fs_readonly(sbi->sb))\n\t\treturn -EROFS;\n\n\tif (copy_from_user(&block_count, (void __user *)arg,\n\t\t\t   sizeof(block_count)))\n\t\treturn -EFAULT;\n\n\treturn f2fs_resize_fs(filp, block_count);\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,5 +13,5 @@\n \t\t\t   sizeof(block_count)))\n \t\treturn -EFAULT;\n \n-\treturn f2fs_resize_fs(sbi, block_count);\n+\treturn f2fs_resize_fs(filp, block_count);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn f2fs_resize_fs(filp, block_count);"
            ],
            "deleted": [
                "\treturn f2fs_resize_fs(sbi, block_count);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476"
        ],
        "cve_description": "There is a null-pointer-dereference flaw found in f2fs_write_end_io in fs/f2fs/data.c in the Linux kernel. This flaw allows a local privileged user to cause a denial of service problem.",
        "id": 3983
    },
    {
        "cve_id": "CVE-2017-7374",
        "code_before_change": "int fscrypt_get_encryption_info(struct inode *inode)\n{\n\tstruct fscrypt_info *ci = inode->i_crypt_info;\n\n\tif (!ci ||\n\t\t(ci->ci_keyring_key &&\n\t\t (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |\n\t\t\t\t\t       (1 << KEY_FLAG_REVOKED) |\n\t\t\t\t\t       (1 << KEY_FLAG_DEAD)))))\n\t\treturn fscrypt_get_crypt_info(inode);\n\treturn 0;\n}",
        "code_after_change": "int fscrypt_get_encryption_info(struct inode *inode)\n{\n\tstruct fscrypt_info *crypt_info;\n\tstruct fscrypt_context ctx;\n\tstruct crypto_skcipher *ctfm;\n\tconst char *cipher_str;\n\tint keysize;\n\tu8 *raw_key = NULL;\n\tint res;\n\n\tif (inode->i_crypt_info)\n\t\treturn 0;\n\n\tres = fscrypt_initialize(inode->i_sb->s_cop->flags);\n\tif (res)\n\t\treturn res;\n\n\tif (!inode->i_sb->s_cop->get_context)\n\t\treturn -EOPNOTSUPP;\n\n\tres = inode->i_sb->s_cop->get_context(inode, &ctx, sizeof(ctx));\n\tif (res < 0) {\n\t\tif (!fscrypt_dummy_context_enabled(inode) ||\n\t\t    inode->i_sb->s_cop->is_encrypted(inode))\n\t\t\treturn res;\n\t\t/* Fake up a context for an unencrypted directory */\n\t\tmemset(&ctx, 0, sizeof(ctx));\n\t\tctx.format = FS_ENCRYPTION_CONTEXT_FORMAT_V1;\n\t\tctx.contents_encryption_mode = FS_ENCRYPTION_MODE_AES_256_XTS;\n\t\tctx.filenames_encryption_mode = FS_ENCRYPTION_MODE_AES_256_CTS;\n\t\tmemset(ctx.master_key_descriptor, 0x42, FS_KEY_DESCRIPTOR_SIZE);\n\t} else if (res != sizeof(ctx)) {\n\t\treturn -EINVAL;\n\t}\n\n\tif (ctx.format != FS_ENCRYPTION_CONTEXT_FORMAT_V1)\n\t\treturn -EINVAL;\n\n\tif (ctx.flags & ~FS_POLICY_FLAGS_VALID)\n\t\treturn -EINVAL;\n\n\tcrypt_info = kmem_cache_alloc(fscrypt_info_cachep, GFP_NOFS);\n\tif (!crypt_info)\n\t\treturn -ENOMEM;\n\n\tcrypt_info->ci_flags = ctx.flags;\n\tcrypt_info->ci_data_mode = ctx.contents_encryption_mode;\n\tcrypt_info->ci_filename_mode = ctx.filenames_encryption_mode;\n\tcrypt_info->ci_ctfm = NULL;\n\tmemcpy(crypt_info->ci_master_key, ctx.master_key_descriptor,\n\t\t\t\tsizeof(crypt_info->ci_master_key));\n\n\tres = determine_cipher_type(crypt_info, inode, &cipher_str, &keysize);\n\tif (res)\n\t\tgoto out;\n\n\t/*\n\t * This cannot be a stack buffer because it is passed to the scatterlist\n\t * crypto API as part of key derivation.\n\t */\n\tres = -ENOMEM;\n\traw_key = kmalloc(FS_MAX_KEY_SIZE, GFP_NOFS);\n\tif (!raw_key)\n\t\tgoto out;\n\n\tres = validate_user_key(crypt_info, &ctx, raw_key, FS_KEY_DESC_PREFIX);\n\tif (res && inode->i_sb->s_cop->key_prefix) {\n\t\tint res2 = validate_user_key(crypt_info, &ctx, raw_key,\n\t\t\t\t\t     inode->i_sb->s_cop->key_prefix);\n\t\tif (res2) {\n\t\t\tif (res2 == -ENOKEY)\n\t\t\t\tres = -ENOKEY;\n\t\t\tgoto out;\n\t\t}\n\t} else if (res) {\n\t\tgoto out;\n\t}\n\tctfm = crypto_alloc_skcipher(cipher_str, 0, 0);\n\tif (!ctfm || IS_ERR(ctfm)) {\n\t\tres = ctfm ? PTR_ERR(ctfm) : -ENOMEM;\n\t\tprintk(KERN_DEBUG\n\t\t       \"%s: error %d (inode %u) allocating crypto tfm\\n\",\n\t\t       __func__, res, (unsigned) inode->i_ino);\n\t\tgoto out;\n\t}\n\tcrypt_info->ci_ctfm = ctfm;\n\tcrypto_skcipher_clear_flags(ctfm, ~0);\n\tcrypto_skcipher_set_flags(ctfm, CRYPTO_TFM_REQ_WEAK_KEY);\n\tres = crypto_skcipher_setkey(ctfm, raw_key, keysize);\n\tif (res)\n\t\tgoto out;\n\n\tif (cmpxchg(&inode->i_crypt_info, NULL, crypt_info) == NULL)\n\t\tcrypt_info = NULL;\nout:\n\tif (res == -ENOKEY)\n\t\tres = 0;\n\tput_crypt_info(crypt_info);\n\tkzfree(raw_key);\n\treturn res;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,12 +1,101 @@\n int fscrypt_get_encryption_info(struct inode *inode)\n {\n-\tstruct fscrypt_info *ci = inode->i_crypt_info;\n+\tstruct fscrypt_info *crypt_info;\n+\tstruct fscrypt_context ctx;\n+\tstruct crypto_skcipher *ctfm;\n+\tconst char *cipher_str;\n+\tint keysize;\n+\tu8 *raw_key = NULL;\n+\tint res;\n \n-\tif (!ci ||\n-\t\t(ci->ci_keyring_key &&\n-\t\t (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |\n-\t\t\t\t\t       (1 << KEY_FLAG_REVOKED) |\n-\t\t\t\t\t       (1 << KEY_FLAG_DEAD)))))\n-\t\treturn fscrypt_get_crypt_info(inode);\n-\treturn 0;\n+\tif (inode->i_crypt_info)\n+\t\treturn 0;\n+\n+\tres = fscrypt_initialize(inode->i_sb->s_cop->flags);\n+\tif (res)\n+\t\treturn res;\n+\n+\tif (!inode->i_sb->s_cop->get_context)\n+\t\treturn -EOPNOTSUPP;\n+\n+\tres = inode->i_sb->s_cop->get_context(inode, &ctx, sizeof(ctx));\n+\tif (res < 0) {\n+\t\tif (!fscrypt_dummy_context_enabled(inode) ||\n+\t\t    inode->i_sb->s_cop->is_encrypted(inode))\n+\t\t\treturn res;\n+\t\t/* Fake up a context for an unencrypted directory */\n+\t\tmemset(&ctx, 0, sizeof(ctx));\n+\t\tctx.format = FS_ENCRYPTION_CONTEXT_FORMAT_V1;\n+\t\tctx.contents_encryption_mode = FS_ENCRYPTION_MODE_AES_256_XTS;\n+\t\tctx.filenames_encryption_mode = FS_ENCRYPTION_MODE_AES_256_CTS;\n+\t\tmemset(ctx.master_key_descriptor, 0x42, FS_KEY_DESCRIPTOR_SIZE);\n+\t} else if (res != sizeof(ctx)) {\n+\t\treturn -EINVAL;\n+\t}\n+\n+\tif (ctx.format != FS_ENCRYPTION_CONTEXT_FORMAT_V1)\n+\t\treturn -EINVAL;\n+\n+\tif (ctx.flags & ~FS_POLICY_FLAGS_VALID)\n+\t\treturn -EINVAL;\n+\n+\tcrypt_info = kmem_cache_alloc(fscrypt_info_cachep, GFP_NOFS);\n+\tif (!crypt_info)\n+\t\treturn -ENOMEM;\n+\n+\tcrypt_info->ci_flags = ctx.flags;\n+\tcrypt_info->ci_data_mode = ctx.contents_encryption_mode;\n+\tcrypt_info->ci_filename_mode = ctx.filenames_encryption_mode;\n+\tcrypt_info->ci_ctfm = NULL;\n+\tmemcpy(crypt_info->ci_master_key, ctx.master_key_descriptor,\n+\t\t\t\tsizeof(crypt_info->ci_master_key));\n+\n+\tres = determine_cipher_type(crypt_info, inode, &cipher_str, &keysize);\n+\tif (res)\n+\t\tgoto out;\n+\n+\t/*\n+\t * This cannot be a stack buffer because it is passed to the scatterlist\n+\t * crypto API as part of key derivation.\n+\t */\n+\tres = -ENOMEM;\n+\traw_key = kmalloc(FS_MAX_KEY_SIZE, GFP_NOFS);\n+\tif (!raw_key)\n+\t\tgoto out;\n+\n+\tres = validate_user_key(crypt_info, &ctx, raw_key, FS_KEY_DESC_PREFIX);\n+\tif (res && inode->i_sb->s_cop->key_prefix) {\n+\t\tint res2 = validate_user_key(crypt_info, &ctx, raw_key,\n+\t\t\t\t\t     inode->i_sb->s_cop->key_prefix);\n+\t\tif (res2) {\n+\t\t\tif (res2 == -ENOKEY)\n+\t\t\t\tres = -ENOKEY;\n+\t\t\tgoto out;\n+\t\t}\n+\t} else if (res) {\n+\t\tgoto out;\n+\t}\n+\tctfm = crypto_alloc_skcipher(cipher_str, 0, 0);\n+\tif (!ctfm || IS_ERR(ctfm)) {\n+\t\tres = ctfm ? PTR_ERR(ctfm) : -ENOMEM;\n+\t\tprintk(KERN_DEBUG\n+\t\t       \"%s: error %d (inode %u) allocating crypto tfm\\n\",\n+\t\t       __func__, res, (unsigned) inode->i_ino);\n+\t\tgoto out;\n+\t}\n+\tcrypt_info->ci_ctfm = ctfm;\n+\tcrypto_skcipher_clear_flags(ctfm, ~0);\n+\tcrypto_skcipher_set_flags(ctfm, CRYPTO_TFM_REQ_WEAK_KEY);\n+\tres = crypto_skcipher_setkey(ctfm, raw_key, keysize);\n+\tif (res)\n+\t\tgoto out;\n+\n+\tif (cmpxchg(&inode->i_crypt_info, NULL, crypt_info) == NULL)\n+\t\tcrypt_info = NULL;\n+out:\n+\tif (res == -ENOKEY)\n+\t\tres = 0;\n+\tput_crypt_info(crypt_info);\n+\tkzfree(raw_key);\n+\treturn res;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct fscrypt_info *crypt_info;",
                "\tstruct fscrypt_context ctx;",
                "\tstruct crypto_skcipher *ctfm;",
                "\tconst char *cipher_str;",
                "\tint keysize;",
                "\tu8 *raw_key = NULL;",
                "\tint res;",
                "\tif (inode->i_crypt_info)",
                "\t\treturn 0;",
                "",
                "\tres = fscrypt_initialize(inode->i_sb->s_cop->flags);",
                "\tif (res)",
                "\t\treturn res;",
                "",
                "\tif (!inode->i_sb->s_cop->get_context)",
                "\t\treturn -EOPNOTSUPP;",
                "",
                "\tres = inode->i_sb->s_cop->get_context(inode, &ctx, sizeof(ctx));",
                "\tif (res < 0) {",
                "\t\tif (!fscrypt_dummy_context_enabled(inode) ||",
                "\t\t    inode->i_sb->s_cop->is_encrypted(inode))",
                "\t\t\treturn res;",
                "\t\t/* Fake up a context for an unencrypted directory */",
                "\t\tmemset(&ctx, 0, sizeof(ctx));",
                "\t\tctx.format = FS_ENCRYPTION_CONTEXT_FORMAT_V1;",
                "\t\tctx.contents_encryption_mode = FS_ENCRYPTION_MODE_AES_256_XTS;",
                "\t\tctx.filenames_encryption_mode = FS_ENCRYPTION_MODE_AES_256_CTS;",
                "\t\tmemset(ctx.master_key_descriptor, 0x42, FS_KEY_DESCRIPTOR_SIZE);",
                "\t} else if (res != sizeof(ctx)) {",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\tif (ctx.format != FS_ENCRYPTION_CONTEXT_FORMAT_V1)",
                "\t\treturn -EINVAL;",
                "",
                "\tif (ctx.flags & ~FS_POLICY_FLAGS_VALID)",
                "\t\treturn -EINVAL;",
                "",
                "\tcrypt_info = kmem_cache_alloc(fscrypt_info_cachep, GFP_NOFS);",
                "\tif (!crypt_info)",
                "\t\treturn -ENOMEM;",
                "",
                "\tcrypt_info->ci_flags = ctx.flags;",
                "\tcrypt_info->ci_data_mode = ctx.contents_encryption_mode;",
                "\tcrypt_info->ci_filename_mode = ctx.filenames_encryption_mode;",
                "\tcrypt_info->ci_ctfm = NULL;",
                "\tmemcpy(crypt_info->ci_master_key, ctx.master_key_descriptor,",
                "\t\t\t\tsizeof(crypt_info->ci_master_key));",
                "",
                "\tres = determine_cipher_type(crypt_info, inode, &cipher_str, &keysize);",
                "\tif (res)",
                "\t\tgoto out;",
                "",
                "\t/*",
                "\t * This cannot be a stack buffer because it is passed to the scatterlist",
                "\t * crypto API as part of key derivation.",
                "\t */",
                "\tres = -ENOMEM;",
                "\traw_key = kmalloc(FS_MAX_KEY_SIZE, GFP_NOFS);",
                "\tif (!raw_key)",
                "\t\tgoto out;",
                "",
                "\tres = validate_user_key(crypt_info, &ctx, raw_key, FS_KEY_DESC_PREFIX);",
                "\tif (res && inode->i_sb->s_cop->key_prefix) {",
                "\t\tint res2 = validate_user_key(crypt_info, &ctx, raw_key,",
                "\t\t\t\t\t     inode->i_sb->s_cop->key_prefix);",
                "\t\tif (res2) {",
                "\t\t\tif (res2 == -ENOKEY)",
                "\t\t\t\tres = -ENOKEY;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t} else if (res) {",
                "\t\tgoto out;",
                "\t}",
                "\tctfm = crypto_alloc_skcipher(cipher_str, 0, 0);",
                "\tif (!ctfm || IS_ERR(ctfm)) {",
                "\t\tres = ctfm ? PTR_ERR(ctfm) : -ENOMEM;",
                "\t\tprintk(KERN_DEBUG",
                "\t\t       \"%s: error %d (inode %u) allocating crypto tfm\\n\",",
                "\t\t       __func__, res, (unsigned) inode->i_ino);",
                "\t\tgoto out;",
                "\t}",
                "\tcrypt_info->ci_ctfm = ctfm;",
                "\tcrypto_skcipher_clear_flags(ctfm, ~0);",
                "\tcrypto_skcipher_set_flags(ctfm, CRYPTO_TFM_REQ_WEAK_KEY);",
                "\tres = crypto_skcipher_setkey(ctfm, raw_key, keysize);",
                "\tif (res)",
                "\t\tgoto out;",
                "",
                "\tif (cmpxchg(&inode->i_crypt_info, NULL, crypt_info) == NULL)",
                "\t\tcrypt_info = NULL;",
                "out:",
                "\tif (res == -ENOKEY)",
                "\t\tres = 0;",
                "\tput_crypt_info(crypt_info);",
                "\tkzfree(raw_key);",
                "\treturn res;"
            ],
            "deleted": [
                "\tstruct fscrypt_info *ci = inode->i_crypt_info;",
                "\tif (!ci ||",
                "\t\t(ci->ci_keyring_key &&",
                "\t\t (ci->ci_keyring_key->flags & ((1 << KEY_FLAG_INVALIDATED) |",
                "\t\t\t\t\t       (1 << KEY_FLAG_REVOKED) |",
                "\t\t\t\t\t       (1 << KEY_FLAG_DEAD)))))",
                "\t\treturn fscrypt_get_crypt_info(inode);",
                "\treturn 0;"
            ]
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "Use-after-free vulnerability in fs/crypto/ in the Linux kernel before 4.10.7 allows local users to cause a denial of service (NULL pointer dereference) or possibly gain privileges by revoking keyring keys being used for ext4, f2fs, or ubifs encryption, causing cryptographic transform objects to be freed prematurely.",
        "id": 1499
    },
    {
        "cve_id": "CVE-2017-16537",
        "code_before_change": "static int imon_probe(struct usb_interface *interface,\n\t\t      const struct usb_device_id *id)\n{\n\tstruct usb_device *usbdev = NULL;\n\tstruct usb_host_interface *iface_desc = NULL;\n\tstruct usb_interface *first_if;\n\tstruct device *dev = &interface->dev;\n\tint ifnum, sysfs_err;\n\tint ret = 0;\n\tstruct imon_context *ictx = NULL;\n\tstruct imon_context *first_if_ctx = NULL;\n\tu16 vendor, product;\n\n\tusbdev     = usb_get_dev(interface_to_usbdev(interface));\n\tiface_desc = interface->cur_altsetting;\n\tifnum      = iface_desc->desc.bInterfaceNumber;\n\tvendor     = le16_to_cpu(usbdev->descriptor.idVendor);\n\tproduct    = le16_to_cpu(usbdev->descriptor.idProduct);\n\n\tdev_dbg(dev, \"%s: found iMON device (%04x:%04x, intf%d)\\n\",\n\t\t__func__, vendor, product, ifnum);\n\n\t/* prevent races probing devices w/multiple interfaces */\n\tmutex_lock(&driver_lock);\n\n\tfirst_if = usb_ifnum_to_if(usbdev, 0);\n\tfirst_if_ctx = usb_get_intfdata(first_if);\n\n\tif (ifnum == 0) {\n\t\tictx = imon_init_intf0(interface, id);\n\t\tif (!ictx) {\n\t\t\tpr_err(\"failed to initialize context!\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t} else {\n\t\t/* this is the secondary interface on the device */\n\n\t\t/* fail early if first intf failed to register */\n\t\tif (!first_if_ctx) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tictx = imon_init_intf1(interface, first_if_ctx);\n\t\tif (!ictx) {\n\t\t\tpr_err(\"failed to attach to context!\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t}\n\n\tusb_set_intfdata(interface, ictx);\n\n\tif (ifnum == 0) {\n\t\tmutex_lock(&ictx->lock);\n\n\t\tif (product == 0xffdc && ictx->rf_device) {\n\t\t\tsysfs_err = sysfs_create_group(&interface->dev.kobj,\n\t\t\t\t\t\t       &imon_rf_attr_group);\n\t\t\tif (sysfs_err)\n\t\t\t\tpr_err(\"Could not create RF sysfs entries(%d)\\n\",\n\t\t\t\t       sysfs_err);\n\t\t}\n\n\t\tif (ictx->display_supported)\n\t\t\timon_init_display(ictx, interface);\n\n\t\tmutex_unlock(&ictx->lock);\n\t}\n\n\tdev_info(dev, \"iMON device (%04x:%04x, intf%d) on usb<%d:%d> initialized\\n\",\n\t\t vendor, product, ifnum,\n\t\t usbdev->bus->busnum, usbdev->devnum);\n\n\tmutex_unlock(&driver_lock);\n\tusb_put_dev(usbdev);\n\n\treturn 0;\n\nfail:\n\tmutex_unlock(&driver_lock);\n\tusb_put_dev(usbdev);\n\tdev_err(dev, \"unable to register, err %d\\n\", ret);\n\n\treturn ret;\n}",
        "code_after_change": "static int imon_probe(struct usb_interface *interface,\n\t\t      const struct usb_device_id *id)\n{\n\tstruct usb_device *usbdev = NULL;\n\tstruct usb_host_interface *iface_desc = NULL;\n\tstruct usb_interface *first_if;\n\tstruct device *dev = &interface->dev;\n\tint ifnum, sysfs_err;\n\tint ret = 0;\n\tstruct imon_context *ictx = NULL;\n\tstruct imon_context *first_if_ctx = NULL;\n\tu16 vendor, product;\n\n\tusbdev     = usb_get_dev(interface_to_usbdev(interface));\n\tiface_desc = interface->cur_altsetting;\n\tifnum      = iface_desc->desc.bInterfaceNumber;\n\tvendor     = le16_to_cpu(usbdev->descriptor.idVendor);\n\tproduct    = le16_to_cpu(usbdev->descriptor.idProduct);\n\n\tdev_dbg(dev, \"%s: found iMON device (%04x:%04x, intf%d)\\n\",\n\t\t__func__, vendor, product, ifnum);\n\n\t/* prevent races probing devices w/multiple interfaces */\n\tmutex_lock(&driver_lock);\n\n\tfirst_if = usb_ifnum_to_if(usbdev, 0);\n\tif (!first_if) {\n\t\tret = -ENODEV;\n\t\tgoto fail;\n\t}\n\n\tfirst_if_ctx = usb_get_intfdata(first_if);\n\n\tif (ifnum == 0) {\n\t\tictx = imon_init_intf0(interface, id);\n\t\tif (!ictx) {\n\t\t\tpr_err(\"failed to initialize context!\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t} else {\n\t\t/* this is the secondary interface on the device */\n\n\t\t/* fail early if first intf failed to register */\n\t\tif (!first_if_ctx) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tictx = imon_init_intf1(interface, first_if_ctx);\n\t\tif (!ictx) {\n\t\t\tpr_err(\"failed to attach to context!\\n\");\n\t\t\tret = -ENODEV;\n\t\t\tgoto fail;\n\t\t}\n\n\t}\n\n\tusb_set_intfdata(interface, ictx);\n\n\tif (ifnum == 0) {\n\t\tmutex_lock(&ictx->lock);\n\n\t\tif (product == 0xffdc && ictx->rf_device) {\n\t\t\tsysfs_err = sysfs_create_group(&interface->dev.kobj,\n\t\t\t\t\t\t       &imon_rf_attr_group);\n\t\t\tif (sysfs_err)\n\t\t\t\tpr_err(\"Could not create RF sysfs entries(%d)\\n\",\n\t\t\t\t       sysfs_err);\n\t\t}\n\n\t\tif (ictx->display_supported)\n\t\t\timon_init_display(ictx, interface);\n\n\t\tmutex_unlock(&ictx->lock);\n\t}\n\n\tdev_info(dev, \"iMON device (%04x:%04x, intf%d) on usb<%d:%d> initialized\\n\",\n\t\t vendor, product, ifnum,\n\t\t usbdev->bus->busnum, usbdev->devnum);\n\n\tmutex_unlock(&driver_lock);\n\tusb_put_dev(usbdev);\n\n\treturn 0;\n\nfail:\n\tmutex_unlock(&driver_lock);\n\tusb_put_dev(usbdev);\n\tdev_err(dev, \"unable to register, err %d\\n\", ret);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,6 +24,11 @@\n \tmutex_lock(&driver_lock);\n \n \tfirst_if = usb_ifnum_to_if(usbdev, 0);\n+\tif (!first_if) {\n+\t\tret = -ENODEV;\n+\t\tgoto fail;\n+\t}\n+\n \tfirst_if_ctx = usb_get_intfdata(first_if);\n \n \tif (ifnum == 0) {",
        "function_modified_lines": {
            "added": [
                "\tif (!first_if) {",
                "\t\tret = -ENODEV;",
                "\t\tgoto fail;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The imon_probe function in drivers/media/rc/imon.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1323
    },
    {
        "cve_id": "CVE-2016-8646",
        "code_before_change": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tint err;\n\n\terr = crypto_ahash_export(req, state);\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = 1;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tbool more;\n\tint err;\n\n\tlock_sock(sk);\n\tmore = ctx->more;\n\terr = more ? crypto_ahash_export(req, state) : 0;\n\trelease_sock(sk);\n\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = more;\n\n\tif (!more)\n\t\treturn err;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,9 +8,14 @@\n \tstruct sock *sk2;\n \tstruct alg_sock *ask2;\n \tstruct hash_ctx *ctx2;\n+\tbool more;\n \tint err;\n \n-\terr = crypto_ahash_export(req, state);\n+\tlock_sock(sk);\n+\tmore = ctx->more;\n+\terr = more ? crypto_ahash_export(req, state) : 0;\n+\trelease_sock(sk);\n+\n \tif (err)\n \t\treturn err;\n \n@@ -21,7 +26,10 @@\n \tsk2 = newsock->sk;\n \task2 = alg_sk(sk2);\n \tctx2 = ask2->private;\n-\tctx2->more = 1;\n+\tctx2->more = more;\n+\n+\tif (!more)\n+\t\treturn err;\n \n \terr = crypto_ahash_import(&ctx2->req, state);\n \tif (err) {",
        "function_modified_lines": {
            "added": [
                "\tbool more;",
                "\tlock_sock(sk);",
                "\tmore = ctx->more;",
                "\terr = more ? crypto_ahash_export(req, state) : 0;",
                "\trelease_sock(sk);",
                "",
                "\tctx2->more = more;",
                "",
                "\tif (!more)",
                "\t\treturn err;"
            ],
            "deleted": [
                "\terr = crypto_ahash_export(req, state);",
                "\tctx2->more = 1;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The hash_accept function in crypto/algif_hash.c in the Linux kernel before 4.3.6 allows local users to cause a denial of service (OOPS) by attempting to trigger use of in-kernel hash algorithms for a socket that has received zero bytes of data.",
        "id": 1129
    },
    {
        "cve_id": "CVE-2017-2647",
        "code_before_change": "static int asymmetric_key_match_preparse(struct key_match_data *match_data)\n{\n\tmatch_data->lookup_type = KEYRING_SEARCH_LOOKUP_ITERATE;\n\treturn 0;\n}",
        "code_after_change": "static int asymmetric_key_match_preparse(struct key_match_data *match_data)\n{\n\tmatch_data->lookup_type = KEYRING_SEARCH_LOOKUP_ITERATE;\n\tmatch_data->cmp = asymmetric_key_cmp;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,6 @@\n static int asymmetric_key_match_preparse(struct key_match_data *match_data)\n {\n \tmatch_data->lookup_type = KEYRING_SEARCH_LOOKUP_ITERATE;\n+\tmatch_data->cmp = asymmetric_key_cmp;\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tmatch_data->cmp = asymmetric_key_cmp;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel before 3.18 allows local users to gain privileges or cause a denial of service (NULL pointer dereference and system crash) via vectors involving a NULL value for a certain match field, related to the keyring_search_iterator function in keyring.c.",
        "id": 1450
    },
    {
        "cve_id": "CVE-2021-30178",
        "code_before_change": "static struct kvm_vcpu_hv_synic *synic_get(struct kvm *kvm, u32 vpidx)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vcpu_hv_synic *synic;\n\n\tvcpu = get_vcpu_by_vpidx(kvm, vpidx);\n\tif (!vcpu)\n\t\treturn NULL;\n\tsynic = to_hv_synic(vcpu);\n\treturn (synic->active) ? synic : NULL;\n}",
        "code_after_change": "static struct kvm_vcpu_hv_synic *synic_get(struct kvm *kvm, u32 vpidx)\n{\n\tstruct kvm_vcpu *vcpu;\n\tstruct kvm_vcpu_hv_synic *synic;\n\n\tvcpu = get_vcpu_by_vpidx(kvm, vpidx);\n\tif (!vcpu || !to_hv_vcpu(vcpu))\n\t\treturn NULL;\n\tsynic = to_hv_synic(vcpu);\n\treturn (synic->active) ? synic : NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n \tstruct kvm_vcpu_hv_synic *synic;\n \n \tvcpu = get_vcpu_by_vpidx(kvm, vpidx);\n-\tif (!vcpu)\n+\tif (!vcpu || !to_hv_vcpu(vcpu))\n \t\treturn NULL;\n \tsynic = to_hv_synic(vcpu);\n \treturn (synic->active) ? synic : NULL;",
        "function_modified_lines": {
            "added": [
                "\tif (!vcpu || !to_hv_vcpu(vcpu))"
            ],
            "deleted": [
                "\tif (!vcpu)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.11.11. synic_get in arch/x86/kvm/hyperv.c has a NULL pointer dereference for certain accesses to the SynIC Hyper-V context, aka CID-919f4ebc5987.",
        "id": 2959
    },
    {
        "cve_id": "CVE-2022-25258",
        "code_before_change": "int\ncomposite_setup(struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_composite_dev\t*cdev = get_gadget_data(gadget);\n\tstruct usb_request\t\t*req = cdev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tint\t\t\t\tstatus = 0;\n\tu16\t\t\t\tw_index = le16_to_cpu(ctrl->wIndex);\n\tu8\t\t\t\tintf = w_index & 0xFF;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\tstruct usb_function\t\t*f = NULL;\n\tu8\t\t\t\tendp;\n\n\tif (w_length > USB_COMP_EP0_BUFSIZ) {\n\t\tif (ctrl->bRequestType & USB_DIR_IN) {\n\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n\n\t\t\t*temp = cpu_to_le16(USB_COMP_EP0_BUFSIZ);\n\t\t\tw_length = USB_COMP_EP0_BUFSIZ;\n\t\t} else {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/* partial re-init of the response message; the function or the\n\t * gadget might need to intercept e.g. a control-OUT completion\n\t * when we delegate to it.\n\t */\n\treq->zero = 0;\n\treq->context = cdev;\n\treq->complete = composite_setup_complete;\n\treq->length = 0;\n\tgadget->ep0->driver_data = cdev;\n\n\t/*\n\t * Don't let non-standard requests match any of the cases below\n\t * by accident.\n\t */\n\tif ((ctrl->bRequestType & USB_TYPE_MASK) != USB_TYPE_STANDARD)\n\t\tgoto unknown;\n\n\tswitch (ctrl->bRequest) {\n\n\t/* we handle all standard USB descriptors */\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tcdev->desc.bNumConfigurations =\n\t\t\t\tcount_configs(cdev, USB_DT_DEVICE);\n\t\t\tcdev->desc.bMaxPacketSize0 =\n\t\t\t\tcdev->gadget->ep0->maxpacket;\n\t\t\tif (gadget_is_superspeed(gadget)) {\n\t\t\t\tif (gadget->speed >= USB_SPEED_SUPER) {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0320);\n\t\t\t\t\tcdev->desc.bMaxPacketSize0 = 9;\n\t\t\t\t} else {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0210);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (gadget->lpm_capable)\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0201);\n\t\t\t\telse\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0200);\n\t\t\t}\n\n\t\t\tvalue = min(w_length, (u16) sizeof cdev->desc);\n\t\t\tmemcpy(req->buf, &cdev->desc, value);\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tdevice_qual(cdev);\n\t\t\tvalue = min_t(int, w_length,\n\t\t\t\tsizeof(struct usb_qualifier_descriptor));\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_desc(cdev, w_value);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tvalue = get_string(cdev, req->buf,\n\t\t\t\t\tw_index, w_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_BOS:\n\t\t\tif (gadget_is_superspeed(gadget) ||\n\t\t\t    gadget->lpm_capable) {\n\t\t\t\tvalue = bos_desc(cdev);\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase USB_DT_OTG:\n\t\t\tif (gadget_is_otg(gadget)) {\n\t\t\t\tstruct usb_configuration *config;\n\t\t\t\tint otg_desc_len = 0;\n\n\t\t\t\tif (cdev->config)\n\t\t\t\t\tconfig = cdev->config;\n\t\t\t\telse\n\t\t\t\t\tconfig = list_first_entry(\n\t\t\t\t\t\t\t&cdev->configs,\n\t\t\t\t\t\tstruct usb_configuration, list);\n\t\t\t\tif (!config)\n\t\t\t\t\tgoto done;\n\n\t\t\t\tif (gadget->otg_caps &&\n\t\t\t\t\t(gadget->otg_caps->otg_rev >= 0x0200))\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg20_descriptor);\n\t\t\t\telse\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg_descriptor);\n\n\t\t\t\tvalue = min_t(int, w_length, otg_desc_len);\n\t\t\t\tmemcpy(req->buf, config->descriptors[0], value);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* any number of configs can work */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unknown;\n\t\tif (gadget_is_otg(gadget)) {\n\t\t\tif (gadget->a_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP available\\n\");\n\t\t\telse if (gadget->a_alt_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP on another port\\n\");\n\t\t\telse\n\t\t\t\tVDBG(cdev, \"HNP inactive\\n\");\n\t\t}\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = set_config(cdev, ctrl, w_value);\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tif (cdev->config)\n\t\t\t*(u8 *)req->buf = cdev->config->bConfigurationValue;\n\t\telse\n\t\t\t*(u8 *)req->buf = 0;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\n\t/* function drivers must handle get/set altsetting */\n\tcase USB_REQ_SET_INTERFACE:\n\t\tif (ctrl->bRequestType != USB_RECIP_INTERFACE)\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If there's no get_alt() method, we know only altsetting zero\n\t\t * works. There is no need to check if set_alt() is not NULL\n\t\t * as we check this in usb_add_function().\n\t\t */\n\t\tif (w_value && !f->get_alt)\n\t\t\tbreak;\n\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = f->set_alt(f, w_index, w_value);\n\t\tif (value == USB_GADGET_DELAYED_STATUS) {\n\t\t\tDBG(cdev,\n\t\t\t \"%s: interface %d (%s) requested delayed status\\n\",\n\t\t\t\t\t__func__, intf, f->name);\n\t\t\tcdev->delayed_status++;\n\t\t\tDBG(cdev, \"delayed_status count %d\\n\",\n\t\t\t\t\tcdev->delayed_status);\n\t\t}\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_INTERFACE:\n\t\tif (ctrl->bRequestType != (USB_DIR_IN|USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\t/* lots of interfaces only need altsetting zero... */\n\t\tvalue = f->get_alt ? f->get_alt(f, w_index) : 0;\n\t\tif (value < 0)\n\t\t\tbreak;\n\t\t*((u8 *)req->buf) = value;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\tcase USB_REQ_GET_STATUS:\n\t\tif (gadget_is_otg(gadget) && gadget->hnp_polling_support &&\n\t\t\t\t\t\t(w_index == OTG_STS_SELECTOR)) {\n\t\t\tif (ctrl->bRequestType != (USB_DIR_IN |\n\t\t\t\t\t\t\tUSB_RECIP_DEVICE))\n\t\t\t\tgoto unknown;\n\t\t\t*((u8 *)req->buf) = gadget->host_request_flag;\n\t\t\tvalue = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * USB 3.0 additions:\n\t\t * Function driver should handle get_status request. If such cb\n\t\t * wasn't supplied we respond with default value = 0\n\t\t * Note: function driver should supply such cb only for the\n\t\t * first interface of the function\n\t\t */\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_IN | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tvalue = 2;\t/* This is the length of the get_status reply */\n\t\tput_unaligned_le16(0, req->buf);\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\tstatus = f->get_status ? f->get_status(f) : 0;\n\t\tif (status < 0)\n\t\t\tbreak;\n\t\tput_unaligned_le16(status & 0x0000ffff, req->buf);\n\t\tbreak;\n\t/*\n\t * Function drivers should handle SetFeature/ClearFeature\n\t * (FUNCTION_SUSPEND) request. function_suspend cb should be supplied\n\t * only for the first interface of the function\n\t */\n\tcase USB_REQ_CLEAR_FEATURE:\n\tcase USB_REQ_SET_FEATURE:\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_OUT | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tswitch (w_value) {\n\t\tcase USB_INTRF_FUNC_SUSPEND:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tif (!f)\n\t\t\t\tbreak;\n\t\t\tvalue = 0;\n\t\t\tif (f->func_suspend)\n\t\t\t\tvalue = f->func_suspend(f, w_index >> 8);\n\t\t\tif (value < 0) {\n\t\t\t\tERROR(cdev,\n\t\t\t\t      \"func_suspend() returned error %d\\n\",\n\t\t\t\t      value);\n\t\t\t\tvalue = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\nunknown:\n\t\t/*\n\t\t * OS descriptors handling\n\t\t */\n\t\tif (cdev->use_os_string && cdev->os_desc_config &&\n\t\t    (ctrl->bRequestType & USB_TYPE_VENDOR) &&\n\t\t    ctrl->bRequest == cdev->b_vendor_code) {\n\t\t\tstruct usb_configuration\t*os_desc_cfg;\n\t\t\tu8\t\t\t\t*buf;\n\t\t\tint\t\t\t\tinterface;\n\t\t\tint\t\t\t\tcount = 0;\n\n\t\t\treq = cdev->os_desc_req;\n\t\t\treq->context = cdev;\n\t\t\treq->complete = composite_setup_complete;\n\t\t\tbuf = req->buf;\n\t\t\tos_desc_cfg = cdev->os_desc_config;\n\t\t\tw_length = min_t(u16, w_length, USB_COMP_EP0_OS_DESC_BUFSIZ);\n\t\t\tmemset(buf, 0, w_length);\n\t\t\tbuf[5] = 0x01;\n\t\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\t\tcase USB_RECIP_DEVICE:\n\t\t\t\tif (w_index != 0x4 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\t/* Number of ext compat interfaces */\n\t\t\t\tcount = count_ext_compat(os_desc_cfg);\n\t\t\t\tbuf[8] = count;\n\t\t\t\tcount *= 24; /* 24 B/ext compat desc */\n\t\t\t\tcount += 16; /* header */\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x10) {\n\t\t\t\t\tvalue = fill_ext_compat(os_desc_cfg, buf);\n\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase USB_RECIP_INTERFACE:\n\t\t\t\tif (w_index != 0x5 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tinterface = w_value & 0xFF;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\tcount = count_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le16(count, buf + 8);\n\t\t\t\tcount = len_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x0A) {\n\t\t\t\t\tvalue = fill_ext_prop(os_desc_cfg,\n\t\t\t\t\t\t\t      interface, buf);\n\t\t\t\t\tif (value >= 0)\n\t\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgoto check_value;\n\t\t}\n\n\t\tVDBG(cdev,\n\t\t\t\"non-core control req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, w_index, w_length);\n\n\t\t/* functions always handle their interfaces and endpoints...\n\t\t * punt other recipients (other, WUSB, ...) to the current\n\t\t * configuration code.\n\t\t */\n\t\tif (cdev->config) {\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list)\n\t\t\t\tif (f->req_match &&\n\t\t\t\t    f->req_match(f, ctrl, false))\n\t\t\t\t\tgoto try_fun_setup;\n\t\t} else {\n\t\t\tstruct usb_configuration *c;\n\t\t\tlist_for_each_entry(c, &cdev->configs, list)\n\t\t\t\tlist_for_each_entry(f, &c->functions, list)\n\t\t\t\t\tif (f->req_match &&\n\t\t\t\t\t    f->req_match(f, ctrl, true))\n\t\t\t\t\t\tgoto try_fun_setup;\n\t\t}\n\t\tf = NULL;\n\n\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\tcase USB_RECIP_INTERFACE:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tbreak;\n\n\t\tcase USB_RECIP_ENDPOINT:\n\t\t\tif (!cdev->config)\n\t\t\t\tbreak;\n\t\t\tendp = ((w_index & 0x80) >> 3) | (w_index & 0x0f);\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list) {\n\t\t\t\tif (test_bit(endp, f->endpoints))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (&f->list == &cdev->config->functions)\n\t\t\t\tf = NULL;\n\t\t\tbreak;\n\t\t}\ntry_fun_setup:\n\t\tif (f && f->setup)\n\t\t\tvalue = f->setup(f, ctrl);\n\t\telse {\n\t\t\tstruct usb_configuration\t*c;\n\n\t\t\tc = cdev->config;\n\t\t\tif (!c)\n\t\t\t\tgoto done;\n\n\t\t\t/* try current config's setup */\n\t\t\tif (c->setup) {\n\t\t\t\tvalue = c->setup(c, ctrl);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* try the only function in the current config */\n\t\t\tif (!list_is_singular(&c->functions))\n\t\t\t\tgoto done;\n\t\t\tf = list_first_entry(&c->functions, struct usb_function,\n\t\t\t\t\t     list);\n\t\t\tif (f->setup)\n\t\t\t\tvalue = f->setup(f, ctrl);\n\t\t}\n\n\t\tgoto done;\n\t}\n\ncheck_value:\n\t/* respond with data transfer before status phase? */\n\tif (value >= 0 && value != USB_GADGET_DELAYED_STATUS) {\n\t\treq->length = value;\n\t\treq->context = cdev;\n\t\treq->zero = value < w_length;\n\t\tvalue = composite_ep0_queue(cdev, req, GFP_ATOMIC);\n\t\tif (value < 0) {\n\t\t\tDBG(cdev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t\tcomposite_setup_complete(gadget->ep0, req);\n\t\t}\n\t} else if (value == USB_GADGET_DELAYED_STATUS && w_length != 0) {\n\t\tWARN(cdev,\n\t\t\t\"%s: Delayed status not supported for w_length != 0\",\n\t\t\t__func__);\n\t}\n\ndone:\n\t/* device either stalls (value < 0) or reports success */\n\treturn value;\n}",
        "code_after_change": "int\ncomposite_setup(struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)\n{\n\tstruct usb_composite_dev\t*cdev = get_gadget_data(gadget);\n\tstruct usb_request\t\t*req = cdev->req;\n\tint\t\t\t\tvalue = -EOPNOTSUPP;\n\tint\t\t\t\tstatus = 0;\n\tu16\t\t\t\tw_index = le16_to_cpu(ctrl->wIndex);\n\tu8\t\t\t\tintf = w_index & 0xFF;\n\tu16\t\t\t\tw_value = le16_to_cpu(ctrl->wValue);\n\tu16\t\t\t\tw_length = le16_to_cpu(ctrl->wLength);\n\tstruct usb_function\t\t*f = NULL;\n\tu8\t\t\t\tendp;\n\n\tif (w_length > USB_COMP_EP0_BUFSIZ) {\n\t\tif (ctrl->bRequestType & USB_DIR_IN) {\n\t\t\t/* Cast away the const, we are going to overwrite on purpose. */\n\t\t\t__le16 *temp = (__le16 *)&ctrl->wLength;\n\n\t\t\t*temp = cpu_to_le16(USB_COMP_EP0_BUFSIZ);\n\t\t\tw_length = USB_COMP_EP0_BUFSIZ;\n\t\t} else {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t/* partial re-init of the response message; the function or the\n\t * gadget might need to intercept e.g. a control-OUT completion\n\t * when we delegate to it.\n\t */\n\treq->zero = 0;\n\treq->context = cdev;\n\treq->complete = composite_setup_complete;\n\treq->length = 0;\n\tgadget->ep0->driver_data = cdev;\n\n\t/*\n\t * Don't let non-standard requests match any of the cases below\n\t * by accident.\n\t */\n\tif ((ctrl->bRequestType & USB_TYPE_MASK) != USB_TYPE_STANDARD)\n\t\tgoto unknown;\n\n\tswitch (ctrl->bRequest) {\n\n\t/* we handle all standard USB descriptors */\n\tcase USB_REQ_GET_DESCRIPTOR:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tswitch (w_value >> 8) {\n\n\t\tcase USB_DT_DEVICE:\n\t\t\tcdev->desc.bNumConfigurations =\n\t\t\t\tcount_configs(cdev, USB_DT_DEVICE);\n\t\t\tcdev->desc.bMaxPacketSize0 =\n\t\t\t\tcdev->gadget->ep0->maxpacket;\n\t\t\tif (gadget_is_superspeed(gadget)) {\n\t\t\t\tif (gadget->speed >= USB_SPEED_SUPER) {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0320);\n\t\t\t\t\tcdev->desc.bMaxPacketSize0 = 9;\n\t\t\t\t} else {\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0210);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (gadget->lpm_capable)\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0201);\n\t\t\t\telse\n\t\t\t\t\tcdev->desc.bcdUSB = cpu_to_le16(0x0200);\n\t\t\t}\n\n\t\t\tvalue = min(w_length, (u16) sizeof cdev->desc);\n\t\t\tmemcpy(req->buf, &cdev->desc, value);\n\t\t\tbreak;\n\t\tcase USB_DT_DEVICE_QUALIFIER:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tdevice_qual(cdev);\n\t\t\tvalue = min_t(int, w_length,\n\t\t\t\tsizeof(struct usb_qualifier_descriptor));\n\t\t\tbreak;\n\t\tcase USB_DT_OTHER_SPEED_CONFIG:\n\t\t\tif (!gadget_is_dualspeed(gadget) ||\n\t\t\t    gadget->speed >= USB_SPEED_SUPER)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase USB_DT_CONFIG:\n\t\t\tvalue = config_desc(cdev, w_value);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_STRING:\n\t\t\tvalue = get_string(cdev, req->buf,\n\t\t\t\t\tw_index, w_value & 0xff);\n\t\t\tif (value >= 0)\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\tbreak;\n\t\tcase USB_DT_BOS:\n\t\t\tif (gadget_is_superspeed(gadget) ||\n\t\t\t    gadget->lpm_capable) {\n\t\t\t\tvalue = bos_desc(cdev);\n\t\t\t\tvalue = min(w_length, (u16) value);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase USB_DT_OTG:\n\t\t\tif (gadget_is_otg(gadget)) {\n\t\t\t\tstruct usb_configuration *config;\n\t\t\t\tint otg_desc_len = 0;\n\n\t\t\t\tif (cdev->config)\n\t\t\t\t\tconfig = cdev->config;\n\t\t\t\telse\n\t\t\t\t\tconfig = list_first_entry(\n\t\t\t\t\t\t\t&cdev->configs,\n\t\t\t\t\t\tstruct usb_configuration, list);\n\t\t\t\tif (!config)\n\t\t\t\t\tgoto done;\n\n\t\t\t\tif (gadget->otg_caps &&\n\t\t\t\t\t(gadget->otg_caps->otg_rev >= 0x0200))\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg20_descriptor);\n\t\t\t\telse\n\t\t\t\t\totg_desc_len += sizeof(\n\t\t\t\t\t\tstruct usb_otg_descriptor);\n\n\t\t\t\tvalue = min_t(int, w_length, otg_desc_len);\n\t\t\t\tmemcpy(req->buf, config->descriptors[0], value);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\t/* any number of configs can work */\n\tcase USB_REQ_SET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != 0)\n\t\t\tgoto unknown;\n\t\tif (gadget_is_otg(gadget)) {\n\t\t\tif (gadget->a_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP available\\n\");\n\t\t\telse if (gadget->a_alt_hnp_support)\n\t\t\t\tDBG(cdev, \"HNP on another port\\n\");\n\t\t\telse\n\t\t\t\tVDBG(cdev, \"HNP inactive\\n\");\n\t\t}\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = set_config(cdev, ctrl, w_value);\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_CONFIGURATION:\n\t\tif (ctrl->bRequestType != USB_DIR_IN)\n\t\t\tgoto unknown;\n\t\tif (cdev->config)\n\t\t\t*(u8 *)req->buf = cdev->config->bConfigurationValue;\n\t\telse\n\t\t\t*(u8 *)req->buf = 0;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\n\t/* function drivers must handle get/set altsetting */\n\tcase USB_REQ_SET_INTERFACE:\n\t\tif (ctrl->bRequestType != USB_RECIP_INTERFACE)\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If there's no get_alt() method, we know only altsetting zero\n\t\t * works. There is no need to check if set_alt() is not NULL\n\t\t * as we check this in usb_add_function().\n\t\t */\n\t\tif (w_value && !f->get_alt)\n\t\t\tbreak;\n\n\t\tspin_lock(&cdev->lock);\n\t\tvalue = f->set_alt(f, w_index, w_value);\n\t\tif (value == USB_GADGET_DELAYED_STATUS) {\n\t\t\tDBG(cdev,\n\t\t\t \"%s: interface %d (%s) requested delayed status\\n\",\n\t\t\t\t\t__func__, intf, f->name);\n\t\t\tcdev->delayed_status++;\n\t\t\tDBG(cdev, \"delayed_status count %d\\n\",\n\t\t\t\t\tcdev->delayed_status);\n\t\t}\n\t\tspin_unlock(&cdev->lock);\n\t\tbreak;\n\tcase USB_REQ_GET_INTERFACE:\n\t\tif (ctrl->bRequestType != (USB_DIR_IN|USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\t/* lots of interfaces only need altsetting zero... */\n\t\tvalue = f->get_alt ? f->get_alt(f, w_index) : 0;\n\t\tif (value < 0)\n\t\t\tbreak;\n\t\t*((u8 *)req->buf) = value;\n\t\tvalue = min(w_length, (u16) 1);\n\t\tbreak;\n\tcase USB_REQ_GET_STATUS:\n\t\tif (gadget_is_otg(gadget) && gadget->hnp_polling_support &&\n\t\t\t\t\t\t(w_index == OTG_STS_SELECTOR)) {\n\t\t\tif (ctrl->bRequestType != (USB_DIR_IN |\n\t\t\t\t\t\t\tUSB_RECIP_DEVICE))\n\t\t\t\tgoto unknown;\n\t\t\t*((u8 *)req->buf) = gadget->host_request_flag;\n\t\t\tvalue = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * USB 3.0 additions:\n\t\t * Function driver should handle get_status request. If such cb\n\t\t * wasn't supplied we respond with default value = 0\n\t\t * Note: function driver should supply such cb only for the\n\t\t * first interface of the function\n\t\t */\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_IN | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tvalue = 2;\t/* This is the length of the get_status reply */\n\t\tput_unaligned_le16(0, req->buf);\n\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\tbreak;\n\t\tf = cdev->config->interface[intf];\n\t\tif (!f)\n\t\t\tbreak;\n\t\tstatus = f->get_status ? f->get_status(f) : 0;\n\t\tif (status < 0)\n\t\t\tbreak;\n\t\tput_unaligned_le16(status & 0x0000ffff, req->buf);\n\t\tbreak;\n\t/*\n\t * Function drivers should handle SetFeature/ClearFeature\n\t * (FUNCTION_SUSPEND) request. function_suspend cb should be supplied\n\t * only for the first interface of the function\n\t */\n\tcase USB_REQ_CLEAR_FEATURE:\n\tcase USB_REQ_SET_FEATURE:\n\t\tif (!gadget_is_superspeed(gadget))\n\t\t\tgoto unknown;\n\t\tif (ctrl->bRequestType != (USB_DIR_OUT | USB_RECIP_INTERFACE))\n\t\t\tgoto unknown;\n\t\tswitch (w_value) {\n\t\tcase USB_INTRF_FUNC_SUSPEND:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tif (!f)\n\t\t\t\tbreak;\n\t\t\tvalue = 0;\n\t\t\tif (f->func_suspend)\n\t\t\t\tvalue = f->func_suspend(f, w_index >> 8);\n\t\t\tif (value < 0) {\n\t\t\t\tERROR(cdev,\n\t\t\t\t      \"func_suspend() returned error %d\\n\",\n\t\t\t\t      value);\n\t\t\t\tvalue = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\nunknown:\n\t\t/*\n\t\t * OS descriptors handling\n\t\t */\n\t\tif (cdev->use_os_string && cdev->os_desc_config &&\n\t\t    (ctrl->bRequestType & USB_TYPE_VENDOR) &&\n\t\t    ctrl->bRequest == cdev->b_vendor_code) {\n\t\t\tstruct usb_configuration\t*os_desc_cfg;\n\t\t\tu8\t\t\t\t*buf;\n\t\t\tint\t\t\t\tinterface;\n\t\t\tint\t\t\t\tcount = 0;\n\n\t\t\treq = cdev->os_desc_req;\n\t\t\treq->context = cdev;\n\t\t\treq->complete = composite_setup_complete;\n\t\t\tbuf = req->buf;\n\t\t\tos_desc_cfg = cdev->os_desc_config;\n\t\t\tw_length = min_t(u16, w_length, USB_COMP_EP0_OS_DESC_BUFSIZ);\n\t\t\tmemset(buf, 0, w_length);\n\t\t\tbuf[5] = 0x01;\n\t\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\t\tcase USB_RECIP_DEVICE:\n\t\t\t\tif (w_index != 0x4 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\t/* Number of ext compat interfaces */\n\t\t\t\tcount = count_ext_compat(os_desc_cfg);\n\t\t\t\tbuf[8] = count;\n\t\t\t\tcount *= 24; /* 24 B/ext compat desc */\n\t\t\t\tcount += 16; /* header */\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x10) {\n\t\t\t\t\tvalue = fill_ext_compat(os_desc_cfg, buf);\n\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase USB_RECIP_INTERFACE:\n\t\t\t\tif (w_index != 0x5 || (w_value >> 8))\n\t\t\t\t\tbreak;\n\t\t\t\tinterface = w_value & 0xFF;\n\t\t\t\tif (interface >= MAX_CONFIG_INTERFACES ||\n\t\t\t\t    !os_desc_cfg->interface[interface])\n\t\t\t\t\tbreak;\n\t\t\t\tbuf[6] = w_index;\n\t\t\t\tcount = count_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le16(count, buf + 8);\n\t\t\t\tcount = len_ext_prop(os_desc_cfg,\n\t\t\t\t\tinterface);\n\t\t\t\tput_unaligned_le32(count, buf);\n\t\t\t\tvalue = w_length;\n\t\t\t\tif (w_length > 0x0A) {\n\t\t\t\t\tvalue = fill_ext_prop(os_desc_cfg,\n\t\t\t\t\t\t\t      interface, buf);\n\t\t\t\t\tif (value >= 0)\n\t\t\t\t\t\tvalue = min_t(u16, w_length, value);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tgoto check_value;\n\t\t}\n\n\t\tVDBG(cdev,\n\t\t\t\"non-core control req%02x.%02x v%04x i%04x l%d\\n\",\n\t\t\tctrl->bRequestType, ctrl->bRequest,\n\t\t\tw_value, w_index, w_length);\n\n\t\t/* functions always handle their interfaces and endpoints...\n\t\t * punt other recipients (other, WUSB, ...) to the current\n\t\t * configuration code.\n\t\t */\n\t\tif (cdev->config) {\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list)\n\t\t\t\tif (f->req_match &&\n\t\t\t\t    f->req_match(f, ctrl, false))\n\t\t\t\t\tgoto try_fun_setup;\n\t\t} else {\n\t\t\tstruct usb_configuration *c;\n\t\t\tlist_for_each_entry(c, &cdev->configs, list)\n\t\t\t\tlist_for_each_entry(f, &c->functions, list)\n\t\t\t\t\tif (f->req_match &&\n\t\t\t\t\t    f->req_match(f, ctrl, true))\n\t\t\t\t\t\tgoto try_fun_setup;\n\t\t}\n\t\tf = NULL;\n\n\t\tswitch (ctrl->bRequestType & USB_RECIP_MASK) {\n\t\tcase USB_RECIP_INTERFACE:\n\t\t\tif (!cdev->config || intf >= MAX_CONFIG_INTERFACES)\n\t\t\t\tbreak;\n\t\t\tf = cdev->config->interface[intf];\n\t\t\tbreak;\n\n\t\tcase USB_RECIP_ENDPOINT:\n\t\t\tif (!cdev->config)\n\t\t\t\tbreak;\n\t\t\tendp = ((w_index & 0x80) >> 3) | (w_index & 0x0f);\n\t\t\tlist_for_each_entry(f, &cdev->config->functions, list) {\n\t\t\t\tif (test_bit(endp, f->endpoints))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (&f->list == &cdev->config->functions)\n\t\t\t\tf = NULL;\n\t\t\tbreak;\n\t\t}\ntry_fun_setup:\n\t\tif (f && f->setup)\n\t\t\tvalue = f->setup(f, ctrl);\n\t\telse {\n\t\t\tstruct usb_configuration\t*c;\n\n\t\t\tc = cdev->config;\n\t\t\tif (!c)\n\t\t\t\tgoto done;\n\n\t\t\t/* try current config's setup */\n\t\t\tif (c->setup) {\n\t\t\t\tvalue = c->setup(c, ctrl);\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* try the only function in the current config */\n\t\t\tif (!list_is_singular(&c->functions))\n\t\t\t\tgoto done;\n\t\t\tf = list_first_entry(&c->functions, struct usb_function,\n\t\t\t\t\t     list);\n\t\t\tif (f->setup)\n\t\t\t\tvalue = f->setup(f, ctrl);\n\t\t}\n\n\t\tgoto done;\n\t}\n\ncheck_value:\n\t/* respond with data transfer before status phase? */\n\tif (value >= 0 && value != USB_GADGET_DELAYED_STATUS) {\n\t\treq->length = value;\n\t\treq->context = cdev;\n\t\treq->zero = value < w_length;\n\t\tvalue = composite_ep0_queue(cdev, req, GFP_ATOMIC);\n\t\tif (value < 0) {\n\t\t\tDBG(cdev, \"ep_queue --> %d\\n\", value);\n\t\t\treq->status = 0;\n\t\t\tcomposite_setup_complete(gadget->ep0, req);\n\t\t}\n\t} else if (value == USB_GADGET_DELAYED_STATUS && w_length != 0) {\n\t\tWARN(cdev,\n\t\t\t\"%s: Delayed status not supported for w_length != 0\",\n\t\t\t__func__);\n\t}\n\ndone:\n\t/* device either stalls (value < 0) or reports success */\n\treturn value;\n}",
        "patch": "--- code before\n+++ code after\n@@ -308,6 +308,9 @@\n \t\t\t\tif (w_index != 0x5 || (w_value >> 8))\n \t\t\t\t\tbreak;\n \t\t\t\tinterface = w_value & 0xFF;\n+\t\t\t\tif (interface >= MAX_CONFIG_INTERFACES ||\n+\t\t\t\t    !os_desc_cfg->interface[interface])\n+\t\t\t\t\tbreak;\n \t\t\t\tbuf[6] = w_index;\n \t\t\t\tcount = count_ext_prop(os_desc_cfg,\n \t\t\t\t\tinterface);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tif (interface >= MAX_CONFIG_INTERFACES ||",
                "\t\t\t\t    !os_desc_cfg->interface[interface])",
                "\t\t\t\t\tbreak;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in drivers/usb/gadget/composite.c in the Linux kernel before 5.16.10. The USB Gadget subsystem lacks certain validation of interface OS descriptor requests (ones with a large array index and ones associated with NULL function pointer retrieval). Memory corruption might occur.",
        "id": 3475
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static bool check_reg_sane_offset(struct bpf_verifier_env *env,\n\t\t\t\t  const struct bpf_reg_state *reg,\n\t\t\t\t  enum bpf_reg_type type)\n{\n\tbool known = tnum_is_const(reg->var_off);\n\ts64 val = reg->var_off.value;\n\ts64 smin = reg->smin_value;\n\n\tif (known && (val >= BPF_MAX_VAR_OFF || val <= -BPF_MAX_VAR_OFF)) {\n\t\tverbose(env, \"math between %s pointer and %lld is not allowed\\n\",\n\t\t\treg_type_str[type], val);\n\t\treturn false;\n\t}\n\n\tif (reg->off >= BPF_MAX_VAR_OFF || reg->off <= -BPF_MAX_VAR_OFF) {\n\t\tverbose(env, \"%s pointer offset %d is not allowed\\n\",\n\t\t\treg_type_str[type], reg->off);\n\t\treturn false;\n\t}\n\n\tif (smin == S64_MIN) {\n\t\tverbose(env, \"math between %s pointer and register with unbounded min value is not allowed\\n\",\n\t\t\treg_type_str[type]);\n\t\treturn false;\n\t}\n\n\tif (smin >= BPF_MAX_VAR_OFF || smin <= -BPF_MAX_VAR_OFF) {\n\t\tverbose(env, \"value %lld makes %s pointer be out of bounds\\n\",\n\t\t\tsmin, reg_type_str[type]);\n\t\treturn false;\n\t}\n\n\treturn true;\n}",
        "code_after_change": "static bool check_reg_sane_offset(struct bpf_verifier_env *env,\n\t\t\t\t  const struct bpf_reg_state *reg,\n\t\t\t\t  enum bpf_reg_type type)\n{\n\tbool known = tnum_is_const(reg->var_off);\n\ts64 val = reg->var_off.value;\n\ts64 smin = reg->smin_value;\n\n\tif (known && (val >= BPF_MAX_VAR_OFF || val <= -BPF_MAX_VAR_OFF)) {\n\t\tverbose(env, \"math between %s pointer and %lld is not allowed\\n\",\n\t\t\treg_type_str(env, type), val);\n\t\treturn false;\n\t}\n\n\tif (reg->off >= BPF_MAX_VAR_OFF || reg->off <= -BPF_MAX_VAR_OFF) {\n\t\tverbose(env, \"%s pointer offset %d is not allowed\\n\",\n\t\t\treg_type_str(env, type), reg->off);\n\t\treturn false;\n\t}\n\n\tif (smin == S64_MIN) {\n\t\tverbose(env, \"math between %s pointer and register with unbounded min value is not allowed\\n\",\n\t\t\treg_type_str(env, type));\n\t\treturn false;\n\t}\n\n\tif (smin >= BPF_MAX_VAR_OFF || smin <= -BPF_MAX_VAR_OFF) {\n\t\tverbose(env, \"value %lld makes %s pointer be out of bounds\\n\",\n\t\t\tsmin, reg_type_str(env, type));\n\t\treturn false;\n\t}\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,25 +8,25 @@\n \n \tif (known && (val >= BPF_MAX_VAR_OFF || val <= -BPF_MAX_VAR_OFF)) {\n \t\tverbose(env, \"math between %s pointer and %lld is not allowed\\n\",\n-\t\t\treg_type_str[type], val);\n+\t\t\treg_type_str(env, type), val);\n \t\treturn false;\n \t}\n \n \tif (reg->off >= BPF_MAX_VAR_OFF || reg->off <= -BPF_MAX_VAR_OFF) {\n \t\tverbose(env, \"%s pointer offset %d is not allowed\\n\",\n-\t\t\treg_type_str[type], reg->off);\n+\t\t\treg_type_str(env, type), reg->off);\n \t\treturn false;\n \t}\n \n \tif (smin == S64_MIN) {\n \t\tverbose(env, \"math between %s pointer and register with unbounded min value is not allowed\\n\",\n-\t\t\treg_type_str[type]);\n+\t\t\treg_type_str(env, type));\n \t\treturn false;\n \t}\n \n \tif (smin >= BPF_MAX_VAR_OFF || smin <= -BPF_MAX_VAR_OFF) {\n \t\tverbose(env, \"value %lld makes %s pointer be out of bounds\\n\",\n-\t\t\tsmin, reg_type_str[type]);\n+\t\t\tsmin, reg_type_str(env, type));\n \t\treturn false;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\treg_type_str(env, type), val);",
                "\t\t\treg_type_str(env, type), reg->off);",
                "\t\t\treg_type_str(env, type));",
                "\t\t\tsmin, reg_type_str(env, type));"
            ],
            "deleted": [
                "\t\t\treg_type_str[type], val);",
                "\t\t\treg_type_str[type], reg->off);",
                "\t\t\treg_type_str[type]);",
                "\t\t\tsmin, reg_type_str[type]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3458
    },
    {
        "cve_id": "CVE-2019-15221",
        "code_before_change": "int line6_init_pcm(struct usb_line6 *line6,\n\t\t   struct line6_pcm_properties *properties)\n{\n\tint i, err;\n\tunsigned ep_read = line6->properties->ep_audio_r;\n\tunsigned ep_write = line6->properties->ep_audio_w;\n\tstruct snd_pcm *pcm;\n\tstruct snd_line6_pcm *line6pcm;\n\n\tif (!(line6->properties->capabilities & LINE6_CAP_PCM))\n\t\treturn 0;\t/* skip PCM initialization and report success */\n\n\terr = snd_line6_new_pcm(line6, &pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\tline6pcm = kzalloc(sizeof(*line6pcm), GFP_KERNEL);\n\tif (!line6pcm)\n\t\treturn -ENOMEM;\n\n\tmutex_init(&line6pcm->state_mutex);\n\tline6pcm->pcm = pcm;\n\tline6pcm->properties = properties;\n\tline6pcm->volume_playback[0] = line6pcm->volume_playback[1] = 255;\n\tline6pcm->volume_monitor = 255;\n\tline6pcm->line6 = line6;\n\n\tline6pcm->max_packet_size_in =\n\t\tusb_maxpacket(line6->usbdev,\n\t\t\tusb_rcvisocpipe(line6->usbdev, ep_read), 0);\n\tline6pcm->max_packet_size_out =\n\t\tusb_maxpacket(line6->usbdev,\n\t\t\tusb_sndisocpipe(line6->usbdev, ep_write), 1);\n\n\tspin_lock_init(&line6pcm->out.lock);\n\tspin_lock_init(&line6pcm->in.lock);\n\tline6pcm->impulse_period = LINE6_IMPULSE_DEFAULT_PERIOD;\n\n\tline6->line6pcm = line6pcm;\n\n\tpcm->private_data = line6pcm;\n\tpcm->private_free = line6_cleanup_pcm;\n\n\terr = line6_create_audio_out_urbs(line6pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = line6_create_audio_in_urbs(line6pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* mixer: */\n\tfor (i = 0; i < ARRAY_SIZE(line6_controls); i++) {\n\t\terr = snd_ctl_add(line6->card,\n\t\t\t\t  snd_ctl_new1(&line6_controls[i], line6pcm));\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "int line6_init_pcm(struct usb_line6 *line6,\n\t\t   struct line6_pcm_properties *properties)\n{\n\tint i, err;\n\tunsigned ep_read = line6->properties->ep_audio_r;\n\tunsigned ep_write = line6->properties->ep_audio_w;\n\tstruct snd_pcm *pcm;\n\tstruct snd_line6_pcm *line6pcm;\n\n\tif (!(line6->properties->capabilities & LINE6_CAP_PCM))\n\t\treturn 0;\t/* skip PCM initialization and report success */\n\n\terr = snd_line6_new_pcm(line6, &pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\tline6pcm = kzalloc(sizeof(*line6pcm), GFP_KERNEL);\n\tif (!line6pcm)\n\t\treturn -ENOMEM;\n\n\tmutex_init(&line6pcm->state_mutex);\n\tline6pcm->pcm = pcm;\n\tline6pcm->properties = properties;\n\tline6pcm->volume_playback[0] = line6pcm->volume_playback[1] = 255;\n\tline6pcm->volume_monitor = 255;\n\tline6pcm->line6 = line6;\n\n\tline6pcm->max_packet_size_in =\n\t\tusb_maxpacket(line6->usbdev,\n\t\t\tusb_rcvisocpipe(line6->usbdev, ep_read), 0);\n\tline6pcm->max_packet_size_out =\n\t\tusb_maxpacket(line6->usbdev,\n\t\t\tusb_sndisocpipe(line6->usbdev, ep_write), 1);\n\tif (!line6pcm->max_packet_size_in || !line6pcm->max_packet_size_out) {\n\t\tdev_err(line6pcm->line6->ifcdev,\n\t\t\t\"cannot get proper max packet size\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tspin_lock_init(&line6pcm->out.lock);\n\tspin_lock_init(&line6pcm->in.lock);\n\tline6pcm->impulse_period = LINE6_IMPULSE_DEFAULT_PERIOD;\n\n\tline6->line6pcm = line6pcm;\n\n\tpcm->private_data = line6pcm;\n\tpcm->private_free = line6_cleanup_pcm;\n\n\terr = line6_create_audio_out_urbs(line6pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = line6_create_audio_in_urbs(line6pcm);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* mixer: */\n\tfor (i = 0; i < ARRAY_SIZE(line6_controls); i++) {\n\t\terr = snd_ctl_add(line6->card,\n\t\t\t\t  snd_ctl_new1(&line6_controls[i], line6pcm));\n\t\tif (err < 0)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,6 +31,11 @@\n \tline6pcm->max_packet_size_out =\n \t\tusb_maxpacket(line6->usbdev,\n \t\t\tusb_sndisocpipe(line6->usbdev, ep_write), 1);\n+\tif (!line6pcm->max_packet_size_in || !line6pcm->max_packet_size_out) {\n+\t\tdev_err(line6pcm->line6->ifcdev,\n+\t\t\t\"cannot get proper max packet size\\n\");\n+\t\treturn -EINVAL;\n+\t}\n \n \tspin_lock_init(&line6pcm->out.lock);\n \tspin_lock_init(&line6pcm->in.lock);",
        "function_modified_lines": {
            "added": [
                "\tif (!line6pcm->max_packet_size_in || !line6pcm->max_packet_size_out) {",
                "\t\tdev_err(line6pcm->line6->ifcdev,",
                "\t\t\t\"cannot get proper max packet size\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.17. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/line6/pcm.c driver.",
        "id": 2006
    },
    {
        "cve_id": "CVE-2019-19037",
        "code_before_change": "bool ext4_empty_dir(struct inode *inode)\n{\n\tunsigned int offset;\n\tstruct buffer_head *bh;\n\tstruct ext4_dir_entry_2 *de, *de1;\n\tstruct super_block *sb;\n\n\tif (ext4_has_inline_data(inode)) {\n\t\tint has_inline_data = 1;\n\t\tint ret;\n\n\t\tret = empty_inline_dir(inode, &has_inline_data);\n\t\tif (has_inline_data)\n\t\t\treturn ret;\n\t}\n\n\tsb = inode->i_sb;\n\tif (inode->i_size < EXT4_DIR_REC_LEN(1) + EXT4_DIR_REC_LEN(2)) {\n\t\tEXT4_ERROR_INODE(inode, \"invalid size\");\n\t\treturn true;\n\t}\n\t/* The first directory block must not be a hole,\n\t * so treat it as DIRENT_HTREE\n\t */\n\tbh = ext4_read_dirblock(inode, 0, DIRENT_HTREE);\n\tif (IS_ERR(bh))\n\t\treturn true;\n\n\tde = (struct ext4_dir_entry_2 *) bh->b_data;\n\tde1 = ext4_next_entry(de, sb->s_blocksize);\n\tif (le32_to_cpu(de->inode) != inode->i_ino ||\n\t\t\tle32_to_cpu(de1->inode) == 0 ||\n\t\t\tstrcmp(\".\", de->name) || strcmp(\"..\", de1->name)) {\n\t\text4_warning_inode(inode, \"directory missing '.' and/or '..'\");\n\t\tbrelse(bh);\n\t\treturn true;\n\t}\n\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize) +\n\t\t ext4_rec_len_from_disk(de1->rec_len, sb->s_blocksize);\n\tde = ext4_next_entry(de1, sb->s_blocksize);\n\twhile (offset < inode->i_size) {\n\t\tif ((void *) de >= (void *) (bh->b_data+sb->s_blocksize)) {\n\t\t\tunsigned int lblock;\n\t\t\tbrelse(bh);\n\t\t\tlblock = offset >> EXT4_BLOCK_SIZE_BITS(sb);\n\t\t\tbh = ext4_read_dirblock(inode, lblock, EITHER);\n\t\t\tif (bh == NULL) {\n\t\t\t\toffset += sb->s_blocksize;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (IS_ERR(bh))\n\t\t\t\treturn true;\n\t\t\tde = (struct ext4_dir_entry_2 *) bh->b_data;\n\t\t}\n\t\tif (ext4_check_dir_entry(inode, NULL, de, bh,\n\t\t\t\t\t bh->b_data, bh->b_size, offset)) {\n\t\t\tde = (struct ext4_dir_entry_2 *)(bh->b_data +\n\t\t\t\t\t\t\t sb->s_blocksize);\n\t\t\toffset = (offset | (sb->s_blocksize - 1)) + 1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (le32_to_cpu(de->inode)) {\n\t\t\tbrelse(bh);\n\t\t\treturn false;\n\t\t}\n\t\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n\t\tde = ext4_next_entry(de, sb->s_blocksize);\n\t}\n\tbrelse(bh);\n\treturn true;\n}",
        "code_after_change": "bool ext4_empty_dir(struct inode *inode)\n{\n\tunsigned int offset;\n\tstruct buffer_head *bh;\n\tstruct ext4_dir_entry_2 *de;\n\tstruct super_block *sb;\n\n\tif (ext4_has_inline_data(inode)) {\n\t\tint has_inline_data = 1;\n\t\tint ret;\n\n\t\tret = empty_inline_dir(inode, &has_inline_data);\n\t\tif (has_inline_data)\n\t\t\treturn ret;\n\t}\n\n\tsb = inode->i_sb;\n\tif (inode->i_size < EXT4_DIR_REC_LEN(1) + EXT4_DIR_REC_LEN(2)) {\n\t\tEXT4_ERROR_INODE(inode, \"invalid size\");\n\t\treturn true;\n\t}\n\t/* The first directory block must not be a hole,\n\t * so treat it as DIRENT_HTREE\n\t */\n\tbh = ext4_read_dirblock(inode, 0, DIRENT_HTREE);\n\tif (IS_ERR(bh))\n\t\treturn true;\n\n\tde = (struct ext4_dir_entry_2 *) bh->b_data;\n\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,\n\t\t\t\t 0) ||\n\t    le32_to_cpu(de->inode) != inode->i_ino || strcmp(\".\", de->name)) {\n\t\text4_warning_inode(inode, \"directory missing '.'\");\n\t\tbrelse(bh);\n\t\treturn true;\n\t}\n\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n\tde = ext4_next_entry(de, sb->s_blocksize);\n\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,\n\t\t\t\t offset) ||\n\t    le32_to_cpu(de->inode) == 0 || strcmp(\"..\", de->name)) {\n\t\text4_warning_inode(inode, \"directory missing '..'\");\n\t\tbrelse(bh);\n\t\treturn true;\n\t}\n\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n\twhile (offset < inode->i_size) {\n\t\tif (!(offset & (sb->s_blocksize - 1))) {\n\t\t\tunsigned int lblock;\n\t\t\tbrelse(bh);\n\t\t\tlblock = offset >> EXT4_BLOCK_SIZE_BITS(sb);\n\t\t\tbh = ext4_read_dirblock(inode, lblock, EITHER);\n\t\t\tif (bh == NULL) {\n\t\t\t\toffset += sb->s_blocksize;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (IS_ERR(bh))\n\t\t\t\treturn true;\n\t\t}\n\t\tde = (struct ext4_dir_entry_2 *) (bh->b_data +\n\t\t\t\t\t(offset & (sb->s_blocksize - 1)));\n\t\tif (ext4_check_dir_entry(inode, NULL, de, bh,\n\t\t\t\t\t bh->b_data, bh->b_size, offset)) {\n\t\t\toffset = (offset | (sb->s_blocksize - 1)) + 1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (le32_to_cpu(de->inode)) {\n\t\t\tbrelse(bh);\n\t\t\treturn false;\n\t\t}\n\t\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n\t}\n\tbrelse(bh);\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n {\n \tunsigned int offset;\n \tstruct buffer_head *bh;\n-\tstruct ext4_dir_entry_2 *de, *de1;\n+\tstruct ext4_dir_entry_2 *de;\n \tstruct super_block *sb;\n \n \tif (ext4_has_inline_data(inode)) {\n@@ -27,19 +27,25 @@\n \t\treturn true;\n \n \tde = (struct ext4_dir_entry_2 *) bh->b_data;\n-\tde1 = ext4_next_entry(de, sb->s_blocksize);\n-\tif (le32_to_cpu(de->inode) != inode->i_ino ||\n-\t\t\tle32_to_cpu(de1->inode) == 0 ||\n-\t\t\tstrcmp(\".\", de->name) || strcmp(\"..\", de1->name)) {\n-\t\text4_warning_inode(inode, \"directory missing '.' and/or '..'\");\n+\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,\n+\t\t\t\t 0) ||\n+\t    le32_to_cpu(de->inode) != inode->i_ino || strcmp(\".\", de->name)) {\n+\t\text4_warning_inode(inode, \"directory missing '.'\");\n \t\tbrelse(bh);\n \t\treturn true;\n \t}\n-\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize) +\n-\t\t ext4_rec_len_from_disk(de1->rec_len, sb->s_blocksize);\n-\tde = ext4_next_entry(de1, sb->s_blocksize);\n+\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n+\tde = ext4_next_entry(de, sb->s_blocksize);\n+\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,\n+\t\t\t\t offset) ||\n+\t    le32_to_cpu(de->inode) == 0 || strcmp(\"..\", de->name)) {\n+\t\text4_warning_inode(inode, \"directory missing '..'\");\n+\t\tbrelse(bh);\n+\t\treturn true;\n+\t}\n+\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n \twhile (offset < inode->i_size) {\n-\t\tif ((void *) de >= (void *) (bh->b_data+sb->s_blocksize)) {\n+\t\tif (!(offset & (sb->s_blocksize - 1))) {\n \t\t\tunsigned int lblock;\n \t\t\tbrelse(bh);\n \t\t\tlblock = offset >> EXT4_BLOCK_SIZE_BITS(sb);\n@@ -50,12 +56,11 @@\n \t\t\t}\n \t\t\tif (IS_ERR(bh))\n \t\t\t\treturn true;\n-\t\t\tde = (struct ext4_dir_entry_2 *) bh->b_data;\n \t\t}\n+\t\tde = (struct ext4_dir_entry_2 *) (bh->b_data +\n+\t\t\t\t\t(offset & (sb->s_blocksize - 1)));\n \t\tif (ext4_check_dir_entry(inode, NULL, de, bh,\n \t\t\t\t\t bh->b_data, bh->b_size, offset)) {\n-\t\t\tde = (struct ext4_dir_entry_2 *)(bh->b_data +\n-\t\t\t\t\t\t\t sb->s_blocksize);\n \t\t\toffset = (offset | (sb->s_blocksize - 1)) + 1;\n \t\t\tcontinue;\n \t\t}\n@@ -64,7 +69,6 @@\n \t\t\treturn false;\n \t\t}\n \t\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);\n-\t\tde = ext4_next_entry(de, sb->s_blocksize);\n \t}\n \tbrelse(bh);\n \treturn true;",
        "function_modified_lines": {
            "added": [
                "\tstruct ext4_dir_entry_2 *de;",
                "\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,",
                "\t\t\t\t 0) ||",
                "\t    le32_to_cpu(de->inode) != inode->i_ino || strcmp(\".\", de->name)) {",
                "\t\text4_warning_inode(inode, \"directory missing '.'\");",
                "\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);",
                "\tde = ext4_next_entry(de, sb->s_blocksize);",
                "\tif (ext4_check_dir_entry(inode, NULL, de, bh, bh->b_data, bh->b_size,",
                "\t\t\t\t offset) ||",
                "\t    le32_to_cpu(de->inode) == 0 || strcmp(\"..\", de->name)) {",
                "\t\text4_warning_inode(inode, \"directory missing '..'\");",
                "\t\tbrelse(bh);",
                "\t\treturn true;",
                "\t}",
                "\toffset += ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize);",
                "\t\tif (!(offset & (sb->s_blocksize - 1))) {",
                "\t\tde = (struct ext4_dir_entry_2 *) (bh->b_data +",
                "\t\t\t\t\t(offset & (sb->s_blocksize - 1)));"
            ],
            "deleted": [
                "\tstruct ext4_dir_entry_2 *de, *de1;",
                "\tde1 = ext4_next_entry(de, sb->s_blocksize);",
                "\tif (le32_to_cpu(de->inode) != inode->i_ino ||",
                "\t\t\tle32_to_cpu(de1->inode) == 0 ||",
                "\t\t\tstrcmp(\".\", de->name) || strcmp(\"..\", de1->name)) {",
                "\t\text4_warning_inode(inode, \"directory missing '.' and/or '..'\");",
                "\toffset = ext4_rec_len_from_disk(de->rec_len, sb->s_blocksize) +",
                "\t\t ext4_rec_len_from_disk(de1->rec_len, sb->s_blocksize);",
                "\tde = ext4_next_entry(de1, sb->s_blocksize);",
                "\t\tif ((void *) de >= (void *) (bh->b_data+sb->s_blocksize)) {",
                "\t\t\tde = (struct ext4_dir_entry_2 *) bh->b_data;",
                "\t\t\tde = (struct ext4_dir_entry_2 *)(bh->b_data +",
                "\t\t\t\t\t\t\t sb->s_blocksize);",
                "\t\tde = ext4_next_entry(de, sb->s_blocksize);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "ext4_empty_dir in fs/ext4/namei.c in the Linux kernel through 5.3.12 allows a NULL pointer dereference because ext4_read_dirblock(inode,0,DIRENT_HTREE) can be zero.",
        "id": 2122
    },
    {
        "cve_id": "CVE-2023-2166",
        "code_before_change": "static int canfd_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t     struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canfd_skb(skb)))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN FD skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "code_after_change": "static int canfd_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t     struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canfd_skb(skb))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN FD skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static int canfd_rcv(struct sk_buff *skb, struct net_device *dev,\n \t\t     struct packet_type *pt, struct net_device *orig_dev)\n {\n-\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canfd_skb(skb)))) {\n+\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canfd_skb(skb))) {\n \t\tpr_warn_once(\"PF_CAN: dropped non conform CAN FD skbuff: dev type %d, len %d\\n\",\n \t\t\t     dev->type, skb->len);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_canfd_skb(skb))) {"
            ],
            "deleted": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_canfd_skb(skb)))) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference issue was found in can protocol in net/can/af_can.c in the Linux before Linux. ml_priv may not be initialized in the receive path of CAN frames. A local user could use this flaw to crash the system or potentially cause a denial of service.",
        "id": 3927
    },
    {
        "cve_id": "CVE-2016-9313",
        "code_before_change": "static int __init big_key_init(void)\n{\n\treturn register_key_type(&key_type_big_key);\n}",
        "code_after_change": "static int __init big_key_init(void)\n{\n\tstruct crypto_skcipher *cipher;\n\tstruct crypto_rng *rng;\n\tint ret;\n\n\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n\tif (IS_ERR(rng)) {\n\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n\t\treturn PTR_ERR(rng);\n\t}\n\n\tbig_key_rng = rng;\n\n\t/* seed RNG */\n\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n\tif (ret) {\n\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\t/* init block cipher */\n\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(cipher)) {\n\t\tret = PTR_ERR(cipher);\n\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\tbig_key_skcipher = cipher;\n\n\tret = register_key_type(&key_type_big_key);\n\tif (ret < 0) {\n\t\tpr_err(\"Can't register type: %d\\n\", ret);\n\t\tgoto error_cipher;\n\t}\n\n\treturn 0;\n\nerror_cipher:\n\tcrypto_free_skcipher(big_key_skcipher);\nerror_rng:\n\tcrypto_free_rng(big_key_rng);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,45 @@\n static int __init big_key_init(void)\n {\n-\treturn register_key_type(&key_type_big_key);\n+\tstruct crypto_skcipher *cipher;\n+\tstruct crypto_rng *rng;\n+\tint ret;\n+\n+\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n+\tif (IS_ERR(rng)) {\n+\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n+\t\treturn PTR_ERR(rng);\n+\t}\n+\n+\tbig_key_rng = rng;\n+\n+\t/* seed RNG */\n+\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n+\tif (ret) {\n+\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n+\t\tgoto error_rng;\n+\t}\n+\n+\t/* init block cipher */\n+\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n+\tif (IS_ERR(cipher)) {\n+\t\tret = PTR_ERR(cipher);\n+\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n+\t\tgoto error_rng;\n+\t}\n+\n+\tbig_key_skcipher = cipher;\n+\n+\tret = register_key_type(&key_type_big_key);\n+\tif (ret < 0) {\n+\t\tpr_err(\"Can't register type: %d\\n\", ret);\n+\t\tgoto error_cipher;\n+\t}\n+\n+\treturn 0;\n+\n+error_cipher:\n+\tcrypto_free_skcipher(big_key_skcipher);\n+error_rng:\n+\tcrypto_free_rng(big_key_rng);\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct crypto_skcipher *cipher;",
                "\tstruct crypto_rng *rng;",
                "\tint ret;",
                "",
                "\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);",
                "\tif (IS_ERR(rng)) {",
                "\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));",
                "\t\treturn PTR_ERR(rng);",
                "\t}",
                "",
                "\tbig_key_rng = rng;",
                "",
                "\t/* seed RNG */",
                "\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));",
                "\tif (ret) {",
                "\t\tpr_err(\"Can't reset rng: %d\\n\", ret);",
                "\t\tgoto error_rng;",
                "\t}",
                "",
                "\t/* init block cipher */",
                "\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);",
                "\tif (IS_ERR(cipher)) {",
                "\t\tret = PTR_ERR(cipher);",
                "\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);",
                "\t\tgoto error_rng;",
                "\t}",
                "",
                "\tbig_key_skcipher = cipher;",
                "",
                "\tret = register_key_type(&key_type_big_key);",
                "\tif (ret < 0) {",
                "\t\tpr_err(\"Can't register type: %d\\n\", ret);",
                "\t\tgoto error_cipher;",
                "\t}",
                "",
                "\treturn 0;",
                "",
                "error_cipher:",
                "\tcrypto_free_skcipher(big_key_skcipher);",
                "error_rng:",
                "\tcrypto_free_rng(big_key_rng);",
                "\treturn ret;"
            ],
            "deleted": [
                "\treturn register_key_type(&key_type_big_key);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "security/keys/big_key.c in the Linux kernel before 4.8.7 mishandles unsuccessful crypto registration in conjunction with successful key-type registration, which allows local users to cause a denial of service (NULL pointer dereference and panic) or possibly have unspecified other impact via a crafted application that uses the big_key data type.",
        "id": 1144
    },
    {
        "cve_id": "CVE-2020-27830",
        "code_before_change": "static int spk_ttyio_initialise_ldisc(struct spk_synth *synth)\n{\n\tint ret = 0;\n\tstruct tty_struct *tty;\n\tstruct ktermios tmp_termios;\n\tdev_t dev;\n\n\tret = get_dev_to_use(synth, &dev);\n\tif (ret)\n\t\treturn ret;\n\n\ttty = tty_kopen(dev);\n\tif (IS_ERR(tty))\n\t\treturn PTR_ERR(tty);\n\n\tif (tty->ops->open)\n\t\tret = tty->ops->open(tty, NULL);\n\telse\n\t\tret = -ENODEV;\n\n\tif (ret) {\n\t\ttty_unlock(tty);\n\t\treturn ret;\n\t}\n\n\tclear_bit(TTY_HUPPED, &tty->flags);\n\t/* ensure hardware flow control is enabled */\n\tget_termios(tty, &tmp_termios);\n\tif (!(tmp_termios.c_cflag & CRTSCTS)) {\n\t\ttmp_termios.c_cflag |= CRTSCTS;\n\t\ttty_set_termios(tty, &tmp_termios);\n\t\t/*\n\t\t * check c_cflag to see if it's updated as tty_set_termios\n\t\t * may not return error even when no tty bits are\n\t\t * changed by the request.\n\t\t */\n\t\tget_termios(tty, &tmp_termios);\n\t\tif (!(tmp_termios.c_cflag & CRTSCTS))\n\t\t\tpr_warn(\"speakup: Failed to set hardware flow control\\n\");\n\t}\n\n\ttty_unlock(tty);\n\n\tret = tty_set_ldisc(tty, N_SPEAKUP);\n\tif (ret)\n\t\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");\n\n\treturn ret;\n}",
        "code_after_change": "static int spk_ttyio_initialise_ldisc(struct spk_synth *synth)\n{\n\tint ret = 0;\n\tstruct tty_struct *tty;\n\tstruct ktermios tmp_termios;\n\tdev_t dev;\n\n\tret = get_dev_to_use(synth, &dev);\n\tif (ret)\n\t\treturn ret;\n\n\ttty = tty_kopen(dev);\n\tif (IS_ERR(tty))\n\t\treturn PTR_ERR(tty);\n\n\tif (tty->ops->open)\n\t\tret = tty->ops->open(tty, NULL);\n\telse\n\t\tret = -ENODEV;\n\n\tif (ret) {\n\t\ttty_unlock(tty);\n\t\treturn ret;\n\t}\n\n\tclear_bit(TTY_HUPPED, &tty->flags);\n\t/* ensure hardware flow control is enabled */\n\tget_termios(tty, &tmp_termios);\n\tif (!(tmp_termios.c_cflag & CRTSCTS)) {\n\t\ttmp_termios.c_cflag |= CRTSCTS;\n\t\ttty_set_termios(tty, &tmp_termios);\n\t\t/*\n\t\t * check c_cflag to see if it's updated as tty_set_termios\n\t\t * may not return error even when no tty bits are\n\t\t * changed by the request.\n\t\t */\n\t\tget_termios(tty, &tmp_termios);\n\t\tif (!(tmp_termios.c_cflag & CRTSCTS))\n\t\t\tpr_warn(\"speakup: Failed to set hardware flow control\\n\");\n\t}\n\n\ttty_unlock(tty);\n\n\tmutex_lock(&speakup_tty_mutex);\n\tspeakup_tty = tty;\n\tret = tty_set_ldisc(tty, N_SPEAKUP);\n\tif (ret)\n\t\tspeakup_tty = NULL;\n\tmutex_unlock(&speakup_tty_mutex);\n\n\tif (!ret)\n\t\t/* Success */\n\t\treturn 0;\n\n\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");\n\n\ttty_lock(tty);\n\tif (tty->ops->close)\n\t\ttty->ops->close(tty, NULL);\n\ttty_unlock(tty);\n\n\ttty_kclose(tty);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -41,9 +41,25 @@\n \n \ttty_unlock(tty);\n \n+\tmutex_lock(&speakup_tty_mutex);\n+\tspeakup_tty = tty;\n \tret = tty_set_ldisc(tty, N_SPEAKUP);\n \tif (ret)\n-\t\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");\n+\t\tspeakup_tty = NULL;\n+\tmutex_unlock(&speakup_tty_mutex);\n+\n+\tif (!ret)\n+\t\t/* Success */\n+\t\treturn 0;\n+\n+\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");\n+\n+\ttty_lock(tty);\n+\tif (tty->ops->close)\n+\t\ttty->ops->close(tty, NULL);\n+\ttty_unlock(tty);\n+\n+\ttty_kclose(tty);\n \n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tmutex_lock(&speakup_tty_mutex);",
                "\tspeakup_tty = tty;",
                "\t\tspeakup_tty = NULL;",
                "\tmutex_unlock(&speakup_tty_mutex);",
                "",
                "\tif (!ret)",
                "\t\t/* Success */",
                "\t\treturn 0;",
                "",
                "\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");",
                "",
                "\ttty_lock(tty);",
                "\tif (tty->ops->close)",
                "\t\ttty->ops->close(tty, NULL);",
                "\ttty_unlock(tty);",
                "",
                "\ttty_kclose(tty);"
            ],
            "deleted": [
                "\t\tpr_err(\"speakup: Failed to set N_SPEAKUP on tty\\n\");"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel where in the spk_ttyio_receive_buf2() function, it would dereference spk_ttyio_synth without checking whether it is NULL or not, and may lead to a NULL-ptr deref crash.",
        "id": 2640
    },
    {
        "cve_id": "CVE-2022-4127",
        "code_before_change": "static int io_files_update_with_index_alloc(struct io_kiocb *req,\n\t\t\t\t\t    unsigned int issue_flags)\n{\n\t__s32 __user *fds = u64_to_user_ptr(req->rsrc_update.arg);\n\tunsigned int done;\n\tstruct file *file;\n\tint ret, fd;\n\n\tfor (done = 0; done < req->rsrc_update.nr_args; done++) {\n\t\tif (copy_from_user(&fd, &fds[done], sizeof(fd))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tfile = fget(fd);\n\t\tif (!file) {\n\t\t\tret = -EBADF;\n\t\t\tbreak;\n\t\t}\n\t\tret = io_fixed_fd_install(req, issue_flags, file,\n\t\t\t\t\t  IORING_FILE_INDEX_ALLOC);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tif (copy_to_user(&fds[done], &ret, sizeof(ret))) {\n\t\t\t__io_close_fixed(req, issue_flags, ret);\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (done)\n\t\treturn done;\n\treturn ret;\n}",
        "code_after_change": "static int io_files_update_with_index_alloc(struct io_kiocb *req,\n\t\t\t\t\t    unsigned int issue_flags)\n{\n\t__s32 __user *fds = u64_to_user_ptr(req->rsrc_update.arg);\n\tunsigned int done;\n\tstruct file *file;\n\tint ret, fd;\n\n\tif (!req->ctx->file_data)\n\t\treturn -ENXIO;\n\n\tfor (done = 0; done < req->rsrc_update.nr_args; done++) {\n\t\tif (copy_from_user(&fd, &fds[done], sizeof(fd))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tfile = fget(fd);\n\t\tif (!file) {\n\t\t\tret = -EBADF;\n\t\t\tbreak;\n\t\t}\n\t\tret = io_fixed_fd_install(req, issue_flags, file,\n\t\t\t\t\t  IORING_FILE_INDEX_ALLOC);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tif (copy_to_user(&fds[done], &ret, sizeof(ret))) {\n\t\t\t__io_close_fixed(req, issue_flags, ret);\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (done)\n\t\treturn done;\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tunsigned int done;\n \tstruct file *file;\n \tint ret, fd;\n+\n+\tif (!req->ctx->file_data)\n+\t\treturn -ENXIO;\n \n \tfor (done = 0; done < req->rsrc_update.nr_args; done++) {\n \t\tif (copy_from_user(&fd, &fds[done], sizeof(fd))) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!req->ctx->file_data)",
                "\t\treturn -ENXIO;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference issue was discovered in the Linux kernel in io_files_update_with_index_alloc. A local user could use this flaw to potentially crash the system causing a denial of service.",
        "id": 3714
    },
    {
        "cve_id": "CVE-2023-4385",
        "code_before_change": "int dbFree(struct inode *ip, s64 blkno, s64 nblocks)\n{\n\tstruct metapage *mp;\n\tstruct dmap *dp;\n\tint nb, rc;\n\ts64 lblkno, rem;\n\tstruct inode *ipbmap = JFS_SBI(ip->i_sb)->ipbmap;\n\tstruct bmap *bmp = JFS_SBI(ip->i_sb)->bmap;\n\tstruct super_block *sb = ipbmap->i_sb;\n\n\tIREAD_LOCK(ipbmap, RDWRLOCK_DMAP);\n\n\t/* block to be freed better be within the mapsize. */\n\tif (unlikely((blkno == 0) || (blkno + nblocks > bmp->db_mapsize))) {\n\t\tIREAD_UNLOCK(ipbmap);\n\t\tprintk(KERN_ERR \"blkno = %Lx, nblocks = %Lx\\n\",\n\t\t       (unsigned long long) blkno,\n\t\t       (unsigned long long) nblocks);\n\t\tjfs_error(ip->i_sb, \"block to be freed is outside the map\\n\");\n\t\treturn -EIO;\n\t}\n\n\t/**\n\t * TRIM the blocks, when mounted with discard option\n\t */\n\tif (JFS_SBI(sb)->flag & JFS_DISCARD)\n\t\tif (JFS_SBI(sb)->minblks_trim <= nblocks)\n\t\t\tjfs_issue_discard(ipbmap, blkno, nblocks);\n\n\t/*\n\t * free the blocks a dmap at a time.\n\t */\n\tmp = NULL;\n\tfor (rem = nblocks; rem > 0; rem -= nb, blkno += nb) {\n\t\t/* release previous dmap if any */\n\t\tif (mp) {\n\t\t\twrite_metapage(mp);\n\t\t}\n\n\t\t/* get the buffer for the current dmap. */\n\t\tlblkno = BLKTODMAP(blkno, bmp->db_l2nbperpage);\n\t\tmp = read_metapage(ipbmap, lblkno, PSIZE, 0);\n\t\tif (mp == NULL) {\n\t\t\tIREAD_UNLOCK(ipbmap);\n\t\t\treturn -EIO;\n\t\t}\n\t\tdp = (struct dmap *) mp->data;\n\n\t\t/* determine the number of blocks to be freed from\n\t\t * this dmap.\n\t\t */\n\t\tnb = min(rem, BPERDMAP - (blkno & (BPERDMAP - 1)));\n\n\t\t/* free the blocks. */\n\t\tif ((rc = dbFreeDmap(bmp, dp, blkno, nb))) {\n\t\t\tjfs_error(ip->i_sb, \"error in block map\\n\");\n\t\t\trelease_metapage(mp);\n\t\t\tIREAD_UNLOCK(ipbmap);\n\t\t\treturn (rc);\n\t\t}\n\t}\n\n\t/* write the last buffer. */\n\twrite_metapage(mp);\n\n\tIREAD_UNLOCK(ipbmap);\n\n\treturn (0);\n}",
        "code_after_change": "int dbFree(struct inode *ip, s64 blkno, s64 nblocks)\n{\n\tstruct metapage *mp;\n\tstruct dmap *dp;\n\tint nb, rc;\n\ts64 lblkno, rem;\n\tstruct inode *ipbmap = JFS_SBI(ip->i_sb)->ipbmap;\n\tstruct bmap *bmp = JFS_SBI(ip->i_sb)->bmap;\n\tstruct super_block *sb = ipbmap->i_sb;\n\n\tIREAD_LOCK(ipbmap, RDWRLOCK_DMAP);\n\n\t/* block to be freed better be within the mapsize. */\n\tif (unlikely((blkno == 0) || (blkno + nblocks > bmp->db_mapsize))) {\n\t\tIREAD_UNLOCK(ipbmap);\n\t\tprintk(KERN_ERR \"blkno = %Lx, nblocks = %Lx\\n\",\n\t\t       (unsigned long long) blkno,\n\t\t       (unsigned long long) nblocks);\n\t\tjfs_error(ip->i_sb, \"block to be freed is outside the map\\n\");\n\t\treturn -EIO;\n\t}\n\n\t/**\n\t * TRIM the blocks, when mounted with discard option\n\t */\n\tif (JFS_SBI(sb)->flag & JFS_DISCARD)\n\t\tif (JFS_SBI(sb)->minblks_trim <= nblocks)\n\t\t\tjfs_issue_discard(ipbmap, blkno, nblocks);\n\n\t/*\n\t * free the blocks a dmap at a time.\n\t */\n\tmp = NULL;\n\tfor (rem = nblocks; rem > 0; rem -= nb, blkno += nb) {\n\t\t/* release previous dmap if any */\n\t\tif (mp) {\n\t\t\twrite_metapage(mp);\n\t\t}\n\n\t\t/* get the buffer for the current dmap. */\n\t\tlblkno = BLKTODMAP(blkno, bmp->db_l2nbperpage);\n\t\tmp = read_metapage(ipbmap, lblkno, PSIZE, 0);\n\t\tif (mp == NULL) {\n\t\t\tIREAD_UNLOCK(ipbmap);\n\t\t\treturn -EIO;\n\t\t}\n\t\tdp = (struct dmap *) mp->data;\n\n\t\t/* determine the number of blocks to be freed from\n\t\t * this dmap.\n\t\t */\n\t\tnb = min(rem, BPERDMAP - (blkno & (BPERDMAP - 1)));\n\n\t\t/* free the blocks. */\n\t\tif ((rc = dbFreeDmap(bmp, dp, blkno, nb))) {\n\t\t\tjfs_error(ip->i_sb, \"error in block map\\n\");\n\t\t\trelease_metapage(mp);\n\t\t\tIREAD_UNLOCK(ipbmap);\n\t\t\treturn (rc);\n\t\t}\n\t}\n\n\t/* write the last buffer. */\n\tif (mp)\n\t\twrite_metapage(mp);\n\n\tIREAD_UNLOCK(ipbmap);\n\n\treturn (0);\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,7 +61,8 @@\n \t}\n \n \t/* write the last buffer. */\n-\twrite_metapage(mp);\n+\tif (mp)\n+\t\twrite_metapage(mp);\n \n \tIREAD_UNLOCK(ipbmap);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (mp)",
                "\t\twrite_metapage(mp);"
            ],
            "deleted": [
                "\twrite_metapage(mp);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in dbFree in fs/jfs/jfs_dmap.c in the journaling file system (JFS) in the Linux Kernel. This issue may allow a local attacker to crash the system due to a missing sanity check.",
        "id": 4209
    },
    {
        "cve_id": "CVE-2023-1382",
        "code_before_change": "static void tipc_topsrv_accept(struct work_struct *work)\n{\n\tstruct tipc_topsrv *srv = container_of(work, struct tipc_topsrv, awork);\n\tstruct socket *newsock, *lsock;\n\tstruct tipc_conn *con;\n\tstruct sock *newsk;\n\tint ret;\n\n\tspin_lock_bh(&srv->idr_lock);\n\tif (!srv->listener) {\n\t\tspin_unlock_bh(&srv->idr_lock);\n\t\treturn;\n\t}\n\tlsock = srv->listener;\n\tspin_unlock_bh(&srv->idr_lock);\n\n\twhile (1) {\n\t\tret = kernel_accept(lsock, &newsock, O_NONBLOCK);\n\t\tif (ret < 0)\n\t\t\treturn;\n\t\tcon = tipc_conn_alloc(srv);\n\t\tif (IS_ERR(con)) {\n\t\t\tret = PTR_ERR(con);\n\t\t\tsock_release(newsock);\n\t\t\treturn;\n\t\t}\n\t\t/* Register callbacks */\n\t\tnewsk = newsock->sk;\n\t\twrite_lock_bh(&newsk->sk_callback_lock);\n\t\tnewsk->sk_data_ready = tipc_conn_data_ready;\n\t\tnewsk->sk_write_space = tipc_conn_write_space;\n\t\tnewsk->sk_user_data = con;\n\t\tcon->sock = newsock;\n\t\twrite_unlock_bh(&newsk->sk_callback_lock);\n\n\t\t/* Wake up receive process in case of 'SYN+' message */\n\t\tnewsk->sk_data_ready(newsk);\n\t}\n}",
        "code_after_change": "static void tipc_topsrv_accept(struct work_struct *work)\n{\n\tstruct tipc_topsrv *srv = container_of(work, struct tipc_topsrv, awork);\n\tstruct socket *newsock, *lsock;\n\tstruct tipc_conn *con;\n\tstruct sock *newsk;\n\tint ret;\n\n\tspin_lock_bh(&srv->idr_lock);\n\tif (!srv->listener) {\n\t\tspin_unlock_bh(&srv->idr_lock);\n\t\treturn;\n\t}\n\tlsock = srv->listener;\n\tspin_unlock_bh(&srv->idr_lock);\n\n\twhile (1) {\n\t\tret = kernel_accept(lsock, &newsock, O_NONBLOCK);\n\t\tif (ret < 0)\n\t\t\treturn;\n\t\tcon = tipc_conn_alloc(srv, newsock);\n\t\tif (IS_ERR(con)) {\n\t\t\tret = PTR_ERR(con);\n\t\t\tsock_release(newsock);\n\t\t\treturn;\n\t\t}\n\t\t/* Register callbacks */\n\t\tnewsk = newsock->sk;\n\t\twrite_lock_bh(&newsk->sk_callback_lock);\n\t\tnewsk->sk_data_ready = tipc_conn_data_ready;\n\t\tnewsk->sk_write_space = tipc_conn_write_space;\n\t\tnewsk->sk_user_data = con;\n\t\twrite_unlock_bh(&newsk->sk_callback_lock);\n\n\t\t/* Wake up receive process in case of 'SYN+' message */\n\t\tnewsk->sk_data_ready(newsk);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t\tret = kernel_accept(lsock, &newsock, O_NONBLOCK);\n \t\tif (ret < 0)\n \t\t\treturn;\n-\t\tcon = tipc_conn_alloc(srv);\n+\t\tcon = tipc_conn_alloc(srv, newsock);\n \t\tif (IS_ERR(con)) {\n \t\t\tret = PTR_ERR(con);\n \t\t\tsock_release(newsock);\n@@ -30,7 +30,6 @@\n \t\tnewsk->sk_data_ready = tipc_conn_data_ready;\n \t\tnewsk->sk_write_space = tipc_conn_write_space;\n \t\tnewsk->sk_user_data = con;\n-\t\tcon->sock = newsock;\n \t\twrite_unlock_bh(&newsk->sk_callback_lock);\n \n \t\t/* Wake up receive process in case of 'SYN+' message */",
        "function_modified_lines": {
            "added": [
                "\t\tcon = tipc_conn_alloc(srv, newsock);"
            ],
            "deleted": [
                "\t\tcon = tipc_conn_alloc(srv);",
                "\t\tcon->sock = newsock;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A data race flaw was found in the Linux kernel, between where con is allocated and con->sock is set. This issue leads to a NULL pointer dereference when accessing con->sock->sk in net/tipc/topsrv.c in the tipc protocol in the Linux kernel.",
        "id": 3866
    },
    {
        "cve_id": "CVE-2022-4128",
        "code_before_change": "static int mptcp_disconnect(struct sock *sk, int flags)\n{\n\tstruct mptcp_subflow_context *subflow;\n\tstruct mptcp_sock *msk = mptcp_sk(sk);\n\n\tinet_sk_state_store(sk, TCP_CLOSE);\n\n\tmptcp_for_each_subflow(msk, subflow) {\n\t\tstruct sock *ssk = mptcp_subflow_tcp_sock(subflow);\n\n\t\t__mptcp_close_ssk(sk, ssk, subflow, MPTCP_CF_FASTCLOSE);\n\t}\n\n\tmptcp_stop_timer(sk);\n\tsk_stop_timer(sk, &sk->sk_timer);\n\n\tif (mptcp_sk(sk)->token)\n\t\tmptcp_event(MPTCP_EVENT_CLOSED, mptcp_sk(sk), NULL, GFP_KERNEL);\n\n\tmptcp_destroy_common(msk);\n\tmsk->last_snd = NULL;\n\tWRITE_ONCE(msk->flags, 0);\n\tmsk->cb_flags = 0;\n\tmsk->push_pending = 0;\n\tmsk->recovery = false;\n\tmsk->can_ack = false;\n\tmsk->fully_established = false;\n\tmsk->rcv_data_fin = false;\n\tmsk->snd_data_fin_enable = false;\n\tmsk->rcv_fastclose = false;\n\tmsk->use_64bit_ack = false;\n\tWRITE_ONCE(msk->csum_enabled, mptcp_is_checksum_enabled(sock_net(sk)));\n\tmptcp_pm_data_reset(msk);\n\tmptcp_ca_reset(sk);\n\n\tsk->sk_shutdown = 0;\n\tsk_error_report(sk);\n\treturn 0;\n}",
        "code_after_change": "static int mptcp_disconnect(struct sock *sk, int flags)\n{\n\tstruct mptcp_subflow_context *subflow, *tmp;\n\tstruct mptcp_sock *msk = mptcp_sk(sk);\n\n\tinet_sk_state_store(sk, TCP_CLOSE);\n\n\tlist_for_each_entry_safe(subflow, tmp, &msk->conn_list, node) {\n\t\tstruct sock *ssk = mptcp_subflow_tcp_sock(subflow);\n\n\t\t__mptcp_close_ssk(sk, ssk, subflow, MPTCP_CF_FASTCLOSE);\n\t}\n\n\tmptcp_stop_timer(sk);\n\tsk_stop_timer(sk, &sk->sk_timer);\n\n\tif (mptcp_sk(sk)->token)\n\t\tmptcp_event(MPTCP_EVENT_CLOSED, mptcp_sk(sk), NULL, GFP_KERNEL);\n\n\tmptcp_destroy_common(msk);\n\tmsk->last_snd = NULL;\n\tWRITE_ONCE(msk->flags, 0);\n\tmsk->cb_flags = 0;\n\tmsk->push_pending = 0;\n\tmsk->recovery = false;\n\tmsk->can_ack = false;\n\tmsk->fully_established = false;\n\tmsk->rcv_data_fin = false;\n\tmsk->snd_data_fin_enable = false;\n\tmsk->rcv_fastclose = false;\n\tmsk->use_64bit_ack = false;\n\tWRITE_ONCE(msk->csum_enabled, mptcp_is_checksum_enabled(sock_net(sk)));\n\tmptcp_pm_data_reset(msk);\n\tmptcp_ca_reset(sk);\n\n\tsk->sk_shutdown = 0;\n\tsk_error_report(sk);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,11 +1,11 @@\n static int mptcp_disconnect(struct sock *sk, int flags)\n {\n-\tstruct mptcp_subflow_context *subflow;\n+\tstruct mptcp_subflow_context *subflow, *tmp;\n \tstruct mptcp_sock *msk = mptcp_sk(sk);\n \n \tinet_sk_state_store(sk, TCP_CLOSE);\n \n-\tmptcp_for_each_subflow(msk, subflow) {\n+\tlist_for_each_entry_safe(subflow, tmp, &msk->conn_list, node) {\n \t\tstruct sock *ssk = mptcp_subflow_tcp_sock(subflow);\n \n \t\t__mptcp_close_ssk(sk, ssk, subflow, MPTCP_CF_FASTCLOSE);",
        "function_modified_lines": {
            "added": [
                "\tstruct mptcp_subflow_context *subflow, *tmp;",
                "\tlist_for_each_entry_safe(subflow, tmp, &msk->conn_list, node) {"
            ],
            "deleted": [
                "\tstruct mptcp_subflow_context *subflow;",
                "\tmptcp_for_each_subflow(msk, subflow) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference issue was discovered in the Linux kernel in the MPTCP protocol when traversing the subflow list at disconnect time. A local user could use this flaw to potentially crash the system causing a denial of service.",
        "id": 3715
    },
    {
        "cve_id": "CVE-2022-3112",
        "code_before_change": "static int\nesparser_queue(struct amvdec_session *sess, struct vb2_v4l2_buffer *vbuf)\n{\n\tint ret;\n\tstruct vb2_buffer *vb = &vbuf->vb2_buf;\n\tstruct amvdec_core *core = sess->core;\n\tstruct amvdec_codec_ops *codec_ops = sess->fmt_out->codec_ops;\n\tu32 payload_size = vb2_get_plane_payload(vb, 0);\n\tdma_addr_t phy = vb2_dma_contig_plane_dma_addr(vb, 0);\n\tu32 num_dst_bufs = 0;\n\tu32 offset;\n\tu32 pad_size;\n\n\t/*\n\t * When max ref frame is held by VP9, this should be -= 3 to prevent a\n\t * shortage of CAPTURE buffers on the decoder side.\n\t * For the future, a good enhancement of the way this is handled could\n\t * be to notify new capture buffers to the decoding modules, so that\n\t * they could pause when there is no capture buffer available and\n\t * resume on this notification.\n\t */\n\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9) {\n\t\tif (codec_ops->num_pending_bufs)\n\t\t\tnum_dst_bufs = codec_ops->num_pending_bufs(sess);\n\n\t\tnum_dst_bufs += v4l2_m2m_num_dst_bufs_ready(sess->m2m_ctx);\n\t\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9)\n\t\t\tnum_dst_bufs -= 3;\n\n\t\tif (esparser_vififo_get_free_space(sess) < payload_size ||\n\t\t    atomic_read(&sess->esparser_queued_bufs) >= num_dst_bufs)\n\t\t\treturn -EAGAIN;\n\t} else if (esparser_vififo_get_free_space(sess) < payload_size) {\n\t\treturn -EAGAIN;\n\t}\n\n\tv4l2_m2m_src_buf_remove_by_buf(sess->m2m_ctx, vbuf);\n\n\toffset = esparser_get_offset(sess);\n\n\tamvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);\n\tdev_dbg(core->dev, \"esparser: ts = %llu pld_size = %u offset = %08X flags = %08X\\n\",\n\t\tvb->timestamp, payload_size, offset, vbuf->flags);\n\n\tvbuf->flags = 0;\n\tvbuf->field = V4L2_FIELD_NONE;\n\tvbuf->sequence = sess->sequence_out++;\n\n\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9) {\n\t\tpayload_size = vp9_update_header(core, vb);\n\n\t\t/* If unable to alter buffer to add headers */\n\t\tif (payload_size == 0) {\n\t\t\tamvdec_remove_ts(sess, vb->timestamp);\n\t\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tpad_size = esparser_pad_start_code(core, vb, payload_size);\n\tret = esparser_write_data(core, phy, payload_size + pad_size);\n\n\tif (ret <= 0) {\n\t\tdev_warn(core->dev, \"esparser: input parsing error\\n\");\n\t\tamvdec_remove_ts(sess, vb->timestamp);\n\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n\t\tamvdec_write_parser(core, PARSER_FETCH_CMD, 0);\n\n\t\treturn 0;\n\t}\n\n\tatomic_inc(&sess->esparser_queued_bufs);\n\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_DONE);\n\n\treturn 0;\n}",
        "code_after_change": "static int\nesparser_queue(struct amvdec_session *sess, struct vb2_v4l2_buffer *vbuf)\n{\n\tint ret;\n\tstruct vb2_buffer *vb = &vbuf->vb2_buf;\n\tstruct amvdec_core *core = sess->core;\n\tstruct amvdec_codec_ops *codec_ops = sess->fmt_out->codec_ops;\n\tu32 payload_size = vb2_get_plane_payload(vb, 0);\n\tdma_addr_t phy = vb2_dma_contig_plane_dma_addr(vb, 0);\n\tu32 num_dst_bufs = 0;\n\tu32 offset;\n\tu32 pad_size;\n\n\t/*\n\t * When max ref frame is held by VP9, this should be -= 3 to prevent a\n\t * shortage of CAPTURE buffers on the decoder side.\n\t * For the future, a good enhancement of the way this is handled could\n\t * be to notify new capture buffers to the decoding modules, so that\n\t * they could pause when there is no capture buffer available and\n\t * resume on this notification.\n\t */\n\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9) {\n\t\tif (codec_ops->num_pending_bufs)\n\t\t\tnum_dst_bufs = codec_ops->num_pending_bufs(sess);\n\n\t\tnum_dst_bufs += v4l2_m2m_num_dst_bufs_ready(sess->m2m_ctx);\n\t\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9)\n\t\t\tnum_dst_bufs -= 3;\n\n\t\tif (esparser_vififo_get_free_space(sess) < payload_size ||\n\t\t    atomic_read(&sess->esparser_queued_bufs) >= num_dst_bufs)\n\t\t\treturn -EAGAIN;\n\t} else if (esparser_vififo_get_free_space(sess) < payload_size) {\n\t\treturn -EAGAIN;\n\t}\n\n\tv4l2_m2m_src_buf_remove_by_buf(sess->m2m_ctx, vbuf);\n\n\toffset = esparser_get_offset(sess);\n\n\tret = amvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);\n\tif (ret) {\n\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n\t\treturn ret;\n\t}\n\n\tdev_dbg(core->dev, \"esparser: ts = %llu pld_size = %u offset = %08X flags = %08X\\n\",\n\t\tvb->timestamp, payload_size, offset, vbuf->flags);\n\n\tvbuf->flags = 0;\n\tvbuf->field = V4L2_FIELD_NONE;\n\tvbuf->sequence = sess->sequence_out++;\n\n\tif (sess->fmt_out->pixfmt == V4L2_PIX_FMT_VP9) {\n\t\tpayload_size = vp9_update_header(core, vb);\n\n\t\t/* If unable to alter buffer to add headers */\n\t\tif (payload_size == 0) {\n\t\t\tamvdec_remove_ts(sess, vb->timestamp);\n\t\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tpad_size = esparser_pad_start_code(core, vb, payload_size);\n\tret = esparser_write_data(core, phy, payload_size + pad_size);\n\n\tif (ret <= 0) {\n\t\tdev_warn(core->dev, \"esparser: input parsing error\\n\");\n\t\tamvdec_remove_ts(sess, vb->timestamp);\n\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n\t\tamvdec_write_parser(core, PARSER_FETCH_CMD, 0);\n\n\t\treturn 0;\n\t}\n\n\tatomic_inc(&sess->esparser_queued_bufs);\n\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_DONE);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,7 +38,12 @@\n \n \toffset = esparser_get_offset(sess);\n \n-\tamvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);\n+\tret = amvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);\n+\tif (ret) {\n+\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);\n+\t\treturn ret;\n+\t}\n+\n \tdev_dbg(core->dev, \"esparser: ts = %llu pld_size = %u offset = %08X flags = %08X\\n\",\n \t\tvb->timestamp, payload_size, offset, vbuf->flags);\n ",
        "function_modified_lines": {
            "added": [
                "\tret = amvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);",
                "\tif (ret) {",
                "\t\tv4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_ERROR);",
                "\t\treturn ret;",
                "\t}",
                ""
            ],
            "deleted": [
                "\tamvdec_add_ts(sess, vb->timestamp, vbuf->timecode, offset, vbuf->flags);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. amvdec_set_canvases in drivers/staging/media/meson/vdec/vdec_helpers.c lacks check of the return value of kzalloc() and will cause the null pointer dereference.",
        "id": 3557
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_helper_mem_access(struct bpf_verifier_env *env, int regno,\n\t\t\t\t   int access_size, bool zero_size_allowed,\n\t\t\t\t   struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\treturn check_packet_access(env, regno, reg->off, access_size,\n\t\t\t\t\t   zero_size_allowed);\n\tcase PTR_TO_MAP_KEY:\n\t\treturn check_mem_region_access(env, regno, reg->off, access_size,\n\t\t\t\t\t       reg->map_ptr->key_size, false);\n\tcase PTR_TO_MAP_VALUE:\n\t\tif (check_map_access_type(env, regno, reg->off, access_size,\n\t\t\t\t\t  meta && meta->raw_mode ? BPF_WRITE :\n\t\t\t\t\t  BPF_READ))\n\t\t\treturn -EACCES;\n\t\treturn check_map_access(env, regno, reg->off, access_size,\n\t\t\t\t\tzero_size_allowed);\n\tcase PTR_TO_MEM:\n\t\treturn check_mem_region_access(env, regno, reg->off,\n\t\t\t\t\t       access_size, reg->mem_size,\n\t\t\t\t\t       zero_size_allowed);\n\tcase PTR_TO_RDONLY_BUF:\n\t\tif (meta && meta->raw_mode)\n\t\t\treturn -EACCES;\n\t\treturn check_buffer_access(env, reg, regno, reg->off,\n\t\t\t\t\t   access_size, zero_size_allowed,\n\t\t\t\t\t   \"rdonly\",\n\t\t\t\t\t   &env->prog->aux->max_rdonly_access);\n\tcase PTR_TO_RDWR_BUF:\n\t\treturn check_buffer_access(env, reg, regno, reg->off,\n\t\t\t\t\t   access_size, zero_size_allowed,\n\t\t\t\t\t   \"rdwr\",\n\t\t\t\t\t   &env->prog->aux->max_rdwr_access);\n\tcase PTR_TO_STACK:\n\t\treturn check_stack_range_initialized(\n\t\t\t\tenv,\n\t\t\t\tregno, reg->off, access_size,\n\t\t\t\tzero_size_allowed, ACCESS_HELPER, meta);\n\tdefault: /* scalar_value or invalid ptr */\n\t\t/* Allow zero-byte read from NULL, regardless of pointer type */\n\t\tif (zero_size_allowed && access_size == 0 &&\n\t\t    register_is_null(reg))\n\t\t\treturn 0;\n\n\t\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n\t\t\treg_type_str[reg->type],\n\t\t\treg_type_str[PTR_TO_STACK]);\n\t\treturn -EACCES;\n\t}\n}",
        "code_after_change": "static int check_helper_mem_access(struct bpf_verifier_env *env, int regno,\n\t\t\t\t   int access_size, bool zero_size_allowed,\n\t\t\t\t   struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\n\tswitch (reg->type) {\n\tcase PTR_TO_PACKET:\n\tcase PTR_TO_PACKET_META:\n\t\treturn check_packet_access(env, regno, reg->off, access_size,\n\t\t\t\t\t   zero_size_allowed);\n\tcase PTR_TO_MAP_KEY:\n\t\treturn check_mem_region_access(env, regno, reg->off, access_size,\n\t\t\t\t\t       reg->map_ptr->key_size, false);\n\tcase PTR_TO_MAP_VALUE:\n\t\tif (check_map_access_type(env, regno, reg->off, access_size,\n\t\t\t\t\t  meta && meta->raw_mode ? BPF_WRITE :\n\t\t\t\t\t  BPF_READ))\n\t\t\treturn -EACCES;\n\t\treturn check_map_access(env, regno, reg->off, access_size,\n\t\t\t\t\tzero_size_allowed);\n\tcase PTR_TO_MEM:\n\t\treturn check_mem_region_access(env, regno, reg->off,\n\t\t\t\t\t       access_size, reg->mem_size,\n\t\t\t\t\t       zero_size_allowed);\n\tcase PTR_TO_RDONLY_BUF:\n\t\tif (meta && meta->raw_mode)\n\t\t\treturn -EACCES;\n\t\treturn check_buffer_access(env, reg, regno, reg->off,\n\t\t\t\t\t   access_size, zero_size_allowed,\n\t\t\t\t\t   \"rdonly\",\n\t\t\t\t\t   &env->prog->aux->max_rdonly_access);\n\tcase PTR_TO_RDWR_BUF:\n\t\treturn check_buffer_access(env, reg, regno, reg->off,\n\t\t\t\t\t   access_size, zero_size_allowed,\n\t\t\t\t\t   \"rdwr\",\n\t\t\t\t\t   &env->prog->aux->max_rdwr_access);\n\tcase PTR_TO_STACK:\n\t\treturn check_stack_range_initialized(\n\t\t\t\tenv,\n\t\t\t\tregno, reg->off, access_size,\n\t\t\t\tzero_size_allowed, ACCESS_HELPER, meta);\n\tdefault: /* scalar_value or invalid ptr */\n\t\t/* Allow zero-byte read from NULL, regardless of pointer type */\n\t\tif (zero_size_allowed && access_size == 0 &&\n\t\t    register_is_null(reg))\n\t\t\treturn 0;\n\n\t\tverbose(env, \"R%d type=%s \", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\tverbose(env, \"expected=%s\\n\", reg_type_str(env, PTR_TO_STACK));\n\t\treturn -EACCES;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -46,9 +46,9 @@\n \t\t    register_is_null(reg))\n \t\t\treturn 0;\n \n-\t\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n-\t\t\treg_type_str[reg->type],\n-\t\t\treg_type_str[PTR_TO_STACK]);\n+\t\tverbose(env, \"R%d type=%s \", regno,\n+\t\t\treg_type_str(env, reg->type));\n+\t\tverbose(env, \"expected=%s\\n\", reg_type_str(env, PTR_TO_STACK));\n \t\treturn -EACCES;\n \t}\n }",
        "function_modified_lines": {
            "added": [
                "\t\tverbose(env, \"R%d type=%s \", regno,",
                "\t\t\treg_type_str(env, reg->type));",
                "\t\tverbose(env, \"expected=%s\\n\", reg_type_str(env, PTR_TO_STACK));"
            ],
            "deleted": [
                "\t\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,",
                "\t\t\treg_type_str[reg->type],",
                "\t\t\treg_type_str[PTR_TO_STACK]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3456
    },
    {
        "cve_id": "CVE-2023-3106",
        "code_before_change": "static int xfrm_dump_sa(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct xfrm_state_walk *walk = (struct xfrm_state_walk *) &cb->args[1];\n\tstruct xfrm_dump_info info;\n\n\tBUILD_BUG_ON(sizeof(struct xfrm_state_walk) >\n\t\t     sizeof(cb->args) - sizeof(cb->args[0]));\n\n\tinfo.in_skb = cb->skb;\n\tinfo.out_skb = skb;\n\tinfo.nlmsg_seq = cb->nlh->nlmsg_seq;\n\tinfo.nlmsg_flags = NLM_F_MULTI;\n\n\tif (!cb->args[0]) {\n\t\tstruct nlattr *attrs[XFRMA_MAX+1];\n\t\tstruct xfrm_address_filter *filter = NULL;\n\t\tu8 proto = 0;\n\t\tint err;\n\n\t\tcb->args[0] = 1;\n\n\t\terr = nlmsg_parse(cb->nlh, 0, attrs, XFRMA_MAX,\n\t\t\t\t  xfrma_policy);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (attrs[XFRMA_ADDRESS_FILTER]) {\n\t\t\tfilter = kmemdup(nla_data(attrs[XFRMA_ADDRESS_FILTER]),\n\t\t\t\t\t sizeof(*filter), GFP_KERNEL);\n\t\t\tif (filter == NULL)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (attrs[XFRMA_PROTO])\n\t\t\tproto = nla_get_u8(attrs[XFRMA_PROTO]);\n\n\t\txfrm_state_walk_init(walk, proto, filter);\n\t}\n\n\t(void) xfrm_state_walk(net, walk, dump_one_state, &info);\n\n\treturn skb->len;\n}",
        "code_after_change": "static int xfrm_dump_sa(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct xfrm_state_walk *walk = (struct xfrm_state_walk *) &cb->args[1];\n\tstruct xfrm_dump_info info;\n\n\tBUILD_BUG_ON(sizeof(struct xfrm_state_walk) >\n\t\t     sizeof(cb->args) - sizeof(cb->args[0]));\n\n\tinfo.in_skb = cb->skb;\n\tinfo.out_skb = skb;\n\tinfo.nlmsg_seq = cb->nlh->nlmsg_seq;\n\tinfo.nlmsg_flags = NLM_F_MULTI;\n\n\tif (!cb->args[0]) {\n\t\tstruct nlattr *attrs[XFRMA_MAX+1];\n\t\tstruct xfrm_address_filter *filter = NULL;\n\t\tu8 proto = 0;\n\t\tint err;\n\n\t\terr = nlmsg_parse(cb->nlh, 0, attrs, XFRMA_MAX,\n\t\t\t\t  xfrma_policy);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\tif (attrs[XFRMA_ADDRESS_FILTER]) {\n\t\t\tfilter = kmemdup(nla_data(attrs[XFRMA_ADDRESS_FILTER]),\n\t\t\t\t\t sizeof(*filter), GFP_KERNEL);\n\t\t\tif (filter == NULL)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (attrs[XFRMA_PROTO])\n\t\t\tproto = nla_get_u8(attrs[XFRMA_PROTO]);\n\n\t\txfrm_state_walk_init(walk, proto, filter);\n\t\tcb->args[0] = 1;\n\t}\n\n\t(void) xfrm_state_walk(net, walk, dump_one_state, &info);\n\n\treturn skb->len;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,8 +18,6 @@\n \t\tu8 proto = 0;\n \t\tint err;\n \n-\t\tcb->args[0] = 1;\n-\n \t\terr = nlmsg_parse(cb->nlh, 0, attrs, XFRMA_MAX,\n \t\t\t\t  xfrma_policy);\n \t\tif (err < 0)\n@@ -36,6 +34,7 @@\n \t\t\tproto = nla_get_u8(attrs[XFRMA_PROTO]);\n \n \t\txfrm_state_walk_init(walk, proto, filter);\n+\t\tcb->args[0] = 1;\n \t}\n \n \t(void) xfrm_state_walk(net, walk, dump_one_state, &info);",
        "function_modified_lines": {
            "added": [
                "\t\tcb->args[0] = 1;"
            ],
            "deleted": [
                "\t\tcb->args[0] = 1;",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference vulnerability was found in netlink_dump. This issue can occur when the Netlink socket receives the message(sendmsg) for the XFRM_MSG_GETSA, XFRM_MSG_GETPOLICY type message, and the DUMP flag is set and can cause a denial of service or possibly another unspecified impact. Due to the nature of the flaw, privilege escalation cannot be fully ruled out, although it is unlikely.",
        "id": 3992
    },
    {
        "cve_id": "CVE-2022-1263",
        "code_before_change": "static void kvm_vcpu_destroy(struct kvm_vcpu *vcpu)\n{\n\tkvm_dirty_ring_free(&vcpu->dirty_ring);\n\tkvm_arch_vcpu_destroy(vcpu);\n\n\t/*\n\t * No need for rcu_read_lock as VCPU_RUN is the only place that changes\n\t * the vcpu->pid pointer, and at destruction time all file descriptors\n\t * are already gone.\n\t */\n\tput_pid(rcu_dereference_protected(vcpu->pid, 1));\n\n\tfree_page((unsigned long)vcpu->run);\n\tkmem_cache_free(kvm_vcpu_cache, vcpu);\n}",
        "code_after_change": "static void kvm_vcpu_destroy(struct kvm_vcpu *vcpu)\n{\n\tkvm_arch_vcpu_destroy(vcpu);\n\tkvm_dirty_ring_free(&vcpu->dirty_ring);\n\n\t/*\n\t * No need for rcu_read_lock as VCPU_RUN is the only place that changes\n\t * the vcpu->pid pointer, and at destruction time all file descriptors\n\t * are already gone.\n\t */\n\tput_pid(rcu_dereference_protected(vcpu->pid, 1));\n\n\tfree_page((unsigned long)vcpu->run);\n\tkmem_cache_free(kvm_vcpu_cache, vcpu);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static void kvm_vcpu_destroy(struct kvm_vcpu *vcpu)\n {\n+\tkvm_arch_vcpu_destroy(vcpu);\n \tkvm_dirty_ring_free(&vcpu->dirty_ring);\n-\tkvm_arch_vcpu_destroy(vcpu);\n \n \t/*\n \t * No need for rcu_read_lock as VCPU_RUN is the only place that changes",
        "function_modified_lines": {
            "added": [
                "\tkvm_arch_vcpu_destroy(vcpu);"
            ],
            "deleted": [
                "\tkvm_arch_vcpu_destroy(vcpu);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference issue was found in KVM when releasing a vCPU with dirty ring support enabled. This flaw allows an unprivileged local attacker on the host to issue specific ioctl calls, causing a kernel oops condition that results in a denial of service.",
        "id": 3257
    },
    {
        "cve_id": "CVE-2016-3070",
        "code_before_change": "void migrate_page_copy(struct page *newpage, struct page *page)\n{\n\tint cpupid;\n\n\tif (PageHuge(page) || PageTransHuge(page))\n\t\tcopy_huge_page(newpage, page);\n\telse\n\t\tcopy_highpage(newpage, page);\n\n\tif (PageError(page))\n\t\tSetPageError(newpage);\n\tif (PageReferenced(page))\n\t\tSetPageReferenced(newpage);\n\tif (PageUptodate(page))\n\t\tSetPageUptodate(newpage);\n\tif (TestClearPageActive(page)) {\n\t\tVM_BUG_ON_PAGE(PageUnevictable(page), page);\n\t\tSetPageActive(newpage);\n\t} else if (TestClearPageUnevictable(page))\n\t\tSetPageUnevictable(newpage);\n\tif (PageChecked(page))\n\t\tSetPageChecked(newpage);\n\tif (PageMappedToDisk(page))\n\t\tSetPageMappedToDisk(newpage);\n\n\tif (PageDirty(page)) {\n\t\tclear_page_dirty_for_io(page);\n\t\t/*\n\t\t * Want to mark the page and the radix tree as dirty, and\n\t\t * redo the accounting that clear_page_dirty_for_io undid,\n\t\t * but we can't use set_page_dirty because that function\n\t\t * is actually a signal that all of the page has become dirty.\n\t\t * Whereas only part of our page may be dirty.\n\t\t */\n\t\tif (PageSwapBacked(page))\n\t\t\tSetPageDirty(newpage);\n\t\telse\n\t\t\t__set_page_dirty_nobuffers(newpage);\n \t}\n\n\tif (page_is_young(page))\n\t\tset_page_young(newpage);\n\tif (page_is_idle(page))\n\t\tset_page_idle(newpage);\n\n\t/*\n\t * Copy NUMA information to the new page, to prevent over-eager\n\t * future migrations of this same page.\n\t */\n\tcpupid = page_cpupid_xchg_last(page, -1);\n\tpage_cpupid_xchg_last(newpage, cpupid);\n\n\tksm_migrate_page(newpage, page);\n\t/*\n\t * Please do not reorder this without considering how mm/ksm.c's\n\t * get_ksm_page() depends upon ksm_migrate_page() and PageSwapCache().\n\t */\n\tif (PageSwapCache(page))\n\t\tClearPageSwapCache(page);\n\tClearPagePrivate(page);\n\tset_page_private(page, 0);\n\n\t/*\n\t * If any waiters have accumulated on the new page then\n\t * wake them up.\n\t */\n\tif (PageWriteback(newpage))\n\t\tend_page_writeback(newpage);\n}",
        "code_after_change": "void migrate_page_copy(struct page *newpage, struct page *page)\n{\n\tint cpupid;\n\n\tif (PageHuge(page) || PageTransHuge(page))\n\t\tcopy_huge_page(newpage, page);\n\telse\n\t\tcopy_highpage(newpage, page);\n\n\tif (PageError(page))\n\t\tSetPageError(newpage);\n\tif (PageReferenced(page))\n\t\tSetPageReferenced(newpage);\n\tif (PageUptodate(page))\n\t\tSetPageUptodate(newpage);\n\tif (TestClearPageActive(page)) {\n\t\tVM_BUG_ON_PAGE(PageUnevictable(page), page);\n\t\tSetPageActive(newpage);\n\t} else if (TestClearPageUnevictable(page))\n\t\tSetPageUnevictable(newpage);\n\tif (PageChecked(page))\n\t\tSetPageChecked(newpage);\n\tif (PageMappedToDisk(page))\n\t\tSetPageMappedToDisk(newpage);\n\n\t/* Move dirty on pages not done by migrate_page_move_mapping() */\n\tif (PageDirty(page))\n\t\tSetPageDirty(newpage);\n\n\tif (page_is_young(page))\n\t\tset_page_young(newpage);\n\tif (page_is_idle(page))\n\t\tset_page_idle(newpage);\n\n\t/*\n\t * Copy NUMA information to the new page, to prevent over-eager\n\t * future migrations of this same page.\n\t */\n\tcpupid = page_cpupid_xchg_last(page, -1);\n\tpage_cpupid_xchg_last(newpage, cpupid);\n\n\tksm_migrate_page(newpage, page);\n\t/*\n\t * Please do not reorder this without considering how mm/ksm.c's\n\t * get_ksm_page() depends upon ksm_migrate_page() and PageSwapCache().\n\t */\n\tif (PageSwapCache(page))\n\t\tClearPageSwapCache(page);\n\tClearPagePrivate(page);\n\tset_page_private(page, 0);\n\n\t/*\n\t * If any waiters have accumulated on the new page then\n\t * wake them up.\n\t */\n\tif (PageWriteback(newpage))\n\t\tend_page_writeback(newpage);\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,20 +23,9 @@\n \tif (PageMappedToDisk(page))\n \t\tSetPageMappedToDisk(newpage);\n \n-\tif (PageDirty(page)) {\n-\t\tclear_page_dirty_for_io(page);\n-\t\t/*\n-\t\t * Want to mark the page and the radix tree as dirty, and\n-\t\t * redo the accounting that clear_page_dirty_for_io undid,\n-\t\t * but we can't use set_page_dirty because that function\n-\t\t * is actually a signal that all of the page has become dirty.\n-\t\t * Whereas only part of our page may be dirty.\n-\t\t */\n-\t\tif (PageSwapBacked(page))\n-\t\t\tSetPageDirty(newpage);\n-\t\telse\n-\t\t\t__set_page_dirty_nobuffers(newpage);\n- \t}\n+\t/* Move dirty on pages not done by migrate_page_move_mapping() */\n+\tif (PageDirty(page))\n+\t\tSetPageDirty(newpage);\n \n \tif (page_is_young(page))\n \t\tset_page_young(newpage);",
        "function_modified_lines": {
            "added": [
                "\t/* Move dirty on pages not done by migrate_page_move_mapping() */",
                "\tif (PageDirty(page))",
                "\t\tSetPageDirty(newpage);"
            ],
            "deleted": [
                "\tif (PageDirty(page)) {",
                "\t\tclear_page_dirty_for_io(page);",
                "\t\t/*",
                "\t\t * Want to mark the page and the radix tree as dirty, and",
                "\t\t * redo the accounting that clear_page_dirty_for_io undid,",
                "\t\t * but we can't use set_page_dirty because that function",
                "\t\t * is actually a signal that all of the page has become dirty.",
                "\t\t * Whereas only part of our page may be dirty.",
                "\t\t */",
                "\t\tif (PageSwapBacked(page))",
                "\t\t\tSetPageDirty(newpage);",
                "\t\telse",
                "\t\t\t__set_page_dirty_nobuffers(newpage);",
                " \t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The trace_writeback_dirty_page implementation in include/trace/events/writeback.h in the Linux kernel before 4.4 improperly interacts with mm/migrate.c, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact by triggering a certain page move.",
        "id": 961
    },
    {
        "cve_id": "CVE-2019-15223",
        "code_before_change": "void line6_disconnect(struct usb_interface *interface)\n{\n\tstruct usb_line6 *line6 = usb_get_intfdata(interface);\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\n\tif (!line6)\n\t\treturn;\n\n\tif (WARN_ON(usbdev != line6->usbdev))\n\t\treturn;\n\n\tif (line6->urb_listen != NULL)\n\t\tline6_stop_listen(line6);\n\n\tsnd_card_disconnect(line6->card);\n\tif (line6->line6pcm)\n\t\tline6_pcm_disconnect(line6->line6pcm);\n\tif (line6->disconnect)\n\t\tline6->disconnect(line6);\n\n\tdev_info(&interface->dev, \"Line 6 %s now disconnected\\n\",\n\t\t line6->properties->name);\n\n\t/* make sure the device isn't destructed twice: */\n\tusb_set_intfdata(interface, NULL);\n\n\tsnd_card_free_when_closed(line6->card);\n}",
        "code_after_change": "void line6_disconnect(struct usb_interface *interface)\n{\n\tstruct usb_line6 *line6 = usb_get_intfdata(interface);\n\tstruct usb_device *usbdev = interface_to_usbdev(interface);\n\n\tif (!line6)\n\t\treturn;\n\n\tif (WARN_ON(usbdev != line6->usbdev))\n\t\treturn;\n\n\tcancel_delayed_work(&line6->startup_work);\n\n\tif (line6->urb_listen != NULL)\n\t\tline6_stop_listen(line6);\n\n\tsnd_card_disconnect(line6->card);\n\tif (line6->line6pcm)\n\t\tline6_pcm_disconnect(line6->line6pcm);\n\tif (line6->disconnect)\n\t\tline6->disconnect(line6);\n\n\tdev_info(&interface->dev, \"Line 6 %s now disconnected\\n\",\n\t\t line6->properties->name);\n\n\t/* make sure the device isn't destructed twice: */\n\tusb_set_intfdata(interface, NULL);\n\n\tsnd_card_free_when_closed(line6->card);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,8 @@\n \n \tif (WARN_ON(usbdev != line6->usbdev))\n \t\treturn;\n+\n+\tcancel_delayed_work(&line6->startup_work);\n \n \tif (line6->urb_listen != NULL)\n \t\tline6_stop_listen(line6);",
        "function_modified_lines": {
            "added": [
                "",
                "\tcancel_delayed_work(&line6->startup_work);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/line6/driver.c driver.",
        "id": 2008
    },
    {
        "cve_id": "CVE-2022-1852",
        "code_before_change": "int x86_decode_emulated_instruction(struct kvm_vcpu *vcpu, int emulation_type,\n\t\t\t\t    void *insn, int insn_len)\n{\n\tint r = EMULATION_OK;\n\tstruct x86_emulate_ctxt *ctxt = vcpu->arch.emulate_ctxt;\n\n\tinit_emulate_ctxt(vcpu);\n\n\t/*\n\t * We will reenter on the same instruction since we do not set\n\t * complete_userspace_io. This does not handle watchpoints yet,\n\t * those would be handled in the emulate_ops.\n\t */\n\tif (!(emulation_type & EMULTYPE_SKIP) &&\n\t    kvm_vcpu_check_breakpoint(vcpu, &r))\n\t\treturn r;\n\n\tr = x86_decode_insn(ctxt, insn, insn_len, emulation_type);\n\n\ttrace_kvm_emulate_insn_start(vcpu);\n\t++vcpu->stat.insn_emulation;\n\n\treturn r;\n}",
        "code_after_change": "int x86_decode_emulated_instruction(struct kvm_vcpu *vcpu, int emulation_type,\n\t\t\t\t    void *insn, int insn_len)\n{\n\tstruct x86_emulate_ctxt *ctxt = vcpu->arch.emulate_ctxt;\n\tint r;\n\n\tinit_emulate_ctxt(vcpu);\n\n\tr = x86_decode_insn(ctxt, insn, insn_len, emulation_type);\n\n\ttrace_kvm_emulate_insn_start(vcpu);\n\t++vcpu->stat.insn_emulation;\n\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,19 +1,10 @@\n int x86_decode_emulated_instruction(struct kvm_vcpu *vcpu, int emulation_type,\n \t\t\t\t    void *insn, int insn_len)\n {\n-\tint r = EMULATION_OK;\n \tstruct x86_emulate_ctxt *ctxt = vcpu->arch.emulate_ctxt;\n+\tint r;\n \n \tinit_emulate_ctxt(vcpu);\n-\n-\t/*\n-\t * We will reenter on the same instruction since we do not set\n-\t * complete_userspace_io. This does not handle watchpoints yet,\n-\t * those would be handled in the emulate_ops.\n-\t */\n-\tif (!(emulation_type & EMULTYPE_SKIP) &&\n-\t    kvm_vcpu_check_breakpoint(vcpu, &r))\n-\t\treturn r;\n \n \tr = x86_decode_insn(ctxt, insn, insn_len, emulation_type);\n ",
        "function_modified_lines": {
            "added": [
                "\tint r;"
            ],
            "deleted": [
                "\tint r = EMULATION_OK;",
                "",
                "\t/*",
                "\t * We will reenter on the same instruction since we do not set",
                "\t * complete_userspace_io. This does not handle watchpoints yet,",
                "\t * those would be handled in the emulate_ops.",
                "\t */",
                "\tif (!(emulation_type & EMULTYPE_SKIP) &&",
                "\t    kvm_vcpu_check_breakpoint(vcpu, &r))",
                "\t\treturn r;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s KVM module, which can lead to a denial of service in the x86_emulate_insn in arch/x86/kvm/emulate.c. This flaw occurs while executing an illegal instruction in guest in the Intel CPU.",
        "id": 3295
    },
    {
        "cve_id": "CVE-2017-15116",
        "code_before_change": "static inline int crypto_rng_generate(struct crypto_rng *tfm,\n\t\t\t\t      const u8 *src, unsigned int slen,\n\t\t\t\t      u8 *dst, unsigned int dlen)\n{\n\treturn tfm->generate(tfm, src, slen, dst, dlen);\n}",
        "code_after_change": "static inline int crypto_rng_generate(struct crypto_rng *tfm,\n\t\t\t\t      const u8 *src, unsigned int slen,\n\t\t\t\t      u8 *dst, unsigned int dlen)\n{\n\treturn crypto_rng_alg(tfm)->generate(tfm, src, slen, dst, dlen);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,5 +2,5 @@\n \t\t\t\t      const u8 *src, unsigned int slen,\n \t\t\t\t      u8 *dst, unsigned int dlen)\n {\n-\treturn tfm->generate(tfm, src, slen, dst, dlen);\n+\treturn crypto_rng_alg(tfm)->generate(tfm, src, slen, dst, dlen);\n }",
        "function_modified_lines": {
            "added": [
                "\treturn crypto_rng_alg(tfm)->generate(tfm, src, slen, dst, dlen);"
            ],
            "deleted": [
                "\treturn tfm->generate(tfm, src, slen, dst, dlen);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The rngapi_reset function in crypto/rng.c in the Linux kernel before 4.2 allows attackers to cause a denial of service (NULL pointer dereference).",
        "id": 1294
    },
    {
        "cve_id": "CVE-2019-19965",
        "code_before_change": "static int sas_get_port_device(struct asd_sas_port *port)\n{\n\tstruct asd_sas_phy *phy;\n\tstruct sas_rphy *rphy;\n\tstruct domain_device *dev;\n\tint rc = -ENODEV;\n\n\tdev = sas_alloc_device();\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tspin_lock_irq(&port->phy_list_lock);\n\tif (list_empty(&port->phy_list)) {\n\t\tspin_unlock_irq(&port->phy_list_lock);\n\t\tsas_put_device(dev);\n\t\treturn -ENODEV;\n\t}\n\tphy = container_of(port->phy_list.next, struct asd_sas_phy, port_phy_el);\n\tspin_lock(&phy->frame_rcvd_lock);\n\tmemcpy(dev->frame_rcvd, phy->frame_rcvd, min(sizeof(dev->frame_rcvd),\n\t\t\t\t\t     (size_t)phy->frame_rcvd_size));\n\tspin_unlock(&phy->frame_rcvd_lock);\n\tspin_unlock_irq(&port->phy_list_lock);\n\n\tif (dev->frame_rcvd[0] == 0x34 && port->oob_mode == SATA_OOB_MODE) {\n\t\tstruct dev_to_host_fis *fis =\n\t\t\t(struct dev_to_host_fis *) dev->frame_rcvd;\n\t\tif (fis->interrupt_reason == 1 && fis->lbal == 1 &&\n\t\t    fis->byte_count_low==0x69 && fis->byte_count_high == 0x96\n\t\t    && (fis->device & ~0x10) == 0)\n\t\t\tdev->dev_type = SAS_SATA_PM;\n\t\telse\n\t\t\tdev->dev_type = SAS_SATA_DEV;\n\t\tdev->tproto = SAS_PROTOCOL_SATA;\n\t} else {\n\t\tstruct sas_identify_frame *id =\n\t\t\t(struct sas_identify_frame *) dev->frame_rcvd;\n\t\tdev->dev_type = id->dev_type;\n\t\tdev->iproto = id->initiator_bits;\n\t\tdev->tproto = id->target_bits;\n\t}\n\n\tsas_init_dev(dev);\n\n\tdev->port = port;\n\tswitch (dev->dev_type) {\n\tcase SAS_SATA_DEV:\n\t\trc = sas_ata_init(dev);\n\t\tif (rc) {\n\t\t\trphy = NULL;\n\t\t\tbreak;\n\t\t}\n\t\t/* fall through */\n\tcase SAS_END_DEVICE:\n\t\trphy = sas_end_device_alloc(port->port);\n\t\tbreak;\n\tcase SAS_EDGE_EXPANDER_DEVICE:\n\t\trphy = sas_expander_alloc(port->port,\n\t\t\t\t\t  SAS_EDGE_EXPANDER_DEVICE);\n\t\tbreak;\n\tcase SAS_FANOUT_EXPANDER_DEVICE:\n\t\trphy = sas_expander_alloc(port->port,\n\t\t\t\t\t  SAS_FANOUT_EXPANDER_DEVICE);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"ERROR: Unidentified device type %d\\n\", dev->dev_type);\n\t\trphy = NULL;\n\t\tbreak;\n\t}\n\n\tif (!rphy) {\n\t\tsas_put_device(dev);\n\t\treturn rc;\n\t}\n\n\trphy->identify.phy_identifier = phy->phy->identify.phy_identifier;\n\tmemcpy(dev->sas_addr, port->attached_sas_addr, SAS_ADDR_SIZE);\n\tsas_fill_in_rphy(dev, rphy);\n\tsas_hash_addr(dev->hashed_sas_addr, dev->sas_addr);\n\tport->port_dev = dev;\n\tdev->linkrate = port->linkrate;\n\tdev->min_linkrate = port->linkrate;\n\tdev->max_linkrate = port->linkrate;\n\tdev->pathways = port->num_phys;\n\tmemset(port->disc.fanout_sas_addr, 0, SAS_ADDR_SIZE);\n\tmemset(port->disc.eeds_a, 0, SAS_ADDR_SIZE);\n\tmemset(port->disc.eeds_b, 0, SAS_ADDR_SIZE);\n\tport->disc.max_level = 0;\n\tsas_device_set_phy(dev, port->port);\n\n\tdev->rphy = rphy;\n\tget_device(&dev->rphy->dev);\n\n\tif (dev_is_sata(dev) || dev->dev_type == SAS_END_DEVICE)\n\t\tlist_add_tail(&dev->disco_list_node, &port->disco_list);\n\telse {\n\t\tspin_lock_irq(&port->dev_list_lock);\n\t\tlist_add_tail(&dev->dev_list_node, &port->dev_list);\n\t\tspin_unlock_irq(&port->dev_list_lock);\n\t}\n\n\tspin_lock_irq(&port->phy_list_lock);\n\tlist_for_each_entry(phy, &port->phy_list, port_phy_el)\n\t\tsas_phy_set_target(phy, dev);\n\tspin_unlock_irq(&port->phy_list_lock);\n\n\treturn 0;\n}",
        "code_after_change": "static int sas_get_port_device(struct asd_sas_port *port)\n{\n\tstruct asd_sas_phy *phy;\n\tstruct sas_rphy *rphy;\n\tstruct domain_device *dev;\n\tint rc = -ENODEV;\n\n\tdev = sas_alloc_device();\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tspin_lock_irq(&port->phy_list_lock);\n\tif (list_empty(&port->phy_list)) {\n\t\tspin_unlock_irq(&port->phy_list_lock);\n\t\tsas_put_device(dev);\n\t\treturn -ENODEV;\n\t}\n\tphy = container_of(port->phy_list.next, struct asd_sas_phy, port_phy_el);\n\tspin_lock(&phy->frame_rcvd_lock);\n\tmemcpy(dev->frame_rcvd, phy->frame_rcvd, min(sizeof(dev->frame_rcvd),\n\t\t\t\t\t     (size_t)phy->frame_rcvd_size));\n\tspin_unlock(&phy->frame_rcvd_lock);\n\tspin_unlock_irq(&port->phy_list_lock);\n\n\tif (dev->frame_rcvd[0] == 0x34 && port->oob_mode == SATA_OOB_MODE) {\n\t\tstruct dev_to_host_fis *fis =\n\t\t\t(struct dev_to_host_fis *) dev->frame_rcvd;\n\t\tif (fis->interrupt_reason == 1 && fis->lbal == 1 &&\n\t\t    fis->byte_count_low==0x69 && fis->byte_count_high == 0x96\n\t\t    && (fis->device & ~0x10) == 0)\n\t\t\tdev->dev_type = SAS_SATA_PM;\n\t\telse\n\t\t\tdev->dev_type = SAS_SATA_DEV;\n\t\tdev->tproto = SAS_PROTOCOL_SATA;\n\t} else if (port->oob_mode == SAS_OOB_MODE) {\n\t\tstruct sas_identify_frame *id =\n\t\t\t(struct sas_identify_frame *) dev->frame_rcvd;\n\t\tdev->dev_type = id->dev_type;\n\t\tdev->iproto = id->initiator_bits;\n\t\tdev->tproto = id->target_bits;\n\t} else {\n\t\t/* If the oob mode is OOB_NOT_CONNECTED, the port is\n\t\t * disconnected due to race with PHY down. We cannot\n\t\t * continue to discover this port\n\t\t */\n\t\tsas_put_device(dev);\n\t\tpr_warn(\"Port %016llx is disconnected when discovering\\n\",\n\t\t\tSAS_ADDR(port->attached_sas_addr));\n\t\treturn -ENODEV;\n\t}\n\n\tsas_init_dev(dev);\n\n\tdev->port = port;\n\tswitch (dev->dev_type) {\n\tcase SAS_SATA_DEV:\n\t\trc = sas_ata_init(dev);\n\t\tif (rc) {\n\t\t\trphy = NULL;\n\t\t\tbreak;\n\t\t}\n\t\t/* fall through */\n\tcase SAS_END_DEVICE:\n\t\trphy = sas_end_device_alloc(port->port);\n\t\tbreak;\n\tcase SAS_EDGE_EXPANDER_DEVICE:\n\t\trphy = sas_expander_alloc(port->port,\n\t\t\t\t\t  SAS_EDGE_EXPANDER_DEVICE);\n\t\tbreak;\n\tcase SAS_FANOUT_EXPANDER_DEVICE:\n\t\trphy = sas_expander_alloc(port->port,\n\t\t\t\t\t  SAS_FANOUT_EXPANDER_DEVICE);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"ERROR: Unidentified device type %d\\n\", dev->dev_type);\n\t\trphy = NULL;\n\t\tbreak;\n\t}\n\n\tif (!rphy) {\n\t\tsas_put_device(dev);\n\t\treturn rc;\n\t}\n\n\trphy->identify.phy_identifier = phy->phy->identify.phy_identifier;\n\tmemcpy(dev->sas_addr, port->attached_sas_addr, SAS_ADDR_SIZE);\n\tsas_fill_in_rphy(dev, rphy);\n\tsas_hash_addr(dev->hashed_sas_addr, dev->sas_addr);\n\tport->port_dev = dev;\n\tdev->linkrate = port->linkrate;\n\tdev->min_linkrate = port->linkrate;\n\tdev->max_linkrate = port->linkrate;\n\tdev->pathways = port->num_phys;\n\tmemset(port->disc.fanout_sas_addr, 0, SAS_ADDR_SIZE);\n\tmemset(port->disc.eeds_a, 0, SAS_ADDR_SIZE);\n\tmemset(port->disc.eeds_b, 0, SAS_ADDR_SIZE);\n\tport->disc.max_level = 0;\n\tsas_device_set_phy(dev, port->port);\n\n\tdev->rphy = rphy;\n\tget_device(&dev->rphy->dev);\n\n\tif (dev_is_sata(dev) || dev->dev_type == SAS_END_DEVICE)\n\t\tlist_add_tail(&dev->disco_list_node, &port->disco_list);\n\telse {\n\t\tspin_lock_irq(&port->dev_list_lock);\n\t\tlist_add_tail(&dev->dev_list_node, &port->dev_list);\n\t\tspin_unlock_irq(&port->dev_list_lock);\n\t}\n\n\tspin_lock_irq(&port->phy_list_lock);\n\tlist_for_each_entry(phy, &port->phy_list, port_phy_el)\n\t\tsas_phy_set_target(phy, dev);\n\tspin_unlock_irq(&port->phy_list_lock);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,12 +32,21 @@\n \t\telse\n \t\t\tdev->dev_type = SAS_SATA_DEV;\n \t\tdev->tproto = SAS_PROTOCOL_SATA;\n-\t} else {\n+\t} else if (port->oob_mode == SAS_OOB_MODE) {\n \t\tstruct sas_identify_frame *id =\n \t\t\t(struct sas_identify_frame *) dev->frame_rcvd;\n \t\tdev->dev_type = id->dev_type;\n \t\tdev->iproto = id->initiator_bits;\n \t\tdev->tproto = id->target_bits;\n+\t} else {\n+\t\t/* If the oob mode is OOB_NOT_CONNECTED, the port is\n+\t\t * disconnected due to race with PHY down. We cannot\n+\t\t * continue to discover this port\n+\t\t */\n+\t\tsas_put_device(dev);\n+\t\tpr_warn(\"Port %016llx is disconnected when discovering\\n\",\n+\t\t\tSAS_ADDR(port->attached_sas_addr));\n+\t\treturn -ENODEV;\n \t}\n \n \tsas_init_dev(dev);",
        "function_modified_lines": {
            "added": [
                "\t} else if (port->oob_mode == SAS_OOB_MODE) {",
                "\t} else {",
                "\t\t/* If the oob mode is OOB_NOT_CONNECTED, the port is",
                "\t\t * disconnected due to race with PHY down. We cannot",
                "\t\t * continue to discover this port",
                "\t\t */",
                "\t\tsas_put_device(dev);",
                "\t\tpr_warn(\"Port %016llx is disconnected when discovering\\n\",",
                "\t\t\tSAS_ADDR(port->attached_sas_addr));",
                "\t\treturn -ENODEV;"
            ],
            "deleted": [
                "\t} else {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel through 5.4.6, there is a NULL pointer dereference in drivers/scsi/libsas/sas_discover.c because of mishandling of port disconnection during discovery, related to a PHY down race condition, aka CID-f70267f379b5.",
        "id": 2269
    },
    {
        "cve_id": "CVE-2019-19036",
        "code_before_change": "int btrfs_verify_level_key(struct extent_buffer *eb, int level,\n\t\t\t   struct btrfs_key *first_key, u64 parent_transid)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tint found_level;\n\tstruct btrfs_key found_key;\n\tint ret;\n\n\tfound_level = btrfs_header_level(eb);\n\tif (found_level != level) {\n\t\tWARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),\n\t\t     KERN_ERR \"BTRFS: tree level check failed\\n\");\n\t\tbtrfs_err(fs_info,\n\"tree level mismatch detected, bytenr=%llu level expected=%u has=%u\",\n\t\t\t  eb->start, level, found_level);\n\t\treturn -EIO;\n\t}\n\n\tif (!first_key)\n\t\treturn 0;\n\n\t/*\n\t * For live tree block (new tree blocks in current transaction),\n\t * we need proper lock context to avoid race, which is impossible here.\n\t * So we only checks tree blocks which is read from disk, whose\n\t * generation <= fs_info->last_trans_committed.\n\t */\n\tif (btrfs_header_generation(eb) > fs_info->last_trans_committed)\n\t\treturn 0;\n\tif (found_level)\n\t\tbtrfs_node_key_to_cpu(eb, &found_key, 0);\n\telse\n\t\tbtrfs_item_key_to_cpu(eb, &found_key, 0);\n\tret = btrfs_comp_cpu_keys(first_key, &found_key);\n\n\tif (ret) {\n\t\tWARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),\n\t\t     KERN_ERR \"BTRFS: tree first key check failed\\n\");\n\t\tbtrfs_err(fs_info,\n\"tree first key mismatch detected, bytenr=%llu parent_transid=%llu key expected=(%llu,%u,%llu) has=(%llu,%u,%llu)\",\n\t\t\t  eb->start, parent_transid, first_key->objectid,\n\t\t\t  first_key->type, first_key->offset,\n\t\t\t  found_key.objectid, found_key.type,\n\t\t\t  found_key.offset);\n\t}\n\treturn ret;\n}",
        "code_after_change": "int btrfs_verify_level_key(struct extent_buffer *eb, int level,\n\t\t\t   struct btrfs_key *first_key, u64 parent_transid)\n{\n\tstruct btrfs_fs_info *fs_info = eb->fs_info;\n\tint found_level;\n\tstruct btrfs_key found_key;\n\tint ret;\n\n\tfound_level = btrfs_header_level(eb);\n\tif (found_level != level) {\n\t\tWARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),\n\t\t     KERN_ERR \"BTRFS: tree level check failed\\n\");\n\t\tbtrfs_err(fs_info,\n\"tree level mismatch detected, bytenr=%llu level expected=%u has=%u\",\n\t\t\t  eb->start, level, found_level);\n\t\treturn -EIO;\n\t}\n\n\tif (!first_key)\n\t\treturn 0;\n\n\t/*\n\t * For live tree block (new tree blocks in current transaction),\n\t * we need proper lock context to avoid race, which is impossible here.\n\t * So we only checks tree blocks which is read from disk, whose\n\t * generation <= fs_info->last_trans_committed.\n\t */\n\tif (btrfs_header_generation(eb) > fs_info->last_trans_committed)\n\t\treturn 0;\n\n\t/* We have @first_key, so this @eb must have at least one item */\n\tif (btrfs_header_nritems(eb) == 0) {\n\t\tbtrfs_err(fs_info,\n\t\t\"invalid tree nritems, bytenr=%llu nritems=0 expect >0\",\n\t\t\t  eb->start);\n\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));\n\t\treturn -EUCLEAN;\n\t}\n\n\tif (found_level)\n\t\tbtrfs_node_key_to_cpu(eb, &found_key, 0);\n\telse\n\t\tbtrfs_item_key_to_cpu(eb, &found_key, 0);\n\tret = btrfs_comp_cpu_keys(first_key, &found_key);\n\n\tif (ret) {\n\t\tWARN(IS_ENABLED(CONFIG_BTRFS_DEBUG),\n\t\t     KERN_ERR \"BTRFS: tree first key check failed\\n\");\n\t\tbtrfs_err(fs_info,\n\"tree first key mismatch detected, bytenr=%llu parent_transid=%llu key expected=(%llu,%u,%llu) has=(%llu,%u,%llu)\",\n\t\t\t  eb->start, parent_transid, first_key->objectid,\n\t\t\t  first_key->type, first_key->offset,\n\t\t\t  found_key.objectid, found_key.type,\n\t\t\t  found_key.offset);\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,6 +27,16 @@\n \t */\n \tif (btrfs_header_generation(eb) > fs_info->last_trans_committed)\n \t\treturn 0;\n+\n+\t/* We have @first_key, so this @eb must have at least one item */\n+\tif (btrfs_header_nritems(eb) == 0) {\n+\t\tbtrfs_err(fs_info,\n+\t\t\"invalid tree nritems, bytenr=%llu nritems=0 expect >0\",\n+\t\t\t  eb->start);\n+\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));\n+\t\treturn -EUCLEAN;\n+\t}\n+\n \tif (found_level)\n \t\tbtrfs_node_key_to_cpu(eb, &found_key, 0);\n \telse",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* We have @first_key, so this @eb must have at least one item */",
                "\tif (btrfs_header_nritems(eb) == 0) {",
                "\t\tbtrfs_err(fs_info,",
                "\t\t\"invalid tree nritems, bytenr=%llu nritems=0 expect >0\",",
                "\t\t\t  eb->start);",
                "\t\tWARN_ON(IS_ENABLED(CONFIG_BTRFS_DEBUG));",
                "\t\treturn -EUCLEAN;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "btrfs_root_node in fs/btrfs/ctree.c in the Linux kernel through 5.3.12 allows a NULL pointer dereference because rcu_dereference(root->node) can be zero.",
        "id": 2120
    },
    {
        "cve_id": "CVE-2017-15274",
        "code_before_change": " */\nSYSCALL_DEFINE5(add_key, const char __user *, _type,\n\t\tconst char __user *, _description,\n\t\tconst void __user *, _payload,\n\t\tsize_t, plen,\n\t\tkey_serial_t, ringid)\n{\n\tkey_ref_t keyring_ref, key_ref;\n\tchar type[32], *description;\n\tvoid *payload;\n\tlong ret;\n\n\tret = -EINVAL;\n\tif (plen > 1024 * 1024 - 1)\n\t\tgoto error;\n\n\t/* draw all the data into kernel space */\n\tret = key_get_type_from_user(type, _type, sizeof(type));\n\tif (ret < 0)\n\t\tgoto error;\n\n\tdescription = NULL;\n\tif (_description) {\n\t\tdescription = strndup_user(_description, KEY_MAX_DESC_SIZE);\n\t\tif (IS_ERR(description)) {\n\t\t\tret = PTR_ERR(description);\n\t\t\tgoto error;\n\t\t}\n\t\tif (!*description) {\n\t\t\tkfree(description);\n\t\t\tdescription = NULL;\n\t\t} else if ((description[0] == '.') &&\n\t\t\t   (strncmp(type, \"keyring\", 7) == 0)) {\n\t\t\tret = -EPERM;\n\t\t\tgoto error2;\n\t\t}\n\t}\n\n\t/* pull the payload in if one was supplied */\n\tpayload = NULL;\n\n\tif (_payload) {\n\t\tret = -ENOMEM;\n\t\tpayload = kvmalloc(plen, GFP_KERNEL);\n\t\tif (!payload)\n\t\t\tgoto error2;\n\n\t\tret = -EFAULT;\n\t\tif (copy_from_user(payload, _payload, plen) != 0)\n\t\t\tgoto error3;\n\t}\n\n\t/* find the target keyring (which must be writable) */\n\tkeyring_ref = lookup_user_key(ringid, KEY_LOOKUP_CREATE, KEY_NEED_WRITE);\n\tif (IS_ERR(keyring_ref)) {\n\t\tret = PTR_ERR(keyring_ref);\n\t\tgoto error3;\n\t}\n\n\t/* create or update the requested key and add it to the target\n\t * keyring */\n\tkey_ref = key_create_or_update(keyring_ref, type, description,\n\t\t\t\t       payload, plen, KEY_PERM_UNDEF,\n\t\t\t\t       KEY_ALLOC_IN_QUOTA);\n\tif (!IS_ERR(key_ref)) {\n\t\tret = key_ref_to_ptr(key_ref)->serial;\n\t\tkey_ref_put(key_ref);\n\t}\n\telse {\n\t\tret = PTR_ERR(key_ref);\n\t}\n\n\tkey_ref_put(keyring_ref);\n error3:\n\tkvfree(payload);\n error2:\n\tkfree(description);\n error:\n\treturn ret;\n}",
        "code_after_change": " */\nSYSCALL_DEFINE5(add_key, const char __user *, _type,\n\t\tconst char __user *, _description,\n\t\tconst void __user *, _payload,\n\t\tsize_t, plen,\n\t\tkey_serial_t, ringid)\n{\n\tkey_ref_t keyring_ref, key_ref;\n\tchar type[32], *description;\n\tvoid *payload;\n\tlong ret;\n\n\tret = -EINVAL;\n\tif (plen > 1024 * 1024 - 1)\n\t\tgoto error;\n\n\t/* draw all the data into kernel space */\n\tret = key_get_type_from_user(type, _type, sizeof(type));\n\tif (ret < 0)\n\t\tgoto error;\n\n\tdescription = NULL;\n\tif (_description) {\n\t\tdescription = strndup_user(_description, KEY_MAX_DESC_SIZE);\n\t\tif (IS_ERR(description)) {\n\t\t\tret = PTR_ERR(description);\n\t\t\tgoto error;\n\t\t}\n\t\tif (!*description) {\n\t\t\tkfree(description);\n\t\t\tdescription = NULL;\n\t\t} else if ((description[0] == '.') &&\n\t\t\t   (strncmp(type, \"keyring\", 7) == 0)) {\n\t\t\tret = -EPERM;\n\t\t\tgoto error2;\n\t\t}\n\t}\n\n\t/* pull the payload in if one was supplied */\n\tpayload = NULL;\n\n\tif (plen) {\n\t\tret = -ENOMEM;\n\t\tpayload = kvmalloc(plen, GFP_KERNEL);\n\t\tif (!payload)\n\t\t\tgoto error2;\n\n\t\tret = -EFAULT;\n\t\tif (copy_from_user(payload, _payload, plen) != 0)\n\t\t\tgoto error3;\n\t}\n\n\t/* find the target keyring (which must be writable) */\n\tkeyring_ref = lookup_user_key(ringid, KEY_LOOKUP_CREATE, KEY_NEED_WRITE);\n\tif (IS_ERR(keyring_ref)) {\n\t\tret = PTR_ERR(keyring_ref);\n\t\tgoto error3;\n\t}\n\n\t/* create or update the requested key and add it to the target\n\t * keyring */\n\tkey_ref = key_create_or_update(keyring_ref, type, description,\n\t\t\t\t       payload, plen, KEY_PERM_UNDEF,\n\t\t\t\t       KEY_ALLOC_IN_QUOTA);\n\tif (!IS_ERR(key_ref)) {\n\t\tret = key_ref_to_ptr(key_ref)->serial;\n\t\tkey_ref_put(key_ref);\n\t}\n\telse {\n\t\tret = PTR_ERR(key_ref);\n\t}\n\n\tkey_ref_put(keyring_ref);\n error3:\n\tkvfree(payload);\n error2:\n\tkfree(description);\n error:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,7 +39,7 @@\n \t/* pull the payload in if one was supplied */\n \tpayload = NULL;\n \n-\tif (_payload) {\n+\tif (plen) {\n \t\tret = -ENOMEM;\n \t\tpayload = kvmalloc(plen, GFP_KERNEL);\n \t\tif (!payload)",
        "function_modified_lines": {
            "added": [
                "\tif (plen) {"
            ],
            "deleted": [
                "\tif (_payload) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "security/keys/keyctl.c in the Linux kernel before 4.11.5 does not consider the case of a NULL payload in conjunction with a nonzero length value, which allows local users to cause a denial of service (NULL pointer dereference and OOPS) via a crafted add_key or keyctl system call, a different vulnerability than CVE-2017-12192.",
        "id": 1303
    },
    {
        "cve_id": "CVE-2021-44879",
        "code_before_change": "static int gc_data_segment(struct f2fs_sb_info *sbi, struct f2fs_summary *sum,\n\t\tstruct gc_inode_list *gc_list, unsigned int segno, int gc_type,\n\t\tbool force_migrate)\n{\n\tstruct super_block *sb = sbi->sb;\n\tstruct f2fs_summary *entry;\n\tblock_t start_addr;\n\tint off;\n\tint phase = 0;\n\tint submitted = 0;\n\tunsigned int usable_blks_in_seg = f2fs_usable_blks_in_seg(sbi, segno);\n\n\tstart_addr = START_BLOCK(sbi, segno);\n\nnext_step:\n\tentry = sum;\n\n\tfor (off = 0; off < usable_blks_in_seg; off++, entry++) {\n\t\tstruct page *data_page;\n\t\tstruct inode *inode;\n\t\tstruct node_info dni; /* dnode info for the data */\n\t\tunsigned int ofs_in_node, nofs;\n\t\tblock_t start_bidx;\n\t\tnid_t nid = le32_to_cpu(entry->nid);\n\n\t\t/*\n\t\t * stop BG_GC if there is not enough free sections.\n\t\t * Or, stop GC if the segment becomes fully valid caused by\n\t\t * race condition along with SSR block allocation.\n\t\t */\n\t\tif ((gc_type == BG_GC && has_not_enough_free_secs(sbi, 0, 0)) ||\n\t\t\t(!force_migrate && get_valid_blocks(sbi, segno, true) ==\n\t\t\t\t\t\t\tBLKS_PER_SEC(sbi)))\n\t\t\treturn submitted;\n\n\t\tif (check_valid_map(sbi, segno, off) == 0)\n\t\t\tcontinue;\n\n\t\tif (phase == 0) {\n\t\t\tf2fs_ra_meta_pages(sbi, NAT_BLOCK_OFFSET(nid), 1,\n\t\t\t\t\t\t\tMETA_NAT, true);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (phase == 1) {\n\t\t\tf2fs_ra_node_page(sbi, nid);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get an inode by ino with checking validity */\n\t\tif (!is_alive(sbi, entry, &dni, start_addr + off, &nofs))\n\t\t\tcontinue;\n\n\t\tif (phase == 2) {\n\t\t\tf2fs_ra_node_page(sbi, dni.ino);\n\t\t\tcontinue;\n\t\t}\n\n\t\tofs_in_node = le16_to_cpu(entry->ofs_in_node);\n\n\t\tif (phase == 3) {\n\t\t\tinode = f2fs_iget(sb, dni.ino);\n\t\t\tif (IS_ERR(inode) || is_bad_inode(inode))\n\t\t\t\tcontinue;\n\n\t\t\tif (!down_write_trylock(\n\t\t\t\t&F2FS_I(inode)->i_gc_rwsem[WRITE])) {\n\t\t\t\tiput(inode);\n\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tstart_bidx = f2fs_start_bidx_of_node(nofs, inode) +\n\t\t\t\t\t\t\t\tofs_in_node;\n\n\t\t\tif (f2fs_post_read_required(inode)) {\n\t\t\t\tint err = ra_data_block(inode, start_bidx);\n\n\t\t\t\tup_write(&F2FS_I(inode)->i_gc_rwsem[WRITE]);\n\t\t\t\tif (err) {\n\t\t\t\t\tiput(inode);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tadd_gc_inode(gc_list, inode);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tdata_page = f2fs_get_read_data_page(inode,\n\t\t\t\t\t\tstart_bidx, REQ_RAHEAD, true);\n\t\t\tup_write(&F2FS_I(inode)->i_gc_rwsem[WRITE]);\n\t\t\tif (IS_ERR(data_page)) {\n\t\t\t\tiput(inode);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf2fs_put_page(data_page, 0);\n\t\t\tadd_gc_inode(gc_list, inode);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* phase 4 */\n\t\tinode = find_gc_inode(gc_list, dni.ino);\n\t\tif (inode) {\n\t\t\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\t\t\tbool locked = false;\n\t\t\tint err;\n\n\t\t\tif (S_ISREG(inode->i_mode)) {\n\t\t\t\tif (!down_write_trylock(&fi->i_gc_rwsem[READ])) {\n\t\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (!down_write_trylock(\n\t\t\t\t\t\t&fi->i_gc_rwsem[WRITE])) {\n\t\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\t\tup_write(&fi->i_gc_rwsem[READ]);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tlocked = true;\n\n\t\t\t\t/* wait for all inflight aio data */\n\t\t\t\tinode_dio_wait(inode);\n\t\t\t}\n\n\t\t\tstart_bidx = f2fs_start_bidx_of_node(nofs, inode)\n\t\t\t\t\t\t\t\t+ ofs_in_node;\n\t\t\tif (f2fs_post_read_required(inode))\n\t\t\t\terr = move_data_block(inode, start_bidx,\n\t\t\t\t\t\t\tgc_type, segno, off);\n\t\t\telse\n\t\t\t\terr = move_data_page(inode, start_bidx, gc_type,\n\t\t\t\t\t\t\t\tsegno, off);\n\n\t\t\tif (!err && (gc_type == FG_GC ||\n\t\t\t\t\tf2fs_post_read_required(inode)))\n\t\t\t\tsubmitted++;\n\n\t\t\tif (locked) {\n\t\t\t\tup_write(&fi->i_gc_rwsem[WRITE]);\n\t\t\t\tup_write(&fi->i_gc_rwsem[READ]);\n\t\t\t}\n\n\t\t\tstat_inc_data_blk_count(sbi, 1, gc_type);\n\t\t}\n\t}\n\n\tif (++phase < 5)\n\t\tgoto next_step;\n\n\treturn submitted;\n}",
        "code_after_change": "static int gc_data_segment(struct f2fs_sb_info *sbi, struct f2fs_summary *sum,\n\t\tstruct gc_inode_list *gc_list, unsigned int segno, int gc_type,\n\t\tbool force_migrate)\n{\n\tstruct super_block *sb = sbi->sb;\n\tstruct f2fs_summary *entry;\n\tblock_t start_addr;\n\tint off;\n\tint phase = 0;\n\tint submitted = 0;\n\tunsigned int usable_blks_in_seg = f2fs_usable_blks_in_seg(sbi, segno);\n\n\tstart_addr = START_BLOCK(sbi, segno);\n\nnext_step:\n\tentry = sum;\n\n\tfor (off = 0; off < usable_blks_in_seg; off++, entry++) {\n\t\tstruct page *data_page;\n\t\tstruct inode *inode;\n\t\tstruct node_info dni; /* dnode info for the data */\n\t\tunsigned int ofs_in_node, nofs;\n\t\tblock_t start_bidx;\n\t\tnid_t nid = le32_to_cpu(entry->nid);\n\n\t\t/*\n\t\t * stop BG_GC if there is not enough free sections.\n\t\t * Or, stop GC if the segment becomes fully valid caused by\n\t\t * race condition along with SSR block allocation.\n\t\t */\n\t\tif ((gc_type == BG_GC && has_not_enough_free_secs(sbi, 0, 0)) ||\n\t\t\t(!force_migrate && get_valid_blocks(sbi, segno, true) ==\n\t\t\t\t\t\t\tBLKS_PER_SEC(sbi)))\n\t\t\treturn submitted;\n\n\t\tif (check_valid_map(sbi, segno, off) == 0)\n\t\t\tcontinue;\n\n\t\tif (phase == 0) {\n\t\t\tf2fs_ra_meta_pages(sbi, NAT_BLOCK_OFFSET(nid), 1,\n\t\t\t\t\t\t\tMETA_NAT, true);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (phase == 1) {\n\t\t\tf2fs_ra_node_page(sbi, nid);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get an inode by ino with checking validity */\n\t\tif (!is_alive(sbi, entry, &dni, start_addr + off, &nofs))\n\t\t\tcontinue;\n\n\t\tif (phase == 2) {\n\t\t\tf2fs_ra_node_page(sbi, dni.ino);\n\t\t\tcontinue;\n\t\t}\n\n\t\tofs_in_node = le16_to_cpu(entry->ofs_in_node);\n\n\t\tif (phase == 3) {\n\t\t\tinode = f2fs_iget(sb, dni.ino);\n\t\t\tif (IS_ERR(inode) || is_bad_inode(inode) ||\n\t\t\t\t\tspecial_file(inode->i_mode))\n\t\t\t\tcontinue;\n\n\t\t\tif (!down_write_trylock(\n\t\t\t\t&F2FS_I(inode)->i_gc_rwsem[WRITE])) {\n\t\t\t\tiput(inode);\n\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tstart_bidx = f2fs_start_bidx_of_node(nofs, inode) +\n\t\t\t\t\t\t\t\tofs_in_node;\n\n\t\t\tif (f2fs_post_read_required(inode)) {\n\t\t\t\tint err = ra_data_block(inode, start_bidx);\n\n\t\t\t\tup_write(&F2FS_I(inode)->i_gc_rwsem[WRITE]);\n\t\t\t\tif (err) {\n\t\t\t\t\tiput(inode);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tadd_gc_inode(gc_list, inode);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tdata_page = f2fs_get_read_data_page(inode,\n\t\t\t\t\t\tstart_bidx, REQ_RAHEAD, true);\n\t\t\tup_write(&F2FS_I(inode)->i_gc_rwsem[WRITE]);\n\t\t\tif (IS_ERR(data_page)) {\n\t\t\t\tiput(inode);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tf2fs_put_page(data_page, 0);\n\t\t\tadd_gc_inode(gc_list, inode);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* phase 4 */\n\t\tinode = find_gc_inode(gc_list, dni.ino);\n\t\tif (inode) {\n\t\t\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\t\t\tbool locked = false;\n\t\t\tint err;\n\n\t\t\tif (S_ISREG(inode->i_mode)) {\n\t\t\t\tif (!down_write_trylock(&fi->i_gc_rwsem[READ])) {\n\t\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (!down_write_trylock(\n\t\t\t\t\t\t&fi->i_gc_rwsem[WRITE])) {\n\t\t\t\t\tsbi->skipped_gc_rwsem++;\n\t\t\t\t\tup_write(&fi->i_gc_rwsem[READ]);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tlocked = true;\n\n\t\t\t\t/* wait for all inflight aio data */\n\t\t\t\tinode_dio_wait(inode);\n\t\t\t}\n\n\t\t\tstart_bidx = f2fs_start_bidx_of_node(nofs, inode)\n\t\t\t\t\t\t\t\t+ ofs_in_node;\n\t\t\tif (f2fs_post_read_required(inode))\n\t\t\t\terr = move_data_block(inode, start_bidx,\n\t\t\t\t\t\t\tgc_type, segno, off);\n\t\t\telse\n\t\t\t\terr = move_data_page(inode, start_bidx, gc_type,\n\t\t\t\t\t\t\t\tsegno, off);\n\n\t\t\tif (!err && (gc_type == FG_GC ||\n\t\t\t\t\tf2fs_post_read_required(inode)))\n\t\t\t\tsubmitted++;\n\n\t\t\tif (locked) {\n\t\t\t\tup_write(&fi->i_gc_rwsem[WRITE]);\n\t\t\t\tup_write(&fi->i_gc_rwsem[READ]);\n\t\t\t}\n\n\t\t\tstat_inc_data_blk_count(sbi, 1, gc_type);\n\t\t}\n\t}\n\n\tif (++phase < 5)\n\t\tgoto next_step;\n\n\treturn submitted;\n}",
        "patch": "--- code before\n+++ code after\n@@ -60,7 +60,8 @@\n \n \t\tif (phase == 3) {\n \t\t\tinode = f2fs_iget(sb, dni.ino);\n-\t\t\tif (IS_ERR(inode) || is_bad_inode(inode))\n+\t\t\tif (IS_ERR(inode) || is_bad_inode(inode) ||\n+\t\t\t\t\tspecial_file(inode->i_mode))\n \t\t\t\tcontinue;\n \n \t\t\tif (!down_write_trylock(",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (IS_ERR(inode) || is_bad_inode(inode) ||",
                "\t\t\t\t\tspecial_file(inode->i_mode))"
            ],
            "deleted": [
                "\t\t\tif (IS_ERR(inode) || is_bad_inode(inode))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In gc_data_segment in fs/f2fs/gc.c in the Linux kernel before 5.16.3, special files are not considered, leading to a move_data_page NULL pointer dereference.",
        "id": 3173
    },
    {
        "cve_id": "CVE-2023-1583",
        "code_before_change": "static int io_file_bitmap_get(struct io_ring_ctx *ctx)\n{\n\tstruct io_file_table *table = &ctx->file_table;\n\tunsigned long nr = ctx->file_alloc_end;\n\tint ret;\n\n\tdo {\n\t\tret = find_next_zero_bit(table->bitmap, nr, table->alloc_hint);\n\t\tif (ret != nr)\n\t\t\treturn ret;\n\n\t\tif (table->alloc_hint == ctx->file_alloc_start)\n\t\t\tbreak;\n\t\tnr = table->alloc_hint;\n\t\ttable->alloc_hint = ctx->file_alloc_start;\n\t} while (1);\n\n\treturn -ENFILE;\n}",
        "code_after_change": "static int io_file_bitmap_get(struct io_ring_ctx *ctx)\n{\n\tstruct io_file_table *table = &ctx->file_table;\n\tunsigned long nr = ctx->file_alloc_end;\n\tint ret;\n\n\tif (!table->bitmap)\n\t\treturn -ENFILE;\n\n\tdo {\n\t\tret = find_next_zero_bit(table->bitmap, nr, table->alloc_hint);\n\t\tif (ret != nr)\n\t\t\treturn ret;\n\n\t\tif (table->alloc_hint == ctx->file_alloc_start)\n\t\t\tbreak;\n\t\tnr = table->alloc_hint;\n\t\ttable->alloc_hint = ctx->file_alloc_start;\n\t} while (1);\n\n\treturn -ENFILE;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,9 @@\n \tstruct io_file_table *table = &ctx->file_table;\n \tunsigned long nr = ctx->file_alloc_end;\n \tint ret;\n+\n+\tif (!table->bitmap)\n+\t\treturn -ENFILE;\n \n \tdo {\n \t\tret = find_next_zero_bit(table->bitmap, nr, table->alloc_hint);",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!table->bitmap)",
                "\t\treturn -ENFILE;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference was found in io_file_bitmap_get in io_uring/filetable.c in the io_uring sub-component in the Linux Kernel. When fixed files are unregistered, some context information (file_alloc_{start,end} and alloc_hint) is not cleared. A subsequent request that has auto index selection enabled via IORING_FILE_INDEX_ALLOC can cause a NULL pointer dereference. An unprivileged user can use the flaw to cause a system crash.",
        "id": 3872
    },
    {
        "cve_id": "CVE-2023-3359",
        "code_before_change": "static int brcm_nvram_parse(struct brcm_nvram *priv)\n{\n\tstruct device *dev = priv->dev;\n\tstruct brcm_nvram_header header;\n\tuint8_t *data;\n\tsize_t len;\n\tint err;\n\n\tmemcpy_fromio(&header, priv->base, sizeof(header));\n\n\tif (memcmp(header.magic, NVRAM_MAGIC, 4)) {\n\t\tdev_err(dev, \"Invalid NVRAM magic\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tlen = le32_to_cpu(header.len);\n\n\tdata = kzalloc(len, GFP_KERNEL);\n\tmemcpy_fromio(data, priv->base, len);\n\tdata[len - 1] = '\\0';\n\n\terr = brcm_nvram_add_cells(priv, data, len);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to add cells: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tkfree(data);\n\n\treturn 0;\n}",
        "code_after_change": "static int brcm_nvram_parse(struct brcm_nvram *priv)\n{\n\tstruct device *dev = priv->dev;\n\tstruct brcm_nvram_header header;\n\tuint8_t *data;\n\tsize_t len;\n\tint err;\n\n\tmemcpy_fromio(&header, priv->base, sizeof(header));\n\n\tif (memcmp(header.magic, NVRAM_MAGIC, 4)) {\n\t\tdev_err(dev, \"Invalid NVRAM magic\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tlen = le32_to_cpu(header.len);\n\n\tdata = kzalloc(len, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tmemcpy_fromio(data, priv->base, len);\n\tdata[len - 1] = '\\0';\n\n\terr = brcm_nvram_add_cells(priv, data, len);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to add cells: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tkfree(data);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,6 +16,9 @@\n \tlen = le32_to_cpu(header.len);\n \n \tdata = kzalloc(len, GFP_KERNEL);\n+\tif (!data)\n+\t\treturn -ENOMEM;\n+\n \tmemcpy_fromio(data, priv->base, len);\n \tdata[len - 1] = '\\0';\n ",
        "function_modified_lines": {
            "added": [
                "\tif (!data)",
                "\t\treturn -ENOMEM;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel brcm_nvram_parse in drivers/nvmem/brcm_nvram.c. Lacks for the check of the return value of kzalloc() can cause the NULL Pointer Dereference.",
        "id": 4064
    },
    {
        "cve_id": "CVE-2020-14356",
        "code_before_change": "struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority)\n{\n\tstruct proto *prot = READ_ONCE(sk->sk_prot);\n\tstruct sock *newsk;\n\tbool is_charged = true;\n\n\tnewsk = sk_prot_alloc(prot, priority, sk->sk_family);\n\tif (newsk != NULL) {\n\t\tstruct sk_filter *filter;\n\n\t\tsock_copy(newsk, sk);\n\n\t\tnewsk->sk_prot_creator = prot;\n\n\t\t/* SANITY */\n\t\tif (likely(newsk->sk_net_refcnt))\n\t\t\tget_net(sock_net(newsk));\n\t\tsk_node_init(&newsk->sk_node);\n\t\tsock_lock_init(newsk);\n\t\tbh_lock_sock(newsk);\n\t\tnewsk->sk_backlog.head\t= newsk->sk_backlog.tail = NULL;\n\t\tnewsk->sk_backlog.len = 0;\n\n\t\tatomic_set(&newsk->sk_rmem_alloc, 0);\n\t\t/*\n\t\t * sk_wmem_alloc set to one (see sk_free() and sock_wfree())\n\t\t */\n\t\trefcount_set(&newsk->sk_wmem_alloc, 1);\n\t\tatomic_set(&newsk->sk_omem_alloc, 0);\n\t\tsk_init_common(newsk);\n\n\t\tnewsk->sk_dst_cache\t= NULL;\n\t\tnewsk->sk_dst_pending_confirm = 0;\n\t\tnewsk->sk_wmem_queued\t= 0;\n\t\tnewsk->sk_forward_alloc = 0;\n\t\tatomic_set(&newsk->sk_drops, 0);\n\t\tnewsk->sk_send_head\t= NULL;\n\t\tnewsk->sk_userlocks\t= sk->sk_userlocks & ~SOCK_BINDPORT_LOCK;\n\t\tatomic_set(&newsk->sk_zckey, 0);\n\n\t\tsock_reset_flag(newsk, SOCK_DONE);\n\n\t\t/* sk->sk_memcg will be populated at accept() time */\n\t\tnewsk->sk_memcg = NULL;\n\n\t\tcgroup_sk_alloc(&newsk->sk_cgrp_data);\n\n\t\trcu_read_lock();\n\t\tfilter = rcu_dereference(sk->sk_filter);\n\t\tif (filter != NULL)\n\t\t\t/* though it's an empty new sock, the charging may fail\n\t\t\t * if sysctl_optmem_max was changed between creation of\n\t\t\t * original socket and cloning\n\t\t\t */\n\t\t\tis_charged = sk_filter_charge(newsk, filter);\n\t\tRCU_INIT_POINTER(newsk->sk_filter, filter);\n\t\trcu_read_unlock();\n\n\t\tif (unlikely(!is_charged || xfrm_sk_clone_policy(newsk, sk))) {\n\t\t\t/* We need to make sure that we don't uncharge the new\n\t\t\t * socket if we couldn't charge it in the first place\n\t\t\t * as otherwise we uncharge the parent's filter.\n\t\t\t */\n\t\t\tif (!is_charged)\n\t\t\t\tRCU_INIT_POINTER(newsk->sk_filter, NULL);\n\t\t\tsk_free_unlock_clone(newsk);\n\t\t\tnewsk = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\tRCU_INIT_POINTER(newsk->sk_reuseport_cb, NULL);\n\n\t\tif (bpf_sk_storage_clone(sk, newsk)) {\n\t\t\tsk_free_unlock_clone(newsk);\n\t\t\tnewsk = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Clear sk_user_data if parent had the pointer tagged\n\t\t * as not suitable for copying when cloning.\n\t\t */\n\t\tif (sk_user_data_is_nocopy(newsk))\n\t\t\tnewsk->sk_user_data = NULL;\n\n\t\tnewsk->sk_err\t   = 0;\n\t\tnewsk->sk_err_soft = 0;\n\t\tnewsk->sk_priority = 0;\n\t\tnewsk->sk_incoming_cpu = raw_smp_processor_id();\n\t\tif (likely(newsk->sk_net_refcnt))\n\t\t\tsock_inuse_add(sock_net(newsk), 1);\n\n\t\t/*\n\t\t * Before updating sk_refcnt, we must commit prior changes to memory\n\t\t * (Documentation/RCU/rculist_nulls.txt for details)\n\t\t */\n\t\tsmp_wmb();\n\t\trefcount_set(&newsk->sk_refcnt, 2);\n\n\t\t/*\n\t\t * Increment the counter in the same struct proto as the master\n\t\t * sock (sk_refcnt_debug_inc uses newsk->sk_prot->socks, that\n\t\t * is the same as sk->sk_prot->socks, as this field was copied\n\t\t * with memcpy).\n\t\t *\n\t\t * This _changes_ the previous behaviour, where\n\t\t * tcp_create_openreq_child always was incrementing the\n\t\t * equivalent to tcp_prot->socks (inet_sock_nr), so this have\n\t\t * to be taken into account in all callers. -acme\n\t\t */\n\t\tsk_refcnt_debug_inc(newsk);\n\t\tsk_set_socket(newsk, NULL);\n\t\tsk_tx_queue_clear(newsk);\n\t\tRCU_INIT_POINTER(newsk->sk_wq, NULL);\n\n\t\tif (newsk->sk_prot->sockets_allocated)\n\t\t\tsk_sockets_allocated_inc(newsk);\n\n\t\tif (sock_needs_netstamp(sk) &&\n\t\t    newsk->sk_flags & SK_FLAGS_TIMESTAMP)\n\t\t\tnet_enable_timestamp();\n\t}\nout:\n\treturn newsk;\n}",
        "code_after_change": "struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority)\n{\n\tstruct proto *prot = READ_ONCE(sk->sk_prot);\n\tstruct sock *newsk;\n\tbool is_charged = true;\n\n\tnewsk = sk_prot_alloc(prot, priority, sk->sk_family);\n\tif (newsk != NULL) {\n\t\tstruct sk_filter *filter;\n\n\t\tsock_copy(newsk, sk);\n\n\t\tnewsk->sk_prot_creator = prot;\n\n\t\t/* SANITY */\n\t\tif (likely(newsk->sk_net_refcnt))\n\t\t\tget_net(sock_net(newsk));\n\t\tsk_node_init(&newsk->sk_node);\n\t\tsock_lock_init(newsk);\n\t\tbh_lock_sock(newsk);\n\t\tnewsk->sk_backlog.head\t= newsk->sk_backlog.tail = NULL;\n\t\tnewsk->sk_backlog.len = 0;\n\n\t\tatomic_set(&newsk->sk_rmem_alloc, 0);\n\t\t/*\n\t\t * sk_wmem_alloc set to one (see sk_free() and sock_wfree())\n\t\t */\n\t\trefcount_set(&newsk->sk_wmem_alloc, 1);\n\t\tatomic_set(&newsk->sk_omem_alloc, 0);\n\t\tsk_init_common(newsk);\n\n\t\tnewsk->sk_dst_cache\t= NULL;\n\t\tnewsk->sk_dst_pending_confirm = 0;\n\t\tnewsk->sk_wmem_queued\t= 0;\n\t\tnewsk->sk_forward_alloc = 0;\n\t\tatomic_set(&newsk->sk_drops, 0);\n\t\tnewsk->sk_send_head\t= NULL;\n\t\tnewsk->sk_userlocks\t= sk->sk_userlocks & ~SOCK_BINDPORT_LOCK;\n\t\tatomic_set(&newsk->sk_zckey, 0);\n\n\t\tsock_reset_flag(newsk, SOCK_DONE);\n\n\t\t/* sk->sk_memcg will be populated at accept() time */\n\t\tnewsk->sk_memcg = NULL;\n\n\t\tcgroup_sk_clone(&newsk->sk_cgrp_data);\n\n\t\trcu_read_lock();\n\t\tfilter = rcu_dereference(sk->sk_filter);\n\t\tif (filter != NULL)\n\t\t\t/* though it's an empty new sock, the charging may fail\n\t\t\t * if sysctl_optmem_max was changed between creation of\n\t\t\t * original socket and cloning\n\t\t\t */\n\t\t\tis_charged = sk_filter_charge(newsk, filter);\n\t\tRCU_INIT_POINTER(newsk->sk_filter, filter);\n\t\trcu_read_unlock();\n\n\t\tif (unlikely(!is_charged || xfrm_sk_clone_policy(newsk, sk))) {\n\t\t\t/* We need to make sure that we don't uncharge the new\n\t\t\t * socket if we couldn't charge it in the first place\n\t\t\t * as otherwise we uncharge the parent's filter.\n\t\t\t */\n\t\t\tif (!is_charged)\n\t\t\t\tRCU_INIT_POINTER(newsk->sk_filter, NULL);\n\t\t\tsk_free_unlock_clone(newsk);\n\t\t\tnewsk = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\tRCU_INIT_POINTER(newsk->sk_reuseport_cb, NULL);\n\n\t\tif (bpf_sk_storage_clone(sk, newsk)) {\n\t\t\tsk_free_unlock_clone(newsk);\n\t\t\tnewsk = NULL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Clear sk_user_data if parent had the pointer tagged\n\t\t * as not suitable for copying when cloning.\n\t\t */\n\t\tif (sk_user_data_is_nocopy(newsk))\n\t\t\tnewsk->sk_user_data = NULL;\n\n\t\tnewsk->sk_err\t   = 0;\n\t\tnewsk->sk_err_soft = 0;\n\t\tnewsk->sk_priority = 0;\n\t\tnewsk->sk_incoming_cpu = raw_smp_processor_id();\n\t\tif (likely(newsk->sk_net_refcnt))\n\t\t\tsock_inuse_add(sock_net(newsk), 1);\n\n\t\t/*\n\t\t * Before updating sk_refcnt, we must commit prior changes to memory\n\t\t * (Documentation/RCU/rculist_nulls.txt for details)\n\t\t */\n\t\tsmp_wmb();\n\t\trefcount_set(&newsk->sk_refcnt, 2);\n\n\t\t/*\n\t\t * Increment the counter in the same struct proto as the master\n\t\t * sock (sk_refcnt_debug_inc uses newsk->sk_prot->socks, that\n\t\t * is the same as sk->sk_prot->socks, as this field was copied\n\t\t * with memcpy).\n\t\t *\n\t\t * This _changes_ the previous behaviour, where\n\t\t * tcp_create_openreq_child always was incrementing the\n\t\t * equivalent to tcp_prot->socks (inet_sock_nr), so this have\n\t\t * to be taken into account in all callers. -acme\n\t\t */\n\t\tsk_refcnt_debug_inc(newsk);\n\t\tsk_set_socket(newsk, NULL);\n\t\tsk_tx_queue_clear(newsk);\n\t\tRCU_INIT_POINTER(newsk->sk_wq, NULL);\n\n\t\tif (newsk->sk_prot->sockets_allocated)\n\t\t\tsk_sockets_allocated_inc(newsk);\n\n\t\tif (sock_needs_netstamp(sk) &&\n\t\t    newsk->sk_flags & SK_FLAGS_TIMESTAMP)\n\t\t\tnet_enable_timestamp();\n\t}\nout:\n\treturn newsk;\n}",
        "patch": "--- code before\n+++ code after\n@@ -43,7 +43,7 @@\n \t\t/* sk->sk_memcg will be populated at accept() time */\n \t\tnewsk->sk_memcg = NULL;\n \n-\t\tcgroup_sk_alloc(&newsk->sk_cgrp_data);\n+\t\tcgroup_sk_clone(&newsk->sk_cgrp_data);\n \n \t\trcu_read_lock();\n \t\tfilter = rcu_dereference(sk->sk_filter);",
        "function_modified_lines": {
            "added": [
                "\t\tcgroup_sk_clone(&newsk->sk_cgrp_data);"
            ],
            "deleted": [
                "\t\tcgroup_sk_alloc(&newsk->sk_cgrp_data);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw null pointer dereference in the Linux kernel cgroupv2 subsystem in versions before 5.7.10 was found in the way when reboot the system. A local user could use this flaw to crash the system or escalate their privileges on the system.",
        "id": 2518
    },
    {
        "cve_id": "CVE-2020-12364",
        "code_before_change": "static int intel_engine_setup(struct intel_gt *gt, enum intel_engine_id id)\n{\n\tconst struct engine_info *info = &intel_engines[id];\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_engine_cs *engine;\n\n\tBUILD_BUG_ON(MAX_ENGINE_CLASS >= BIT(GEN11_ENGINE_CLASS_WIDTH));\n\tBUILD_BUG_ON(MAX_ENGINE_INSTANCE >= BIT(GEN11_ENGINE_INSTANCE_WIDTH));\n\n\tif (GEM_DEBUG_WARN_ON(id >= ARRAY_SIZE(gt->engine)))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->class > MAX_ENGINE_CLASS))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->instance > MAX_ENGINE_INSTANCE))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(gt->engine_class[info->class][info->instance]))\n\t\treturn -EINVAL;\n\n\tengine = kzalloc(sizeof(*engine), GFP_KERNEL);\n\tif (!engine)\n\t\treturn -ENOMEM;\n\n\tBUILD_BUG_ON(BITS_PER_TYPE(engine->mask) < I915_NUM_ENGINES);\n\n\tengine->id = id;\n\tengine->legacy_idx = INVALID_ENGINE;\n\tengine->mask = BIT(id);\n\tengine->i915 = i915;\n\tengine->gt = gt;\n\tengine->uncore = gt->uncore;\n\tengine->hw_id = engine->guc_id = info->hw_id;\n\tengine->mmio_base = __engine_mmio_base(i915, info->mmio_bases);\n\n\tengine->class = info->class;\n\tengine->instance = info->instance;\n\t__sprint_engine_name(engine);\n\n\tengine->props.heartbeat_interval_ms =\n\t\tCONFIG_DRM_I915_HEARTBEAT_INTERVAL;\n\tengine->props.max_busywait_duration_ns =\n\t\tCONFIG_DRM_I915_MAX_REQUEST_BUSYWAIT;\n\tengine->props.preempt_timeout_ms =\n\t\tCONFIG_DRM_I915_PREEMPT_TIMEOUT;\n\tengine->props.stop_timeout_ms =\n\t\tCONFIG_DRM_I915_STOP_TIMEOUT;\n\tengine->props.timeslice_duration_ms =\n\t\tCONFIG_DRM_I915_TIMESLICE_DURATION;\n\n\t/* Override to uninterruptible for OpenCL workloads. */\n\tif (INTEL_GEN(i915) == 12 && engine->class == RENDER_CLASS)\n\t\tengine->props.preempt_timeout_ms = 0;\n\n\tengine->defaults = engine->props; /* never to change again */\n\n\tengine->context_size = intel_engine_context_size(gt, engine->class);\n\tif (WARN_ON(engine->context_size > BIT(20)))\n\t\tengine->context_size = 0;\n\tif (engine->context_size)\n\t\tDRIVER_CAPS(i915)->has_logical_contexts = true;\n\n\t/* Nothing to do here, execute in order of dependencies */\n\tengine->schedule = NULL;\n\n\tewma__engine_latency_init(&engine->latency);\n\tseqlock_init(&engine->stats.lock);\n\n\tATOMIC_INIT_NOTIFIER_HEAD(&engine->context_status_notifier);\n\n\t/* Scrub mmio state on takeover */\n\tintel_engine_sanitize_mmio(engine);\n\n\tgt->engine_class[info->class][info->instance] = engine;\n\tgt->engine[id] = engine;\n\n\treturn 0;\n}",
        "code_after_change": "static int intel_engine_setup(struct intel_gt *gt, enum intel_engine_id id)\n{\n\tconst struct engine_info *info = &intel_engines[id];\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_engine_cs *engine;\n\n\tBUILD_BUG_ON(MAX_ENGINE_CLASS >= BIT(GEN11_ENGINE_CLASS_WIDTH));\n\tBUILD_BUG_ON(MAX_ENGINE_INSTANCE >= BIT(GEN11_ENGINE_INSTANCE_WIDTH));\n\n\tif (GEM_DEBUG_WARN_ON(id >= ARRAY_SIZE(gt->engine)))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->class > MAX_ENGINE_CLASS))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->instance > MAX_ENGINE_INSTANCE))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(gt->engine_class[info->class][info->instance]))\n\t\treturn -EINVAL;\n\n\tengine = kzalloc(sizeof(*engine), GFP_KERNEL);\n\tif (!engine)\n\t\treturn -ENOMEM;\n\n\tBUILD_BUG_ON(BITS_PER_TYPE(engine->mask) < I915_NUM_ENGINES);\n\n\tengine->id = id;\n\tengine->legacy_idx = INVALID_ENGINE;\n\tengine->mask = BIT(id);\n\tengine->i915 = i915;\n\tengine->gt = gt;\n\tengine->uncore = gt->uncore;\n\tengine->mmio_base = __engine_mmio_base(i915, info->mmio_bases);\n\tengine->hw_id = info->hw_id;\n\tengine->guc_id = MAKE_GUC_ID(info->class, info->instance);\n\n\tengine->class = info->class;\n\tengine->instance = info->instance;\n\t__sprint_engine_name(engine);\n\n\tengine->props.heartbeat_interval_ms =\n\t\tCONFIG_DRM_I915_HEARTBEAT_INTERVAL;\n\tengine->props.max_busywait_duration_ns =\n\t\tCONFIG_DRM_I915_MAX_REQUEST_BUSYWAIT;\n\tengine->props.preempt_timeout_ms =\n\t\tCONFIG_DRM_I915_PREEMPT_TIMEOUT;\n\tengine->props.stop_timeout_ms =\n\t\tCONFIG_DRM_I915_STOP_TIMEOUT;\n\tengine->props.timeslice_duration_ms =\n\t\tCONFIG_DRM_I915_TIMESLICE_DURATION;\n\n\t/* Override to uninterruptible for OpenCL workloads. */\n\tif (INTEL_GEN(i915) == 12 && engine->class == RENDER_CLASS)\n\t\tengine->props.preempt_timeout_ms = 0;\n\n\tengine->defaults = engine->props; /* never to change again */\n\n\tengine->context_size = intel_engine_context_size(gt, engine->class);\n\tif (WARN_ON(engine->context_size > BIT(20)))\n\t\tengine->context_size = 0;\n\tif (engine->context_size)\n\t\tDRIVER_CAPS(i915)->has_logical_contexts = true;\n\n\t/* Nothing to do here, execute in order of dependencies */\n\tengine->schedule = NULL;\n\n\tewma__engine_latency_init(&engine->latency);\n\tseqlock_init(&engine->stats.lock);\n\n\tATOMIC_INIT_NOTIFIER_HEAD(&engine->context_status_notifier);\n\n\t/* Scrub mmio state on takeover */\n\tintel_engine_sanitize_mmio(engine);\n\n\tgt->engine_class[info->class][info->instance] = engine;\n\tgt->engine[id] = engine;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,8 +31,9 @@\n \tengine->i915 = i915;\n \tengine->gt = gt;\n \tengine->uncore = gt->uncore;\n-\tengine->hw_id = engine->guc_id = info->hw_id;\n \tengine->mmio_base = __engine_mmio_base(i915, info->mmio_bases);\n+\tengine->hw_id = info->hw_id;\n+\tengine->guc_id = MAKE_GUC_ID(info->class, info->instance);\n \n \tengine->class = info->class;\n \tengine->instance = info->instance;",
        "function_modified_lines": {
            "added": [
                "\tengine->hw_id = info->hw_id;",
                "\tengine->guc_id = MAKE_GUC_ID(info->class, info->instance);"
            ],
            "deleted": [
                "\tengine->hw_id = engine->guc_id = info->hw_id;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "Null pointer reference in some Intel(R) Graphics Drivers for Windows* before version 26.20.100.7212 and before version Linux kernel version 5.5 may allow a privileged user to potentially enable a denial of service via local access.",
        "id": 2464
    },
    {
        "cve_id": "CVE-2017-7374",
        "code_before_change": "static int validate_user_key(struct fscrypt_info *crypt_info,\n\t\t\tstruct fscrypt_context *ctx, u8 *raw_key,\n\t\t\tconst char *prefix)\n{\n\tchar *description;\n\tstruct key *keyring_key;\n\tstruct fscrypt_key *master_key;\n\tconst struct user_key_payload *ukp;\n\tint res;\n\n\tdescription = kasprintf(GFP_NOFS, \"%s%*phN\", prefix,\n\t\t\t\tFS_KEY_DESCRIPTOR_SIZE,\n\t\t\t\tctx->master_key_descriptor);\n\tif (!description)\n\t\treturn -ENOMEM;\n\n\tkeyring_key = request_key(&key_type_logon, description, NULL);\n\tkfree(description);\n\tif (IS_ERR(keyring_key))\n\t\treturn PTR_ERR(keyring_key);\n\n\tif (keyring_key->type != &key_type_logon) {\n\t\tprintk_once(KERN_WARNING\n\t\t\t\t\"%s: key type must be logon\\n\", __func__);\n\t\tres = -ENOKEY;\n\t\tgoto out;\n\t}\n\tdown_read(&keyring_key->sem);\n\tukp = user_key_payload(keyring_key);\n\tif (ukp->datalen != sizeof(struct fscrypt_key)) {\n\t\tres = -EINVAL;\n\t\tup_read(&keyring_key->sem);\n\t\tgoto out;\n\t}\n\tmaster_key = (struct fscrypt_key *)ukp->data;\n\tBUILD_BUG_ON(FS_AES_128_ECB_KEY_SIZE != FS_KEY_DERIVATION_NONCE_SIZE);\n\n\tif (master_key->size != FS_AES_256_XTS_KEY_SIZE) {\n\t\tprintk_once(KERN_WARNING\n\t\t\t\t\"%s: key size incorrect: %d\\n\",\n\t\t\t\t__func__, master_key->size);\n\t\tres = -ENOKEY;\n\t\tup_read(&keyring_key->sem);\n\t\tgoto out;\n\t}\n\tres = derive_key_aes(ctx->nonce, master_key->raw, raw_key);\n\tup_read(&keyring_key->sem);\n\tif (res)\n\t\tgoto out;\n\n\tcrypt_info->ci_keyring_key = keyring_key;\n\treturn 0;\nout:\n\tkey_put(keyring_key);\n\treturn res;\n}",
        "code_after_change": "static int validate_user_key(struct fscrypt_info *crypt_info,\n\t\t\tstruct fscrypt_context *ctx, u8 *raw_key,\n\t\t\tconst char *prefix)\n{\n\tchar *description;\n\tstruct key *keyring_key;\n\tstruct fscrypt_key *master_key;\n\tconst struct user_key_payload *ukp;\n\tint res;\n\n\tdescription = kasprintf(GFP_NOFS, \"%s%*phN\", prefix,\n\t\t\t\tFS_KEY_DESCRIPTOR_SIZE,\n\t\t\t\tctx->master_key_descriptor);\n\tif (!description)\n\t\treturn -ENOMEM;\n\n\tkeyring_key = request_key(&key_type_logon, description, NULL);\n\tkfree(description);\n\tif (IS_ERR(keyring_key))\n\t\treturn PTR_ERR(keyring_key);\n\tdown_read(&keyring_key->sem);\n\n\tif (keyring_key->type != &key_type_logon) {\n\t\tprintk_once(KERN_WARNING\n\t\t\t\t\"%s: key type must be logon\\n\", __func__);\n\t\tres = -ENOKEY;\n\t\tgoto out;\n\t}\n\tukp = user_key_payload(keyring_key);\n\tif (ukp->datalen != sizeof(struct fscrypt_key)) {\n\t\tres = -EINVAL;\n\t\tgoto out;\n\t}\n\tmaster_key = (struct fscrypt_key *)ukp->data;\n\tBUILD_BUG_ON(FS_AES_128_ECB_KEY_SIZE != FS_KEY_DERIVATION_NONCE_SIZE);\n\n\tif (master_key->size != FS_AES_256_XTS_KEY_SIZE) {\n\t\tprintk_once(KERN_WARNING\n\t\t\t\t\"%s: key size incorrect: %d\\n\",\n\t\t\t\t__func__, master_key->size);\n\t\tres = -ENOKEY;\n\t\tgoto out;\n\t}\n\tres = derive_key_aes(ctx->nonce, master_key->raw, raw_key);\nout:\n\tup_read(&keyring_key->sem);\n\tkey_put(keyring_key);\n\treturn res;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,6 +18,7 @@\n \tkfree(description);\n \tif (IS_ERR(keyring_key))\n \t\treturn PTR_ERR(keyring_key);\n+\tdown_read(&keyring_key->sem);\n \n \tif (keyring_key->type != &key_type_logon) {\n \t\tprintk_once(KERN_WARNING\n@@ -25,11 +26,9 @@\n \t\tres = -ENOKEY;\n \t\tgoto out;\n \t}\n-\tdown_read(&keyring_key->sem);\n \tukp = user_key_payload(keyring_key);\n \tif (ukp->datalen != sizeof(struct fscrypt_key)) {\n \t\tres = -EINVAL;\n-\t\tup_read(&keyring_key->sem);\n \t\tgoto out;\n \t}\n \tmaster_key = (struct fscrypt_key *)ukp->data;\n@@ -40,17 +39,11 @@\n \t\t\t\t\"%s: key size incorrect: %d\\n\",\n \t\t\t\t__func__, master_key->size);\n \t\tres = -ENOKEY;\n-\t\tup_read(&keyring_key->sem);\n \t\tgoto out;\n \t}\n \tres = derive_key_aes(ctx->nonce, master_key->raw, raw_key);\n+out:\n \tup_read(&keyring_key->sem);\n-\tif (res)\n-\t\tgoto out;\n-\n-\tcrypt_info->ci_keyring_key = keyring_key;\n-\treturn 0;\n-out:\n \tkey_put(keyring_key);\n \treturn res;\n }",
        "function_modified_lines": {
            "added": [
                "\tdown_read(&keyring_key->sem);",
                "out:"
            ],
            "deleted": [
                "\tdown_read(&keyring_key->sem);",
                "\t\tup_read(&keyring_key->sem);",
                "\t\tup_read(&keyring_key->sem);",
                "\tif (res)",
                "\t\tgoto out;",
                "",
                "\tcrypt_info->ci_keyring_key = keyring_key;",
                "\treturn 0;",
                "out:"
            ]
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "Use-after-free vulnerability in fs/crypto/ in the Linux kernel before 4.10.7 allows local users to cause a denial of service (NULL pointer dereference) or possibly gain privileges by revoking keyring keys being used for ext4, f2fs, or ubifs encryption, causing cryptographic transform objects to be freed prematurely.",
        "id": 1500
    },
    {
        "cve_id": "CVE-2019-16234",
        "code_before_change": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\t/*\n\t\t * W/A - seems to solve weird behavior. We need to remove this\n\t\t * if we don't want to stay in L1 all the time. This wastes a\n\t\t * lot of power.\n\t\t */\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\n\ttrans_pcie->def_rx_queue = 0;\n\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\n\tpci_set_master(pdev);\n\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\t/* both attempts failed: */\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\n\t/* We disable the RETRY_TIMEOUT register (0x41) to keep\n\t * PCI Tx retries from interfering with C3 CPU state */\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\n\t/*\n\t * In the 8000 HW family the format of the 4 bytes of CSR_HW_REV have\n\t * changed, and now the revision step also includes bit 0-1 (no more\n\t * \"dash\" value). To keep hw_rev backwards compatible - we'll store it\n\t * in the old format.\n\t */\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\n\t\t/*\n\t\t * in-order to recognize C step driver should read chip version\n\t\t * id located at the AUX bus MISC address space.\n\t\t */\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\n\t}\n\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\n\t/* Initialize the wait queue for commands */\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\n\treturn trans;\n\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "struct iwl_trans *iwl_trans_pcie_alloc(struct pci_dev *pdev,\n\t\t\t       const struct pci_device_id *ent,\n\t\t\t       const struct iwl_cfg_trans_params *cfg_trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie;\n\tstruct iwl_trans *trans;\n\tint ret, addr_size;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tif (cfg_trans->gen2)\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie_gen2);\n\telse\n\t\ttrans = iwl_trans_alloc(sizeof(struct iwl_trans_pcie),\n\t\t\t\t\t&pdev->dev, &trans_ops_pcie);\n\n\tif (!trans)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\ttrans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\n\ttrans_pcie->trans = trans;\n\ttrans_pcie->opmode_down = true;\n\tspin_lock_init(&trans_pcie->irq_lock);\n\tspin_lock_init(&trans_pcie->reg_lock);\n\tmutex_init(&trans_pcie->mutex);\n\tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n\n\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n\tif (!trans_pcie->rba.alloc_wq) {\n\t\tret = -ENOMEM;\n\t\tgoto out_free_trans;\n\t}\n\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n\n\ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n\tif (!trans_pcie->tso_hdr_page) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pci;\n\t}\n\ttrans_pcie->debug_rfkill = -1;\n\n\tif (!cfg_trans->base_params->pcie_l1_allowed) {\n\t\t/*\n\t\t * W/A - seems to solve weird behavior. We need to remove this\n\t\t * if we don't want to stay in L1 all the time. This wastes a\n\t\t * lot of power.\n\t\t */\n\t\tpci_disable_link_state(pdev, PCIE_LINK_STATE_L0S |\n\t\t\t\t       PCIE_LINK_STATE_L1 |\n\t\t\t\t       PCIE_LINK_STATE_CLKPM);\n\t}\n\n\ttrans_pcie->def_rx_queue = 0;\n\n\tif (cfg_trans->use_tfh) {\n\t\taddr_size = 64;\n\t\ttrans_pcie->max_tbs = IWL_TFH_NUM_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfh_tfd);\n\t} else {\n\t\taddr_size = 36;\n\t\ttrans_pcie->max_tbs = IWL_NUM_OF_TBS;\n\t\ttrans_pcie->tfd_size = sizeof(struct iwl_tfd);\n\t}\n\ttrans->max_skb_frags = IWL_PCIE_MAX_FRAGS(trans_pcie);\n\n\tpci_set_master(pdev);\n\n\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(addr_size));\n\tif (!ret)\n\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t  DMA_BIT_MASK(addr_size));\n\tif (ret) {\n\t\tret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\n\t\tif (!ret)\n\t\t\tret = pci_set_consistent_dma_mask(pdev,\n\t\t\t\t\t\t\t  DMA_BIT_MASK(32));\n\t\t/* both attempts failed: */\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"No suitable DMA available\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\t}\n\n\tret = pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_regions_request_all failed\\n\");\n\t\tgoto out_no_pci;\n\t}\n\n\ttrans_pcie->hw_base = pcim_iomap_table(pdev)[0];\n\tif (!trans_pcie->hw_base) {\n\t\tdev_err(&pdev->dev, \"pcim_iomap_table failed\\n\");\n\t\tret = -ENODEV;\n\t\tgoto out_no_pci;\n\t}\n\n\t/* We disable the RETRY_TIMEOUT register (0x41) to keep\n\t * PCI Tx retries from interfering with C3 CPU state */\n\tpci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00);\n\n\ttrans_pcie->pci_dev = pdev;\n\tiwl_disable_interrupts(trans);\n\n\ttrans->hw_rev = iwl_read32(trans, CSR_HW_REV);\n\tif (trans->hw_rev == 0xffffffff) {\n\t\tdev_err(&pdev->dev, \"HW_REV=0xFFFFFFFF, PCI issues?\\n\");\n\t\tret = -EIO;\n\t\tgoto out_no_pci;\n\t}\n\n\t/*\n\t * In the 8000 HW family the format of the 4 bytes of CSR_HW_REV have\n\t * changed, and now the revision step also includes bit 0-1 (no more\n\t * \"dash\" value). To keep hw_rev backwards compatible - we'll store it\n\t * in the old format.\n\t */\n\tif (cfg_trans->device_family >= IWL_DEVICE_FAMILY_8000) {\n\t\ttrans->hw_rev = (trans->hw_rev & 0xfff0) |\n\t\t\t\t(CSR_HW_REV_STEP(trans->hw_rev << 2) << 2);\n\n\t\tret = iwl_pcie_prepare_card_hw(trans);\n\t\tif (ret) {\n\t\t\tIWL_WARN(trans, \"Exit HW not ready\\n\");\n\t\t\tgoto out_no_pci;\n\t\t}\n\n\t\t/*\n\t\t * in-order to recognize C step driver should read chip version\n\t\t * id located at the AUX bus MISC address space.\n\t\t */\n\t\tret = iwl_finish_nic_init(trans, cfg_trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\n\t}\n\n\tIWL_DEBUG_INFO(trans, \"HW REV: 0x%0x\\n\", trans->hw_rev);\n\n\tiwl_pcie_set_interrupt_capa(pdev, trans, cfg_trans);\n\ttrans->hw_id = (pdev->device << 16) + pdev->subsystem_device;\n\tsnprintf(trans->hw_id_str, sizeof(trans->hw_id_str),\n\t\t \"PCI ID: 0x%04X:0x%04X\", pdev->device, pdev->subsystem_device);\n\n\t/* Initialize the wait queue for commands */\n\tinit_waitqueue_head(&trans_pcie->wait_command_queue);\n\n\tinit_waitqueue_head(&trans_pcie->sx_waitq);\n\n\tif (trans_pcie->msix_enabled) {\n\t\tret = iwl_pcie_init_msix_handler(pdev, trans_pcie);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\t } else {\n\t\tret = iwl_pcie_alloc_ict(trans);\n\t\tif (ret)\n\t\t\tgoto out_no_pci;\n\n\t\tret = devm_request_threaded_irq(&pdev->dev, pdev->irq,\n\t\t\t\t\t\tiwl_pcie_isr,\n\t\t\t\t\t\tiwl_pcie_irq_handler,\n\t\t\t\t\t\tIRQF_SHARED, DRV_NAME, trans);\n\t\tif (ret) {\n\t\t\tIWL_ERR(trans, \"Error allocating IRQ %d\\n\", pdev->irq);\n\t\t\tgoto out_free_ict;\n\t\t}\n\t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n\t }\n\n#ifdef CONFIG_IWLWIFI_DEBUGFS\n\ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n\tmutex_init(&trans_pcie->fw_mon_data.mutex);\n#endif\n\n\treturn trans;\n\nout_free_ict:\n\tiwl_pcie_free_ict(trans);\nout_no_pci:\n\tfree_percpu(trans_pcie->tso_hdr_page);\n\tdestroy_workqueue(trans_pcie->rba.alloc_wq);\nout_free_trans:\n\tiwl_trans_free(trans);\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,6 +28,15 @@\n \tspin_lock_init(&trans_pcie->reg_lock);\n \tmutex_init(&trans_pcie->mutex);\n \tinit_waitqueue_head(&trans_pcie->ucode_write_waitq);\n+\n+\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n+\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n+\tif (!trans_pcie->rba.alloc_wq) {\n+\t\tret = -ENOMEM;\n+\t\tgoto out_free_trans;\n+\t}\n+\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n+\n \ttrans_pcie->tso_hdr_page = alloc_percpu(struct iwl_tso_hdr_page);\n \tif (!trans_pcie->tso_hdr_page) {\n \t\tret = -ENOMEM;\n@@ -162,10 +171,6 @@\n \t\ttrans_pcie->inta_mask = CSR_INI_SET_MASK;\n \t }\n \n-\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",\n-\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);\n-\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);\n-\n #ifdef CONFIG_IWLWIFI_DEBUGFS\n \ttrans_pcie->fw_mon_data.state = IWL_FW_MON_DBGFS_STATE_CLOSED;\n \tmutex_init(&trans_pcie->fw_mon_data.mutex);\n@@ -177,6 +182,8 @@\n \tiwl_pcie_free_ict(trans);\n out_no_pci:\n \tfree_percpu(trans_pcie->tso_hdr_page);\n+\tdestroy_workqueue(trans_pcie->rba.alloc_wq);\n+out_free_trans:\n \tiwl_trans_free(trans);\n \treturn ERR_PTR(ret);\n }",
        "function_modified_lines": {
            "added": [
                "",
                "\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",",
                "\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);",
                "\tif (!trans_pcie->rba.alloc_wq) {",
                "\t\tret = -ENOMEM;",
                "\t\tgoto out_free_trans;",
                "\t}",
                "\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);",
                "",
                "\tdestroy_workqueue(trans_pcie->rba.alloc_wq);",
                "out_free_trans:"
            ],
            "deleted": [
                "\ttrans_pcie->rba.alloc_wq = alloc_workqueue(\"rb_allocator\",",
                "\t\t\t\t\t\t   WQ_HIGHPRI | WQ_UNBOUND, 1);",
                "\tINIT_WORK(&trans_pcie->rba.rx_alloc, iwl_pcie_rx_allocator_work);",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/wireless/intel/iwlwifi/pcie/trans.c in the Linux kernel 5.2.14 does not check the alloc_workqueue return value, leading to a NULL pointer dereference.",
        "id": 2047
    },
    {
        "cve_id": "CVE-2017-2647",
        "code_before_change": "key_ref_t key_create_or_update(key_ref_t keyring_ref,\n\t\t\t       const char *type,\n\t\t\t       const char *description,\n\t\t\t       const void *payload,\n\t\t\t       size_t plen,\n\t\t\t       key_perm_t perm,\n\t\t\t       unsigned long flags)\n{\n\tstruct keyring_index_key index_key = {\n\t\t.description\t= description,\n\t};\n\tstruct key_preparsed_payload prep;\n\tstruct assoc_array_edit *edit;\n\tconst struct cred *cred = current_cred();\n\tstruct key *keyring, *key = NULL;\n\tkey_ref_t key_ref;\n\tint ret;\n\n\t/* look up the key type to see if it's one of the registered kernel\n\t * types */\n\tindex_key.type = key_type_lookup(type);\n\tif (IS_ERR(index_key.type)) {\n\t\tkey_ref = ERR_PTR(-ENODEV);\n\t\tgoto error;\n\t}\n\n\tkey_ref = ERR_PTR(-EINVAL);\n\tif (!index_key.type->match || !index_key.type->instantiate ||\n\t    (!index_key.description && !index_key.type->preparse))\n\t\tgoto error_put_type;\n\n\tkeyring = key_ref_to_ptr(keyring_ref);\n\n\tkey_check(keyring);\n\n\tkey_ref = ERR_PTR(-ENOTDIR);\n\tif (keyring->type != &key_type_keyring)\n\t\tgoto error_put_type;\n\n\tmemset(&prep, 0, sizeof(prep));\n\tprep.data = payload;\n\tprep.datalen = plen;\n\tprep.quotalen = index_key.type->def_datalen;\n\tprep.trusted = flags & KEY_ALLOC_TRUSTED;\n\tprep.expiry = TIME_T_MAX;\n\tif (index_key.type->preparse) {\n\t\tret = index_key.type->preparse(&prep);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_free_prep;\n\t\t}\n\t\tif (!index_key.description)\n\t\t\tindex_key.description = prep.description;\n\t\tkey_ref = ERR_PTR(-EINVAL);\n\t\tif (!index_key.description)\n\t\t\tgoto error_free_prep;\n\t}\n\tindex_key.desc_len = strlen(index_key.description);\n\n\tkey_ref = ERR_PTR(-EPERM);\n\tif (!prep.trusted && test_bit(KEY_FLAG_TRUSTED_ONLY, &keyring->flags))\n\t\tgoto error_free_prep;\n\tflags |= prep.trusted ? KEY_ALLOC_TRUSTED : 0;\n\n\tret = __key_link_begin(keyring, &index_key, &edit);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_free_prep;\n\t}\n\n\t/* if we're going to allocate a new key, we're going to have\n\t * to modify the keyring */\n\tret = key_permission(keyring_ref, KEY_NEED_WRITE);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\t/* if it's possible to update this type of key, search for an existing\n\t * key of the same type and description in the destination keyring and\n\t * update that instead if possible\n\t */\n\tif (index_key.type->update) {\n\t\tkey_ref = find_key_to_update(keyring_ref, &index_key);\n\t\tif (key_ref)\n\t\t\tgoto found_matching_key;\n\t}\n\n\t/* if the client doesn't provide, decide on the permissions we want */\n\tif (perm == KEY_PERM_UNDEF) {\n\t\tperm = KEY_POS_VIEW | KEY_POS_SEARCH | KEY_POS_LINK | KEY_POS_SETATTR;\n\t\tperm |= KEY_USR_VIEW;\n\n\t\tif (index_key.type->read)\n\t\t\tperm |= KEY_POS_READ;\n\n\t\tif (index_key.type == &key_type_keyring ||\n\t\t    index_key.type->update)\n\t\t\tperm |= KEY_POS_WRITE;\n\t}\n\n\t/* allocate a new key */\n\tkey = key_alloc(index_key.type, index_key.description,\n\t\t\tcred->fsuid, cred->fsgid, cred, perm, flags);\n\tif (IS_ERR(key)) {\n\t\tkey_ref = ERR_CAST(key);\n\t\tgoto error_link_end;\n\t}\n\n\t/* instantiate it and link it into the target keyring */\n\tret = __key_instantiate_and_link(key, &prep, keyring, NULL, &edit);\n\tif (ret < 0) {\n\t\tkey_put(key);\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\tkey_ref = make_key_ref(key, is_key_possessed(keyring_ref));\n\nerror_link_end:\n\t__key_link_end(keyring, &index_key, edit);\nerror_free_prep:\n\tif (index_key.type->preparse)\n\t\tindex_key.type->free_preparse(&prep);\nerror_put_type:\n\tkey_type_put(index_key.type);\nerror:\n\treturn key_ref;\n\n found_matching_key:\n\t/* we found a matching key, so we're going to try to update it\n\t * - we can drop the locks first as we have the key pinned\n\t */\n\t__key_link_end(keyring, &index_key, edit);\n\n\tkey_ref = __key_update(key_ref, &prep);\n\tgoto error_free_prep;\n}",
        "code_after_change": "key_ref_t key_create_or_update(key_ref_t keyring_ref,\n\t\t\t       const char *type,\n\t\t\t       const char *description,\n\t\t\t       const void *payload,\n\t\t\t       size_t plen,\n\t\t\t       key_perm_t perm,\n\t\t\t       unsigned long flags)\n{\n\tstruct keyring_index_key index_key = {\n\t\t.description\t= description,\n\t};\n\tstruct key_preparsed_payload prep;\n\tstruct assoc_array_edit *edit;\n\tconst struct cred *cred = current_cred();\n\tstruct key *keyring, *key = NULL;\n\tkey_ref_t key_ref;\n\tint ret;\n\n\t/* look up the key type to see if it's one of the registered kernel\n\t * types */\n\tindex_key.type = key_type_lookup(type);\n\tif (IS_ERR(index_key.type)) {\n\t\tkey_ref = ERR_PTR(-ENODEV);\n\t\tgoto error;\n\t}\n\n\tkey_ref = ERR_PTR(-EINVAL);\n\tif (!index_key.type->instantiate ||\n\t    (!index_key.description && !index_key.type->preparse))\n\t\tgoto error_put_type;\n\n\tkeyring = key_ref_to_ptr(keyring_ref);\n\n\tkey_check(keyring);\n\n\tkey_ref = ERR_PTR(-ENOTDIR);\n\tif (keyring->type != &key_type_keyring)\n\t\tgoto error_put_type;\n\n\tmemset(&prep, 0, sizeof(prep));\n\tprep.data = payload;\n\tprep.datalen = plen;\n\tprep.quotalen = index_key.type->def_datalen;\n\tprep.trusted = flags & KEY_ALLOC_TRUSTED;\n\tprep.expiry = TIME_T_MAX;\n\tif (index_key.type->preparse) {\n\t\tret = index_key.type->preparse(&prep);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_free_prep;\n\t\t}\n\t\tif (!index_key.description)\n\t\t\tindex_key.description = prep.description;\n\t\tkey_ref = ERR_PTR(-EINVAL);\n\t\tif (!index_key.description)\n\t\t\tgoto error_free_prep;\n\t}\n\tindex_key.desc_len = strlen(index_key.description);\n\n\tkey_ref = ERR_PTR(-EPERM);\n\tif (!prep.trusted && test_bit(KEY_FLAG_TRUSTED_ONLY, &keyring->flags))\n\t\tgoto error_free_prep;\n\tflags |= prep.trusted ? KEY_ALLOC_TRUSTED : 0;\n\n\tret = __key_link_begin(keyring, &index_key, &edit);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_free_prep;\n\t}\n\n\t/* if we're going to allocate a new key, we're going to have\n\t * to modify the keyring */\n\tret = key_permission(keyring_ref, KEY_NEED_WRITE);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\t/* if it's possible to update this type of key, search for an existing\n\t * key of the same type and description in the destination keyring and\n\t * update that instead if possible\n\t */\n\tif (index_key.type->update) {\n\t\tkey_ref = find_key_to_update(keyring_ref, &index_key);\n\t\tif (key_ref)\n\t\t\tgoto found_matching_key;\n\t}\n\n\t/* if the client doesn't provide, decide on the permissions we want */\n\tif (perm == KEY_PERM_UNDEF) {\n\t\tperm = KEY_POS_VIEW | KEY_POS_SEARCH | KEY_POS_LINK | KEY_POS_SETATTR;\n\t\tperm |= KEY_USR_VIEW;\n\n\t\tif (index_key.type->read)\n\t\t\tperm |= KEY_POS_READ;\n\n\t\tif (index_key.type == &key_type_keyring ||\n\t\t    index_key.type->update)\n\t\t\tperm |= KEY_POS_WRITE;\n\t}\n\n\t/* allocate a new key */\n\tkey = key_alloc(index_key.type, index_key.description,\n\t\t\tcred->fsuid, cred->fsgid, cred, perm, flags);\n\tif (IS_ERR(key)) {\n\t\tkey_ref = ERR_CAST(key);\n\t\tgoto error_link_end;\n\t}\n\n\t/* instantiate it and link it into the target keyring */\n\tret = __key_instantiate_and_link(key, &prep, keyring, NULL, &edit);\n\tif (ret < 0) {\n\t\tkey_put(key);\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\tkey_ref = make_key_ref(key, is_key_possessed(keyring_ref));\n\nerror_link_end:\n\t__key_link_end(keyring, &index_key, edit);\nerror_free_prep:\n\tif (index_key.type->preparse)\n\t\tindex_key.type->free_preparse(&prep);\nerror_put_type:\n\tkey_type_put(index_key.type);\nerror:\n\treturn key_ref;\n\n found_matching_key:\n\t/* we found a matching key, so we're going to try to update it\n\t * - we can drop the locks first as we have the key pinned\n\t */\n\t__key_link_end(keyring, &index_key, edit);\n\n\tkey_ref = __key_update(key_ref, &prep);\n\tgoto error_free_prep;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,7 +25,7 @@\n \t}\n \n \tkey_ref = ERR_PTR(-EINVAL);\n-\tif (!index_key.type->match || !index_key.type->instantiate ||\n+\tif (!index_key.type->instantiate ||\n \t    (!index_key.description && !index_key.type->preparse))\n \t\tgoto error_put_type;\n ",
        "function_modified_lines": {
            "added": [
                "\tif (!index_key.type->instantiate ||"
            ],
            "deleted": [
                "\tif (!index_key.type->match || !index_key.type->instantiate ||"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel before 3.18 allows local users to gain privileges or cause a denial of service (NULL pointer dereference and system crash) via vectors involving a NULL value for a certain match field, related to the keyring_search_iterator function in keyring.c.",
        "id": 1451
    },
    {
        "cve_id": "CVE-2017-18216",
        "code_before_change": "static ssize_t o2nm_node_local_store(struct config_item *item, const char *page,\n\t\t\t\t     size_t count)\n{\n\tstruct o2nm_node *node = to_o2nm_node(item);\n\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);\n\tunsigned long tmp;\n\tchar *p = (char *)page;\n\tssize_t ret;\n\n\ttmp = simple_strtoul(p, &p, 0);\n\tif (!p || (*p && (*p != '\\n')))\n\t\treturn -EINVAL;\n\n\ttmp = !!tmp; /* boolean of whether this node wants to be local */\n\n\t/* setting local turns on networking rx for now so we require having\n\t * set everything else first */\n\tif (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_NUM, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n\t\treturn -EINVAL; /* XXX */\n\n\t/* the only failure case is trying to set a new local node\n\t * when a different one is already set */\n\tif (tmp && tmp == cluster->cl_has_local &&\n\t    cluster->cl_local_node != node->nd_num)\n\t\treturn -EBUSY;\n\n\t/* bring up the rx thread if we're setting the new local node. */\n\tif (tmp && !cluster->cl_has_local) {\n\t\tret = o2net_start_listening(node);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (!tmp && cluster->cl_has_local &&\n\t    cluster->cl_local_node == node->nd_num) {\n\t\to2net_stop_listening(node);\n\t\tcluster->cl_local_node = O2NM_INVALID_NODE_NUM;\n\t}\n\n\tnode->nd_local = tmp;\n\tif (node->nd_local) {\n\t\tcluster->cl_has_local = tmp;\n\t\tcluster->cl_local_node = node->nd_num;\n\t}\n\n\treturn count;\n}",
        "code_after_change": "static ssize_t o2nm_node_local_store(struct config_item *item, const char *page,\n\t\t\t\t     size_t count)\n{\n\tstruct o2nm_node *node = to_o2nm_node(item);\n\tstruct o2nm_cluster *cluster;\n\tunsigned long tmp;\n\tchar *p = (char *)page;\n\tssize_t ret;\n\n\ttmp = simple_strtoul(p, &p, 0);\n\tif (!p || (*p && (*p != '\\n')))\n\t\treturn -EINVAL;\n\n\ttmp = !!tmp; /* boolean of whether this node wants to be local */\n\n\t/* setting local turns on networking rx for now so we require having\n\t * set everything else first */\n\tif (!test_bit(O2NM_NODE_ATTR_ADDRESS, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_NUM, &node->nd_set_attributes) ||\n\t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n\t\treturn -EINVAL; /* XXX */\n\n\to2nm_lock_subsystem();\n\tcluster = to_o2nm_cluster_from_node(node);\n\tif (!cluster) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* the only failure case is trying to set a new local node\n\t * when a different one is already set */\n\tif (tmp && tmp == cluster->cl_has_local &&\n\t    cluster->cl_local_node != node->nd_num) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t/* bring up the rx thread if we're setting the new local node. */\n\tif (tmp && !cluster->cl_has_local) {\n\t\tret = o2net_start_listening(node);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tif (!tmp && cluster->cl_has_local &&\n\t    cluster->cl_local_node == node->nd_num) {\n\t\to2net_stop_listening(node);\n\t\tcluster->cl_local_node = O2NM_INVALID_NODE_NUM;\n\t}\n\n\tnode->nd_local = tmp;\n\tif (node->nd_local) {\n\t\tcluster->cl_has_local = tmp;\n\t\tcluster->cl_local_node = node->nd_num;\n\t}\n\n\tret = count;\n\nout:\n\to2nm_unlock_subsystem();\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t\t     size_t count)\n {\n \tstruct o2nm_node *node = to_o2nm_node(item);\n-\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);\n+\tstruct o2nm_cluster *cluster;\n \tunsigned long tmp;\n \tchar *p = (char *)page;\n \tssize_t ret;\n@@ -20,17 +20,26 @@\n \t    !test_bit(O2NM_NODE_ATTR_PORT, &node->nd_set_attributes))\n \t\treturn -EINVAL; /* XXX */\n \n+\to2nm_lock_subsystem();\n+\tcluster = to_o2nm_cluster_from_node(node);\n+\tif (!cluster) {\n+\t\tret = -EINVAL;\n+\t\tgoto out;\n+\t}\n+\n \t/* the only failure case is trying to set a new local node\n \t * when a different one is already set */\n \tif (tmp && tmp == cluster->cl_has_local &&\n-\t    cluster->cl_local_node != node->nd_num)\n-\t\treturn -EBUSY;\n+\t    cluster->cl_local_node != node->nd_num) {\n+\t\tret = -EBUSY;\n+\t\tgoto out;\n+\t}\n \n \t/* bring up the rx thread if we're setting the new local node. */\n \tif (tmp && !cluster->cl_has_local) {\n \t\tret = o2net_start_listening(node);\n \t\tif (ret)\n-\t\t\treturn ret;\n+\t\t\tgoto out;\n \t}\n \n \tif (!tmp && cluster->cl_has_local &&\n@@ -45,5 +54,9 @@\n \t\tcluster->cl_local_node = node->nd_num;\n \t}\n \n-\treturn count;\n+\tret = count;\n+\n+out:\n+\to2nm_unlock_subsystem();\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct o2nm_cluster *cluster;",
                "\to2nm_lock_subsystem();",
                "\tcluster = to_o2nm_cluster_from_node(node);",
                "\tif (!cluster) {",
                "\t\tret = -EINVAL;",
                "\t\tgoto out;",
                "\t}",
                "",
                "\t    cluster->cl_local_node != node->nd_num) {",
                "\t\tret = -EBUSY;",
                "\t\tgoto out;",
                "\t}",
                "\t\t\tgoto out;",
                "\tret = count;",
                "",
                "out:",
                "\to2nm_unlock_subsystem();",
                "\treturn ret;"
            ],
            "deleted": [
                "\tstruct o2nm_cluster *cluster = to_o2nm_cluster_from_node(node);",
                "\t    cluster->cl_local_node != node->nd_num)",
                "\t\treturn -EBUSY;",
                "\t\t\treturn ret;",
                "\treturn count;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In fs/ocfs2/cluster/nodemanager.c in the Linux kernel before 4.15, local users can cause a denial of service (NULL pointer dereference and BUG) because a required mutex is not used.",
        "id": 1400
    },
    {
        "cve_id": "CVE-2018-1000200",
        "code_before_change": "static void oom_reap_task(struct task_struct *tsk)\n{\n\tint attempts = 0;\n\tstruct mm_struct *mm = tsk->signal->oom_mm;\n\n\t/* Retry the down_read_trylock(mmap_sem) a few times */\n\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !__oom_reap_task_mm(tsk, mm))\n\t\tschedule_timeout_idle(HZ/10);\n\n\tif (attempts <= MAX_OOM_REAP_RETRIES ||\n\t    test_bit(MMF_OOM_SKIP, &mm->flags))\n\t\tgoto done;\n\n\n\tpr_info(\"oom_reaper: unable to reap pid:%d (%s)\\n\",\n\t\ttask_pid_nr(tsk), tsk->comm);\n\tdebug_show_all_locks();\n\ndone:\n\ttsk->oom_reaper_list = NULL;\n\n\t/*\n\t * Hide this mm from OOM killer because it has been either reaped or\n\t * somebody can't call up_write(mmap_sem).\n\t */\n\tset_bit(MMF_OOM_SKIP, &mm->flags);\n\n\t/* Drop a reference taken by wake_oom_reaper */\n\tput_task_struct(tsk);\n}",
        "code_after_change": "static void oom_reap_task(struct task_struct *tsk)\n{\n\tint attempts = 0;\n\tstruct mm_struct *mm = tsk->signal->oom_mm;\n\n\t/* Retry the down_read_trylock(mmap_sem) a few times */\n\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !oom_reap_task_mm(tsk, mm))\n\t\tschedule_timeout_idle(HZ/10);\n\n\tif (attempts <= MAX_OOM_REAP_RETRIES ||\n\t    test_bit(MMF_OOM_SKIP, &mm->flags))\n\t\tgoto done;\n\n\tpr_info(\"oom_reaper: unable to reap pid:%d (%s)\\n\",\n\t\ttask_pid_nr(tsk), tsk->comm);\n\tdebug_show_all_locks();\n\ndone:\n\ttsk->oom_reaper_list = NULL;\n\n\t/*\n\t * Hide this mm from OOM killer because it has been either reaped or\n\t * somebody can't call up_write(mmap_sem).\n\t */\n\tset_bit(MMF_OOM_SKIP, &mm->flags);\n\n\t/* Drop a reference taken by wake_oom_reaper */\n\tput_task_struct(tsk);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,13 +4,12 @@\n \tstruct mm_struct *mm = tsk->signal->oom_mm;\n \n \t/* Retry the down_read_trylock(mmap_sem) a few times */\n-\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !__oom_reap_task_mm(tsk, mm))\n+\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !oom_reap_task_mm(tsk, mm))\n \t\tschedule_timeout_idle(HZ/10);\n \n \tif (attempts <= MAX_OOM_REAP_RETRIES ||\n \t    test_bit(MMF_OOM_SKIP, &mm->flags))\n \t\tgoto done;\n-\n \n \tpr_info(\"oom_reaper: unable to reap pid:%d (%s)\\n\",\n \t\ttask_pid_nr(tsk), tsk->comm);",
        "function_modified_lines": {
            "added": [
                "\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !oom_reap_task_mm(tsk, mm))"
            ],
            "deleted": [
                "\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !__oom_reap_task_mm(tsk, mm))",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux Kernel versions 4.14, 4.15, and 4.16 has a null pointer dereference which can result in an out of memory (OOM) killing of large mlocked processes. The issue arises from an oom killed process's final thread calling exit_mmap(), which calls munlock_vma_pages_all() for mlocked vmas.This can happen synchronously with the oom reaper's unmap_page_range() since the vma's VM_LOCKED bit is cleared before munlocking (to determine if any other vmas share the memory and are mlocked).",
        "id": 1579
    },
    {
        "cve_id": "CVE-2023-2177",
        "code_before_change": "int sctp_stream_init(struct sctp_stream *stream, __u16 outcnt, __u16 incnt,\n\t\t     gfp_t gfp)\n{\n\tstruct sctp_sched_ops *sched = sctp_sched_ops_from_stream(stream);\n\tint i, ret = 0;\n\n\tgfp |= __GFP_NOWARN;\n\n\t/* Initial stream->out size may be very big, so free it and alloc\n\t * a new one with new outcnt to save memory if needed.\n\t */\n\tif (outcnt == stream->outcnt)\n\t\tgoto handle_in;\n\n\t/* Filter out chunks queued on streams that won't exist anymore */\n\tsched->unsched_all(stream);\n\tsctp_stream_outq_migrate(stream, NULL, outcnt);\n\tsched->sched_all(stream);\n\n\tret = sctp_stream_alloc_out(stream, outcnt, gfp);\n\tif (ret)\n\t\tgoto out_err;\n\n\tfor (i = 0; i < stream->outcnt; i++)\n\t\tSCTP_SO(stream, i)->state = SCTP_STREAM_OPEN;\n\nhandle_in:\n\tsctp_stream_interleave_init(stream);\n\tif (!incnt)\n\t\tgoto out;\n\n\tret = sctp_stream_alloc_in(stream, incnt, gfp);\n\tif (ret)\n\t\tgoto in_err;\n\n\tgoto out;\n\nin_err:\n\tsched->free(stream);\n\tgenradix_free(&stream->in);\nout_err:\n\tgenradix_free(&stream->out);\n\tstream->outcnt = 0;\nout:\n\treturn ret;\n}",
        "code_after_change": "int sctp_stream_init(struct sctp_stream *stream, __u16 outcnt, __u16 incnt,\n\t\t     gfp_t gfp)\n{\n\tstruct sctp_sched_ops *sched = sctp_sched_ops_from_stream(stream);\n\tint i, ret = 0;\n\n\tgfp |= __GFP_NOWARN;\n\n\t/* Initial stream->out size may be very big, so free it and alloc\n\t * a new one with new outcnt to save memory if needed.\n\t */\n\tif (outcnt == stream->outcnt)\n\t\tgoto handle_in;\n\n\t/* Filter out chunks queued on streams that won't exist anymore */\n\tsched->unsched_all(stream);\n\tsctp_stream_outq_migrate(stream, NULL, outcnt);\n\tsched->sched_all(stream);\n\n\tret = sctp_stream_alloc_out(stream, outcnt, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < stream->outcnt; i++)\n\t\tSCTP_SO(stream, i)->state = SCTP_STREAM_OPEN;\n\nhandle_in:\n\tsctp_stream_interleave_init(stream);\n\tif (!incnt)\n\t\treturn 0;\n\n\treturn sctp_stream_alloc_in(stream, incnt, gfp);\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \n \tret = sctp_stream_alloc_out(stream, outcnt, gfp);\n \tif (ret)\n-\t\tgoto out_err;\n+\t\treturn ret;\n \n \tfor (i = 0; i < stream->outcnt; i++)\n \t\tSCTP_SO(stream, i)->state = SCTP_STREAM_OPEN;\n@@ -27,20 +27,7 @@\n handle_in:\n \tsctp_stream_interleave_init(stream);\n \tif (!incnt)\n-\t\tgoto out;\n+\t\treturn 0;\n \n-\tret = sctp_stream_alloc_in(stream, incnt, gfp);\n-\tif (ret)\n-\t\tgoto in_err;\n-\n-\tgoto out;\n-\n-in_err:\n-\tsched->free(stream);\n-\tgenradix_free(&stream->in);\n-out_err:\n-\tgenradix_free(&stream->out);\n-\tstream->outcnt = 0;\n-out:\n-\treturn ret;\n+\treturn sctp_stream_alloc_in(stream, incnt, gfp);\n }",
        "function_modified_lines": {
            "added": [
                "\t\treturn ret;",
                "\t\treturn 0;",
                "\treturn sctp_stream_alloc_in(stream, incnt, gfp);"
            ],
            "deleted": [
                "\t\tgoto out_err;",
                "\t\tgoto out;",
                "\tret = sctp_stream_alloc_in(stream, incnt, gfp);",
                "\tif (ret)",
                "\t\tgoto in_err;",
                "",
                "\tgoto out;",
                "",
                "in_err:",
                "\tsched->free(stream);",
                "\tgenradix_free(&stream->in);",
                "out_err:",
                "\tgenradix_free(&stream->out);",
                "\tstream->outcnt = 0;",
                "out:",
                "\treturn ret;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference issue was found in the sctp network protocol in net/sctp/stream_sched.c in Linux Kernel. If stream_in allocation is failed, stream_out is freed which would further be accessed. A local user could use this flaw to crash the system or potentially cause a denial of service.",
        "id": 3933
    },
    {
        "cve_id": "CVE-2017-18079",
        "code_before_change": "static int i8042_start(struct serio *serio)\n{\n\tstruct i8042_port *port = serio->port_data;\n\n\tport->exists = true;\n\tmb();\n\treturn 0;\n}",
        "code_after_change": "static int i8042_start(struct serio *serio)\n{\n\tstruct i8042_port *port = serio->port_data;\n\n\tspin_lock_irq(&i8042_lock);\n\tport->exists = true;\n\tspin_unlock_irq(&i8042_lock);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,9 @@\n {\n \tstruct i8042_port *port = serio->port_data;\n \n+\tspin_lock_irq(&i8042_lock);\n \tport->exists = true;\n-\tmb();\n+\tspin_unlock_irq(&i8042_lock);\n+\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tspin_lock_irq(&i8042_lock);",
                "\tspin_unlock_irq(&i8042_lock);",
                ""
            ],
            "deleted": [
                "\tmb();"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/input/serio/i8042.c in the Linux kernel before 4.12.4 allows attackers to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact because the port->exists value can change after it is validated.",
        "id": 1391
    },
    {
        "cve_id": "CVE-2023-2166",
        "code_before_change": "static int can_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t   struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_can_skb(skb)))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "code_after_change": "static int can_rcv(struct sk_buff *skb, struct net_device *dev,\n\t\t   struct packet_type *pt, struct net_device *orig_dev)\n{\n\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_can_skb(skb))) {\n\t\tpr_warn_once(\"PF_CAN: dropped non conform CAN skbuff: dev type %d, len %d\\n\",\n\t\t\t     dev->type, skb->len);\n\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\n\tcan_receive(skb, dev);\n\treturn NET_RX_SUCCESS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,7 @@\n static int can_rcv(struct sk_buff *skb, struct net_device *dev,\n \t\t   struct packet_type *pt, struct net_device *orig_dev)\n {\n-\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_can_skb(skb)))) {\n+\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_can_skb(skb))) {\n \t\tpr_warn_once(\"PF_CAN: dropped non conform CAN skbuff: dev type %d, len %d\\n\",\n \t\t\t     dev->type, skb->len);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || !can_get_ml_priv(dev) || !can_is_can_skb(skb))) {"
            ],
            "deleted": [
                "\tif (unlikely(dev->type != ARPHRD_CAN || (!can_is_can_skb(skb)))) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference issue was found in can protocol in net/can/af_can.c in the Linux before Linux. ml_priv may not be initialized in the receive path of CAN frames. A local user could use this flaw to crash the system or potentially cause a denial of service.",
        "id": 3926
    },
    {
        "cve_id": "CVE-2018-14616",
        "code_before_change": "static int do_read_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tstruct page *node_page;\n\tstruct f2fs_inode *ri;\n\tprojid_t i_projid;\n\n\t/* Check if ino is within scope */\n\tif (f2fs_check_nid_range(sbi, inode->i_ino))\n\t\treturn -EINVAL;\n\n\tnode_page = f2fs_get_node_page(sbi, inode->i_ino);\n\tif (IS_ERR(node_page))\n\t\treturn PTR_ERR(node_page);\n\n\tri = F2FS_INODE(node_page);\n\n\tinode->i_mode = le16_to_cpu(ri->i_mode);\n\ti_uid_write(inode, le32_to_cpu(ri->i_uid));\n\ti_gid_write(inode, le32_to_cpu(ri->i_gid));\n\tset_nlink(inode, le32_to_cpu(ri->i_links));\n\tinode->i_size = le64_to_cpu(ri->i_size);\n\tinode->i_blocks = SECTOR_FROM_BLOCK(le64_to_cpu(ri->i_blocks) - 1);\n\n\tinode->i_atime.tv_sec = le64_to_cpu(ri->i_atime);\n\tinode->i_ctime.tv_sec = le64_to_cpu(ri->i_ctime);\n\tinode->i_mtime.tv_sec = le64_to_cpu(ri->i_mtime);\n\tinode->i_atime.tv_nsec = le32_to_cpu(ri->i_atime_nsec);\n\tinode->i_ctime.tv_nsec = le32_to_cpu(ri->i_ctime_nsec);\n\tinode->i_mtime.tv_nsec = le32_to_cpu(ri->i_mtime_nsec);\n\tinode->i_generation = le32_to_cpu(ri->i_generation);\n\tif (S_ISDIR(inode->i_mode))\n\t\tfi->i_current_depth = le32_to_cpu(ri->i_current_depth);\n\telse if (S_ISREG(inode->i_mode))\n\t\tfi->i_gc_failures[GC_FAILURE_PIN] =\n\t\t\t\t\tle16_to_cpu(ri->i_gc_failures);\n\tfi->i_xattr_nid = le32_to_cpu(ri->i_xattr_nid);\n\tfi->i_flags = le32_to_cpu(ri->i_flags);\n\tfi->flags = 0;\n\tfi->i_advise = ri->i_advise;\n\tfi->i_pino = le32_to_cpu(ri->i_pino);\n\tfi->i_dir_level = ri->i_dir_level;\n\n\tif (f2fs_init_extent_tree(inode, &ri->i_ext))\n\t\tset_page_dirty(node_page);\n\n\tget_inline_info(inode, ri);\n\n\tfi->i_extra_isize = f2fs_has_extra_attr(inode) ?\n\t\t\t\t\tle16_to_cpu(ri->i_extra_isize) : 0;\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)) {\n\t\tfi->i_inline_xattr_size = le16_to_cpu(ri->i_inline_xattr_size);\n\t} else if (f2fs_has_inline_xattr(inode) ||\n\t\t\t\tf2fs_has_inline_dentry(inode)) {\n\t\tfi->i_inline_xattr_size = DEFAULT_INLINE_XATTR_ADDRS;\n\t} else {\n\n\t\t/*\n\t\t * Previous inline data or directory always reserved 200 bytes\n\t\t * in inode layout, even if inline_xattr is disabled. In order\n\t\t * to keep inline_dentry's structure for backward compatibility,\n\t\t * we get the space back only from inline_data.\n\t\t */\n\t\tfi->i_inline_xattr_size = 0;\n\t}\n\n\tif (!sanity_check_inode(inode, node_page)) {\n\t\tf2fs_put_page(node_page, 1);\n\t\treturn -EINVAL;\n\t}\n\n\t/* check data exist */\n\tif (f2fs_has_inline_data(inode) && !f2fs_exist_data(inode))\n\t\t__recover_inline_status(inode, node_page);\n\n\t/* get rdev by using inline_info */\n\t__get_inode_rdev(inode, ri);\n\n\tif (__written_first_block(sbi, ri))\n\t\tset_inode_flag(inode, FI_FIRST_BLOCK_WRITTEN);\n\n\tif (!f2fs_need_inode_block_update(sbi, inode->i_ino))\n\t\tfi->last_disk_size = inode->i_size;\n\n\tif (fi->i_flags & F2FS_PROJINHERIT_FL)\n\t\tset_inode_flag(inode, FI_PROJ_INHERIT);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_project_quota(sbi->sb) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(ri->i_projid);\n\telse\n\t\ti_projid = F2FS_DEF_PROJID;\n\tfi->i_projid = make_kprojid(&init_user_ns, i_projid);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_inode_crtime(sbi->sb) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_crtime)) {\n\t\tfi->i_crtime.tv_sec = le64_to_cpu(ri->i_crtime);\n\t\tfi->i_crtime.tv_nsec = le32_to_cpu(ri->i_crtime_nsec);\n\t}\n\n\tF2FS_I(inode)->i_disk_time[0] = inode->i_atime;\n\tF2FS_I(inode)->i_disk_time[1] = inode->i_ctime;\n\tF2FS_I(inode)->i_disk_time[2] = inode->i_mtime;\n\tF2FS_I(inode)->i_disk_time[3] = F2FS_I(inode)->i_crtime;\n\tf2fs_put_page(node_page, 1);\n\n\tstat_inc_inline_xattr(inode);\n\tstat_inc_inline_inode(inode);\n\tstat_inc_inline_dir(inode);\n\n\treturn 0;\n}",
        "code_after_change": "static int do_read_inode(struct inode *inode)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct f2fs_inode_info *fi = F2FS_I(inode);\n\tstruct page *node_page;\n\tstruct f2fs_inode *ri;\n\tprojid_t i_projid;\n\tint err;\n\n\t/* Check if ino is within scope */\n\tif (f2fs_check_nid_range(sbi, inode->i_ino))\n\t\treturn -EINVAL;\n\n\tnode_page = f2fs_get_node_page(sbi, inode->i_ino);\n\tif (IS_ERR(node_page))\n\t\treturn PTR_ERR(node_page);\n\n\tri = F2FS_INODE(node_page);\n\n\tinode->i_mode = le16_to_cpu(ri->i_mode);\n\ti_uid_write(inode, le32_to_cpu(ri->i_uid));\n\ti_gid_write(inode, le32_to_cpu(ri->i_gid));\n\tset_nlink(inode, le32_to_cpu(ri->i_links));\n\tinode->i_size = le64_to_cpu(ri->i_size);\n\tinode->i_blocks = SECTOR_FROM_BLOCK(le64_to_cpu(ri->i_blocks) - 1);\n\n\tinode->i_atime.tv_sec = le64_to_cpu(ri->i_atime);\n\tinode->i_ctime.tv_sec = le64_to_cpu(ri->i_ctime);\n\tinode->i_mtime.tv_sec = le64_to_cpu(ri->i_mtime);\n\tinode->i_atime.tv_nsec = le32_to_cpu(ri->i_atime_nsec);\n\tinode->i_ctime.tv_nsec = le32_to_cpu(ri->i_ctime_nsec);\n\tinode->i_mtime.tv_nsec = le32_to_cpu(ri->i_mtime_nsec);\n\tinode->i_generation = le32_to_cpu(ri->i_generation);\n\tif (S_ISDIR(inode->i_mode))\n\t\tfi->i_current_depth = le32_to_cpu(ri->i_current_depth);\n\telse if (S_ISREG(inode->i_mode))\n\t\tfi->i_gc_failures[GC_FAILURE_PIN] =\n\t\t\t\t\tle16_to_cpu(ri->i_gc_failures);\n\tfi->i_xattr_nid = le32_to_cpu(ri->i_xattr_nid);\n\tfi->i_flags = le32_to_cpu(ri->i_flags);\n\tfi->flags = 0;\n\tfi->i_advise = ri->i_advise;\n\tfi->i_pino = le32_to_cpu(ri->i_pino);\n\tfi->i_dir_level = ri->i_dir_level;\n\n\tif (f2fs_init_extent_tree(inode, &ri->i_ext))\n\t\tset_page_dirty(node_page);\n\n\tget_inline_info(inode, ri);\n\n\tfi->i_extra_isize = f2fs_has_extra_attr(inode) ?\n\t\t\t\t\tle16_to_cpu(ri->i_extra_isize) : 0;\n\n\tif (f2fs_sb_has_flexible_inline_xattr(sbi->sb)) {\n\t\tfi->i_inline_xattr_size = le16_to_cpu(ri->i_inline_xattr_size);\n\t} else if (f2fs_has_inline_xattr(inode) ||\n\t\t\t\tf2fs_has_inline_dentry(inode)) {\n\t\tfi->i_inline_xattr_size = DEFAULT_INLINE_XATTR_ADDRS;\n\t} else {\n\n\t\t/*\n\t\t * Previous inline data or directory always reserved 200 bytes\n\t\t * in inode layout, even if inline_xattr is disabled. In order\n\t\t * to keep inline_dentry's structure for backward compatibility,\n\t\t * we get the space back only from inline_data.\n\t\t */\n\t\tfi->i_inline_xattr_size = 0;\n\t}\n\n\tif (!sanity_check_inode(inode, node_page)) {\n\t\tf2fs_put_page(node_page, 1);\n\t\treturn -EINVAL;\n\t}\n\n\t/* check data exist */\n\tif (f2fs_has_inline_data(inode) && !f2fs_exist_data(inode))\n\t\t__recover_inline_status(inode, node_page);\n\n\t/* get rdev by using inline_info */\n\t__get_inode_rdev(inode, ri);\n\n\terr = __written_first_block(sbi, ri);\n\tif (err < 0) {\n\t\tf2fs_put_page(node_page, 1);\n\t\treturn err;\n\t}\n\tif (!err)\n\t\tset_inode_flag(inode, FI_FIRST_BLOCK_WRITTEN);\n\n\tif (!f2fs_need_inode_block_update(sbi, inode->i_ino))\n\t\tfi->last_disk_size = inode->i_size;\n\n\tif (fi->i_flags & F2FS_PROJINHERIT_FL)\n\t\tset_inode_flag(inode, FI_PROJ_INHERIT);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_project_quota(sbi->sb) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_projid))\n\t\ti_projid = (projid_t)le32_to_cpu(ri->i_projid);\n\telse\n\t\ti_projid = F2FS_DEF_PROJID;\n\tfi->i_projid = make_kprojid(&init_user_ns, i_projid);\n\n\tif (f2fs_has_extra_attr(inode) && f2fs_sb_has_inode_crtime(sbi->sb) &&\n\t\t\tF2FS_FITS_IN_INODE(ri, fi->i_extra_isize, i_crtime)) {\n\t\tfi->i_crtime.tv_sec = le64_to_cpu(ri->i_crtime);\n\t\tfi->i_crtime.tv_nsec = le32_to_cpu(ri->i_crtime_nsec);\n\t}\n\n\tF2FS_I(inode)->i_disk_time[0] = inode->i_atime;\n\tF2FS_I(inode)->i_disk_time[1] = inode->i_ctime;\n\tF2FS_I(inode)->i_disk_time[2] = inode->i_mtime;\n\tF2FS_I(inode)->i_disk_time[3] = F2FS_I(inode)->i_crtime;\n\tf2fs_put_page(node_page, 1);\n\n\tstat_inc_inline_xattr(inode);\n\tstat_inc_inline_inode(inode);\n\tstat_inc_inline_dir(inode);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,7 @@\n \tstruct page *node_page;\n \tstruct f2fs_inode *ri;\n \tprojid_t i_projid;\n+\tint err;\n \n \t/* Check if ino is within scope */\n \tif (f2fs_check_nid_range(sbi, inode->i_ino))\n@@ -78,7 +79,12 @@\n \t/* get rdev by using inline_info */\n \t__get_inode_rdev(inode, ri);\n \n-\tif (__written_first_block(sbi, ri))\n+\terr = __written_first_block(sbi, ri);\n+\tif (err < 0) {\n+\t\tf2fs_put_page(node_page, 1);\n+\t\treturn err;\n+\t}\n+\tif (!err)\n \t\tset_inode_flag(inode, FI_FIRST_BLOCK_WRITTEN);\n \n \tif (!f2fs_need_inode_block_update(sbi, inode->i_ino))",
        "function_modified_lines": {
            "added": [
                "\tint err;",
                "\terr = __written_first_block(sbi, ri);",
                "\tif (err < 0) {",
                "\t\tf2fs_put_page(node_page, 1);",
                "\t\treturn err;",
                "\t}",
                "\tif (!err)"
            ],
            "deleted": [
                "\tif (__written_first_block(sbi, ri))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference in fscrypt_do_page_crypto() in fs/crypto/crypto.c when operating on a file in a corrupted f2fs image.",
        "id": 1688
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static bool reg_type_may_be_refcounted_or_null(enum bpf_reg_type type)\n{\n\treturn type == PTR_TO_SOCKET ||\n\t\ttype == PTR_TO_SOCKET_OR_NULL ||\n\t\ttype == PTR_TO_TCP_SOCK ||\n\t\ttype == PTR_TO_TCP_SOCK_OR_NULL ||\n\t\ttype == PTR_TO_MEM ||\n\t\ttype == PTR_TO_MEM_OR_NULL;\n}",
        "code_after_change": "static bool reg_type_may_be_refcounted_or_null(enum bpf_reg_type type)\n{\n\treturn base_type(type) == PTR_TO_SOCKET ||\n\t\tbase_type(type) == PTR_TO_TCP_SOCK ||\n\t\tbase_type(type) == PTR_TO_MEM;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,9 +1,6 @@\n static bool reg_type_may_be_refcounted_or_null(enum bpf_reg_type type)\n {\n-\treturn type == PTR_TO_SOCKET ||\n-\t\ttype == PTR_TO_SOCKET_OR_NULL ||\n-\t\ttype == PTR_TO_TCP_SOCK ||\n-\t\ttype == PTR_TO_TCP_SOCK_OR_NULL ||\n-\t\ttype == PTR_TO_MEM ||\n-\t\ttype == PTR_TO_MEM_OR_NULL;\n+\treturn base_type(type) == PTR_TO_SOCKET ||\n+\t\tbase_type(type) == PTR_TO_TCP_SOCK ||\n+\t\tbase_type(type) == PTR_TO_MEM;\n }",
        "function_modified_lines": {
            "added": [
                "\treturn base_type(type) == PTR_TO_SOCKET ||",
                "\t\tbase_type(type) == PTR_TO_TCP_SOCK ||",
                "\t\tbase_type(type) == PTR_TO_MEM;"
            ],
            "deleted": [
                "\treturn type == PTR_TO_SOCKET ||",
                "\t\ttype == PTR_TO_SOCKET_OR_NULL ||",
                "\t\ttype == PTR_TO_TCP_SOCK ||",
                "\t\ttype == PTR_TO_TCP_SOCK_OR_NULL ||",
                "\t\ttype == PTR_TO_MEM ||",
                "\t\ttype == PTR_TO_MEM_OR_NULL;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3445
    },
    {
        "cve_id": "CVE-2023-22997",
        "code_before_change": "static ssize_t module_xz_decompress(struct load_info *info,\n\t\t\t\t    const void *buf, size_t size)\n{\n\tstatic const u8 signature[] = { 0xfd, '7', 'z', 'X', 'Z', 0 };\n\tstruct xz_dec *xz_dec;\n\tstruct xz_buf xz_buf;\n\tenum xz_ret xz_ret;\n\tsize_t new_size = 0;\n\tssize_t retval;\n\n\tif (size < sizeof(signature) ||\n\t    memcmp(buf, signature, sizeof(signature))) {\n\t\tpr_err(\"not an xz compressed module\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\txz_dec = xz_dec_init(XZ_DYNALLOC, (u32)-1);\n\tif (!xz_dec)\n\t\treturn -ENOMEM;\n\n\txz_buf.in_size = size;\n\txz_buf.in = buf;\n\txz_buf.in_pos = 0;\n\n\tdo {\n\t\tstruct page *page = module_get_next_page(info);\n\n\t\tif (!page) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\txz_buf.out = kmap_local_page(page);\n\t\txz_buf.out_pos = 0;\n\t\txz_buf.out_size = PAGE_SIZE;\n\t\txz_ret = xz_dec_run(xz_dec, &xz_buf);\n\t\tkunmap_local(xz_buf.out);\n\n\t\tnew_size += xz_buf.out_pos;\n\t} while (xz_buf.out_pos == PAGE_SIZE && xz_ret == XZ_OK);\n\n\tif (xz_ret != XZ_STREAM_END) {\n\t\tpr_err(\"decompression failed with status %d\\n\", xz_ret);\n\t\tretval = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tretval = new_size;\n\n out:\n\txz_dec_end(xz_dec);\n\treturn retval;\n}",
        "code_after_change": "static ssize_t module_xz_decompress(struct load_info *info,\n\t\t\t\t    const void *buf, size_t size)\n{\n\tstatic const u8 signature[] = { 0xfd, '7', 'z', 'X', 'Z', 0 };\n\tstruct xz_dec *xz_dec;\n\tstruct xz_buf xz_buf;\n\tenum xz_ret xz_ret;\n\tsize_t new_size = 0;\n\tssize_t retval;\n\n\tif (size < sizeof(signature) ||\n\t    memcmp(buf, signature, sizeof(signature))) {\n\t\tpr_err(\"not an xz compressed module\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\txz_dec = xz_dec_init(XZ_DYNALLOC, (u32)-1);\n\tif (!xz_dec)\n\t\treturn -ENOMEM;\n\n\txz_buf.in_size = size;\n\txz_buf.in = buf;\n\txz_buf.in_pos = 0;\n\n\tdo {\n\t\tstruct page *page = module_get_next_page(info);\n\n\t\tif (IS_ERR(page)) {\n\t\t\tretval = PTR_ERR(page);\n\t\t\tgoto out;\n\t\t}\n\n\t\txz_buf.out = kmap_local_page(page);\n\t\txz_buf.out_pos = 0;\n\t\txz_buf.out_size = PAGE_SIZE;\n\t\txz_ret = xz_dec_run(xz_dec, &xz_buf);\n\t\tkunmap_local(xz_buf.out);\n\n\t\tnew_size += xz_buf.out_pos;\n\t} while (xz_buf.out_pos == PAGE_SIZE && xz_ret == XZ_OK);\n\n\tif (xz_ret != XZ_STREAM_END) {\n\t\tpr_err(\"decompression failed with status %d\\n\", xz_ret);\n\t\tretval = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tretval = new_size;\n\n out:\n\txz_dec_end(xz_dec);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,8 @@\n \tdo {\n \t\tstruct page *page = module_get_next_page(info);\n \n-\t\tif (!page) {\n-\t\t\tretval = -ENOMEM;\n+\t\tif (IS_ERR(page)) {\n+\t\t\tretval = PTR_ERR(page);\n \t\t\tgoto out;\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (IS_ERR(page)) {",
                "\t\t\tretval = PTR_ERR(page);"
            ],
            "deleted": [
                "\t\tif (!page) {",
                "\t\t\tretval = -ENOMEM;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 6.1.2, kernel/module/decompress.c misinterprets the module_get_next_page return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3940
    },
    {
        "cve_id": "CVE-2023-23005",
        "code_before_change": "static int __init memory_tier_init(void)\n{\n\tint ret, node;\n\tstruct memory_tier *memtier;\n\n\tret = subsys_virtual_register(&memory_tier_subsys, NULL);\n\tif (ret)\n\t\tpanic(\"%s() failed to register memory tier subsystem\\n\", __func__);\n\n#ifdef CONFIG_MIGRATION\n\tnode_demotion = kcalloc(nr_node_ids, sizeof(struct demotion_nodes),\n\t\t\t\tGFP_KERNEL);\n\tWARN_ON(!node_demotion);\n#endif\n\tmutex_lock(&memory_tier_lock);\n\t/*\n\t * For now we can have 4 faster memory tiers with smaller adistance\n\t * than default DRAM tier.\n\t */\n\tdefault_dram_type = alloc_memory_type(MEMTIER_ADISTANCE_DRAM);\n\tif (!default_dram_type)\n\t\tpanic(\"%s() failed to allocate default DRAM tier\\n\", __func__);\n\n\t/*\n\t * Look at all the existing N_MEMORY nodes and add them to\n\t * default memory tier or to a tier if we already have memory\n\t * types assigned.\n\t */\n\tfor_each_node_state(node, N_MEMORY) {\n\t\tmemtier = set_node_memory_tier(node);\n\t\tif (IS_ERR(memtier))\n\t\t\t/*\n\t\t\t * Continue with memtiers we are able to setup\n\t\t\t */\n\t\t\tbreak;\n\t}\n\testablish_demotion_targets();\n\tmutex_unlock(&memory_tier_lock);\n\n\thotplug_memory_notifier(memtier_hotplug_callback, MEMTIER_HOTPLUG_PRI);\n\treturn 0;\n}",
        "code_after_change": "static int __init memory_tier_init(void)\n{\n\tint ret, node;\n\tstruct memory_tier *memtier;\n\n\tret = subsys_virtual_register(&memory_tier_subsys, NULL);\n\tif (ret)\n\t\tpanic(\"%s() failed to register memory tier subsystem\\n\", __func__);\n\n#ifdef CONFIG_MIGRATION\n\tnode_demotion = kcalloc(nr_node_ids, sizeof(struct demotion_nodes),\n\t\t\t\tGFP_KERNEL);\n\tWARN_ON(!node_demotion);\n#endif\n\tmutex_lock(&memory_tier_lock);\n\t/*\n\t * For now we can have 4 faster memory tiers with smaller adistance\n\t * than default DRAM tier.\n\t */\n\tdefault_dram_type = alloc_memory_type(MEMTIER_ADISTANCE_DRAM);\n\tif (IS_ERR(default_dram_type))\n\t\tpanic(\"%s() failed to allocate default DRAM tier\\n\", __func__);\n\n\t/*\n\t * Look at all the existing N_MEMORY nodes and add them to\n\t * default memory tier or to a tier if we already have memory\n\t * types assigned.\n\t */\n\tfor_each_node_state(node, N_MEMORY) {\n\t\tmemtier = set_node_memory_tier(node);\n\t\tif (IS_ERR(memtier))\n\t\t\t/*\n\t\t\t * Continue with memtiers we are able to setup\n\t\t\t */\n\t\t\tbreak;\n\t}\n\testablish_demotion_targets();\n\tmutex_unlock(&memory_tier_lock);\n\n\thotplug_memory_notifier(memtier_hotplug_callback, MEMTIER_HOTPLUG_PRI);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,7 +18,7 @@\n \t * than default DRAM tier.\n \t */\n \tdefault_dram_type = alloc_memory_type(MEMTIER_ADISTANCE_DRAM);\n-\tif (!default_dram_type)\n+\tif (IS_ERR(default_dram_type))\n \t\tpanic(\"%s() failed to allocate default DRAM tier\\n\", __func__);\n \n \t/*",
        "function_modified_lines": {
            "added": [
                "\tif (IS_ERR(default_dram_type))"
            ],
            "deleted": [
                "\tif (!default_dram_type)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 6.2, mm/memory-tiers.c misinterprets the alloc_memory_type return value (expects it to be NULL in the error case, whereas it is actually an error pointer). NOTE: this is disputed by third parties because there are no realistic cases in which a user can cause the alloc_memory_type error case to be reached.",
        "id": 3948
    },
    {
        "cve_id": "CVE-2017-13686",
        "code_before_change": "static int inet_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct rtmsg *rtm;\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct fib_result res = {};\n\tstruct rtable *rt = NULL;\n\tstruct flowi4 fl4;\n\t__be32 dst = 0;\n\t__be32 src = 0;\n\tu32 iif;\n\tint err;\n\tint mark;\n\tstruct sk_buff *skb;\n\tu32 table_id = RT_TABLE_MAIN;\n\tkuid_t uid;\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_ipv4_policy,\n\t\t\t  extack);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtm = nlmsg_data(nlh);\n\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb) {\n\t\terr = -ENOBUFS;\n\t\tgoto errout;\n\t}\n\n\t/* Reserve room for dummy headers, this skb can pass\n\t   through good chunk of routing engine.\n\t */\n\tskb_reset_mac_header(skb);\n\tskb_reset_network_header(skb);\n\n\tsrc = tb[RTA_SRC] ? nla_get_in_addr(tb[RTA_SRC]) : 0;\n\tdst = tb[RTA_DST] ? nla_get_in_addr(tb[RTA_DST]) : 0;\n\tiif = tb[RTA_IIF] ? nla_get_u32(tb[RTA_IIF]) : 0;\n\tmark = tb[RTA_MARK] ? nla_get_u32(tb[RTA_MARK]) : 0;\n\tif (tb[RTA_UID])\n\t\tuid = make_kuid(current_user_ns(), nla_get_u32(tb[RTA_UID]));\n\telse\n\t\tuid = (iif ? INVALID_UID : current_uid());\n\n\t/* Bugfix: need to give ip_route_input enough of an IP header to\n\t * not gag.\n\t */\n\tip_hdr(skb)->protocol = IPPROTO_UDP;\n\tip_hdr(skb)->saddr = src;\n\tip_hdr(skb)->daddr = dst;\n\n\tskb_reserve(skb, MAX_HEADER + sizeof(struct iphdr));\n\n\tmemset(&fl4, 0, sizeof(fl4));\n\tfl4.daddr = dst;\n\tfl4.saddr = src;\n\tfl4.flowi4_tos = rtm->rtm_tos;\n\tfl4.flowi4_oif = tb[RTA_OIF] ? nla_get_u32(tb[RTA_OIF]) : 0;\n\tfl4.flowi4_mark = mark;\n\tfl4.flowi4_uid = uid;\n\n\trcu_read_lock();\n\n\tif (iif) {\n\t\tstruct net_device *dev;\n\n\t\tdev = dev_get_by_index_rcu(net, iif);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto errout_free;\n\t\t}\n\n\t\tskb->protocol\t= htons(ETH_P_IP);\n\t\tskb->dev\t= dev;\n\t\tskb->mark\t= mark;\n\t\terr = ip_route_input_rcu(skb, dst, src, rtm->rtm_tos,\n\t\t\t\t\t dev, &res);\n\n\t\trt = skb_rtable(skb);\n\t\tif (err == 0 && rt->dst.error)\n\t\t\terr = -rt->dst.error;\n\t} else {\n\t\trt = ip_route_output_key_hash_rcu(net, &fl4, &res, skb);\n\t\terr = 0;\n\t\tif (IS_ERR(rt))\n\t\t\terr = PTR_ERR(rt);\n\t\telse\n\t\t\tskb_dst_set(skb, &rt->dst);\n\t}\n\n\tif (err)\n\t\tgoto errout_free;\n\n\tif (rtm->rtm_flags & RTM_F_NOTIFY)\n\t\trt->rt_flags |= RTCF_NOTIFY;\n\n\tif (rtm->rtm_flags & RTM_F_LOOKUP_TABLE)\n\t\ttable_id = rt->rt_table_id;\n\n\tif (rtm->rtm_flags & RTM_F_FIB_MATCH)\n\t\terr = fib_dump_info(skb, NETLINK_CB(in_skb).portid,\n\t\t\t\t    nlh->nlmsg_seq, RTM_NEWROUTE, table_id,\n\t\t\t\t    rt->rt_type, res.prefix, res.prefixlen,\n\t\t\t\t    fl4.flowi4_tos, res.fi, 0);\n\telse\n\t\terr = rt_fill_info(net, dst, src, table_id, &fl4, skb,\n\t\t\t\t   NETLINK_CB(in_skb).portid, nlh->nlmsg_seq);\n\tif (err < 0)\n\t\tgoto errout_free;\n\n\trcu_read_unlock();\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\nerrout:\n\treturn err;\n\nerrout_free:\n\trcu_read_unlock();\n\tkfree_skb(skb);\n\tgoto errout;\n}",
        "code_after_change": "static int inet_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tstruct net *net = sock_net(in_skb->sk);\n\tstruct rtmsg *rtm;\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct fib_result res = {};\n\tstruct rtable *rt = NULL;\n\tstruct flowi4 fl4;\n\t__be32 dst = 0;\n\t__be32 src = 0;\n\tu32 iif;\n\tint err;\n\tint mark;\n\tstruct sk_buff *skb;\n\tu32 table_id = RT_TABLE_MAIN;\n\tkuid_t uid;\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_ipv4_policy,\n\t\t\t  extack);\n\tif (err < 0)\n\t\tgoto errout;\n\n\trtm = nlmsg_data(nlh);\n\n\tskb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!skb) {\n\t\terr = -ENOBUFS;\n\t\tgoto errout;\n\t}\n\n\t/* Reserve room for dummy headers, this skb can pass\n\t   through good chunk of routing engine.\n\t */\n\tskb_reset_mac_header(skb);\n\tskb_reset_network_header(skb);\n\n\tsrc = tb[RTA_SRC] ? nla_get_in_addr(tb[RTA_SRC]) : 0;\n\tdst = tb[RTA_DST] ? nla_get_in_addr(tb[RTA_DST]) : 0;\n\tiif = tb[RTA_IIF] ? nla_get_u32(tb[RTA_IIF]) : 0;\n\tmark = tb[RTA_MARK] ? nla_get_u32(tb[RTA_MARK]) : 0;\n\tif (tb[RTA_UID])\n\t\tuid = make_kuid(current_user_ns(), nla_get_u32(tb[RTA_UID]));\n\telse\n\t\tuid = (iif ? INVALID_UID : current_uid());\n\n\t/* Bugfix: need to give ip_route_input enough of an IP header to\n\t * not gag.\n\t */\n\tip_hdr(skb)->protocol = IPPROTO_UDP;\n\tip_hdr(skb)->saddr = src;\n\tip_hdr(skb)->daddr = dst;\n\n\tskb_reserve(skb, MAX_HEADER + sizeof(struct iphdr));\n\n\tmemset(&fl4, 0, sizeof(fl4));\n\tfl4.daddr = dst;\n\tfl4.saddr = src;\n\tfl4.flowi4_tos = rtm->rtm_tos;\n\tfl4.flowi4_oif = tb[RTA_OIF] ? nla_get_u32(tb[RTA_OIF]) : 0;\n\tfl4.flowi4_mark = mark;\n\tfl4.flowi4_uid = uid;\n\n\trcu_read_lock();\n\n\tif (iif) {\n\t\tstruct net_device *dev;\n\n\t\tdev = dev_get_by_index_rcu(net, iif);\n\t\tif (!dev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto errout_free;\n\t\t}\n\n\t\tskb->protocol\t= htons(ETH_P_IP);\n\t\tskb->dev\t= dev;\n\t\tskb->mark\t= mark;\n\t\terr = ip_route_input_rcu(skb, dst, src, rtm->rtm_tos,\n\t\t\t\t\t dev, &res);\n\n\t\trt = skb_rtable(skb);\n\t\tif (err == 0 && rt->dst.error)\n\t\t\terr = -rt->dst.error;\n\t} else {\n\t\trt = ip_route_output_key_hash_rcu(net, &fl4, &res, skb);\n\t\terr = 0;\n\t\tif (IS_ERR(rt))\n\t\t\terr = PTR_ERR(rt);\n\t\telse\n\t\t\tskb_dst_set(skb, &rt->dst);\n\t}\n\n\tif (err)\n\t\tgoto errout_free;\n\n\tif (rtm->rtm_flags & RTM_F_NOTIFY)\n\t\trt->rt_flags |= RTCF_NOTIFY;\n\n\tif (rtm->rtm_flags & RTM_F_LOOKUP_TABLE)\n\t\ttable_id = rt->rt_table_id;\n\n\tif (rtm->rtm_flags & RTM_F_FIB_MATCH) {\n\t\tif (!res.fi) {\n\t\t\terr = fib_props[res.type].error;\n\t\t\tif (!err)\n\t\t\t\terr = -EHOSTUNREACH;\n\t\t\tgoto errout_free;\n\t\t}\n\t\terr = fib_dump_info(skb, NETLINK_CB(in_skb).portid,\n\t\t\t\t    nlh->nlmsg_seq, RTM_NEWROUTE, table_id,\n\t\t\t\t    rt->rt_type, res.prefix, res.prefixlen,\n\t\t\t\t    fl4.flowi4_tos, res.fi, 0);\n\t} else {\n\t\terr = rt_fill_info(net, dst, src, table_id, &fl4, skb,\n\t\t\t\t   NETLINK_CB(in_skb).portid, nlh->nlmsg_seq);\n\t}\n\tif (err < 0)\n\t\tgoto errout_free;\n\n\trcu_read_unlock();\n\n\terr = rtnl_unicast(skb, net, NETLINK_CB(in_skb).portid);\nerrout:\n\treturn err;\n\nerrout_free:\n\trcu_read_unlock();\n\tkfree_skb(skb);\n\tgoto errout;\n}",
        "patch": "--- code before\n+++ code after\n@@ -99,14 +99,21 @@\n \tif (rtm->rtm_flags & RTM_F_LOOKUP_TABLE)\n \t\ttable_id = rt->rt_table_id;\n \n-\tif (rtm->rtm_flags & RTM_F_FIB_MATCH)\n+\tif (rtm->rtm_flags & RTM_F_FIB_MATCH) {\n+\t\tif (!res.fi) {\n+\t\t\terr = fib_props[res.type].error;\n+\t\t\tif (!err)\n+\t\t\t\terr = -EHOSTUNREACH;\n+\t\t\tgoto errout_free;\n+\t\t}\n \t\terr = fib_dump_info(skb, NETLINK_CB(in_skb).portid,\n \t\t\t\t    nlh->nlmsg_seq, RTM_NEWROUTE, table_id,\n \t\t\t\t    rt->rt_type, res.prefix, res.prefixlen,\n \t\t\t\t    fl4.flowi4_tos, res.fi, 0);\n-\telse\n+\t} else {\n \t\terr = rt_fill_info(net, dst, src, table_id, &fl4, skb,\n \t\t\t\t   NETLINK_CB(in_skb).portid, nlh->nlmsg_seq);\n+\t}\n \tif (err < 0)\n \t\tgoto errout_free;\n ",
        "function_modified_lines": {
            "added": [
                "\tif (rtm->rtm_flags & RTM_F_FIB_MATCH) {",
                "\t\tif (!res.fi) {",
                "\t\t\terr = fib_props[res.type].error;",
                "\t\t\tif (!err)",
                "\t\t\t\terr = -EHOSTUNREACH;",
                "\t\t\tgoto errout_free;",
                "\t\t}",
                "\t} else {",
                "\t}"
            ],
            "deleted": [
                "\tif (rtm->rtm_flags & RTM_F_FIB_MATCH)",
                "\telse"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "net/ipv4/route.c in the Linux kernel 4.13-rc1 through 4.13-rc6 is too late to check for a NULL fi field when RTM_F_FIB_MATCH is set, which allows local users to cause a denial of service (NULL pointer dereference) or possibly have unspecified other impact via crafted system calls. NOTE: this does not affect any stable release.",
        "id": 1277
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int pctv340e_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* Power Supply on */\n\tdib0700_set_gpio(adap->dev, GPIO6,  GPIO_OUT, 0);\n\tmsleep(50);\n\tdib0700_set_gpio(adap->dev, GPIO6,  GPIO_OUT, 1);\n\tmsleep(100); /* Allow power supply to settle before probing */\n\n\t/* cx25843 reset */\n\tdib0700_set_gpio(adap->dev, GPIO10,  GPIO_OUT, 0);\n\tmsleep(1); /* cx25843 datasheet say 350us required */\n\tdib0700_set_gpio(adap->dev, GPIO10,  GPIO_OUT, 1);\n\n\t/* LNA off for now */\n\tdib0700_set_gpio(adap->dev, GPIO8,  GPIO_OUT, 1);\n\n\t/* Put the CX25843 to sleep for now since we're in digital mode */\n\tdib0700_set_gpio(adap->dev, GPIO2, GPIO_OUT, 1);\n\n\t/* FIXME: not verified yet */\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\n\tmsleep(500);\n\n\tif (state->dib7000p_ops.dib7000pc_detection(&adap->dev->i2c_adap) == 0) {\n\t\t/* Demodulator not found for some reason? */\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x12,\n\t\t\t      &pctv_340e_config);\n\tst->is_dib7000pc = 1;\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int pctv340e_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* Power Supply on */\n\tdib0700_set_gpio(adap->dev, GPIO6,  GPIO_OUT, 0);\n\tmsleep(50);\n\tdib0700_set_gpio(adap->dev, GPIO6,  GPIO_OUT, 1);\n\tmsleep(100); /* Allow power supply to settle before probing */\n\n\t/* cx25843 reset */\n\tdib0700_set_gpio(adap->dev, GPIO10,  GPIO_OUT, 0);\n\tmsleep(1); /* cx25843 datasheet say 350us required */\n\tdib0700_set_gpio(adap->dev, GPIO10,  GPIO_OUT, 1);\n\n\t/* LNA off for now */\n\tdib0700_set_gpio(adap->dev, GPIO8,  GPIO_OUT, 1);\n\n\t/* Put the CX25843 to sleep for now since we're in digital mode */\n\tdib0700_set_gpio(adap->dev, GPIO2, GPIO_OUT, 1);\n\n\t/* FIXME: not verified yet */\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\n\tmsleep(500);\n\n\tif (state->dib7000p_ops.dib7000pc_detection(&adap->dev->i2c_adap) == 0) {\n\t\t/* Demodulator not found for some reason? */\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x12,\n\t\t\t      &pctv_340e_config);\n\tst->is_dib7000pc = 1;\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,7 +30,7 @@\n \n \tif (state->dib7000p_ops.dib7000pc_detection(&adap->dev->i2c_adap) == 0) {\n \t\t/* Demodulator not found for some reason? */\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1330
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static int btrfs_finish_sprout(struct btrfs_trans_handle *trans,\n\t\t\t       struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root = fs_info->chunk_root;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_dev_item *dev_item;\n\tstruct btrfs_device *device;\n\tstruct btrfs_key key;\n\tu8 fs_uuid[BTRFS_FSID_SIZE];\n\tu8 dev_uuid[BTRFS_UUID_SIZE];\n\tu64 devid;\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = BTRFS_DEV_ITEMS_OBJECTID;\n\tkey.offset = 0;\n\tkey.type = BTRFS_DEV_ITEM_KEY;\n\n\twhile (1) {\n\t\tret = btrfs_search_slot(trans, root, &key, path, 0, 1);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\n\t\tleaf = path->nodes[0];\nnext_slot:\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret > 0)\n\t\t\t\tbreak;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto error;\n\t\t\tleaf = path->nodes[0];\n\t\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\t\t\tbtrfs_release_path(path);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\t\tif (key.objectid != BTRFS_DEV_ITEMS_OBJECTID ||\n\t\t    key.type != BTRFS_DEV_ITEM_KEY)\n\t\t\tbreak;\n\n\t\tdev_item = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t\t  struct btrfs_dev_item);\n\t\tdevid = btrfs_device_id(leaf, dev_item);\n\t\tread_extent_buffer(leaf, dev_uuid, btrfs_device_uuid(dev_item),\n\t\t\t\t   BTRFS_UUID_SIZE);\n\t\tread_extent_buffer(leaf, fs_uuid, btrfs_device_fsid(dev_item),\n\t\t\t\t   BTRFS_FSID_SIZE);\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   fs_uuid);\n\t\tBUG_ON(!device); /* Logic error */\n\n\t\tif (device->fs_devices->seeding) {\n\t\t\tbtrfs_set_device_generation(leaf, dev_item,\n\t\t\t\t\t\t    device->generation);\n\t\t\tbtrfs_mark_buffer_dirty(leaf);\n\t\t}\n\n\t\tpath->slots[0]++;\n\t\tgoto next_slot;\n\t}\n\tret = 0;\nerror:\n\tbtrfs_free_path(path);\n\treturn ret;\n}",
        "code_after_change": "static int btrfs_finish_sprout(struct btrfs_trans_handle *trans,\n\t\t\t       struct btrfs_fs_info *fs_info)\n{\n\tstruct btrfs_root *root = fs_info->chunk_root;\n\tstruct btrfs_path *path;\n\tstruct extent_buffer *leaf;\n\tstruct btrfs_dev_item *dev_item;\n\tstruct btrfs_device *device;\n\tstruct btrfs_key key;\n\tu8 fs_uuid[BTRFS_FSID_SIZE];\n\tu8 dev_uuid[BTRFS_UUID_SIZE];\n\tu64 devid;\n\tint ret;\n\n\tpath = btrfs_alloc_path();\n\tif (!path)\n\t\treturn -ENOMEM;\n\n\tkey.objectid = BTRFS_DEV_ITEMS_OBJECTID;\n\tkey.offset = 0;\n\tkey.type = BTRFS_DEV_ITEM_KEY;\n\n\twhile (1) {\n\t\tret = btrfs_search_slot(trans, root, &key, path, 0, 1);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\n\t\tleaf = path->nodes[0];\nnext_slot:\n\t\tif (path->slots[0] >= btrfs_header_nritems(leaf)) {\n\t\t\tret = btrfs_next_leaf(root, path);\n\t\t\tif (ret > 0)\n\t\t\t\tbreak;\n\t\t\tif (ret < 0)\n\t\t\t\tgoto error;\n\t\t\tleaf = path->nodes[0];\n\t\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\t\t\tbtrfs_release_path(path);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\n\t\tif (key.objectid != BTRFS_DEV_ITEMS_OBJECTID ||\n\t\t    key.type != BTRFS_DEV_ITEM_KEY)\n\t\t\tbreak;\n\n\t\tdev_item = btrfs_item_ptr(leaf, path->slots[0],\n\t\t\t\t\t  struct btrfs_dev_item);\n\t\tdevid = btrfs_device_id(leaf, dev_item);\n\t\tread_extent_buffer(leaf, dev_uuid, btrfs_device_uuid(dev_item),\n\t\t\t\t   BTRFS_UUID_SIZE);\n\t\tread_extent_buffer(leaf, fs_uuid, btrfs_device_fsid(dev_item),\n\t\t\t\t   BTRFS_FSID_SIZE);\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   fs_uuid, true);\n\t\tBUG_ON(!device); /* Logic error */\n\n\t\tif (device->fs_devices->seeding) {\n\t\t\tbtrfs_set_device_generation(leaf, dev_item,\n\t\t\t\t\t\t    device->generation);\n\t\t\tbtrfs_mark_buffer_dirty(leaf);\n\t\t}\n\n\t\tpath->slots[0]++;\n\t\tgoto next_slot;\n\t}\n\tret = 0;\nerror:\n\tbtrfs_free_path(path);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -52,7 +52,7 @@\n \t\tread_extent_buffer(leaf, fs_uuid, btrfs_device_fsid(dev_item),\n \t\t\t\t   BTRFS_FSID_SIZE);\n \t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n-\t\t\t\t\t   fs_uuid);\n+\t\t\t\t\t   fs_uuid, true);\n \t\tBUG_ON(!device); /* Logic error */\n \n \t\tif (device->fs_devices->seeding) {",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t   fs_uuid, true);"
            ],
            "deleted": [
                "\t\t\t\t\t   fs_uuid);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2118
    },
    {
        "cve_id": "CVE-2022-1516",
        "code_before_change": "void x25_kill_by_neigh(struct x25_neigh *nb)\n{\n\tstruct sock *s;\n\n\twrite_lock_bh(&x25_list_lock);\n\n\tsk_for_each(s, &x25_list)\n\t\tif (x25_sk(s)->neighbour == nb)\n\t\t\tx25_disconnect(s, ENETUNREACH, 0, 0);\n\n\twrite_unlock_bh(&x25_list_lock);\n\n\t/* Remove any related forwards */\n\tx25_clear_forward_by_dev(nb->dev);\n}",
        "code_after_change": "void x25_kill_by_neigh(struct x25_neigh *nb)\n{\n\tstruct sock *s;\n\n\twrite_lock_bh(&x25_list_lock);\n\n\tsk_for_each(s, &x25_list) {\n\t\tif (x25_sk(s)->neighbour == nb) {\n\t\t\twrite_unlock_bh(&x25_list_lock);\n\t\t\tlock_sock(s);\n\t\t\tx25_disconnect(s, ENETUNREACH, 0, 0);\n\t\t\trelease_sock(s);\n\t\t\twrite_lock_bh(&x25_list_lock);\n\t\t}\n\t}\n\twrite_unlock_bh(&x25_list_lock);\n\n\t/* Remove any related forwards */\n\tx25_clear_forward_by_dev(nb->dev);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,15 @@\n \n \twrite_lock_bh(&x25_list_lock);\n \n-\tsk_for_each(s, &x25_list)\n-\t\tif (x25_sk(s)->neighbour == nb)\n+\tsk_for_each(s, &x25_list) {\n+\t\tif (x25_sk(s)->neighbour == nb) {\n+\t\t\twrite_unlock_bh(&x25_list_lock);\n+\t\t\tlock_sock(s);\n \t\t\tx25_disconnect(s, ENETUNREACH, 0, 0);\n-\n+\t\t\trelease_sock(s);\n+\t\t\twrite_lock_bh(&x25_list_lock);\n+\t\t}\n+\t}\n \twrite_unlock_bh(&x25_list_lock);\n \n \t/* Remove any related forwards */",
        "function_modified_lines": {
            "added": [
                "\tsk_for_each(s, &x25_list) {",
                "\t\tif (x25_sk(s)->neighbour == nb) {",
                "\t\t\twrite_unlock_bh(&x25_list_lock);",
                "\t\t\tlock_sock(s);",
                "\t\t\trelease_sock(s);",
                "\t\t\twrite_lock_bh(&x25_list_lock);",
                "\t\t}",
                "\t}"
            ],
            "deleted": [
                "\tsk_for_each(s, &x25_list)",
                "\t\tif (x25_sk(s)->neighbour == nb)",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s X.25 set of standardized network protocols functionality in the way a user terminates their session using a simulated Ethernet card and continued usage of this connection. This flaw allows a local user to crash the system.",
        "id": 3264
    },
    {
        "cve_id": "CVE-2017-15306",
        "code_before_change": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&\n\t\t    is_kvmppc_hv_enabled(kvm);\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}",
        "code_after_change": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}",
        "patch": "--- code before\n+++ code after\n@@ -154,8 +154,7 @@\n \t\tbreak;\n #endif\n \tcase KVM_CAP_PPC_HTM:\n-\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&\n-\t\t    is_kvmppc_hv_enabled(kvm);\n+\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;\n \t\tbreak;\n \tdefault:\n \t\tr = 0;",
        "function_modified_lines": {
            "added": [
                "\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;"
            ],
            "deleted": [
                "\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&",
                "\t\t    is_kvmppc_hv_enabled(kvm);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The kvm_vm_ioctl_check_extension function in arch/powerpc/kvm/powerpc.c in the Linux kernel before 4.13.11 allows local users to cause a denial of service (NULL pointer dereference and system crash) via a KVM_CHECK_EXTENSION KVM_CAP_PPC_HTM ioctl call to /dev/kvm.",
        "id": 1305
    },
    {
        "cve_id": "CVE-2019-15099",
        "code_before_change": "static struct ath10k_urb_context *\nath10k_usb_alloc_urb_from_pipe(struct ath10k_usb_pipe *pipe)\n{\n\tstruct ath10k_urb_context *urb_context = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n\tif (!list_empty(&pipe->urb_list_head)) {\n\t\turb_context = list_first_entry(&pipe->urb_list_head,\n\t\t\t\t\t       struct ath10k_urb_context, link);\n\t\tlist_del(&urb_context->link);\n\t\tpipe->urb_cnt--;\n\t}\n\tspin_unlock_irqrestore(&pipe->ar_usb->cs_lock, flags);\n\n\treturn urb_context;\n}",
        "code_after_change": "static struct ath10k_urb_context *\nath10k_usb_alloc_urb_from_pipe(struct ath10k_usb_pipe *pipe)\n{\n\tstruct ath10k_urb_context *urb_context = NULL;\n\tunsigned long flags;\n\n\t/* bail if this pipe is not initialized */\n\tif (!pipe->ar_usb)\n\t\treturn NULL;\n\n\tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n\tif (!list_empty(&pipe->urb_list_head)) {\n\t\turb_context = list_first_entry(&pipe->urb_list_head,\n\t\t\t\t\t       struct ath10k_urb_context, link);\n\t\tlist_del(&urb_context->link);\n\t\tpipe->urb_cnt--;\n\t}\n\tspin_unlock_irqrestore(&pipe->ar_usb->cs_lock, flags);\n\n\treturn urb_context;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,10 @@\n {\n \tstruct ath10k_urb_context *urb_context = NULL;\n \tunsigned long flags;\n+\n+\t/* bail if this pipe is not initialized */\n+\tif (!pipe->ar_usb)\n+\t\treturn NULL;\n \n \tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n \tif (!list_empty(&pipe->urb_list_head)) {",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* bail if this pipe is not initialized */",
                "\tif (!pipe->ar_usb)",
                "\t\treturn NULL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/wireless/ath/ath10k/usb.c in the Linux kernel through 5.2.8 has a NULL pointer dereference via an incomplete address in an endpoint descriptor.",
        "id": 1989
    },
    {
        "cve_id": "CVE-2016-3070",
        "code_before_change": "int migrate_page_move_mapping(struct address_space *mapping,\n\t\tstruct page *newpage, struct page *page,\n\t\tstruct buffer_head *head, enum migrate_mode mode,\n\t\tint extra_count)\n{\n\tint expected_count = 1 + extra_count;\n\tvoid **pslot;\n\n\tif (!mapping) {\n\t\t/* Anonymous page without mapping */\n\t\tif (page_count(page) != expected_count)\n\t\t\treturn -EAGAIN;\n\n\t\t/* No turning back from here */\n\t\tset_page_memcg(newpage, page_memcg(page));\n\t\tnewpage->index = page->index;\n\t\tnewpage->mapping = page->mapping;\n\t\tif (PageSwapBacked(page))\n\t\t\tSetPageSwapBacked(newpage);\n\n\t\treturn MIGRATEPAGE_SUCCESS;\n\t}\n\n\tspin_lock_irq(&mapping->tree_lock);\n\n\tpslot = radix_tree_lookup_slot(&mapping->page_tree,\n \t\t\t\t\tpage_index(page));\n\n\texpected_count += 1 + page_has_private(page);\n\tif (page_count(page) != expected_count ||\n\t\tradix_tree_deref_slot_protected(pslot, &mapping->tree_lock) != page) {\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\tif (!page_freeze_refs(page, expected_count)) {\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\t/*\n\t * In the async migration case of moving a page with buffers, lock the\n\t * buffers using trylock before the mapping is moved. If the mapping\n\t * was moved, we later failed to lock the buffers and could not move\n\t * the mapping back due to an elevated page count, we would have to\n\t * block waiting on other references to be dropped.\n\t */\n\tif (mode == MIGRATE_ASYNC && head &&\n\t\t\t!buffer_migrate_lock_buffers(head, mode)) {\n\t\tpage_unfreeze_refs(page, expected_count);\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\t/*\n\t * Now we know that no one else is looking at the page:\n\t * no turning back from here.\n\t */\n\tset_page_memcg(newpage, page_memcg(page));\n\tnewpage->index = page->index;\n\tnewpage->mapping = page->mapping;\n\tif (PageSwapBacked(page))\n\t\tSetPageSwapBacked(newpage);\n\n\tget_page(newpage);\t/* add cache reference */\n\tif (PageSwapCache(page)) {\n\t\tSetPageSwapCache(newpage);\n\t\tset_page_private(newpage, page_private(page));\n\t}\n\n\tradix_tree_replace_slot(pslot, newpage);\n\n\t/*\n\t * Drop cache reference from old page by unfreezing\n\t * to one less reference.\n\t * We know this isn't the last reference.\n\t */\n\tpage_unfreeze_refs(page, expected_count - 1);\n\n\t/*\n\t * If moved to a different zone then also account\n\t * the page for that zone. Other VM counters will be\n\t * taken care of when we establish references to the\n\t * new page and drop references to the old page.\n\t *\n\t * Note that anonymous pages are accounted for\n\t * via NR_FILE_PAGES and NR_ANON_PAGES if they\n\t * are mapped to swap space.\n\t */\n\t__dec_zone_page_state(page, NR_FILE_PAGES);\n\t__inc_zone_page_state(newpage, NR_FILE_PAGES);\n\tif (!PageSwapCache(page) && PageSwapBacked(page)) {\n\t\t__dec_zone_page_state(page, NR_SHMEM);\n\t\t__inc_zone_page_state(newpage, NR_SHMEM);\n\t}\n\tspin_unlock_irq(&mapping->tree_lock);\n\n\treturn MIGRATEPAGE_SUCCESS;\n}",
        "code_after_change": "int migrate_page_move_mapping(struct address_space *mapping,\n\t\tstruct page *newpage, struct page *page,\n\t\tstruct buffer_head *head, enum migrate_mode mode,\n\t\tint extra_count)\n{\n\tstruct zone *oldzone, *newzone;\n\tint dirty;\n\tint expected_count = 1 + extra_count;\n\tvoid **pslot;\n\n\tif (!mapping) {\n\t\t/* Anonymous page without mapping */\n\t\tif (page_count(page) != expected_count)\n\t\t\treturn -EAGAIN;\n\n\t\t/* No turning back from here */\n\t\tset_page_memcg(newpage, page_memcg(page));\n\t\tnewpage->index = page->index;\n\t\tnewpage->mapping = page->mapping;\n\t\tif (PageSwapBacked(page))\n\t\t\tSetPageSwapBacked(newpage);\n\n\t\treturn MIGRATEPAGE_SUCCESS;\n\t}\n\n\toldzone = page_zone(page);\n\tnewzone = page_zone(newpage);\n\n\tspin_lock_irq(&mapping->tree_lock);\n\n\tpslot = radix_tree_lookup_slot(&mapping->page_tree,\n \t\t\t\t\tpage_index(page));\n\n\texpected_count += 1 + page_has_private(page);\n\tif (page_count(page) != expected_count ||\n\t\tradix_tree_deref_slot_protected(pslot, &mapping->tree_lock) != page) {\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\tif (!page_freeze_refs(page, expected_count)) {\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\t/*\n\t * In the async migration case of moving a page with buffers, lock the\n\t * buffers using trylock before the mapping is moved. If the mapping\n\t * was moved, we later failed to lock the buffers and could not move\n\t * the mapping back due to an elevated page count, we would have to\n\t * block waiting on other references to be dropped.\n\t */\n\tif (mode == MIGRATE_ASYNC && head &&\n\t\t\t!buffer_migrate_lock_buffers(head, mode)) {\n\t\tpage_unfreeze_refs(page, expected_count);\n\t\tspin_unlock_irq(&mapping->tree_lock);\n\t\treturn -EAGAIN;\n\t}\n\n\t/*\n\t * Now we know that no one else is looking at the page:\n\t * no turning back from here.\n\t */\n\tset_page_memcg(newpage, page_memcg(page));\n\tnewpage->index = page->index;\n\tnewpage->mapping = page->mapping;\n\tif (PageSwapBacked(page))\n\t\tSetPageSwapBacked(newpage);\n\n\tget_page(newpage);\t/* add cache reference */\n\tif (PageSwapCache(page)) {\n\t\tSetPageSwapCache(newpage);\n\t\tset_page_private(newpage, page_private(page));\n\t}\n\n\t/* Move dirty while page refs frozen and newpage not yet exposed */\n\tdirty = PageDirty(page);\n\tif (dirty) {\n\t\tClearPageDirty(page);\n\t\tSetPageDirty(newpage);\n\t}\n\n\tradix_tree_replace_slot(pslot, newpage);\n\n\t/*\n\t * Drop cache reference from old page by unfreezing\n\t * to one less reference.\n\t * We know this isn't the last reference.\n\t */\n\tpage_unfreeze_refs(page, expected_count - 1);\n\n\tspin_unlock(&mapping->tree_lock);\n\t/* Leave irq disabled to prevent preemption while updating stats */\n\n\t/*\n\t * If moved to a different zone then also account\n\t * the page for that zone. Other VM counters will be\n\t * taken care of when we establish references to the\n\t * new page and drop references to the old page.\n\t *\n\t * Note that anonymous pages are accounted for\n\t * via NR_FILE_PAGES and NR_ANON_PAGES if they\n\t * are mapped to swap space.\n\t */\n\tif (newzone != oldzone) {\n\t\t__dec_zone_state(oldzone, NR_FILE_PAGES);\n\t\t__inc_zone_state(newzone, NR_FILE_PAGES);\n\t\tif (PageSwapBacked(page) && !PageSwapCache(page)) {\n\t\t\t__dec_zone_state(oldzone, NR_SHMEM);\n\t\t\t__inc_zone_state(newzone, NR_SHMEM);\n\t\t}\n\t\tif (dirty && mapping_cap_account_dirty(mapping)) {\n\t\t\t__dec_zone_state(oldzone, NR_FILE_DIRTY);\n\t\t\t__inc_zone_state(newzone, NR_FILE_DIRTY);\n\t\t}\n\t}\n\tlocal_irq_enable();\n\n\treturn MIGRATEPAGE_SUCCESS;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,8 @@\n \t\tstruct buffer_head *head, enum migrate_mode mode,\n \t\tint extra_count)\n {\n+\tstruct zone *oldzone, *newzone;\n+\tint dirty;\n \tint expected_count = 1 + extra_count;\n \tvoid **pslot;\n \n@@ -20,6 +22,9 @@\n \n \t\treturn MIGRATEPAGE_SUCCESS;\n \t}\n+\n+\toldzone = page_zone(page);\n+\tnewzone = page_zone(newpage);\n \n \tspin_lock_irq(&mapping->tree_lock);\n \n@@ -68,6 +73,13 @@\n \t\tset_page_private(newpage, page_private(page));\n \t}\n \n+\t/* Move dirty while page refs frozen and newpage not yet exposed */\n+\tdirty = PageDirty(page);\n+\tif (dirty) {\n+\t\tClearPageDirty(page);\n+\t\tSetPageDirty(newpage);\n+\t}\n+\n \tradix_tree_replace_slot(pslot, newpage);\n \n \t/*\n@@ -76,6 +88,9 @@\n \t * We know this isn't the last reference.\n \t */\n \tpage_unfreeze_refs(page, expected_count - 1);\n+\n+\tspin_unlock(&mapping->tree_lock);\n+\t/* Leave irq disabled to prevent preemption while updating stats */\n \n \t/*\n \t * If moved to a different zone then also account\n@@ -87,13 +102,19 @@\n \t * via NR_FILE_PAGES and NR_ANON_PAGES if they\n \t * are mapped to swap space.\n \t */\n-\t__dec_zone_page_state(page, NR_FILE_PAGES);\n-\t__inc_zone_page_state(newpage, NR_FILE_PAGES);\n-\tif (!PageSwapCache(page) && PageSwapBacked(page)) {\n-\t\t__dec_zone_page_state(page, NR_SHMEM);\n-\t\t__inc_zone_page_state(newpage, NR_SHMEM);\n+\tif (newzone != oldzone) {\n+\t\t__dec_zone_state(oldzone, NR_FILE_PAGES);\n+\t\t__inc_zone_state(newzone, NR_FILE_PAGES);\n+\t\tif (PageSwapBacked(page) && !PageSwapCache(page)) {\n+\t\t\t__dec_zone_state(oldzone, NR_SHMEM);\n+\t\t\t__inc_zone_state(newzone, NR_SHMEM);\n+\t\t}\n+\t\tif (dirty && mapping_cap_account_dirty(mapping)) {\n+\t\t\t__dec_zone_state(oldzone, NR_FILE_DIRTY);\n+\t\t\t__inc_zone_state(newzone, NR_FILE_DIRTY);\n+\t\t}\n \t}\n-\tspin_unlock_irq(&mapping->tree_lock);\n+\tlocal_irq_enable();\n \n \treturn MIGRATEPAGE_SUCCESS;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct zone *oldzone, *newzone;",
                "\tint dirty;",
                "",
                "\toldzone = page_zone(page);",
                "\tnewzone = page_zone(newpage);",
                "\t/* Move dirty while page refs frozen and newpage not yet exposed */",
                "\tdirty = PageDirty(page);",
                "\tif (dirty) {",
                "\t\tClearPageDirty(page);",
                "\t\tSetPageDirty(newpage);",
                "\t}",
                "",
                "",
                "\tspin_unlock(&mapping->tree_lock);",
                "\t/* Leave irq disabled to prevent preemption while updating stats */",
                "\tif (newzone != oldzone) {",
                "\t\t__dec_zone_state(oldzone, NR_FILE_PAGES);",
                "\t\t__inc_zone_state(newzone, NR_FILE_PAGES);",
                "\t\tif (PageSwapBacked(page) && !PageSwapCache(page)) {",
                "\t\t\t__dec_zone_state(oldzone, NR_SHMEM);",
                "\t\t\t__inc_zone_state(newzone, NR_SHMEM);",
                "\t\t}",
                "\t\tif (dirty && mapping_cap_account_dirty(mapping)) {",
                "\t\t\t__dec_zone_state(oldzone, NR_FILE_DIRTY);",
                "\t\t\t__inc_zone_state(newzone, NR_FILE_DIRTY);",
                "\t\t}",
                "\tlocal_irq_enable();"
            ],
            "deleted": [
                "\t__dec_zone_page_state(page, NR_FILE_PAGES);",
                "\t__inc_zone_page_state(newpage, NR_FILE_PAGES);",
                "\tif (!PageSwapCache(page) && PageSwapBacked(page)) {",
                "\t\t__dec_zone_page_state(page, NR_SHMEM);",
                "\t\t__inc_zone_page_state(newpage, NR_SHMEM);",
                "\tspin_unlock_irq(&mapping->tree_lock);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The trace_writeback_dirty_page implementation in include/trace/events/writeback.h in the Linux kernel before 4.4 improperly interacts with mm/migrate.c, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact by triggering a certain page move.",
        "id": 960
    },
    {
        "cve_id": "CVE-2023-23004",
        "code_before_change": "static bool malidp_check_pages_threshold(struct malidp_plane_state *ms,\n\t\t\t\t\t u32 pgsize)\n{\n\tint i;\n\n\tfor (i = 0; i < ms->n_planes; i++) {\n\t\tstruct drm_gem_object *obj;\n\t\tstruct drm_gem_cma_object *cma_obj;\n\t\tstruct sg_table *sgt;\n\t\tstruct scatterlist *sgl;\n\n\t\tobj = drm_gem_fb_get_obj(ms->base.fb, i);\n\t\tcma_obj = to_drm_gem_cma_obj(obj);\n\n\t\tif (cma_obj->sgt)\n\t\t\tsgt = cma_obj->sgt;\n\t\telse\n\t\t\tsgt = obj->funcs->get_sg_table(obj);\n\n\t\tif (!sgt)\n\t\t\treturn false;\n\n\t\tsgl = sgt->sgl;\n\n\t\twhile (sgl) {\n\t\t\tif (sgl->length < pgsize) {\n\t\t\t\tif (!cma_obj->sgt)\n\t\t\t\t\tkfree(sgt);\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tsgl = sg_next(sgl);\n\t\t}\n\t\tif (!cma_obj->sgt)\n\t\t\tkfree(sgt);\n\t}\n\n\treturn true;\n}",
        "code_after_change": "static bool malidp_check_pages_threshold(struct malidp_plane_state *ms,\n\t\t\t\t\t u32 pgsize)\n{\n\tint i;\n\n\tfor (i = 0; i < ms->n_planes; i++) {\n\t\tstruct drm_gem_object *obj;\n\t\tstruct drm_gem_cma_object *cma_obj;\n\t\tstruct sg_table *sgt;\n\t\tstruct scatterlist *sgl;\n\n\t\tobj = drm_gem_fb_get_obj(ms->base.fb, i);\n\t\tcma_obj = to_drm_gem_cma_obj(obj);\n\n\t\tif (cma_obj->sgt)\n\t\t\tsgt = cma_obj->sgt;\n\t\telse\n\t\t\tsgt = obj->funcs->get_sg_table(obj);\n\n\t\tif (IS_ERR(sgt))\n\t\t\treturn false;\n\n\t\tsgl = sgt->sgl;\n\n\t\twhile (sgl) {\n\t\t\tif (sgl->length < pgsize) {\n\t\t\t\tif (!cma_obj->sgt)\n\t\t\t\t\tkfree(sgt);\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tsgl = sg_next(sgl);\n\t\t}\n\t\tif (!cma_obj->sgt)\n\t\t\tkfree(sgt);\n\t}\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,7 +17,7 @@\n \t\telse\n \t\t\tsgt = obj->funcs->get_sg_table(obj);\n \n-\t\tif (!sgt)\n+\t\tif (IS_ERR(sgt))\n \t\t\treturn false;\n \n \t\tsgl = sgt->sgl;",
        "function_modified_lines": {
            "added": [
                "\t\tif (IS_ERR(sgt))"
            ],
            "deleted": [
                "\t\tif (!sgt)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.19, drivers/gpu/drm/arm/malidp_planes.c misinterprets the get_sg_table return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3947
    },
    {
        "cve_id": "CVE-2017-15299",
        "code_before_change": "key_ref_t key_create_or_update(key_ref_t keyring_ref,\n\t\t\t       const char *type,\n\t\t\t       const char *description,\n\t\t\t       const void *payload,\n\t\t\t       size_t plen,\n\t\t\t       key_perm_t perm,\n\t\t\t       unsigned long flags)\n{\n\tstruct keyring_index_key index_key = {\n\t\t.description\t= description,\n\t};\n\tstruct key_preparsed_payload prep;\n\tstruct assoc_array_edit *edit;\n\tconst struct cred *cred = current_cred();\n\tstruct key *keyring, *key = NULL;\n\tkey_ref_t key_ref;\n\tint ret;\n\tstruct key_restriction *restrict_link = NULL;\n\n\t/* look up the key type to see if it's one of the registered kernel\n\t * types */\n\tindex_key.type = key_type_lookup(type);\n\tif (IS_ERR(index_key.type)) {\n\t\tkey_ref = ERR_PTR(-ENODEV);\n\t\tgoto error;\n\t}\n\n\tkey_ref = ERR_PTR(-EINVAL);\n\tif (!index_key.type->instantiate ||\n\t    (!index_key.description && !index_key.type->preparse))\n\t\tgoto error_put_type;\n\n\tkeyring = key_ref_to_ptr(keyring_ref);\n\n\tkey_check(keyring);\n\n\tkey_ref = ERR_PTR(-EPERM);\n\tif (!(flags & KEY_ALLOC_BYPASS_RESTRICTION))\n\t\trestrict_link = keyring->restrict_link;\n\n\tkey_ref = ERR_PTR(-ENOTDIR);\n\tif (keyring->type != &key_type_keyring)\n\t\tgoto error_put_type;\n\n\tmemset(&prep, 0, sizeof(prep));\n\tprep.data = payload;\n\tprep.datalen = plen;\n\tprep.quotalen = index_key.type->def_datalen;\n\tprep.expiry = TIME_T_MAX;\n\tif (index_key.type->preparse) {\n\t\tret = index_key.type->preparse(&prep);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_free_prep;\n\t\t}\n\t\tif (!index_key.description)\n\t\t\tindex_key.description = prep.description;\n\t\tkey_ref = ERR_PTR(-EINVAL);\n\t\tif (!index_key.description)\n\t\t\tgoto error_free_prep;\n\t}\n\tindex_key.desc_len = strlen(index_key.description);\n\n\tret = __key_link_begin(keyring, &index_key, &edit);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_free_prep;\n\t}\n\n\tif (restrict_link && restrict_link->check) {\n\t\tret = restrict_link->check(keyring, index_key.type,\n\t\t\t\t\t   &prep.payload, restrict_link->key);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_link_end;\n\t\t}\n\t}\n\n\t/* if we're going to allocate a new key, we're going to have\n\t * to modify the keyring */\n\tret = key_permission(keyring_ref, KEY_NEED_WRITE);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\t/* if it's possible to update this type of key, search for an existing\n\t * key of the same type and description in the destination keyring and\n\t * update that instead if possible\n\t */\n\tif (index_key.type->update) {\n\t\tkey_ref = find_key_to_update(keyring_ref, &index_key);\n\t\tif (key_ref)\n\t\t\tgoto found_matching_key;\n\t}\n\n\t/* if the client doesn't provide, decide on the permissions we want */\n\tif (perm == KEY_PERM_UNDEF) {\n\t\tperm = KEY_POS_VIEW | KEY_POS_SEARCH | KEY_POS_LINK | KEY_POS_SETATTR;\n\t\tperm |= KEY_USR_VIEW;\n\n\t\tif (index_key.type->read)\n\t\t\tperm |= KEY_POS_READ;\n\n\t\tif (index_key.type == &key_type_keyring ||\n\t\t    index_key.type->update)\n\t\t\tperm |= KEY_POS_WRITE;\n\t}\n\n\t/* allocate a new key */\n\tkey = key_alloc(index_key.type, index_key.description,\n\t\t\tcred->fsuid, cred->fsgid, cred, perm, flags, NULL);\n\tif (IS_ERR(key)) {\n\t\tkey_ref = ERR_CAST(key);\n\t\tgoto error_link_end;\n\t}\n\n\t/* instantiate it and link it into the target keyring */\n\tret = __key_instantiate_and_link(key, &prep, keyring, NULL, &edit);\n\tif (ret < 0) {\n\t\tkey_put(key);\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\tkey_ref = make_key_ref(key, is_key_possessed(keyring_ref));\n\nerror_link_end:\n\t__key_link_end(keyring, &index_key, edit);\nerror_free_prep:\n\tif (index_key.type->preparse)\n\t\tindex_key.type->free_preparse(&prep);\nerror_put_type:\n\tkey_type_put(index_key.type);\nerror:\n\treturn key_ref;\n\n found_matching_key:\n\t/* we found a matching key, so we're going to try to update it\n\t * - we can drop the locks first as we have the key pinned\n\t */\n\t__key_link_end(keyring, &index_key, edit);\n\n\tkey_ref = __key_update(key_ref, &prep);\n\tgoto error_free_prep;\n}",
        "code_after_change": "key_ref_t key_create_or_update(key_ref_t keyring_ref,\n\t\t\t       const char *type,\n\t\t\t       const char *description,\n\t\t\t       const void *payload,\n\t\t\t       size_t plen,\n\t\t\t       key_perm_t perm,\n\t\t\t       unsigned long flags)\n{\n\tstruct keyring_index_key index_key = {\n\t\t.description\t= description,\n\t};\n\tstruct key_preparsed_payload prep;\n\tstruct assoc_array_edit *edit;\n\tconst struct cred *cred = current_cred();\n\tstruct key *keyring, *key = NULL;\n\tkey_ref_t key_ref;\n\tint ret;\n\tstruct key_restriction *restrict_link = NULL;\n\n\t/* look up the key type to see if it's one of the registered kernel\n\t * types */\n\tindex_key.type = key_type_lookup(type);\n\tif (IS_ERR(index_key.type)) {\n\t\tkey_ref = ERR_PTR(-ENODEV);\n\t\tgoto error;\n\t}\n\n\tkey_ref = ERR_PTR(-EINVAL);\n\tif (!index_key.type->instantiate ||\n\t    (!index_key.description && !index_key.type->preparse))\n\t\tgoto error_put_type;\n\n\tkeyring = key_ref_to_ptr(keyring_ref);\n\n\tkey_check(keyring);\n\n\tkey_ref = ERR_PTR(-EPERM);\n\tif (!(flags & KEY_ALLOC_BYPASS_RESTRICTION))\n\t\trestrict_link = keyring->restrict_link;\n\n\tkey_ref = ERR_PTR(-ENOTDIR);\n\tif (keyring->type != &key_type_keyring)\n\t\tgoto error_put_type;\n\n\tmemset(&prep, 0, sizeof(prep));\n\tprep.data = payload;\n\tprep.datalen = plen;\n\tprep.quotalen = index_key.type->def_datalen;\n\tprep.expiry = TIME_T_MAX;\n\tif (index_key.type->preparse) {\n\t\tret = index_key.type->preparse(&prep);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_free_prep;\n\t\t}\n\t\tif (!index_key.description)\n\t\t\tindex_key.description = prep.description;\n\t\tkey_ref = ERR_PTR(-EINVAL);\n\t\tif (!index_key.description)\n\t\t\tgoto error_free_prep;\n\t}\n\tindex_key.desc_len = strlen(index_key.description);\n\n\tret = __key_link_begin(keyring, &index_key, &edit);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_free_prep;\n\t}\n\n\tif (restrict_link && restrict_link->check) {\n\t\tret = restrict_link->check(keyring, index_key.type,\n\t\t\t\t\t   &prep.payload, restrict_link->key);\n\t\tif (ret < 0) {\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_link_end;\n\t\t}\n\t}\n\n\t/* if we're going to allocate a new key, we're going to have\n\t * to modify the keyring */\n\tret = key_permission(keyring_ref, KEY_NEED_WRITE);\n\tif (ret < 0) {\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\t/* if it's possible to update this type of key, search for an existing\n\t * key of the same type and description in the destination keyring and\n\t * update that instead if possible\n\t */\n\tif (index_key.type->update) {\n\t\tkey_ref = find_key_to_update(keyring_ref, &index_key);\n\t\tif (key_ref)\n\t\t\tgoto found_matching_key;\n\t}\n\n\t/* if the client doesn't provide, decide on the permissions we want */\n\tif (perm == KEY_PERM_UNDEF) {\n\t\tperm = KEY_POS_VIEW | KEY_POS_SEARCH | KEY_POS_LINK | KEY_POS_SETATTR;\n\t\tperm |= KEY_USR_VIEW;\n\n\t\tif (index_key.type->read)\n\t\t\tperm |= KEY_POS_READ;\n\n\t\tif (index_key.type == &key_type_keyring ||\n\t\t    index_key.type->update)\n\t\t\tperm |= KEY_POS_WRITE;\n\t}\n\n\t/* allocate a new key */\n\tkey = key_alloc(index_key.type, index_key.description,\n\t\t\tcred->fsuid, cred->fsgid, cred, perm, flags, NULL);\n\tif (IS_ERR(key)) {\n\t\tkey_ref = ERR_CAST(key);\n\t\tgoto error_link_end;\n\t}\n\n\t/* instantiate it and link it into the target keyring */\n\tret = __key_instantiate_and_link(key, &prep, keyring, NULL, &edit);\n\tif (ret < 0) {\n\t\tkey_put(key);\n\t\tkey_ref = ERR_PTR(ret);\n\t\tgoto error_link_end;\n\t}\n\n\tkey_ref = make_key_ref(key, is_key_possessed(keyring_ref));\n\nerror_link_end:\n\t__key_link_end(keyring, &index_key, edit);\nerror_free_prep:\n\tif (index_key.type->preparse)\n\t\tindex_key.type->free_preparse(&prep);\nerror_put_type:\n\tkey_type_put(index_key.type);\nerror:\n\treturn key_ref;\n\n found_matching_key:\n\t/* we found a matching key, so we're going to try to update it\n\t * - we can drop the locks first as we have the key pinned\n\t */\n\t__key_link_end(keyring, &index_key, edit);\n\n\tkey = key_ref_to_ptr(key_ref);\n\tif (test_bit(KEY_FLAG_USER_CONSTRUCT, &key->flags)) {\n\t\tret = wait_for_key_construction(key, true);\n\t\tif (ret < 0) {\n\t\t\tkey_ref_put(key_ref);\n\t\t\tkey_ref = ERR_PTR(ret);\n\t\t\tgoto error_free_prep;\n\t\t}\n\t}\n\n\tkey_ref = __key_update(key_ref, &prep);\n\tgoto error_free_prep;\n}",
        "patch": "--- code before\n+++ code after\n@@ -141,6 +141,16 @@\n \t */\n \t__key_link_end(keyring, &index_key, edit);\n \n+\tkey = key_ref_to_ptr(key_ref);\n+\tif (test_bit(KEY_FLAG_USER_CONSTRUCT, &key->flags)) {\n+\t\tret = wait_for_key_construction(key, true);\n+\t\tif (ret < 0) {\n+\t\t\tkey_ref_put(key_ref);\n+\t\t\tkey_ref = ERR_PTR(ret);\n+\t\t\tgoto error_free_prep;\n+\t\t}\n+\t}\n+\n \tkey_ref = __key_update(key_ref, &prep);\n \tgoto error_free_prep;\n }",
        "function_modified_lines": {
            "added": [
                "\tkey = key_ref_to_ptr(key_ref);",
                "\tif (test_bit(KEY_FLAG_USER_CONSTRUCT, &key->flags)) {",
                "\t\tret = wait_for_key_construction(key, true);",
                "\t\tif (ret < 0) {",
                "\t\t\tkey_ref_put(key_ref);",
                "\t\t\tkey_ref = ERR_PTR(ret);",
                "\t\t\tgoto error_free_prep;",
                "\t\t}",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel through 4.13.7 mishandles use of add_key for a key that already exists but is uninstantiated, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a crafted system call.",
        "id": 1304
    },
    {
        "cve_id": "CVE-2020-11668",
        "code_before_change": "static int sd_isoc_nego(struct gspca_dev *gspca_dev)\n{\n\tint ret, packet_size, min_packet_size;\n\tstruct usb_host_interface *alt;\n\n\tswitch (gspca_dev->pixfmt.width) {\n\tcase 160:\n\t\tmin_packet_size = 200;\n\t\tbreak;\n\tcase 176:\n\t\tmin_packet_size = 266;\n\t\tbreak;\n\tdefault:\n\t\tmin_packet_size = 400;\n\t\tbreak;\n\t}\n\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\tif (packet_size <= min_packet_size)\n\t\treturn -EIO;\n\n\tpacket_size -= 100;\n\tif (packet_size < min_packet_size)\n\t\tpacket_size = min_packet_size;\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(packet_size);\n\n\tret = usb_set_interface(gspca_dev->dev, gspca_dev->iface, 1);\n\tif (ret < 0)\n\t\tpr_err(\"set alt 1 err %d\\n\", ret);\n\n\treturn ret;\n}",
        "code_after_change": "static int sd_isoc_nego(struct gspca_dev *gspca_dev)\n{\n\tint ret, packet_size, min_packet_size;\n\tstruct usb_host_interface *alt;\n\n\tswitch (gspca_dev->pixfmt.width) {\n\tcase 160:\n\t\tmin_packet_size = 200;\n\t\tbreak;\n\tcase 176:\n\t\tmin_packet_size = 266;\n\t\tbreak;\n\tdefault:\n\t\tmin_packet_size = 400;\n\t\tbreak;\n\t}\n\n\t/*\n\t * Existence of altsetting and endpoint was verified in sd_isoc_init()\n\t */\n\talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n\tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n\tif (packet_size <= min_packet_size)\n\t\treturn -EIO;\n\n\tpacket_size -= 100;\n\tif (packet_size < min_packet_size)\n\t\tpacket_size = min_packet_size;\n\talt->endpoint[0].desc.wMaxPacketSize = cpu_to_le16(packet_size);\n\n\tret = usb_set_interface(gspca_dev->dev, gspca_dev->iface, 1);\n\tif (ret < 0)\n\t\tpr_err(\"set alt 1 err %d\\n\", ret);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,6 +15,9 @@\n \t\tbreak;\n \t}\n \n+\t/*\n+\t * Existence of altsetting and endpoint was verified in sd_isoc_init()\n+\t */\n \talt = &gspca_dev->dev->actconfig->intf_cache[0]->altsetting[1];\n \tpacket_size = le16_to_cpu(alt->endpoint[0].desc.wMaxPacketSize);\n \tif (packet_size <= min_packet_size)",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * Existence of altsetting and endpoint was verified in sd_isoc_init()",
                "\t */"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.6.1, drivers/media/usb/gspca/xirlink_cit.c (aka the Xirlink camera USB driver) mishandles invalid descriptors, aka CID-a246b4d54770.",
        "id": 2435
    },
    {
        "cve_id": "CVE-2018-14609",
        "code_before_change": "static void __del_reloc_root(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *rb_node;\n\tstruct mapping_node *node = NULL;\n\tstruct reloc_control *rc = fs_info->reloc_ctl;\n\n\tspin_lock(&rc->reloc_root_tree.lock);\n\trb_node = tree_search(&rc->reloc_root_tree.rb_root,\n\t\t\t      root->node->start);\n\tif (rb_node) {\n\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);\n\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\n\t}\n\tspin_unlock(&rc->reloc_root_tree.lock);\n\n\tif (!node)\n\t\treturn;\n\tBUG_ON((struct btrfs_root *)node->data != root);\n\n\tspin_lock(&fs_info->trans_lock);\n\tlist_del_init(&root->root_list);\n\tspin_unlock(&fs_info->trans_lock);\n\tkfree(node);\n}",
        "code_after_change": "static void __del_reloc_root(struct btrfs_root *root)\n{\n\tstruct btrfs_fs_info *fs_info = root->fs_info;\n\tstruct rb_node *rb_node;\n\tstruct mapping_node *node = NULL;\n\tstruct reloc_control *rc = fs_info->reloc_ctl;\n\n\tif (rc) {\n\t\tspin_lock(&rc->reloc_root_tree.lock);\n\t\trb_node = tree_search(&rc->reloc_root_tree.rb_root,\n\t\t\t\t      root->node->start);\n\t\tif (rb_node) {\n\t\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);\n\t\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\n\t\t}\n\t\tspin_unlock(&rc->reloc_root_tree.lock);\n\t\tif (!node)\n\t\t\treturn;\n\t\tBUG_ON((struct btrfs_root *)node->data != root);\n\t}\n\n\tspin_lock(&fs_info->trans_lock);\n\tlist_del_init(&root->root_list);\n\tspin_unlock(&fs_info->trans_lock);\n\tkfree(node);\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,18 +5,19 @@\n \tstruct mapping_node *node = NULL;\n \tstruct reloc_control *rc = fs_info->reloc_ctl;\n \n-\tspin_lock(&rc->reloc_root_tree.lock);\n-\trb_node = tree_search(&rc->reloc_root_tree.rb_root,\n-\t\t\t      root->node->start);\n-\tif (rb_node) {\n-\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);\n-\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\n+\tif (rc) {\n+\t\tspin_lock(&rc->reloc_root_tree.lock);\n+\t\trb_node = tree_search(&rc->reloc_root_tree.rb_root,\n+\t\t\t\t      root->node->start);\n+\t\tif (rb_node) {\n+\t\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);\n+\t\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\n+\t\t}\n+\t\tspin_unlock(&rc->reloc_root_tree.lock);\n+\t\tif (!node)\n+\t\t\treturn;\n+\t\tBUG_ON((struct btrfs_root *)node->data != root);\n \t}\n-\tspin_unlock(&rc->reloc_root_tree.lock);\n-\n-\tif (!node)\n-\t\treturn;\n-\tBUG_ON((struct btrfs_root *)node->data != root);\n \n \tspin_lock(&fs_info->trans_lock);\n \tlist_del_init(&root->root_list);",
        "function_modified_lines": {
            "added": [
                "\tif (rc) {",
                "\t\tspin_lock(&rc->reloc_root_tree.lock);",
                "\t\trb_node = tree_search(&rc->reloc_root_tree.rb_root,",
                "\t\t\t\t      root->node->start);",
                "\t\tif (rb_node) {",
                "\t\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);",
                "\t\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);",
                "\t\t}",
                "\t\tspin_unlock(&rc->reloc_root_tree.lock);",
                "\t\tif (!node)",
                "\t\t\treturn;",
                "\t\tBUG_ON((struct btrfs_root *)node->data != root);"
            ],
            "deleted": [
                "\tspin_lock(&rc->reloc_root_tree.lock);",
                "\trb_node = tree_search(&rc->reloc_root_tree.rb_root,",
                "\t\t\t      root->node->start);",
                "\tif (rb_node) {",
                "\t\tnode = rb_entry(rb_node, struct mapping_node, rb_node);",
                "\t\trb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);",
                "\tspin_unlock(&rc->reloc_root_tree.lock);",
                "",
                "\tif (!node)",
                "\t\treturn;",
                "\tBUG_ON((struct btrfs_root *)node->data != root);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is an invalid pointer dereference in __del_reloc_root() in fs/btrfs/relocation.c when mounting a crafted btrfs image, related to removing reloc rb_trees when reloc control has not been initialized.",
        "id": 1678
    },
    {
        "cve_id": "CVE-2020-27675",
        "code_before_change": "evtchn_port_t evtchn_from_irq(unsigned irq)\n{\n\tif (WARN(irq >= nr_irqs, \"Invalid irq %d!\\n\", irq))\n\t\treturn 0;\n\n\treturn info_for_irq(irq)->evtchn;\n}",
        "code_after_change": "evtchn_port_t evtchn_from_irq(unsigned irq)\n{\n\tconst struct irq_info *info = NULL;\n\n\tif (likely(irq < nr_irqs))\n\t\tinfo = info_for_irq(irq);\n\tif (!info)\n\t\treturn 0;\n\n\treturn info->evtchn;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,11 @@\n evtchn_port_t evtchn_from_irq(unsigned irq)\n {\n-\tif (WARN(irq >= nr_irqs, \"Invalid irq %d!\\n\", irq))\n+\tconst struct irq_info *info = NULL;\n+\n+\tif (likely(irq < nr_irqs))\n+\t\tinfo = info_for_irq(irq);\n+\tif (!info)\n \t\treturn 0;\n \n-\treturn info_for_irq(irq)->evtchn;\n+\treturn info->evtchn;\n }",
        "function_modified_lines": {
            "added": [
                "\tconst struct irq_info *info = NULL;",
                "",
                "\tif (likely(irq < nr_irqs))",
                "\t\tinfo = info_for_irq(irq);",
                "\tif (!info)",
                "\treturn info->evtchn;"
            ],
            "deleted": [
                "\tif (WARN(irq >= nr_irqs, \"Invalid irq %d!\\n\", irq))",
                "\treturn info_for_irq(irq)->evtchn;"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. drivers/xen/events/events_base.c allows event-channel removal during the event-handling loop (a race condition). This can cause a use-after-free or NULL pointer dereference, as demonstrated by a dom0 crash via events for an in-reconfiguration paravirtualized device, aka CID-073d0552ead5.",
        "id": 2626
    },
    {
        "cve_id": "CVE-2019-15223",
        "code_before_change": "static void line6_toneport_disconnect(struct usb_line6 *line6)\n{\n\tstruct usb_line6_toneport *toneport =\n\t\t(struct usb_line6_toneport *)line6;\n\n\tcancel_delayed_work_sync(&toneport->pcm_work);\n\n\tif (toneport_has_led(toneport))\n\t\ttoneport_remove_leds(toneport);\n}",
        "code_after_change": "static void line6_toneport_disconnect(struct usb_line6 *line6)\n{\n\tstruct usb_line6_toneport *toneport =\n\t\t(struct usb_line6_toneport *)line6;\n\n\tif (toneport_has_led(toneport))\n\t\ttoneport_remove_leds(toneport);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,8 +3,6 @@\n \tstruct usb_line6_toneport *toneport =\n \t\t(struct usb_line6_toneport *)line6;\n \n-\tcancel_delayed_work_sync(&toneport->pcm_work);\n-\n \tif (toneport_has_led(toneport))\n \t\ttoneport_remove_leds(toneport);\n }",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tcancel_delayed_work_sync(&toneport->pcm_work);",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.1.8. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/line6/driver.c driver.",
        "id": 2010
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int stk7700ph_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct usb_device_descriptor *desc = &adap->dev->udev->descriptor;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (desc->idVendor  == cpu_to_le16(USB_VID_PINNACLE) &&\n\t    desc->idProduct == cpu_to_le16(USB_PID_PINNACLE_EXPRESSCARD_320CX))\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 0);\n\telse\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\tmsleep(10);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t     &stk7700ph_dib7700_xc3028_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80,\n\t\t&stk7700ph_dib7700_xc3028_config);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int stk7700ph_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct usb_device_descriptor *desc = &adap->dev->udev->descriptor;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (desc->idVendor  == cpu_to_le16(USB_VID_PINNACLE) &&\n\t    desc->idProduct == cpu_to_le16(USB_PID_PINNACLE_EXPRESSCARD_320CX))\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 0);\n\telse\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\tmsleep(10);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t     &stk7700ph_dib7700_xc3028_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80,\n\t\t&stk7700ph_dib7700_xc3028_config);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -26,7 +26,7 @@\n \t\t\t\t     &stk7700ph_dib7700_xc3028_config) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n \t\t    __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1332
    },
    {
        "cve_id": "CVE-2018-1066",
        "code_before_change": "static int\nSMB2_sess_establish_session(struct SMB2_sess_data *sess_data)\n{\n\tint rc = 0;\n\tstruct cifs_ses *ses = sess_data->ses;\n\n\tmutex_lock(&ses->server->srv_mutex);\n\tif (ses->server->sign && ses->server->ops->generate_signingkey) {\n\t\trc = ses->server->ops->generate_signingkey(ses);\n\t\tkfree(ses->auth_key.response);\n\t\tses->auth_key.response = NULL;\n\t\tif (rc) {\n\t\t\tcifs_dbg(FYI,\n\t\t\t\t\"SMB3 session key generation failed\\n\");\n\t\t\tmutex_unlock(&ses->server->srv_mutex);\n\t\t\tgoto keygen_exit;\n\t\t}\n\t}\n\tif (!ses->server->session_estab) {\n\t\tses->server->sequence_number = 0x2;\n\t\tses->server->session_estab = true;\n\t}\n\tmutex_unlock(&ses->server->srv_mutex);\n\n\tcifs_dbg(FYI, \"SMB2/3 session established successfully\\n\");\n\tspin_lock(&GlobalMid_Lock);\n\tses->status = CifsGood;\n\tses->need_reconnect = false;\n\tspin_unlock(&GlobalMid_Lock);\n\nkeygen_exit:\n\tif (!ses->server->sign) {\n\t\tkfree(ses->auth_key.response);\n\t\tses->auth_key.response = NULL;\n\t}\n\treturn rc;\n}",
        "code_after_change": "static int\nSMB2_sess_establish_session(struct SMB2_sess_data *sess_data)\n{\n\tint rc = 0;\n\tstruct cifs_ses *ses = sess_data->ses;\n\n\tmutex_lock(&ses->server->srv_mutex);\n\tif (ses->server->ops->generate_signingkey) {\n\t\trc = ses->server->ops->generate_signingkey(ses);\n\t\tif (rc) {\n\t\t\tcifs_dbg(FYI,\n\t\t\t\t\"SMB3 session key generation failed\\n\");\n\t\t\tmutex_unlock(&ses->server->srv_mutex);\n\t\t\treturn rc;\n\t\t}\n\t}\n\tif (!ses->server->session_estab) {\n\t\tses->server->sequence_number = 0x2;\n\t\tses->server->session_estab = true;\n\t}\n\tmutex_unlock(&ses->server->srv_mutex);\n\n\tcifs_dbg(FYI, \"SMB2/3 session established successfully\\n\");\n\tspin_lock(&GlobalMid_Lock);\n\tses->status = CifsGood;\n\tses->need_reconnect = false;\n\tspin_unlock(&GlobalMid_Lock);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,15 +5,13 @@\n \tstruct cifs_ses *ses = sess_data->ses;\n \n \tmutex_lock(&ses->server->srv_mutex);\n-\tif (ses->server->sign && ses->server->ops->generate_signingkey) {\n+\tif (ses->server->ops->generate_signingkey) {\n \t\trc = ses->server->ops->generate_signingkey(ses);\n-\t\tkfree(ses->auth_key.response);\n-\t\tses->auth_key.response = NULL;\n \t\tif (rc) {\n \t\t\tcifs_dbg(FYI,\n \t\t\t\t\"SMB3 session key generation failed\\n\");\n \t\t\tmutex_unlock(&ses->server->srv_mutex);\n-\t\t\tgoto keygen_exit;\n+\t\t\treturn rc;\n \t\t}\n \t}\n \tif (!ses->server->session_estab) {\n@@ -27,11 +25,5 @@\n \tses->status = CifsGood;\n \tses->need_reconnect = false;\n \tspin_unlock(&GlobalMid_Lock);\n-\n-keygen_exit:\n-\tif (!ses->server->sign) {\n-\t\tkfree(ses->auth_key.response);\n-\t\tses->auth_key.response = NULL;\n-\t}\n \treturn rc;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (ses->server->ops->generate_signingkey) {",
                "\t\t\treturn rc;"
            ],
            "deleted": [
                "\tif (ses->server->sign && ses->server->ops->generate_signingkey) {",
                "\t\tkfree(ses->auth_key.response);",
                "\t\tses->auth_key.response = NULL;",
                "\t\t\tgoto keygen_exit;",
                "",
                "keygen_exit:",
                "\tif (!ses->server->sign) {",
                "\t\tkfree(ses->auth_key.response);",
                "\t\tses->auth_key.response = NULL;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux kernel before version 4.11 is vulnerable to a NULL pointer dereference in fs/cifs/cifsencrypt.c:setup_ntlmv2_rsp() that allows an attacker controlling a CIFS server to kernel panic a client that has this server mounted, because an empty TargetInfo field in an NTLMSSP setup negotiation response is mishandled during session recovery.",
        "id": 1592
    },
    {
        "cve_id": "CVE-2021-38206",
        "code_before_change": "bool ieee80211_parse_tx_radiotap(struct sk_buff *skb,\n\t\t\t\t struct net_device *dev)\n{\n\tstruct ieee80211_local *local = wdev_priv(dev->ieee80211_ptr);\n\tstruct ieee80211_radiotap_iterator iterator;\n\tstruct ieee80211_radiotap_header *rthdr =\n\t\t(struct ieee80211_radiotap_header *) skb->data;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ieee80211_supported_band *sband =\n\t\tlocal->hw.wiphy->bands[info->band];\n\tint ret = ieee80211_radiotap_iterator_init(&iterator, rthdr, skb->len,\n\t\t\t\t\t\t   NULL);\n\tu16 txflags;\n\tu16 rate = 0;\n\tbool rate_found = false;\n\tu8 rate_retries = 0;\n\tu16 rate_flags = 0;\n\tu8 mcs_known, mcs_flags, mcs_bw;\n\tu16 vht_known;\n\tu8 vht_mcs = 0, vht_nss = 0;\n\tint i;\n\n\t/* check for not even having the fixed radiotap header part */\n\tif (unlikely(skb->len < sizeof(struct ieee80211_radiotap_header)))\n\t\treturn false; /* too short to be possibly valid */\n\n\t/* is it a header version we can trust to find length from? */\n\tif (unlikely(rthdr->it_version))\n\t\treturn false; /* only version 0 is supported */\n\n\t/* does the skb contain enough to deliver on the alleged length? */\n\tif (unlikely(skb->len < ieee80211_get_radiotap_len(skb->data)))\n\t\treturn false; /* skb too short for claimed rt header extent */\n\n\tinfo->flags |= IEEE80211_TX_INTFL_DONT_ENCRYPT |\n\t\t       IEEE80211_TX_CTL_DONTFRAG;\n\n\t/*\n\t * for every radiotap entry that is present\n\t * (ieee80211_radiotap_iterator_next returns -ENOENT when no more\n\t * entries present, or -EINVAL on error)\n\t */\n\n\twhile (!ret) {\n\t\tret = ieee80211_radiotap_iterator_next(&iterator);\n\n\t\tif (ret)\n\t\t\tcontinue;\n\n\t\t/* see if this argument is something we can use */\n\t\tswitch (iterator.this_arg_index) {\n\t\t/*\n\t\t * You must take care when dereferencing iterator.this_arg\n\t\t * for multibyte types... the pointer is not aligned.  Use\n\t\t * get_unaligned((type *)iterator.this_arg) to dereference\n\t\t * iterator.this_arg for type \"type\" safely on all arches.\n\t\t*/\n\t\tcase IEEE80211_RADIOTAP_FLAGS:\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_FCS) {\n\t\t\t\t/*\n\t\t\t\t * this indicates that the skb we have been\n\t\t\t\t * handed has the 32-bit FCS CRC at the end...\n\t\t\t\t * we should react to that by snipping it off\n\t\t\t\t * because it will be recomputed and added\n\t\t\t\t * on transmission\n\t\t\t\t */\n\t\t\t\tif (skb->len < (iterator._max_length + FCS_LEN))\n\t\t\t\t\treturn false;\n\n\t\t\t\tskb_trim(skb, skb->len - FCS_LEN);\n\t\t\t}\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_WEP)\n\t\t\t\tinfo->flags &= ~IEEE80211_TX_INTFL_DONT_ENCRYPT;\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_FRAG)\n\t\t\t\tinfo->flags &= ~IEEE80211_TX_CTL_DONTFRAG;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_TX_FLAGS:\n\t\t\ttxflags = get_unaligned_le16(iterator.this_arg);\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_NOACK)\n\t\t\t\tinfo->flags |= IEEE80211_TX_CTL_NO_ACK;\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_NOSEQNO)\n\t\t\t\tinfo->control.flags |= IEEE80211_TX_CTRL_NO_SEQNO;\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_ORDER)\n\t\t\t\tinfo->control.flags |=\n\t\t\t\t\tIEEE80211_TX_CTRL_DONT_REORDER;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_RATE:\n\t\t\trate = *iterator.this_arg;\n\t\t\trate_flags = 0;\n\t\t\trate_found = true;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_DATA_RETRIES:\n\t\t\trate_retries = *iterator.this_arg;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_MCS:\n\t\t\tmcs_known = iterator.this_arg[0];\n\t\t\tmcs_flags = iterator.this_arg[1];\n\t\t\tif (!(mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_MCS))\n\t\t\t\tbreak;\n\n\t\t\trate_found = true;\n\t\t\trate = iterator.this_arg[2];\n\t\t\trate_flags = IEEE80211_TX_RC_MCS;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_GI &&\n\t\t\t    mcs_flags & IEEE80211_RADIOTAP_MCS_SGI)\n\t\t\t\trate_flags |= IEEE80211_TX_RC_SHORT_GI;\n\n\t\t\tmcs_bw = mcs_flags & IEEE80211_RADIOTAP_MCS_BW_MASK;\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_BW &&\n\t\t\t    mcs_bw == IEEE80211_RADIOTAP_MCS_BW_40)\n\t\t\t\trate_flags |= IEEE80211_TX_RC_40_MHZ_WIDTH;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_FEC &&\n\t\t\t    mcs_flags & IEEE80211_RADIOTAP_MCS_FEC_LDPC)\n\t\t\t\tinfo->flags |= IEEE80211_TX_CTL_LDPC;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_STBC) {\n\t\t\t\tu8 stbc = u8_get_bits(mcs_flags,\n\t\t\t\t\t\t      IEEE80211_RADIOTAP_MCS_STBC_MASK);\n\n\t\t\t\tinfo->flags |=\n\t\t\t\t\tu32_encode_bits(stbc,\n\t\t\t\t\t\t\tIEEE80211_TX_CTL_STBC);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_VHT:\n\t\t\tvht_known = get_unaligned_le16(iterator.this_arg);\n\t\t\trate_found = true;\n\n\t\t\trate_flags = IEEE80211_TX_RC_VHT_MCS;\n\t\t\tif ((vht_known & IEEE80211_RADIOTAP_VHT_KNOWN_GI) &&\n\t\t\t    (iterator.this_arg[2] &\n\t\t\t     IEEE80211_RADIOTAP_VHT_FLAG_SGI))\n\t\t\t\trate_flags |= IEEE80211_TX_RC_SHORT_GI;\n\t\t\tif (vht_known &\n\t\t\t    IEEE80211_RADIOTAP_VHT_KNOWN_BANDWIDTH) {\n\t\t\t\tif (iterator.this_arg[3] == 1)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_40_MHZ_WIDTH;\n\t\t\t\telse if (iterator.this_arg[3] == 4)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_80_MHZ_WIDTH;\n\t\t\t\telse if (iterator.this_arg[3] == 11)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_160_MHZ_WIDTH;\n\t\t\t}\n\n\t\t\tvht_mcs = iterator.this_arg[4] >> 4;\n\t\t\tvht_nss = iterator.this_arg[4] & 0xF;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Please update the file\n\t\t * Documentation/networking/mac80211-injection.rst\n\t\t * when parsing new fields here.\n\t\t */\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret != -ENOENT) /* ie, if we didn't simply run out of fields */\n\t\treturn false;\n\n\tif (rate_found) {\n\t\tinfo->control.flags |= IEEE80211_TX_CTRL_RATE_INJECT;\n\n\t\tfor (i = 0; i < IEEE80211_TX_MAX_RATES; i++) {\n\t\t\tinfo->control.rates[i].idx = -1;\n\t\t\tinfo->control.rates[i].flags = 0;\n\t\t\tinfo->control.rates[i].count = 0;\n\t\t}\n\n\t\tif (rate_flags & IEEE80211_TX_RC_MCS) {\n\t\t\tinfo->control.rates[0].idx = rate;\n\t\t} else if (rate_flags & IEEE80211_TX_RC_VHT_MCS) {\n\t\t\tieee80211_rate_set_vht(info->control.rates, vht_mcs,\n\t\t\t\t\t       vht_nss);\n\t\t} else {\n\t\t\tfor (i = 0; i < sband->n_bitrates; i++) {\n\t\t\t\tif (rate * 5 != sband->bitrates[i].bitrate)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tinfo->control.rates[0].idx = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (info->control.rates[0].idx < 0)\n\t\t\tinfo->control.flags &= ~IEEE80211_TX_CTRL_RATE_INJECT;\n\n\t\tinfo->control.rates[0].flags = rate_flags;\n\t\tinfo->control.rates[0].count = min_t(u8, rate_retries + 1,\n\t\t\t\t\t\t     local->hw.max_rate_tries);\n\t}\n\n\treturn true;\n}",
        "code_after_change": "bool ieee80211_parse_tx_radiotap(struct sk_buff *skb,\n\t\t\t\t struct net_device *dev)\n{\n\tstruct ieee80211_local *local = wdev_priv(dev->ieee80211_ptr);\n\tstruct ieee80211_radiotap_iterator iterator;\n\tstruct ieee80211_radiotap_header *rthdr =\n\t\t(struct ieee80211_radiotap_header *) skb->data;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tint ret = ieee80211_radiotap_iterator_init(&iterator, rthdr, skb->len,\n\t\t\t\t\t\t   NULL);\n\tu16 txflags;\n\tu16 rate = 0;\n\tbool rate_found = false;\n\tu8 rate_retries = 0;\n\tu16 rate_flags = 0;\n\tu8 mcs_known, mcs_flags, mcs_bw;\n\tu16 vht_known;\n\tu8 vht_mcs = 0, vht_nss = 0;\n\tint i;\n\n\tif (!ieee80211_validate_radiotap_len(skb))\n\t\treturn false;\n\n\tinfo->flags |= IEEE80211_TX_INTFL_DONT_ENCRYPT |\n\t\t       IEEE80211_TX_CTL_DONTFRAG;\n\n\t/*\n\t * for every radiotap entry that is present\n\t * (ieee80211_radiotap_iterator_next returns -ENOENT when no more\n\t * entries present, or -EINVAL on error)\n\t */\n\n\twhile (!ret) {\n\t\tret = ieee80211_radiotap_iterator_next(&iterator);\n\n\t\tif (ret)\n\t\t\tcontinue;\n\n\t\t/* see if this argument is something we can use */\n\t\tswitch (iterator.this_arg_index) {\n\t\t/*\n\t\t * You must take care when dereferencing iterator.this_arg\n\t\t * for multibyte types... the pointer is not aligned.  Use\n\t\t * get_unaligned((type *)iterator.this_arg) to dereference\n\t\t * iterator.this_arg for type \"type\" safely on all arches.\n\t\t*/\n\t\tcase IEEE80211_RADIOTAP_FLAGS:\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_FCS) {\n\t\t\t\t/*\n\t\t\t\t * this indicates that the skb we have been\n\t\t\t\t * handed has the 32-bit FCS CRC at the end...\n\t\t\t\t * we should react to that by snipping it off\n\t\t\t\t * because it will be recomputed and added\n\t\t\t\t * on transmission\n\t\t\t\t */\n\t\t\t\tif (skb->len < (iterator._max_length + FCS_LEN))\n\t\t\t\t\treturn false;\n\n\t\t\t\tskb_trim(skb, skb->len - FCS_LEN);\n\t\t\t}\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_WEP)\n\t\t\t\tinfo->flags &= ~IEEE80211_TX_INTFL_DONT_ENCRYPT;\n\t\t\tif (*iterator.this_arg & IEEE80211_RADIOTAP_F_FRAG)\n\t\t\t\tinfo->flags &= ~IEEE80211_TX_CTL_DONTFRAG;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_TX_FLAGS:\n\t\t\ttxflags = get_unaligned_le16(iterator.this_arg);\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_NOACK)\n\t\t\t\tinfo->flags |= IEEE80211_TX_CTL_NO_ACK;\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_NOSEQNO)\n\t\t\t\tinfo->control.flags |= IEEE80211_TX_CTRL_NO_SEQNO;\n\t\t\tif (txflags & IEEE80211_RADIOTAP_F_TX_ORDER)\n\t\t\t\tinfo->control.flags |=\n\t\t\t\t\tIEEE80211_TX_CTRL_DONT_REORDER;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_RATE:\n\t\t\trate = *iterator.this_arg;\n\t\t\trate_flags = 0;\n\t\t\trate_found = true;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_DATA_RETRIES:\n\t\t\trate_retries = *iterator.this_arg;\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_MCS:\n\t\t\tmcs_known = iterator.this_arg[0];\n\t\t\tmcs_flags = iterator.this_arg[1];\n\t\t\tif (!(mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_MCS))\n\t\t\t\tbreak;\n\n\t\t\trate_found = true;\n\t\t\trate = iterator.this_arg[2];\n\t\t\trate_flags = IEEE80211_TX_RC_MCS;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_GI &&\n\t\t\t    mcs_flags & IEEE80211_RADIOTAP_MCS_SGI)\n\t\t\t\trate_flags |= IEEE80211_TX_RC_SHORT_GI;\n\n\t\t\tmcs_bw = mcs_flags & IEEE80211_RADIOTAP_MCS_BW_MASK;\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_BW &&\n\t\t\t    mcs_bw == IEEE80211_RADIOTAP_MCS_BW_40)\n\t\t\t\trate_flags |= IEEE80211_TX_RC_40_MHZ_WIDTH;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_FEC &&\n\t\t\t    mcs_flags & IEEE80211_RADIOTAP_MCS_FEC_LDPC)\n\t\t\t\tinfo->flags |= IEEE80211_TX_CTL_LDPC;\n\n\t\t\tif (mcs_known & IEEE80211_RADIOTAP_MCS_HAVE_STBC) {\n\t\t\t\tu8 stbc = u8_get_bits(mcs_flags,\n\t\t\t\t\t\t      IEEE80211_RADIOTAP_MCS_STBC_MASK);\n\n\t\t\t\tinfo->flags |=\n\t\t\t\t\tu32_encode_bits(stbc,\n\t\t\t\t\t\t\tIEEE80211_TX_CTL_STBC);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IEEE80211_RADIOTAP_VHT:\n\t\t\tvht_known = get_unaligned_le16(iterator.this_arg);\n\t\t\trate_found = true;\n\n\t\t\trate_flags = IEEE80211_TX_RC_VHT_MCS;\n\t\t\tif ((vht_known & IEEE80211_RADIOTAP_VHT_KNOWN_GI) &&\n\t\t\t    (iterator.this_arg[2] &\n\t\t\t     IEEE80211_RADIOTAP_VHT_FLAG_SGI))\n\t\t\t\trate_flags |= IEEE80211_TX_RC_SHORT_GI;\n\t\t\tif (vht_known &\n\t\t\t    IEEE80211_RADIOTAP_VHT_KNOWN_BANDWIDTH) {\n\t\t\t\tif (iterator.this_arg[3] == 1)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_40_MHZ_WIDTH;\n\t\t\t\telse if (iterator.this_arg[3] == 4)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_80_MHZ_WIDTH;\n\t\t\t\telse if (iterator.this_arg[3] == 11)\n\t\t\t\t\trate_flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_160_MHZ_WIDTH;\n\t\t\t}\n\n\t\t\tvht_mcs = iterator.this_arg[4] >> 4;\n\t\t\tvht_nss = iterator.this_arg[4] & 0xF;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Please update the file\n\t\t * Documentation/networking/mac80211-injection.rst\n\t\t * when parsing new fields here.\n\t\t */\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret != -ENOENT) /* ie, if we didn't simply run out of fields */\n\t\treturn false;\n\n\tif (rate_found) {\n\t\tstruct ieee80211_supported_band *sband =\n\t\t\tlocal->hw.wiphy->bands[info->band];\n\n\t\tinfo->control.flags |= IEEE80211_TX_CTRL_RATE_INJECT;\n\n\t\tfor (i = 0; i < IEEE80211_TX_MAX_RATES; i++) {\n\t\t\tinfo->control.rates[i].idx = -1;\n\t\t\tinfo->control.rates[i].flags = 0;\n\t\t\tinfo->control.rates[i].count = 0;\n\t\t}\n\n\t\tif (rate_flags & IEEE80211_TX_RC_MCS) {\n\t\t\tinfo->control.rates[0].idx = rate;\n\t\t} else if (rate_flags & IEEE80211_TX_RC_VHT_MCS) {\n\t\t\tieee80211_rate_set_vht(info->control.rates, vht_mcs,\n\t\t\t\t\t       vht_nss);\n\t\t} else if (sband) {\n\t\t\tfor (i = 0; i < sband->n_bitrates; i++) {\n\t\t\t\tif (rate * 5 != sband->bitrates[i].bitrate)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tinfo->control.rates[0].idx = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (info->control.rates[0].idx < 0)\n\t\t\tinfo->control.flags &= ~IEEE80211_TX_CTRL_RATE_INJECT;\n\n\t\tinfo->control.rates[0].flags = rate_flags;\n\t\tinfo->control.rates[0].count = min_t(u8, rate_retries + 1,\n\t\t\t\t\t\t     local->hw.max_rate_tries);\n\t}\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,8 +6,6 @@\n \tstruct ieee80211_radiotap_header *rthdr =\n \t\t(struct ieee80211_radiotap_header *) skb->data;\n \tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n-\tstruct ieee80211_supported_band *sband =\n-\t\tlocal->hw.wiphy->bands[info->band];\n \tint ret = ieee80211_radiotap_iterator_init(&iterator, rthdr, skb->len,\n \t\t\t\t\t\t   NULL);\n \tu16 txflags;\n@@ -20,17 +18,8 @@\n \tu8 vht_mcs = 0, vht_nss = 0;\n \tint i;\n \n-\t/* check for not even having the fixed radiotap header part */\n-\tif (unlikely(skb->len < sizeof(struct ieee80211_radiotap_header)))\n-\t\treturn false; /* too short to be possibly valid */\n-\n-\t/* is it a header version we can trust to find length from? */\n-\tif (unlikely(rthdr->it_version))\n-\t\treturn false; /* only version 0 is supported */\n-\n-\t/* does the skb contain enough to deliver on the alleged length? */\n-\tif (unlikely(skb->len < ieee80211_get_radiotap_len(skb->data)))\n-\t\treturn false; /* skb too short for claimed rt header extent */\n+\tif (!ieee80211_validate_radiotap_len(skb))\n+\t\treturn false;\n \n \tinfo->flags |= IEEE80211_TX_INTFL_DONT_ENCRYPT |\n \t\t       IEEE80211_TX_CTL_DONTFRAG;\n@@ -170,6 +159,9 @@\n \t\treturn false;\n \n \tif (rate_found) {\n+\t\tstruct ieee80211_supported_band *sband =\n+\t\t\tlocal->hw.wiphy->bands[info->band];\n+\n \t\tinfo->control.flags |= IEEE80211_TX_CTRL_RATE_INJECT;\n \n \t\tfor (i = 0; i < IEEE80211_TX_MAX_RATES; i++) {\n@@ -183,7 +175,7 @@\n \t\t} else if (rate_flags & IEEE80211_TX_RC_VHT_MCS) {\n \t\t\tieee80211_rate_set_vht(info->control.rates, vht_mcs,\n \t\t\t\t\t       vht_nss);\n-\t\t} else {\n+\t\t} else if (sband) {\n \t\t\tfor (i = 0; i < sband->n_bitrates; i++) {\n \t\t\t\tif (rate * 5 != sband->bitrates[i].bitrate)\n \t\t\t\t\tcontinue;",
        "function_modified_lines": {
            "added": [
                "\tif (!ieee80211_validate_radiotap_len(skb))",
                "\t\treturn false;",
                "\t\tstruct ieee80211_supported_band *sband =",
                "\t\t\tlocal->hw.wiphy->bands[info->band];",
                "",
                "\t\t} else if (sband) {"
            ],
            "deleted": [
                "\tstruct ieee80211_supported_band *sband =",
                "\t\tlocal->hw.wiphy->bands[info->band];",
                "\t/* check for not even having the fixed radiotap header part */",
                "\tif (unlikely(skb->len < sizeof(struct ieee80211_radiotap_header)))",
                "\t\treturn false; /* too short to be possibly valid */",
                "",
                "\t/* is it a header version we can trust to find length from? */",
                "\tif (unlikely(rthdr->it_version))",
                "\t\treturn false; /* only version 0 is supported */",
                "",
                "\t/* does the skb contain enough to deliver on the alleged length? */",
                "\tif (unlikely(skb->len < ieee80211_get_radiotap_len(skb->data)))",
                "\t\treturn false; /* skb too short for claimed rt header extent */",
                "\t\t} else {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The mac80211 subsystem in the Linux kernel before 5.12.13, when a device supporting only 5 GHz is used, allows attackers to cause a denial of service (NULL pointer dereference in the radiotap parser) by injecting a frame with 802.11a rates.",
        "id": 3082
    },
    {
        "cve_id": "CVE-2023-1583",
        "code_before_change": "void __io_sqe_files_unregister(struct io_ring_ctx *ctx)\n{\n\tint i;\n\n\tfor (i = 0; i < ctx->nr_user_files; i++) {\n\t\tstruct file *file = io_file_from_index(&ctx->file_table, i);\n\n\t\t/* skip scm accounted files, they'll be freed by ->ring_sock */\n\t\tif (!file || io_file_need_scm(file))\n\t\t\tcontinue;\n\t\tio_file_bitmap_clear(&ctx->file_table, i);\n\t\tfput(file);\n\t}\n\n#if defined(CONFIG_UNIX)\n\tif (ctx->ring_sock) {\n\t\tstruct sock *sock = ctx->ring_sock->sk;\n\t\tstruct sk_buff *skb;\n\n\t\twhile ((skb = skb_dequeue(&sock->sk_receive_queue)) != NULL)\n\t\t\tkfree_skb(skb);\n\t}\n#endif\n\tio_free_file_tables(&ctx->file_table);\n\tio_rsrc_data_free(ctx->file_data);\n\tctx->file_data = NULL;\n\tctx->nr_user_files = 0;\n}",
        "code_after_change": "void __io_sqe_files_unregister(struct io_ring_ctx *ctx)\n{\n\tint i;\n\n\tfor (i = 0; i < ctx->nr_user_files; i++) {\n\t\tstruct file *file = io_file_from_index(&ctx->file_table, i);\n\n\t\t/* skip scm accounted files, they'll be freed by ->ring_sock */\n\t\tif (!file || io_file_need_scm(file))\n\t\t\tcontinue;\n\t\tio_file_bitmap_clear(&ctx->file_table, i);\n\t\tfput(file);\n\t}\n\n#if defined(CONFIG_UNIX)\n\tif (ctx->ring_sock) {\n\t\tstruct sock *sock = ctx->ring_sock->sk;\n\t\tstruct sk_buff *skb;\n\n\t\twhile ((skb = skb_dequeue(&sock->sk_receive_queue)) != NULL)\n\t\t\tkfree_skb(skb);\n\t}\n#endif\n\tio_free_file_tables(&ctx->file_table);\n\tio_file_table_set_alloc_range(ctx, 0, 0);\n\tio_rsrc_data_free(ctx->file_data);\n\tctx->file_data = NULL;\n\tctx->nr_user_files = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,6 +22,7 @@\n \t}\n #endif\n \tio_free_file_tables(&ctx->file_table);\n+\tio_file_table_set_alloc_range(ctx, 0, 0);\n \tio_rsrc_data_free(ctx->file_data);\n \tctx->file_data = NULL;\n \tctx->nr_user_files = 0;",
        "function_modified_lines": {
            "added": [
                "\tio_file_table_set_alloc_range(ctx, 0, 0);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference was found in io_file_bitmap_get in io_uring/filetable.c in the io_uring sub-component in the Linux Kernel. When fixed files are unregistered, some context information (file_alloc_{start,end} and alloc_hint) is not cleared. A subsequent request that has auto index selection enabled via IORING_FILE_INDEX_ALLOC can cause a NULL pointer dereference. An unprivileged user can use the flaw to cause a system crash.",
        "id": 3873
    },
    {
        "cve_id": "CVE-2019-16229",
        "code_before_change": "int kfd_interrupt_init(struct kfd_dev *kfd)\n{\n\tint r;\n\n\tr = kfifo_alloc(&kfd->ih_fifo,\n\t\tKFD_IH_NUM_ENTRIES * kfd->device_info->ih_ring_entry_size,\n\t\tGFP_KERNEL);\n\tif (r) {\n\t\tdev_err(kfd_chardev(), \"Failed to allocate IH fifo\\n\");\n\t\treturn r;\n\t}\n\n\tkfd->ih_wq = alloc_workqueue(\"KFD IH\", WQ_HIGHPRI, 1);\n\tspin_lock_init(&kfd->interrupt_lock);\n\n\tINIT_WORK(&kfd->interrupt_work, interrupt_wq);\n\n\tkfd->interrupts_active = true;\n\n\t/*\n\t * After this function returns, the interrupt will be enabled. This\n\t * barrier ensures that the interrupt running on a different processor\n\t * sees all the above writes.\n\t */\n\tsmp_wmb();\n\n\treturn 0;\n}",
        "code_after_change": "int kfd_interrupt_init(struct kfd_dev *kfd)\n{\n\tint r;\n\n\tr = kfifo_alloc(&kfd->ih_fifo,\n\t\tKFD_IH_NUM_ENTRIES * kfd->device_info->ih_ring_entry_size,\n\t\tGFP_KERNEL);\n\tif (r) {\n\t\tdev_err(kfd_chardev(), \"Failed to allocate IH fifo\\n\");\n\t\treturn r;\n\t}\n\n\tkfd->ih_wq = alloc_workqueue(\"KFD IH\", WQ_HIGHPRI, 1);\n\tif (unlikely(!kfd->ih_wq)) {\n\t\tkfifo_free(&kfd->ih_fifo);\n\t\tdev_err(kfd_chardev(), \"Failed to allocate KFD IH workqueue\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tspin_lock_init(&kfd->interrupt_lock);\n\n\tINIT_WORK(&kfd->interrupt_work, interrupt_wq);\n\n\tkfd->interrupts_active = true;\n\n\t/*\n\t * After this function returns, the interrupt will be enabled. This\n\t * barrier ensures that the interrupt running on a different processor\n\t * sees all the above writes.\n\t */\n\tsmp_wmb();\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,11 @@\n \t}\n \n \tkfd->ih_wq = alloc_workqueue(\"KFD IH\", WQ_HIGHPRI, 1);\n+\tif (unlikely(!kfd->ih_wq)) {\n+\t\tkfifo_free(&kfd->ih_fifo);\n+\t\tdev_err(kfd_chardev(), \"Failed to allocate KFD IH workqueue\\n\");\n+\t\treturn -ENOMEM;\n+\t}\n \tspin_lock_init(&kfd->interrupt_lock);\n \n \tINIT_WORK(&kfd->interrupt_work, interrupt_wq);",
        "function_modified_lines": {
            "added": [
                "\tif (unlikely(!kfd->ih_wq)) {",
                "\t\tkfifo_free(&kfd->ih_fifo);",
                "\t\tdev_err(kfd_chardev(), \"Failed to allocate KFD IH workqueue\\n\");",
                "\t\treturn -ENOMEM;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/gpu/drm/amd/amdkfd/kfd_interrupt.c in the Linux kernel 5.2.14 does not check the alloc_workqueue return value, leading to a NULL pointer dereference. NOTE: The security community disputes this issues as not being serious enough to be deserving a CVE id",
        "id": 2043
    },
    {
        "cve_id": "CVE-2019-11810",
        "code_before_change": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -53,6 +53,7 @@\n \tif (megasas_create_frame_pool(instance)) {\n \t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n \t\tmegasas_free_cmds(instance);\n+\t\treturn -ENOMEM;\n \t}\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\t\treturn -ENOMEM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.7. A NULL pointer dereference can occur when megasas_create_frame_pool() fails in megasas_alloc_cmds() in drivers/scsi/megaraid/megaraid_sas_base.c. This causes a Denial of Service, related to a use-after-free.",
        "id": 1931
    },
    {
        "cve_id": "CVE-2018-14614",
        "code_before_change": "int f2fs_sanity_check_ckpt(struct f2fs_sb_info *sbi)\n{\n\tunsigned int total, fsmeta;\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tunsigned int ovp_segments, reserved_segments;\n\tunsigned int main_segs, blocks_per_seg;\n\tunsigned int sit_segs, nat_segs;\n\tunsigned int sit_bitmap_size, nat_bitmap_size;\n\tunsigned int log_blocks_per_seg;\n\tunsigned int segment_count_main;\n\tblock_t user_block_count;\n\tint i;\n\n\ttotal = le32_to_cpu(raw_super->segment_count);\n\tfsmeta = le32_to_cpu(raw_super->segment_count_ckpt);\n\tsit_segs = le32_to_cpu(raw_super->segment_count_sit);\n\tfsmeta += sit_segs;\n\tnat_segs = le32_to_cpu(raw_super->segment_count_nat);\n\tfsmeta += nat_segs;\n\tfsmeta += le32_to_cpu(ckpt->rsvd_segment_count);\n\tfsmeta += le32_to_cpu(raw_super->segment_count_ssa);\n\n\tif (unlikely(fsmeta >= total))\n\t\treturn 1;\n\n\tovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\treserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\n\tif (unlikely(fsmeta < F2FS_MIN_SEGMENTS ||\n\t\t\tovp_segments == 0 || reserved_segments == 0)) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong layout: check mkfs.f2fs version\");\n\t\treturn 1;\n\t}\n\n\tuser_block_count = le64_to_cpu(ckpt->user_block_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tif (!user_block_count || user_block_count >=\n\t\t\tsegment_count_main << log_blocks_per_seg) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong user_block_count: %u\", user_block_count);\n\t\treturn 1;\n\t}\n\n\tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n\tblocks_per_seg = sbi->blocks_per_seg;\n\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_node_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\tfor (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_data_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\n\tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n\tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n\n\tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n\t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong bitmap size: sit: %u, nat:%u\",\n\t\t\tsit_bitmap_size, nat_bitmap_size);\n\t\treturn 1;\n\t}\n\n\tif (unlikely(f2fs_cp_error(sbi))) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR, \"A bug case: need to run fsck\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "code_after_change": "int f2fs_sanity_check_ckpt(struct f2fs_sb_info *sbi)\n{\n\tunsigned int total, fsmeta;\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tunsigned int ovp_segments, reserved_segments;\n\tunsigned int main_segs, blocks_per_seg;\n\tunsigned int sit_segs, nat_segs;\n\tunsigned int sit_bitmap_size, nat_bitmap_size;\n\tunsigned int log_blocks_per_seg;\n\tunsigned int segment_count_main;\n\tunsigned int cp_pack_start_sum, cp_payload;\n\tblock_t user_block_count;\n\tint i;\n\n\ttotal = le32_to_cpu(raw_super->segment_count);\n\tfsmeta = le32_to_cpu(raw_super->segment_count_ckpt);\n\tsit_segs = le32_to_cpu(raw_super->segment_count_sit);\n\tfsmeta += sit_segs;\n\tnat_segs = le32_to_cpu(raw_super->segment_count_nat);\n\tfsmeta += nat_segs;\n\tfsmeta += le32_to_cpu(ckpt->rsvd_segment_count);\n\tfsmeta += le32_to_cpu(raw_super->segment_count_ssa);\n\n\tif (unlikely(fsmeta >= total))\n\t\treturn 1;\n\n\tovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\treserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\n\tif (unlikely(fsmeta < F2FS_MIN_SEGMENTS ||\n\t\t\tovp_segments == 0 || reserved_segments == 0)) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong layout: check mkfs.f2fs version\");\n\t\treturn 1;\n\t}\n\n\tuser_block_count = le64_to_cpu(ckpt->user_block_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tif (!user_block_count || user_block_count >=\n\t\t\tsegment_count_main << log_blocks_per_seg) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong user_block_count: %u\", user_block_count);\n\t\treturn 1;\n\t}\n\n\tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n\tblocks_per_seg = sbi->blocks_per_seg;\n\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_node_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\tfor (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_data_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\n\tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n\tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n\n\tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n\t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong bitmap size: sit: %u, nat:%u\",\n\t\t\tsit_bitmap_size, nat_bitmap_size);\n\t\treturn 1;\n\t}\n\n\tcp_pack_start_sum = __start_sum_addr(sbi);\n\tcp_payload = __cp_payload(sbi);\n\tif (cp_pack_start_sum < cp_payload + 1 ||\n\t\tcp_pack_start_sum > blocks_per_seg - 1 -\n\t\t\tNR_CURSEG_TYPE) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong cp_pack_start_sum: %u\",\n\t\t\tcp_pack_start_sum);\n\t\treturn 1;\n\t}\n\n\tif (unlikely(f2fs_cp_error(sbi))) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR, \"A bug case: need to run fsck\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,7 @@\n \tunsigned int sit_bitmap_size, nat_bitmap_size;\n \tunsigned int log_blocks_per_seg;\n \tunsigned int segment_count_main;\n+\tunsigned int cp_pack_start_sum, cp_payload;\n \tblock_t user_block_count;\n \tint i;\n \n@@ -69,6 +70,17 @@\n \t\treturn 1;\n \t}\n \n+\tcp_pack_start_sum = __start_sum_addr(sbi);\n+\tcp_payload = __cp_payload(sbi);\n+\tif (cp_pack_start_sum < cp_payload + 1 ||\n+\t\tcp_pack_start_sum > blocks_per_seg - 1 -\n+\t\t\tNR_CURSEG_TYPE) {\n+\t\tf2fs_msg(sbi->sb, KERN_ERR,\n+\t\t\t\"Wrong cp_pack_start_sum: %u\",\n+\t\t\tcp_pack_start_sum);\n+\t\treturn 1;\n+\t}\n+\n \tif (unlikely(f2fs_cp_error(sbi))) {\n \t\tf2fs_msg(sbi->sb, KERN_ERR, \"A bug case: need to run fsck\");\n \t\treturn 1;",
        "function_modified_lines": {
            "added": [
                "\tunsigned int cp_pack_start_sum, cp_payload;",
                "\tcp_pack_start_sum = __start_sum_addr(sbi);",
                "\tcp_payload = __cp_payload(sbi);",
                "\tif (cp_pack_start_sum < cp_payload + 1 ||",
                "\t\tcp_pack_start_sum > blocks_per_seg - 1 -",
                "\t\t\tNR_CURSEG_TYPE) {",
                "\t\tf2fs_msg(sbi->sb, KERN_ERR,",
                "\t\t\t\"Wrong cp_pack_start_sum: %u\",",
                "\t\t\tcp_pack_start_sum);",
                "\t\treturn 1;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is an out-of-bounds access in __remove_dirty_segment() in fs/f2fs/segment.c when mounting an f2fs image.",
        "id": 1685
    },
    {
        "cve_id": "CVE-2019-19227",
        "code_before_change": "static int __init atalk_init(void)\n{\n\tint rc;\n\n\trc = proto_register(&ddp_proto, 0);\n\tif (rc)\n\t\tgoto out;\n\n\trc = sock_register(&atalk_family_ops);\n\tif (rc)\n\t\tgoto out_proto;\n\n\tddp_dl = register_snap_client(ddp_snap_id, atalk_rcv);\n\tif (!ddp_dl)\n\t\tprintk(atalk_err_snap);\n\n\tdev_add_pack(&ltalk_packet_type);\n\tdev_add_pack(&ppptalk_packet_type);\n\n\trc = register_netdevice_notifier(&ddp_notifier);\n\tif (rc)\n\t\tgoto out_sock;\n\n\taarp_proto_init();\n\trc = atalk_proc_init();\n\tif (rc)\n\t\tgoto out_aarp;\n\n\trc = atalk_register_sysctl();\n\tif (rc)\n\t\tgoto out_proc;\nout:\n\treturn rc;\nout_proc:\n\tatalk_proc_exit();\nout_aarp:\n\taarp_cleanup_module();\n\tunregister_netdevice_notifier(&ddp_notifier);\nout_sock:\n\tdev_remove_pack(&ppptalk_packet_type);\n\tdev_remove_pack(&ltalk_packet_type);\n\tunregister_snap_client(ddp_dl);\n\tsock_unregister(PF_APPLETALK);\nout_proto:\n\tproto_unregister(&ddp_proto);\n\tgoto out;\n}",
        "code_after_change": "static int __init atalk_init(void)\n{\n\tint rc;\n\n\trc = proto_register(&ddp_proto, 0);\n\tif (rc)\n\t\tgoto out;\n\n\trc = sock_register(&atalk_family_ops);\n\tif (rc)\n\t\tgoto out_proto;\n\n\tddp_dl = register_snap_client(ddp_snap_id, atalk_rcv);\n\tif (!ddp_dl) {\n\t\tpr_crit(\"Unable to register DDP with SNAP.\\n\");\n\t\tgoto out_sock;\n\t}\n\n\tdev_add_pack(&ltalk_packet_type);\n\tdev_add_pack(&ppptalk_packet_type);\n\n\trc = register_netdevice_notifier(&ddp_notifier);\n\tif (rc)\n\t\tgoto out_snap;\n\n\trc = aarp_proto_init();\n\tif (rc)\n\t\tgoto out_dev;\n\n\trc = atalk_proc_init();\n\tif (rc)\n\t\tgoto out_aarp;\n\n\trc = atalk_register_sysctl();\n\tif (rc)\n\t\tgoto out_proc;\nout:\n\treturn rc;\nout_proc:\n\tatalk_proc_exit();\nout_aarp:\n\taarp_cleanup_module();\nout_dev:\n\tunregister_netdevice_notifier(&ddp_notifier);\nout_snap:\n\tdev_remove_pack(&ppptalk_packet_type);\n\tdev_remove_pack(&ltalk_packet_type);\n\tunregister_snap_client(ddp_dl);\nout_sock:\n\tsock_unregister(PF_APPLETALK);\nout_proto:\n\tproto_unregister(&ddp_proto);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,17 +11,22 @@\n \t\tgoto out_proto;\n \n \tddp_dl = register_snap_client(ddp_snap_id, atalk_rcv);\n-\tif (!ddp_dl)\n-\t\tprintk(atalk_err_snap);\n+\tif (!ddp_dl) {\n+\t\tpr_crit(\"Unable to register DDP with SNAP.\\n\");\n+\t\tgoto out_sock;\n+\t}\n \n \tdev_add_pack(&ltalk_packet_type);\n \tdev_add_pack(&ppptalk_packet_type);\n \n \trc = register_netdevice_notifier(&ddp_notifier);\n \tif (rc)\n-\t\tgoto out_sock;\n+\t\tgoto out_snap;\n \n-\taarp_proto_init();\n+\trc = aarp_proto_init();\n+\tif (rc)\n+\t\tgoto out_dev;\n+\n \trc = atalk_proc_init();\n \tif (rc)\n \t\tgoto out_aarp;\n@@ -35,11 +40,13 @@\n \tatalk_proc_exit();\n out_aarp:\n \taarp_cleanup_module();\n+out_dev:\n \tunregister_netdevice_notifier(&ddp_notifier);\n-out_sock:\n+out_snap:\n \tdev_remove_pack(&ppptalk_packet_type);\n \tdev_remove_pack(&ltalk_packet_type);\n \tunregister_snap_client(ddp_dl);\n+out_sock:\n \tsock_unregister(PF_APPLETALK);\n out_proto:\n \tproto_unregister(&ddp_proto);",
        "function_modified_lines": {
            "added": [
                "\tif (!ddp_dl) {",
                "\t\tpr_crit(\"Unable to register DDP with SNAP.\\n\");",
                "\t\tgoto out_sock;",
                "\t}",
                "\t\tgoto out_snap;",
                "\trc = aarp_proto_init();",
                "\tif (rc)",
                "\t\tgoto out_dev;",
                "",
                "out_dev:",
                "out_snap:",
                "out_sock:"
            ],
            "deleted": [
                "\tif (!ddp_dl)",
                "\t\tprintk(atalk_err_snap);",
                "\t\tgoto out_sock;",
                "\taarp_proto_init();",
                "out_sock:"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the AppleTalk subsystem in the Linux kernel before 5.1, there is a potential NULL pointer dereference because register_snap_client may return NULL. This will lead to denial of service in net/appletalk/aarp.c and net/appletalk/ddp.c, as demonstrated by unregister_snap_client, aka CID-9804501fa122.",
        "id": 2178
    },
    {
        "cve_id": "CVE-2023-6176",
        "code_before_change": "static int bpf_exec_tx_verdict(struct sk_msg *msg, struct sock *sk,\n\t\t\t       bool full_record, u8 record_type,\n\t\t\t       ssize_t *copied, int flags)\n{\n\tstruct tls_context *tls_ctx = tls_get_ctx(sk);\n\tstruct tls_sw_context_tx *ctx = tls_sw_ctx_tx(tls_ctx);\n\tstruct sk_msg msg_redir = { };\n\tstruct sk_psock *psock;\n\tstruct sock *sk_redir;\n\tstruct tls_rec *rec;\n\tbool enospc, policy, redir_ingress;\n\tint err = 0, send;\n\tu32 delta = 0;\n\n\tpolicy = !(flags & MSG_SENDPAGE_NOPOLICY);\n\tpsock = sk_psock_get(sk);\n\tif (!psock || !policy) {\n\t\terr = tls_push_record(sk, flags, record_type);\n\t\tif (err && sk->sk_err == EBADMSG) {\n\t\t\t*copied -= sk_msg_free(sk, msg);\n\t\t\ttls_free_open_rec(sk);\n\t\t\terr = -sk->sk_err;\n\t\t}\n\t\tif (psock)\n\t\t\tsk_psock_put(sk, psock);\n\t\treturn err;\n\t}\nmore_data:\n\tenospc = sk_msg_full(msg);\n\tif (psock->eval == __SK_NONE) {\n\t\tdelta = msg->sg.size;\n\t\tpsock->eval = sk_psock_msg_verdict(sk, psock, msg);\n\t\tdelta -= msg->sg.size;\n\t}\n\tif (msg->cork_bytes && msg->cork_bytes > msg->sg.size &&\n\t    !enospc && !full_record) {\n\t\terr = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\tmsg->cork_bytes = 0;\n\tsend = msg->sg.size;\n\tif (msg->apply_bytes && msg->apply_bytes < send)\n\t\tsend = msg->apply_bytes;\n\n\tswitch (psock->eval) {\n\tcase __SK_PASS:\n\t\terr = tls_push_record(sk, flags, record_type);\n\t\tif (err && sk->sk_err == EBADMSG) {\n\t\t\t*copied -= sk_msg_free(sk, msg);\n\t\t\ttls_free_open_rec(sk);\n\t\t\terr = -sk->sk_err;\n\t\t\tgoto out_err;\n\t\t}\n\t\tbreak;\n\tcase __SK_REDIRECT:\n\t\tredir_ingress = psock->redir_ingress;\n\t\tsk_redir = psock->sk_redir;\n\t\tmemcpy(&msg_redir, msg, sizeof(*msg));\n\t\tif (msg->apply_bytes < send)\n\t\t\tmsg->apply_bytes = 0;\n\t\telse\n\t\t\tmsg->apply_bytes -= send;\n\t\tsk_msg_return_zero(sk, msg, send);\n\t\tmsg->sg.size -= send;\n\t\trelease_sock(sk);\n\t\terr = tcp_bpf_sendmsg_redir(sk_redir, redir_ingress,\n\t\t\t\t\t    &msg_redir, send, flags);\n\t\tlock_sock(sk);\n\t\tif (err < 0) {\n\t\t\t*copied -= sk_msg_free_nocharge(sk, &msg_redir);\n\t\t\tmsg->sg.size = 0;\n\t\t}\n\t\tif (msg->sg.size == 0)\n\t\t\ttls_free_open_rec(sk);\n\t\tbreak;\n\tcase __SK_DROP:\n\tdefault:\n\t\tsk_msg_free_partial(sk, msg, send);\n\t\tif (msg->apply_bytes < send)\n\t\t\tmsg->apply_bytes = 0;\n\t\telse\n\t\t\tmsg->apply_bytes -= send;\n\t\tif (msg->sg.size == 0)\n\t\t\ttls_free_open_rec(sk);\n\t\t*copied -= (send + delta);\n\t\terr = -EACCES;\n\t}\n\n\tif (likely(!err)) {\n\t\tbool reset_eval = !ctx->open_rec;\n\n\t\trec = ctx->open_rec;\n\t\tif (rec) {\n\t\t\tmsg = &rec->msg_plaintext;\n\t\t\tif (!msg->apply_bytes)\n\t\t\t\treset_eval = true;\n\t\t}\n\t\tif (reset_eval) {\n\t\t\tpsock->eval = __SK_NONE;\n\t\t\tif (psock->sk_redir) {\n\t\t\t\tsock_put(psock->sk_redir);\n\t\t\t\tpsock->sk_redir = NULL;\n\t\t\t}\n\t\t}\n\t\tif (rec)\n\t\t\tgoto more_data;\n\t}\n out_err:\n\tsk_psock_put(sk, psock);\n\treturn err;\n}",
        "code_after_change": "static int bpf_exec_tx_verdict(struct sk_msg *msg, struct sock *sk,\n\t\t\t       bool full_record, u8 record_type,\n\t\t\t       ssize_t *copied, int flags)\n{\n\tstruct tls_context *tls_ctx = tls_get_ctx(sk);\n\tstruct tls_sw_context_tx *ctx = tls_sw_ctx_tx(tls_ctx);\n\tstruct sk_msg msg_redir = { };\n\tstruct sk_psock *psock;\n\tstruct sock *sk_redir;\n\tstruct tls_rec *rec;\n\tbool enospc, policy, redir_ingress;\n\tint err = 0, send;\n\tu32 delta = 0;\n\n\tpolicy = !(flags & MSG_SENDPAGE_NOPOLICY);\n\tpsock = sk_psock_get(sk);\n\tif (!psock || !policy) {\n\t\terr = tls_push_record(sk, flags, record_type);\n\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {\n\t\t\t*copied -= sk_msg_free(sk, msg);\n\t\t\ttls_free_open_rec(sk);\n\t\t\terr = -sk->sk_err;\n\t\t}\n\t\tif (psock)\n\t\t\tsk_psock_put(sk, psock);\n\t\treturn err;\n\t}\nmore_data:\n\tenospc = sk_msg_full(msg);\n\tif (psock->eval == __SK_NONE) {\n\t\tdelta = msg->sg.size;\n\t\tpsock->eval = sk_psock_msg_verdict(sk, psock, msg);\n\t\tdelta -= msg->sg.size;\n\t}\n\tif (msg->cork_bytes && msg->cork_bytes > msg->sg.size &&\n\t    !enospc && !full_record) {\n\t\terr = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\tmsg->cork_bytes = 0;\n\tsend = msg->sg.size;\n\tif (msg->apply_bytes && msg->apply_bytes < send)\n\t\tsend = msg->apply_bytes;\n\n\tswitch (psock->eval) {\n\tcase __SK_PASS:\n\t\terr = tls_push_record(sk, flags, record_type);\n\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {\n\t\t\t*copied -= sk_msg_free(sk, msg);\n\t\t\ttls_free_open_rec(sk);\n\t\t\terr = -sk->sk_err;\n\t\t\tgoto out_err;\n\t\t}\n\t\tbreak;\n\tcase __SK_REDIRECT:\n\t\tredir_ingress = psock->redir_ingress;\n\t\tsk_redir = psock->sk_redir;\n\t\tmemcpy(&msg_redir, msg, sizeof(*msg));\n\t\tif (msg->apply_bytes < send)\n\t\t\tmsg->apply_bytes = 0;\n\t\telse\n\t\t\tmsg->apply_bytes -= send;\n\t\tsk_msg_return_zero(sk, msg, send);\n\t\tmsg->sg.size -= send;\n\t\trelease_sock(sk);\n\t\terr = tcp_bpf_sendmsg_redir(sk_redir, redir_ingress,\n\t\t\t\t\t    &msg_redir, send, flags);\n\t\tlock_sock(sk);\n\t\tif (err < 0) {\n\t\t\t*copied -= sk_msg_free_nocharge(sk, &msg_redir);\n\t\t\tmsg->sg.size = 0;\n\t\t}\n\t\tif (msg->sg.size == 0)\n\t\t\ttls_free_open_rec(sk);\n\t\tbreak;\n\tcase __SK_DROP:\n\tdefault:\n\t\tsk_msg_free_partial(sk, msg, send);\n\t\tif (msg->apply_bytes < send)\n\t\t\tmsg->apply_bytes = 0;\n\t\telse\n\t\t\tmsg->apply_bytes -= send;\n\t\tif (msg->sg.size == 0)\n\t\t\ttls_free_open_rec(sk);\n\t\t*copied -= (send + delta);\n\t\terr = -EACCES;\n\t}\n\n\tif (likely(!err)) {\n\t\tbool reset_eval = !ctx->open_rec;\n\n\t\trec = ctx->open_rec;\n\t\tif (rec) {\n\t\t\tmsg = &rec->msg_plaintext;\n\t\t\tif (!msg->apply_bytes)\n\t\t\t\treset_eval = true;\n\t\t}\n\t\tif (reset_eval) {\n\t\t\tpsock->eval = __SK_NONE;\n\t\t\tif (psock->sk_redir) {\n\t\t\t\tsock_put(psock->sk_redir);\n\t\t\t\tpsock->sk_redir = NULL;\n\t\t\t}\n\t\t}\n\t\tif (rec)\n\t\t\tgoto more_data;\n\t}\n out_err:\n\tsk_psock_put(sk, psock);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,7 +16,7 @@\n \tpsock = sk_psock_get(sk);\n \tif (!psock || !policy) {\n \t\terr = tls_push_record(sk, flags, record_type);\n-\t\tif (err && sk->sk_err == EBADMSG) {\n+\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {\n \t\t\t*copied -= sk_msg_free(sk, msg);\n \t\t\ttls_free_open_rec(sk);\n \t\t\terr = -sk->sk_err;\n@@ -45,7 +45,7 @@\n \tswitch (psock->eval) {\n \tcase __SK_PASS:\n \t\terr = tls_push_record(sk, flags, record_type);\n-\t\tif (err && sk->sk_err == EBADMSG) {\n+\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {\n \t\t\t*copied -= sk_msg_free(sk, msg);\n \t\t\ttls_free_open_rec(sk);\n \t\t\terr = -sk->sk_err;",
        "function_modified_lines": {
            "added": [
                "\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {",
                "\t\tif (err && err != -EINPROGRESS && sk->sk_err == EBADMSG) {"
            ],
            "deleted": [
                "\t\tif (err && sk->sk_err == EBADMSG) {",
                "\t\tif (err && sk->sk_err == EBADMSG) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference flaw was found in the Linux kernel API for the cryptographic algorithm scatterwalk functionality. This issue occurs when a user constructs a malicious packet with specific socket configuration, which could allow a local user to crash the system or escalate their privileges on the system.",
        "id": 4300
    },
    {
        "cve_id": "CVE-2017-18241",
        "code_before_change": "int build_segment_manager(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tstruct f2fs_sm_info *sm_info;\n\tint err;\n\n\tsm_info = kzalloc(sizeof(struct f2fs_sm_info), GFP_KERNEL);\n\tif (!sm_info)\n\t\treturn -ENOMEM;\n\n\t/* init sm info */\n\tsbi->sm_info = sm_info;\n\tsm_info->seg0_blkaddr = le32_to_cpu(raw_super->segment0_blkaddr);\n\tsm_info->main_blkaddr = le32_to_cpu(raw_super->main_blkaddr);\n\tsm_info->segment_count = le32_to_cpu(raw_super->segment_count);\n\tsm_info->reserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\tsm_info->ovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\tsm_info->main_segments = le32_to_cpu(raw_super->segment_count_main);\n\tsm_info->ssa_blkaddr = le32_to_cpu(raw_super->ssa_blkaddr);\n\tsm_info->rec_prefree_segments = sm_info->main_segments *\n\t\t\t\t\tDEF_RECLAIM_PREFREE_SEGMENTS / 100;\n\tif (sm_info->rec_prefree_segments > DEF_MAX_RECLAIM_PREFREE_SEGMENTS)\n\t\tsm_info->rec_prefree_segments = DEF_MAX_RECLAIM_PREFREE_SEGMENTS;\n\n\tif (!test_opt(sbi, LFS))\n\t\tsm_info->ipu_policy = 1 << F2FS_IPU_FSYNC;\n\tsm_info->min_ipu_util = DEF_MIN_IPU_UTIL;\n\tsm_info->min_fsync_blocks = DEF_MIN_FSYNC_BLOCKS;\n\tsm_info->min_hot_blocks = DEF_MIN_HOT_BLOCKS;\n\n\tsm_info->trim_sections = DEF_BATCHED_TRIM_SECTIONS;\n\n\tINIT_LIST_HEAD(&sm_info->sit_entry_set);\n\n\tif (test_opt(sbi, FLUSH_MERGE) && !f2fs_readonly(sbi->sb)) {\n\t\terr = create_flush_cmd_control(sbi);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = create_discard_cmd_control(sbi);\n\tif (err)\n\t\treturn err;\n\n\terr = build_sit_info(sbi);\n\tif (err)\n\t\treturn err;\n\terr = build_free_segmap(sbi);\n\tif (err)\n\t\treturn err;\n\terr = build_curseg(sbi);\n\tif (err)\n\t\treturn err;\n\n\t/* reinit free segmap based on SIT */\n\tbuild_sit_entries(sbi);\n\n\tinit_free_segmap(sbi);\n\terr = build_dirty_segmap(sbi);\n\tif (err)\n\t\treturn err;\n\n\tinit_min_max_mtime(sbi);\n\treturn 0;\n}",
        "code_after_change": "int build_segment_manager(struct f2fs_sb_info *sbi)\n{\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tstruct f2fs_sm_info *sm_info;\n\tint err;\n\n\tsm_info = kzalloc(sizeof(struct f2fs_sm_info), GFP_KERNEL);\n\tif (!sm_info)\n\t\treturn -ENOMEM;\n\n\t/* init sm info */\n\tsbi->sm_info = sm_info;\n\tsm_info->seg0_blkaddr = le32_to_cpu(raw_super->segment0_blkaddr);\n\tsm_info->main_blkaddr = le32_to_cpu(raw_super->main_blkaddr);\n\tsm_info->segment_count = le32_to_cpu(raw_super->segment_count);\n\tsm_info->reserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\tsm_info->ovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\tsm_info->main_segments = le32_to_cpu(raw_super->segment_count_main);\n\tsm_info->ssa_blkaddr = le32_to_cpu(raw_super->ssa_blkaddr);\n\tsm_info->rec_prefree_segments = sm_info->main_segments *\n\t\t\t\t\tDEF_RECLAIM_PREFREE_SEGMENTS / 100;\n\tif (sm_info->rec_prefree_segments > DEF_MAX_RECLAIM_PREFREE_SEGMENTS)\n\t\tsm_info->rec_prefree_segments = DEF_MAX_RECLAIM_PREFREE_SEGMENTS;\n\n\tif (!test_opt(sbi, LFS))\n\t\tsm_info->ipu_policy = 1 << F2FS_IPU_FSYNC;\n\tsm_info->min_ipu_util = DEF_MIN_IPU_UTIL;\n\tsm_info->min_fsync_blocks = DEF_MIN_FSYNC_BLOCKS;\n\tsm_info->min_hot_blocks = DEF_MIN_HOT_BLOCKS;\n\n\tsm_info->trim_sections = DEF_BATCHED_TRIM_SECTIONS;\n\n\tINIT_LIST_HEAD(&sm_info->sit_entry_set);\n\n\tif (!f2fs_readonly(sbi->sb)) {\n\t\terr = create_flush_cmd_control(sbi);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\terr = create_discard_cmd_control(sbi);\n\tif (err)\n\t\treturn err;\n\n\terr = build_sit_info(sbi);\n\tif (err)\n\t\treturn err;\n\terr = build_free_segmap(sbi);\n\tif (err)\n\t\treturn err;\n\terr = build_curseg(sbi);\n\tif (err)\n\t\treturn err;\n\n\t/* reinit free segmap based on SIT */\n\tbuild_sit_entries(sbi);\n\n\tinit_free_segmap(sbi);\n\terr = build_dirty_segmap(sbi);\n\tif (err)\n\t\treturn err;\n\n\tinit_min_max_mtime(sbi);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -33,7 +33,7 @@\n \n \tINIT_LIST_HEAD(&sm_info->sit_entry_set);\n \n-\tif (test_opt(sbi, FLUSH_MERGE) && !f2fs_readonly(sbi->sb)) {\n+\tif (!f2fs_readonly(sbi->sb)) {\n \t\terr = create_flush_cmd_control(sbi);\n \t\tif (err)\n \t\t\treturn err;",
        "function_modified_lines": {
            "added": [
                "\tif (!f2fs_readonly(sbi->sb)) {"
            ],
            "deleted": [
                "\tif (test_opt(sbi, FLUSH_MERGE) && !f2fs_readonly(sbi->sb)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/f2fs/segment.c in the Linux kernel before 4.13 allows local users to cause a denial of service (NULL pointer dereference and panic) by using a noflush_merge option that triggers a NULL value for a flush_cmd_control data structure.",
        "id": 1424
    },
    {
        "cve_id": "CVE-2017-2647",
        "code_before_change": "struct key *request_key_and_link(struct key_type *type,\n\t\t\t\t const char *description,\n\t\t\t\t const void *callout_info,\n\t\t\t\t size_t callout_len,\n\t\t\t\t void *aux,\n\t\t\t\t struct key *dest_keyring,\n\t\t\t\t unsigned long flags)\n{\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= type,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= type->match,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t};\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tint ret;\n\n\tkenter(\"%s,%s,%p,%zu,%p,%p,%lx\",\n\t       ctx.index_key.type->name, ctx.index_key.description,\n\t       callout_info, callout_len, aux, dest_keyring, flags);\n\n\tif (type->match_preparse) {\n\t\tret = type->match_preparse(&ctx.match_data);\n\t\tif (ret < 0) {\n\t\t\tkey = ERR_PTR(ret);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\t/* search all the process keyrings for a key */\n\tkey_ref = search_process_keyrings(&ctx);\n\n\tif (!IS_ERR(key_ref)) {\n\t\tkey = key_ref_to_ptr(key_ref);\n\t\tif (dest_keyring) {\n\t\t\tconstruct_get_dest_keyring(&dest_keyring);\n\t\t\tret = key_link(dest_keyring, key);\n\t\t\tkey_put(dest_keyring);\n\t\t\tif (ret < 0) {\n\t\t\t\tkey_put(key);\n\t\t\t\tkey = ERR_PTR(ret);\n\t\t\t\tgoto error_free;\n\t\t\t}\n\t\t}\n\t} else if (PTR_ERR(key_ref) != -EAGAIN) {\n\t\tkey = ERR_CAST(key_ref);\n\t} else  {\n\t\t/* the search failed, but the keyrings were searchable, so we\n\t\t * should consult userspace if we can */\n\t\tkey = ERR_PTR(-ENOKEY);\n\t\tif (!callout_info)\n\t\t\tgoto error_free;\n\n\t\tkey = construct_key_and_link(&ctx, callout_info, callout_len,\n\t\t\t\t\t     aux, dest_keyring, flags);\n\t}\n\nerror_free:\n\tif (type->match_free)\n\t\ttype->match_free(&ctx.match_data);\nerror:\n\tkleave(\" = %p\", key);\n\treturn key;\n}",
        "code_after_change": "struct key *request_key_and_link(struct key_type *type,\n\t\t\t\t const char *description,\n\t\t\t\t const void *callout_info,\n\t\t\t\t size_t callout_len,\n\t\t\t\t void *aux,\n\t\t\t\t struct key *dest_keyring,\n\t\t\t\t unsigned long flags)\n{\n\tstruct keyring_search_context ctx = {\n\t\t.index_key.type\t\t= type,\n\t\t.index_key.description\t= description,\n\t\t.cred\t\t\t= current_cred(),\n\t\t.match_data.cmp\t\t= key_default_cmp,\n\t\t.match_data.raw_data\t= description,\n\t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n\t};\n\tstruct key *key;\n\tkey_ref_t key_ref;\n\tint ret;\n\n\tkenter(\"%s,%s,%p,%zu,%p,%p,%lx\",\n\t       ctx.index_key.type->name, ctx.index_key.description,\n\t       callout_info, callout_len, aux, dest_keyring, flags);\n\n\tif (type->match_preparse) {\n\t\tret = type->match_preparse(&ctx.match_data);\n\t\tif (ret < 0) {\n\t\t\tkey = ERR_PTR(ret);\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\t/* search all the process keyrings for a key */\n\tkey_ref = search_process_keyrings(&ctx);\n\n\tif (!IS_ERR(key_ref)) {\n\t\tkey = key_ref_to_ptr(key_ref);\n\t\tif (dest_keyring) {\n\t\t\tconstruct_get_dest_keyring(&dest_keyring);\n\t\t\tret = key_link(dest_keyring, key);\n\t\t\tkey_put(dest_keyring);\n\t\t\tif (ret < 0) {\n\t\t\t\tkey_put(key);\n\t\t\t\tkey = ERR_PTR(ret);\n\t\t\t\tgoto error_free;\n\t\t\t}\n\t\t}\n\t} else if (PTR_ERR(key_ref) != -EAGAIN) {\n\t\tkey = ERR_CAST(key_ref);\n\t} else  {\n\t\t/* the search failed, but the keyrings were searchable, so we\n\t\t * should consult userspace if we can */\n\t\tkey = ERR_PTR(-ENOKEY);\n\t\tif (!callout_info)\n\t\t\tgoto error_free;\n\n\t\tkey = construct_key_and_link(&ctx, callout_info, callout_len,\n\t\t\t\t\t     aux, dest_keyring, flags);\n\t}\n\nerror_free:\n\tif (type->match_free)\n\t\ttype->match_free(&ctx.match_data);\nerror:\n\tkleave(\" = %p\", key);\n\treturn key;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \t\t.index_key.type\t\t= type,\n \t\t.index_key.description\t= description,\n \t\t.cred\t\t\t= current_cred(),\n-\t\t.match_data.cmp\t\t= type->match,\n+\t\t.match_data.cmp\t\t= key_default_cmp,\n \t\t.match_data.raw_data\t= description,\n \t\t.match_data.lookup_type\t= KEYRING_SEARCH_LOOKUP_DIRECT,\n \t};",
        "function_modified_lines": {
            "added": [
                "\t\t.match_data.cmp\t\t= key_default_cmp,"
            ],
            "deleted": [
                "\t\t.match_data.cmp\t\t= type->match,"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The KEYS subsystem in the Linux kernel before 3.18 allows local users to gain privileges or cause a denial of service (NULL pointer dereference and system crash) via vectors involving a NULL value for a certain match field, related to the keyring_search_iterator function in keyring.c.",
        "id": 1453
    },
    {
        "cve_id": "CVE-2019-10207",
        "code_before_change": "static int qca_open(struct hci_uart *hu)\n{\n\tstruct qca_serdev *qcadev;\n\tstruct qca_data *qca;\n\tint ret;\n\n\tBT_DBG(\"hu %p qca_open\", hu);\n\n\tqca = kzalloc(sizeof(struct qca_data), GFP_KERNEL);\n\tif (!qca)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&qca->txq);\n\tskb_queue_head_init(&qca->tx_wait_q);\n\tspin_lock_init(&qca->hci_ibs_lock);\n\tqca->workqueue = alloc_ordered_workqueue(\"qca_wq\", 0);\n\tif (!qca->workqueue) {\n\t\tBT_ERR(\"QCA Workqueue not initialized properly\");\n\t\tkfree(qca);\n\t\treturn -ENOMEM;\n\t}\n\n\tINIT_WORK(&qca->ws_awake_rx, qca_wq_awake_rx);\n\tINIT_WORK(&qca->ws_awake_device, qca_wq_awake_device);\n\tINIT_WORK(&qca->ws_rx_vote_off, qca_wq_serial_rx_clock_vote_off);\n\tINIT_WORK(&qca->ws_tx_vote_off, qca_wq_serial_tx_clock_vote_off);\n\n\tqca->hu = hu;\n\tinit_completion(&qca->drop_ev_comp);\n\n\t/* Assume we start with both sides asleep -- extra wakes OK */\n\tqca->tx_ibs_state = HCI_IBS_TX_ASLEEP;\n\tqca->rx_ibs_state = HCI_IBS_RX_ASLEEP;\n\n\t/* clocks actually on, but we start votes off */\n\tqca->tx_vote = false;\n\tqca->rx_vote = false;\n\tqca->flags = 0;\n\n\tqca->ibs_sent_wacks = 0;\n\tqca->ibs_sent_slps = 0;\n\tqca->ibs_sent_wakes = 0;\n\tqca->ibs_recv_wacks = 0;\n\tqca->ibs_recv_slps = 0;\n\tqca->ibs_recv_wakes = 0;\n\tqca->vote_last_jif = jiffies;\n\tqca->vote_on_ms = 0;\n\tqca->vote_off_ms = 0;\n\tqca->votes_on = 0;\n\tqca->votes_off = 0;\n\tqca->tx_votes_on = 0;\n\tqca->tx_votes_off = 0;\n\tqca->rx_votes_on = 0;\n\tqca->rx_votes_off = 0;\n\n\thu->priv = qca;\n\n\tif (hu->serdev) {\n\n\t\tqcadev = serdev_device_get_drvdata(hu->serdev);\n\t\tif (!qca_is_wcn399x(qcadev->btsoc_type)) {\n\t\t\tgpiod_set_value_cansleep(qcadev->bt_en, 1);\n\t\t\t/* Controller needs time to bootup. */\n\t\t\tmsleep(150);\n\t\t} else {\n\t\t\thu->init_speed = qcadev->init_speed;\n\t\t\thu->oper_speed = qcadev->oper_speed;\n\t\t\tret = qca_power_setup(hu, true);\n\t\t\tif (ret) {\n\t\t\t\tdestroy_workqueue(qca->workqueue);\n\t\t\t\tkfree_skb(qca->rx_skb);\n\t\t\t\thu->priv = NULL;\n\t\t\t\tkfree(qca);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\ttimer_setup(&qca->wake_retrans_timer, hci_ibs_wake_retrans_timeout, 0);\n\tqca->wake_retrans = IBS_WAKE_RETRANS_TIMEOUT_MS;\n\n\ttimer_setup(&qca->tx_idle_timer, hci_ibs_tx_idle_timeout, 0);\n\tqca->tx_idle_delay = IBS_TX_IDLE_TIMEOUT_MS;\n\n\tBT_DBG(\"HCI_UART_QCA open, tx_idle_delay=%u, wake_retrans=%u\",\n\t       qca->tx_idle_delay, qca->wake_retrans);\n\n\treturn 0;\n}",
        "code_after_change": "static int qca_open(struct hci_uart *hu)\n{\n\tstruct qca_serdev *qcadev;\n\tstruct qca_data *qca;\n\tint ret;\n\n\tBT_DBG(\"hu %p qca_open\", hu);\n\n\tif (!hci_uart_has_flow_control(hu))\n\t\treturn -EOPNOTSUPP;\n\n\tqca = kzalloc(sizeof(struct qca_data), GFP_KERNEL);\n\tif (!qca)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&qca->txq);\n\tskb_queue_head_init(&qca->tx_wait_q);\n\tspin_lock_init(&qca->hci_ibs_lock);\n\tqca->workqueue = alloc_ordered_workqueue(\"qca_wq\", 0);\n\tif (!qca->workqueue) {\n\t\tBT_ERR(\"QCA Workqueue not initialized properly\");\n\t\tkfree(qca);\n\t\treturn -ENOMEM;\n\t}\n\n\tINIT_WORK(&qca->ws_awake_rx, qca_wq_awake_rx);\n\tINIT_WORK(&qca->ws_awake_device, qca_wq_awake_device);\n\tINIT_WORK(&qca->ws_rx_vote_off, qca_wq_serial_rx_clock_vote_off);\n\tINIT_WORK(&qca->ws_tx_vote_off, qca_wq_serial_tx_clock_vote_off);\n\n\tqca->hu = hu;\n\tinit_completion(&qca->drop_ev_comp);\n\n\t/* Assume we start with both sides asleep -- extra wakes OK */\n\tqca->tx_ibs_state = HCI_IBS_TX_ASLEEP;\n\tqca->rx_ibs_state = HCI_IBS_RX_ASLEEP;\n\n\t/* clocks actually on, but we start votes off */\n\tqca->tx_vote = false;\n\tqca->rx_vote = false;\n\tqca->flags = 0;\n\n\tqca->ibs_sent_wacks = 0;\n\tqca->ibs_sent_slps = 0;\n\tqca->ibs_sent_wakes = 0;\n\tqca->ibs_recv_wacks = 0;\n\tqca->ibs_recv_slps = 0;\n\tqca->ibs_recv_wakes = 0;\n\tqca->vote_last_jif = jiffies;\n\tqca->vote_on_ms = 0;\n\tqca->vote_off_ms = 0;\n\tqca->votes_on = 0;\n\tqca->votes_off = 0;\n\tqca->tx_votes_on = 0;\n\tqca->tx_votes_off = 0;\n\tqca->rx_votes_on = 0;\n\tqca->rx_votes_off = 0;\n\n\thu->priv = qca;\n\n\tif (hu->serdev) {\n\n\t\tqcadev = serdev_device_get_drvdata(hu->serdev);\n\t\tif (!qca_is_wcn399x(qcadev->btsoc_type)) {\n\t\t\tgpiod_set_value_cansleep(qcadev->bt_en, 1);\n\t\t\t/* Controller needs time to bootup. */\n\t\t\tmsleep(150);\n\t\t} else {\n\t\t\thu->init_speed = qcadev->init_speed;\n\t\t\thu->oper_speed = qcadev->oper_speed;\n\t\t\tret = qca_power_setup(hu, true);\n\t\t\tif (ret) {\n\t\t\t\tdestroy_workqueue(qca->workqueue);\n\t\t\t\tkfree_skb(qca->rx_skb);\n\t\t\t\thu->priv = NULL;\n\t\t\t\tkfree(qca);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\ttimer_setup(&qca->wake_retrans_timer, hci_ibs_wake_retrans_timeout, 0);\n\tqca->wake_retrans = IBS_WAKE_RETRANS_TIMEOUT_MS;\n\n\ttimer_setup(&qca->tx_idle_timer, hci_ibs_tx_idle_timeout, 0);\n\tqca->tx_idle_delay = IBS_TX_IDLE_TIMEOUT_MS;\n\n\tBT_DBG(\"HCI_UART_QCA open, tx_idle_delay=%u, wake_retrans=%u\",\n\t       qca->tx_idle_delay, qca->wake_retrans);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tint ret;\n \n \tBT_DBG(\"hu %p qca_open\", hu);\n+\n+\tif (!hci_uart_has_flow_control(hu))\n+\t\treturn -EOPNOTSUPP;\n \n \tqca = kzalloc(sizeof(struct qca_data), GFP_KERNEL);\n \tif (!qca)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!hci_uart_has_flow_control(hu))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's Bluetooth implementation of UART, all versions kernel 3.x.x before 4.18.0 and kernel 5.x.x. An attacker with local access and write permissions to the Bluetooth hardware could use this flaw to issue a specially crafted ioctl function call and cause the system to crash.",
        "id": 1900
    },
    {
        "cve_id": "CVE-2023-6679",
        "code_before_change": "static int\ndpll_pin_parent_pin_set(struct dpll_pin *pin, struct nlattr *parent_nest,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[DPLL_A_PIN_MAX + 1];\n\tenum dpll_pin_state state;\n\tu32 ppin_idx;\n\tint ret;\n\n\tnla_parse_nested(tb, DPLL_A_PIN_MAX, parent_nest,\n\t\t\t dpll_pin_parent_pin_nl_policy, extack);\n\tif (!tb[DPLL_A_PIN_PARENT_ID]) {\n\t\tNL_SET_ERR_MSG(extack, \"device parent id expected\");\n\t\treturn -EINVAL;\n\t}\n\tppin_idx = nla_get_u32(tb[DPLL_A_PIN_PARENT_ID]);\n\tstate = nla_get_u32(tb[DPLL_A_PIN_STATE]);\n\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}",
        "code_after_change": "static int\ndpll_pin_parent_pin_set(struct dpll_pin *pin, struct nlattr *parent_nest,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tstruct nlattr *tb[DPLL_A_PIN_MAX + 1];\n\tu32 ppin_idx;\n\tint ret;\n\n\tnla_parse_nested(tb, DPLL_A_PIN_MAX, parent_nest,\n\t\t\t dpll_pin_parent_pin_nl_policy, extack);\n\tif (!tb[DPLL_A_PIN_PARENT_ID]) {\n\t\tNL_SET_ERR_MSG(extack, \"device parent id expected\");\n\t\treturn -EINVAL;\n\t}\n\tppin_idx = nla_get_u32(tb[DPLL_A_PIN_PARENT_ID]);\n\n\tif (tb[DPLL_A_PIN_STATE]) {\n\t\tenum dpll_pin_state state = nla_get_u32(tb[DPLL_A_PIN_STATE]);\n\n\t\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,6 @@\n \t\t\tstruct netlink_ext_ack *extack)\n {\n \tstruct nlattr *tb[DPLL_A_PIN_MAX + 1];\n-\tenum dpll_pin_state state;\n \tu32 ppin_idx;\n \tint ret;\n \n@@ -14,10 +13,14 @@\n \t\treturn -EINVAL;\n \t}\n \tppin_idx = nla_get_u32(tb[DPLL_A_PIN_PARENT_ID]);\n-\tstate = nla_get_u32(tb[DPLL_A_PIN_STATE]);\n-\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);\n-\tif (ret)\n-\t\treturn ret;\n+\n+\tif (tb[DPLL_A_PIN_STATE]) {\n+\t\tenum dpll_pin_state state = nla_get_u32(tb[DPLL_A_PIN_STATE]);\n+\n+\t\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);\n+\t\tif (ret)\n+\t\t\treturn ret;\n+\t}\n \n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (tb[DPLL_A_PIN_STATE]) {",
                "\t\tenum dpll_pin_state state = nla_get_u32(tb[DPLL_A_PIN_STATE]);",
                "",
                "\t\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);",
                "\t\tif (ret)",
                "\t\t\treturn ret;",
                "\t}"
            ],
            "deleted": [
                "\tenum dpll_pin_state state;",
                "\tstate = nla_get_u32(tb[DPLL_A_PIN_STATE]);",
                "\tret = dpll_pin_on_pin_state_set(pin, ppin_idx, state, extack);",
                "\tif (ret)",
                "\t\treturn ret;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference vulnerability was found in dpll_pin_parent_pin_set() in drivers/dpll/dpll_netlink.c in the Digital Phase Locked Loop (DPLL) subsystem in the  Linux kernel. This issue could be exploited to trigger a denial of service.",
        "id": 4308
    },
    {
        "cve_id": "CVE-2018-13094",
        "code_before_change": "int\nxfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\terror = xfs_da_shrink_inode(args, 0, bp);\n\t\tbp = NULL;\n\t\tif (error)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}",
        "code_after_change": "int\nxfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\t/* xfs_attr3_leaf_create may not have instantiated a block */\n\t\tif (bp && (xfs_da_shrink_inode(args, 0, bp) != 0))\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -44,9 +44,8 @@\n \tASSERT(blkno == 0);\n \terror = xfs_attr3_leaf_create(args, blkno, &bp);\n \tif (error) {\n-\t\terror = xfs_da_shrink_inode(args, 0, bp);\n-\t\tbp = NULL;\n-\t\tif (error)\n+\t\t/* xfs_attr3_leaf_create may not have instantiated a block */\n+\t\tif (bp && (xfs_da_shrink_inode(args, 0, bp) != 0))\n \t\t\tgoto out;\n \t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n \t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */",
        "function_modified_lines": {
            "added": [
                "\t\t/* xfs_attr3_leaf_create may not have instantiated a block */",
                "\t\tif (bp && (xfs_da_shrink_inode(args, 0, bp) != 0))"
            ],
            "deleted": [
                "\t\terror = xfs_da_shrink_inode(args, 0, bp);",
                "\t\tbp = NULL;",
                "\t\tif (error)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in fs/xfs/libxfs/xfs_attr_leaf.c in the Linux kernel through 4.17.3. An OOPS may occur for a corrupted xfs image after xfs_da_shrink_inode() is called with a NULL bp.",
        "id": 1669
    },
    {
        "cve_id": "CVE-2023-46862",
        "code_before_change": "__cold void io_uring_show_fdinfo(struct seq_file *m, struct file *f)\n{\n\tstruct io_ring_ctx *ctx = f->private_data;\n\tstruct io_sq_data *sq = NULL;\n\tstruct io_overflow_cqe *ocqe;\n\tstruct io_rings *r = ctx->rings;\n\tunsigned int sq_mask = ctx->sq_entries - 1, cq_mask = ctx->cq_entries - 1;\n\tunsigned int sq_head = READ_ONCE(r->sq.head);\n\tunsigned int sq_tail = READ_ONCE(r->sq.tail);\n\tunsigned int cq_head = READ_ONCE(r->cq.head);\n\tunsigned int cq_tail = READ_ONCE(r->cq.tail);\n\tunsigned int cq_shift = 0;\n\tunsigned int sq_shift = 0;\n\tunsigned int sq_entries, cq_entries;\n\tbool has_lock;\n\tunsigned int i;\n\n\tif (ctx->flags & IORING_SETUP_CQE32)\n\t\tcq_shift = 1;\n\tif (ctx->flags & IORING_SETUP_SQE128)\n\t\tsq_shift = 1;\n\n\t/*\n\t * we may get imprecise sqe and cqe info if uring is actively running\n\t * since we get cached_sq_head and cached_cq_tail without uring_lock\n\t * and sq_tail and cq_head are changed by userspace. But it's ok since\n\t * we usually use these info when it is stuck.\n\t */\n\tseq_printf(m, \"SqMask:\\t0x%x\\n\", sq_mask);\n\tseq_printf(m, \"SqHead:\\t%u\\n\", sq_head);\n\tseq_printf(m, \"SqTail:\\t%u\\n\", sq_tail);\n\tseq_printf(m, \"CachedSqHead:\\t%u\\n\", ctx->cached_sq_head);\n\tseq_printf(m, \"CqMask:\\t0x%x\\n\", cq_mask);\n\tseq_printf(m, \"CqHead:\\t%u\\n\", cq_head);\n\tseq_printf(m, \"CqTail:\\t%u\\n\", cq_tail);\n\tseq_printf(m, \"CachedCqTail:\\t%u\\n\", ctx->cached_cq_tail);\n\tseq_printf(m, \"SQEs:\\t%u\\n\", sq_tail - sq_head);\n\tsq_entries = min(sq_tail - sq_head, ctx->sq_entries);\n\tfor (i = 0; i < sq_entries; i++) {\n\t\tunsigned int entry = i + sq_head;\n\t\tstruct io_uring_sqe *sqe;\n\t\tunsigned int sq_idx;\n\n\t\tif (ctx->flags & IORING_SETUP_NO_SQARRAY)\n\t\t\tbreak;\n\t\tsq_idx = READ_ONCE(ctx->sq_array[entry & sq_mask]);\n\t\tif (sq_idx > sq_mask)\n\t\t\tcontinue;\n\t\tsqe = &ctx->sq_sqes[sq_idx << sq_shift];\n\t\tseq_printf(m, \"%5u: opcode:%s, fd:%d, flags:%x, off:%llu, \"\n\t\t\t      \"addr:0x%llx, rw_flags:0x%x, buf_index:%d \"\n\t\t\t      \"user_data:%llu\",\n\t\t\t   sq_idx, io_uring_get_opcode(sqe->opcode), sqe->fd,\n\t\t\t   sqe->flags, (unsigned long long) sqe->off,\n\t\t\t   (unsigned long long) sqe->addr, sqe->rw_flags,\n\t\t\t   sqe->buf_index, sqe->user_data);\n\t\tif (sq_shift) {\n\t\t\tu64 *sqeb = (void *) (sqe + 1);\n\t\t\tint size = sizeof(struct io_uring_sqe) / sizeof(u64);\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tseq_printf(m, \", e%d:0x%llx\", j,\n\t\t\t\t\t\t(unsigned long long) *sqeb);\n\t\t\t\tsqeb++;\n\t\t\t}\n\t\t}\n\t\tseq_printf(m, \"\\n\");\n\t}\n\tseq_printf(m, \"CQEs:\\t%u\\n\", cq_tail - cq_head);\n\tcq_entries = min(cq_tail - cq_head, ctx->cq_entries);\n\tfor (i = 0; i < cq_entries; i++) {\n\t\tunsigned int entry = i + cq_head;\n\t\tstruct io_uring_cqe *cqe = &r->cqes[(entry & cq_mask) << cq_shift];\n\n\t\tseq_printf(m, \"%5u: user_data:%llu, res:%d, flag:%x\",\n\t\t\t   entry & cq_mask, cqe->user_data, cqe->res,\n\t\t\t   cqe->flags);\n\t\tif (cq_shift)\n\t\t\tseq_printf(m, \", extra1:%llu, extra2:%llu\\n\",\n\t\t\t\t\tcqe->big_cqe[0], cqe->big_cqe[1]);\n\t\tseq_printf(m, \"\\n\");\n\t}\n\n\t/*\n\t * Avoid ABBA deadlock between the seq lock and the io_uring mutex,\n\t * since fdinfo case grabs it in the opposite direction of normal use\n\t * cases. If we fail to get the lock, we just don't iterate any\n\t * structures that could be going away outside the io_uring mutex.\n\t */\n\thas_lock = mutex_trylock(&ctx->uring_lock);\n\n\tif (has_lock && (ctx->flags & IORING_SETUP_SQPOLL)) {\n\t\tsq = ctx->sq_data;\n\t\tif (!sq->thread)\n\t\t\tsq = NULL;\n\t}\n\n\tseq_printf(m, \"SqThread:\\t%d\\n\", sq ? task_pid_nr(sq->thread) : -1);\n\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq ? task_cpu(sq->thread) : -1);\n\tseq_printf(m, \"UserFiles:\\t%u\\n\", ctx->nr_user_files);\n\tfor (i = 0; has_lock && i < ctx->nr_user_files; i++) {\n\t\tstruct file *f = io_file_from_index(&ctx->file_table, i);\n\n\t\tif (f)\n\t\t\tseq_printf(m, \"%5u: %s\\n\", i, file_dentry(f)->d_iname);\n\t\telse\n\t\t\tseq_printf(m, \"%5u: <none>\\n\", i);\n\t}\n\tseq_printf(m, \"UserBufs:\\t%u\\n\", ctx->nr_user_bufs);\n\tfor (i = 0; has_lock && i < ctx->nr_user_bufs; i++) {\n\t\tstruct io_mapped_ubuf *buf = ctx->user_bufs[i];\n\t\tunsigned int len = buf->ubuf_end - buf->ubuf;\n\n\t\tseq_printf(m, \"%5u: 0x%llx/%u\\n\", i, buf->ubuf, len);\n\t}\n\tif (has_lock && !xa_empty(&ctx->personalities)) {\n\t\tunsigned long index;\n\t\tconst struct cred *cred;\n\n\t\tseq_printf(m, \"Personalities:\\n\");\n\t\txa_for_each(&ctx->personalities, index, cred)\n\t\t\tio_uring_show_cred(m, index, cred);\n\t}\n\n\tseq_puts(m, \"PollList:\\n\");\n\tfor (i = 0; i < (1U << ctx->cancel_table.hash_bits); i++) {\n\t\tstruct io_hash_bucket *hb = &ctx->cancel_table.hbs[i];\n\t\tstruct io_hash_bucket *hbl = &ctx->cancel_table_locked.hbs[i];\n\t\tstruct io_kiocb *req;\n\n\t\tspin_lock(&hb->lock);\n\t\thlist_for_each_entry(req, &hb->list, hash_node)\n\t\t\tseq_printf(m, \"  op=%d, task_works=%d\\n\", req->opcode,\n\t\t\t\t\ttask_work_pending(req->task));\n\t\tspin_unlock(&hb->lock);\n\n\t\tif (!has_lock)\n\t\t\tcontinue;\n\t\thlist_for_each_entry(req, &hbl->list, hash_node)\n\t\t\tseq_printf(m, \"  op=%d, task_works=%d\\n\", req->opcode,\n\t\t\t\t\ttask_work_pending(req->task));\n\t}\n\n\tif (has_lock)\n\t\tmutex_unlock(&ctx->uring_lock);\n\n\tseq_puts(m, \"CqOverflowList:\\n\");\n\tspin_lock(&ctx->completion_lock);\n\tlist_for_each_entry(ocqe, &ctx->cq_overflow_list, list) {\n\t\tstruct io_uring_cqe *cqe = &ocqe->cqe;\n\n\t\tseq_printf(m, \"  user_data=%llu, res=%d, flags=%x\\n\",\n\t\t\t   cqe->user_data, cqe->res, cqe->flags);\n\n\t}\n\n\tspin_unlock(&ctx->completion_lock);\n}",
        "code_after_change": "__cold void io_uring_show_fdinfo(struct seq_file *m, struct file *f)\n{\n\tstruct io_ring_ctx *ctx = f->private_data;\n\tstruct io_overflow_cqe *ocqe;\n\tstruct io_rings *r = ctx->rings;\n\tunsigned int sq_mask = ctx->sq_entries - 1, cq_mask = ctx->cq_entries - 1;\n\tunsigned int sq_head = READ_ONCE(r->sq.head);\n\tunsigned int sq_tail = READ_ONCE(r->sq.tail);\n\tunsigned int cq_head = READ_ONCE(r->cq.head);\n\tunsigned int cq_tail = READ_ONCE(r->cq.tail);\n\tunsigned int cq_shift = 0;\n\tunsigned int sq_shift = 0;\n\tunsigned int sq_entries, cq_entries;\n\tint sq_pid = -1, sq_cpu = -1;\n\tbool has_lock;\n\tunsigned int i;\n\n\tif (ctx->flags & IORING_SETUP_CQE32)\n\t\tcq_shift = 1;\n\tif (ctx->flags & IORING_SETUP_SQE128)\n\t\tsq_shift = 1;\n\n\t/*\n\t * we may get imprecise sqe and cqe info if uring is actively running\n\t * since we get cached_sq_head and cached_cq_tail without uring_lock\n\t * and sq_tail and cq_head are changed by userspace. But it's ok since\n\t * we usually use these info when it is stuck.\n\t */\n\tseq_printf(m, \"SqMask:\\t0x%x\\n\", sq_mask);\n\tseq_printf(m, \"SqHead:\\t%u\\n\", sq_head);\n\tseq_printf(m, \"SqTail:\\t%u\\n\", sq_tail);\n\tseq_printf(m, \"CachedSqHead:\\t%u\\n\", ctx->cached_sq_head);\n\tseq_printf(m, \"CqMask:\\t0x%x\\n\", cq_mask);\n\tseq_printf(m, \"CqHead:\\t%u\\n\", cq_head);\n\tseq_printf(m, \"CqTail:\\t%u\\n\", cq_tail);\n\tseq_printf(m, \"CachedCqTail:\\t%u\\n\", ctx->cached_cq_tail);\n\tseq_printf(m, \"SQEs:\\t%u\\n\", sq_tail - sq_head);\n\tsq_entries = min(sq_tail - sq_head, ctx->sq_entries);\n\tfor (i = 0; i < sq_entries; i++) {\n\t\tunsigned int entry = i + sq_head;\n\t\tstruct io_uring_sqe *sqe;\n\t\tunsigned int sq_idx;\n\n\t\tif (ctx->flags & IORING_SETUP_NO_SQARRAY)\n\t\t\tbreak;\n\t\tsq_idx = READ_ONCE(ctx->sq_array[entry & sq_mask]);\n\t\tif (sq_idx > sq_mask)\n\t\t\tcontinue;\n\t\tsqe = &ctx->sq_sqes[sq_idx << sq_shift];\n\t\tseq_printf(m, \"%5u: opcode:%s, fd:%d, flags:%x, off:%llu, \"\n\t\t\t      \"addr:0x%llx, rw_flags:0x%x, buf_index:%d \"\n\t\t\t      \"user_data:%llu\",\n\t\t\t   sq_idx, io_uring_get_opcode(sqe->opcode), sqe->fd,\n\t\t\t   sqe->flags, (unsigned long long) sqe->off,\n\t\t\t   (unsigned long long) sqe->addr, sqe->rw_flags,\n\t\t\t   sqe->buf_index, sqe->user_data);\n\t\tif (sq_shift) {\n\t\t\tu64 *sqeb = (void *) (sqe + 1);\n\t\t\tint size = sizeof(struct io_uring_sqe) / sizeof(u64);\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tseq_printf(m, \", e%d:0x%llx\", j,\n\t\t\t\t\t\t(unsigned long long) *sqeb);\n\t\t\t\tsqeb++;\n\t\t\t}\n\t\t}\n\t\tseq_printf(m, \"\\n\");\n\t}\n\tseq_printf(m, \"CQEs:\\t%u\\n\", cq_tail - cq_head);\n\tcq_entries = min(cq_tail - cq_head, ctx->cq_entries);\n\tfor (i = 0; i < cq_entries; i++) {\n\t\tunsigned int entry = i + cq_head;\n\t\tstruct io_uring_cqe *cqe = &r->cqes[(entry & cq_mask) << cq_shift];\n\n\t\tseq_printf(m, \"%5u: user_data:%llu, res:%d, flag:%x\",\n\t\t\t   entry & cq_mask, cqe->user_data, cqe->res,\n\t\t\t   cqe->flags);\n\t\tif (cq_shift)\n\t\t\tseq_printf(m, \", extra1:%llu, extra2:%llu\\n\",\n\t\t\t\t\tcqe->big_cqe[0], cqe->big_cqe[1]);\n\t\tseq_printf(m, \"\\n\");\n\t}\n\n\t/*\n\t * Avoid ABBA deadlock between the seq lock and the io_uring mutex,\n\t * since fdinfo case grabs it in the opposite direction of normal use\n\t * cases. If we fail to get the lock, we just don't iterate any\n\t * structures that could be going away outside the io_uring mutex.\n\t */\n\thas_lock = mutex_trylock(&ctx->uring_lock);\n\n\tif (has_lock && (ctx->flags & IORING_SETUP_SQPOLL)) {\n\t\tstruct io_sq_data *sq = ctx->sq_data;\n\n\t\tif (mutex_trylock(&sq->lock)) {\n\t\t\tif (sq->thread) {\n\t\t\t\tsq_pid = task_pid_nr(sq->thread);\n\t\t\t\tsq_cpu = task_cpu(sq->thread);\n\t\t\t}\n\t\t\tmutex_unlock(&sq->lock);\n\t\t}\n\t}\n\n\tseq_printf(m, \"SqThread:\\t%d\\n\", sq_pid);\n\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq_cpu);\n\tseq_printf(m, \"UserFiles:\\t%u\\n\", ctx->nr_user_files);\n\tfor (i = 0; has_lock && i < ctx->nr_user_files; i++) {\n\t\tstruct file *f = io_file_from_index(&ctx->file_table, i);\n\n\t\tif (f)\n\t\t\tseq_printf(m, \"%5u: %s\\n\", i, file_dentry(f)->d_iname);\n\t\telse\n\t\t\tseq_printf(m, \"%5u: <none>\\n\", i);\n\t}\n\tseq_printf(m, \"UserBufs:\\t%u\\n\", ctx->nr_user_bufs);\n\tfor (i = 0; has_lock && i < ctx->nr_user_bufs; i++) {\n\t\tstruct io_mapped_ubuf *buf = ctx->user_bufs[i];\n\t\tunsigned int len = buf->ubuf_end - buf->ubuf;\n\n\t\tseq_printf(m, \"%5u: 0x%llx/%u\\n\", i, buf->ubuf, len);\n\t}\n\tif (has_lock && !xa_empty(&ctx->personalities)) {\n\t\tunsigned long index;\n\t\tconst struct cred *cred;\n\n\t\tseq_printf(m, \"Personalities:\\n\");\n\t\txa_for_each(&ctx->personalities, index, cred)\n\t\t\tio_uring_show_cred(m, index, cred);\n\t}\n\n\tseq_puts(m, \"PollList:\\n\");\n\tfor (i = 0; i < (1U << ctx->cancel_table.hash_bits); i++) {\n\t\tstruct io_hash_bucket *hb = &ctx->cancel_table.hbs[i];\n\t\tstruct io_hash_bucket *hbl = &ctx->cancel_table_locked.hbs[i];\n\t\tstruct io_kiocb *req;\n\n\t\tspin_lock(&hb->lock);\n\t\thlist_for_each_entry(req, &hb->list, hash_node)\n\t\t\tseq_printf(m, \"  op=%d, task_works=%d\\n\", req->opcode,\n\t\t\t\t\ttask_work_pending(req->task));\n\t\tspin_unlock(&hb->lock);\n\n\t\tif (!has_lock)\n\t\t\tcontinue;\n\t\thlist_for_each_entry(req, &hbl->list, hash_node)\n\t\t\tseq_printf(m, \"  op=%d, task_works=%d\\n\", req->opcode,\n\t\t\t\t\ttask_work_pending(req->task));\n\t}\n\n\tif (has_lock)\n\t\tmutex_unlock(&ctx->uring_lock);\n\n\tseq_puts(m, \"CqOverflowList:\\n\");\n\tspin_lock(&ctx->completion_lock);\n\tlist_for_each_entry(ocqe, &ctx->cq_overflow_list, list) {\n\t\tstruct io_uring_cqe *cqe = &ocqe->cqe;\n\n\t\tseq_printf(m, \"  user_data=%llu, res=%d, flags=%x\\n\",\n\t\t\t   cqe->user_data, cqe->res, cqe->flags);\n\n\t}\n\n\tspin_unlock(&ctx->completion_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,6 @@\n __cold void io_uring_show_fdinfo(struct seq_file *m, struct file *f)\n {\n \tstruct io_ring_ctx *ctx = f->private_data;\n-\tstruct io_sq_data *sq = NULL;\n \tstruct io_overflow_cqe *ocqe;\n \tstruct io_rings *r = ctx->rings;\n \tunsigned int sq_mask = ctx->sq_entries - 1, cq_mask = ctx->cq_entries - 1;\n@@ -12,6 +11,7 @@\n \tunsigned int cq_shift = 0;\n \tunsigned int sq_shift = 0;\n \tunsigned int sq_entries, cq_entries;\n+\tint sq_pid = -1, sq_cpu = -1;\n \tbool has_lock;\n \tunsigned int i;\n \n@@ -91,13 +91,19 @@\n \thas_lock = mutex_trylock(&ctx->uring_lock);\n \n \tif (has_lock && (ctx->flags & IORING_SETUP_SQPOLL)) {\n-\t\tsq = ctx->sq_data;\n-\t\tif (!sq->thread)\n-\t\t\tsq = NULL;\n+\t\tstruct io_sq_data *sq = ctx->sq_data;\n+\n+\t\tif (mutex_trylock(&sq->lock)) {\n+\t\t\tif (sq->thread) {\n+\t\t\t\tsq_pid = task_pid_nr(sq->thread);\n+\t\t\t\tsq_cpu = task_cpu(sq->thread);\n+\t\t\t}\n+\t\t\tmutex_unlock(&sq->lock);\n+\t\t}\n \t}\n \n-\tseq_printf(m, \"SqThread:\\t%d\\n\", sq ? task_pid_nr(sq->thread) : -1);\n-\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq ? task_cpu(sq->thread) : -1);\n+\tseq_printf(m, \"SqThread:\\t%d\\n\", sq_pid);\n+\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq_cpu);\n \tseq_printf(m, \"UserFiles:\\t%u\\n\", ctx->nr_user_files);\n \tfor (i = 0; has_lock && i < ctx->nr_user_files; i++) {\n \t\tstruct file *f = io_file_from_index(&ctx->file_table, i);",
        "function_modified_lines": {
            "added": [
                "\tint sq_pid = -1, sq_cpu = -1;",
                "\t\tstruct io_sq_data *sq = ctx->sq_data;",
                "",
                "\t\tif (mutex_trylock(&sq->lock)) {",
                "\t\t\tif (sq->thread) {",
                "\t\t\t\tsq_pid = task_pid_nr(sq->thread);",
                "\t\t\t\tsq_cpu = task_cpu(sq->thread);",
                "\t\t\t}",
                "\t\t\tmutex_unlock(&sq->lock);",
                "\t\t}",
                "\tseq_printf(m, \"SqThread:\\t%d\\n\", sq_pid);",
                "\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq_cpu);"
            ],
            "deleted": [
                "\tstruct io_sq_data *sq = NULL;",
                "\t\tsq = ctx->sq_data;",
                "\t\tif (!sq->thread)",
                "\t\t\tsq = NULL;",
                "\tseq_printf(m, \"SqThread:\\t%d\\n\", sq ? task_pid_nr(sq->thread) : -1);",
                "\tseq_printf(m, \"SqThreadCpu:\\t%d\\n\", sq ? task_cpu(sq->thread) : -1);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 6.5.9. During a race with SQ thread exit, an io_uring/fdinfo.c io_uring_show_fdinfo NULL pointer dereference can occur.",
        "id": 4242
    },
    {
        "cve_id": "CVE-2017-5970",
        "code_before_change": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\tskb_dst_drop(skb);\n}",
        "code_after_change": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\t/* We need to keep the dst for __ip_options_echo()\n\t * We could restrict the test to opt.ts_needtime || opt.srr,\n\t * but the following is good enough as IP options are not often used.\n\t */\n\tif (unlikely(IPCB(skb)->opt.optlen))\n\t\tskb_dst_force(skb);\n\telse\n\t\tskb_dst_drop(skb);\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,5 +22,12 @@\n \t\tpktinfo->ipi_ifindex = 0;\n \t\tpktinfo->ipi_spec_dst.s_addr = 0;\n \t}\n-\tskb_dst_drop(skb);\n+\t/* We need to keep the dst for __ip_options_echo()\n+\t * We could restrict the test to opt.ts_needtime || opt.srr,\n+\t * but the following is good enough as IP options are not often used.\n+\t */\n+\tif (unlikely(IPCB(skb)->opt.optlen))\n+\t\tskb_dst_force(skb);\n+\telse\n+\t\tskb_dst_drop(skb);\n }",
        "function_modified_lines": {
            "added": [
                "\t/* We need to keep the dst for __ip_options_echo()",
                "\t * We could restrict the test to opt.ts_needtime || opt.srr,",
                "\t * but the following is good enough as IP options are not often used.",
                "\t */",
                "\tif (unlikely(IPCB(skb)->opt.optlen))",
                "\t\tskb_dst_force(skb);",
                "\telse",
                "\t\tskb_dst_drop(skb);"
            ],
            "deleted": [
                "\tskb_dst_drop(skb);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The ipv4_pktinfo_prepare function in net/ipv4/ip_sockglue.c in the Linux kernel through 4.9.9 allows attackers to cause a denial of service (system crash) via (1) an application that makes crafted system calls or possibly (2) IPv4 traffic with invalid IP options.",
        "id": 1474
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int stk7700P2_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n\t\t    != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\t\tdvb_detach(&state->dib7000p_ops);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t   0x80 + (adap->id << 1),\n\t\t\t   &stk7700d_dib7000p_mt2266_config[adap->id]);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int stk7700P2_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n\t\t    != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t   0x80 + (adap->id << 1),\n\t\t\t   &stk7700d_dib7000p_mt2266_config[adap->id]);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n \t\t    != 0) {\n \t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n-\t\t\tdvb_detach(&state->dib7000p_ops);\n+\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\t\treturn -ENODEV;\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1339
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int adjust_ptr_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t   struct bpf_insn *insn,\n\t\t\t\t   const struct bpf_reg_state *ptr_reg,\n\t\t\t\t   const struct bpf_reg_state *off_reg)\n{\n\tstruct bpf_verifier_state *vstate = env->cur_state;\n\tstruct bpf_func_state *state = vstate->frame[vstate->curframe];\n\tstruct bpf_reg_state *regs = state->regs, *dst_reg;\n\tbool known = tnum_is_const(off_reg->var_off);\n\ts64 smin_val = off_reg->smin_value, smax_val = off_reg->smax_value,\n\t    smin_ptr = ptr_reg->smin_value, smax_ptr = ptr_reg->smax_value;\n\tu64 umin_val = off_reg->umin_value, umax_val = off_reg->umax_value,\n\t    umin_ptr = ptr_reg->umin_value, umax_ptr = ptr_reg->umax_value;\n\tstruct bpf_sanitize_info info = {};\n\tu8 opcode = BPF_OP(insn->code);\n\tu32 dst = insn->dst_reg;\n\tint ret;\n\n\tdst_reg = &regs[dst];\n\n\tif ((known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(env, dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops on pointers produce (meaningless) scalars */\n\t\tif (opcode == BPF_SUB && env->allow_ptr_leaks) {\n\t\t\t__mark_reg_unknown(env, dst_reg);\n\t\t\treturn 0;\n\t\t}\n\n\t\tverbose(env,\n\t\t\t\"R%d 32-bit pointer arithmetic prohibited\\n\",\n\t\t\tdst);\n\t\treturn -EACCES;\n\t}\n\n\tswitch (ptr_reg->type) {\n\tcase PTR_TO_MAP_VALUE_OR_NULL:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited, null-check it first\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tcase CONST_PTR_TO_MAP:\n\t\t/* smin_val represents the known value */\n\t\tif (known && smin_val == 0 && opcode == BPF_ADD)\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited\\n\",\n\t\t\tdst, reg_type_str[ptr_reg->type]);\n\t\treturn -EACCES;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t/* In case of 'scalar += pointer', dst_reg inherits pointer type and id.\n\t * The id may be overwritten later if we create a new variable offset.\n\t */\n\tdst_reg->type = ptr_reg->type;\n\tdst_reg->id = ptr_reg->id;\n\n\tif (!check_reg_sane_offset(env, off_reg, ptr_reg->type) ||\n\t    !check_reg_sane_offset(env, ptr_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t/* pointer types do not carry 32-bit bounds at the moment. */\n\t__mark_reg32_unbounded(dst_reg);\n\n\tif (sanitize_needed(opcode)) {\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, off_reg, dst_reg,\n\t\t\t\t       &info, false);\n\t\tif (ret < 0)\n\t\t\treturn sanitize_err(env, insn, ret, off_reg, dst_reg);\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\t/* We can take a fixed offset as long as it doesn't overflow\n\t\t * the s32 'off' field\n\t\t */\n\t\tif (known && (ptr_reg->off + smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off + smin_val))) {\n\t\t\t/* pointer += K.  Accumulate it into fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->off = ptr_reg->off + smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  Note that off_reg->off\n\t\t * == 0, since it's a scalar.\n\t\t * dst_reg gets the pointer type and since some positive\n\t\t * integer value was added to the pointer, give it a new 'id'\n\t\t * if it's a PTR_TO_PACKET.\n\t\t * this creates a new 'base' pointer, off_reg (variable) gets\n\t\t * added into the variable offset, and we copy the fixed offset\n\t\t * from ptr_reg.\n\t\t */\n\t\tif (signed_add_overflows(smin_ptr, smin_val) ||\n\t\t    signed_add_overflows(smax_ptr, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr + smin_val;\n\t\t\tdst_reg->smax_value = smax_ptr + smax_val;\n\t\t}\n\t\tif (umin_ptr + umin_val < umin_ptr ||\n\t\t    umax_ptr + umax_val < umax_ptr) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value = umin_ptr + umin_val;\n\t\t\tdst_reg->umax_value = umax_ptr + umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (dst_reg == off_reg) {\n\t\t\t/* scalar -= pointer.  Creates an unknown scalar */\n\t\t\tverbose(env, \"R%d tried to subtract pointer from scalar\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* We don't allow subtraction from FP, because (according to\n\t\t * test_verifier.c test \"invalid fp arithmetic\", JITs might not\n\t\t * be able to deal with it.\n\t\t */\n\t\tif (ptr_reg->type == PTR_TO_STACK) {\n\t\t\tverbose(env, \"R%d subtraction from stack pointer prohibited\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (known && (ptr_reg->off - smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off - smin_val))) {\n\t\t\t/* pointer -= K.  Subtract it from fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->id = ptr_reg->id;\n\t\t\tdst_reg->off = ptr_reg->off - smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  If the subtrahend is known\n\t\t * nonnegative, then any reg->range we had before is still good.\n\t\t */\n\t\tif (signed_sub_overflows(smin_ptr, smax_val) ||\n\t\t    signed_sub_overflows(smax_ptr, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr - smax_val;\n\t\t\tdst_reg->smax_value = smax_ptr - smin_val;\n\t\t}\n\t\tif (umin_ptr < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value = umin_ptr - umax_val;\n\t\t\tdst_reg->umax_value = umax_ptr - umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tif (smin_val < 0)\n\t\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\tcase BPF_OR:\n\tcase BPF_XOR:\n\t\t/* bitwise ops on pointers are troublesome, prohibit. */\n\t\tverbose(env, \"R%d bitwise operator %s on pointer prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\tdefault:\n\t\t/* other operators (e.g. MUL,LSH) produce non-pointer results */\n\t\tverbose(env, \"R%d pointer arithmetic with %s operator prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!check_reg_sane_offset(env, dst_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t__update_reg_bounds(dst_reg);\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\n\tif (sanitize_check_bounds(env, insn, dst_reg) < 0)\n\t\treturn -EACCES;\n\tif (sanitize_needed(opcode)) {\n\t\tret = sanitize_ptr_alu(env, insn, dst_reg, off_reg, dst_reg,\n\t\t\t\t       &info, true);\n\t\tif (ret < 0)\n\t\t\treturn sanitize_err(env, insn, ret, off_reg, dst_reg);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int adjust_ptr_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t   struct bpf_insn *insn,\n\t\t\t\t   const struct bpf_reg_state *ptr_reg,\n\t\t\t\t   const struct bpf_reg_state *off_reg)\n{\n\tstruct bpf_verifier_state *vstate = env->cur_state;\n\tstruct bpf_func_state *state = vstate->frame[vstate->curframe];\n\tstruct bpf_reg_state *regs = state->regs, *dst_reg;\n\tbool known = tnum_is_const(off_reg->var_off);\n\ts64 smin_val = off_reg->smin_value, smax_val = off_reg->smax_value,\n\t    smin_ptr = ptr_reg->smin_value, smax_ptr = ptr_reg->smax_value;\n\tu64 umin_val = off_reg->umin_value, umax_val = off_reg->umax_value,\n\t    umin_ptr = ptr_reg->umin_value, umax_ptr = ptr_reg->umax_value;\n\tstruct bpf_sanitize_info info = {};\n\tu8 opcode = BPF_OP(insn->code);\n\tu32 dst = insn->dst_reg;\n\tint ret;\n\n\tdst_reg = &regs[dst];\n\n\tif ((known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(env, dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops on pointers produce (meaningless) scalars */\n\t\tif (opcode == BPF_SUB && env->allow_ptr_leaks) {\n\t\t\t__mark_reg_unknown(env, dst_reg);\n\t\t\treturn 0;\n\t\t}\n\n\t\tverbose(env,\n\t\t\t\"R%d 32-bit pointer arithmetic prohibited\\n\",\n\t\t\tdst);\n\t\treturn -EACCES;\n\t}\n\n\tif (ptr_reg->type & PTR_MAYBE_NULL) {\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited, null-check it first\\n\",\n\t\t\tdst, reg_type_str(env, ptr_reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tswitch (base_type(ptr_reg->type)) {\n\tcase CONST_PTR_TO_MAP:\n\t\t/* smin_val represents the known value */\n\t\tif (known && smin_val == 0 && opcode == BPF_ADD)\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase PTR_TO_PACKET_END:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_XDP_SOCK:\n\t\tverbose(env, \"R%d pointer arithmetic on %s prohibited\\n\",\n\t\t\tdst, reg_type_str(env, ptr_reg->type));\n\t\treturn -EACCES;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t/* In case of 'scalar += pointer', dst_reg inherits pointer type and id.\n\t * The id may be overwritten later if we create a new variable offset.\n\t */\n\tdst_reg->type = ptr_reg->type;\n\tdst_reg->id = ptr_reg->id;\n\n\tif (!check_reg_sane_offset(env, off_reg, ptr_reg->type) ||\n\t    !check_reg_sane_offset(env, ptr_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t/* pointer types do not carry 32-bit bounds at the moment. */\n\t__mark_reg32_unbounded(dst_reg);\n\n\tif (sanitize_needed(opcode)) {\n\t\tret = sanitize_ptr_alu(env, insn, ptr_reg, off_reg, dst_reg,\n\t\t\t\t       &info, false);\n\t\tif (ret < 0)\n\t\t\treturn sanitize_err(env, insn, ret, off_reg, dst_reg);\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\t/* We can take a fixed offset as long as it doesn't overflow\n\t\t * the s32 'off' field\n\t\t */\n\t\tif (known && (ptr_reg->off + smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off + smin_val))) {\n\t\t\t/* pointer += K.  Accumulate it into fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->off = ptr_reg->off + smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  Note that off_reg->off\n\t\t * == 0, since it's a scalar.\n\t\t * dst_reg gets the pointer type and since some positive\n\t\t * integer value was added to the pointer, give it a new 'id'\n\t\t * if it's a PTR_TO_PACKET.\n\t\t * this creates a new 'base' pointer, off_reg (variable) gets\n\t\t * added into the variable offset, and we copy the fixed offset\n\t\t * from ptr_reg.\n\t\t */\n\t\tif (signed_add_overflows(smin_ptr, smin_val) ||\n\t\t    signed_add_overflows(smax_ptr, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr + smin_val;\n\t\t\tdst_reg->smax_value = smax_ptr + smax_val;\n\t\t}\n\t\tif (umin_ptr + umin_val < umin_ptr ||\n\t\t    umax_ptr + umax_val < umax_ptr) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value = umin_ptr + umin_val;\n\t\t\tdst_reg->umax_value = umax_ptr + umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (dst_reg == off_reg) {\n\t\t\t/* scalar -= pointer.  Creates an unknown scalar */\n\t\t\tverbose(env, \"R%d tried to subtract pointer from scalar\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\t/* We don't allow subtraction from FP, because (according to\n\t\t * test_verifier.c test \"invalid fp arithmetic\", JITs might not\n\t\t * be able to deal with it.\n\t\t */\n\t\tif (ptr_reg->type == PTR_TO_STACK) {\n\t\t\tverbose(env, \"R%d subtraction from stack pointer prohibited\\n\",\n\t\t\t\tdst);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (known && (ptr_reg->off - smin_val ==\n\t\t\t      (s64)(s32)(ptr_reg->off - smin_val))) {\n\t\t\t/* pointer -= K.  Subtract it from fixed offset */\n\t\t\tdst_reg->smin_value = smin_ptr;\n\t\t\tdst_reg->smax_value = smax_ptr;\n\t\t\tdst_reg->umin_value = umin_ptr;\n\t\t\tdst_reg->umax_value = umax_ptr;\n\t\t\tdst_reg->var_off = ptr_reg->var_off;\n\t\t\tdst_reg->id = ptr_reg->id;\n\t\t\tdst_reg->off = ptr_reg->off - smin_val;\n\t\t\tdst_reg->raw = ptr_reg->raw;\n\t\t\tbreak;\n\t\t}\n\t\t/* A new variable offset is created.  If the subtrahend is known\n\t\t * nonnegative, then any reg->range we had before is still good.\n\t\t */\n\t\tif (signed_sub_overflows(smin_ptr, smax_val) ||\n\t\t    signed_sub_overflows(smax_ptr, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = smin_ptr - smax_val;\n\t\t\tdst_reg->smax_value = smax_ptr - smin_val;\n\t\t}\n\t\tif (umin_ptr < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value = umin_ptr - umax_val;\n\t\t\tdst_reg->umax_value = umax_ptr - umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(ptr_reg->var_off, off_reg->var_off);\n\t\tdst_reg->off = ptr_reg->off;\n\t\tdst_reg->raw = ptr_reg->raw;\n\t\tif (reg_is_pkt_pointer(ptr_reg)) {\n\t\t\tdst_reg->id = ++env->id_gen;\n\t\t\t/* something was added to pkt_ptr, set range to zero */\n\t\t\tif (smin_val < 0)\n\t\t\t\tmemset(&dst_reg->raw, 0, sizeof(dst_reg->raw));\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\tcase BPF_OR:\n\tcase BPF_XOR:\n\t\t/* bitwise ops on pointers are troublesome, prohibit. */\n\t\tverbose(env, \"R%d bitwise operator %s on pointer prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\tdefault:\n\t\t/* other operators (e.g. MUL,LSH) produce non-pointer results */\n\t\tverbose(env, \"R%d pointer arithmetic with %s operator prohibited\\n\",\n\t\t\tdst, bpf_alu_string[opcode >> 4]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!check_reg_sane_offset(env, dst_reg, ptr_reg->type))\n\t\treturn -EINVAL;\n\n\t__update_reg_bounds(dst_reg);\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\n\tif (sanitize_check_bounds(env, insn, dst_reg) < 0)\n\t\treturn -EACCES;\n\tif (sanitize_needed(opcode)) {\n\t\tret = sanitize_ptr_alu(env, insn, dst_reg, off_reg, dst_reg,\n\t\t\t\t       &info, true);\n\t\tif (ret < 0)\n\t\t\treturn sanitize_err(env, insn, ret, off_reg, dst_reg);\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -40,11 +40,13 @@\n \t\treturn -EACCES;\n \t}\n \n-\tswitch (ptr_reg->type) {\n-\tcase PTR_TO_MAP_VALUE_OR_NULL:\n+\tif (ptr_reg->type & PTR_MAYBE_NULL) {\n \t\tverbose(env, \"R%d pointer arithmetic on %s prohibited, null-check it first\\n\",\n-\t\t\tdst, reg_type_str[ptr_reg->type]);\n-\t\treturn -EACCES;\n+\t\t\tdst, reg_type_str(env, ptr_reg->type));\n+\t\treturn -EACCES;\n+\t}\n+\n+\tswitch (base_type(ptr_reg->type)) {\n \tcase CONST_PTR_TO_MAP:\n \t\t/* smin_val represents the known value */\n \t\tif (known && smin_val == 0 && opcode == BPF_ADD)\n@@ -52,14 +54,11 @@\n \t\tfallthrough;\n \tcase PTR_TO_PACKET_END:\n \tcase PTR_TO_SOCKET:\n-\tcase PTR_TO_SOCKET_OR_NULL:\n \tcase PTR_TO_SOCK_COMMON:\n-\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n \tcase PTR_TO_TCP_SOCK:\n-\tcase PTR_TO_TCP_SOCK_OR_NULL:\n \tcase PTR_TO_XDP_SOCK:\n \t\tverbose(env, \"R%d pointer arithmetic on %s prohibited\\n\",\n-\t\t\tdst, reg_type_str[ptr_reg->type]);\n+\t\t\tdst, reg_type_str(env, ptr_reg->type));\n \t\treturn -EACCES;\n \tdefault:\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\tif (ptr_reg->type & PTR_MAYBE_NULL) {",
                "\t\t\tdst, reg_type_str(env, ptr_reg->type));",
                "\t\treturn -EACCES;",
                "\t}",
                "",
                "\tswitch (base_type(ptr_reg->type)) {",
                "\t\t\tdst, reg_type_str(env, ptr_reg->type));"
            ],
            "deleted": [
                "\tswitch (ptr_reg->type) {",
                "\tcase PTR_TO_MAP_VALUE_OR_NULL:",
                "\t\t\tdst, reg_type_str[ptr_reg->type]);",
                "\t\treturn -EACCES;",
                "\tcase PTR_TO_SOCKET_OR_NULL:",
                "\tcase PTR_TO_SOCK_COMMON_OR_NULL:",
                "\tcase PTR_TO_TCP_SOCK_OR_NULL:",
                "\t\t\tdst, reg_type_str[ptr_reg->type]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3457
    },
    {
        "cve_id": "CVE-2022-3114",
        "code_before_change": "void imx_register_uart_clocks(unsigned int clk_count)\n{\n\timx_enabled_uart_clocks = 0;\n\n/* i.MX boards use device trees now.  For build tests without CONFIG_OF, do nothing */\n#ifdef CONFIG_OF\n\tif (imx_keep_uart_clocks) {\n\t\tint i;\n\n\t\timx_uart_clocks = kcalloc(clk_count, sizeof(struct clk *), GFP_KERNEL);\n\n\t\tif (!of_stdout)\n\t\t\treturn;\n\n\t\tfor (i = 0; i < clk_count; i++) {\n\t\t\timx_uart_clocks[imx_enabled_uart_clocks] = of_clk_get(of_stdout, i);\n\n\t\t\t/* Stop if there are no more of_stdout references */\n\t\t\tif (IS_ERR(imx_uart_clocks[imx_enabled_uart_clocks]))\n\t\t\t\treturn;\n\n\t\t\t/* Only enable the clock if it's not NULL */\n\t\t\tif (imx_uart_clocks[imx_enabled_uart_clocks])\n\t\t\t\tclk_prepare_enable(imx_uart_clocks[imx_enabled_uart_clocks++]);\n\t\t}\n\t}\n#endif\n}",
        "code_after_change": "void imx_register_uart_clocks(unsigned int clk_count)\n{\n\timx_enabled_uart_clocks = 0;\n\n/* i.MX boards use device trees now.  For build tests without CONFIG_OF, do nothing */\n#ifdef CONFIG_OF\n\tif (imx_keep_uart_clocks) {\n\t\tint i;\n\n\t\timx_uart_clocks = kcalloc(clk_count, sizeof(struct clk *), GFP_KERNEL);\n\t\tif (!imx_uart_clocks)\n\t\t\treturn;\n\n\t\tif (!of_stdout)\n\t\t\treturn;\n\n\t\tfor (i = 0; i < clk_count; i++) {\n\t\t\timx_uart_clocks[imx_enabled_uart_clocks] = of_clk_get(of_stdout, i);\n\n\t\t\t/* Stop if there are no more of_stdout references */\n\t\t\tif (IS_ERR(imx_uart_clocks[imx_enabled_uart_clocks]))\n\t\t\t\treturn;\n\n\t\t\t/* Only enable the clock if it's not NULL */\n\t\t\tif (imx_uart_clocks[imx_enabled_uart_clocks])\n\t\t\t\tclk_prepare_enable(imx_uart_clocks[imx_enabled_uart_clocks++]);\n\t\t}\n\t}\n#endif\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,8 @@\n \t\tint i;\n \n \t\timx_uart_clocks = kcalloc(clk_count, sizeof(struct clk *), GFP_KERNEL);\n+\t\tif (!imx_uart_clocks)\n+\t\t\treturn;\n \n \t\tif (!of_stdout)\n \t\t\treturn;",
        "function_modified_lines": {
            "added": [
                "\t\tif (!imx_uart_clocks)",
                "\t\t\treturn;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. imx_register_uart_clocks in drivers/clk/imx/clk.c lacks check of the return value of kcalloc() and will cause the null pointer dereference.",
        "id": 3560
    },
    {
        "cve_id": "CVE-2023-23006",
        "code_before_change": "static int dr_domain_init_resources(struct mlx5dr_domain *dmn)\n{\n\tint ret;\n\n\tdmn->ste_ctx = mlx5dr_ste_get_ctx(dmn->info.caps.sw_format_ver);\n\tif (!dmn->ste_ctx) {\n\t\tmlx5dr_err(dmn, \"SW Steering on this device is unsupported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tret = mlx5_core_alloc_pd(dmn->mdev, &dmn->pdn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate PD, ret: %d\", ret);\n\t\treturn ret;\n\t}\n\n\tdmn->uar = mlx5_get_uars_page(dmn->mdev);\n\tif (!dmn->uar) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate UAR\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto clean_pd;\n\t}\n\n\tdmn->ste_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_STE);\n\tif (!dmn->ste_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto clean_uar;\n\t}\n\n\tdmn->action_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_MODIFY_ACTION);\n\tif (!dmn->action_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get action icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_ste_icm_pool;\n\t}\n\n\tret = mlx5dr_send_ring_alloc(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create send-ring\\n\");\n\t\tgoto free_action_icm_pool;\n\t}\n\n\treturn 0;\n\nfree_action_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->action_icm_pool);\nfree_ste_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->ste_icm_pool);\nclean_uar:\n\tmlx5_put_uars_page(dmn->mdev, dmn->uar);\nclean_pd:\n\tmlx5_core_dealloc_pd(dmn->mdev, dmn->pdn);\n\n\treturn ret;\n}",
        "code_after_change": "static int dr_domain_init_resources(struct mlx5dr_domain *dmn)\n{\n\tint ret;\n\n\tdmn->ste_ctx = mlx5dr_ste_get_ctx(dmn->info.caps.sw_format_ver);\n\tif (!dmn->ste_ctx) {\n\t\tmlx5dr_err(dmn, \"SW Steering on this device is unsupported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tret = mlx5_core_alloc_pd(dmn->mdev, &dmn->pdn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate PD, ret: %d\", ret);\n\t\treturn ret;\n\t}\n\n\tdmn->uar = mlx5_get_uars_page(dmn->mdev);\n\tif (IS_ERR(dmn->uar)) {\n\t\tmlx5dr_err(dmn, \"Couldn't allocate UAR\\n\");\n\t\tret = PTR_ERR(dmn->uar);\n\t\tgoto clean_pd;\n\t}\n\n\tdmn->ste_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_STE);\n\tif (!dmn->ste_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto clean_uar;\n\t}\n\n\tdmn->action_icm_pool = mlx5dr_icm_pool_create(dmn, DR_ICM_TYPE_MODIFY_ACTION);\n\tif (!dmn->action_icm_pool) {\n\t\tmlx5dr_err(dmn, \"Couldn't get action icm memory\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_ste_icm_pool;\n\t}\n\n\tret = mlx5dr_send_ring_alloc(dmn);\n\tif (ret) {\n\t\tmlx5dr_err(dmn, \"Couldn't create send-ring\\n\");\n\t\tgoto free_action_icm_pool;\n\t}\n\n\treturn 0;\n\nfree_action_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->action_icm_pool);\nfree_ste_icm_pool:\n\tmlx5dr_icm_pool_destroy(dmn->ste_icm_pool);\nclean_uar:\n\tmlx5_put_uars_page(dmn->mdev, dmn->uar);\nclean_pd:\n\tmlx5_core_dealloc_pd(dmn->mdev, dmn->pdn);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,9 +15,9 @@\n \t}\n \n \tdmn->uar = mlx5_get_uars_page(dmn->mdev);\n-\tif (!dmn->uar) {\n+\tif (IS_ERR(dmn->uar)) {\n \t\tmlx5dr_err(dmn, \"Couldn't allocate UAR\\n\");\n-\t\tret = -ENOMEM;\n+\t\tret = PTR_ERR(dmn->uar);\n \t\tgoto clean_pd;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tif (IS_ERR(dmn->uar)) {",
                "\t\tret = PTR_ERR(dmn->uar);"
            ],
            "deleted": [
                "\tif (!dmn->uar) {",
                "\t\tret = -ENOMEM;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.15.13, drivers/net/ethernet/mellanox/mlx5/core/steering/dr_domain.c misinterprets the mlx5_get_uars_page return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3949
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (reg->type == PTR_TO_MEM) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (reg_type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (reg_type == PTR_TO_BTF_ID ||\n\t\t\t\t    reg_type == PTR_TO_BTF_ID_OR_NULL) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str[reg->type]);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == PTR_TO_RDONLY_BUF) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str[reg->type]);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  \"rdonly\",\n\t\t\t\t\t  &env->prog->aux->max_rdonly_access);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_RDWR_BUF) {\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  \"rdwr\",\n\t\t\t\t\t  &env->prog->aux->max_rdwr_access);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str[reg->type]);\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "code_after_change": "static int check_mem_access(struct bpf_verifier_env *env, int insn_idx, u32 regno,\n\t\t\t    int off, int bpf_size, enum bpf_access_type t,\n\t\t\t    int value_regno, bool strict_alignment_once)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tstruct bpf_reg_state *reg = regs + regno;\n\tstruct bpf_func_state *state;\n\tint size, err = 0;\n\n\tsize = bpf_size_to_bytes(bpf_size);\n\tif (size < 0)\n\t\treturn size;\n\n\t/* alignment checks will add in reg->off themselves */\n\terr = check_ptr_alignment(env, reg, off, size, strict_alignment_once);\n\tif (err)\n\t\treturn err;\n\n\t/* for access checks, reg->off is just part of off */\n\toff += reg->off;\n\n\tif (reg->type == PTR_TO_MAP_KEY) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"write to change key R%d not allowed\\n\", regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->map_ptr->key_size, false);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_MAP_VALUE) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into map\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_map_access_type(env, regno, off, size, t);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = check_map_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\tstruct bpf_map *map = reg->map_ptr;\n\n\t\t\t/* if map is read-only, track its contents as scalars */\n\t\t\tif (tnum_is_const(reg->var_off) &&\n\t\t\t    bpf_map_is_rdonly(map) &&\n\t\t\t    map->ops->map_direct_value_addr) {\n\t\t\t\tint map_off = off + reg->var_off.value;\n\t\t\t\tu64 val = 0;\n\n\t\t\t\terr = bpf_map_direct_read(map, map_off, size,\n\t\t\t\t\t\t\t  &val);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\n\t\t\t\tregs[value_regno].type = SCALAR_VALUE;\n\t\t\t\t__mark_reg_known(&regs[value_regno], val);\n\t\t\t} else {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t}\n\t\t}\n\t} else if (reg->type == PTR_TO_MEM) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into mem\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_mem_region_access(env, regno, off, size,\n\t\t\t\t\t      reg->mem_size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_CTX) {\n\t\tenum bpf_reg_type reg_type = SCALAR_VALUE;\n\t\tstruct btf *btf = NULL;\n\t\tu32 btf_id = 0;\n\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into ctx\\n\", value_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\n\t\terr = check_ctx_access(env, insn_idx, off, size, t, &reg_type, &btf, &btf_id);\n\t\tif (err)\n\t\t\tverbose_linfo(env, insn_idx, \"; \");\n\t\tif (!err && t == BPF_READ && value_regno >= 0) {\n\t\t\t/* ctx access returns either a scalar, or a\n\t\t\t * PTR_TO_PACKET[_META,_END]. In the latter\n\t\t\t * case, we know the offset is zero.\n\t\t\t */\n\t\t\tif (reg_type == SCALAR_VALUE) {\n\t\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t\t\t} else {\n\t\t\t\tmark_reg_known_zero(env, regs,\n\t\t\t\t\t\t    value_regno);\n\t\t\t\tif (type_may_be_null(reg_type))\n\t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n\t\t\t\t/* A load of ctx field could have different\n\t\t\t\t * actual load size with the one encoded in the\n\t\t\t\t * insn. When the dst is PTR, it is for sure not\n\t\t\t\t * a sub-register.\n\t\t\t\t */\n\t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n\t\t\t\t\tregs[value_regno].btf = btf;\n\t\t\t\t\tregs[value_regno].btf_id = btf_id;\n\t\t\t\t}\n\t\t\t}\n\t\t\tregs[value_regno].type = reg_type;\n\t\t}\n\n\t} else if (reg->type == PTR_TO_STACK) {\n\t\t/* Basic bounds checks. */\n\t\terr = check_stack_access_within_bounds(env, regno, off, size, ACCESS_DIRECT, t);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tstate = func(env, reg);\n\t\terr = update_stack_depth(env, state, off);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (t == BPF_READ)\n\t\t\terr = check_stack_read(env, regno, off, size,\n\t\t\t\t\t       value_regno);\n\t\telse\n\t\t\terr = check_stack_write(env, regno, off, size,\n\t\t\t\t\t\tvalue_regno, insn_idx);\n\t} else if (reg_is_pkt_pointer(reg)) {\n\t\tif (t == BPF_WRITE && !may_access_direct_pkt_data(env, NULL, t)) {\n\t\t\tverbose(env, \"cannot write into packet\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into packet\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_packet_access(env, regno, off, size, false);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_FLOW_KEYS) {\n\t\tif (t == BPF_WRITE && value_regno >= 0 &&\n\t\t    is_pointer_value(env, value_regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into flow keys\\n\",\n\t\t\t\tvalue_regno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\terr = check_flow_keys_access(env, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (type_is_sk_pointer(reg->type)) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_TP_BUFFER) {\n\t\terr = check_tp_buffer_access(env, reg, regno, off, size);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_BTF_ID) {\n\t\terr = check_ptr_to_btf_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == CONST_PTR_TO_MAP) {\n\t\terr = check_ptr_to_map_access(env, regs, regno, off, size, t,\n\t\t\t\t\t      value_regno);\n\t} else if (reg->type == PTR_TO_RDONLY_BUF) {\n\t\tif (t == BPF_WRITE) {\n\t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n\t\t\t\tregno, reg_type_str(env, reg->type));\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  \"rdonly\",\n\t\t\t\t\t  &env->prog->aux->max_rdonly_access);\n\t\tif (!err && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else if (reg->type == PTR_TO_RDWR_BUF) {\n\t\terr = check_buffer_access(env, reg, regno, off, size, false,\n\t\t\t\t\t  \"rdwr\",\n\t\t\t\t\t  &env->prog->aux->max_rdwr_access);\n\t\tif (!err && t == BPF_READ && value_regno >= 0)\n\t\t\tmark_reg_unknown(env, regs, value_regno);\n\t} else {\n\t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n\t\t\treg_type_str(env, reg->type));\n\t\treturn -EACCES;\n\t}\n\n\tif (!err && size < BPF_REG_SIZE && value_regno >= 0 && t == BPF_READ &&\n\t    regs[value_regno].type == SCALAR_VALUE) {\n\t\t/* b/h/w load zero-extends, mark upper bits as known 0 */\n\t\tcoerce_reg_to_size(&regs[value_regno], size);\n\t}\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -100,7 +100,7 @@\n \t\t\t} else {\n \t\t\t\tmark_reg_known_zero(env, regs,\n \t\t\t\t\t\t    value_regno);\n-\t\t\t\tif (reg_type_may_be_null(reg_type))\n+\t\t\t\tif (type_may_be_null(reg_type))\n \t\t\t\t\tregs[value_regno].id = ++env->id_gen;\n \t\t\t\t/* A load of ctx field could have different\n \t\t\t\t * actual load size with the one encoded in the\n@@ -108,8 +108,7 @@\n \t\t\t\t * a sub-register.\n \t\t\t\t */\n \t\t\t\tregs[value_regno].subreg_def = DEF_NOT_SUBREG;\n-\t\t\t\tif (reg_type == PTR_TO_BTF_ID ||\n-\t\t\t\t    reg_type == PTR_TO_BTF_ID_OR_NULL) {\n+\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {\n \t\t\t\t\tregs[value_regno].btf = btf;\n \t\t\t\t\tregs[value_regno].btf_id = btf_id;\n \t\t\t\t}\n@@ -162,7 +161,7 @@\n \t} else if (type_is_sk_pointer(reg->type)) {\n \t\tif (t == BPF_WRITE) {\n \t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n-\t\t\t\tregno, reg_type_str[reg->type]);\n+\t\t\t\tregno, reg_type_str(env, reg->type));\n \t\t\treturn -EACCES;\n \t\t}\n \t\terr = check_sock_access(env, insn_idx, regno, off, size, t);\n@@ -181,7 +180,7 @@\n \t} else if (reg->type == PTR_TO_RDONLY_BUF) {\n \t\tif (t == BPF_WRITE) {\n \t\t\tverbose(env, \"R%d cannot write into %s\\n\",\n-\t\t\t\tregno, reg_type_str[reg->type]);\n+\t\t\t\tregno, reg_type_str(env, reg->type));\n \t\t\treturn -EACCES;\n \t\t}\n \t\terr = check_buffer_access(env, reg, regno, off, size, false,\n@@ -197,7 +196,7 @@\n \t\t\tmark_reg_unknown(env, regs, value_regno);\n \t} else {\n \t\tverbose(env, \"R%d invalid mem access '%s'\\n\", regno,\n-\t\t\treg_type_str[reg->type]);\n+\t\t\treg_type_str(env, reg->type));\n \t\treturn -EACCES;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tif (type_may_be_null(reg_type))",
                "\t\t\t\tif (base_type(reg_type) == PTR_TO_BTF_ID) {",
                "\t\t\t\tregno, reg_type_str(env, reg->type));",
                "\t\t\t\tregno, reg_type_str(env, reg->type));",
                "\t\t\treg_type_str(env, reg->type));"
            ],
            "deleted": [
                "\t\t\t\tif (reg_type_may_be_null(reg_type))",
                "\t\t\t\tif (reg_type == PTR_TO_BTF_ID ||",
                "\t\t\t\t    reg_type == PTR_TO_BTF_ID_OR_NULL) {",
                "\t\t\t\tregno, reg_type_str[reg->type]);",
                "\t\t\t\tregno, reg_type_str[reg->type]);",
                "\t\t\treg_type_str[reg->type]);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3448
    },
    {
        "cve_id": "CVE-2023-28328",
        "code_before_change": "static int az6027_i2c_xfer(struct i2c_adapter *adap, struct i2c_msg msg[], int num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tint i = 0, j = 0, len = 0;\n\tu16 index;\n\tu16 value;\n\tint length;\n\tu8 req;\n\tu8 *data;\n\n\tdata = kmalloc(256, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0) {\n\t\tkfree(data);\n\t\treturn -EAGAIN;\n\t}\n\n\tif (num > 2)\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet. TODO.\");\n\n\tfor (i = 0; i < num; i++) {\n\n\t\tif (msg[i].addr == 0x99) {\n\t\t\treq = 0xBE;\n\t\t\tindex = 0;\n\t\t\tvalue = msg[i].buf[0] & 0x00ff;\n\t\t\tlength = 1;\n\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t}\n\n\t\tif (msg[i].addr == 0xd0) {\n\t\t\t/* write/read request */\n\t\t\tif (i + 1 < num && (msg[i + 1].flags & I2C_M_RD)) {\n\t\t\t\treq = 0xB9;\n\t\t\t\tindex = (((msg[i].buf[0] << 8) & 0xff00) | (msg[i].buf[1] & 0x00ff));\n\t\t\t\tvalue = msg[i].addr + (msg[i].len << 8);\n\t\t\t\tlength = msg[i + 1].len + 6;\n\t\t\t\taz6027_usb_in_op(d, req, value, index, data, length);\n\t\t\t\tlen = msg[i + 1].len;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tmsg[i + 1].buf[j] = data[j + 5];\n\n\t\t\t\ti++;\n\t\t\t} else {\n\n\t\t\t\t/* demod 16bit addr */\n\t\t\t\treq = 0xBD;\n\t\t\t\tindex = (((msg[i].buf[0] << 8) & 0xff00) | (msg[i].buf[1] & 0x00ff));\n\t\t\t\tvalue = msg[i].addr + (2 << 8);\n\t\t\t\tlength = msg[i].len - 2;\n\t\t\t\tlen = msg[i].len - 2;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tdata[j] = msg[i].buf[j + 2];\n\t\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t\t}\n\t\t}\n\n\t\tif (msg[i].addr == 0xc0) {\n\t\t\tif (msg[i].flags & I2C_M_RD) {\n\n\t\t\t\treq = 0xB9;\n\t\t\t\tindex = 0x0;\n\t\t\t\tvalue = msg[i].addr;\n\t\t\t\tlength = msg[i].len + 6;\n\t\t\t\taz6027_usb_in_op(d, req, value, index, data, length);\n\t\t\t\tlen = msg[i].len;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tmsg[i].buf[j] = data[j + 5];\n\n\t\t\t} else {\n\n\t\t\t\treq = 0xBD;\n\t\t\t\tindex = msg[i].buf[0] & 0x00FF;\n\t\t\t\tvalue = msg[i].addr + (1 << 8);\n\t\t\t\tlength = msg[i].len - 1;\n\t\t\t\tlen = msg[i].len - 1;\n\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tdata[j] = msg[i].buf[j + 1];\n\n\t\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&d->i2c_mutex);\n\tkfree(data);\n\n\treturn i;\n}",
        "code_after_change": "static int az6027_i2c_xfer(struct i2c_adapter *adap, struct i2c_msg msg[], int num)\n{\n\tstruct dvb_usb_device *d = i2c_get_adapdata(adap);\n\tint i = 0, j = 0, len = 0;\n\tu16 index;\n\tu16 value;\n\tint length;\n\tu8 req;\n\tu8 *data;\n\n\tdata = kmalloc(256, GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tif (mutex_lock_interruptible(&d->i2c_mutex) < 0) {\n\t\tkfree(data);\n\t\treturn -EAGAIN;\n\t}\n\n\tif (num > 2)\n\t\twarn(\"more than 2 i2c messages at a time is not handled yet. TODO.\");\n\n\tfor (i = 0; i < num; i++) {\n\n\t\tif (msg[i].addr == 0x99) {\n\t\t\treq = 0xBE;\n\t\t\tindex = 0;\n\t\t\tif (msg[i].len < 1) {\n\t\t\t\ti = -EOPNOTSUPP;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvalue = msg[i].buf[0] & 0x00ff;\n\t\t\tlength = 1;\n\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t}\n\n\t\tif (msg[i].addr == 0xd0) {\n\t\t\t/* write/read request */\n\t\t\tif (i + 1 < num && (msg[i + 1].flags & I2C_M_RD)) {\n\t\t\t\treq = 0xB9;\n\t\t\t\tindex = (((msg[i].buf[0] << 8) & 0xff00) | (msg[i].buf[1] & 0x00ff));\n\t\t\t\tvalue = msg[i].addr + (msg[i].len << 8);\n\t\t\t\tlength = msg[i + 1].len + 6;\n\t\t\t\taz6027_usb_in_op(d, req, value, index, data, length);\n\t\t\t\tlen = msg[i + 1].len;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tmsg[i + 1].buf[j] = data[j + 5];\n\n\t\t\t\ti++;\n\t\t\t} else {\n\n\t\t\t\t/* demod 16bit addr */\n\t\t\t\treq = 0xBD;\n\t\t\t\tindex = (((msg[i].buf[0] << 8) & 0xff00) | (msg[i].buf[1] & 0x00ff));\n\t\t\t\tvalue = msg[i].addr + (2 << 8);\n\t\t\t\tlength = msg[i].len - 2;\n\t\t\t\tlen = msg[i].len - 2;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tdata[j] = msg[i].buf[j + 2];\n\t\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t\t}\n\t\t}\n\n\t\tif (msg[i].addr == 0xc0) {\n\t\t\tif (msg[i].flags & I2C_M_RD) {\n\n\t\t\t\treq = 0xB9;\n\t\t\t\tindex = 0x0;\n\t\t\t\tvalue = msg[i].addr;\n\t\t\t\tlength = msg[i].len + 6;\n\t\t\t\taz6027_usb_in_op(d, req, value, index, data, length);\n\t\t\t\tlen = msg[i].len;\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tmsg[i].buf[j] = data[j + 5];\n\n\t\t\t} else {\n\n\t\t\t\treq = 0xBD;\n\t\t\t\tindex = msg[i].buf[0] & 0x00FF;\n\t\t\t\tvalue = msg[i].addr + (1 << 8);\n\t\t\t\tlength = msg[i].len - 1;\n\t\t\t\tlen = msg[i].len - 1;\n\n\t\t\t\tfor (j = 0; j < len; j++)\n\t\t\t\t\tdata[j] = msg[i].buf[j + 1];\n\n\t\t\t\taz6027_usb_out_op(d, req, value, index, data, length);\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&d->i2c_mutex);\n\tkfree(data);\n\n\treturn i;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,6 +25,10 @@\n \t\tif (msg[i].addr == 0x99) {\n \t\t\treq = 0xBE;\n \t\t\tindex = 0;\n+\t\t\tif (msg[i].len < 1) {\n+\t\t\t\ti = -EOPNOTSUPP;\n+\t\t\t\tbreak;\n+\t\t\t}\n \t\t\tvalue = msg[i].buf[0] & 0x00ff;\n \t\t\tlength = 1;\n \t\t\taz6027_usb_out_op(d, req, value, index, data, length);",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (msg[i].len < 1) {",
                "\t\t\t\ti = -EOPNOTSUPP;",
                "\t\t\t\tbreak;",
                "\t\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the az6027 driver in drivers/media/usb/dev-usb/az6027.c in the Linux Kernel. The message from user space is not checked properly before transferring into the device. This flaw allows a local user to crash the system or potentially cause a denial of service.",
        "id": 3976
    },
    {
        "cve_id": "CVE-2023-28466",
        "code_before_change": "static int do_tls_getsockopt(struct sock *sk, int optname,\n\t\t\t     char __user *optval, int __user *optlen)\n{\n\tint rc = 0;\n\n\tswitch (optname) {\n\tcase TLS_TX:\n\tcase TLS_RX:\n\t\trc = do_tls_getsockopt_conf(sk, optval, optlen,\n\t\t\t\t\t    optname == TLS_TX);\n\t\tbreak;\n\tcase TLS_TX_ZEROCOPY_RO:\n\t\trc = do_tls_getsockopt_tx_zc(sk, optval, optlen);\n\t\tbreak;\n\tcase TLS_RX_EXPECT_NO_PAD:\n\t\trc = do_tls_getsockopt_no_pad(sk, optval, optlen);\n\t\tbreak;\n\tdefault:\n\t\trc = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\treturn rc;\n}",
        "code_after_change": "static int do_tls_getsockopt(struct sock *sk, int optname,\n\t\t\t     char __user *optval, int __user *optlen)\n{\n\tint rc = 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase TLS_TX:\n\tcase TLS_RX:\n\t\trc = do_tls_getsockopt_conf(sk, optval, optlen,\n\t\t\t\t\t    optname == TLS_TX);\n\t\tbreak;\n\tcase TLS_TX_ZEROCOPY_RO:\n\t\trc = do_tls_getsockopt_tx_zc(sk, optval, optlen);\n\t\tbreak;\n\tcase TLS_RX_EXPECT_NO_PAD:\n\t\trc = do_tls_getsockopt_no_pad(sk, optval, optlen);\n\t\tbreak;\n\tdefault:\n\t\trc = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,8 @@\n \t\t\t     char __user *optval, int __user *optlen)\n {\n \tint rc = 0;\n+\n+\tlock_sock(sk);\n \n \tswitch (optname) {\n \tcase TLS_TX:\n@@ -19,5 +21,8 @@\n \t\trc = -ENOPROTOOPT;\n \t\tbreak;\n \t}\n+\n+\trelease_sock(sk);\n+\n \treturn rc;\n }",
        "function_modified_lines": {
            "added": [
                "",
                "\tlock_sock(sk);",
                "",
                "\trelease_sock(sk);",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "do_tls_getsockopt in net/tls/tls_main.c in the Linux kernel through 6.2.6 lacks a lock_sock call, leading to a race condition (with a resultant use-after-free or NULL pointer dereference).",
        "id": 3981
    },
    {
        "cve_id": "CVE-2019-15222",
        "code_before_change": "int snd_usb_pipe_sanity_check(struct usb_device *dev, unsigned int pipe)\n{\n\tstatic const int pipetypes[4] = {\n\t\tPIPE_CONTROL, PIPE_ISOCHRONOUS, PIPE_BULK, PIPE_INTERRUPT\n\t};\n\tstruct usb_host_endpoint *ep;\n\n\tep = usb_pipe_endpoint(dev, pipe);\n\tif (usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])\n\t\treturn -EINVAL;\n\treturn 0;\n}",
        "code_after_change": "int snd_usb_pipe_sanity_check(struct usb_device *dev, unsigned int pipe)\n{\n\tstatic const int pipetypes[4] = {\n\t\tPIPE_CONTROL, PIPE_ISOCHRONOUS, PIPE_BULK, PIPE_INTERRUPT\n\t};\n\tstruct usb_host_endpoint *ep;\n\n\tep = usb_pipe_endpoint(dev, pipe);\n\tif (!ep || usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])\n\t\treturn -EINVAL;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \tstruct usb_host_endpoint *ep;\n \n \tep = usb_pipe_endpoint(dev, pipe);\n-\tif (usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])\n+\tif (!ep || usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])\n \t\treturn -EINVAL;\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!ep || usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])"
            ],
            "deleted": [
                "\tif (usb_pipetype(pipe) != pipetypes[usb_endpoint_type(&ep->desc)])"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.8. There is a NULL pointer dereference caused by a malicious USB device in the sound/usb/helper.c (motu_microbookii) driver.",
        "id": 2007
    },
    {
        "cve_id": "CVE-2019-19815",
        "code_before_change": "static int f2fs_read_single_page(struct inode *inode, struct page *page,\n\t\t\t\t\tunsigned nr_pages,\n\t\t\t\t\tstruct f2fs_map_blocks *map,\n\t\t\t\t\tstruct bio **bio_ret,\n\t\t\t\t\tsector_t *last_block_in_bio,\n\t\t\t\t\tbool is_readahead)\n{\n\tstruct bio *bio = *bio_ret;\n\tconst unsigned blkbits = inode->i_blkbits;\n\tconst unsigned blocksize = 1 << blkbits;\n\tsector_t block_in_file;\n\tsector_t last_block;\n\tsector_t last_block_in_file;\n\tsector_t block_nr;\n\tint ret = 0;\n\n\tblock_in_file = (sector_t)page->index;\n\tlast_block = block_in_file + nr_pages;\n\tlast_block_in_file = (i_size_read(inode) + blocksize - 1) >>\n\t\t\t\t\t\t\tblkbits;\n\tif (last_block > last_block_in_file)\n\t\tlast_block = last_block_in_file;\n\n\t/* just zeroing out page which is beyond EOF */\n\tif (block_in_file >= last_block)\n\t\tgoto zero_out;\n\t/*\n\t * Map blocks using the previous result first.\n\t */\n\tif ((map->m_flags & F2FS_MAP_MAPPED) &&\n\t\t\tblock_in_file > map->m_lblk &&\n\t\t\tblock_in_file < (map->m_lblk + map->m_len))\n\t\tgoto got_it;\n\n\t/*\n\t * Then do more f2fs_map_blocks() calls until we are\n\t * done with this page.\n\t */\n\tmap->m_lblk = block_in_file;\n\tmap->m_len = last_block - block_in_file;\n\n\tret = f2fs_map_blocks(inode, map, 0, F2FS_GET_BLOCK_DEFAULT);\n\tif (ret)\n\t\tgoto out;\ngot_it:\n\tif ((map->m_flags & F2FS_MAP_MAPPED)) {\n\t\tblock_nr = map->m_pblk + block_in_file - map->m_lblk;\n\t\tSetPageMappedToDisk(page);\n\n\t\tif (!PageUptodate(page) && !cleancache_get_page(page)) {\n\t\t\tSetPageUptodate(page);\n\t\t\tgoto confused;\n\t\t}\n\n\t\tif (!f2fs_is_valid_blkaddr(F2FS_I_SB(inode), block_nr,\n\t\t\t\t\t\tDATA_GENERIC_ENHANCE_READ)) {\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto out;\n\t\t}\n\t} else {\nzero_out:\n\t\tzero_user_segment(page, 0, PAGE_SIZE);\n\t\tif (!PageUptodate(page))\n\t\t\tSetPageUptodate(page);\n\t\tunlock_page(page);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * This page will go to BIO.  Do we need to send this\n\t * BIO off first?\n\t */\n\tif (bio && (*last_block_in_bio != block_nr - 1 ||\n\t\t!__same_bdev(F2FS_I_SB(inode), block_nr, bio))) {\nsubmit_and_realloc:\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\t\tbio = NULL;\n\t}\n\tif (bio == NULL) {\n\t\tbio = f2fs_grab_read_bio(inode, block_nr, nr_pages,\n\t\t\t\tis_readahead ? REQ_RAHEAD : 0);\n\t\tif (IS_ERR(bio)) {\n\t\t\tret = PTR_ERR(bio);\n\t\t\tbio = NULL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * If the page is under writeback, we need to wait for\n\t * its completion to see the correct decrypted data.\n\t */\n\tf2fs_wait_on_block_writeback(inode, block_nr);\n\n\tif (bio_add_page(bio, page, blocksize, 0) < blocksize)\n\t\tgoto submit_and_realloc;\n\n\tinc_page_count(F2FS_I_SB(inode), F2FS_RD_DATA);\n\tClearPageError(page);\n\t*last_block_in_bio = block_nr;\n\tgoto out;\nconfused:\n\tif (bio) {\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\t\tbio = NULL;\n\t}\n\tunlock_page(page);\nout:\n\t*bio_ret = bio;\n\treturn ret;\n}",
        "code_after_change": "static int f2fs_read_single_page(struct inode *inode, struct page *page,\n\t\t\t\t\tunsigned nr_pages,\n\t\t\t\t\tstruct f2fs_map_blocks *map,\n\t\t\t\t\tstruct bio **bio_ret,\n\t\t\t\t\tsector_t *last_block_in_bio,\n\t\t\t\t\tbool is_readahead)\n{\n\tstruct bio *bio = *bio_ret;\n\tconst unsigned blkbits = inode->i_blkbits;\n\tconst unsigned blocksize = 1 << blkbits;\n\tsector_t block_in_file;\n\tsector_t last_block;\n\tsector_t last_block_in_file;\n\tsector_t block_nr;\n\tint ret = 0;\n\n\tblock_in_file = (sector_t)page_index(page);\n\tlast_block = block_in_file + nr_pages;\n\tlast_block_in_file = (i_size_read(inode) + blocksize - 1) >>\n\t\t\t\t\t\t\tblkbits;\n\tif (last_block > last_block_in_file)\n\t\tlast_block = last_block_in_file;\n\n\t/* just zeroing out page which is beyond EOF */\n\tif (block_in_file >= last_block)\n\t\tgoto zero_out;\n\t/*\n\t * Map blocks using the previous result first.\n\t */\n\tif ((map->m_flags & F2FS_MAP_MAPPED) &&\n\t\t\tblock_in_file > map->m_lblk &&\n\t\t\tblock_in_file < (map->m_lblk + map->m_len))\n\t\tgoto got_it;\n\n\t/*\n\t * Then do more f2fs_map_blocks() calls until we are\n\t * done with this page.\n\t */\n\tmap->m_lblk = block_in_file;\n\tmap->m_len = last_block - block_in_file;\n\n\tret = f2fs_map_blocks(inode, map, 0, F2FS_GET_BLOCK_DEFAULT);\n\tif (ret)\n\t\tgoto out;\ngot_it:\n\tif ((map->m_flags & F2FS_MAP_MAPPED)) {\n\t\tblock_nr = map->m_pblk + block_in_file - map->m_lblk;\n\t\tSetPageMappedToDisk(page);\n\n\t\tif (!PageUptodate(page) && (!PageSwapCache(page) &&\n\t\t\t\t\t!cleancache_get_page(page))) {\n\t\t\tSetPageUptodate(page);\n\t\t\tgoto confused;\n\t\t}\n\n\t\tif (!f2fs_is_valid_blkaddr(F2FS_I_SB(inode), block_nr,\n\t\t\t\t\t\tDATA_GENERIC_ENHANCE_READ)) {\n\t\t\tret = -EFSCORRUPTED;\n\t\t\tgoto out;\n\t\t}\n\t} else {\nzero_out:\n\t\tzero_user_segment(page, 0, PAGE_SIZE);\n\t\tif (!PageUptodate(page))\n\t\t\tSetPageUptodate(page);\n\t\tunlock_page(page);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * This page will go to BIO.  Do we need to send this\n\t * BIO off first?\n\t */\n\tif (bio && (*last_block_in_bio != block_nr - 1 ||\n\t\t!__same_bdev(F2FS_I_SB(inode), block_nr, bio))) {\nsubmit_and_realloc:\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\t\tbio = NULL;\n\t}\n\tif (bio == NULL) {\n\t\tbio = f2fs_grab_read_bio(inode, block_nr, nr_pages,\n\t\t\t\tis_readahead ? REQ_RAHEAD : 0);\n\t\tif (IS_ERR(bio)) {\n\t\t\tret = PTR_ERR(bio);\n\t\t\tbio = NULL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * If the page is under writeback, we need to wait for\n\t * its completion to see the correct decrypted data.\n\t */\n\tf2fs_wait_on_block_writeback(inode, block_nr);\n\n\tif (bio_add_page(bio, page, blocksize, 0) < blocksize)\n\t\tgoto submit_and_realloc;\n\n\tinc_page_count(F2FS_I_SB(inode), F2FS_RD_DATA);\n\tClearPageError(page);\n\t*last_block_in_bio = block_nr;\n\tgoto out;\nconfused:\n\tif (bio) {\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\t\tbio = NULL;\n\t}\n\tunlock_page(page);\nout:\n\t*bio_ret = bio;\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,7 @@\n \tsector_t block_nr;\n \tint ret = 0;\n \n-\tblock_in_file = (sector_t)page->index;\n+\tblock_in_file = (sector_t)page_index(page);\n \tlast_block = block_in_file + nr_pages;\n \tlast_block_in_file = (i_size_read(inode) + blocksize - 1) >>\n \t\t\t\t\t\t\tblkbits;\n@@ -47,7 +47,8 @@\n \t\tblock_nr = map->m_pblk + block_in_file - map->m_lblk;\n \t\tSetPageMappedToDisk(page);\n \n-\t\tif (!PageUptodate(page) && !cleancache_get_page(page)) {\n+\t\tif (!PageUptodate(page) && (!PageSwapCache(page) &&\n+\t\t\t\t\t!cleancache_get_page(page))) {\n \t\t\tSetPageUptodate(page);\n \t\t\tgoto confused;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\tblock_in_file = (sector_t)page_index(page);",
                "\t\tif (!PageUptodate(page) && (!PageSwapCache(page) &&",
                "\t\t\t\t\t!cleancache_get_page(page))) {"
            ],
            "deleted": [
                "\tblock_in_file = (sector_t)page->index;",
                "\t\tif (!PageUptodate(page) && !cleancache_get_page(page)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted f2fs filesystem image can cause a NULL pointer dereference in f2fs_recover_fsync_data in fs/f2fs/recovery.c. This is related to F2FS_P_SB in fs/f2fs/f2fs.h.",
        "id": 2249
    },
    {
        "cve_id": "CVE-2014-7826",
        "code_before_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "code_after_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n \t\treturn;",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the ftrace subsystem, which allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via a crafted application.",
        "id": 596
    },
    {
        "cve_id": "CVE-2018-7191",
        "code_before_change": "static int dev_get_valid_name(struct net *net,\n\t\t\t      struct net_device *dev,\n\t\t\t      const char *name)\n{\n\tBUG_ON(!net);\n\n\tif (!dev_valid_name(name))\n\t\treturn -EINVAL;\n\n\tif (strchr(name, '%'))\n\t\treturn dev_alloc_name_ns(net, dev, name);\n\telse if (__dev_get_by_name(net, name))\n\t\treturn -EEXIST;\n\telse if (dev->name != name)\n\t\tstrlcpy(dev->name, name, IFNAMSIZ);\n\n\treturn 0;\n}",
        "code_after_change": "int dev_get_valid_name(struct net *net, struct net_device *dev,\n\t\t       const char *name)\n{\n\tBUG_ON(!net);\n\n\tif (!dev_valid_name(name))\n\t\treturn -EINVAL;\n\n\tif (strchr(name, '%'))\n\t\treturn dev_alloc_name_ns(net, dev, name);\n\telse if (__dev_get_by_name(net, name))\n\t\treturn -EEXIST;\n\telse if (dev->name != name)\n\t\tstrlcpy(dev->name, name, IFNAMSIZ);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,5 @@\n-static int dev_get_valid_name(struct net *net,\n-\t\t\t      struct net_device *dev,\n-\t\t\t      const char *name)\n+int dev_get_valid_name(struct net *net, struct net_device *dev,\n+\t\t       const char *name)\n {\n \tBUG_ON(!net);\n ",
        "function_modified_lines": {
            "added": [
                "int dev_get_valid_name(struct net *net, struct net_device *dev,",
                "\t\t       const char *name)"
            ],
            "deleted": [
                "static int dev_get_valid_name(struct net *net,",
                "\t\t\t      struct net_device *dev,",
                "\t\t\t      const char *name)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the tun subsystem in the Linux kernel before 4.13.14, dev_get_valid_name is not called before register_netdevice. This allows local users to cause a denial of service (NULL pointer dereference and panic) via an ioctl(TUNSETIFF) call with a dev name containing a / character. This is similar to CVE-2013-4343.",
        "id": 1844
    },
    {
        "cve_id": "CVE-2015-8970",
        "code_before_change": "static void skcipher_release(void *private)\n{\n\tcrypto_free_skcipher(private);\n}",
        "code_after_change": "static void skcipher_release(void *private)\n{\n\tstruct skcipher_tfm *tfm = private;\n\n\tcrypto_free_skcipher(tfm->skcipher);\n\tkfree(tfm);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,7 @@\n static void skcipher_release(void *private)\n {\n-\tcrypto_free_skcipher(private);\n+\tstruct skcipher_tfm *tfm = private;\n+\n+\tcrypto_free_skcipher(tfm->skcipher);\n+\tkfree(tfm);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct skcipher_tfm *tfm = private;",
                "",
                "\tcrypto_free_skcipher(tfm->skcipher);",
                "\tkfree(tfm);"
            ],
            "deleted": [
                "\tcrypto_free_skcipher(private);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "crypto/algif_skcipher.c in the Linux kernel before 4.4.2 does not verify that a setkey operation has been performed on an AF_ALG socket before an accept system call is processed, which allows local users to cause a denial of service (NULL pointer dereference and system crash) via a crafted application that does not supply a key, related to the lrw_crypt function in crypto/lrw.c.",
        "id": 877
    },
    {
        "cve_id": "CVE-2023-32252",
        "code_before_change": "static inline int check_conn_state(struct ksmbd_work *work)\n{\n\tstruct smb_hdr *rsp_hdr;\n\n\tif (ksmbd_conn_exiting(work) || ksmbd_conn_need_reconnect(work)) {\n\t\trsp_hdr = work->response_buf;\n\t\trsp_hdr->Status.CifsError = STATUS_CONNECTION_DISCONNECTED;\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "code_after_change": "static inline int check_conn_state(struct ksmbd_work *work)\n{\n\tstruct smb_hdr *rsp_hdr;\n\n\tif (ksmbd_conn_exiting(work->conn) ||\n\t    ksmbd_conn_need_reconnect(work->conn)) {\n\t\trsp_hdr = work->response_buf;\n\t\trsp_hdr->Status.CifsError = STATUS_CONNECTION_DISCONNECTED;\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,8 @@\n {\n \tstruct smb_hdr *rsp_hdr;\n \n-\tif (ksmbd_conn_exiting(work) || ksmbd_conn_need_reconnect(work)) {\n+\tif (ksmbd_conn_exiting(work->conn) ||\n+\t    ksmbd_conn_need_reconnect(work->conn)) {\n \t\trsp_hdr = work->response_buf;\n \t\trsp_hdr->Status.CifsError = STATUS_CONNECTION_DISCONNECTED;\n \t\treturn 1;",
        "function_modified_lines": {
            "added": [
                "\tif (ksmbd_conn_exiting(work->conn) ||",
                "\t    ksmbd_conn_need_reconnect(work->conn)) {"
            ],
            "deleted": [
                "\tif (ksmbd_conn_exiting(work) || ksmbd_conn_need_reconnect(work)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_LOGOFF commands. The issue results from the lack of proper validation of a pointer prior to accessing it. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4028
    },
    {
        "cve_id": "CVE-2022-3113",
        "code_before_change": "struct mtk_vcodec_fw *mtk_vcodec_fw_vpu_init(struct mtk_vcodec_dev *dev,\n\t\t\t\t\t     enum mtk_vcodec_fw_use fw_use)\n{\n\tstruct platform_device *fw_pdev;\n\tstruct mtk_vcodec_fw *fw;\n\tenum rst_id rst_id;\n\n\tswitch (fw_use) {\n\tcase ENCODER:\n\t\trst_id = VPU_RST_ENC;\n\t\tbreak;\n\tcase DECODER:\n\tdefault:\n\t\trst_id = VPU_RST_DEC;\n\t\tbreak;\n\t}\n\n\tfw_pdev = vpu_get_plat_device(dev->plat_dev);\n\tif (!fw_pdev) {\n\t\tmtk_v4l2_err(\"firmware device is not ready\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tvpu_wdt_reg_handler(fw_pdev, mtk_vcodec_vpu_reset_handler, dev, rst_id);\n\n\tfw = devm_kzalloc(&dev->plat_dev->dev, sizeof(*fw), GFP_KERNEL);\n\tfw->type = VPU;\n\tfw->ops = &mtk_vcodec_vpu_msg;\n\tfw->pdev = fw_pdev;\n\n\treturn fw;\n}",
        "code_after_change": "struct mtk_vcodec_fw *mtk_vcodec_fw_vpu_init(struct mtk_vcodec_dev *dev,\n\t\t\t\t\t     enum mtk_vcodec_fw_use fw_use)\n{\n\tstruct platform_device *fw_pdev;\n\tstruct mtk_vcodec_fw *fw;\n\tenum rst_id rst_id;\n\n\tswitch (fw_use) {\n\tcase ENCODER:\n\t\trst_id = VPU_RST_ENC;\n\t\tbreak;\n\tcase DECODER:\n\tdefault:\n\t\trst_id = VPU_RST_DEC;\n\t\tbreak;\n\t}\n\n\tfw_pdev = vpu_get_plat_device(dev->plat_dev);\n\tif (!fw_pdev) {\n\t\tmtk_v4l2_err(\"firmware device is not ready\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tvpu_wdt_reg_handler(fw_pdev, mtk_vcodec_vpu_reset_handler, dev, rst_id);\n\n\tfw = devm_kzalloc(&dev->plat_dev->dev, sizeof(*fw), GFP_KERNEL);\n\tif (!fw)\n\t\treturn ERR_PTR(-ENOMEM);\n\tfw->type = VPU;\n\tfw->ops = &mtk_vcodec_vpu_msg;\n\tfw->pdev = fw_pdev;\n\n\treturn fw;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,6 +23,8 @@\n \tvpu_wdt_reg_handler(fw_pdev, mtk_vcodec_vpu_reset_handler, dev, rst_id);\n \n \tfw = devm_kzalloc(&dev->plat_dev->dev, sizeof(*fw), GFP_KERNEL);\n+\tif (!fw)\n+\t\treturn ERR_PTR(-ENOMEM);\n \tfw->type = VPU;\n \tfw->ops = &mtk_vcodec_vpu_msg;\n \tfw->pdev = fw_pdev;",
        "function_modified_lines": {
            "added": [
                "\tif (!fw)",
                "\t\treturn ERR_PTR(-ENOMEM);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. mtk_vcodec_fw_vpu_init in drivers/media/platform/mtk-vcodec/mtk_vcodec_fw_vpu.c lacks check of the return value of devm_kzalloc() and will cause the null pointer dereference.",
        "id": 3559
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static int verify_one_dev_extent(struct btrfs_fs_info *fs_info,\n\t\t\t\t u64 chunk_offset, u64 devid,\n\t\t\t\t u64 physical_offset, u64 physical_len)\n{\n\tstruct extent_map_tree *em_tree = &fs_info->mapping_tree.map_tree;\n\tstruct extent_map *em;\n\tstruct map_lookup *map;\n\tstruct btrfs_device *dev;\n\tu64 stripe_len;\n\tbool found = false;\n\tint ret = 0;\n\tint i;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, chunk_offset, 1);\n\tread_unlock(&em_tree->lock);\n\n\tif (!em) {\n\t\tbtrfs_err(fs_info,\n\"dev extent physical offset %llu on devid %llu doesn't have corresponding chunk\",\n\t\t\t  physical_offset, devid);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tmap = em->map_lookup;\n\tstripe_len = calc_stripe_length(map->type, em->len, map->num_stripes);\n\tif (physical_len != stripe_len) {\n\t\tbtrfs_err(fs_info,\n\"dev extent physical offset %llu on devid %llu length doesn't match chunk %llu, have %llu expect %llu\",\n\t\t\t  physical_offset, devid, em->start, physical_len,\n\t\t\t  stripe_len);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < map->num_stripes; i++) {\n\t\tif (map->stripes[i].dev->devid == devid &&\n\t\t    map->stripes[i].physical == physical_offset) {\n\t\t\tfound = true;\n\t\t\tif (map->verified_stripes >= map->num_stripes) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t\"too many dev extents for chunk %llu found\",\n\t\t\t\t\t  em->start);\n\t\t\t\tret = -EUCLEAN;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmap->verified_stripes++;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!found) {\n\t\tbtrfs_err(fs_info,\n\t\"dev extent physical offset %llu devid %llu has no corresponding chunk\",\n\t\t\tphysical_offset, devid);\n\t\tret = -EUCLEAN;\n\t}\n\n\t/* Make sure no dev extent is beyond device bondary */\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n\tif (!dev) {\n\t\tbtrfs_err(fs_info, \"failed to find devid %llu\", devid);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\t/* It's possible this device is a dummy for seed device */\n\tif (dev->disk_total_bytes == 0) {\n\t\tdev = find_device(fs_info->fs_devices->seed, devid, NULL);\n\t\tif (!dev) {\n\t\t\tbtrfs_err(fs_info, \"failed to find seed devid %llu\",\n\t\t\t\t  devid);\n\t\t\tret = -EUCLEAN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (physical_offset + physical_len > dev->disk_total_bytes) {\n\t\tbtrfs_err(fs_info,\n\"dev extent devid %llu physical offset %llu len %llu is beyond device boundary %llu\",\n\t\t\t  devid, physical_offset, physical_len,\n\t\t\t  dev->disk_total_bytes);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\nout:\n\tfree_extent_map(em);\n\treturn ret;\n}",
        "code_after_change": "static int verify_one_dev_extent(struct btrfs_fs_info *fs_info,\n\t\t\t\t u64 chunk_offset, u64 devid,\n\t\t\t\t u64 physical_offset, u64 physical_len)\n{\n\tstruct extent_map_tree *em_tree = &fs_info->mapping_tree.map_tree;\n\tstruct extent_map *em;\n\tstruct map_lookup *map;\n\tstruct btrfs_device *dev;\n\tu64 stripe_len;\n\tbool found = false;\n\tint ret = 0;\n\tint i;\n\n\tread_lock(&em_tree->lock);\n\tem = lookup_extent_mapping(em_tree, chunk_offset, 1);\n\tread_unlock(&em_tree->lock);\n\n\tif (!em) {\n\t\tbtrfs_err(fs_info,\n\"dev extent physical offset %llu on devid %llu doesn't have corresponding chunk\",\n\t\t\t  physical_offset, devid);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tmap = em->map_lookup;\n\tstripe_len = calc_stripe_length(map->type, em->len, map->num_stripes);\n\tif (physical_len != stripe_len) {\n\t\tbtrfs_err(fs_info,\n\"dev extent physical offset %llu on devid %llu length doesn't match chunk %llu, have %llu expect %llu\",\n\t\t\t  physical_offset, devid, em->start, physical_len,\n\t\t\t  stripe_len);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < map->num_stripes; i++) {\n\t\tif (map->stripes[i].dev->devid == devid &&\n\t\t    map->stripes[i].physical == physical_offset) {\n\t\t\tfound = true;\n\t\t\tif (map->verified_stripes >= map->num_stripes) {\n\t\t\t\tbtrfs_err(fs_info,\n\t\t\t\t\"too many dev extents for chunk %llu found\",\n\t\t\t\t\t  em->start);\n\t\t\t\tret = -EUCLEAN;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmap->verified_stripes++;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!found) {\n\t\tbtrfs_err(fs_info,\n\t\"dev extent physical offset %llu devid %llu has no corresponding chunk\",\n\t\t\tphysical_offset, devid);\n\t\tret = -EUCLEAN;\n\t}\n\n\t/* Make sure no dev extent is beyond device bondary */\n\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n\tif (!dev) {\n\t\tbtrfs_err(fs_info, \"failed to find devid %llu\", devid);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\n\n\t/* It's possible this device is a dummy for seed device */\n\tif (dev->disk_total_bytes == 0) {\n\t\tdev = btrfs_find_device(fs_info->fs_devices->seed, devid, NULL,\n\t\t\t\t\tNULL, false);\n\t\tif (!dev) {\n\t\t\tbtrfs_err(fs_info, \"failed to find seed devid %llu\",\n\t\t\t\t  devid);\n\t\t\tret = -EUCLEAN;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (physical_offset + physical_len > dev->disk_total_bytes) {\n\t\tbtrfs_err(fs_info,\n\"dev extent devid %llu physical offset %llu len %llu is beyond device boundary %llu\",\n\t\t\t  devid, physical_offset, physical_len,\n\t\t\t  dev->disk_total_bytes);\n\t\tret = -EUCLEAN;\n\t\tgoto out;\n\t}\nout:\n\tfree_extent_map(em);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -57,7 +57,7 @@\n \t}\n \n \t/* Make sure no dev extent is beyond device bondary */\n-\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);\n+\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);\n \tif (!dev) {\n \t\tbtrfs_err(fs_info, \"failed to find devid %llu\", devid);\n \t\tret = -EUCLEAN;\n@@ -66,7 +66,8 @@\n \n \t/* It's possible this device is a dummy for seed device */\n \tif (dev->disk_total_bytes == 0) {\n-\t\tdev = find_device(fs_info->fs_devices->seed, devid, NULL);\n+\t\tdev = btrfs_find_device(fs_info->fs_devices->seed, devid, NULL,\n+\t\t\t\t\tNULL, false);\n \t\tif (!dev) {\n \t\t\tbtrfs_err(fs_info, \"failed to find seed devid %llu\",\n \t\t\t\t  devid);",
        "function_modified_lines": {
            "added": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL, true);",
                "\t\tdev = btrfs_find_device(fs_info->fs_devices->seed, devid, NULL,",
                "\t\t\t\t\tNULL, false);"
            ],
            "deleted": [
                "\tdev = btrfs_find_device(fs_info->fs_devices, devid, NULL, NULL);",
                "\t\tdev = find_device(fs_info->fs_devices->seed, devid, NULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2119
    },
    {
        "cve_id": "CVE-2019-15922",
        "code_before_change": "static void __exit pf_exit(void)\n{\n\tstruct pf_unit *pf;\n\tint unit;\n\tunregister_blkdev(major, name);\n\tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n\t\tif (pf->present)\n\t\t\tdel_gendisk(pf->disk);\n\n\t\tblk_cleanup_queue(pf->disk->queue);\n\t\tblk_mq_free_tag_set(&pf->tag_set);\n\t\tput_disk(pf->disk);\n\n\t\tif (pf->present)\n\t\t\tpi_release(pf->pi);\n\t}\n}",
        "code_after_change": "static void __exit pf_exit(void)\n{\n\tstruct pf_unit *pf;\n\tint unit;\n\tunregister_blkdev(major, name);\n\tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n\t\tif (!pf->disk)\n\t\t\tcontinue;\n\n\t\tif (pf->present)\n\t\t\tdel_gendisk(pf->disk);\n\n\t\tblk_cleanup_queue(pf->disk->queue);\n\t\tblk_mq_free_tag_set(&pf->tag_set);\n\t\tput_disk(pf->disk);\n\n\t\tif (pf->present)\n\t\t\tpi_release(pf->pi);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,6 +4,9 @@\n \tint unit;\n \tunregister_blkdev(major, name);\n \tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n+\t\tif (!pf->disk)\n+\t\t\tcontinue;\n+\n \t\tif (pf->present)\n \t\t\tdel_gendisk(pf->disk);\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (!pf->disk)",
                "\t\t\tcontinue;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.9. There is a NULL pointer dereference for a pf data structure if alloc_disk fails in drivers/block/paride/pf.c.",
        "id": 2030
    },
    {
        "cve_id": "CVE-2023-23000",
        "code_before_change": "static struct device_node *\ntegra_xusb_find_port_node(struct tegra_xusb_padctl *padctl, const char *type,\n\t\t\t  unsigned int index)\n{\n\tstruct device_node *ports, *np;\n\tchar *name;\n\n\tports = of_get_child_by_name(padctl->dev->of_node, \"ports\");\n\tif (!ports)\n\t\treturn NULL;\n\n\tname = kasprintf(GFP_KERNEL, \"%s-%u\", type, index);\n\tif (!name) {\n\t\tof_node_put(ports);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tnp = of_get_child_by_name(ports, name);\n\tkfree(name);\n\tof_node_put(ports);\n\n\treturn np;\n}",
        "code_after_change": "static struct device_node *\ntegra_xusb_find_port_node(struct tegra_xusb_padctl *padctl, const char *type,\n\t\t\t  unsigned int index)\n{\n\tstruct device_node *ports, *np;\n\tchar *name;\n\n\tports = of_get_child_by_name(padctl->dev->of_node, \"ports\");\n\tif (!ports)\n\t\treturn NULL;\n\n\tname = kasprintf(GFP_KERNEL, \"%s-%u\", type, index);\n\tif (!name) {\n\t\tof_node_put(ports);\n\t\treturn NULL;\n\t}\n\tnp = of_get_child_by_name(ports, name);\n\tkfree(name);\n\tof_node_put(ports);\n\n\treturn np;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \tname = kasprintf(GFP_KERNEL, \"%s-%u\", type, index);\n \tif (!name) {\n \t\tof_node_put(ports);\n-\t\treturn ERR_PTR(-ENOMEM);\n+\t\treturn NULL;\n \t}\n \tnp = of_get_child_by_name(ports, name);\n \tkfree(name);",
        "function_modified_lines": {
            "added": [
                "\t\treturn NULL;"
            ],
            "deleted": [
                "\t\treturn ERR_PTR(-ENOMEM);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.17, drivers/phy/tegra/xusb.c mishandles the tegra_xusb_find_port_node return value. Callers expect NULL in the error case, but an error pointer is used.",
        "id": 3943
    },
    {
        "cve_id": "CVE-2020-25285",
        "code_before_change": "int hugetlb_overcommit_handler(struct ctl_table *table, int write,\n\t\tvoid *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttmp = h->nr_overcommit_huge_pages;\n\n\tif (write && hstate_is_gigantic(h))\n\t\treturn -EINVAL;\n\n\ttable->data = &tmp;\n\ttable->maxlen = sizeof(unsigned long);\n\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write) {\n\t\tspin_lock(&hugetlb_lock);\n\t\th->nr_overcommit_huge_pages = tmp;\n\t\tspin_unlock(&hugetlb_lock);\n\t}\nout:\n\treturn ret;\n}",
        "code_after_change": "int hugetlb_overcommit_handler(struct ctl_table *table, int write,\n\t\tvoid *buffer, size_t *length, loff_t *ppos)\n{\n\tstruct hstate *h = &default_hstate;\n\tunsigned long tmp;\n\tint ret;\n\n\tif (!hugepages_supported())\n\t\treturn -EOPNOTSUPP;\n\n\ttmp = h->nr_overcommit_huge_pages;\n\n\tif (write && hstate_is_gigantic(h))\n\t\treturn -EINVAL;\n\n\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n\t\t\t\t\t     &tmp);\n\tif (ret)\n\t\tgoto out;\n\n\tif (write) {\n\t\tspin_lock(&hugetlb_lock);\n\t\th->nr_overcommit_huge_pages = tmp;\n\t\tspin_unlock(&hugetlb_lock);\n\t}\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,9 +13,8 @@\n \tif (write && hstate_is_gigantic(h))\n \t\treturn -EINVAL;\n \n-\ttable->data = &tmp;\n-\ttable->maxlen = sizeof(unsigned long);\n-\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);\n+\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,\n+\t\t\t\t\t     &tmp);\n \tif (ret)\n \t\tgoto out;\n ",
        "function_modified_lines": {
            "added": [
                "\tret = proc_hugetlb_doulongvec_minmax(table, write, buffer, length, ppos,",
                "\t\t\t\t\t     &tmp);"
            ],
            "deleted": [
                "\ttable->data = &tmp;",
                "\ttable->maxlen = sizeof(unsigned long);",
                "\tret = proc_doulongvec_minmax(table, write, buffer, length, ppos);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-787",
            "CWE-476"
        ],
        "cve_description": "A race condition between hugetlb sysctl handlers in mm/hugetlb.c in the Linux kernel before 5.8.8 could be used by local attackers to corrupt memory, cause a NULL pointer dereference, or possibly have unspecified other impact, aka CID-17743798d812.",
        "id": 2586
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int stk7770p_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct usb_device_descriptor *p = &adap->dev->udev->descriptor;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (p->idVendor  == cpu_to_le16(USB_VID_PINNACLE) &&\n\t    p->idProduct == cpu_to_le16(USB_PID_PINNACLE_PCTV72E))\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 0);\n\telse\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t     &dib7770p_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80,\n\t\t&dib7770p_dib7000p_config);\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int stk7770p_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct usb_device_descriptor *p = &adap->dev->udev->descriptor;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (p->idVendor  == cpu_to_le16(USB_VID_PINNACLE) &&\n\t    p->idProduct == cpu_to_le16(USB_PID_PINNACLE_PCTV72E))\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 0);\n\telse\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 18,\n\t\t\t\t     &dib7770p_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80,\n\t\t&dib7770p_dib7000p_config);\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,7 +28,7 @@\n \t\t\t\t     &dib7770p_dib7000p_config) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n \t\t    __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1336
    },
    {
        "cve_id": "CVE-2022-1205",
        "code_before_change": "static void ax25_kill_by_device(struct net_device *dev)\n{\n\tax25_dev *ax25_dev;\n\tax25_cb *s;\n\tstruct sock *sk;\n\n\tif ((ax25_dev = ax25_dev_ax25dev(dev)) == NULL)\n\t\treturn;\n\n\tspin_lock_bh(&ax25_list_lock);\nagain:\n\tax25_for_each(s, &ax25_list) {\n\t\tif (s->ax25_dev == ax25_dev) {\n\t\t\tsk = s->sk;\n\t\t\tif (!sk) {\n\t\t\t\tspin_unlock_bh(&ax25_list_lock);\n\t\t\t\ts->ax25_dev = NULL;\n\t\t\t\tax25_disconnect(s, ENETUNREACH);\n\t\t\t\tspin_lock_bh(&ax25_list_lock);\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\tsock_hold(sk);\n\t\t\tspin_unlock_bh(&ax25_list_lock);\n\t\t\tlock_sock(sk);\n\t\t\ts->ax25_dev = NULL;\n\t\t\tif (sk->sk_socket) {\n\t\t\t\tdev_put_track(ax25_dev->dev, &ax25_dev->dev_tracker);\n\t\t\t\tax25_dev_put(ax25_dev);\n\t\t\t}\n\t\t\tax25_disconnect(s, ENETUNREACH);\n\t\t\trelease_sock(sk);\n\t\t\tspin_lock_bh(&ax25_list_lock);\n\t\t\tsock_put(sk);\n\t\t\t/* The entry could have been deleted from the\n\t\t\t * list meanwhile and thus the next pointer is\n\t\t\t * no longer valid.  Play it safe and restart\n\t\t\t * the scan.  Forward progress is ensured\n\t\t\t * because we set s->ax25_dev to NULL and we\n\t\t\t * are never passed a NULL 'dev' argument.\n\t\t\t */\n\t\t\tgoto again;\n\t\t}\n\t}\n\tspin_unlock_bh(&ax25_list_lock);\n}",
        "code_after_change": "static void ax25_kill_by_device(struct net_device *dev)\n{\n\tax25_dev *ax25_dev;\n\tax25_cb *s;\n\tstruct sock *sk;\n\n\tif ((ax25_dev = ax25_dev_ax25dev(dev)) == NULL)\n\t\treturn;\n\n\tspin_lock_bh(&ax25_list_lock);\nagain:\n\tax25_for_each(s, &ax25_list) {\n\t\tif (s->ax25_dev == ax25_dev) {\n\t\t\tsk = s->sk;\n\t\t\tif (!sk) {\n\t\t\t\tspin_unlock_bh(&ax25_list_lock);\n\t\t\t\tax25_disconnect(s, ENETUNREACH);\n\t\t\t\ts->ax25_dev = NULL;\n\t\t\t\tspin_lock_bh(&ax25_list_lock);\n\t\t\t\tgoto again;\n\t\t\t}\n\t\t\tsock_hold(sk);\n\t\t\tspin_unlock_bh(&ax25_list_lock);\n\t\t\tlock_sock(sk);\n\t\t\tax25_disconnect(s, ENETUNREACH);\n\t\t\ts->ax25_dev = NULL;\n\t\t\tif (sk->sk_socket) {\n\t\t\t\tdev_put_track(ax25_dev->dev, &ax25_dev->dev_tracker);\n\t\t\t\tax25_dev_put(ax25_dev);\n\t\t\t}\n\t\t\trelease_sock(sk);\n\t\t\tspin_lock_bh(&ax25_list_lock);\n\t\t\tsock_put(sk);\n\t\t\t/* The entry could have been deleted from the\n\t\t\t * list meanwhile and thus the next pointer is\n\t\t\t * no longer valid.  Play it safe and restart\n\t\t\t * the scan.  Forward progress is ensured\n\t\t\t * because we set s->ax25_dev to NULL and we\n\t\t\t * are never passed a NULL 'dev' argument.\n\t\t\t */\n\t\t\tgoto again;\n\t\t}\n\t}\n\tspin_unlock_bh(&ax25_list_lock);\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,20 +14,20 @@\n \t\t\tsk = s->sk;\n \t\t\tif (!sk) {\n \t\t\t\tspin_unlock_bh(&ax25_list_lock);\n+\t\t\t\tax25_disconnect(s, ENETUNREACH);\n \t\t\t\ts->ax25_dev = NULL;\n-\t\t\t\tax25_disconnect(s, ENETUNREACH);\n \t\t\t\tspin_lock_bh(&ax25_list_lock);\n \t\t\t\tgoto again;\n \t\t\t}\n \t\t\tsock_hold(sk);\n \t\t\tspin_unlock_bh(&ax25_list_lock);\n \t\t\tlock_sock(sk);\n+\t\t\tax25_disconnect(s, ENETUNREACH);\n \t\t\ts->ax25_dev = NULL;\n \t\t\tif (sk->sk_socket) {\n \t\t\t\tdev_put_track(ax25_dev->dev, &ax25_dev->dev_tracker);\n \t\t\t\tax25_dev_put(ax25_dev);\n \t\t\t}\n-\t\t\tax25_disconnect(s, ENETUNREACH);\n \t\t\trelease_sock(sk);\n \t\t\tspin_lock_bh(&ax25_list_lock);\n \t\t\tsock_put(sk);",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tax25_disconnect(s, ENETUNREACH);",
                "\t\t\tax25_disconnect(s, ENETUNREACH);"
            ],
            "deleted": [
                "\t\t\t\tax25_disconnect(s, ENETUNREACH);",
                "\t\t\tax25_disconnect(s, ENETUNREACH);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel’s Amateur Radio AX.25 protocol functionality in the way a user connects with the protocol. This flaw allows a local user to crash the system.",
        "id": 3255
    },
    {
        "cve_id": "CVE-2023-3355",
        "code_before_change": "static int submit_lookup_cmds(struct msm_gem_submit *submit,\n\t\tstruct drm_msm_gem_submit *args, struct drm_file *file)\n{\n\tunsigned i;\n\tsize_t sz;\n\tint ret = 0;\n\n\tfor (i = 0; i < args->nr_cmds; i++) {\n\t\tstruct drm_msm_gem_submit_cmd submit_cmd;\n\t\tvoid __user *userptr =\n\t\t\tu64_to_user_ptr(args->cmds + (i * sizeof(submit_cmd)));\n\n\t\tret = copy_from_user(&submit_cmd, userptr, sizeof(submit_cmd));\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* validate input from userspace: */\n\t\tswitch (submit_cmd.type) {\n\t\tcase MSM_SUBMIT_CMD_BUF:\n\t\tcase MSM_SUBMIT_CMD_IB_TARGET_BUF:\n\t\tcase MSM_SUBMIT_CMD_CTX_RESTORE_BUF:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_ERROR(\"invalid type: %08x\\n\", submit_cmd.type);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (submit_cmd.size % 4) {\n\t\t\tDRM_ERROR(\"non-aligned cmdstream buffer size: %u\\n\",\n\t\t\t\t\tsubmit_cmd.size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsubmit->cmd[i].type = submit_cmd.type;\n\t\tsubmit->cmd[i].size = submit_cmd.size / 4;\n\t\tsubmit->cmd[i].offset = submit_cmd.submit_offset / 4;\n\t\tsubmit->cmd[i].idx  = submit_cmd.submit_idx;\n\t\tsubmit->cmd[i].nr_relocs = submit_cmd.nr_relocs;\n\n\t\tuserptr = u64_to_user_ptr(submit_cmd.relocs);\n\n\t\tsz = array_size(submit_cmd.nr_relocs,\n\t\t\t\tsizeof(struct drm_msm_gem_submit_reloc));\n\t\t/* check for overflow: */\n\t\tif (sz == SIZE_MAX) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tsubmit->cmd[i].relocs = kmalloc(sz, GFP_KERNEL);\n\t\tret = copy_from_user(submit->cmd[i].relocs, userptr, sz);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}",
        "code_after_change": "static int submit_lookup_cmds(struct msm_gem_submit *submit,\n\t\tstruct drm_msm_gem_submit *args, struct drm_file *file)\n{\n\tunsigned i;\n\tsize_t sz;\n\tint ret = 0;\n\n\tfor (i = 0; i < args->nr_cmds; i++) {\n\t\tstruct drm_msm_gem_submit_cmd submit_cmd;\n\t\tvoid __user *userptr =\n\t\t\tu64_to_user_ptr(args->cmds + (i * sizeof(submit_cmd)));\n\n\t\tret = copy_from_user(&submit_cmd, userptr, sizeof(submit_cmd));\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* validate input from userspace: */\n\t\tswitch (submit_cmd.type) {\n\t\tcase MSM_SUBMIT_CMD_BUF:\n\t\tcase MSM_SUBMIT_CMD_IB_TARGET_BUF:\n\t\tcase MSM_SUBMIT_CMD_CTX_RESTORE_BUF:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_ERROR(\"invalid type: %08x\\n\", submit_cmd.type);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (submit_cmd.size % 4) {\n\t\t\tDRM_ERROR(\"non-aligned cmdstream buffer size: %u\\n\",\n\t\t\t\t\tsubmit_cmd.size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsubmit->cmd[i].type = submit_cmd.type;\n\t\tsubmit->cmd[i].size = submit_cmd.size / 4;\n\t\tsubmit->cmd[i].offset = submit_cmd.submit_offset / 4;\n\t\tsubmit->cmd[i].idx  = submit_cmd.submit_idx;\n\t\tsubmit->cmd[i].nr_relocs = submit_cmd.nr_relocs;\n\n\t\tuserptr = u64_to_user_ptr(submit_cmd.relocs);\n\n\t\tsz = array_size(submit_cmd.nr_relocs,\n\t\t\t\tsizeof(struct drm_msm_gem_submit_reloc));\n\t\t/* check for overflow: */\n\t\tif (sz == SIZE_MAX) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tsubmit->cmd[i].relocs = kmalloc(sz, GFP_KERNEL);\n\t\tif (!submit->cmd[i].relocs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = copy_from_user(submit->cmd[i].relocs, userptr, sz);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -50,6 +50,10 @@\n \t\t\tgoto out;\n \t\t}\n \t\tsubmit->cmd[i].relocs = kmalloc(sz, GFP_KERNEL);\n+\t\tif (!submit->cmd[i].relocs) {\n+\t\t\tret = -ENOMEM;\n+\t\t\tgoto out;\n+\t\t}\n \t\tret = copy_from_user(submit->cmd[i].relocs, userptr, sz);\n \t\tif (ret) {\n \t\t\tret = -EFAULT;",
        "function_modified_lines": {
            "added": [
                "\t\tif (!submit->cmd[i].relocs) {",
                "\t\t\tret = -ENOMEM;",
                "\t\t\tgoto out;",
                "\t\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel's drivers/gpu/drm/msm/msm_gem_submit.c code in the submit_lookup_cmds function, which fails because it lacks a check of the return value of kmalloc(). This issue allows a local user to crash the system.",
        "id": 4060
    },
    {
        "cve_id": "CVE-2018-1066",
        "code_before_change": "int build_ntlmssp_auth_blob(unsigned char **pbuffer,\n\t\t\t\t\tu16 *buflen,\n\t\t\t\t   struct cifs_ses *ses,\n\t\t\t\t   const struct nls_table *nls_cp)\n{\n\tint rc;\n\tAUTHENTICATE_MESSAGE *sec_blob;\n\t__u32 flags;\n\tunsigned char *tmp;\n\n\trc = setup_ntlmv2_rsp(ses, nls_cp);\n\tif (rc) {\n\t\tcifs_dbg(VFS, \"Error %d during NTLMSSP authentication\\n\", rc);\n\t\t*buflen = 0;\n\t\tgoto setup_ntlmv2_ret;\n\t}\n\t*pbuffer = kmalloc(size_of_ntlmssp_blob(ses), GFP_KERNEL);\n\tsec_blob = (AUTHENTICATE_MESSAGE *)*pbuffer;\n\n\tmemcpy(sec_blob->Signature, NTLMSSP_SIGNATURE, 8);\n\tsec_blob->MessageType = NtLmAuthenticate;\n\n\tflags = NTLMSSP_NEGOTIATE_56 |\n\t\tNTLMSSP_REQUEST_TARGET | NTLMSSP_NEGOTIATE_TARGET_INFO |\n\t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;\n\tif (ses->server->sign) {\n\t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n\t\tif (!ses->server->session_estab ||\n\t\t\t\tses->ntlmssp->sesskey_per_smbsess)\n\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n\t}\n\n\ttmp = *pbuffer + sizeof(AUTHENTICATE_MESSAGE);\n\tsec_blob->NegotiateFlags = cpu_to_le32(flags);\n\n\tsec_blob->LmChallengeResponse.BufferOffset =\n\t\t\t\tcpu_to_le32(sizeof(AUTHENTICATE_MESSAGE));\n\tsec_blob->LmChallengeResponse.Length = 0;\n\tsec_blob->LmChallengeResponse.MaximumLength = 0;\n\n\tsec_blob->NtChallengeResponse.BufferOffset =\n\t\t\t\tcpu_to_le32(tmp - *pbuffer);\n\tif (ses->user_name != NULL) {\n\t\tmemcpy(tmp, ses->auth_key.response + CIFS_SESS_KEY_SIZE,\n\t\t\t\tses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t\ttmp += ses->auth_key.len - CIFS_SESS_KEY_SIZE;\n\n\t\tsec_blob->NtChallengeResponse.Length =\n\t\t\t\tcpu_to_le16(ses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t\tsec_blob->NtChallengeResponse.MaximumLength =\n\t\t\t\tcpu_to_le16(ses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t} else {\n\t\t/*\n\t\t * don't send an NT Response for anonymous access\n\t\t */\n\t\tsec_blob->NtChallengeResponse.Length = 0;\n\t\tsec_blob->NtChallengeResponse.MaximumLength = 0;\n\t}\n\n\tif (ses->domainName == NULL) {\n\t\tsec_blob->DomainName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->DomainName.Length = 0;\n\t\tsec_blob->DomainName.MaximumLength = 0;\n\t\ttmp += 2;\n\t} else {\n\t\tint len;\n\t\tlen = cifs_strtoUTF16((__le16 *)tmp, ses->domainName,\n\t\t\t\t      CIFS_MAX_DOMAINNAME_LEN, nls_cp);\n\t\tlen *= 2; /* unicode is 2 bytes each */\n\t\tsec_blob->DomainName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->DomainName.Length = cpu_to_le16(len);\n\t\tsec_blob->DomainName.MaximumLength = cpu_to_le16(len);\n\t\ttmp += len;\n\t}\n\n\tif (ses->user_name == NULL) {\n\t\tsec_blob->UserName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->UserName.Length = 0;\n\t\tsec_blob->UserName.MaximumLength = 0;\n\t\ttmp += 2;\n\t} else {\n\t\tint len;\n\t\tlen = cifs_strtoUTF16((__le16 *)tmp, ses->user_name,\n\t\t\t\t      CIFS_MAX_USERNAME_LEN, nls_cp);\n\t\tlen *= 2; /* unicode is 2 bytes each */\n\t\tsec_blob->UserName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->UserName.Length = cpu_to_le16(len);\n\t\tsec_blob->UserName.MaximumLength = cpu_to_le16(len);\n\t\ttmp += len;\n\t}\n\n\tsec_blob->WorkstationName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\tsec_blob->WorkstationName.Length = 0;\n\tsec_blob->WorkstationName.MaximumLength = 0;\n\ttmp += 2;\n\n\tif (((ses->ntlmssp->server_flags & NTLMSSP_NEGOTIATE_KEY_XCH) ||\n\t\t(ses->ntlmssp->server_flags & NTLMSSP_NEGOTIATE_EXTENDED_SEC))\n\t\t\t&& !calc_seckey(ses)) {\n\t\tmemcpy(tmp, ses->ntlmssp->ciphertext, CIFS_CPHTXT_SIZE);\n\t\tsec_blob->SessionKey.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->SessionKey.Length = cpu_to_le16(CIFS_CPHTXT_SIZE);\n\t\tsec_blob->SessionKey.MaximumLength =\n\t\t\t\tcpu_to_le16(CIFS_CPHTXT_SIZE);\n\t\ttmp += CIFS_CPHTXT_SIZE;\n\t} else {\n\t\tsec_blob->SessionKey.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->SessionKey.Length = 0;\n\t\tsec_blob->SessionKey.MaximumLength = 0;\n\t}\n\n\t*buflen = tmp - *pbuffer;\nsetup_ntlmv2_ret:\n\treturn rc;\n}",
        "code_after_change": "int build_ntlmssp_auth_blob(unsigned char **pbuffer,\n\t\t\t\t\tu16 *buflen,\n\t\t\t\t   struct cifs_ses *ses,\n\t\t\t\t   const struct nls_table *nls_cp)\n{\n\tint rc;\n\tAUTHENTICATE_MESSAGE *sec_blob;\n\t__u32 flags;\n\tunsigned char *tmp;\n\n\trc = setup_ntlmv2_rsp(ses, nls_cp);\n\tif (rc) {\n\t\tcifs_dbg(VFS, \"Error %d during NTLMSSP authentication\\n\", rc);\n\t\t*buflen = 0;\n\t\tgoto setup_ntlmv2_ret;\n\t}\n\t*pbuffer = kmalloc(size_of_ntlmssp_blob(ses), GFP_KERNEL);\n\tsec_blob = (AUTHENTICATE_MESSAGE *)*pbuffer;\n\n\tmemcpy(sec_blob->Signature, NTLMSSP_SIGNATURE, 8);\n\tsec_blob->MessageType = NtLmAuthenticate;\n\n\tflags = NTLMSSP_NEGOTIATE_56 |\n\t\tNTLMSSP_REQUEST_TARGET | NTLMSSP_NEGOTIATE_TARGET_INFO |\n\t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |\n\t\tNTLMSSP_NEGOTIATE_SEAL;\n\tif (ses->server->sign)\n\t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)\n\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n\n\ttmp = *pbuffer + sizeof(AUTHENTICATE_MESSAGE);\n\tsec_blob->NegotiateFlags = cpu_to_le32(flags);\n\n\tsec_blob->LmChallengeResponse.BufferOffset =\n\t\t\t\tcpu_to_le32(sizeof(AUTHENTICATE_MESSAGE));\n\tsec_blob->LmChallengeResponse.Length = 0;\n\tsec_blob->LmChallengeResponse.MaximumLength = 0;\n\n\tsec_blob->NtChallengeResponse.BufferOffset =\n\t\t\t\tcpu_to_le32(tmp - *pbuffer);\n\tif (ses->user_name != NULL) {\n\t\tmemcpy(tmp, ses->auth_key.response + CIFS_SESS_KEY_SIZE,\n\t\t\t\tses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t\ttmp += ses->auth_key.len - CIFS_SESS_KEY_SIZE;\n\n\t\tsec_blob->NtChallengeResponse.Length =\n\t\t\t\tcpu_to_le16(ses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t\tsec_blob->NtChallengeResponse.MaximumLength =\n\t\t\t\tcpu_to_le16(ses->auth_key.len - CIFS_SESS_KEY_SIZE);\n\t} else {\n\t\t/*\n\t\t * don't send an NT Response for anonymous access\n\t\t */\n\t\tsec_blob->NtChallengeResponse.Length = 0;\n\t\tsec_blob->NtChallengeResponse.MaximumLength = 0;\n\t}\n\n\tif (ses->domainName == NULL) {\n\t\tsec_blob->DomainName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->DomainName.Length = 0;\n\t\tsec_blob->DomainName.MaximumLength = 0;\n\t\ttmp += 2;\n\t} else {\n\t\tint len;\n\t\tlen = cifs_strtoUTF16((__le16 *)tmp, ses->domainName,\n\t\t\t\t      CIFS_MAX_DOMAINNAME_LEN, nls_cp);\n\t\tlen *= 2; /* unicode is 2 bytes each */\n\t\tsec_blob->DomainName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->DomainName.Length = cpu_to_le16(len);\n\t\tsec_blob->DomainName.MaximumLength = cpu_to_le16(len);\n\t\ttmp += len;\n\t}\n\n\tif (ses->user_name == NULL) {\n\t\tsec_blob->UserName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->UserName.Length = 0;\n\t\tsec_blob->UserName.MaximumLength = 0;\n\t\ttmp += 2;\n\t} else {\n\t\tint len;\n\t\tlen = cifs_strtoUTF16((__le16 *)tmp, ses->user_name,\n\t\t\t\t      CIFS_MAX_USERNAME_LEN, nls_cp);\n\t\tlen *= 2; /* unicode is 2 bytes each */\n\t\tsec_blob->UserName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->UserName.Length = cpu_to_le16(len);\n\t\tsec_blob->UserName.MaximumLength = cpu_to_le16(len);\n\t\ttmp += len;\n\t}\n\n\tsec_blob->WorkstationName.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\tsec_blob->WorkstationName.Length = 0;\n\tsec_blob->WorkstationName.MaximumLength = 0;\n\ttmp += 2;\n\n\tif (((ses->ntlmssp->server_flags & NTLMSSP_NEGOTIATE_KEY_XCH) ||\n\t\t(ses->ntlmssp->server_flags & NTLMSSP_NEGOTIATE_EXTENDED_SEC))\n\t\t\t&& !calc_seckey(ses)) {\n\t\tmemcpy(tmp, ses->ntlmssp->ciphertext, CIFS_CPHTXT_SIZE);\n\t\tsec_blob->SessionKey.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->SessionKey.Length = cpu_to_le16(CIFS_CPHTXT_SIZE);\n\t\tsec_blob->SessionKey.MaximumLength =\n\t\t\t\tcpu_to_le16(CIFS_CPHTXT_SIZE);\n\t\ttmp += CIFS_CPHTXT_SIZE;\n\t} else {\n\t\tsec_blob->SessionKey.BufferOffset = cpu_to_le32(tmp - *pbuffer);\n\t\tsec_blob->SessionKey.Length = 0;\n\t\tsec_blob->SessionKey.MaximumLength = 0;\n\t}\n\n\t*buflen = tmp - *pbuffer;\nsetup_ntlmv2_ret:\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -23,13 +23,12 @@\n \tflags = NTLMSSP_NEGOTIATE_56 |\n \t\tNTLMSSP_REQUEST_TARGET | NTLMSSP_NEGOTIATE_TARGET_INFO |\n \t\tNTLMSSP_NEGOTIATE_128 | NTLMSSP_NEGOTIATE_UNICODE |\n-\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;\n-\tif (ses->server->sign) {\n+\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |\n+\t\tNTLMSSP_NEGOTIATE_SEAL;\n+\tif (ses->server->sign)\n \t\tflags |= NTLMSSP_NEGOTIATE_SIGN;\n-\t\tif (!ses->server->session_estab ||\n-\t\t\t\tses->ntlmssp->sesskey_per_smbsess)\n-\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n-\t}\n+\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)\n+\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;\n \n \ttmp = *pbuffer + sizeof(AUTHENTICATE_MESSAGE);\n \tsec_blob->NegotiateFlags = cpu_to_le32(flags);",
        "function_modified_lines": {
            "added": [
                "\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC |",
                "\t\tNTLMSSP_NEGOTIATE_SEAL;",
                "\tif (ses->server->sign)",
                "\tif (!ses->server->session_estab || ses->ntlmssp->sesskey_per_smbsess)",
                "\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;"
            ],
            "deleted": [
                "\t\tNTLMSSP_NEGOTIATE_NTLM | NTLMSSP_NEGOTIATE_EXTENDED_SEC;",
                "\tif (ses->server->sign) {",
                "\t\tif (!ses->server->session_estab ||",
                "\t\t\t\tses->ntlmssp->sesskey_per_smbsess)",
                "\t\t\tflags |= NTLMSSP_NEGOTIATE_KEY_XCH;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux kernel before version 4.11 is vulnerable to a NULL pointer dereference in fs/cifs/cifsencrypt.c:setup_ntlmv2_rsp() that allows an attacker controlling a CIFS server to kernel panic a client that has this server mounted, because an empty TargetInfo field in an NTLMSSP setup negotiation response is mishandled during session recovery.",
        "id": 1590
    },
    {
        "cve_id": "CVE-2018-14616",
        "code_before_change": "static struct bio *f2fs_grab_read_bio(struct inode *inode, block_t blkaddr,\n\t\t\t\t\tunsigned nr_pages, unsigned op_flag)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct bio *bio;\n\tstruct bio_post_read_ctx *ctx;\n\tunsigned int post_read_steps = 0;\n\n\tbio = f2fs_bio_alloc(sbi, min_t(int, nr_pages, BIO_MAX_PAGES), false);\n\tif (!bio)\n\t\treturn ERR_PTR(-ENOMEM);\n\tf2fs_target_device(sbi, blkaddr, bio);\n\tbio->bi_end_io = f2fs_read_end_io;\n\tbio_set_op_attrs(bio, REQ_OP_READ, op_flag);\n\n\tif (f2fs_encrypted_file(inode))\n\t\tpost_read_steps |= 1 << STEP_DECRYPT;\n\tif (post_read_steps) {\n\t\tctx = mempool_alloc(bio_post_read_ctx_pool, GFP_NOFS);\n\t\tif (!ctx) {\n\t\t\tbio_put(bio);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->bio = bio;\n\t\tctx->enabled_steps = post_read_steps;\n\t\tbio->bi_private = ctx;\n\n\t\t/* wait the page to be moved by cleaning */\n\t\tf2fs_wait_on_block_writeback(sbi, blkaddr);\n\t}\n\n\treturn bio;\n}",
        "code_after_change": "static struct bio *f2fs_grab_read_bio(struct inode *inode, block_t blkaddr,\n\t\t\t\t\tunsigned nr_pages, unsigned op_flag)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_I_SB(inode);\n\tstruct bio *bio;\n\tstruct bio_post_read_ctx *ctx;\n\tunsigned int post_read_steps = 0;\n\n\tif (!f2fs_is_valid_blkaddr(sbi, blkaddr, DATA_GENERIC))\n\t\treturn ERR_PTR(-EFAULT);\n\n\tbio = f2fs_bio_alloc(sbi, min_t(int, nr_pages, BIO_MAX_PAGES), false);\n\tif (!bio)\n\t\treturn ERR_PTR(-ENOMEM);\n\tf2fs_target_device(sbi, blkaddr, bio);\n\tbio->bi_end_io = f2fs_read_end_io;\n\tbio_set_op_attrs(bio, REQ_OP_READ, op_flag);\n\n\tif (f2fs_encrypted_file(inode))\n\t\tpost_read_steps |= 1 << STEP_DECRYPT;\n\tif (post_read_steps) {\n\t\tctx = mempool_alloc(bio_post_read_ctx_pool, GFP_NOFS);\n\t\tif (!ctx) {\n\t\t\tbio_put(bio);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->bio = bio;\n\t\tctx->enabled_steps = post_read_steps;\n\t\tbio->bi_private = ctx;\n\n\t\t/* wait the page to be moved by cleaning */\n\t\tf2fs_wait_on_block_writeback(sbi, blkaddr);\n\t}\n\n\treturn bio;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tstruct bio *bio;\n \tstruct bio_post_read_ctx *ctx;\n \tunsigned int post_read_steps = 0;\n+\n+\tif (!f2fs_is_valid_blkaddr(sbi, blkaddr, DATA_GENERIC))\n+\t\treturn ERR_PTR(-EFAULT);\n \n \tbio = f2fs_bio_alloc(sbi, min_t(int, nr_pages, BIO_MAX_PAGES), false);\n \tif (!bio)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!f2fs_is_valid_blkaddr(sbi, blkaddr, DATA_GENERIC))",
                "\t\treturn ERR_PTR(-EFAULT);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 4.17.10. There is a NULL pointer dereference in fscrypt_do_page_crypto() in fs/crypto/crypto.c when operating on a file in a corrupted f2fs image.",
        "id": 1687
    },
    {
        "cve_id": "CVE-2022-3112",
        "code_before_change": "void amvdec_add_ts(struct amvdec_session *sess, u64 ts,\n\t\t   struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)\n{\n\tstruct amvdec_timestamp *new_ts;\n\tunsigned long flags;\n\n\tnew_ts = kzalloc(sizeof(*new_ts), GFP_KERNEL);\n\tnew_ts->ts = ts;\n\tnew_ts->tc = tc;\n\tnew_ts->offset = offset;\n\tnew_ts->flags = vbuf_flags;\n\n\tspin_lock_irqsave(&sess->ts_spinlock, flags);\n\tlist_add_tail(&new_ts->list, &sess->timestamps);\n\tspin_unlock_irqrestore(&sess->ts_spinlock, flags);\n}",
        "code_after_change": "int amvdec_add_ts(struct amvdec_session *sess, u64 ts,\n\t\t  struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)\n{\n\tstruct amvdec_timestamp *new_ts;\n\tunsigned long flags;\n\n\tnew_ts = kzalloc(sizeof(*new_ts), GFP_KERNEL);\n\tif (!new_ts)\n\t\treturn -ENOMEM;\n\n\tnew_ts->ts = ts;\n\tnew_ts->tc = tc;\n\tnew_ts->offset = offset;\n\tnew_ts->flags = vbuf_flags;\n\n\tspin_lock_irqsave(&sess->ts_spinlock, flags);\n\tlist_add_tail(&new_ts->list, &sess->timestamps);\n\tspin_unlock_irqrestore(&sess->ts_spinlock, flags);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,13 @@\n-void amvdec_add_ts(struct amvdec_session *sess, u64 ts,\n-\t\t   struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)\n+int amvdec_add_ts(struct amvdec_session *sess, u64 ts,\n+\t\t  struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)\n {\n \tstruct amvdec_timestamp *new_ts;\n \tunsigned long flags;\n \n \tnew_ts = kzalloc(sizeof(*new_ts), GFP_KERNEL);\n+\tif (!new_ts)\n+\t\treturn -ENOMEM;\n+\n \tnew_ts->ts = ts;\n \tnew_ts->tc = tc;\n \tnew_ts->offset = offset;\n@@ -13,4 +16,5 @@\n \tspin_lock_irqsave(&sess->ts_spinlock, flags);\n \tlist_add_tail(&new_ts->list, &sess->timestamps);\n \tspin_unlock_irqrestore(&sess->ts_spinlock, flags);\n+\treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "int amvdec_add_ts(struct amvdec_session *sess, u64 ts,",
                "\t\t  struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)",
                "\tif (!new_ts)",
                "\t\treturn -ENOMEM;",
                "",
                "\treturn 0;"
            ],
            "deleted": [
                "void amvdec_add_ts(struct amvdec_session *sess, u64 ts,",
                "\t\t   struct v4l2_timecode tc, u32 offset, u32 vbuf_flags)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. amvdec_set_canvases in drivers/staging/media/meson/vdec/vdec_helpers.c lacks check of the return value of kzalloc() and will cause the null pointer dereference.",
        "id": 3558
    },
    {
        "cve_id": "CVE-2020-27675",
        "code_before_change": "static void clear_evtchn_to_irq_row(unsigned row)\n{\n\tunsigned col;\n\n\tfor (col = 0; col < EVTCHN_PER_ROW; col++)\n\t\tevtchn_to_irq[row][col] = -1;\n}",
        "code_after_change": "static void clear_evtchn_to_irq_row(unsigned row)\n{\n\tunsigned col;\n\n\tfor (col = 0; col < EVTCHN_PER_ROW; col++)\n\t\tWRITE_ONCE(evtchn_to_irq[row][col], -1);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,5 +3,5 @@\n \tunsigned col;\n \n \tfor (col = 0; col < EVTCHN_PER_ROW; col++)\n-\t\tevtchn_to_irq[row][col] = -1;\n+\t\tWRITE_ONCE(evtchn_to_irq[row][col], -1);\n }",
        "function_modified_lines": {
            "added": [
                "\t\tWRITE_ONCE(evtchn_to_irq[row][col], -1);"
            ],
            "deleted": [
                "\t\tevtchn_to_irq[row][col] = -1;"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. drivers/xen/events/events_base.c allows event-channel removal during the event-handling loop (a race condition). This can cause a use-after-free or NULL pointer dereference, as demonstrated by a dom0 crash via events for an in-reconfiguration paravirtualized device, aka CID-073d0552ead5.",
        "id": 2622
    },
    {
        "cve_id": "CVE-2019-15922",
        "code_before_change": "static int pf_detect(void)\n{\n\tstruct pf_unit *pf = units;\n\tint k, unit;\n\n\tprintk(\"%s: %s version %s, major %d, cluster %d, nice %d\\n\",\n\t       name, name, PF_VERSION, major, cluster, nice);\n\n\tpar_drv = pi_register_driver(name);\n\tif (!par_drv) {\n\t\tpr_err(\"failed to register %s driver\\n\", name);\n\t\treturn -1;\n\t}\n\tk = 0;\n\tif (pf_drive_count == 0) {\n\t\tif (pi_init(pf->pi, 1, -1, -1, -1, -1, -1, pf_scratch, PI_PF,\n\t\t\t    verbose, pf->name)) {\n\t\t\tif (!pf_probe(pf) && pf->disk) {\n\t\t\t\tpf->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(pf->pi);\n\t\t}\n\n\t} else\n\t\tfor (unit = 0; unit < PF_UNITS; unit++, pf++) {\n\t\t\tint *conf = *drives[unit];\n\t\t\tif (!conf[D_PRT])\n\t\t\t\tcontinue;\n\t\t\tif (pi_init(pf->pi, 0, conf[D_PRT], conf[D_MOD],\n\t\t\t\t    conf[D_UNI], conf[D_PRO], conf[D_DLY],\n\t\t\t\t    pf_scratch, PI_PF, verbose, pf->name)) {\n\t\t\t\tif (pf->disk && !pf_probe(pf)) {\n\t\t\t\t\tpf->present = 1;\n\t\t\t\t\tk++;\n\t\t\t\t} else\n\t\t\t\t\tpi_release(pf->pi);\n\t\t\t}\n\t\t}\n\tif (k)\n\t\treturn 0;\n\n\tprintk(\"%s: No ATAPI disk detected\\n\", name);\n\tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n\t\tblk_cleanup_queue(pf->disk->queue);\n\t\tpf->disk->queue = NULL;\n\t\tblk_mq_free_tag_set(&pf->tag_set);\n\t\tput_disk(pf->disk);\n\t}\n\tpi_unregister_driver(par_drv);\n\treturn -1;\n}",
        "code_after_change": "static int pf_detect(void)\n{\n\tstruct pf_unit *pf = units;\n\tint k, unit;\n\n\tprintk(\"%s: %s version %s, major %d, cluster %d, nice %d\\n\",\n\t       name, name, PF_VERSION, major, cluster, nice);\n\n\tpar_drv = pi_register_driver(name);\n\tif (!par_drv) {\n\t\tpr_err(\"failed to register %s driver\\n\", name);\n\t\treturn -1;\n\t}\n\tk = 0;\n\tif (pf_drive_count == 0) {\n\t\tif (pi_init(pf->pi, 1, -1, -1, -1, -1, -1, pf_scratch, PI_PF,\n\t\t\t    verbose, pf->name)) {\n\t\t\tif (!pf_probe(pf) && pf->disk) {\n\t\t\t\tpf->present = 1;\n\t\t\t\tk++;\n\t\t\t} else\n\t\t\t\tpi_release(pf->pi);\n\t\t}\n\n\t} else\n\t\tfor (unit = 0; unit < PF_UNITS; unit++, pf++) {\n\t\t\tint *conf = *drives[unit];\n\t\t\tif (!conf[D_PRT])\n\t\t\t\tcontinue;\n\t\t\tif (pi_init(pf->pi, 0, conf[D_PRT], conf[D_MOD],\n\t\t\t\t    conf[D_UNI], conf[D_PRO], conf[D_DLY],\n\t\t\t\t    pf_scratch, PI_PF, verbose, pf->name)) {\n\t\t\t\tif (pf->disk && !pf_probe(pf)) {\n\t\t\t\t\tpf->present = 1;\n\t\t\t\t\tk++;\n\t\t\t\t} else\n\t\t\t\t\tpi_release(pf->pi);\n\t\t\t}\n\t\t}\n\tif (k)\n\t\treturn 0;\n\n\tprintk(\"%s: No ATAPI disk detected\\n\", name);\n\tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n\t\tif (!pf->disk)\n\t\t\tcontinue;\n\t\tblk_cleanup_queue(pf->disk->queue);\n\t\tpf->disk->queue = NULL;\n\t\tblk_mq_free_tag_set(&pf->tag_set);\n\t\tput_disk(pf->disk);\n\t}\n\tpi_unregister_driver(par_drv);\n\treturn -1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,6 +42,8 @@\n \n \tprintk(\"%s: No ATAPI disk detected\\n\", name);\n \tfor (pf = units, unit = 0; unit < PF_UNITS; pf++, unit++) {\n+\t\tif (!pf->disk)\n+\t\t\tcontinue;\n \t\tblk_cleanup_queue(pf->disk->queue);\n \t\tpf->disk->queue = NULL;\n \t\tblk_mq_free_tag_set(&pf->tag_set);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!pf->disk)",
                "\t\t\tcontinue;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.9. There is a NULL pointer dereference for a pf data structure if alloc_disk fails in drivers/block/paride/pf.c.",
        "id": 2029
    },
    {
        "cve_id": "CVE-2017-7374",
        "code_before_change": "int fscrypt_setup_filename(struct inode *dir, const struct qstr *iname,\n\t\t\t      int lookup, struct fscrypt_name *fname)\n{\n\tint ret = 0, bigname = 0;\n\n\tmemset(fname, 0, sizeof(struct fscrypt_name));\n\tfname->usr_fname = iname;\n\n\tif (!dir->i_sb->s_cop->is_encrypted(dir) ||\n\t\t\t\tfscrypt_is_dot_dotdot(iname)) {\n\t\tfname->disk_name.name = (unsigned char *)iname->name;\n\t\tfname->disk_name.len = iname->len;\n\t\treturn 0;\n\t}\n\tret = fscrypt_get_crypt_info(dir);\n\tif (ret && ret != -EOPNOTSUPP)\n\t\treturn ret;\n\n\tif (dir->i_crypt_info) {\n\t\tret = fscrypt_fname_alloc_buffer(dir, iname->len,\n\t\t\t\t\t\t\t&fname->crypto_buf);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = fname_encrypt(dir, iname, &fname->crypto_buf);\n\t\tif (ret)\n\t\t\tgoto errout;\n\t\tfname->disk_name.name = fname->crypto_buf.name;\n\t\tfname->disk_name.len = fname->crypto_buf.len;\n\t\treturn 0;\n\t}\n\tif (!lookup)\n\t\treturn -ENOKEY;\n\n\t/*\n\t * We don't have the key and we are doing a lookup; decode the\n\t * user-supplied name\n\t */\n\tif (iname->name[0] == '_')\n\t\tbigname = 1;\n\tif ((bigname && (iname->len != 33)) || (!bigname && (iname->len > 43)))\n\t\treturn -ENOENT;\n\n\tfname->crypto_buf.name = kmalloc(32, GFP_KERNEL);\n\tif (fname->crypto_buf.name == NULL)\n\t\treturn -ENOMEM;\n\n\tret = digest_decode(iname->name + bigname, iname->len - bigname,\n\t\t\t\tfname->crypto_buf.name);\n\tif (ret < 0) {\n\t\tret = -ENOENT;\n\t\tgoto errout;\n\t}\n\tfname->crypto_buf.len = ret;\n\tif (bigname) {\n\t\tmemcpy(&fname->hash, fname->crypto_buf.name, 4);\n\t\tmemcpy(&fname->minor_hash, fname->crypto_buf.name + 4, 4);\n\t} else {\n\t\tfname->disk_name.name = fname->crypto_buf.name;\n\t\tfname->disk_name.len = fname->crypto_buf.len;\n\t}\n\treturn 0;\n\nerrout:\n\tfscrypt_fname_free_buffer(&fname->crypto_buf);\n\treturn ret;\n}",
        "code_after_change": "int fscrypt_setup_filename(struct inode *dir, const struct qstr *iname,\n\t\t\t      int lookup, struct fscrypt_name *fname)\n{\n\tint ret = 0, bigname = 0;\n\n\tmemset(fname, 0, sizeof(struct fscrypt_name));\n\tfname->usr_fname = iname;\n\n\tif (!dir->i_sb->s_cop->is_encrypted(dir) ||\n\t\t\t\tfscrypt_is_dot_dotdot(iname)) {\n\t\tfname->disk_name.name = (unsigned char *)iname->name;\n\t\tfname->disk_name.len = iname->len;\n\t\treturn 0;\n\t}\n\tret = fscrypt_get_encryption_info(dir);\n\tif (ret && ret != -EOPNOTSUPP)\n\t\treturn ret;\n\n\tif (dir->i_crypt_info) {\n\t\tret = fscrypt_fname_alloc_buffer(dir, iname->len,\n\t\t\t\t\t\t\t&fname->crypto_buf);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = fname_encrypt(dir, iname, &fname->crypto_buf);\n\t\tif (ret)\n\t\t\tgoto errout;\n\t\tfname->disk_name.name = fname->crypto_buf.name;\n\t\tfname->disk_name.len = fname->crypto_buf.len;\n\t\treturn 0;\n\t}\n\tif (!lookup)\n\t\treturn -ENOKEY;\n\n\t/*\n\t * We don't have the key and we are doing a lookup; decode the\n\t * user-supplied name\n\t */\n\tif (iname->name[0] == '_')\n\t\tbigname = 1;\n\tif ((bigname && (iname->len != 33)) || (!bigname && (iname->len > 43)))\n\t\treturn -ENOENT;\n\n\tfname->crypto_buf.name = kmalloc(32, GFP_KERNEL);\n\tif (fname->crypto_buf.name == NULL)\n\t\treturn -ENOMEM;\n\n\tret = digest_decode(iname->name + bigname, iname->len - bigname,\n\t\t\t\tfname->crypto_buf.name);\n\tif (ret < 0) {\n\t\tret = -ENOENT;\n\t\tgoto errout;\n\t}\n\tfname->crypto_buf.len = ret;\n\tif (bigname) {\n\t\tmemcpy(&fname->hash, fname->crypto_buf.name, 4);\n\t\tmemcpy(&fname->minor_hash, fname->crypto_buf.name + 4, 4);\n\t} else {\n\t\tfname->disk_name.name = fname->crypto_buf.name;\n\t\tfname->disk_name.len = fname->crypto_buf.len;\n\t}\n\treturn 0;\n\nerrout:\n\tfscrypt_fname_free_buffer(&fname->crypto_buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \t\tfname->disk_name.len = iname->len;\n \t\treturn 0;\n \t}\n-\tret = fscrypt_get_crypt_info(dir);\n+\tret = fscrypt_get_encryption_info(dir);\n \tif (ret && ret != -EOPNOTSUPP)\n \t\treturn ret;\n ",
        "function_modified_lines": {
            "added": [
                "\tret = fscrypt_get_encryption_info(dir);"
            ],
            "deleted": [
                "\tret = fscrypt_get_crypt_info(dir);"
            ]
        },
        "cwe": [
            "CWE-476",
            "CWE-416"
        ],
        "cve_description": "Use-after-free vulnerability in fs/crypto/ in the Linux kernel before 4.10.7 allows local users to cause a denial of service (NULL pointer dereference) or possibly gain privileges by revoking keyring keys being used for ext4, f2fs, or ubifs encryption, causing cryptographic transform objects to be freed prematurely.",
        "id": 1498
    },
    {
        "cve_id": "CVE-2020-35499",
        "code_before_change": "static int sco_sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint len, err = 0;\n\tstruct bt_voice voice;\n\tu32 phys;\n\tint pkt_status;\n\n\tBT_DBG(\"sk %p\", sk);\n\n\tif (level == SOL_SCO)\n\t\treturn sco_sock_getsockopt_old(sock, optname, optval, optlen);\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\n\tcase BT_DEFER_SETUP:\n\t\tif (sk->sk_state != BT_BOUND && sk->sk_state != BT_LISTEN) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (put_user(test_bit(BT_SK_DEFER_SETUP, &bt_sk(sk)->flags),\n\t\t\t     (u32 __user *)optval))\n\t\t\terr = -EFAULT;\n\n\t\tbreak;\n\n\tcase BT_VOICE:\n\t\tvoice.setting = sco_pi(sk)->setting;\n\n\t\tlen = min_t(unsigned int, len, sizeof(voice));\n\t\tif (copy_to_user(optval, (char *)&voice, len))\n\t\t\terr = -EFAULT;\n\n\t\tbreak;\n\n\tcase BT_PHY:\n\t\tif (sk->sk_state != BT_CONNECTED) {\n\t\t\terr = -ENOTCONN;\n\t\t\tbreak;\n\t\t}\n\n\t\tphys = hci_conn_get_phy(sco_pi(sk)->conn->hcon);\n\n\t\tif (put_user(phys, (u32 __user *) optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tcase BT_PKT_STATUS:\n\t\tpkt_status = (sco_pi(sk)->cmsg_mask & SCO_CMSG_PKT_STATUS);\n\n\t\tif (put_user(pkt_status, (int __user *)optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tcase BT_SNDMTU:\n\tcase BT_RCVMTU:\n\t\tif (put_user(sco_pi(sk)->conn->mtu, (u32 __user *)optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tdefault:\n\t\terr = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\treturn err;\n}",
        "code_after_change": "static int sco_sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint len, err = 0;\n\tstruct bt_voice voice;\n\tu32 phys;\n\tint pkt_status;\n\n\tBT_DBG(\"sk %p\", sk);\n\n\tif (level == SOL_SCO)\n\t\treturn sco_sock_getsockopt_old(sock, optname, optval, optlen);\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\n\tcase BT_DEFER_SETUP:\n\t\tif (sk->sk_state != BT_BOUND && sk->sk_state != BT_LISTEN) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (put_user(test_bit(BT_SK_DEFER_SETUP, &bt_sk(sk)->flags),\n\t\t\t     (u32 __user *)optval))\n\t\t\terr = -EFAULT;\n\n\t\tbreak;\n\n\tcase BT_VOICE:\n\t\tvoice.setting = sco_pi(sk)->setting;\n\n\t\tlen = min_t(unsigned int, len, sizeof(voice));\n\t\tif (copy_to_user(optval, (char *)&voice, len))\n\t\t\terr = -EFAULT;\n\n\t\tbreak;\n\n\tcase BT_PHY:\n\t\tif (sk->sk_state != BT_CONNECTED) {\n\t\t\terr = -ENOTCONN;\n\t\t\tbreak;\n\t\t}\n\n\t\tphys = hci_conn_get_phy(sco_pi(sk)->conn->hcon);\n\n\t\tif (put_user(phys, (u32 __user *) optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tcase BT_PKT_STATUS:\n\t\tpkt_status = (sco_pi(sk)->cmsg_mask & SCO_CMSG_PKT_STATUS);\n\n\t\tif (put_user(pkt_status, (int __user *)optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tcase BT_SNDMTU:\n\tcase BT_RCVMTU:\n\t\tif (sk->sk_state != BT_CONNECTED) {\n\t\t\terr = -ENOTCONN;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (put_user(sco_pi(sk)->conn->mtu, (u32 __user *)optval))\n\t\t\terr = -EFAULT;\n\t\tbreak;\n\n\tdefault:\n\t\terr = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -61,6 +61,11 @@\n \n \tcase BT_SNDMTU:\n \tcase BT_RCVMTU:\n+\t\tif (sk->sk_state != BT_CONNECTED) {\n+\t\t\terr = -ENOTCONN;\n+\t\t\tbreak;\n+\t\t}\n+\n \t\tif (put_user(sco_pi(sk)->conn->mtu, (u32 __user *)optval))\n \t\t\terr = -EFAULT;\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\t\tif (sk->sk_state != BT_CONNECTED) {",
                "\t\t\terr = -ENOTCONN;",
                "\t\t\tbreak;",
                "\t\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw in Linux kernel versions prior to 5.11 may be seen if sco_sock_getsockopt function in net/bluetooth/sco.c do not have a sanity check for a socket connection, when using BT_SNDMTU/BT_RCVMTU for SCO sockets. This could allow a local attacker with a special user privilege to crash the system (DOS) or leak kernel internal information.",
        "id": 2705
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "bool btf_ctx_access(int off, int size, enum bpf_access_type type,\n\t\t    const struct bpf_prog *prog,\n\t\t    struct bpf_insn_access_aux *info)\n{\n\tconst struct btf_type *t = prog->aux->attach_func_proto;\n\tstruct bpf_prog *tgt_prog = prog->aux->dst_prog;\n\tstruct btf *btf = bpf_prog_get_target_btf(prog);\n\tconst char *tname = prog->aux->attach_func_name;\n\tstruct bpf_verifier_log *log = info->log;\n\tconst struct btf_param *args;\n\tu32 nr_args, arg;\n\tint i, ret;\n\n\tif (off % 8) {\n\t\tbpf_log(log, \"func '%s' offset %d is not multiple of 8\\n\",\n\t\t\ttname, off);\n\t\treturn false;\n\t}\n\targ = off / 8;\n\targs = (const struct btf_param *)(t + 1);\n\t/* if (t == NULL) Fall back to default BPF prog with\n\t * MAX_BPF_FUNC_REG_ARGS u64 arguments.\n\t */\n\tnr_args = t ? btf_type_vlen(t) : MAX_BPF_FUNC_REG_ARGS;\n\tif (prog->aux->attach_btf_trace) {\n\t\t/* skip first 'void *__data' argument in btf_trace_##name typedef */\n\t\targs++;\n\t\tnr_args--;\n\t}\n\n\tif (arg > nr_args) {\n\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\ttname, arg + 1);\n\t\treturn false;\n\t}\n\n\tif (arg == nr_args) {\n\t\tswitch (prog->expected_attach_type) {\n\t\tcase BPF_LSM_MAC:\n\t\tcase BPF_TRACE_FEXIT:\n\t\t\t/* When LSM programs are attached to void LSM hooks\n\t\t\t * they use FEXIT trampolines and when attached to\n\t\t\t * int LSM hooks, they use MODIFY_RETURN trampolines.\n\t\t\t *\n\t\t\t * While the LSM programs are BPF_MODIFY_RETURN-like\n\t\t\t * the check:\n\t\t\t *\n\t\t\t *\tif (ret_type != 'int')\n\t\t\t *\t\treturn -EINVAL;\n\t\t\t *\n\t\t\t * is _not_ done here. This is still safe as LSM hooks\n\t\t\t * have only void and int return types.\n\t\t\t */\n\t\t\tif (!t)\n\t\t\t\treturn true;\n\t\t\tt = btf_type_by_id(btf, t->type);\n\t\t\tbreak;\n\t\tcase BPF_MODIFY_RETURN:\n\t\t\t/* For now the BPF_MODIFY_RETURN can only be attached to\n\t\t\t * functions that return an int.\n\t\t\t */\n\t\t\tif (!t)\n\t\t\t\treturn false;\n\n\t\t\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\t\t\tif (!btf_type_is_small_int(t)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"ret type %s not allowed for fmod_ret\\n\",\n\t\t\t\t\tbtf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\t\ttname, arg + 1);\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tif (!t)\n\t\t\t/* Default prog with MAX_BPF_FUNC_REG_ARGS args */\n\t\t\treturn true;\n\t\tt = btf_type_by_id(btf, args[arg].type);\n\t}\n\n\t/* skip modifiers */\n\twhile (btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (btf_type_is_small_int(t) || btf_type_is_enum(t))\n\t\t/* accessing a scalar */\n\t\treturn true;\n\tif (!btf_type_is_ptr(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d '%s' has type %s. Only pointer access is allowed\\n\",\n\t\t\ttname, arg,\n\t\t\t__btf_name_by_offset(btf, t->name_off),\n\t\t\tbtf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\treturn false;\n\t}\n\n\t/* check for PTR_TO_RDONLY_BUF_OR_NULL or PTR_TO_RDWR_BUF_OR_NULL */\n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\n\t\tif (ctx_arg_info->offset == off &&\n\t\t    (ctx_arg_info->reg_type == PTR_TO_RDONLY_BUF_OR_NULL ||\n\t\t     ctx_arg_info->reg_type == PTR_TO_RDWR_BUF_OR_NULL)) {\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (t->type == 0)\n\t\t/* This is a pointer to void.\n\t\t * It is the same as scalar from the verifier safety pov.\n\t\t * No further pointer walking is allowed.\n\t\t */\n\t\treturn true;\n\n\tif (is_int_ptr(btf, t))\n\t\treturn true;\n\n\t/* this is a pointer to another type */\n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\n\t\tif (ctx_arg_info->offset == off) {\n\t\t\tif (!ctx_arg_info->btf_id) {\n\t\t\t\tbpf_log(log,\"invalid btf_id for context argument offset %u\\n\", off);\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ctx_arg_info->btf_id;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tinfo->reg_type = PTR_TO_BTF_ID;\n\tif (tgt_prog) {\n\t\tenum bpf_prog_type tgt_type;\n\n\t\tif (tgt_prog->type == BPF_PROG_TYPE_EXT)\n\t\t\ttgt_type = tgt_prog->aux->saved_dst_prog_type;\n\t\telse\n\t\t\ttgt_type = tgt_prog->type;\n\n\t\tret = btf_translate_to_vmlinux(log, btf, t, tgt_type, arg);\n\t\tif (ret > 0) {\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ret;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tinfo->btf = btf;\n\tinfo->btf_id = t->type;\n\tt = btf_type_by_id(btf, t->type);\n\t/* skip modifiers */\n\twhile (btf_type_is_modifier(t)) {\n\t\tinfo->btf_id = t->type;\n\t\tt = btf_type_by_id(btf, t->type);\n\t}\n\tif (!btf_type_is_struct(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d type %s is not a struct\\n\",\n\t\t\ttname, arg, btf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\treturn false;\n\t}\n\tbpf_log(log, \"func '%s' arg%d has btf_id %d type %s '%s'\\n\",\n\t\ttname, arg, info->btf_id, btf_kind_str[BTF_INFO_KIND(t->info)],\n\t\t__btf_name_by_offset(btf, t->name_off));\n\treturn true;\n}",
        "code_after_change": "bool btf_ctx_access(int off, int size, enum bpf_access_type type,\n\t\t    const struct bpf_prog *prog,\n\t\t    struct bpf_insn_access_aux *info)\n{\n\tconst struct btf_type *t = prog->aux->attach_func_proto;\n\tstruct bpf_prog *tgt_prog = prog->aux->dst_prog;\n\tstruct btf *btf = bpf_prog_get_target_btf(prog);\n\tconst char *tname = prog->aux->attach_func_name;\n\tstruct bpf_verifier_log *log = info->log;\n\tconst struct btf_param *args;\n\tu32 nr_args, arg;\n\tint i, ret;\n\n\tif (off % 8) {\n\t\tbpf_log(log, \"func '%s' offset %d is not multiple of 8\\n\",\n\t\t\ttname, off);\n\t\treturn false;\n\t}\n\targ = off / 8;\n\targs = (const struct btf_param *)(t + 1);\n\t/* if (t == NULL) Fall back to default BPF prog with\n\t * MAX_BPF_FUNC_REG_ARGS u64 arguments.\n\t */\n\tnr_args = t ? btf_type_vlen(t) : MAX_BPF_FUNC_REG_ARGS;\n\tif (prog->aux->attach_btf_trace) {\n\t\t/* skip first 'void *__data' argument in btf_trace_##name typedef */\n\t\targs++;\n\t\tnr_args--;\n\t}\n\n\tif (arg > nr_args) {\n\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\ttname, arg + 1);\n\t\treturn false;\n\t}\n\n\tif (arg == nr_args) {\n\t\tswitch (prog->expected_attach_type) {\n\t\tcase BPF_LSM_MAC:\n\t\tcase BPF_TRACE_FEXIT:\n\t\t\t/* When LSM programs are attached to void LSM hooks\n\t\t\t * they use FEXIT trampolines and when attached to\n\t\t\t * int LSM hooks, they use MODIFY_RETURN trampolines.\n\t\t\t *\n\t\t\t * While the LSM programs are BPF_MODIFY_RETURN-like\n\t\t\t * the check:\n\t\t\t *\n\t\t\t *\tif (ret_type != 'int')\n\t\t\t *\t\treturn -EINVAL;\n\t\t\t *\n\t\t\t * is _not_ done here. This is still safe as LSM hooks\n\t\t\t * have only void and int return types.\n\t\t\t */\n\t\t\tif (!t)\n\t\t\t\treturn true;\n\t\t\tt = btf_type_by_id(btf, t->type);\n\t\t\tbreak;\n\t\tcase BPF_MODIFY_RETURN:\n\t\t\t/* For now the BPF_MODIFY_RETURN can only be attached to\n\t\t\t * functions that return an int.\n\t\t\t */\n\t\t\tif (!t)\n\t\t\t\treturn false;\n\n\t\t\tt = btf_type_skip_modifiers(btf, t->type, NULL);\n\t\t\tif (!btf_type_is_small_int(t)) {\n\t\t\t\tbpf_log(log,\n\t\t\t\t\t\"ret type %s not allowed for fmod_ret\\n\",\n\t\t\t\t\tbtf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_log(log, \"func '%s' doesn't have %d-th argument\\n\",\n\t\t\t\ttname, arg + 1);\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tif (!t)\n\t\t\t/* Default prog with MAX_BPF_FUNC_REG_ARGS args */\n\t\t\treturn true;\n\t\tt = btf_type_by_id(btf, args[arg].type);\n\t}\n\n\t/* skip modifiers */\n\twhile (btf_type_is_modifier(t))\n\t\tt = btf_type_by_id(btf, t->type);\n\tif (btf_type_is_small_int(t) || btf_type_is_enum(t))\n\t\t/* accessing a scalar */\n\t\treturn true;\n\tif (!btf_type_is_ptr(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d '%s' has type %s. Only pointer access is allowed\\n\",\n\t\t\ttname, arg,\n\t\t\t__btf_name_by_offset(btf, t->name_off),\n\t\t\tbtf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\treturn false;\n\t}\n\n\t/* check for PTR_TO_RDONLY_BUF_OR_NULL or PTR_TO_RDWR_BUF_OR_NULL */\n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\t\tu32 type, flag;\n\n\t\ttype = base_type(ctx_arg_info->reg_type);\n\t\tflag = type_flag(ctx_arg_info->reg_type);\n\t\tif (ctx_arg_info->offset == off &&\n\t\t    (type == PTR_TO_RDWR_BUF || type == PTR_TO_RDONLY_BUF) &&\n\t\t    (flag & PTR_MAYBE_NULL)) {\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif (t->type == 0)\n\t\t/* This is a pointer to void.\n\t\t * It is the same as scalar from the verifier safety pov.\n\t\t * No further pointer walking is allowed.\n\t\t */\n\t\treturn true;\n\n\tif (is_int_ptr(btf, t))\n\t\treturn true;\n\n\t/* this is a pointer to another type */\n\tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n\t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n\n\t\tif (ctx_arg_info->offset == off) {\n\t\t\tif (!ctx_arg_info->btf_id) {\n\t\t\t\tbpf_log(log,\"invalid btf_id for context argument offset %u\\n\", off);\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ctx_arg_info->btf_id;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tinfo->reg_type = PTR_TO_BTF_ID;\n\tif (tgt_prog) {\n\t\tenum bpf_prog_type tgt_type;\n\n\t\tif (tgt_prog->type == BPF_PROG_TYPE_EXT)\n\t\t\ttgt_type = tgt_prog->aux->saved_dst_prog_type;\n\t\telse\n\t\t\ttgt_type = tgt_prog->type;\n\n\t\tret = btf_translate_to_vmlinux(log, btf, t, tgt_type, arg);\n\t\tif (ret > 0) {\n\t\t\tinfo->btf = btf_vmlinux;\n\t\t\tinfo->btf_id = ret;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tinfo->btf = btf;\n\tinfo->btf_id = t->type;\n\tt = btf_type_by_id(btf, t->type);\n\t/* skip modifiers */\n\twhile (btf_type_is_modifier(t)) {\n\t\tinfo->btf_id = t->type;\n\t\tt = btf_type_by_id(btf, t->type);\n\t}\n\tif (!btf_type_is_struct(t)) {\n\t\tbpf_log(log,\n\t\t\t\"func '%s' arg%d type %s is not a struct\\n\",\n\t\t\ttname, arg, btf_kind_str[BTF_INFO_KIND(t->info)]);\n\t\treturn false;\n\t}\n\tbpf_log(log, \"func '%s' arg%d has btf_id %d type %s '%s'\\n\",\n\t\ttname, arg, info->btf_id, btf_kind_str[BTF_INFO_KIND(t->info)],\n\t\t__btf_name_by_offset(btf, t->name_off));\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -100,10 +100,13 @@\n \t/* check for PTR_TO_RDONLY_BUF_OR_NULL or PTR_TO_RDWR_BUF_OR_NULL */\n \tfor (i = 0; i < prog->aux->ctx_arg_info_size; i++) {\n \t\tconst struct bpf_ctx_arg_aux *ctx_arg_info = &prog->aux->ctx_arg_info[i];\n+\t\tu32 type, flag;\n \n+\t\ttype = base_type(ctx_arg_info->reg_type);\n+\t\tflag = type_flag(ctx_arg_info->reg_type);\n \t\tif (ctx_arg_info->offset == off &&\n-\t\t    (ctx_arg_info->reg_type == PTR_TO_RDONLY_BUF_OR_NULL ||\n-\t\t     ctx_arg_info->reg_type == PTR_TO_RDWR_BUF_OR_NULL)) {\n+\t\t    (type == PTR_TO_RDWR_BUF || type == PTR_TO_RDONLY_BUF) &&\n+\t\t    (flag & PTR_MAYBE_NULL)) {\n \t\t\tinfo->reg_type = ctx_arg_info->reg_type;\n \t\t\treturn true;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tu32 type, flag;",
                "\t\ttype = base_type(ctx_arg_info->reg_type);",
                "\t\tflag = type_flag(ctx_arg_info->reg_type);",
                "\t\t    (type == PTR_TO_RDWR_BUF || type == PTR_TO_RDONLY_BUF) &&",
                "\t\t    (flag & PTR_MAYBE_NULL)) {"
            ],
            "deleted": [
                "\t\t    (ctx_arg_info->reg_type == PTR_TO_RDONLY_BUF_OR_NULL ||",
                "\t\t     ctx_arg_info->reg_type == PTR_TO_RDWR_BUF_OR_NULL)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3440
    },
    {
        "cve_id": "CVE-2017-8106",
        "code_before_change": "static int handle_invept(struct kvm_vcpu *vcpu)\n{\n\tu32 vmx_instruction_info, types;\n\tunsigned long type;\n\tgva_t gva;\n\tstruct x86_exception e;\n\tstruct {\n\t\tu64 eptp, gpa;\n\t} operand;\n\tu64 eptp_mask = ((1ull << 51) - 1) & PAGE_MASK;\n\n\tif (!(nested_vmx_secondary_ctls_high & SECONDARY_EXEC_ENABLE_EPT) ||\n\t    !(nested_vmx_ept_caps & VMX_EPT_INVEPT_BIT)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tif (!kvm_read_cr0_bits(vcpu, X86_CR0_PE)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\ttype = kvm_register_read(vcpu, (vmx_instruction_info >> 28) & 0xf);\n\n\ttypes = (nested_vmx_ept_caps >> VMX_EPT_EXTENT_SHIFT) & 6;\n\n\tif (!(types & (1UL << type))) {\n\t\tnested_vmx_failValid(vcpu,\n\t\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\t\treturn 1;\n\t}\n\n\t/* According to the Intel VMX instruction reference, the memory\n\t * operand is read even if it isn't needed (e.g., for type==global)\n\t */\n\tif (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),\n\t\t\tvmx_instruction_info, &gva))\n\t\treturn 1;\n\tif (kvm_read_guest_virt(&vcpu->arch.emulate_ctxt, gva, &operand,\n\t\t\t\tsizeof(operand), &e)) {\n\t\tkvm_inject_page_fault(vcpu, &e);\n\t\treturn 1;\n\t}\n\n\tswitch (type) {\n\tcase VMX_EPT_EXTENT_CONTEXT:\n\t\tif ((operand.eptp & eptp_mask) !=\n\t\t\t\t(nested_ept_get_cr3(vcpu) & eptp_mask))\n\t\t\tbreak;\n\tcase VMX_EPT_EXTENT_GLOBAL:\n\t\tkvm_mmu_sync_roots(vcpu);\n\t\tkvm_mmu_flush_tlb(vcpu);\n\t\tnested_vmx_succeed(vcpu);\n\t\tbreak;\n\tdefault:\n\t\tBUG_ON(1);\n\t\tbreak;\n\t}\n\n\tskip_emulated_instruction(vcpu);\n\treturn 1;\n}",
        "code_after_change": "static int handle_invept(struct kvm_vcpu *vcpu)\n{\n\tu32 vmx_instruction_info, types;\n\tunsigned long type;\n\tgva_t gva;\n\tstruct x86_exception e;\n\tstruct {\n\t\tu64 eptp, gpa;\n\t} operand;\n\n\tif (!(nested_vmx_secondary_ctls_high & SECONDARY_EXEC_ENABLE_EPT) ||\n\t    !(nested_vmx_ept_caps & VMX_EPT_INVEPT_BIT)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (!nested_vmx_check_permission(vcpu))\n\t\treturn 1;\n\n\tif (!kvm_read_cr0_bits(vcpu, X86_CR0_PE)) {\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tvmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);\n\ttype = kvm_register_read(vcpu, (vmx_instruction_info >> 28) & 0xf);\n\n\ttypes = (nested_vmx_ept_caps >> VMX_EPT_EXTENT_SHIFT) & 6;\n\n\tif (!(types & (1UL << type))) {\n\t\tnested_vmx_failValid(vcpu,\n\t\t\t\tVMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);\n\t\treturn 1;\n\t}\n\n\t/* According to the Intel VMX instruction reference, the memory\n\t * operand is read even if it isn't needed (e.g., for type==global)\n\t */\n\tif (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),\n\t\t\tvmx_instruction_info, &gva))\n\t\treturn 1;\n\tif (kvm_read_guest_virt(&vcpu->arch.emulate_ctxt, gva, &operand,\n\t\t\t\tsizeof(operand), &e)) {\n\t\tkvm_inject_page_fault(vcpu, &e);\n\t\treturn 1;\n\t}\n\n\tswitch (type) {\n\tcase VMX_EPT_EXTENT_GLOBAL:\n\t\tkvm_mmu_sync_roots(vcpu);\n\t\tkvm_mmu_flush_tlb(vcpu);\n\t\tnested_vmx_succeed(vcpu);\n\t\tbreak;\n\tdefault:\n\t\t/* Trap single context invalidation invept calls */\n\t\tBUG_ON(1);\n\t\tbreak;\n\t}\n\n\tskip_emulated_instruction(vcpu);\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,6 @@\n \tstruct {\n \t\tu64 eptp, gpa;\n \t} operand;\n-\tu64 eptp_mask = ((1ull << 51) - 1) & PAGE_MASK;\n \n \tif (!(nested_vmx_secondary_ctls_high & SECONDARY_EXEC_ENABLE_EPT) ||\n \t    !(nested_vmx_ept_caps & VMX_EPT_INVEPT_BIT)) {\n@@ -47,16 +46,13 @@\n \t}\n \n \tswitch (type) {\n-\tcase VMX_EPT_EXTENT_CONTEXT:\n-\t\tif ((operand.eptp & eptp_mask) !=\n-\t\t\t\t(nested_ept_get_cr3(vcpu) & eptp_mask))\n-\t\t\tbreak;\n \tcase VMX_EPT_EXTENT_GLOBAL:\n \t\tkvm_mmu_sync_roots(vcpu);\n \t\tkvm_mmu_flush_tlb(vcpu);\n \t\tnested_vmx_succeed(vcpu);\n \t\tbreak;\n \tdefault:\n+\t\t/* Trap single context invalidation invept calls */\n \t\tBUG_ON(1);\n \t\tbreak;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t/* Trap single context invalidation invept calls */"
            ],
            "deleted": [
                "\tu64 eptp_mask = ((1ull << 51) - 1) & PAGE_MASK;",
                "\tcase VMX_EPT_EXTENT_CONTEXT:",
                "\t\tif ((operand.eptp & eptp_mask) !=",
                "\t\t\t\t(nested_ept_get_cr3(vcpu) & eptp_mask))",
                "\t\t\tbreak;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The handle_invept function in arch/x86/kvm/vmx.c in the Linux kernel 3.12 through 3.15 allows privileged KVM guest OS users to cause a denial of service (NULL pointer dereference and host OS crash) via a single-context INVEPT instruction with a NULL EPT pointer.",
        "id": 1551
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int nim7090_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x10, &nim7090_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80, &nim7090_dib7000p_config);\n\n\treturn adap->fe_adap[0].fe == NULL ?  -ENODEV : 0;\n}",
        "code_after_change": "static int nim7090_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x10, &nim7090_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80, &nim7090_dib7000p_config);\n\n\treturn adap->fe_adap[0].fe == NULL ?  -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \n \tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 1, 0x10, &nim7090_dib7000p_config) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n \tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80, &nim7090_dib7000p_config);",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1337
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static int check_cond_jmp_op(struct bpf_verifier_env *env,\n\t\t\t     struct bpf_insn *insn, int *insn_idx)\n{\n\tstruct bpf_verifier_state *this_branch = env->cur_state;\n\tstruct bpf_verifier_state *other_branch;\n\tstruct bpf_reg_state *regs = this_branch->frame[this_branch->curframe]->regs;\n\tstruct bpf_reg_state *dst_reg, *other_branch_regs, *src_reg = NULL;\n\tu8 opcode = BPF_OP(insn->code);\n\tbool is_jmp32;\n\tint pred = -1;\n\tint err;\n\n\t/* Only conditional jumps are expected to reach here. */\n\tif (opcode == BPF_JA || opcode > BPF_JSLE) {\n\t\tverbose(env, \"invalid BPF_JMP/JMP32 opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\t}\n\n\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\tif (insn->imm != 0) {\n\t\t\tverbose(env, \"BPF_JMP/JMP32 uses reserved fields\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* check src1 operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\tverbose(env, \"R%d pointer comparison prohibited\\n\",\n\t\t\t\tinsn->src_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tsrc_reg = &regs[insn->src_reg];\n\t} else {\n\t\tif (insn->src_reg != BPF_REG_0) {\n\t\t\tverbose(env, \"BPF_JMP/JMP32 uses reserved fields\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* check src2 operand */\n\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tdst_reg = &regs[insn->dst_reg];\n\tis_jmp32 = BPF_CLASS(insn->code) == BPF_JMP32;\n\n\tif (BPF_SRC(insn->code) == BPF_K) {\n\t\tpred = is_branch_taken(dst_reg, insn->imm, opcode, is_jmp32);\n\t} else if (src_reg->type == SCALAR_VALUE &&\n\t\t   is_jmp32 && tnum_is_const(tnum_subreg(src_reg->var_off))) {\n\t\tpred = is_branch_taken(dst_reg,\n\t\t\t\t       tnum_subreg(src_reg->var_off).value,\n\t\t\t\t       opcode,\n\t\t\t\t       is_jmp32);\n\t} else if (src_reg->type == SCALAR_VALUE &&\n\t\t   !is_jmp32 && tnum_is_const(src_reg->var_off)) {\n\t\tpred = is_branch_taken(dst_reg,\n\t\t\t\t       src_reg->var_off.value,\n\t\t\t\t       opcode,\n\t\t\t\t       is_jmp32);\n\t} else if (reg_is_pkt_pointer_any(dst_reg) &&\n\t\t   reg_is_pkt_pointer_any(src_reg) &&\n\t\t   !is_jmp32) {\n\t\tpred = is_pkt_ptr_branch_taken(dst_reg, src_reg, opcode);\n\t}\n\n\tif (pred >= 0) {\n\t\t/* If we get here with a dst_reg pointer type it is because\n\t\t * above is_branch_taken() special cased the 0 comparison.\n\t\t */\n\t\tif (!__is_pointer_value(false, dst_reg))\n\t\t\terr = mark_chain_precision(env, insn->dst_reg);\n\t\tif (BPF_SRC(insn->code) == BPF_X && !err &&\n\t\t    !__is_pointer_value(false, src_reg))\n\t\t\terr = mark_chain_precision(env, insn->src_reg);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (pred == 1) {\n\t\t/* Only follow the goto, ignore fall-through. If needed, push\n\t\t * the fall-through branch for simulation under speculative\n\t\t * execution.\n\t\t */\n\t\tif (!env->bypass_spec_v1 &&\n\t\t    !sanitize_speculative_path(env, insn, *insn_idx + 1,\n\t\t\t\t\t       *insn_idx))\n\t\t\treturn -EFAULT;\n\t\t*insn_idx += insn->off;\n\t\treturn 0;\n\t} else if (pred == 0) {\n\t\t/* Only follow the fall-through branch, since that's where the\n\t\t * program will go. If needed, push the goto branch for\n\t\t * simulation under speculative execution.\n\t\t */\n\t\tif (!env->bypass_spec_v1 &&\n\t\t    !sanitize_speculative_path(env, insn,\n\t\t\t\t\t       *insn_idx + insn->off + 1,\n\t\t\t\t\t       *insn_idx))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\n\tother_branch = push_stack(env, *insn_idx + insn->off + 1, *insn_idx,\n\t\t\t\t  false);\n\tif (!other_branch)\n\t\treturn -EFAULT;\n\tother_branch_regs = other_branch->frame[other_branch->curframe]->regs;\n\n\t/* detect if we are comparing against a constant value so we can adjust\n\t * our min/max values for our dst register.\n\t * this is only legit if both are scalars (or pointers to the same\n\t * object, I suppose, but we don't support that right now), because\n\t * otherwise the different base pointers mean the offsets aren't\n\t * comparable.\n\t */\n\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\tstruct bpf_reg_state *src_reg = &regs[insn->src_reg];\n\n\t\tif (dst_reg->type == SCALAR_VALUE &&\n\t\t    src_reg->type == SCALAR_VALUE) {\n\t\t\tif (tnum_is_const(src_reg->var_off) ||\n\t\t\t    (is_jmp32 &&\n\t\t\t     tnum_is_const(tnum_subreg(src_reg->var_off))))\n\t\t\t\treg_set_min_max(&other_branch_regs[insn->dst_reg],\n\t\t\t\t\t\tdst_reg,\n\t\t\t\t\t\tsrc_reg->var_off.value,\n\t\t\t\t\t\ttnum_subreg(src_reg->var_off).value,\n\t\t\t\t\t\topcode, is_jmp32);\n\t\t\telse if (tnum_is_const(dst_reg->var_off) ||\n\t\t\t\t (is_jmp32 &&\n\t\t\t\t  tnum_is_const(tnum_subreg(dst_reg->var_off))))\n\t\t\t\treg_set_min_max_inv(&other_branch_regs[insn->src_reg],\n\t\t\t\t\t\t    src_reg,\n\t\t\t\t\t\t    dst_reg->var_off.value,\n\t\t\t\t\t\t    tnum_subreg(dst_reg->var_off).value,\n\t\t\t\t\t\t    opcode, is_jmp32);\n\t\t\telse if (!is_jmp32 &&\n\t\t\t\t (opcode == BPF_JEQ || opcode == BPF_JNE))\n\t\t\t\t/* Comparing for equality, we can combine knowledge */\n\t\t\t\treg_combine_min_max(&other_branch_regs[insn->src_reg],\n\t\t\t\t\t\t    &other_branch_regs[insn->dst_reg],\n\t\t\t\t\t\t    src_reg, dst_reg, opcode);\n\t\t\tif (src_reg->id &&\n\t\t\t    !WARN_ON_ONCE(src_reg->id != other_branch_regs[insn->src_reg].id)) {\n\t\t\t\tfind_equal_scalars(this_branch, src_reg);\n\t\t\t\tfind_equal_scalars(other_branch, &other_branch_regs[insn->src_reg]);\n\t\t\t}\n\n\t\t}\n\t} else if (dst_reg->type == SCALAR_VALUE) {\n\t\treg_set_min_max(&other_branch_regs[insn->dst_reg],\n\t\t\t\t\tdst_reg, insn->imm, (u32)insn->imm,\n\t\t\t\t\topcode, is_jmp32);\n\t}\n\n\tif (dst_reg->type == SCALAR_VALUE && dst_reg->id &&\n\t    !WARN_ON_ONCE(dst_reg->id != other_branch_regs[insn->dst_reg].id)) {\n\t\tfind_equal_scalars(this_branch, dst_reg);\n\t\tfind_equal_scalars(other_branch, &other_branch_regs[insn->dst_reg]);\n\t}\n\n\t/* detect if R == 0 where R is returned from bpf_map_lookup_elem().\n\t * NOTE: these optimizations below are related with pointer comparison\n\t *       which will never be JMP32.\n\t */\n\tif (!is_jmp32 && BPF_SRC(insn->code) == BPF_K &&\n\t    insn->imm == 0 && (opcode == BPF_JEQ || opcode == BPF_JNE) &&\n\t    reg_type_may_be_null(dst_reg->type)) {\n\t\t/* Mark all identical registers in each branch as either\n\t\t * safe or unknown depending R == 0 or R != 0 conditional.\n\t\t */\n\t\tmark_ptr_or_null_regs(this_branch, insn->dst_reg,\n\t\t\t\t      opcode == BPF_JNE);\n\t\tmark_ptr_or_null_regs(other_branch, insn->dst_reg,\n\t\t\t\t      opcode == BPF_JEQ);\n\t} else if (!try_match_pkt_pointers(insn, dst_reg, &regs[insn->src_reg],\n\t\t\t\t\t   this_branch, other_branch) &&\n\t\t   is_pointer_value(env, insn->dst_reg)) {\n\t\tverbose(env, \"R%d pointer comparison prohibited\\n\",\n\t\t\tinsn->dst_reg);\n\t\treturn -EACCES;\n\t}\n\tif (env->log.level & BPF_LOG_LEVEL)\n\t\tprint_insn_state(env, this_branch->frame[this_branch->curframe]);\n\treturn 0;\n}",
        "code_after_change": "static int check_cond_jmp_op(struct bpf_verifier_env *env,\n\t\t\t     struct bpf_insn *insn, int *insn_idx)\n{\n\tstruct bpf_verifier_state *this_branch = env->cur_state;\n\tstruct bpf_verifier_state *other_branch;\n\tstruct bpf_reg_state *regs = this_branch->frame[this_branch->curframe]->regs;\n\tstruct bpf_reg_state *dst_reg, *other_branch_regs, *src_reg = NULL;\n\tu8 opcode = BPF_OP(insn->code);\n\tbool is_jmp32;\n\tint pred = -1;\n\tint err;\n\n\t/* Only conditional jumps are expected to reach here. */\n\tif (opcode == BPF_JA || opcode > BPF_JSLE) {\n\t\tverbose(env, \"invalid BPF_JMP/JMP32 opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\t}\n\n\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\tif (insn->imm != 0) {\n\t\t\tverbose(env, \"BPF_JMP/JMP32 uses reserved fields\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* check src1 operand */\n\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\tverbose(env, \"R%d pointer comparison prohibited\\n\",\n\t\t\t\tinsn->src_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\t\tsrc_reg = &regs[insn->src_reg];\n\t} else {\n\t\tif (insn->src_reg != BPF_REG_0) {\n\t\t\tverbose(env, \"BPF_JMP/JMP32 uses reserved fields\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* check src2 operand */\n\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tdst_reg = &regs[insn->dst_reg];\n\tis_jmp32 = BPF_CLASS(insn->code) == BPF_JMP32;\n\n\tif (BPF_SRC(insn->code) == BPF_K) {\n\t\tpred = is_branch_taken(dst_reg, insn->imm, opcode, is_jmp32);\n\t} else if (src_reg->type == SCALAR_VALUE &&\n\t\t   is_jmp32 && tnum_is_const(tnum_subreg(src_reg->var_off))) {\n\t\tpred = is_branch_taken(dst_reg,\n\t\t\t\t       tnum_subreg(src_reg->var_off).value,\n\t\t\t\t       opcode,\n\t\t\t\t       is_jmp32);\n\t} else if (src_reg->type == SCALAR_VALUE &&\n\t\t   !is_jmp32 && tnum_is_const(src_reg->var_off)) {\n\t\tpred = is_branch_taken(dst_reg,\n\t\t\t\t       src_reg->var_off.value,\n\t\t\t\t       opcode,\n\t\t\t\t       is_jmp32);\n\t} else if (reg_is_pkt_pointer_any(dst_reg) &&\n\t\t   reg_is_pkt_pointer_any(src_reg) &&\n\t\t   !is_jmp32) {\n\t\tpred = is_pkt_ptr_branch_taken(dst_reg, src_reg, opcode);\n\t}\n\n\tif (pred >= 0) {\n\t\t/* If we get here with a dst_reg pointer type it is because\n\t\t * above is_branch_taken() special cased the 0 comparison.\n\t\t */\n\t\tif (!__is_pointer_value(false, dst_reg))\n\t\t\terr = mark_chain_precision(env, insn->dst_reg);\n\t\tif (BPF_SRC(insn->code) == BPF_X && !err &&\n\t\t    !__is_pointer_value(false, src_reg))\n\t\t\terr = mark_chain_precision(env, insn->src_reg);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (pred == 1) {\n\t\t/* Only follow the goto, ignore fall-through. If needed, push\n\t\t * the fall-through branch for simulation under speculative\n\t\t * execution.\n\t\t */\n\t\tif (!env->bypass_spec_v1 &&\n\t\t    !sanitize_speculative_path(env, insn, *insn_idx + 1,\n\t\t\t\t\t       *insn_idx))\n\t\t\treturn -EFAULT;\n\t\t*insn_idx += insn->off;\n\t\treturn 0;\n\t} else if (pred == 0) {\n\t\t/* Only follow the fall-through branch, since that's where the\n\t\t * program will go. If needed, push the goto branch for\n\t\t * simulation under speculative execution.\n\t\t */\n\t\tif (!env->bypass_spec_v1 &&\n\t\t    !sanitize_speculative_path(env, insn,\n\t\t\t\t\t       *insn_idx + insn->off + 1,\n\t\t\t\t\t       *insn_idx))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\n\tother_branch = push_stack(env, *insn_idx + insn->off + 1, *insn_idx,\n\t\t\t\t  false);\n\tif (!other_branch)\n\t\treturn -EFAULT;\n\tother_branch_regs = other_branch->frame[other_branch->curframe]->regs;\n\n\t/* detect if we are comparing against a constant value so we can adjust\n\t * our min/max values for our dst register.\n\t * this is only legit if both are scalars (or pointers to the same\n\t * object, I suppose, but we don't support that right now), because\n\t * otherwise the different base pointers mean the offsets aren't\n\t * comparable.\n\t */\n\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\tstruct bpf_reg_state *src_reg = &regs[insn->src_reg];\n\n\t\tif (dst_reg->type == SCALAR_VALUE &&\n\t\t    src_reg->type == SCALAR_VALUE) {\n\t\t\tif (tnum_is_const(src_reg->var_off) ||\n\t\t\t    (is_jmp32 &&\n\t\t\t     tnum_is_const(tnum_subreg(src_reg->var_off))))\n\t\t\t\treg_set_min_max(&other_branch_regs[insn->dst_reg],\n\t\t\t\t\t\tdst_reg,\n\t\t\t\t\t\tsrc_reg->var_off.value,\n\t\t\t\t\t\ttnum_subreg(src_reg->var_off).value,\n\t\t\t\t\t\topcode, is_jmp32);\n\t\t\telse if (tnum_is_const(dst_reg->var_off) ||\n\t\t\t\t (is_jmp32 &&\n\t\t\t\t  tnum_is_const(tnum_subreg(dst_reg->var_off))))\n\t\t\t\treg_set_min_max_inv(&other_branch_regs[insn->src_reg],\n\t\t\t\t\t\t    src_reg,\n\t\t\t\t\t\t    dst_reg->var_off.value,\n\t\t\t\t\t\t    tnum_subreg(dst_reg->var_off).value,\n\t\t\t\t\t\t    opcode, is_jmp32);\n\t\t\telse if (!is_jmp32 &&\n\t\t\t\t (opcode == BPF_JEQ || opcode == BPF_JNE))\n\t\t\t\t/* Comparing for equality, we can combine knowledge */\n\t\t\t\treg_combine_min_max(&other_branch_regs[insn->src_reg],\n\t\t\t\t\t\t    &other_branch_regs[insn->dst_reg],\n\t\t\t\t\t\t    src_reg, dst_reg, opcode);\n\t\t\tif (src_reg->id &&\n\t\t\t    !WARN_ON_ONCE(src_reg->id != other_branch_regs[insn->src_reg].id)) {\n\t\t\t\tfind_equal_scalars(this_branch, src_reg);\n\t\t\t\tfind_equal_scalars(other_branch, &other_branch_regs[insn->src_reg]);\n\t\t\t}\n\n\t\t}\n\t} else if (dst_reg->type == SCALAR_VALUE) {\n\t\treg_set_min_max(&other_branch_regs[insn->dst_reg],\n\t\t\t\t\tdst_reg, insn->imm, (u32)insn->imm,\n\t\t\t\t\topcode, is_jmp32);\n\t}\n\n\tif (dst_reg->type == SCALAR_VALUE && dst_reg->id &&\n\t    !WARN_ON_ONCE(dst_reg->id != other_branch_regs[insn->dst_reg].id)) {\n\t\tfind_equal_scalars(this_branch, dst_reg);\n\t\tfind_equal_scalars(other_branch, &other_branch_regs[insn->dst_reg]);\n\t}\n\n\t/* detect if R == 0 where R is returned from bpf_map_lookup_elem().\n\t * NOTE: these optimizations below are related with pointer comparison\n\t *       which will never be JMP32.\n\t */\n\tif (!is_jmp32 && BPF_SRC(insn->code) == BPF_K &&\n\t    insn->imm == 0 && (opcode == BPF_JEQ || opcode == BPF_JNE) &&\n\t    type_may_be_null(dst_reg->type)) {\n\t\t/* Mark all identical registers in each branch as either\n\t\t * safe or unknown depending R == 0 or R != 0 conditional.\n\t\t */\n\t\tmark_ptr_or_null_regs(this_branch, insn->dst_reg,\n\t\t\t\t      opcode == BPF_JNE);\n\t\tmark_ptr_or_null_regs(other_branch, insn->dst_reg,\n\t\t\t\t      opcode == BPF_JEQ);\n\t} else if (!try_match_pkt_pointers(insn, dst_reg, &regs[insn->src_reg],\n\t\t\t\t\t   this_branch, other_branch) &&\n\t\t   is_pointer_value(env, insn->dst_reg)) {\n\t\tverbose(env, \"R%d pointer comparison prohibited\\n\",\n\t\t\tinsn->dst_reg);\n\t\treturn -EACCES;\n\t}\n\tif (env->log.level & BPF_LOG_LEVEL)\n\t\tprint_insn_state(env, this_branch->frame[this_branch->curframe]);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -170,7 +170,7 @@\n \t */\n \tif (!is_jmp32 && BPF_SRC(insn->code) == BPF_K &&\n \t    insn->imm == 0 && (opcode == BPF_JEQ || opcode == BPF_JNE) &&\n-\t    reg_type_may_be_null(dst_reg->type)) {\n+\t    type_may_be_null(dst_reg->type)) {\n \t\t/* Mark all identical registers in each branch as either\n \t\t * safe or unknown depending R == 0 or R != 0 conditional.\n \t\t */",
        "function_modified_lines": {
            "added": [
                "\t    type_may_be_null(dst_reg->type)) {"
            ],
            "deleted": [
                "\t    reg_type_may_be_null(dst_reg->type)) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3441
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int tfe7790p_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* The TFE7790P requires the dib0700 to not be in master mode */\n\tst->disable_streaming_master_mode = 1;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\tmsleep(20);\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap,\n\t\t\t\t1, 0x10, &tfe7790p_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t\t\t__func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t0x80, &tfe7790p_dib7000p_config);\n\n\treturn adap->fe_adap[0].fe == NULL ?  -ENODEV : 0;\n}",
        "code_after_change": "static int tfe7790p_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_state *st = adap->dev->priv;\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\t/* The TFE7790P requires the dib0700 to not be in master mode */\n\tst->disable_streaming_master_mode = 1;\n\n\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\tmsleep(20);\n\tdib0700_ctrl_clock(adap->dev, 72, 1);\n\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\tmsleep(20);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap,\n\t\t\t\t1, 0x10, &tfe7790p_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t\t\t__func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t0x80, &tfe7790p_dib7000p_config);\n\n\treturn adap->fe_adap[0].fe == NULL ?  -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,7 +25,7 @@\n \t\t\t\t1, 0x10, &tfe7790p_dib7000p_config) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n \t\t\t\t__func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n \tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1331
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static void mark_ptr_not_null_reg(struct bpf_reg_state *reg)\n{\n\tswitch (reg->type) {\n\tcase PTR_TO_MAP_VALUE_OR_NULL: {\n\t\tconst struct bpf_map *map = reg->map_ptr;\n\n\t\tif (map->inner_map_meta) {\n\t\t\treg->type = CONST_PTR_TO_MAP;\n\t\t\treg->map_ptr = map->inner_map_meta;\n\t\t\t/* transfer reg's id which is unique for every map_lookup_elem\n\t\t\t * as UID of the inner map.\n\t\t\t */\n\t\t\tif (map_value_has_timer(map->inner_map_meta))\n\t\t\t\treg->map_uid = reg->id;\n\t\t} else if (map->map_type == BPF_MAP_TYPE_XSKMAP) {\n\t\t\treg->type = PTR_TO_XDP_SOCK;\n\t\t} else if (map->map_type == BPF_MAP_TYPE_SOCKMAP ||\n\t\t\t   map->map_type == BPF_MAP_TYPE_SOCKHASH) {\n\t\t\treg->type = PTR_TO_SOCKET;\n\t\t} else {\n\t\t\treg->type = PTR_TO_MAP_VALUE;\n\t\t}\n\t\tbreak;\n\t}\n\tcase PTR_TO_SOCKET_OR_NULL:\n\t\treg->type = PTR_TO_SOCKET;\n\t\tbreak;\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\t\treg->type = PTR_TO_SOCK_COMMON;\n\t\tbreak;\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\t\treg->type = PTR_TO_TCP_SOCK;\n\t\tbreak;\n\tcase PTR_TO_BTF_ID_OR_NULL:\n\t\treg->type = PTR_TO_BTF_ID;\n\t\tbreak;\n\tcase PTR_TO_MEM_OR_NULL:\n\t\treg->type = PTR_TO_MEM;\n\t\tbreak;\n\tcase PTR_TO_RDONLY_BUF_OR_NULL:\n\t\treg->type = PTR_TO_RDONLY_BUF;\n\t\tbreak;\n\tcase PTR_TO_RDWR_BUF_OR_NULL:\n\t\treg->type = PTR_TO_RDWR_BUF;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ONCE(1, \"unknown nullable register type\");\n\t}\n}",
        "code_after_change": "static void mark_ptr_not_null_reg(struct bpf_reg_state *reg)\n{\n\tif (base_type(reg->type) == PTR_TO_MAP_VALUE) {\n\t\tconst struct bpf_map *map = reg->map_ptr;\n\n\t\tif (map->inner_map_meta) {\n\t\t\treg->type = CONST_PTR_TO_MAP;\n\t\t\treg->map_ptr = map->inner_map_meta;\n\t\t\t/* transfer reg's id which is unique for every map_lookup_elem\n\t\t\t * as UID of the inner map.\n\t\t\t */\n\t\t\tif (map_value_has_timer(map->inner_map_meta))\n\t\t\t\treg->map_uid = reg->id;\n\t\t} else if (map->map_type == BPF_MAP_TYPE_XSKMAP) {\n\t\t\treg->type = PTR_TO_XDP_SOCK;\n\t\t} else if (map->map_type == BPF_MAP_TYPE_SOCKMAP ||\n\t\t\t   map->map_type == BPF_MAP_TYPE_SOCKHASH) {\n\t\t\treg->type = PTR_TO_SOCKET;\n\t\t} else {\n\t\t\treg->type = PTR_TO_MAP_VALUE;\n\t\t}\n\t\treturn;\n\t}\n\n\treg->type &= ~PTR_MAYBE_NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,7 +1,6 @@\n static void mark_ptr_not_null_reg(struct bpf_reg_state *reg)\n {\n-\tswitch (reg->type) {\n-\tcase PTR_TO_MAP_VALUE_OR_NULL: {\n+\tif (base_type(reg->type) == PTR_TO_MAP_VALUE) {\n \t\tconst struct bpf_map *map = reg->map_ptr;\n \n \t\tif (map->inner_map_meta) {\n@@ -20,30 +19,8 @@\n \t\t} else {\n \t\t\treg->type = PTR_TO_MAP_VALUE;\n \t\t}\n-\t\tbreak;\n+\t\treturn;\n \t}\n-\tcase PTR_TO_SOCKET_OR_NULL:\n-\t\treg->type = PTR_TO_SOCKET;\n-\t\tbreak;\n-\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n-\t\treg->type = PTR_TO_SOCK_COMMON;\n-\t\tbreak;\n-\tcase PTR_TO_TCP_SOCK_OR_NULL:\n-\t\treg->type = PTR_TO_TCP_SOCK;\n-\t\tbreak;\n-\tcase PTR_TO_BTF_ID_OR_NULL:\n-\t\treg->type = PTR_TO_BTF_ID;\n-\t\tbreak;\n-\tcase PTR_TO_MEM_OR_NULL:\n-\t\treg->type = PTR_TO_MEM;\n-\t\tbreak;\n-\tcase PTR_TO_RDONLY_BUF_OR_NULL:\n-\t\treg->type = PTR_TO_RDONLY_BUF;\n-\t\tbreak;\n-\tcase PTR_TO_RDWR_BUF_OR_NULL:\n-\t\treg->type = PTR_TO_RDWR_BUF;\n-\t\tbreak;\n-\tdefault:\n-\t\tWARN_ONCE(1, \"unknown nullable register type\");\n-\t}\n+\n+\treg->type &= ~PTR_MAYBE_NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (base_type(reg->type) == PTR_TO_MAP_VALUE) {",
                "\t\treturn;",
                "",
                "\treg->type &= ~PTR_MAYBE_NULL;"
            ],
            "deleted": [
                "\tswitch (reg->type) {",
                "\tcase PTR_TO_MAP_VALUE_OR_NULL: {",
                "\t\tbreak;",
                "\tcase PTR_TO_SOCKET_OR_NULL:",
                "\t\treg->type = PTR_TO_SOCKET;",
                "\t\tbreak;",
                "\tcase PTR_TO_SOCK_COMMON_OR_NULL:",
                "\t\treg->type = PTR_TO_SOCK_COMMON;",
                "\t\tbreak;",
                "\tcase PTR_TO_TCP_SOCK_OR_NULL:",
                "\t\treg->type = PTR_TO_TCP_SOCK;",
                "\t\tbreak;",
                "\tcase PTR_TO_BTF_ID_OR_NULL:",
                "\t\treg->type = PTR_TO_BTF_ID;",
                "\t\tbreak;",
                "\tcase PTR_TO_MEM_OR_NULL:",
                "\t\treg->type = PTR_TO_MEM;",
                "\t\tbreak;",
                "\tcase PTR_TO_RDONLY_BUF_OR_NULL:",
                "\t\treg->type = PTR_TO_RDONLY_BUF;",
                "\t\tbreak;",
                "\tcase PTR_TO_RDWR_BUF_OR_NULL:",
                "\t\treg->type = PTR_TO_RDWR_BUF;",
                "\t\tbreak;",
                "\tdefault:",
                "\t\tWARN_ONCE(1, \"unknown nullable register type\");",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3454
    },
    {
        "cve_id": "CVE-2022-23222",
        "code_before_change": "static bool reg_type_mismatch_ok(enum bpf_reg_type type)\n{\n\tswitch (type) {\n\tcase PTR_TO_CTX:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCKET_OR_NULL:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_TCP_SOCK_OR_NULL:\n\tcase PTR_TO_XDP_SOCK:\n\tcase PTR_TO_BTF_ID:\n\tcase PTR_TO_BTF_ID_OR_NULL:\n\t\treturn false;\n\tdefault:\n\t\treturn true;\n\t}\n}",
        "code_after_change": "static bool reg_type_mismatch_ok(enum bpf_reg_type type)\n{\n\tswitch (base_type(type)) {\n\tcase PTR_TO_CTX:\n\tcase PTR_TO_SOCKET:\n\tcase PTR_TO_SOCK_COMMON:\n\tcase PTR_TO_TCP_SOCK:\n\tcase PTR_TO_XDP_SOCK:\n\tcase PTR_TO_BTF_ID:\n\t\treturn false;\n\tdefault:\n\t\treturn true;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,16 +1,12 @@\n static bool reg_type_mismatch_ok(enum bpf_reg_type type)\n {\n-\tswitch (type) {\n+\tswitch (base_type(type)) {\n \tcase PTR_TO_CTX:\n \tcase PTR_TO_SOCKET:\n-\tcase PTR_TO_SOCKET_OR_NULL:\n \tcase PTR_TO_SOCK_COMMON:\n-\tcase PTR_TO_SOCK_COMMON_OR_NULL:\n \tcase PTR_TO_TCP_SOCK:\n-\tcase PTR_TO_TCP_SOCK_OR_NULL:\n \tcase PTR_TO_XDP_SOCK:\n \tcase PTR_TO_BTF_ID:\n-\tcase PTR_TO_BTF_ID_OR_NULL:\n \t\treturn false;\n \tdefault:\n \t\treturn true;",
        "function_modified_lines": {
            "added": [
                "\tswitch (base_type(type)) {"
            ],
            "deleted": [
                "\tswitch (type) {",
                "\tcase PTR_TO_SOCKET_OR_NULL:",
                "\tcase PTR_TO_SOCK_COMMON_OR_NULL:",
                "\tcase PTR_TO_TCP_SOCK_OR_NULL:",
                "\tcase PTR_TO_BTF_ID_OR_NULL:"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/bpf/verifier.c in the Linux kernel through 5.15.14 allows local users to gain privileges because of the availability of pointer arithmetic via certain *_OR_NULL pointer types.",
        "id": 3452
    },
    {
        "cve_id": "CVE-2019-12382",
        "code_before_change": "struct edid *drm_load_edid_firmware(struct drm_connector *connector)\n{\n\tconst char *connector_name = connector->name;\n\tchar *edidname, *last, *colon, *fwstr, *edidstr, *fallback = NULL;\n\tstruct edid *edid;\n\n\tif (edid_firmware[0] == '\\0')\n\t\treturn ERR_PTR(-ENOENT);\n\n\t/*\n\t * If there are multiple edid files specified and separated\n\t * by commas, search through the list looking for one that\n\t * matches the connector.\n\t *\n\t * If there's one or more that doesn't specify a connector, keep\n\t * the last one found one as a fallback.\n\t */\n\tfwstr = kstrdup(edid_firmware, GFP_KERNEL);\n\tedidstr = fwstr;\n\n\twhile ((edidname = strsep(&edidstr, \",\"))) {\n\t\tcolon = strchr(edidname, ':');\n\t\tif (colon != NULL) {\n\t\t\tif (strncmp(connector_name, edidname, colon - edidname))\n\t\t\t\tcontinue;\n\t\t\tedidname = colon + 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (*edidname != '\\0') /* corner case: multiple ',' */\n\t\t\tfallback = edidname;\n\t}\n\n\tif (!edidname) {\n\t\tif (!fallback) {\n\t\t\tkfree(fwstr);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t\tedidname = fallback;\n\t}\n\n\tlast = edidname + strlen(edidname) - 1;\n\tif (*last == '\\n')\n\t\t*last = '\\0';\n\n\tedid = edid_load(connector, edidname, connector_name);\n\tkfree(fwstr);\n\n\treturn edid;\n}",
        "code_after_change": "struct edid *drm_load_edid_firmware(struct drm_connector *connector)\n{\n\tconst char *connector_name = connector->name;\n\tchar *edidname, *last, *colon, *fwstr, *edidstr, *fallback = NULL;\n\tstruct edid *edid;\n\n\tif (edid_firmware[0] == '\\0')\n\t\treturn ERR_PTR(-ENOENT);\n\n\t/*\n\t * If there are multiple edid files specified and separated\n\t * by commas, search through the list looking for one that\n\t * matches the connector.\n\t *\n\t * If there's one or more that doesn't specify a connector, keep\n\t * the last one found one as a fallback.\n\t */\n\tfwstr = kstrdup(edid_firmware, GFP_KERNEL);\n\tif (!fwstr)\n\t\treturn ERR_PTR(-ENOMEM);\n\tedidstr = fwstr;\n\n\twhile ((edidname = strsep(&edidstr, \",\"))) {\n\t\tcolon = strchr(edidname, ':');\n\t\tif (colon != NULL) {\n\t\t\tif (strncmp(connector_name, edidname, colon - edidname))\n\t\t\t\tcontinue;\n\t\t\tedidname = colon + 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (*edidname != '\\0') /* corner case: multiple ',' */\n\t\t\tfallback = edidname;\n\t}\n\n\tif (!edidname) {\n\t\tif (!fallback) {\n\t\t\tkfree(fwstr);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t\tedidname = fallback;\n\t}\n\n\tlast = edidname + strlen(edidname) - 1;\n\tif (*last == '\\n')\n\t\t*last = '\\0';\n\n\tedid = edid_load(connector, edidname, connector_name);\n\tkfree(fwstr);\n\n\treturn edid;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,6 +16,8 @@\n \t * the last one found one as a fallback.\n \t */\n \tfwstr = kstrdup(edid_firmware, GFP_KERNEL);\n+\tif (!fwstr)\n+\t\treturn ERR_PTR(-ENOMEM);\n \tedidstr = fwstr;\n \n \twhile ((edidname = strsep(&edidstr, \",\"))) {",
        "function_modified_lines": {
            "added": [
                "\tif (!fwstr)",
                "\t\treturn ERR_PTR(-ENOMEM);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in drm_load_edid_firmware in drivers/gpu/drm/drm_edid_load.c in the Linux kernel through 5.1.5. There is an unchecked kstrdup of fwstr, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash). NOTE: The vendor disputes this issues as not being a vulnerability because kstrdup() returning NULL is handled sufficiently and there is no chance for a NULL pointer dereference",
        "id": 1944
    },
    {
        "cve_id": "CVE-2018-10322",
        "code_before_change": "xfs_failaddr_t\nxfs_dinode_verify(\n\tstruct xfs_mount\t*mp,\n\txfs_ino_t\t\tino,\n\tstruct xfs_dinode\t*dip)\n{\n\tuint16_t\t\tmode;\n\tuint16_t\t\tflags;\n\tuint64_t\t\tflags2;\n\tuint64_t\t\tdi_size;\n\n\tif (dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))\n\t\treturn __this_address;\n\n\t/* Verify v3 integrity information first */\n\tif (dip->di_version >= 3) {\n\t\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\t\treturn __this_address;\n\t\tif (!xfs_verify_cksum((char *)dip, mp->m_sb.sb_inodesize,\n\t\t\t\t      XFS_DINODE_CRC_OFF))\n\t\t\treturn __this_address;\n\t\tif (be64_to_cpu(dip->di_ino) != ino)\n\t\t\treturn __this_address;\n\t\tif (!uuid_equal(&dip->di_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t}\n\n\t/* don't allow invalid i_size */\n\tdi_size = be64_to_cpu(dip->di_size);\n\tif (di_size & (1ULL << 63))\n\t\treturn __this_address;\n\n\tmode = be16_to_cpu(dip->di_mode);\n\tif (mode && xfs_mode_to_ftype(mode) == XFS_DIR3_FT_UNKNOWN)\n\t\treturn __this_address;\n\n\t/* No zero-length symlinks/dirs. */\n\tif ((S_ISLNK(mode) || S_ISDIR(mode)) && di_size == 0)\n\t\treturn __this_address;\n\n\t/* Fork checks carried over from xfs_iformat_fork */\n\tif (mode &&\n\t    be32_to_cpu(dip->di_nextents) + be16_to_cpu(dip->di_anextents) >\n\t\t\tbe64_to_cpu(dip->di_nblocks))\n\t\treturn __this_address;\n\n\tif (mode && XFS_DFORK_BOFF(dip) > mp->m_sb.sb_inodesize)\n\t\treturn __this_address;\n\n\tflags = be16_to_cpu(dip->di_flags);\n\n\tif (mode && (flags & XFS_DIFLAG_REALTIME) && !mp->m_rtdev_targp)\n\t\treturn __this_address;\n\n\t/* Do we have appropriate data fork formats for the mode? */\n\tswitch (mode & S_IFMT) {\n\tcase S_IFIFO:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFSOCK:\n\t\tif (dip->di_format != XFS_DINODE_FMT_DEV)\n\t\t\treturn __this_address;\n\t\tbreak;\n\tcase S_IFREG:\n\tcase S_IFLNK:\n\tcase S_IFDIR:\n\t\tswitch (dip->di_format) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\t\t/*\n\t\t\t * no local regular files yet\n\t\t\t */\n\t\t\tif (S_ISREG(mode))\n\t\t\t\treturn __this_address;\n\t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))\n\t\t\t\treturn __this_address;\n\t\t\t/* fall through */\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tbreak;\n\tcase 0:\n\t\t/* Uninitialized inode ok. */\n\t\tbreak;\n\tdefault:\n\t\treturn __this_address;\n\t}\n\n\tif (XFS_DFORK_Q(dip)) {\n\t\tswitch (dip->di_aformat) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t}\n\n\t/* only version 3 or greater inodes are extensively verified here */\n\tif (dip->di_version < 3)\n\t\treturn NULL;\n\n\tflags2 = be64_to_cpu(dip->di_flags2);\n\n\t/* don't allow reflink/cowextsize if we don't have reflink */\n\tif ((flags2 & (XFS_DIFLAG2_REFLINK | XFS_DIFLAG2_COWEXTSIZE)) &&\n            !xfs_sb_version_hasreflink(&mp->m_sb))\n\t\treturn __this_address;\n\n\t/* only regular files get reflink */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (mode & S_IFMT) != S_IFREG)\n\t\treturn __this_address;\n\n\t/* don't let reflink and realtime mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags & XFS_DIFLAG_REALTIME))\n\t\treturn __this_address;\n\n\t/* don't let reflink and dax mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags2 & XFS_DIFLAG2_DAX))\n\t\treturn __this_address;\n\n\treturn NULL;\n}",
        "code_after_change": "xfs_failaddr_t\nxfs_dinode_verify(\n\tstruct xfs_mount\t*mp,\n\txfs_ino_t\t\tino,\n\tstruct xfs_dinode\t*dip)\n{\n\tuint16_t\t\tmode;\n\tuint16_t\t\tflags;\n\tuint64_t\t\tflags2;\n\tuint64_t\t\tdi_size;\n\n\tif (dip->di_magic != cpu_to_be16(XFS_DINODE_MAGIC))\n\t\treturn __this_address;\n\n\t/* Verify v3 integrity information first */\n\tif (dip->di_version >= 3) {\n\t\tif (!xfs_sb_version_hascrc(&mp->m_sb))\n\t\t\treturn __this_address;\n\t\tif (!xfs_verify_cksum((char *)dip, mp->m_sb.sb_inodesize,\n\t\t\t\t      XFS_DINODE_CRC_OFF))\n\t\t\treturn __this_address;\n\t\tif (be64_to_cpu(dip->di_ino) != ino)\n\t\t\treturn __this_address;\n\t\tif (!uuid_equal(&dip->di_uuid, &mp->m_sb.sb_meta_uuid))\n\t\t\treturn __this_address;\n\t}\n\n\t/* don't allow invalid i_size */\n\tdi_size = be64_to_cpu(dip->di_size);\n\tif (di_size & (1ULL << 63))\n\t\treturn __this_address;\n\n\tmode = be16_to_cpu(dip->di_mode);\n\tif (mode && xfs_mode_to_ftype(mode) == XFS_DIR3_FT_UNKNOWN)\n\t\treturn __this_address;\n\n\t/* No zero-length symlinks/dirs. */\n\tif ((S_ISLNK(mode) || S_ISDIR(mode)) && di_size == 0)\n\t\treturn __this_address;\n\n\t/* Fork checks carried over from xfs_iformat_fork */\n\tif (mode &&\n\t    be32_to_cpu(dip->di_nextents) + be16_to_cpu(dip->di_anextents) >\n\t\t\tbe64_to_cpu(dip->di_nblocks))\n\t\treturn __this_address;\n\n\tif (mode && XFS_DFORK_BOFF(dip) > mp->m_sb.sb_inodesize)\n\t\treturn __this_address;\n\n\tflags = be16_to_cpu(dip->di_flags);\n\n\tif (mode && (flags & XFS_DIFLAG_REALTIME) && !mp->m_rtdev_targp)\n\t\treturn __this_address;\n\n\t/* Do we have appropriate data fork formats for the mode? */\n\tswitch (mode & S_IFMT) {\n\tcase S_IFIFO:\n\tcase S_IFCHR:\n\tcase S_IFBLK:\n\tcase S_IFSOCK:\n\t\tif (dip->di_format != XFS_DINODE_FMT_DEV)\n\t\t\treturn __this_address;\n\t\tbreak;\n\tcase S_IFREG:\n\tcase S_IFLNK:\n\tcase S_IFDIR:\n\t\tswitch (dip->di_format) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\t\t/*\n\t\t\t * no local regular files yet\n\t\t\t */\n\t\t\tif (S_ISREG(mode))\n\t\t\t\treturn __this_address;\n\t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))\n\t\t\t\treturn __this_address;\n\t\t\tif (dip->di_nextents)\n\t\t\t\treturn __this_address;\n\t\t\t/* fall through */\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tbreak;\n\tcase 0:\n\t\t/* Uninitialized inode ok. */\n\t\tbreak;\n\tdefault:\n\t\treturn __this_address;\n\t}\n\n\tif (XFS_DFORK_Q(dip)) {\n\t\tswitch (dip->di_aformat) {\n\t\tcase XFS_DINODE_FMT_LOCAL:\n\t\t\tif (dip->di_anextents)\n\t\t\t\treturn __this_address;\n\t\t/* fall through */\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\tcase XFS_DINODE_FMT_BTREE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t} else {\n\t\t/*\n\t\t * If there is no fork offset, this may be a freshly-made inode\n\t\t * in a new disk cluster, in which case di_aformat is zeroed.\n\t\t * Otherwise, such an inode must be in EXTENTS format; this goes\n\t\t * for freed inodes as well.\n\t\t */\n\t\tswitch (dip->di_aformat) {\n\t\tcase 0:\n\t\tcase XFS_DINODE_FMT_EXTENTS:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn __this_address;\n\t\t}\n\t\tif (dip->di_anextents)\n\t\t\treturn __this_address;\n\t}\n\n\t/* only version 3 or greater inodes are extensively verified here */\n\tif (dip->di_version < 3)\n\t\treturn NULL;\n\n\tflags2 = be64_to_cpu(dip->di_flags2);\n\n\t/* don't allow reflink/cowextsize if we don't have reflink */\n\tif ((flags2 & (XFS_DIFLAG2_REFLINK | XFS_DIFLAG2_COWEXTSIZE)) &&\n            !xfs_sb_version_hasreflink(&mp->m_sb))\n\t\treturn __this_address;\n\n\t/* only regular files get reflink */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (mode & S_IFMT) != S_IFREG)\n\t\treturn __this_address;\n\n\t/* don't let reflink and realtime mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags & XFS_DIFLAG_REALTIME))\n\t\treturn __this_address;\n\n\t/* don't let reflink and dax mix */\n\tif ((flags2 & XFS_DIFLAG2_REFLINK) && (flags2 & XFS_DIFLAG2_DAX))\n\t\treturn __this_address;\n\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -73,6 +73,8 @@\n \t\t\t\treturn __this_address;\n \t\t\tif (di_size > XFS_DFORK_DSIZE(dip, mp))\n \t\t\t\treturn __this_address;\n+\t\t\tif (dip->di_nextents)\n+\t\t\t\treturn __this_address;\n \t\t\t/* fall through */\n \t\tcase XFS_DINODE_FMT_EXTENTS:\n \t\tcase XFS_DINODE_FMT_BTREE:\n@@ -91,12 +93,31 @@\n \tif (XFS_DFORK_Q(dip)) {\n \t\tswitch (dip->di_aformat) {\n \t\tcase XFS_DINODE_FMT_LOCAL:\n+\t\t\tif (dip->di_anextents)\n+\t\t\t\treturn __this_address;\n+\t\t/* fall through */\n \t\tcase XFS_DINODE_FMT_EXTENTS:\n \t\tcase XFS_DINODE_FMT_BTREE:\n \t\t\tbreak;\n \t\tdefault:\n \t\t\treturn __this_address;\n \t\t}\n+\t} else {\n+\t\t/*\n+\t\t * If there is no fork offset, this may be a freshly-made inode\n+\t\t * in a new disk cluster, in which case di_aformat is zeroed.\n+\t\t * Otherwise, such an inode must be in EXTENTS format; this goes\n+\t\t * for freed inodes as well.\n+\t\t */\n+\t\tswitch (dip->di_aformat) {\n+\t\tcase 0:\n+\t\tcase XFS_DINODE_FMT_EXTENTS:\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\treturn __this_address;\n+\t\t}\n+\t\tif (dip->di_anextents)\n+\t\t\treturn __this_address;\n \t}\n \n \t/* only version 3 or greater inodes are extensively verified here */",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (dip->di_nextents)",
                "\t\t\t\treturn __this_address;",
                "\t\t\tif (dip->di_anextents)",
                "\t\t\t\treturn __this_address;",
                "\t\t/* fall through */",
                "\t} else {",
                "\t\t/*",
                "\t\t * If there is no fork offset, this may be a freshly-made inode",
                "\t\t * in a new disk cluster, in which case di_aformat is zeroed.",
                "\t\t * Otherwise, such an inode must be in EXTENTS format; this goes",
                "\t\t * for freed inodes as well.",
                "\t\t */",
                "\t\tswitch (dip->di_aformat) {",
                "\t\tcase 0:",
                "\t\tcase XFS_DINODE_FMT_EXTENTS:",
                "\t\t\tbreak;",
                "\t\tdefault:",
                "\t\t\treturn __this_address;",
                "\t\t}",
                "\t\tif (dip->di_anextents)",
                "\t\t\treturn __this_address;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The xfs_dinode_verify function in fs/xfs/libxfs/xfs_inode_buf.c in the Linux kernel through 4.16.3 allows local users to cause a denial of service (xfs_ilock_attr_map_shared invalid pointer dereference) via a crafted xfs image.",
        "id": 1587
    },
    {
        "cve_id": "CVE-2023-5972",
        "code_before_change": "int nft_expr_inner_parse(const struct nft_ctx *ctx, const struct nlattr *nla,\n\t\t\t struct nft_expr_info *info)\n{\n\tstruct nlattr *tb[NFTA_EXPR_MAX + 1];\n\tconst struct nft_expr_type *type;\n\tint err;\n\n\terr = nla_parse_nested_deprecated(tb, NFTA_EXPR_MAX, nla,\n\t\t\t\t\t  nft_expr_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[NFTA_EXPR_DATA])\n\t\treturn -EINVAL;\n\n\ttype = __nft_expr_type_get(ctx->family, tb[NFTA_EXPR_NAME]);\n\tif (!type)\n\t\treturn -ENOENT;\n\n\tif (!type->inner_ops)\n\t\treturn -EOPNOTSUPP;\n\n\terr = nla_parse_nested_deprecated(info->tb, type->maxattr,\n\t\t\t\t\t  tb[NFTA_EXPR_DATA],\n\t\t\t\t\t  type->policy, NULL);\n\tif (err < 0)\n\t\tgoto err_nla_parse;\n\n\tinfo->attr = nla;\n\tinfo->ops = type->inner_ops;\n\n\treturn 0;\n\nerr_nla_parse:\n\treturn err;\n}",
        "code_after_change": "int nft_expr_inner_parse(const struct nft_ctx *ctx, const struct nlattr *nla,\n\t\t\t struct nft_expr_info *info)\n{\n\tstruct nlattr *tb[NFTA_EXPR_MAX + 1];\n\tconst struct nft_expr_type *type;\n\tint err;\n\n\terr = nla_parse_nested_deprecated(tb, NFTA_EXPR_MAX, nla,\n\t\t\t\t\t  nft_expr_policy, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (!tb[NFTA_EXPR_DATA] || !tb[NFTA_EXPR_NAME])\n\t\treturn -EINVAL;\n\n\ttype = __nft_expr_type_get(ctx->family, tb[NFTA_EXPR_NAME]);\n\tif (!type)\n\t\treturn -ENOENT;\n\n\tif (!type->inner_ops)\n\t\treturn -EOPNOTSUPP;\n\n\terr = nla_parse_nested_deprecated(info->tb, type->maxattr,\n\t\t\t\t\t  tb[NFTA_EXPR_DATA],\n\t\t\t\t\t  type->policy, NULL);\n\tif (err < 0)\n\t\tgoto err_nla_parse;\n\n\tinfo->attr = nla;\n\tinfo->ops = type->inner_ops;\n\n\treturn 0;\n\nerr_nla_parse:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \tif (err < 0)\n \t\treturn err;\n \n-\tif (!tb[NFTA_EXPR_DATA])\n+\tif (!tb[NFTA_EXPR_DATA] || !tb[NFTA_EXPR_NAME])\n \t\treturn -EINVAL;\n \n \ttype = __nft_expr_type_get(ctx->family, tb[NFTA_EXPR_NAME]);",
        "function_modified_lines": {
            "added": [
                "\tif (!tb[NFTA_EXPR_DATA] || !tb[NFTA_EXPR_NAME])"
            ],
            "deleted": [
                "\tif (!tb[NFTA_EXPR_DATA])"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference flaw was found in the nft_inner.c functionality of netfilter in the Linux kernel. This issue could allow a local user to crash the system or escalate their privileges on the system.",
        "id": 4293
    },
    {
        "cve_id": "CVE-2018-10074",
        "code_before_change": "static int hi3660_stub_clk_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *res;\n\tunsigned int i;\n\tint ret;\n\n\t/* Use mailbox client without blocking */\n\tstub_clk_chan.cl.dev = dev;\n\tstub_clk_chan.cl.tx_done = NULL;\n\tstub_clk_chan.cl.tx_block = false;\n\tstub_clk_chan.cl.knows_txdone = false;\n\n\t/* Allocate mailbox channel */\n\tstub_clk_chan.mbox = mbox_request_channel(&stub_clk_chan.cl, 0);\n\tif (IS_ERR(stub_clk_chan.mbox))\n\t\treturn PTR_ERR(stub_clk_chan.mbox);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tfreq_reg = devm_ioremap(dev, res->start, resource_size(res));\n\tif (!freq_reg)\n\t\treturn -ENOMEM;\n\n\tfreq_reg += HI3660_STUB_CLOCK_DATA;\n\n\tfor (i = 0; i < HI3660_CLK_STUB_NUM; i++) {\n\t\tret = devm_clk_hw_register(&pdev->dev, &hi3660_stub_clks[i].hw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn devm_of_clk_add_hw_provider(&pdev->dev, hi3660_stub_clk_hw_get,\n\t\t\t\t\t   hi3660_stub_clks);\n}",
        "code_after_change": "static int hi3660_stub_clk_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *res;\n\tunsigned int i;\n\tint ret;\n\n\t/* Use mailbox client without blocking */\n\tstub_clk_chan.cl.dev = dev;\n\tstub_clk_chan.cl.tx_done = NULL;\n\tstub_clk_chan.cl.tx_block = false;\n\tstub_clk_chan.cl.knows_txdone = false;\n\n\t/* Allocate mailbox channel */\n\tstub_clk_chan.mbox = mbox_request_channel(&stub_clk_chan.cl, 0);\n\tif (IS_ERR(stub_clk_chan.mbox))\n\t\treturn PTR_ERR(stub_clk_chan.mbox);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res)\n\t\treturn -EINVAL;\n\tfreq_reg = devm_ioremap(dev, res->start, resource_size(res));\n\tif (!freq_reg)\n\t\treturn -ENOMEM;\n\n\tfreq_reg += HI3660_STUB_CLOCK_DATA;\n\n\tfor (i = 0; i < HI3660_CLK_STUB_NUM; i++) {\n\t\tret = devm_clk_hw_register(&pdev->dev, &hi3660_stub_clks[i].hw);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn devm_of_clk_add_hw_provider(&pdev->dev, hi3660_stub_clk_hw_get,\n\t\t\t\t\t   hi3660_stub_clks);\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,8 @@\n \t\treturn PTR_ERR(stub_clk_chan.mbox);\n \n \tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n+\tif (!res)\n+\t\treturn -EINVAL;\n \tfreq_reg = devm_ioremap(dev, res->start, resource_size(res));\n \tif (!freq_reg)\n \t\treturn -ENOMEM;",
        "function_modified_lines": {
            "added": [
                "\tif (!res)",
                "\t\treturn -EINVAL;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The hi3660_stub_clk_probe function in drivers/clk/hisilicon/clk-hi3660-stub.c in the Linux kernel before 4.16 allows local users to cause a denial of service (NULL pointer dereference) by triggering a failure of resource retrieval.",
        "id": 1584
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static noinline struct btrfs_device *device_list_add(const char *path,\n\t\t\t   struct btrfs_super_block *disk_super,\n\t\t\t   bool *new_device_added)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *fs_devices = NULL;\n\tstruct rcu_string *name;\n\tu64 found_transid = btrfs_super_generation(disk_super);\n\tu64 devid = btrfs_stack_device_id(&disk_super->dev_item);\n\tbool has_metadata_uuid = (btrfs_super_incompat_flags(disk_super) &\n\t\tBTRFS_FEATURE_INCOMPAT_METADATA_UUID);\n\tbool fsid_change_in_progress = (btrfs_super_flags(disk_super) &\n\t\t\t\t\tBTRFS_SUPER_FLAG_CHANGING_FSID_V2);\n\n\tif (fsid_change_in_progress) {\n\t\tif (!has_metadata_uuid) {\n\t\t\t/*\n\t\t\t * When we have an image which has CHANGING_FSID_V2 set\n\t\t\t * it might belong to either a filesystem which has\n\t\t\t * disks with completed fsid change or it might belong\n\t\t\t * to fs with no UUID changes in effect, handle both.\n\t\t\t */\n\t\t\tfs_devices = find_fsid_inprogress(disk_super);\n\t\t\tif (!fs_devices)\n\t\t\t\tfs_devices = find_fsid(disk_super->fsid, NULL);\n\t\t} else {\n\t\t\tfs_devices = find_fsid_changed(disk_super);\n\t\t}\n\t} else if (has_metadata_uuid) {\n\t\tfs_devices = find_fsid(disk_super->fsid,\n\t\t\t\t       disk_super->metadata_uuid);\n\t} else {\n\t\tfs_devices = find_fsid(disk_super->fsid, NULL);\n\t}\n\n\n\tif (!fs_devices) {\n\t\tif (has_metadata_uuid)\n\t\t\tfs_devices = alloc_fs_devices(disk_super->fsid,\n\t\t\t\t\t\t      disk_super->metadata_uuid);\n\t\telse\n\t\t\tfs_devices = alloc_fs_devices(disk_super->fsid, NULL);\n\n\t\tif (IS_ERR(fs_devices))\n\t\t\treturn ERR_CAST(fs_devices);\n\n\t\tfs_devices->fsid_change = fsid_change_in_progress;\n\n\t\tmutex_lock(&fs_devices->device_list_mutex);\n\t\tlist_add(&fs_devices->fs_list, &fs_uuids);\n\n\t\tdevice = NULL;\n\t} else {\n\t\tmutex_lock(&fs_devices->device_list_mutex);\n\t\tdevice = find_device(fs_devices, devid,\n\t\t\t\tdisk_super->dev_item.uuid);\n\n\t\t/*\n\t\t * If this disk has been pulled into an fs devices created by\n\t\t * a device which had the CHANGING_FSID_V2 flag then replace the\n\t\t * metadata_uuid/fsid values of the fs_devices.\n\t\t */\n\t\tif (has_metadata_uuid && fs_devices->fsid_change &&\n\t\t    found_transid > fs_devices->latest_generation) {\n\t\t\tmemcpy(fs_devices->fsid, disk_super->fsid,\n\t\t\t\t\tBTRFS_FSID_SIZE);\n\t\t\tmemcpy(fs_devices->metadata_uuid,\n\t\t\t\t\tdisk_super->metadata_uuid, BTRFS_FSID_SIZE);\n\n\t\t\tfs_devices->fsid_change = false;\n\t\t}\n\t}\n\n\tif (!device) {\n\t\tif (fs_devices->opened) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\n\t\tdevice = btrfs_alloc_device(NULL, &devid,\n\t\t\t\t\t    disk_super->dev_item.uuid);\n\t\tif (IS_ERR(device)) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t/* we can safely leave the fs_devices entry around */\n\t\t\treturn device;\n\t\t}\n\n\t\tname = rcu_string_strdup(path, GFP_NOFS);\n\t\tif (!name) {\n\t\t\tbtrfs_free_device(device);\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\trcu_assign_pointer(device->name, name);\n\n\t\tlist_add_rcu(&device->dev_list, &fs_devices->devices);\n\t\tfs_devices->num_devices++;\n\n\t\tdevice->fs_devices = fs_devices;\n\t\t*new_device_added = true;\n\n\t\tif (disk_super->label[0])\n\t\t\tpr_info(\"BTRFS: device label %s devid %llu transid %llu %s\\n\",\n\t\t\t\tdisk_super->label, devid, found_transid, path);\n\t\telse\n\t\t\tpr_info(\"BTRFS: device fsid %pU devid %llu transid %llu %s\\n\",\n\t\t\t\tdisk_super->fsid, devid, found_transid, path);\n\n\t} else if (!device->name || strcmp(device->name->str, path)) {\n\t\t/*\n\t\t * When FS is already mounted.\n\t\t * 1. If you are here and if the device->name is NULL that\n\t\t *    means this device was missing at time of FS mount.\n\t\t * 2. If you are here and if the device->name is different\n\t\t *    from 'path' that means either\n\t\t *      a. The same device disappeared and reappeared with\n\t\t *         different name. or\n\t\t *      b. The missing-disk-which-was-replaced, has\n\t\t *         reappeared now.\n\t\t *\n\t\t * We must allow 1 and 2a above. But 2b would be a spurious\n\t\t * and unintentional.\n\t\t *\n\t\t * Further in case of 1 and 2a above, the disk at 'path'\n\t\t * would have missed some transaction when it was away and\n\t\t * in case of 2a the stale bdev has to be updated as well.\n\t\t * 2b must not be allowed at all time.\n\t\t */\n\n\t\t/*\n\t\t * For now, we do allow update to btrfs_fs_device through the\n\t\t * btrfs dev scan cli after FS has been mounted.  We're still\n\t\t * tracking a problem where systems fail mount by subvolume id\n\t\t * when we reject replacement on a mounted FS.\n\t\t */\n\t\tif (!fs_devices->opened && found_transid < device->generation) {\n\t\t\t/*\n\t\t\t * That is if the FS is _not_ mounted and if you\n\t\t\t * are here, that means there is more than one\n\t\t\t * disk with same uuid and devid.We keep the one\n\t\t\t * with larger generation number or the last-in if\n\t\t\t * generation are equal.\n\t\t\t */\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-EEXIST);\n\t\t}\n\n\t\t/*\n\t\t * We are going to replace the device path for a given devid,\n\t\t * make sure it's the same device if the device is mounted\n\t\t */\n\t\tif (device->bdev) {\n\t\t\tstruct block_device *path_bdev;\n\n\t\t\tpath_bdev = lookup_bdev(path);\n\t\t\tif (IS_ERR(path_bdev)) {\n\t\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t\treturn ERR_CAST(path_bdev);\n\t\t\t}\n\n\t\t\tif (device->bdev != path_bdev) {\n\t\t\t\tbdput(path_bdev);\n\t\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t\tbtrfs_warn_in_rcu(device->fs_info,\n\t\t\t\"duplicate device fsid:devid for %pU:%llu old:%s new:%s\",\n\t\t\t\t\tdisk_super->fsid, devid,\n\t\t\t\t\trcu_str_deref(device->name), path);\n\t\t\t\treturn ERR_PTR(-EEXIST);\n\t\t\t}\n\t\t\tbdput(path_bdev);\n\t\t\tbtrfs_info_in_rcu(device->fs_info,\n\t\t\t\t\"device fsid %pU devid %llu moved old:%s new:%s\",\n\t\t\t\tdisk_super->fsid, devid,\n\t\t\t\trcu_str_deref(device->name), path);\n\t\t}\n\n\t\tname = rcu_string_strdup(path, GFP_NOFS);\n\t\tif (!name) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\trcu_string_free(device->name);\n\t\trcu_assign_pointer(device->name, name);\n\t\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state)) {\n\t\t\tfs_devices->missing_devices--;\n\t\t\tclear_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state);\n\t\t}\n\t}\n\n\t/*\n\t * Unmount does not free the btrfs_device struct but would zero\n\t * generation along with most of the other members. So just update\n\t * it back. We need it to pick the disk with largest generation\n\t * (as above).\n\t */\n\tif (!fs_devices->opened) {\n\t\tdevice->generation = found_transid;\n\t\tfs_devices->latest_generation = max_t(u64, found_transid,\n\t\t\t\t\t\tfs_devices->latest_generation);\n\t}\n\n\tfs_devices->total_devices = btrfs_super_num_devices(disk_super);\n\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\treturn device;\n}",
        "code_after_change": "static noinline struct btrfs_device *device_list_add(const char *path,\n\t\t\t   struct btrfs_super_block *disk_super,\n\t\t\t   bool *new_device_added)\n{\n\tstruct btrfs_device *device;\n\tstruct btrfs_fs_devices *fs_devices = NULL;\n\tstruct rcu_string *name;\n\tu64 found_transid = btrfs_super_generation(disk_super);\n\tu64 devid = btrfs_stack_device_id(&disk_super->dev_item);\n\tbool has_metadata_uuid = (btrfs_super_incompat_flags(disk_super) &\n\t\tBTRFS_FEATURE_INCOMPAT_METADATA_UUID);\n\tbool fsid_change_in_progress = (btrfs_super_flags(disk_super) &\n\t\t\t\t\tBTRFS_SUPER_FLAG_CHANGING_FSID_V2);\n\n\tif (fsid_change_in_progress) {\n\t\tif (!has_metadata_uuid) {\n\t\t\t/*\n\t\t\t * When we have an image which has CHANGING_FSID_V2 set\n\t\t\t * it might belong to either a filesystem which has\n\t\t\t * disks with completed fsid change or it might belong\n\t\t\t * to fs with no UUID changes in effect, handle both.\n\t\t\t */\n\t\t\tfs_devices = find_fsid_inprogress(disk_super);\n\t\t\tif (!fs_devices)\n\t\t\t\tfs_devices = find_fsid(disk_super->fsid, NULL);\n\t\t} else {\n\t\t\tfs_devices = find_fsid_changed(disk_super);\n\t\t}\n\t} else if (has_metadata_uuid) {\n\t\tfs_devices = find_fsid(disk_super->fsid,\n\t\t\t\t       disk_super->metadata_uuid);\n\t} else {\n\t\tfs_devices = find_fsid(disk_super->fsid, NULL);\n\t}\n\n\n\tif (!fs_devices) {\n\t\tif (has_metadata_uuid)\n\t\t\tfs_devices = alloc_fs_devices(disk_super->fsid,\n\t\t\t\t\t\t      disk_super->metadata_uuid);\n\t\telse\n\t\t\tfs_devices = alloc_fs_devices(disk_super->fsid, NULL);\n\n\t\tif (IS_ERR(fs_devices))\n\t\t\treturn ERR_CAST(fs_devices);\n\n\t\tfs_devices->fsid_change = fsid_change_in_progress;\n\n\t\tmutex_lock(&fs_devices->device_list_mutex);\n\t\tlist_add(&fs_devices->fs_list, &fs_uuids);\n\n\t\tdevice = NULL;\n\t} else {\n\t\tmutex_lock(&fs_devices->device_list_mutex);\n\t\tdevice = btrfs_find_device(fs_devices, devid,\n\t\t\t\tdisk_super->dev_item.uuid, NULL, false);\n\n\t\t/*\n\t\t * If this disk has been pulled into an fs devices created by\n\t\t * a device which had the CHANGING_FSID_V2 flag then replace the\n\t\t * metadata_uuid/fsid values of the fs_devices.\n\t\t */\n\t\tif (has_metadata_uuid && fs_devices->fsid_change &&\n\t\t    found_transid > fs_devices->latest_generation) {\n\t\t\tmemcpy(fs_devices->fsid, disk_super->fsid,\n\t\t\t\t\tBTRFS_FSID_SIZE);\n\t\t\tmemcpy(fs_devices->metadata_uuid,\n\t\t\t\t\tdisk_super->metadata_uuid, BTRFS_FSID_SIZE);\n\n\t\t\tfs_devices->fsid_change = false;\n\t\t}\n\t}\n\n\tif (!device) {\n\t\tif (fs_devices->opened) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\n\t\tdevice = btrfs_alloc_device(NULL, &devid,\n\t\t\t\t\t    disk_super->dev_item.uuid);\n\t\tif (IS_ERR(device)) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t/* we can safely leave the fs_devices entry around */\n\t\t\treturn device;\n\t\t}\n\n\t\tname = rcu_string_strdup(path, GFP_NOFS);\n\t\tif (!name) {\n\t\t\tbtrfs_free_device(device);\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\trcu_assign_pointer(device->name, name);\n\n\t\tlist_add_rcu(&device->dev_list, &fs_devices->devices);\n\t\tfs_devices->num_devices++;\n\n\t\tdevice->fs_devices = fs_devices;\n\t\t*new_device_added = true;\n\n\t\tif (disk_super->label[0])\n\t\t\tpr_info(\"BTRFS: device label %s devid %llu transid %llu %s\\n\",\n\t\t\t\tdisk_super->label, devid, found_transid, path);\n\t\telse\n\t\t\tpr_info(\"BTRFS: device fsid %pU devid %llu transid %llu %s\\n\",\n\t\t\t\tdisk_super->fsid, devid, found_transid, path);\n\n\t} else if (!device->name || strcmp(device->name->str, path)) {\n\t\t/*\n\t\t * When FS is already mounted.\n\t\t * 1. If you are here and if the device->name is NULL that\n\t\t *    means this device was missing at time of FS mount.\n\t\t * 2. If you are here and if the device->name is different\n\t\t *    from 'path' that means either\n\t\t *      a. The same device disappeared and reappeared with\n\t\t *         different name. or\n\t\t *      b. The missing-disk-which-was-replaced, has\n\t\t *         reappeared now.\n\t\t *\n\t\t * We must allow 1 and 2a above. But 2b would be a spurious\n\t\t * and unintentional.\n\t\t *\n\t\t * Further in case of 1 and 2a above, the disk at 'path'\n\t\t * would have missed some transaction when it was away and\n\t\t * in case of 2a the stale bdev has to be updated as well.\n\t\t * 2b must not be allowed at all time.\n\t\t */\n\n\t\t/*\n\t\t * For now, we do allow update to btrfs_fs_device through the\n\t\t * btrfs dev scan cli after FS has been mounted.  We're still\n\t\t * tracking a problem where systems fail mount by subvolume id\n\t\t * when we reject replacement on a mounted FS.\n\t\t */\n\t\tif (!fs_devices->opened && found_transid < device->generation) {\n\t\t\t/*\n\t\t\t * That is if the FS is _not_ mounted and if you\n\t\t\t * are here, that means there is more than one\n\t\t\t * disk with same uuid and devid.We keep the one\n\t\t\t * with larger generation number or the last-in if\n\t\t\t * generation are equal.\n\t\t\t */\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-EEXIST);\n\t\t}\n\n\t\t/*\n\t\t * We are going to replace the device path for a given devid,\n\t\t * make sure it's the same device if the device is mounted\n\t\t */\n\t\tif (device->bdev) {\n\t\t\tstruct block_device *path_bdev;\n\n\t\t\tpath_bdev = lookup_bdev(path);\n\t\t\tif (IS_ERR(path_bdev)) {\n\t\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t\treturn ERR_CAST(path_bdev);\n\t\t\t}\n\n\t\t\tif (device->bdev != path_bdev) {\n\t\t\t\tbdput(path_bdev);\n\t\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\t\tbtrfs_warn_in_rcu(device->fs_info,\n\t\t\t\"duplicate device fsid:devid for %pU:%llu old:%s new:%s\",\n\t\t\t\t\tdisk_super->fsid, devid,\n\t\t\t\t\trcu_str_deref(device->name), path);\n\t\t\t\treturn ERR_PTR(-EEXIST);\n\t\t\t}\n\t\t\tbdput(path_bdev);\n\t\t\tbtrfs_info_in_rcu(device->fs_info,\n\t\t\t\t\"device fsid %pU devid %llu moved old:%s new:%s\",\n\t\t\t\tdisk_super->fsid, devid,\n\t\t\t\trcu_str_deref(device->name), path);\n\t\t}\n\n\t\tname = rcu_string_strdup(path, GFP_NOFS);\n\t\tif (!name) {\n\t\t\tmutex_unlock(&fs_devices->device_list_mutex);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\trcu_string_free(device->name);\n\t\trcu_assign_pointer(device->name, name);\n\t\tif (test_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state)) {\n\t\t\tfs_devices->missing_devices--;\n\t\t\tclear_bit(BTRFS_DEV_STATE_MISSING, &device->dev_state);\n\t\t}\n\t}\n\n\t/*\n\t * Unmount does not free the btrfs_device struct but would zero\n\t * generation along with most of the other members. So just update\n\t * it back. We need it to pick the disk with largest generation\n\t * (as above).\n\t */\n\tif (!fs_devices->opened) {\n\t\tdevice->generation = found_transid;\n\t\tfs_devices->latest_generation = max_t(u64, found_transid,\n\t\t\t\t\t\tfs_devices->latest_generation);\n\t}\n\n\tfs_devices->total_devices = btrfs_super_num_devices(disk_super);\n\n\tmutex_unlock(&fs_devices->device_list_mutex);\n\treturn device;\n}",
        "patch": "--- code before\n+++ code after\n@@ -52,8 +52,8 @@\n \t\tdevice = NULL;\n \t} else {\n \t\tmutex_lock(&fs_devices->device_list_mutex);\n-\t\tdevice = find_device(fs_devices, devid,\n-\t\t\t\tdisk_super->dev_item.uuid);\n+\t\tdevice = btrfs_find_device(fs_devices, devid,\n+\t\t\t\tdisk_super->dev_item.uuid, NULL, false);\n \n \t\t/*\n \t\t * If this disk has been pulled into an fs devices created by",
        "function_modified_lines": {
            "added": [
                "\t\tdevice = btrfs_find_device(fs_devices, devid,",
                "\t\t\t\tdisk_super->dev_item.uuid, NULL, false);"
            ],
            "deleted": [
                "\t\tdevice = find_device(fs_devices, devid,",
                "\t\t\t\tdisk_super->dev_item.uuid);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2117
    },
    {
        "cve_id": "CVE-2020-36558",
        "code_before_change": "int vt_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tunsigned int console;\n\tunsigned char ucval;\n\tunsigned int uival;\n\tvoid __user *up = (void __user *)arg;\n\tint i, perm;\n\tint ret = 0;\n\n\tconsole = vc->vc_num;\n\n\n\tif (!vc_cons_allocated(console)) { \t/* impossible? */\n\t\tret = -ENOIOCTLCMD;\n\t\tgoto out;\n\t}\n\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n \n\tswitch (cmd) {\n\tcase TIOCLINUX:\n\t\tret = tioclinux(tty, arg);\n\t\tbreak;\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\t\t\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is naïve.\n\t\t */\n\t\tucval = KB_101;\n\t\tret = put_user(ucval, (char __user *)arg);\n\t\tbreak;\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tret = ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\t\tbreak;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\tret = ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n\t\tbreak;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\t\t\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\t\t\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat))) {\n\t\t\tret =  -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\t/*\n\t\t * currently, setting the mode from KD_TEXT to KD_GRAPHICS\n\t\t * doesn't do a whole lot. i'm not sure if it should do any\n\t\t * restoration of modes or what...\n\t\t *\n\t\t * XXX It should at least call into the driver, fbdev's definitely\n\t\t * need to restore their engine state. --BenH\n\t\t */\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tswitch (arg) {\n\t\tcase KD_GRAPHICS:\n\t\t\tbreak;\n\t\tcase KD_TEXT0:\n\t\tcase KD_TEXT1:\n\t\t\targ = KD_TEXT;\n\t\tcase KD_TEXT:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\t/* FIXME: this needs the console lock extending */\n\t\tif (vc->vc_mode == (unsigned char) arg)\n\t\t\tbreak;\n\t\tvc->vc_mode = (unsigned char) arg;\n\t\tif (console != fg_console)\n\t\t\tbreak;\n\t\t/*\n\t\t * explicitly blank/unblank the screen if switching modes\n\t\t */\n\t\tconsole_lock();\n\t\tif (arg == KD_TEXT)\n\t\t\tdo_unblank_screen(1);\n\t\telse\n\t\t\tdo_blank_screen(1);\n\t\tconsole_unlock();\n\t\tbreak;\n\n\tcase KDGETMODE:\n\t\tuival = vc->vc_mode;\n\t\tgoto setint;\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\tret = -EINVAL;\n\t\tbreak;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret == 0)\n\t\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\tuival = vt_do_kdgkbmode(console);\n\t\tret = put_user(uival, (int __user *)arg);\n\t\tbreak;\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\tret = vt_do_kdskbmeta(console, arg);\n\t\tbreak;\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\tuival = vt_do_kdgkbmeta(console);\n\tsetint:\n\t\tret = put_user(uival, (int __user *)arg);\n\t\tbreak;\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\tret = vt_do_kbkeycode_ioctl(cmd, up, perm);\n\t\tbreak;\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\tret = vt_do_kdsk_ioctl(cmd, up, perm, console);\n\t\tbreak;\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\tret = vt_do_kdgkb_ioctl(cmd, up, perm);\n\t\tbreak;\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\tret = vt_do_diacrit(cmd, up, perm);\n\t\tbreak;\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\tret = vt_do_kdskled(console, cmd, arg, perm);\n\t\tbreak;\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t{\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\tret = -EINVAL;\n\t\telse {\n\t\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\t\tput_pid(vt_spawn_con.pid);\n\t\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\t\tvt_spawn_con.sig = arg;\n\t\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase VT_SETMODE:\n\t{\n\t\tstruct vt_mode tmp;\n\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&tmp, up, sizeof(struct vt_mode))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (tmp.mode != VT_AUTO && tmp.mode != VT_PROCESS) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tconsole_lock();\n\t\tvc->vt_mode = tmp;\n\t\t/* the frsig is ignored, so we set it to 0 */\n\t\tvc->vt_mode.frsig = 0;\n\t\tput_pid(vc->vt_pid);\n\t\tvc->vt_pid = get_pid(task_pid(current));\n\t\t/* no switch is required -- saw@shade.msu.ru */\n\t\tvc->vt_newvt = -1;\n\t\tconsole_unlock();\n\t\tbreak;\n\t}\n\n\tcase VT_GETMODE:\n\t{\n\t\tstruct vt_mode tmp;\n\t\tint rc;\n\n\t\tconsole_lock();\n\t\tmemcpy(&tmp, &vc->vt_mode, sizeof(struct vt_mode));\n\t\tconsole_unlock();\n\n\t\trc = copy_to_user(up, &tmp, sizeof(struct vt_mode));\n\t\tif (rc)\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\t/*\n\t * Returns global vt state. Note that VT 0 is always open, since\n\t * it's an alias for the current VT, and people can't use it here.\n\t * We cannot return state for more than 16 VTs, since v_state is short.\n\t */\n\tcase VT_GETSTATE:\n\t{\n\t\tstruct vt_stat __user *vtstat = up;\n\t\tunsigned short state, mask;\n\n\t\t/* Review: FIXME: Console lock ? */\n\t\tif (put_user(fg_console + 1, &vtstat->v_active))\n\t\t\tret = -EFAULT;\n\t\telse {\n\t\t\tstate = 1;\t/* /dev/tty0 is always open */\n\t\t\tfor (i = 0, mask = 2; i < MAX_NR_CONSOLES && mask;\n\t\t\t\t\t\t\t++i, mask <<= 1)\n\t\t\t\tif (VT_IS_IN_USE(i))\n\t\t\t\t\tstate |= mask;\n\t\t\tret = put_user(state, &vtstat->v_state);\n\t\t}\n\t\tbreak;\n\t}\n\n\t/*\n\t * Returns the first available (non-opened) console.\n\t */\n\tcase VT_OPENQRY:\n\t\t/* FIXME: locking ? - but then this is a stupid API */\n\t\tfor (i = 0; i < MAX_NR_CONSOLES; ++i)\n\t\t\tif (! VT_IS_IN_USE(i))\n\t\t\t\tbreak;\n\t\tuival = i < MAX_NR_CONSOLES ? (i+1) : -1;\n\t\tgoto setint;\t\t \n\n\t/*\n\t * ioctl(fd, VT_ACTIVATE, num) will cause us to switch to vt # num,\n\t * with num >= 1 (switches to vt 0, our console, are not allowed, just\n\t * to preserve sanity).\n\t */\n\tcase VT_ACTIVATE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (arg == 0 || arg > MAX_NR_CONSOLES)\n\t\t\tret =  -ENXIO;\n\t\telse {\n\t\t\targ--;\n\t\t\tconsole_lock();\n\t\t\tret = vc_allocate(arg);\n\t\t\tconsole_unlock();\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\tset_console(arg);\n\t\t}\n\t\tbreak;\n\n\tcase VT_SETACTIVATE:\n\t{\n\t\tstruct vt_setactivate vsa;\n\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&vsa, (struct vt_setactivate __user *)arg,\n\t\t\t\t\tsizeof(struct vt_setactivate))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (vsa.console == 0 || vsa.console > MAX_NR_CONSOLES)\n\t\t\tret = -ENXIO;\n\t\telse {\n\t\t\tvsa.console = array_index_nospec(vsa.console,\n\t\t\t\t\t\t\t MAX_NR_CONSOLES + 1);\n\t\t\tvsa.console--;\n\t\t\tconsole_lock();\n\t\t\tret = vc_allocate(vsa.console);\n\t\t\tif (ret == 0) {\n\t\t\t\tstruct vc_data *nvc;\n\t\t\t\t/* This is safe providing we don't drop the\n\t\t\t\t   console sem between vc_allocate and\n\t\t\t\t   finishing referencing nvc */\n\t\t\t\tnvc = vc_cons[vsa.console].d;\n\t\t\t\tnvc->vt_mode = vsa.mode;\n\t\t\t\tnvc->vt_mode.frsig = 0;\n\t\t\t\tput_pid(nvc->vt_pid);\n\t\t\t\tnvc->vt_pid = get_pid(task_pid(current));\n\t\t\t}\n\t\t\tconsole_unlock();\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\t/* Commence switch and lock */\n\t\t\t/* Review set_console locks */\n\t\t\tset_console(vsa.console);\n\t\t}\n\t\tbreak;\n\t}\n\n\t/*\n\t * wait until the specified VT has been activated\n\t */\n\tcase VT_WAITACTIVE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (arg == 0 || arg > MAX_NR_CONSOLES)\n\t\t\tret = -ENXIO;\n\t\telse\n\t\t\tret = vt_waitactive(arg);\n\t\tbreak;\n\n\t/*\n\t * If a vt is under process control, the kernel will not switch to it\n\t * immediately, but postpone the operation until the process calls this\n\t * ioctl, allowing the switch to complete.\n\t *\n\t * According to the X sources this is the behavior:\n\t *\t0:\tpending switch-from not OK\n\t *\t1:\tpending switch-from OK\n\t *\t2:\tcompleted switch-to OK\n\t */\n\tcase VT_RELDISP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tconsole_lock();\n\t\tif (vc->vt_mode.mode != VT_PROCESS) {\n\t\t\tconsole_unlock();\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * Switching-from response\n\t\t */\n\t\tif (vc->vt_newvt >= 0) {\n\t\t\tif (arg == 0)\n\t\t\t\t/*\n\t\t\t\t * Switch disallowed, so forget we were trying\n\t\t\t\t * to do it.\n\t\t\t\t */\n\t\t\t\tvc->vt_newvt = -1;\n\n\t\t\telse {\n\t\t\t\t/*\n\t\t\t\t * The current vt has been released, so\n\t\t\t\t * complete the switch.\n\t\t\t\t */\n\t\t\t\tint newvt;\n\t\t\t\tnewvt = vc->vt_newvt;\n\t\t\t\tvc->vt_newvt = -1;\n\t\t\t\tret = vc_allocate(newvt);\n\t\t\t\tif (ret) {\n\t\t\t\t\tconsole_unlock();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * When we actually do the console switch,\n\t\t\t\t * make sure we are atomic with respect to\n\t\t\t\t * other console switches..\n\t\t\t\t */\n\t\t\t\tcomplete_change_console(vc_cons[newvt].d);\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * Switched-to response\n\t\t\t */\n\t\t\t/*\n\t\t\t * If it's just an ACK, ignore it\n\t\t\t */\n\t\t\tif (arg != VT_ACKACQ)\n\t\t\t\tret = -EINVAL;\n\t\t}\n\t\tconsole_unlock();\n\t\tbreak;\n\n\t /*\n\t  * Disallocate memory associated to VT (but leave VT1)\n\t  */\n\t case VT_DISALLOCATE:\n\t\tif (arg > MAX_NR_CONSOLES) {\n\t\t\tret = -ENXIO;\n\t\t\tbreak;\n\t\t}\n\t\tif (arg == 0)\n\t\t\tvt_disallocate_all();\n\t\telse\n\t\t\tret = vt_disallocate(--arg);\n\t\tbreak;\n\n\tcase VT_RESIZE:\n\t{\n\t\tstruct vt_sizes __user *vtsizes = up;\n\t\tstruct vc_data *vc;\n\n\t\tushort ll,cc;\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (get_user(ll, &vtsizes->v_rows) ||\n\t\t    get_user(cc, &vtsizes->v_cols))\n\t\t\tret = -EFAULT;\n\t\telse {\n\t\t\tconsole_lock();\n\t\t\tfor (i = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\t\tvc = vc_cons[i].d;\n\n\t\t\t\tif (vc) {\n\t\t\t\t\tvc->vc_resize_user = 1;\n\t\t\t\t\t/* FIXME: review v tty lock */\n\t\t\t\t\tvc_resize(vc_cons[i].d, cc, ll);\n\t\t\t\t}\n\t\t\t}\n\t\t\tconsole_unlock();\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase VT_RESIZEX:\n\t{\n\t\tstruct vt_consize v;\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&v, up, sizeof(struct vt_consize)))\n\t\t\treturn -EFAULT;\n\t\t/* FIXME: Should check the copies properly */\n\t\tif (!v.v_vlin)\n\t\t\tv.v_vlin = vc->vc_scan_lines;\n\t\tif (v.v_clin) {\n\t\t\tint rows = v.v_vlin/v.v_clin;\n\t\t\tif (v.v_rows != rows) {\n\t\t\t\tif (v.v_rows) /* Parameters don't add up */\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tv.v_rows = rows;\n\t\t\t}\n\t\t}\n\t\tif (v.v_vcol && v.v_ccol) {\n\t\t\tint cols = v.v_vcol/v.v_ccol;\n\t\t\tif (v.v_cols != cols) {\n\t\t\t\tif (v.v_cols)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tv.v_cols = cols;\n\t\t\t}\n\t\t}\n\n\t\tif (v.v_clin > 32)\n\t\t\treturn -EINVAL;\n\n\t\tfor (i = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\tif (!vc_cons[i].d)\n\t\t\t\tcontinue;\n\t\t\tconsole_lock();\n\t\t\tif (v.v_vlin)\n\t\t\t\tvc_cons[i].d->vc_scan_lines = v.v_vlin;\n\t\t\tif (v.v_clin)\n\t\t\t\tvc_cons[i].d->vc_font.height = v.v_clin;\n\t\t\tvc_cons[i].d->vc_resize_user = 1;\n\t\t\tvc_resize(vc_cons[i].d, v.v_cols, v.v_rows);\n\t\t\tconsole_unlock();\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase PIO_FONT: {\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top.op = KD_FONT_OP_SET;\n\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n\t\top.width = 8;\n\t\top.height = 0;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tbreak;\n\t}\n\n\tcase GIO_FONT: {\n\t\top.op = KD_FONT_OP_GET;\n\t\top.flags = KD_FONT_FLAG_OLD;\n\t\top.width = 8;\n\t\top.height = 32;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tbreak;\n\t}\n\n\tcase PIO_CMAP:\n                if (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t                ret = con_set_cmap(up);\n\t\tbreak;\n\n\tcase GIO_CMAP:\n                ret = con_get_cmap(up);\n\t\tbreak;\n\n\tcase PIO_FONTX:\n\tcase GIO_FONTX:\n\t\tret = do_fontx_ioctl(cmd, up, perm, &op);\n\t\tbreak;\n\n\tcase PIO_FONTRESET:\n\t{\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n#ifdef BROKEN_GRAPHICS_PROGRAMS\n\t\t/* With BROKEN_GRAPHICS_PROGRAMS defined, the default\n\t\t   font is not saved. */\n\t\tret = -ENOSYS;\n\t\tbreak;\n#else\n\t\t{\n\t\top.op = KD_FONT_OP_SET_DEFAULT;\n\t\top.data = NULL;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tconsole_lock();\n\t\tcon_set_default_unimap(vc_cons[fg_console].d);\n\t\tconsole_unlock();\n\t\tbreak;\n\t\t}\n#endif\n\t}\n\n\tcase KDFONTOP: {\n\t\tif (copy_from_user(&op, up, sizeof(op))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tret = con_set_trans_old(up);\n\t\tbreak;\n\n\tcase GIO_SCRNMAP:\n\t\tret = con_get_trans_old(up);\n\t\tbreak;\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tret = con_set_trans_new(up);\n\t\tbreak;\n\n\tcase GIO_UNISCRNMAP:\n\t\tret = con_get_trans_new(up);\n\t\tbreak;\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\tret = do_unimap_ioctl(cmd, up, perm, vc);\n\t\tbreak;\n\n\tcase VT_LOCKSWITCH:\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\t\tvt_dont_switch = 1;\n\t\tbreak;\n\tcase VT_UNLOCKSWITCH:\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\t\tvt_dont_switch = 0;\n\t\tbreak;\n\tcase VT_GETHIFONTMASK:\n\t\tret = put_user(vc->vc_hi_font_mask,\n\t\t\t\t\t(unsigned short __user *)arg);\n\t\tbreak;\n\tcase VT_WAITEVENT:\n\t\tret = vt_event_wait_ioctl((struct vt_event __user *)arg);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOIOCTLCMD;\n\t}\nout:\n\treturn ret;\n}",
        "code_after_change": "int vt_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tunsigned int console;\n\tunsigned char ucval;\n\tunsigned int uival;\n\tvoid __user *up = (void __user *)arg;\n\tint i, perm;\n\tint ret = 0;\n\n\tconsole = vc->vc_num;\n\n\n\tif (!vc_cons_allocated(console)) { \t/* impossible? */\n\t\tret = -ENOIOCTLCMD;\n\t\tgoto out;\n\t}\n\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n \n\tswitch (cmd) {\n\tcase TIOCLINUX:\n\t\tret = tioclinux(tty, arg);\n\t\tbreak;\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\t\t\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is naïve.\n\t\t */\n\t\tucval = KB_101;\n\t\tret = put_user(ucval, (char __user *)arg);\n\t\tbreak;\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tret = ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\t\tbreak;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\tret = ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n\t\tbreak;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\t\t\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\t\t\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat))) {\n\t\t\tret =  -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\t/*\n\t\t * currently, setting the mode from KD_TEXT to KD_GRAPHICS\n\t\t * doesn't do a whole lot. i'm not sure if it should do any\n\t\t * restoration of modes or what...\n\t\t *\n\t\t * XXX It should at least call into the driver, fbdev's definitely\n\t\t * need to restore their engine state. --BenH\n\t\t */\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tswitch (arg) {\n\t\tcase KD_GRAPHICS:\n\t\t\tbreak;\n\t\tcase KD_TEXT0:\n\t\tcase KD_TEXT1:\n\t\t\targ = KD_TEXT;\n\t\tcase KD_TEXT:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\t/* FIXME: this needs the console lock extending */\n\t\tif (vc->vc_mode == (unsigned char) arg)\n\t\t\tbreak;\n\t\tvc->vc_mode = (unsigned char) arg;\n\t\tif (console != fg_console)\n\t\t\tbreak;\n\t\t/*\n\t\t * explicitly blank/unblank the screen if switching modes\n\t\t */\n\t\tconsole_lock();\n\t\tif (arg == KD_TEXT)\n\t\t\tdo_unblank_screen(1);\n\t\telse\n\t\t\tdo_blank_screen(1);\n\t\tconsole_unlock();\n\t\tbreak;\n\n\tcase KDGETMODE:\n\t\tuival = vc->vc_mode;\n\t\tgoto setint;\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\tret = -EINVAL;\n\t\tbreak;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret == 0)\n\t\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\tuival = vt_do_kdgkbmode(console);\n\t\tret = put_user(uival, (int __user *)arg);\n\t\tbreak;\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\tret = vt_do_kdskbmeta(console, arg);\n\t\tbreak;\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\tuival = vt_do_kdgkbmeta(console);\n\tsetint:\n\t\tret = put_user(uival, (int __user *)arg);\n\t\tbreak;\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\tret = vt_do_kbkeycode_ioctl(cmd, up, perm);\n\t\tbreak;\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\tret = vt_do_kdsk_ioctl(cmd, up, perm, console);\n\t\tbreak;\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\tret = vt_do_kdgkb_ioctl(cmd, up, perm);\n\t\tbreak;\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\tret = vt_do_diacrit(cmd, up, perm);\n\t\tbreak;\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\tret = vt_do_kdskled(console, cmd, arg, perm);\n\t\tbreak;\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t{\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\tret = -EINVAL;\n\t\telse {\n\t\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\t\tput_pid(vt_spawn_con.pid);\n\t\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\t\tvt_spawn_con.sig = arg;\n\t\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase VT_SETMODE:\n\t{\n\t\tstruct vt_mode tmp;\n\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&tmp, up, sizeof(struct vt_mode))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (tmp.mode != VT_AUTO && tmp.mode != VT_PROCESS) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tconsole_lock();\n\t\tvc->vt_mode = tmp;\n\t\t/* the frsig is ignored, so we set it to 0 */\n\t\tvc->vt_mode.frsig = 0;\n\t\tput_pid(vc->vt_pid);\n\t\tvc->vt_pid = get_pid(task_pid(current));\n\t\t/* no switch is required -- saw@shade.msu.ru */\n\t\tvc->vt_newvt = -1;\n\t\tconsole_unlock();\n\t\tbreak;\n\t}\n\n\tcase VT_GETMODE:\n\t{\n\t\tstruct vt_mode tmp;\n\t\tint rc;\n\n\t\tconsole_lock();\n\t\tmemcpy(&tmp, &vc->vt_mode, sizeof(struct vt_mode));\n\t\tconsole_unlock();\n\n\t\trc = copy_to_user(up, &tmp, sizeof(struct vt_mode));\n\t\tif (rc)\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\t/*\n\t * Returns global vt state. Note that VT 0 is always open, since\n\t * it's an alias for the current VT, and people can't use it here.\n\t * We cannot return state for more than 16 VTs, since v_state is short.\n\t */\n\tcase VT_GETSTATE:\n\t{\n\t\tstruct vt_stat __user *vtstat = up;\n\t\tunsigned short state, mask;\n\n\t\t/* Review: FIXME: Console lock ? */\n\t\tif (put_user(fg_console + 1, &vtstat->v_active))\n\t\t\tret = -EFAULT;\n\t\telse {\n\t\t\tstate = 1;\t/* /dev/tty0 is always open */\n\t\t\tfor (i = 0, mask = 2; i < MAX_NR_CONSOLES && mask;\n\t\t\t\t\t\t\t++i, mask <<= 1)\n\t\t\t\tif (VT_IS_IN_USE(i))\n\t\t\t\t\tstate |= mask;\n\t\t\tret = put_user(state, &vtstat->v_state);\n\t\t}\n\t\tbreak;\n\t}\n\n\t/*\n\t * Returns the first available (non-opened) console.\n\t */\n\tcase VT_OPENQRY:\n\t\t/* FIXME: locking ? - but then this is a stupid API */\n\t\tfor (i = 0; i < MAX_NR_CONSOLES; ++i)\n\t\t\tif (! VT_IS_IN_USE(i))\n\t\t\t\tbreak;\n\t\tuival = i < MAX_NR_CONSOLES ? (i+1) : -1;\n\t\tgoto setint;\t\t \n\n\t/*\n\t * ioctl(fd, VT_ACTIVATE, num) will cause us to switch to vt # num,\n\t * with num >= 1 (switches to vt 0, our console, are not allowed, just\n\t * to preserve sanity).\n\t */\n\tcase VT_ACTIVATE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (arg == 0 || arg > MAX_NR_CONSOLES)\n\t\t\tret =  -ENXIO;\n\t\telse {\n\t\t\targ--;\n\t\t\tconsole_lock();\n\t\t\tret = vc_allocate(arg);\n\t\t\tconsole_unlock();\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\tset_console(arg);\n\t\t}\n\t\tbreak;\n\n\tcase VT_SETACTIVATE:\n\t{\n\t\tstruct vt_setactivate vsa;\n\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&vsa, (struct vt_setactivate __user *)arg,\n\t\t\t\t\tsizeof(struct vt_setactivate))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (vsa.console == 0 || vsa.console > MAX_NR_CONSOLES)\n\t\t\tret = -ENXIO;\n\t\telse {\n\t\t\tvsa.console = array_index_nospec(vsa.console,\n\t\t\t\t\t\t\t MAX_NR_CONSOLES + 1);\n\t\t\tvsa.console--;\n\t\t\tconsole_lock();\n\t\t\tret = vc_allocate(vsa.console);\n\t\t\tif (ret == 0) {\n\t\t\t\tstruct vc_data *nvc;\n\t\t\t\t/* This is safe providing we don't drop the\n\t\t\t\t   console sem between vc_allocate and\n\t\t\t\t   finishing referencing nvc */\n\t\t\t\tnvc = vc_cons[vsa.console].d;\n\t\t\t\tnvc->vt_mode = vsa.mode;\n\t\t\t\tnvc->vt_mode.frsig = 0;\n\t\t\t\tput_pid(nvc->vt_pid);\n\t\t\t\tnvc->vt_pid = get_pid(task_pid(current));\n\t\t\t}\n\t\t\tconsole_unlock();\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\t/* Commence switch and lock */\n\t\t\t/* Review set_console locks */\n\t\t\tset_console(vsa.console);\n\t\t}\n\t\tbreak;\n\t}\n\n\t/*\n\t * wait until the specified VT has been activated\n\t */\n\tcase VT_WAITACTIVE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (arg == 0 || arg > MAX_NR_CONSOLES)\n\t\t\tret = -ENXIO;\n\t\telse\n\t\t\tret = vt_waitactive(arg);\n\t\tbreak;\n\n\t/*\n\t * If a vt is under process control, the kernel will not switch to it\n\t * immediately, but postpone the operation until the process calls this\n\t * ioctl, allowing the switch to complete.\n\t *\n\t * According to the X sources this is the behavior:\n\t *\t0:\tpending switch-from not OK\n\t *\t1:\tpending switch-from OK\n\t *\t2:\tcompleted switch-to OK\n\t */\n\tcase VT_RELDISP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tconsole_lock();\n\t\tif (vc->vt_mode.mode != VT_PROCESS) {\n\t\t\tconsole_unlock();\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * Switching-from response\n\t\t */\n\t\tif (vc->vt_newvt >= 0) {\n\t\t\tif (arg == 0)\n\t\t\t\t/*\n\t\t\t\t * Switch disallowed, so forget we were trying\n\t\t\t\t * to do it.\n\t\t\t\t */\n\t\t\t\tvc->vt_newvt = -1;\n\n\t\t\telse {\n\t\t\t\t/*\n\t\t\t\t * The current vt has been released, so\n\t\t\t\t * complete the switch.\n\t\t\t\t */\n\t\t\t\tint newvt;\n\t\t\t\tnewvt = vc->vt_newvt;\n\t\t\t\tvc->vt_newvt = -1;\n\t\t\t\tret = vc_allocate(newvt);\n\t\t\t\tif (ret) {\n\t\t\t\t\tconsole_unlock();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * When we actually do the console switch,\n\t\t\t\t * make sure we are atomic with respect to\n\t\t\t\t * other console switches..\n\t\t\t\t */\n\t\t\t\tcomplete_change_console(vc_cons[newvt].d);\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * Switched-to response\n\t\t\t */\n\t\t\t/*\n\t\t\t * If it's just an ACK, ignore it\n\t\t\t */\n\t\t\tif (arg != VT_ACKACQ)\n\t\t\t\tret = -EINVAL;\n\t\t}\n\t\tconsole_unlock();\n\t\tbreak;\n\n\t /*\n\t  * Disallocate memory associated to VT (but leave VT1)\n\t  */\n\t case VT_DISALLOCATE:\n\t\tif (arg > MAX_NR_CONSOLES) {\n\t\t\tret = -ENXIO;\n\t\t\tbreak;\n\t\t}\n\t\tif (arg == 0)\n\t\t\tvt_disallocate_all();\n\t\telse\n\t\t\tret = vt_disallocate(--arg);\n\t\tbreak;\n\n\tcase VT_RESIZE:\n\t{\n\t\tstruct vt_sizes __user *vtsizes = up;\n\t\tstruct vc_data *vc;\n\n\t\tushort ll,cc;\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (get_user(ll, &vtsizes->v_rows) ||\n\t\t    get_user(cc, &vtsizes->v_cols))\n\t\t\tret = -EFAULT;\n\t\telse {\n\t\t\tconsole_lock();\n\t\t\tfor (i = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\t\tvc = vc_cons[i].d;\n\n\t\t\t\tif (vc) {\n\t\t\t\t\tvc->vc_resize_user = 1;\n\t\t\t\t\t/* FIXME: review v tty lock */\n\t\t\t\t\tvc_resize(vc_cons[i].d, cc, ll);\n\t\t\t\t}\n\t\t\t}\n\t\t\tconsole_unlock();\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase VT_RESIZEX:\n\t{\n\t\tstruct vt_consize v;\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&v, up, sizeof(struct vt_consize)))\n\t\t\treturn -EFAULT;\n\t\t/* FIXME: Should check the copies properly */\n\t\tif (!v.v_vlin)\n\t\t\tv.v_vlin = vc->vc_scan_lines;\n\t\tif (v.v_clin) {\n\t\t\tint rows = v.v_vlin/v.v_clin;\n\t\t\tif (v.v_rows != rows) {\n\t\t\t\tif (v.v_rows) /* Parameters don't add up */\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tv.v_rows = rows;\n\t\t\t}\n\t\t}\n\t\tif (v.v_vcol && v.v_ccol) {\n\t\t\tint cols = v.v_vcol/v.v_ccol;\n\t\t\tif (v.v_cols != cols) {\n\t\t\t\tif (v.v_cols)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tv.v_cols = cols;\n\t\t\t}\n\t\t}\n\n\t\tif (v.v_clin > 32)\n\t\t\treturn -EINVAL;\n\n\t\tfor (i = 0; i < MAX_NR_CONSOLES; i++) {\n\t\t\tstruct vc_data *vcp;\n\n\t\t\tif (!vc_cons[i].d)\n\t\t\t\tcontinue;\n\t\t\tconsole_lock();\n\t\t\tvcp = vc_cons[i].d;\n\t\t\tif (vcp) {\n\t\t\t\tif (v.v_vlin)\n\t\t\t\t\tvcp->vc_scan_lines = v.v_vlin;\n\t\t\t\tif (v.v_clin)\n\t\t\t\t\tvcp->vc_font.height = v.v_clin;\n\t\t\t\tvcp->vc_resize_user = 1;\n\t\t\t\tvc_resize(vcp, v.v_cols, v.v_rows);\n\t\t\t}\n\t\t\tconsole_unlock();\n\t\t}\n\t\tbreak;\n\t}\n\n\tcase PIO_FONT: {\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top.op = KD_FONT_OP_SET;\n\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n\t\top.width = 8;\n\t\top.height = 0;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tbreak;\n\t}\n\n\tcase GIO_FONT: {\n\t\top.op = KD_FONT_OP_GET;\n\t\top.flags = KD_FONT_FLAG_OLD;\n\t\top.width = 8;\n\t\top.height = 32;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tbreak;\n\t}\n\n\tcase PIO_CMAP:\n                if (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t                ret = con_set_cmap(up);\n\t\tbreak;\n\n\tcase GIO_CMAP:\n                ret = con_get_cmap(up);\n\t\tbreak;\n\n\tcase PIO_FONTX:\n\tcase GIO_FONTX:\n\t\tret = do_fontx_ioctl(cmd, up, perm, &op);\n\t\tbreak;\n\n\tcase PIO_FONTRESET:\n\t{\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n#ifdef BROKEN_GRAPHICS_PROGRAMS\n\t\t/* With BROKEN_GRAPHICS_PROGRAMS defined, the default\n\t\t   font is not saved. */\n\t\tret = -ENOSYS;\n\t\tbreak;\n#else\n\t\t{\n\t\top.op = KD_FONT_OP_SET_DEFAULT;\n\t\top.data = NULL;\n\t\tret = con_font_op(vc_cons[fg_console].d, &op);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tconsole_lock();\n\t\tcon_set_default_unimap(vc_cons[fg_console].d);\n\t\tconsole_unlock();\n\t\tbreak;\n\t\t}\n#endif\n\t}\n\n\tcase KDFONTOP: {\n\t\tif (copy_from_user(&op, up, sizeof(op))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tret = con_set_trans_old(up);\n\t\tbreak;\n\n\tcase GIO_SCRNMAP:\n\t\tret = con_get_trans_old(up);\n\t\tbreak;\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tret = con_set_trans_new(up);\n\t\tbreak;\n\n\tcase GIO_UNISCRNMAP:\n\t\tret = con_get_trans_new(up);\n\t\tbreak;\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\tret = do_unimap_ioctl(cmd, up, perm, vc);\n\t\tbreak;\n\n\tcase VT_LOCKSWITCH:\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\t\tvt_dont_switch = 1;\n\t\tbreak;\n\tcase VT_UNLOCKSWITCH:\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\t\tvt_dont_switch = 0;\n\t\tbreak;\n\tcase VT_GETHIFONTMASK:\n\t\tret = put_user(vc->vc_hi_font_mask,\n\t\t\t\t\t(unsigned short __user *)arg);\n\t\tbreak;\n\tcase VT_WAITEVENT:\n\t\tret = vt_event_wait_ioctl((struct vt_event __user *)arg);\n\t\tbreak;\n\tdefault:\n\t\tret = -ENOIOCTLCMD;\n\t}\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -544,15 +544,20 @@\n \t\t\treturn -EINVAL;\n \n \t\tfor (i = 0; i < MAX_NR_CONSOLES; i++) {\n+\t\t\tstruct vc_data *vcp;\n+\n \t\t\tif (!vc_cons[i].d)\n \t\t\t\tcontinue;\n \t\t\tconsole_lock();\n-\t\t\tif (v.v_vlin)\n-\t\t\t\tvc_cons[i].d->vc_scan_lines = v.v_vlin;\n-\t\t\tif (v.v_clin)\n-\t\t\t\tvc_cons[i].d->vc_font.height = v.v_clin;\n-\t\t\tvc_cons[i].d->vc_resize_user = 1;\n-\t\t\tvc_resize(vc_cons[i].d, v.v_cols, v.v_rows);\n+\t\t\tvcp = vc_cons[i].d;\n+\t\t\tif (vcp) {\n+\t\t\t\tif (v.v_vlin)\n+\t\t\t\t\tvcp->vc_scan_lines = v.v_vlin;\n+\t\t\t\tif (v.v_clin)\n+\t\t\t\t\tvcp->vc_font.height = v.v_clin;\n+\t\t\t\tvcp->vc_resize_user = 1;\n+\t\t\t\tvc_resize(vcp, v.v_cols, v.v_rows);\n+\t\t\t}\n \t\t\tconsole_unlock();\n \t\t}\n \t\tbreak;",
        "function_modified_lines": {
            "added": [
                "\t\t\tstruct vc_data *vcp;",
                "",
                "\t\t\tvcp = vc_cons[i].d;",
                "\t\t\tif (vcp) {",
                "\t\t\t\tif (v.v_vlin)",
                "\t\t\t\t\tvcp->vc_scan_lines = v.v_vlin;",
                "\t\t\t\tif (v.v_clin)",
                "\t\t\t\t\tvcp->vc_font.height = v.v_clin;",
                "\t\t\t\tvcp->vc_resize_user = 1;",
                "\t\t\t\tvc_resize(vcp, v.v_cols, v.v_rows);",
                "\t\t\t}"
            ],
            "deleted": [
                "\t\t\tif (v.v_vlin)",
                "\t\t\t\tvc_cons[i].d->vc_scan_lines = v.v_vlin;",
                "\t\t\tif (v.v_clin)",
                "\t\t\t\tvc_cons[i].d->vc_font.height = v.v_clin;",
                "\t\t\tvc_cons[i].d->vc_resize_user = 1;",
                "\t\t\tvc_resize(vc_cons[i].d, v.v_cols, v.v_rows);"
            ]
        },
        "cwe": [
            "CWE-362",
            "CWE-476"
        ],
        "cve_description": "A race condition in the Linux kernel before 5.5.7 involving VT_RESIZEX could lead to a NULL pointer dereference and general protection fault.",
        "id": 2767
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static struct btrfs_device *btrfs_find_device_by_path(\n\t\tstruct btrfs_fs_info *fs_info, const char *device_path)\n{\n\tint ret = 0;\n\tstruct btrfs_super_block *disk_super;\n\tu64 devid;\n\tu8 *dev_uuid;\n\tstruct block_device *bdev;\n\tstruct buffer_head *bh;\n\tstruct btrfs_device *device;\n\n\tret = btrfs_get_bdev_and_sb(device_path, FMODE_READ,\n\t\t\t\t    fs_info->bdev_holder, 0, &bdev, &bh);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tdisk_super = (struct btrfs_super_block *)bh->b_data;\n\tdevid = btrfs_stack_device_id(&disk_super->dev_item);\n\tdev_uuid = disk_super->dev_item.uuid;\n\tif (btrfs_fs_incompat(fs_info, METADATA_UUID))\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   disk_super->metadata_uuid);\n\telse\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   disk_super->fsid);\n\n\tbrelse(bh);\n\tif (!device)\n\t\tdevice = ERR_PTR(-ENOENT);\n\tblkdev_put(bdev, FMODE_READ);\n\treturn device;\n}",
        "code_after_change": "static struct btrfs_device *btrfs_find_device_by_path(\n\t\tstruct btrfs_fs_info *fs_info, const char *device_path)\n{\n\tint ret = 0;\n\tstruct btrfs_super_block *disk_super;\n\tu64 devid;\n\tu8 *dev_uuid;\n\tstruct block_device *bdev;\n\tstruct buffer_head *bh;\n\tstruct btrfs_device *device;\n\n\tret = btrfs_get_bdev_and_sb(device_path, FMODE_READ,\n\t\t\t\t    fs_info->bdev_holder, 0, &bdev, &bh);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tdisk_super = (struct btrfs_super_block *)bh->b_data;\n\tdevid = btrfs_stack_device_id(&disk_super->dev_item);\n\tdev_uuid = disk_super->dev_item.uuid;\n\tif (btrfs_fs_incompat(fs_info, METADATA_UUID))\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   disk_super->metadata_uuid, true);\n\telse\n\t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n\t\t\t\t\t   disk_super->fsid, true);\n\n\tbrelse(bh);\n\tif (!device)\n\t\tdevice = ERR_PTR(-ENOENT);\n\tblkdev_put(bdev, FMODE_READ);\n\treturn device;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,10 +18,10 @@\n \tdev_uuid = disk_super->dev_item.uuid;\n \tif (btrfs_fs_incompat(fs_info, METADATA_UUID))\n \t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n-\t\t\t\t\t   disk_super->metadata_uuid);\n+\t\t\t\t\t   disk_super->metadata_uuid, true);\n \telse\n \t\tdevice = btrfs_find_device(fs_info->fs_devices, devid, dev_uuid,\n-\t\t\t\t\t   disk_super->fsid);\n+\t\t\t\t\t   disk_super->fsid, true);\n \n \tbrelse(bh);\n \tif (!device)",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t   disk_super->metadata_uuid, true);",
                "\t\t\t\t\t   disk_super->fsid, true);"
            ],
            "deleted": [
                "\t\t\t\t\t   disk_super->metadata_uuid);",
                "\t\t\t\t\t   disk_super->fsid);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2114
    },
    {
        "cve_id": "CVE-2020-14356",
        "code_before_change": "void cgroup_sk_free(struct sock_cgroup_data *skcd)\n{\n\tstruct cgroup *cgrp = sock_cgroup_ptr(skcd);\n\n\tcgroup_bpf_put(cgrp);\n\tcgroup_put(cgrp);\n}",
        "code_after_change": "void cgroup_sk_free(struct sock_cgroup_data *skcd)\n{\n\tstruct cgroup *cgrp = sock_cgroup_ptr(skcd);\n\n\tif (skcd->no_refcnt)\n\t\treturn;\n\tcgroup_bpf_put(cgrp);\n\tcgroup_put(cgrp);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,8 @@\n {\n \tstruct cgroup *cgrp = sock_cgroup_ptr(skcd);\n \n+\tif (skcd->no_refcnt)\n+\t\treturn;\n \tcgroup_bpf_put(cgrp);\n \tcgroup_put(cgrp);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (skcd->no_refcnt)",
                "\t\treturn;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw null pointer dereference in the Linux kernel cgroupv2 subsystem in versions before 5.7.10 was found in the way when reboot the system. A local user could use this flaw to crash the system or escalate their privileges on the system.",
        "id": 2516
    },
    {
        "cve_id": "CVE-2019-10207",
        "code_before_change": "static int bcm_open(struct hci_uart *hu)\n{\n\tstruct bcm_data *bcm;\n\tstruct list_head *p;\n\tint err;\n\n\tbt_dev_dbg(hu->hdev, \"hu %p\", hu);\n\n\tbcm = kzalloc(sizeof(*bcm), GFP_KERNEL);\n\tif (!bcm)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&bcm->txq);\n\n\thu->priv = bcm;\n\n\tmutex_lock(&bcm_device_lock);\n\n\tif (hu->serdev) {\n\t\tbcm->dev = serdev_device_get_drvdata(hu->serdev);\n\t\tgoto out;\n\t}\n\n\tif (!hu->tty->dev)\n\t\tgoto out;\n\n\tlist_for_each(p, &bcm_device_list) {\n\t\tstruct bcm_device *dev = list_entry(p, struct bcm_device, list);\n\n\t\t/* Retrieve saved bcm_device based on parent of the\n\t\t * platform device (saved during device probe) and\n\t\t * parent of tty device used by hci_uart\n\t\t */\n\t\tif (hu->tty->dev->parent == dev->dev->parent) {\n\t\t\tbcm->dev = dev;\n#ifdef CONFIG_PM\n\t\t\tdev->hu = hu;\n#endif\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tif (bcm->dev) {\n\t\thu->init_speed = bcm->dev->init_speed;\n\t\thu->oper_speed = bcm->dev->oper_speed;\n\t\terr = bcm_gpio_set_power(bcm->dev, true);\n\t\tif (err)\n\t\t\tgoto err_unset_hu;\n\t}\n\n\tmutex_unlock(&bcm_device_lock);\n\treturn 0;\n\nerr_unset_hu:\n#ifdef CONFIG_PM\n\tif (!hu->serdev)\n\t\tbcm->dev->hu = NULL;\n#endif\n\tmutex_unlock(&bcm_device_lock);\n\thu->priv = NULL;\n\tkfree(bcm);\n\treturn err;\n}",
        "code_after_change": "static int bcm_open(struct hci_uart *hu)\n{\n\tstruct bcm_data *bcm;\n\tstruct list_head *p;\n\tint err;\n\n\tbt_dev_dbg(hu->hdev, \"hu %p\", hu);\n\n\tif (!hci_uart_has_flow_control(hu))\n\t\treturn -EOPNOTSUPP;\n\n\tbcm = kzalloc(sizeof(*bcm), GFP_KERNEL);\n\tif (!bcm)\n\t\treturn -ENOMEM;\n\n\tskb_queue_head_init(&bcm->txq);\n\n\thu->priv = bcm;\n\n\tmutex_lock(&bcm_device_lock);\n\n\tif (hu->serdev) {\n\t\tbcm->dev = serdev_device_get_drvdata(hu->serdev);\n\t\tgoto out;\n\t}\n\n\tif (!hu->tty->dev)\n\t\tgoto out;\n\n\tlist_for_each(p, &bcm_device_list) {\n\t\tstruct bcm_device *dev = list_entry(p, struct bcm_device, list);\n\n\t\t/* Retrieve saved bcm_device based on parent of the\n\t\t * platform device (saved during device probe) and\n\t\t * parent of tty device used by hci_uart\n\t\t */\n\t\tif (hu->tty->dev->parent == dev->dev->parent) {\n\t\t\tbcm->dev = dev;\n#ifdef CONFIG_PM\n\t\t\tdev->hu = hu;\n#endif\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\tif (bcm->dev) {\n\t\thu->init_speed = bcm->dev->init_speed;\n\t\thu->oper_speed = bcm->dev->oper_speed;\n\t\terr = bcm_gpio_set_power(bcm->dev, true);\n\t\tif (err)\n\t\t\tgoto err_unset_hu;\n\t}\n\n\tmutex_unlock(&bcm_device_lock);\n\treturn 0;\n\nerr_unset_hu:\n#ifdef CONFIG_PM\n\tif (!hu->serdev)\n\t\tbcm->dev->hu = NULL;\n#endif\n\tmutex_unlock(&bcm_device_lock);\n\thu->priv = NULL;\n\tkfree(bcm);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,6 +5,9 @@\n \tint err;\n \n \tbt_dev_dbg(hu->hdev, \"hu %p\", hu);\n+\n+\tif (!hci_uart_has_flow_control(hu))\n+\t\treturn -EOPNOTSUPP;\n \n \tbcm = kzalloc(sizeof(*bcm), GFP_KERNEL);\n \tif (!bcm)",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!hci_uart_has_flow_control(hu))",
                "\t\treturn -EOPNOTSUPP;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw was found in the Linux kernel's Bluetooth implementation of UART, all versions kernel 3.x.x before 4.18.0 and kernel 5.x.x. An attacker with local access and write permissions to the Bluetooth hardware could use this flaw to issue a specially crafted ioctl function call and cause the system to crash.",
        "id": 1897
    },
    {
        "cve_id": "CVE-2017-8106",
        "code_before_change": "static __init void nested_vmx_setup_ctls_msrs(void)\n{\n\t/*\n\t * Note that as a general rule, the high half of the MSRs (bits in\n\t * the control fields which may be 1) should be initialized by the\n\t * intersection of the underlying hardware's MSR (i.e., features which\n\t * can be supported) and the list of features we want to expose -\n\t * because they are known to be properly supported in our code.\n\t * Also, usually, the low half of the MSRs (bits which must be 1) can\n\t * be set to 0, meaning that L1 may turn off any of these bits. The\n\t * reason is that if one of these bits is necessary, it will appear\n\t * in vmcs01 and prepare_vmcs02, when it bitwise-or's the control\n\t * fields of vmcs01 and vmcs02, will turn these bits off - and\n\t * nested_vmx_exit_handled() will not pass related exits to L1.\n\t * These rules have exceptions below.\n\t */\n\n\t/* pin-based controls */\n\trdmsr(MSR_IA32_VMX_PINBASED_CTLS,\n\t      nested_vmx_pinbased_ctls_low, nested_vmx_pinbased_ctls_high);\n\t/*\n\t * According to the Intel spec, if bit 55 of VMX_BASIC is off (as it is\n\t * in our case), bits 1, 2 and 4 (i.e., 0x16) must be 1 in this MSR.\n\t */\n\tnested_vmx_pinbased_ctls_low |= PIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\tnested_vmx_pinbased_ctls_high &= PIN_BASED_EXT_INTR_MASK |\n\t\tPIN_BASED_NMI_EXITING | PIN_BASED_VIRTUAL_NMIS;\n\tnested_vmx_pinbased_ctls_high |= PIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tPIN_BASED_VMX_PREEMPTION_TIMER;\n\n\t/*\n\t * Exit controls\n\t * If bit 55 of VMX_BASIC is off, bits 0-8 and 10, 11, 13, 14, 16 and\n\t * 17 must be 1.\n\t */\n\trdmsr(MSR_IA32_VMX_EXIT_CTLS,\n\t\tnested_vmx_exit_ctls_low, nested_vmx_exit_ctls_high);\n\tnested_vmx_exit_ctls_low = VM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR;\n\t/* Note that guest use of VM_EXIT_ACK_INTR_ON_EXIT is not supported. */\n\tnested_vmx_exit_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_EXIT_HOST_ADDR_SPACE_SIZE |\n#endif\n\t\tVM_EXIT_LOAD_IA32_PAT | VM_EXIT_SAVE_IA32_PAT;\n\tnested_vmx_exit_ctls_high |= VM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tVM_EXIT_LOAD_IA32_EFER | VM_EXIT_SAVE_IA32_EFER |\n\t\tVM_EXIT_SAVE_VMX_PREEMPTION_TIMER;\n\tif (vmx_mpx_supported())\n\t\tnested_vmx_exit_ctls_high |= VM_EXIT_CLEAR_BNDCFGS;\n\n\t/* entry controls */\n\trdmsr(MSR_IA32_VMX_ENTRY_CTLS,\n\t\tnested_vmx_entry_ctls_low, nested_vmx_entry_ctls_high);\n\t/* If bit 55 of VMX_BASIC is off, bits 0-8 and 12 must be 1. */\n\tnested_vmx_entry_ctls_low = VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR;\n\tnested_vmx_entry_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_ENTRY_IA32E_MODE |\n#endif\n\t\tVM_ENTRY_LOAD_IA32_PAT;\n\tnested_vmx_entry_ctls_high |= (VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\t\t\t       VM_ENTRY_LOAD_IA32_EFER);\n\tif (vmx_mpx_supported())\n\t\tnested_vmx_entry_ctls_high |= VM_ENTRY_LOAD_BNDCFGS;\n\n\t/* cpu-based controls */\n\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS,\n\t\tnested_vmx_procbased_ctls_low, nested_vmx_procbased_ctls_high);\n\tnested_vmx_procbased_ctls_low = 0;\n\tnested_vmx_procbased_ctls_high &=\n\t\tCPU_BASED_VIRTUAL_INTR_PENDING |\n\t\tCPU_BASED_VIRTUAL_NMI_PENDING | CPU_BASED_USE_TSC_OFFSETING |\n\t\tCPU_BASED_HLT_EXITING | CPU_BASED_INVLPG_EXITING |\n\t\tCPU_BASED_MWAIT_EXITING | CPU_BASED_CR3_LOAD_EXITING |\n\t\tCPU_BASED_CR3_STORE_EXITING |\n#ifdef CONFIG_X86_64\n\t\tCPU_BASED_CR8_LOAD_EXITING | CPU_BASED_CR8_STORE_EXITING |\n#endif\n\t\tCPU_BASED_MOV_DR_EXITING | CPU_BASED_UNCOND_IO_EXITING |\n\t\tCPU_BASED_USE_IO_BITMAPS | CPU_BASED_MONITOR_EXITING |\n\t\tCPU_BASED_RDPMC_EXITING | CPU_BASED_RDTSC_EXITING |\n\t\tCPU_BASED_PAUSE_EXITING |\n\t\tCPU_BASED_ACTIVATE_SECONDARY_CONTROLS;\n\t/*\n\t * We can allow some features even when not supported by the\n\t * hardware. For example, L1 can specify an MSR bitmap - and we\n\t * can use it to avoid exits to L1 - even when L0 runs L2\n\t * without MSR bitmaps.\n\t */\n\tnested_vmx_procbased_ctls_high |= CPU_BASED_USE_MSR_BITMAPS;\n\n\t/* secondary cpu-based controls */\n\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS2,\n\t\tnested_vmx_secondary_ctls_low, nested_vmx_secondary_ctls_high);\n\tnested_vmx_secondary_ctls_low = 0;\n\tnested_vmx_secondary_ctls_high &=\n\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\tSECONDARY_EXEC_UNRESTRICTED_GUEST |\n\t\tSECONDARY_EXEC_WBINVD_EXITING;\n\n\tif (enable_ept) {\n\t\t/* nested EPT: emulate EPT also to L1 */\n\t\tnested_vmx_secondary_ctls_high |= SECONDARY_EXEC_ENABLE_EPT;\n\t\tnested_vmx_ept_caps = VMX_EPT_PAGE_WALK_4_BIT |\n\t\t\t VMX_EPTP_WB_BIT | VMX_EPT_2MB_PAGE_BIT |\n\t\t\t VMX_EPT_INVEPT_BIT;\n\t\tnested_vmx_ept_caps &= vmx_capability.ept;\n\t\t/*\n\t\t * Since invept is completely emulated we support both global\n\t\t * and context invalidation independent of what host cpu\n\t\t * supports\n\t\t */\n\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT |\n\t\t\tVMX_EPT_EXTENT_CONTEXT_BIT;\n\t} else\n\t\tnested_vmx_ept_caps = 0;\n\n\t/* miscellaneous data */\n\trdmsr(MSR_IA32_VMX_MISC, nested_vmx_misc_low, nested_vmx_misc_high);\n\tnested_vmx_misc_low &= VMX_MISC_SAVE_EFER_LMA;\n\tnested_vmx_misc_low |= VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE |\n\t\tVMX_MISC_ACTIVITY_HLT;\n\tnested_vmx_misc_high = 0;\n}",
        "code_after_change": "static __init void nested_vmx_setup_ctls_msrs(void)\n{\n\t/*\n\t * Note that as a general rule, the high half of the MSRs (bits in\n\t * the control fields which may be 1) should be initialized by the\n\t * intersection of the underlying hardware's MSR (i.e., features which\n\t * can be supported) and the list of features we want to expose -\n\t * because they are known to be properly supported in our code.\n\t * Also, usually, the low half of the MSRs (bits which must be 1) can\n\t * be set to 0, meaning that L1 may turn off any of these bits. The\n\t * reason is that if one of these bits is necessary, it will appear\n\t * in vmcs01 and prepare_vmcs02, when it bitwise-or's the control\n\t * fields of vmcs01 and vmcs02, will turn these bits off - and\n\t * nested_vmx_exit_handled() will not pass related exits to L1.\n\t * These rules have exceptions below.\n\t */\n\n\t/* pin-based controls */\n\trdmsr(MSR_IA32_VMX_PINBASED_CTLS,\n\t      nested_vmx_pinbased_ctls_low, nested_vmx_pinbased_ctls_high);\n\t/*\n\t * According to the Intel spec, if bit 55 of VMX_BASIC is off (as it is\n\t * in our case), bits 1, 2 and 4 (i.e., 0x16) must be 1 in this MSR.\n\t */\n\tnested_vmx_pinbased_ctls_low |= PIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR;\n\tnested_vmx_pinbased_ctls_high &= PIN_BASED_EXT_INTR_MASK |\n\t\tPIN_BASED_NMI_EXITING | PIN_BASED_VIRTUAL_NMIS;\n\tnested_vmx_pinbased_ctls_high |= PIN_BASED_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tPIN_BASED_VMX_PREEMPTION_TIMER;\n\n\t/*\n\t * Exit controls\n\t * If bit 55 of VMX_BASIC is off, bits 0-8 and 10, 11, 13, 14, 16 and\n\t * 17 must be 1.\n\t */\n\trdmsr(MSR_IA32_VMX_EXIT_CTLS,\n\t\tnested_vmx_exit_ctls_low, nested_vmx_exit_ctls_high);\n\tnested_vmx_exit_ctls_low = VM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR;\n\t/* Note that guest use of VM_EXIT_ACK_INTR_ON_EXIT is not supported. */\n\tnested_vmx_exit_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_EXIT_HOST_ADDR_SPACE_SIZE |\n#endif\n\t\tVM_EXIT_LOAD_IA32_PAT | VM_EXIT_SAVE_IA32_PAT;\n\tnested_vmx_exit_ctls_high |= VM_EXIT_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\tVM_EXIT_LOAD_IA32_EFER | VM_EXIT_SAVE_IA32_EFER |\n\t\tVM_EXIT_SAVE_VMX_PREEMPTION_TIMER;\n\tif (vmx_mpx_supported())\n\t\tnested_vmx_exit_ctls_high |= VM_EXIT_CLEAR_BNDCFGS;\n\n\t/* entry controls */\n\trdmsr(MSR_IA32_VMX_ENTRY_CTLS,\n\t\tnested_vmx_entry_ctls_low, nested_vmx_entry_ctls_high);\n\t/* If bit 55 of VMX_BASIC is off, bits 0-8 and 12 must be 1. */\n\tnested_vmx_entry_ctls_low = VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR;\n\tnested_vmx_entry_ctls_high &=\n#ifdef CONFIG_X86_64\n\t\tVM_ENTRY_IA32E_MODE |\n#endif\n\t\tVM_ENTRY_LOAD_IA32_PAT;\n\tnested_vmx_entry_ctls_high |= (VM_ENTRY_ALWAYSON_WITHOUT_TRUE_MSR |\n\t\t\t\t       VM_ENTRY_LOAD_IA32_EFER);\n\tif (vmx_mpx_supported())\n\t\tnested_vmx_entry_ctls_high |= VM_ENTRY_LOAD_BNDCFGS;\n\n\t/* cpu-based controls */\n\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS,\n\t\tnested_vmx_procbased_ctls_low, nested_vmx_procbased_ctls_high);\n\tnested_vmx_procbased_ctls_low = 0;\n\tnested_vmx_procbased_ctls_high &=\n\t\tCPU_BASED_VIRTUAL_INTR_PENDING |\n\t\tCPU_BASED_VIRTUAL_NMI_PENDING | CPU_BASED_USE_TSC_OFFSETING |\n\t\tCPU_BASED_HLT_EXITING | CPU_BASED_INVLPG_EXITING |\n\t\tCPU_BASED_MWAIT_EXITING | CPU_BASED_CR3_LOAD_EXITING |\n\t\tCPU_BASED_CR3_STORE_EXITING |\n#ifdef CONFIG_X86_64\n\t\tCPU_BASED_CR8_LOAD_EXITING | CPU_BASED_CR8_STORE_EXITING |\n#endif\n\t\tCPU_BASED_MOV_DR_EXITING | CPU_BASED_UNCOND_IO_EXITING |\n\t\tCPU_BASED_USE_IO_BITMAPS | CPU_BASED_MONITOR_EXITING |\n\t\tCPU_BASED_RDPMC_EXITING | CPU_BASED_RDTSC_EXITING |\n\t\tCPU_BASED_PAUSE_EXITING |\n\t\tCPU_BASED_ACTIVATE_SECONDARY_CONTROLS;\n\t/*\n\t * We can allow some features even when not supported by the\n\t * hardware. For example, L1 can specify an MSR bitmap - and we\n\t * can use it to avoid exits to L1 - even when L0 runs L2\n\t * without MSR bitmaps.\n\t */\n\tnested_vmx_procbased_ctls_high |= CPU_BASED_USE_MSR_BITMAPS;\n\n\t/* secondary cpu-based controls */\n\trdmsr(MSR_IA32_VMX_PROCBASED_CTLS2,\n\t\tnested_vmx_secondary_ctls_low, nested_vmx_secondary_ctls_high);\n\tnested_vmx_secondary_ctls_low = 0;\n\tnested_vmx_secondary_ctls_high &=\n\t\tSECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |\n\t\tSECONDARY_EXEC_UNRESTRICTED_GUEST |\n\t\tSECONDARY_EXEC_WBINVD_EXITING;\n\n\tif (enable_ept) {\n\t\t/* nested EPT: emulate EPT also to L1 */\n\t\tnested_vmx_secondary_ctls_high |= SECONDARY_EXEC_ENABLE_EPT;\n\t\tnested_vmx_ept_caps = VMX_EPT_PAGE_WALK_4_BIT |\n\t\t\t VMX_EPTP_WB_BIT | VMX_EPT_2MB_PAGE_BIT |\n\t\t\t VMX_EPT_INVEPT_BIT;\n\t\tnested_vmx_ept_caps &= vmx_capability.ept;\n\t\t/*\n\t\t * For nested guests, we don't do anything specific\n\t\t * for single context invalidation. Hence, only advertise\n\t\t * support for global context invalidation.\n\t\t */\n\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT;\n\t} else\n\t\tnested_vmx_ept_caps = 0;\n\n\t/* miscellaneous data */\n\trdmsr(MSR_IA32_VMX_MISC, nested_vmx_misc_low, nested_vmx_misc_high);\n\tnested_vmx_misc_low &= VMX_MISC_SAVE_EFER_LMA;\n\tnested_vmx_misc_low |= VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE |\n\t\tVMX_MISC_ACTIVITY_HLT;\n\tnested_vmx_misc_high = 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -106,12 +106,11 @@\n \t\t\t VMX_EPT_INVEPT_BIT;\n \t\tnested_vmx_ept_caps &= vmx_capability.ept;\n \t\t/*\n-\t\t * Since invept is completely emulated we support both global\n-\t\t * and context invalidation independent of what host cpu\n-\t\t * supports\n+\t\t * For nested guests, we don't do anything specific\n+\t\t * for single context invalidation. Hence, only advertise\n+\t\t * support for global context invalidation.\n \t\t */\n-\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT |\n-\t\t\tVMX_EPT_EXTENT_CONTEXT_BIT;\n+\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT;\n \t} else\n \t\tnested_vmx_ept_caps = 0;\n ",
        "function_modified_lines": {
            "added": [
                "\t\t * For nested guests, we don't do anything specific",
                "\t\t * for single context invalidation. Hence, only advertise",
                "\t\t * support for global context invalidation.",
                "\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT;"
            ],
            "deleted": [
                "\t\t * Since invept is completely emulated we support both global",
                "\t\t * and context invalidation independent of what host cpu",
                "\t\t * supports",
                "\t\tnested_vmx_ept_caps |= VMX_EPT_EXTENT_GLOBAL_BIT |",
                "\t\t\tVMX_EPT_EXTENT_CONTEXT_BIT;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The handle_invept function in arch/x86/kvm/vmx.c in the Linux kernel 3.12 through 3.15 allows privileged KVM guest OS users to cause a denial of service (NULL pointer dereference and host OS crash) via a single-context INVEPT instruction with a NULL EPT pointer.",
        "id": 1550
    },
    {
        "cve_id": "CVE-2020-14356",
        "code_before_change": "static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)\n{\n#if defined(CONFIG_CGROUP_NET_PRIO) || defined(CONFIG_CGROUP_NET_CLASSID)\n\tunsigned long v;\n\n\t/*\n\t * @skcd->val is 64bit but the following is safe on 32bit too as we\n\t * just need the lower ulong to be written and read atomically.\n\t */\n\tv = READ_ONCE(skcd->val);\n\n\tif (v & 1)\n\t\treturn &cgrp_dfl_root.cgrp;\n\n\treturn (struct cgroup *)(unsigned long)v ?: &cgrp_dfl_root.cgrp;\n#else\n\treturn (struct cgroup *)(unsigned long)skcd->val;\n#endif\n}",
        "code_after_change": "static inline struct cgroup *sock_cgroup_ptr(struct sock_cgroup_data *skcd)\n{\n#if defined(CONFIG_CGROUP_NET_PRIO) || defined(CONFIG_CGROUP_NET_CLASSID)\n\tunsigned long v;\n\n\t/*\n\t * @skcd->val is 64bit but the following is safe on 32bit too as we\n\t * just need the lower ulong to be written and read atomically.\n\t */\n\tv = READ_ONCE(skcd->val);\n\n\tif (v & 3)\n\t\treturn &cgrp_dfl_root.cgrp;\n\n\treturn (struct cgroup *)(unsigned long)v ?: &cgrp_dfl_root.cgrp;\n#else\n\treturn (struct cgroup *)(unsigned long)skcd->val;\n#endif\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,7 @@\n \t */\n \tv = READ_ONCE(skcd->val);\n \n-\tif (v & 1)\n+\tif (v & 3)\n \t\treturn &cgrp_dfl_root.cgrp;\n \n \treturn (struct cgroup *)(unsigned long)v ?: &cgrp_dfl_root.cgrp;",
        "function_modified_lines": {
            "added": [
                "\tif (v & 3)"
            ],
            "deleted": [
                "\tif (v & 1)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw null pointer dereference in the Linux kernel cgroupv2 subsystem in versions before 5.7.10 was found in the way when reboot the system. A local user could use this flaw to crash the system or escalate their privileges on the system.",
        "id": 2515
    },
    {
        "cve_id": "CVE-2014-7826",
        "code_before_change": "static void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "code_after_change": "static void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n \t\treturn;",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the ftrace subsystem, which allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via a crafted application.",
        "id": 594
    },
    {
        "cve_id": "CVE-2017-15116",
        "code_before_change": "int crypto_rng_reset(struct crypto_rng *tfm, const u8 *seed, unsigned int slen)\n{\n\tu8 *buf = NULL;\n\tint err;\n\n\tif (!seed && slen) {\n\t\tbuf = kmalloc(slen, GFP_KERNEL);\n\t\tif (!buf)\n\t\t\treturn -ENOMEM;\n\n\t\tget_random_bytes(buf, slen);\n\t\tseed = buf;\n\t}\n\n\terr = tfm->seed(tfm, seed, slen);\n\n\tkfree(buf);\n\treturn err;\n}",
        "code_after_change": "int crypto_rng_reset(struct crypto_rng *tfm, const u8 *seed, unsigned int slen)\n{\n\tu8 *buf = NULL;\n\tint err;\n\n\tif (!seed && slen) {\n\t\tbuf = kmalloc(slen, GFP_KERNEL);\n\t\tif (!buf)\n\t\t\treturn -ENOMEM;\n\n\t\tget_random_bytes(buf, slen);\n\t\tseed = buf;\n\t}\n\n\terr = crypto_rng_alg(tfm)->seed(tfm, seed, slen);\n\n\tkfree(buf);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,7 +12,7 @@\n \t\tseed = buf;\n \t}\n \n-\terr = tfm->seed(tfm, seed, slen);\n+\terr = crypto_rng_alg(tfm)->seed(tfm, seed, slen);\n \n \tkfree(buf);\n \treturn err;",
        "function_modified_lines": {
            "added": [
                "\terr = crypto_rng_alg(tfm)->seed(tfm, seed, slen);"
            ],
            "deleted": [
                "\terr = tfm->seed(tfm, seed, slen);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The rngapi_reset function in crypto/rng.c in the Linux kernel before 4.2 allows attackers to cause a denial of service (NULL pointer dereference).",
        "id": 1290
    },
    {
        "cve_id": "CVE-2021-38200",
        "code_before_change": "unsigned long perf_instruction_pointer(struct pt_regs *regs)\n{\n\tbool use_siar = regs_use_siar(regs);\n\tunsigned long siar = mfspr(SPRN_SIAR);\n\n\tif (ppmu->flags & PPMU_P10_DD1) {\n\t\tif (siar)\n\t\t\treturn siar;\n\t\telse\n\t\t\treturn regs->nip;\n\t} else if (use_siar && siar_valid(regs))\n\t\treturn mfspr(SPRN_SIAR) + perf_ip_adjust(regs);\n\telse if (use_siar)\n\t\treturn 0;\t\t// no valid instruction pointer\n\telse\n\t\treturn regs->nip;\n}",
        "code_after_change": "unsigned long perf_instruction_pointer(struct pt_regs *regs)\n{\n\tbool use_siar = regs_use_siar(regs);\n\tunsigned long siar = mfspr(SPRN_SIAR);\n\n\tif (ppmu && (ppmu->flags & PPMU_P10_DD1)) {\n\t\tif (siar)\n\t\t\treturn siar;\n\t\telse\n\t\t\treturn regs->nip;\n\t} else if (use_siar && siar_valid(regs))\n\t\treturn mfspr(SPRN_SIAR) + perf_ip_adjust(regs);\n\telse if (use_siar)\n\t\treturn 0;\t\t// no valid instruction pointer\n\telse\n\t\treturn regs->nip;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tbool use_siar = regs_use_siar(regs);\n \tunsigned long siar = mfspr(SPRN_SIAR);\n \n-\tif (ppmu->flags & PPMU_P10_DD1) {\n+\tif (ppmu && (ppmu->flags & PPMU_P10_DD1)) {\n \t\tif (siar)\n \t\t\treturn siar;\n \t\telse",
        "function_modified_lines": {
            "added": [
                "\tif (ppmu && (ppmu->flags & PPMU_P10_DD1)) {"
            ],
            "deleted": [
                "\tif (ppmu->flags & PPMU_P10_DD1) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "arch/powerpc/perf/core-book3s.c in the Linux kernel before 5.12.13, on systems with perf_event_paranoid=-1 and no specific PMU driver support registered, allows local users to cause a denial of service (perf_instruction_pointer NULL pointer dereference and OOPS) via a \"perf record\" command.",
        "id": 3074
    },
    {
        "cve_id": "CVE-2023-3358",
        "code_before_change": "void ishtp_cl_release_dma_acked_mem(struct ishtp_device *dev,\n\t\t\t\t    void *msg_addr,\n\t\t\t\t    uint8_t size)\n{\n\tunsigned long\tflags;\n\tint acked_slots = (size / DMA_SLOT_SIZE)\n\t\t+ 1 * (size % DMA_SLOT_SIZE != 0);\n\tint i, j;\n\n\tif ((msg_addr - dev->ishtp_host_dma_tx_buf) % DMA_SLOT_SIZE) {\n\t\tdev_err(dev->devc, \"Bad DMA Tx ack address\\n\");\n\t\treturn;\n\t}\n\n\ti = (msg_addr - dev->ishtp_host_dma_tx_buf) / DMA_SLOT_SIZE;\n\tspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\n\tfor (j = 0; j < acked_slots; j++) {\n\t\tif ((i + j) >= dev->ishtp_dma_num_slots ||\n\t\t\t\t\t!dev->ishtp_dma_tx_map[i+j]) {\n\t\t\t/* no such slot, or memory is already free */\n\t\t\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\t\t\tdev_err(dev->devc, \"Bad DMA Tx ack address\\n\");\n\t\t\treturn;\n\t\t}\n\t\tdev->ishtp_dma_tx_map[i+j] = 0;\n\t}\n\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n}",
        "code_after_change": "void ishtp_cl_release_dma_acked_mem(struct ishtp_device *dev,\n\t\t\t\t    void *msg_addr,\n\t\t\t\t    uint8_t size)\n{\n\tunsigned long\tflags;\n\tint acked_slots = (size / DMA_SLOT_SIZE)\n\t\t+ 1 * (size % DMA_SLOT_SIZE != 0);\n\tint i, j;\n\n\tif ((msg_addr - dev->ishtp_host_dma_tx_buf) % DMA_SLOT_SIZE) {\n\t\tdev_err(dev->devc, \"Bad DMA Tx ack address\\n\");\n\t\treturn;\n\t}\n\n\tif (!dev->ishtp_dma_tx_map) {\n\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");\n\t\treturn;\n\t}\n\n\ti = (msg_addr - dev->ishtp_host_dma_tx_buf) / DMA_SLOT_SIZE;\n\tspin_lock_irqsave(&dev->ishtp_dma_tx_lock, flags);\n\tfor (j = 0; j < acked_slots; j++) {\n\t\tif ((i + j) >= dev->ishtp_dma_num_slots ||\n\t\t\t\t\t!dev->ishtp_dma_tx_map[i+j]) {\n\t\t\t/* no such slot, or memory is already free */\n\t\t\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n\t\t\tdev_err(dev->devc, \"Bad DMA Tx ack address\\n\");\n\t\t\treturn;\n\t\t}\n\t\tdev->ishtp_dma_tx_map[i+j] = 0;\n\t}\n\tspin_unlock_irqrestore(&dev->ishtp_dma_tx_lock, flags);\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,6 +9,11 @@\n \n \tif ((msg_addr - dev->ishtp_host_dma_tx_buf) % DMA_SLOT_SIZE) {\n \t\tdev_err(dev->devc, \"Bad DMA Tx ack address\\n\");\n+\t\treturn;\n+\t}\n+\n+\tif (!dev->ishtp_dma_tx_map) {\n+\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");\n \t\treturn;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\treturn;",
                "\t}",
                "",
                "\tif (!dev->ishtp_dma_tx_map) {",
                "\t\tdev_err(dev->devc, \"Fail to allocate Tx map\\n\");"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A null pointer dereference was found in the Linux kernel's Integrated Sensor Hub (ISH) driver. This issue could allow a local user to crash the system.",
        "id": 4063
    },
    {
        "cve_id": "CVE-2020-10711",
        "code_before_change": "static int calipso_opt_getattr(const unsigned char *calipso,\n\t\t\t       struct netlbl_lsm_secattr *secattr)\n{\n\tint ret_val = -ENOMSG;\n\tu32 doi, len = calipso[1], cat_len = calipso[6] * 4;\n\tstruct calipso_doi *doi_def;\n\n\tif (cat_len + 8 > len)\n\t\treturn -EINVAL;\n\n\tif (calipso_cache_check(calipso + 2, calipso[1], secattr) == 0)\n\t\treturn 0;\n\n\tdoi = get_unaligned_be32(calipso + 2);\n\trcu_read_lock();\n\tdoi_def = calipso_doi_search(doi);\n\tif (!doi_def)\n\t\tgoto getattr_return;\n\n\tsecattr->attr.mls.lvl = calipso[7];\n\tsecattr->flags |= NETLBL_SECATTR_MLS_LVL;\n\n\tif (cat_len) {\n\t\tret_val = calipso_map_cat_ntoh(doi_def,\n\t\t\t\t\t       calipso + 10,\n\t\t\t\t\t       cat_len,\n\t\t\t\t\t       secattr);\n\t\tif (ret_val != 0) {\n\t\t\tnetlbl_catmap_free(secattr->attr.mls.cat);\n\t\t\tgoto getattr_return;\n\t\t}\n\n\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\n\t}\n\n\tsecattr->type = NETLBL_NLTYPE_CALIPSO;\n\ngetattr_return:\n\trcu_read_unlock();\n\treturn ret_val;\n}",
        "code_after_change": "static int calipso_opt_getattr(const unsigned char *calipso,\n\t\t\t       struct netlbl_lsm_secattr *secattr)\n{\n\tint ret_val = -ENOMSG;\n\tu32 doi, len = calipso[1], cat_len = calipso[6] * 4;\n\tstruct calipso_doi *doi_def;\n\n\tif (cat_len + 8 > len)\n\t\treturn -EINVAL;\n\n\tif (calipso_cache_check(calipso + 2, calipso[1], secattr) == 0)\n\t\treturn 0;\n\n\tdoi = get_unaligned_be32(calipso + 2);\n\trcu_read_lock();\n\tdoi_def = calipso_doi_search(doi);\n\tif (!doi_def)\n\t\tgoto getattr_return;\n\n\tsecattr->attr.mls.lvl = calipso[7];\n\tsecattr->flags |= NETLBL_SECATTR_MLS_LVL;\n\n\tif (cat_len) {\n\t\tret_val = calipso_map_cat_ntoh(doi_def,\n\t\t\t\t\t       calipso + 10,\n\t\t\t\t\t       cat_len,\n\t\t\t\t\t       secattr);\n\t\tif (ret_val != 0) {\n\t\t\tnetlbl_catmap_free(secattr->attr.mls.cat);\n\t\t\tgoto getattr_return;\n\t\t}\n\n\t\tif (secattr->attr.mls.cat)\n\t\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\n\t}\n\n\tsecattr->type = NETLBL_NLTYPE_CALIPSO;\n\ngetattr_return:\n\trcu_read_unlock();\n\treturn ret_val;\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,7 +30,8 @@\n \t\t\tgoto getattr_return;\n \t\t}\n \n-\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\n+\t\tif (secattr->attr.mls.cat)\n+\t\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;\n \t}\n \n \tsecattr->type = NETLBL_NLTYPE_CALIPSO;",
        "function_modified_lines": {
            "added": [
                "\t\tif (secattr->attr.mls.cat)",
                "\t\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;"
            ],
            "deleted": [
                "\t\tsecattr->flags |= NETLBL_SECATTR_MLS_CAT;"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in the Linux kernel's SELinux subsystem in versions before 5.7. This flaw occurs while importing the Commercial IP Security Option (CIPSO) protocol's category bitmap into the SELinux extensible bitmap via the' ebitmap_netlbl_import' routine. While processing the CIPSO restricted bitmap tag in the 'cipso_v4_parsetag_rbm' routine, it sets the security attribute to indicate that the category bitmap is present, even if it has not been allocated. This issue leads to a NULL pointer dereference issue while importing the same category bitmap into SELinux. This flaw allows a remote network user to crash the system kernel, resulting in a denial of service.",
        "id": 2405
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int stk7700d_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\t\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 2, 18,\n\t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n\t\t    != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\t\tdvb_detach(&state->dib7000p_ops);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t   0x80 + (adap->id << 1),\n\t\t\t   &stk7700d_dib7000p_mt2266_config[adap->id]);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int stk7700d_frontend_attach(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tif (adap->id == 0) {\n\t\tdib0700_set_gpio(adap->dev, GPIO6, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO9, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO4, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO7, GPIO_OUT, 1);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 0);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO10, GPIO_OUT, 1);\n\t\tmsleep(10);\n\t\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\t\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 2, 18,\n\t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n\t\t    != 0) {\n\t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\t\treturn -ENODEV;\n\t\t}\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap,\n\t\t\t   0x80 + (adap->id << 1),\n\t\t\t   &stk7700d_dib7000p_mt2266_config[adap->id]);\n\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,7 +20,7 @@\n \t\t\t\t\t     stk7700d_dib7000p_mt2266_config)\n \t\t    != 0) {\n \t\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\", __func__);\n-\t\t\tdvb_detach(&state->dib7000p_ops);\n+\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\t\treturn -ENODEV;\n \t\t}\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1328
    },
    {
        "cve_id": "CVE-2023-23002",
        "code_before_change": "static int qca_serdev_probe(struct serdev_device *serdev)\n{\n\tstruct qca_serdev *qcadev;\n\tstruct hci_dev *hdev;\n\tconst struct qca_device_data *data;\n\tint err;\n\tbool power_ctrl_enabled = true;\n\n\tqcadev = devm_kzalloc(&serdev->dev, sizeof(*qcadev), GFP_KERNEL);\n\tif (!qcadev)\n\t\treturn -ENOMEM;\n\n\tqcadev->serdev_hu.serdev = serdev;\n\tdata = device_get_match_data(&serdev->dev);\n\tserdev_device_set_drvdata(serdev, qcadev);\n\tdevice_property_read_string(&serdev->dev, \"firmware-name\",\n\t\t\t\t\t &qcadev->firmware_name);\n\tdevice_property_read_u32(&serdev->dev, \"max-speed\",\n\t\t\t\t &qcadev->oper_speed);\n\tif (!qcadev->oper_speed)\n\t\tBT_DBG(\"UART will pick default operating speed\");\n\n\tif (data &&\n\t    (qca_is_wcn399x(data->soc_type) ||\n\t    qca_is_wcn6750(data->soc_type))) {\n\t\tqcadev->btsoc_type = data->soc_type;\n\t\tqcadev->bt_power = devm_kzalloc(&serdev->dev,\n\t\t\t\t\t\tsizeof(struct qca_power),\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!qcadev->bt_power)\n\t\t\treturn -ENOMEM;\n\n\t\tqcadev->bt_power->dev = &serdev->dev;\n\t\terr = qca_init_regulators(qcadev->bt_power, data->vregs,\n\t\t\t\t\t  data->num_vregs);\n\t\tif (err) {\n\t\t\tBT_ERR(\"Failed to init regulators:%d\", err);\n\t\t\treturn err;\n\t\t}\n\n\t\tqcadev->bt_power->vregs_on = false;\n\n\t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n\t\t\t\t\t       GPIOD_OUT_LOW);\n\t\tif (!qcadev->bt_en && data->soc_type == QCA_WCN6750) {\n\t\t\tdev_err(&serdev->dev, \"failed to acquire BT_EN gpio\\n\");\n\t\t\tpower_ctrl_enabled = false;\n\t\t}\n\n\t\tqcadev->sw_ctrl = devm_gpiod_get_optional(&serdev->dev, \"swctrl\",\n\t\t\t\t\t       GPIOD_IN);\n\t\tif (!qcadev->sw_ctrl && data->soc_type == QCA_WCN6750)\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire SW_CTRL gpio\\n\");\n\n\t\tqcadev->susclk = devm_clk_get_optional(&serdev->dev, NULL);\n\t\tif (IS_ERR(qcadev->susclk)) {\n\t\t\tdev_err(&serdev->dev, \"failed to acquire clk\\n\");\n\t\t\treturn PTR_ERR(qcadev->susclk);\n\t\t}\n\n\t\terr = hci_uart_register_device(&qcadev->serdev_hu, &qca_proto);\n\t\tif (err) {\n\t\t\tBT_ERR(\"wcn3990 serdev registration failed\");\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tif (data)\n\t\t\tqcadev->btsoc_type = data->soc_type;\n\t\telse\n\t\t\tqcadev->btsoc_type = QCA_ROME;\n\n\t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n\t\t\t\t\t       GPIOD_OUT_LOW);\n\t\tif (!qcadev->bt_en) {\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire enable gpio\\n\");\n\t\t\tpower_ctrl_enabled = false;\n\t\t}\n\n\t\tqcadev->susclk = devm_clk_get_optional(&serdev->dev, NULL);\n\t\tif (IS_ERR(qcadev->susclk)) {\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire clk\\n\");\n\t\t\treturn PTR_ERR(qcadev->susclk);\n\t\t}\n\t\terr = clk_set_rate(qcadev->susclk, SUSCLK_RATE_32KHZ);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = clk_prepare_enable(qcadev->susclk);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = hci_uart_register_device(&qcadev->serdev_hu, &qca_proto);\n\t\tif (err) {\n\t\t\tBT_ERR(\"Rome serdev registration failed\");\n\t\t\tclk_disable_unprepare(qcadev->susclk);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\thdev = qcadev->serdev_hu.hdev;\n\n\tif (power_ctrl_enabled) {\n\t\tset_bit(HCI_QUIRK_NON_PERSISTENT_SETUP, &hdev->quirks);\n\t\thdev->shutdown = qca_power_off;\n\t}\n\n\tif (data) {\n\t\t/* Wideband speech support must be set per driver since it can't\n\t\t * be queried via hci. Same with the valid le states quirk.\n\t\t */\n\t\tif (data->capabilities & QCA_CAP_WIDEBAND_SPEECH)\n\t\t\tset_bit(HCI_QUIRK_WIDEBAND_SPEECH_SUPPORTED,\n\t\t\t\t&hdev->quirks);\n\n\t\tif (data->capabilities & QCA_CAP_VALID_LE_STATES)\n\t\t\tset_bit(HCI_QUIRK_VALID_LE_STATES, &hdev->quirks);\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int qca_serdev_probe(struct serdev_device *serdev)\n{\n\tstruct qca_serdev *qcadev;\n\tstruct hci_dev *hdev;\n\tconst struct qca_device_data *data;\n\tint err;\n\tbool power_ctrl_enabled = true;\n\n\tqcadev = devm_kzalloc(&serdev->dev, sizeof(*qcadev), GFP_KERNEL);\n\tif (!qcadev)\n\t\treturn -ENOMEM;\n\n\tqcadev->serdev_hu.serdev = serdev;\n\tdata = device_get_match_data(&serdev->dev);\n\tserdev_device_set_drvdata(serdev, qcadev);\n\tdevice_property_read_string(&serdev->dev, \"firmware-name\",\n\t\t\t\t\t &qcadev->firmware_name);\n\tdevice_property_read_u32(&serdev->dev, \"max-speed\",\n\t\t\t\t &qcadev->oper_speed);\n\tif (!qcadev->oper_speed)\n\t\tBT_DBG(\"UART will pick default operating speed\");\n\n\tif (data &&\n\t    (qca_is_wcn399x(data->soc_type) ||\n\t    qca_is_wcn6750(data->soc_type))) {\n\t\tqcadev->btsoc_type = data->soc_type;\n\t\tqcadev->bt_power = devm_kzalloc(&serdev->dev,\n\t\t\t\t\t\tsizeof(struct qca_power),\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!qcadev->bt_power)\n\t\t\treturn -ENOMEM;\n\n\t\tqcadev->bt_power->dev = &serdev->dev;\n\t\terr = qca_init_regulators(qcadev->bt_power, data->vregs,\n\t\t\t\t\t  data->num_vregs);\n\t\tif (err) {\n\t\t\tBT_ERR(\"Failed to init regulators:%d\", err);\n\t\t\treturn err;\n\t\t}\n\n\t\tqcadev->bt_power->vregs_on = false;\n\n\t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n\t\t\t\t\t       GPIOD_OUT_LOW);\n\t\tif (IS_ERR_OR_NULL(qcadev->bt_en) && data->soc_type == QCA_WCN6750) {\n\t\t\tdev_err(&serdev->dev, \"failed to acquire BT_EN gpio\\n\");\n\t\t\tpower_ctrl_enabled = false;\n\t\t}\n\n\t\tqcadev->sw_ctrl = devm_gpiod_get_optional(&serdev->dev, \"swctrl\",\n\t\t\t\t\t       GPIOD_IN);\n\t\tif (IS_ERR_OR_NULL(qcadev->sw_ctrl) && data->soc_type == QCA_WCN6750)\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire SW_CTRL gpio\\n\");\n\n\t\tqcadev->susclk = devm_clk_get_optional(&serdev->dev, NULL);\n\t\tif (IS_ERR(qcadev->susclk)) {\n\t\t\tdev_err(&serdev->dev, \"failed to acquire clk\\n\");\n\t\t\treturn PTR_ERR(qcadev->susclk);\n\t\t}\n\n\t\terr = hci_uart_register_device(&qcadev->serdev_hu, &qca_proto);\n\t\tif (err) {\n\t\t\tBT_ERR(\"wcn3990 serdev registration failed\");\n\t\t\treturn err;\n\t\t}\n\t} else {\n\t\tif (data)\n\t\t\tqcadev->btsoc_type = data->soc_type;\n\t\telse\n\t\t\tqcadev->btsoc_type = QCA_ROME;\n\n\t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n\t\t\t\t\t       GPIOD_OUT_LOW);\n\t\tif (IS_ERR_OR_NULL(qcadev->bt_en)) {\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire enable gpio\\n\");\n\t\t\tpower_ctrl_enabled = false;\n\t\t}\n\n\t\tqcadev->susclk = devm_clk_get_optional(&serdev->dev, NULL);\n\t\tif (IS_ERR(qcadev->susclk)) {\n\t\t\tdev_warn(&serdev->dev, \"failed to acquire clk\\n\");\n\t\t\treturn PTR_ERR(qcadev->susclk);\n\t\t}\n\t\terr = clk_set_rate(qcadev->susclk, SUSCLK_RATE_32KHZ);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = clk_prepare_enable(qcadev->susclk);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = hci_uart_register_device(&qcadev->serdev_hu, &qca_proto);\n\t\tif (err) {\n\t\t\tBT_ERR(\"Rome serdev registration failed\");\n\t\t\tclk_disable_unprepare(qcadev->susclk);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\thdev = qcadev->serdev_hu.hdev;\n\n\tif (power_ctrl_enabled) {\n\t\tset_bit(HCI_QUIRK_NON_PERSISTENT_SETUP, &hdev->quirks);\n\t\thdev->shutdown = qca_power_off;\n\t}\n\n\tif (data) {\n\t\t/* Wideband speech support must be set per driver since it can't\n\t\t * be queried via hci. Same with the valid le states quirk.\n\t\t */\n\t\tif (data->capabilities & QCA_CAP_WIDEBAND_SPEECH)\n\t\t\tset_bit(HCI_QUIRK_WIDEBAND_SPEECH_SUPPORTED,\n\t\t\t\t&hdev->quirks);\n\n\t\tif (data->capabilities & QCA_CAP_VALID_LE_STATES)\n\t\t\tset_bit(HCI_QUIRK_VALID_LE_STATES, &hdev->quirks);\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -42,14 +42,14 @@\n \n \t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n \t\t\t\t\t       GPIOD_OUT_LOW);\n-\t\tif (!qcadev->bt_en && data->soc_type == QCA_WCN6750) {\n+\t\tif (IS_ERR_OR_NULL(qcadev->bt_en) && data->soc_type == QCA_WCN6750) {\n \t\t\tdev_err(&serdev->dev, \"failed to acquire BT_EN gpio\\n\");\n \t\t\tpower_ctrl_enabled = false;\n \t\t}\n \n \t\tqcadev->sw_ctrl = devm_gpiod_get_optional(&serdev->dev, \"swctrl\",\n \t\t\t\t\t       GPIOD_IN);\n-\t\tif (!qcadev->sw_ctrl && data->soc_type == QCA_WCN6750)\n+\t\tif (IS_ERR_OR_NULL(qcadev->sw_ctrl) && data->soc_type == QCA_WCN6750)\n \t\t\tdev_warn(&serdev->dev, \"failed to acquire SW_CTRL gpio\\n\");\n \n \t\tqcadev->susclk = devm_clk_get_optional(&serdev->dev, NULL);\n@@ -71,7 +71,7 @@\n \n \t\tqcadev->bt_en = devm_gpiod_get_optional(&serdev->dev, \"enable\",\n \t\t\t\t\t       GPIOD_OUT_LOW);\n-\t\tif (!qcadev->bt_en) {\n+\t\tif (IS_ERR_OR_NULL(qcadev->bt_en)) {\n \t\t\tdev_warn(&serdev->dev, \"failed to acquire enable gpio\\n\");\n \t\t\tpower_ctrl_enabled = false;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\tif (IS_ERR_OR_NULL(qcadev->bt_en) && data->soc_type == QCA_WCN6750) {",
                "\t\tif (IS_ERR_OR_NULL(qcadev->sw_ctrl) && data->soc_type == QCA_WCN6750)",
                "\t\tif (IS_ERR_OR_NULL(qcadev->bt_en)) {"
            ],
            "deleted": [
                "\t\tif (!qcadev->bt_en && data->soc_type == QCA_WCN6750) {",
                "\t\tif (!qcadev->sw_ctrl && data->soc_type == QCA_WCN6750)",
                "\t\tif (!qcadev->bt_en) {"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel before 5.16.3, drivers/bluetooth/hci_qca.c misinterprets the devm_gpiod_get_index_optional return value (expects it to be NULL in the error case, whereas it is actually an error pointer).",
        "id": 3945
    },
    {
        "cve_id": "CVE-2017-16647",
        "code_before_change": "static int asix_suspend(struct usb_interface *intf, pm_message_t message)\n{\n\tstruct usbnet *dev = usb_get_intfdata(intf);\n\tstruct asix_common_private *priv = dev->driver_priv;\n\n\tif (priv->suspend)\n\t\tpriv->suspend(dev);\n\n\treturn usbnet_suspend(intf, message);\n}",
        "code_after_change": "static int asix_suspend(struct usb_interface *intf, pm_message_t message)\n{\n\tstruct usbnet *dev = usb_get_intfdata(intf);\n\tstruct asix_common_private *priv = dev->driver_priv;\n\n\tif (priv && priv->suspend)\n\t\tpriv->suspend(dev);\n\n\treturn usbnet_suspend(intf, message);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct usbnet *dev = usb_get_intfdata(intf);\n \tstruct asix_common_private *priv = dev->driver_priv;\n \n-\tif (priv->suspend)\n+\tif (priv && priv->suspend)\n \t\tpriv->suspend(dev);\n \n \treturn usbnet_suspend(intf, message);",
        "function_modified_lines": {
            "added": [
                "\tif (priv && priv->suspend)"
            ],
            "deleted": [
                "\tif (priv->suspend)"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/usb/asix_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1340
    },
    {
        "cve_id": "CVE-2019-19815",
        "code_before_change": "static int f2fs_mpage_readpages(struct address_space *mapping,\n\t\t\tstruct list_head *pages, struct page *page,\n\t\t\tunsigned nr_pages, bool is_readahead)\n{\n\tstruct bio *bio = NULL;\n\tsector_t last_block_in_bio = 0;\n\tstruct inode *inode = mapping->host;\n\tstruct f2fs_map_blocks map;\n\tint ret = 0;\n\n\tmap.m_pblk = 0;\n\tmap.m_lblk = 0;\n\tmap.m_len = 0;\n\tmap.m_flags = 0;\n\tmap.m_next_pgofs = NULL;\n\tmap.m_next_extent = NULL;\n\tmap.m_seg_type = NO_CHECK_TYPE;\n\tmap.m_may_create = false;\n\n\tfor (; nr_pages; nr_pages--) {\n\t\tif (pages) {\n\t\t\tpage = list_last_entry(pages, struct page, lru);\n\n\t\t\tprefetchw(&page->flags);\n\t\t\tlist_del(&page->lru);\n\t\t\tif (add_to_page_cache_lru(page, mapping,\n\t\t\t\t\t\t  page->index,\n\t\t\t\t\t\t  readahead_gfp_mask(mapping)))\n\t\t\t\tgoto next_page;\n\t\t}\n\n\t\tret = f2fs_read_single_page(inode, page, nr_pages, &map, &bio,\n\t\t\t\t\t&last_block_in_bio, is_readahead);\n\t\tif (ret) {\n\t\t\tSetPageError(page);\n\t\t\tzero_user_segment(page, 0, PAGE_SIZE);\n\t\t\tunlock_page(page);\n\t\t}\nnext_page:\n\t\tif (pages)\n\t\t\tput_page(page);\n\t}\n\tBUG_ON(pages && !list_empty(pages));\n\tif (bio)\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\treturn pages ? 0 : ret;\n}",
        "code_after_change": "static int f2fs_mpage_readpages(struct address_space *mapping,\n\t\t\tstruct list_head *pages, struct page *page,\n\t\t\tunsigned nr_pages, bool is_readahead)\n{\n\tstruct bio *bio = NULL;\n\tsector_t last_block_in_bio = 0;\n\tstruct inode *inode = mapping->host;\n\tstruct f2fs_map_blocks map;\n\tint ret = 0;\n\n\tmap.m_pblk = 0;\n\tmap.m_lblk = 0;\n\tmap.m_len = 0;\n\tmap.m_flags = 0;\n\tmap.m_next_pgofs = NULL;\n\tmap.m_next_extent = NULL;\n\tmap.m_seg_type = NO_CHECK_TYPE;\n\tmap.m_may_create = false;\n\n\tfor (; nr_pages; nr_pages--) {\n\t\tif (pages) {\n\t\t\tpage = list_last_entry(pages, struct page, lru);\n\n\t\t\tprefetchw(&page->flags);\n\t\t\tlist_del(&page->lru);\n\t\t\tif (add_to_page_cache_lru(page, mapping,\n\t\t\t\t\t\t  page_index(page),\n\t\t\t\t\t\t  readahead_gfp_mask(mapping)))\n\t\t\t\tgoto next_page;\n\t\t}\n\n\t\tret = f2fs_read_single_page(inode, page, nr_pages, &map, &bio,\n\t\t\t\t\t&last_block_in_bio, is_readahead);\n\t\tif (ret) {\n\t\t\tSetPageError(page);\n\t\t\tzero_user_segment(page, 0, PAGE_SIZE);\n\t\t\tunlock_page(page);\n\t\t}\nnext_page:\n\t\tif (pages)\n\t\t\tput_page(page);\n\t}\n\tBUG_ON(pages && !list_empty(pages));\n\tif (bio)\n\t\t__submit_bio(F2FS_I_SB(inode), bio, DATA);\n\treturn pages ? 0 : ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -24,7 +24,7 @@\n \t\t\tprefetchw(&page->flags);\n \t\t\tlist_del(&page->lru);\n \t\t\tif (add_to_page_cache_lru(page, mapping,\n-\t\t\t\t\t\t  page->index,\n+\t\t\t\t\t\t  page_index(page),\n \t\t\t\t\t\t  readahead_gfp_mask(mapping)))\n \t\t\t\tgoto next_page;\n \t\t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t\t\t\t  page_index(page),"
            ],
            "deleted": [
                "\t\t\t\t\t\t  page->index,"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "In the Linux kernel 5.0.21, mounting a crafted f2fs filesystem image can cause a NULL pointer dereference in f2fs_recover_fsync_data in fs/f2fs/recovery.c. This is related to F2FS_P_SB in fs/f2fs/f2fs.h.",
        "id": 2251
    },
    {
        "cve_id": "CVE-2022-0617",
        "code_before_change": "int udf_expand_file_adinicb(struct inode *inode)\n{\n\tstruct page *page;\n\tchar *kaddr;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tint err;\n\tstruct writeback_control udf_wbc = {\n\t\t.sync_mode = WB_SYNC_NONE,\n\t\t.nr_to_write = 1,\n\t};\n\n\tWARN_ON_ONCE(!inode_is_locked(inode));\n\tif (!iinfo->i_lenAlloc) {\n\t\tif (UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_USE_SHORT_AD))\n\t\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_SHORT;\n\t\telse\n\t\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_LONG;\n\t\t/* from now on we have normal address_space methods */\n\t\tinode->i_data.a_ops = &udf_aops;\n\t\tup_write(&iinfo->i_data_sem);\n\t\tmark_inode_dirty(inode);\n\t\treturn 0;\n\t}\n\t/*\n\t * Release i_data_sem so that we can lock a page - page lock ranks\n\t * above i_data_sem. i_mutex still protects us against file changes.\n\t */\n\tup_write(&iinfo->i_data_sem);\n\n\tpage = find_or_create_page(inode->i_mapping, 0, GFP_NOFS);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tif (!PageUptodate(page)) {\n\t\tkaddr = kmap_atomic(page);\n\t\tmemset(kaddr + iinfo->i_lenAlloc, 0x00,\n\t\t       PAGE_SIZE - iinfo->i_lenAlloc);\n\t\tmemcpy(kaddr, iinfo->i_data + iinfo->i_lenEAttr,\n\t\t\tiinfo->i_lenAlloc);\n\t\tflush_dcache_page(page);\n\t\tSetPageUptodate(page);\n\t\tkunmap_atomic(kaddr);\n\t}\n\tdown_write(&iinfo->i_data_sem);\n\tmemset(iinfo->i_data + iinfo->i_lenEAttr, 0x00,\n\t       iinfo->i_lenAlloc);\n\tiinfo->i_lenAlloc = 0;\n\tif (UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_USE_SHORT_AD))\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_SHORT;\n\telse\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_LONG;\n\t/* from now on we have normal address_space methods */\n\tinode->i_data.a_ops = &udf_aops;\n\tup_write(&iinfo->i_data_sem);\n\terr = inode->i_data.a_ops->writepage(page, &udf_wbc);\n\tif (err) {\n\t\t/* Restore everything back so that we don't lose data... */\n\t\tlock_page(page);\n\t\tdown_write(&iinfo->i_data_sem);\n\t\tkaddr = kmap_atomic(page);\n\t\tmemcpy(iinfo->i_data + iinfo->i_lenEAttr, kaddr, inode->i_size);\n\t\tkunmap_atomic(kaddr);\n\t\tunlock_page(page);\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_IN_ICB;\n\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\tup_write(&iinfo->i_data_sem);\n\t}\n\tput_page(page);\n\tmark_inode_dirty(inode);\n\n\treturn err;\n}",
        "code_after_change": "int udf_expand_file_adinicb(struct inode *inode)\n{\n\tstruct page *page;\n\tchar *kaddr;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tint err;\n\n\tWARN_ON_ONCE(!inode_is_locked(inode));\n\tif (!iinfo->i_lenAlloc) {\n\t\tif (UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_USE_SHORT_AD))\n\t\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_SHORT;\n\t\telse\n\t\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_LONG;\n\t\t/* from now on we have normal address_space methods */\n\t\tinode->i_data.a_ops = &udf_aops;\n\t\tup_write(&iinfo->i_data_sem);\n\t\tmark_inode_dirty(inode);\n\t\treturn 0;\n\t}\n\t/*\n\t * Release i_data_sem so that we can lock a page - page lock ranks\n\t * above i_data_sem. i_mutex still protects us against file changes.\n\t */\n\tup_write(&iinfo->i_data_sem);\n\n\tpage = find_or_create_page(inode->i_mapping, 0, GFP_NOFS);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tif (!PageUptodate(page)) {\n\t\tkaddr = kmap_atomic(page);\n\t\tmemset(kaddr + iinfo->i_lenAlloc, 0x00,\n\t\t       PAGE_SIZE - iinfo->i_lenAlloc);\n\t\tmemcpy(kaddr, iinfo->i_data + iinfo->i_lenEAttr,\n\t\t\tiinfo->i_lenAlloc);\n\t\tflush_dcache_page(page);\n\t\tSetPageUptodate(page);\n\t\tkunmap_atomic(kaddr);\n\t}\n\tdown_write(&iinfo->i_data_sem);\n\tmemset(iinfo->i_data + iinfo->i_lenEAttr, 0x00,\n\t       iinfo->i_lenAlloc);\n\tiinfo->i_lenAlloc = 0;\n\tif (UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_USE_SHORT_AD))\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_SHORT;\n\telse\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_LONG;\n\t/* from now on we have normal address_space methods */\n\tinode->i_data.a_ops = &udf_aops;\n\tset_page_dirty(page);\n\tunlock_page(page);\n\tup_write(&iinfo->i_data_sem);\n\terr = filemap_fdatawrite(inode->i_mapping);\n\tif (err) {\n\t\t/* Restore everything back so that we don't lose data... */\n\t\tlock_page(page);\n\t\tdown_write(&iinfo->i_data_sem);\n\t\tkaddr = kmap_atomic(page);\n\t\tmemcpy(iinfo->i_data + iinfo->i_lenEAttr, kaddr, inode->i_size);\n\t\tkunmap_atomic(kaddr);\n\t\tunlock_page(page);\n\t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_IN_ICB;\n\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\tup_write(&iinfo->i_data_sem);\n\t}\n\tput_page(page);\n\tmark_inode_dirty(inode);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,6 @@\n \tchar *kaddr;\n \tstruct udf_inode_info *iinfo = UDF_I(inode);\n \tint err;\n-\tstruct writeback_control udf_wbc = {\n-\t\t.sync_mode = WB_SYNC_NONE,\n-\t\t.nr_to_write = 1,\n-\t};\n \n \tWARN_ON_ONCE(!inode_is_locked(inode));\n \tif (!iinfo->i_lenAlloc) {\n@@ -51,8 +47,10 @@\n \t\tiinfo->i_alloc_type = ICBTAG_FLAG_AD_LONG;\n \t/* from now on we have normal address_space methods */\n \tinode->i_data.a_ops = &udf_aops;\n+\tset_page_dirty(page);\n+\tunlock_page(page);\n \tup_write(&iinfo->i_data_sem);\n-\terr = inode->i_data.a_ops->writepage(page, &udf_wbc);\n+\terr = filemap_fdatawrite(inode->i_mapping);\n \tif (err) {\n \t\t/* Restore everything back so that we don't lose data... */\n \t\tlock_page(page);",
        "function_modified_lines": {
            "added": [
                "\tset_page_dirty(page);",
                "\tunlock_page(page);",
                "\terr = filemap_fdatawrite(inode->i_mapping);"
            ],
            "deleted": [
                "\tstruct writeback_control udf_wbc = {",
                "\t\t.sync_mode = WB_SYNC_NONE,",
                "\t\t.nr_to_write = 1,",
                "\t};",
                "\terr = inode->i_data.a_ops->writepage(page, &udf_wbc);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A flaw null pointer dereference in the Linux kernel UDF file system functionality was found in the way user triggers udf_file_write_iter function for the malicious UDF image. A local user could use this flaw to crash the system. Actual from Linux kernel 4.2-rc1 till 5.17-rc2.",
        "id": 3215
    },
    {
        "cve_id": "CVE-2017-16646",
        "code_before_change": "static int stk7070pd_frontend_attach0(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tstk7070pd_init(adap->dev);\n\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 2, 18,\n\t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(&state->dib7000p_ops);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80, &stk7070pd_dib7000p_config[0]);\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "code_after_change": "static int stk7070pd_frontend_attach0(struct dvb_usb_adapter *adap)\n{\n\tstruct dib0700_adapter_state *state = adap->priv;\n\n\tif (!dvb_attach(dib7000p_attach, &state->dib7000p_ops))\n\t\treturn -ENODEV;\n\n\tstk7070pd_init(adap->dev);\n\n\tmsleep(10);\n\tdib0700_set_gpio(adap->dev, GPIO0, GPIO_OUT, 1);\n\n\tif (state->dib7000p_ops.i2c_enumeration(&adap->dev->i2c_adap, 2, 18,\n\t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n\t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n\t\t    __func__);\n\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n\t\treturn -ENODEV;\n\t}\n\n\tadap->fe_adap[0].fe = state->dib7000p_ops.init(&adap->dev->i2c_adap, 0x80, &stk7070pd_dib7000p_config[0]);\n\treturn adap->fe_adap[0].fe == NULL ? -ENODEV : 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,7 @@\n \t\t\t\t     stk7070pd_dib7000p_config) != 0) {\n \t\terr(\"%s: state->dib7000p_ops.i2c_enumeration failed.  Cannot continue\\n\",\n \t\t    __func__);\n-\t\tdvb_detach(&state->dib7000p_ops);\n+\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);\n \t\treturn -ENODEV;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tdvb_detach(state->dib7000p_ops.set_wbd_ref);"
            ],
            "deleted": [
                "\t\tdvb_detach(&state->dib7000p_ops);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/media/usb/dvb-usb/dib0700_devices.c in the Linux kernel through 4.13.11 allows local users to cause a denial of service (BUG and system crash) or possibly have unspecified other impact via a crafted USB device.",
        "id": 1334
    },
    {
        "cve_id": "CVE-2019-15099",
        "code_before_change": "static void ath10k_usb_free_urb_to_pipe(struct ath10k_usb_pipe *pipe,\n\t\t\t\t\tstruct ath10k_urb_context *urb_context)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n\n\tpipe->urb_cnt++;\n\tlist_add(&urb_context->link, &pipe->urb_list_head);\n\n\tspin_unlock_irqrestore(&pipe->ar_usb->cs_lock, flags);\n}",
        "code_after_change": "static void ath10k_usb_free_urb_to_pipe(struct ath10k_usb_pipe *pipe,\n\t\t\t\t\tstruct ath10k_urb_context *urb_context)\n{\n\tunsigned long flags;\n\n\t/* bail if this pipe is not initialized */\n\tif (!pipe->ar_usb)\n\t\treturn;\n\n\tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n\n\tpipe->urb_cnt++;\n\tlist_add(&urb_context->link, &pipe->urb_list_head);\n\n\tspin_unlock_irqrestore(&pipe->ar_usb->cs_lock, flags);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,10 @@\n \t\t\t\t\tstruct ath10k_urb_context *urb_context)\n {\n \tunsigned long flags;\n+\n+\t/* bail if this pipe is not initialized */\n+\tif (!pipe->ar_usb)\n+\t\treturn;\n \n \tspin_lock_irqsave(&pipe->ar_usb->cs_lock, flags);\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\t/* bail if this pipe is not initialized */",
                "\tif (!pipe->ar_usb)",
                "\t\treturn;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/net/wireless/ath/ath10k/usb.c in the Linux kernel through 5.2.8 has a NULL pointer dereference via an incomplete address in an endpoint descriptor.",
        "id": 1990
    },
    {
        "cve_id": "CVE-2018-14646",
        "code_before_change": "static int rtnl_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net *tgt_net = net;\n\tint h, s_h;\n\tint idx = 0, s_idx;\n\tstruct net_device *dev;\n\tstruct hlist_head *head;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tu32 ext_filter_mask = 0;\n\tconst struct rtnl_link_ops *kind_ops = NULL;\n\tunsigned int flags = NLM_F_MULTI;\n\tint master_idx = 0;\n\tint netnsid = -1;\n\tint err;\n\tint hdrlen;\n\n\ts_h = cb->args[0];\n\ts_idx = cb->args[1];\n\n\t/* A hack to preserve kernel<->userspace interface.\n\t * The correct header is ifinfomsg. It is consistent with rtnl_getlink.\n\t * However, before Linux v3.9 the code here assumed rtgenmsg and that's\n\t * what iproute2 < v3.9.0 used.\n\t * We can detect the old iproute2. Even including the IFLA_EXT_MASK\n\t * attribute, its netlink message is shorter than struct ifinfomsg.\n\t */\n\thdrlen = nlmsg_len(cb->nlh) < sizeof(struct ifinfomsg) ?\n\t\t sizeof(struct rtgenmsg) : sizeof(struct ifinfomsg);\n\n\tif (nlmsg_parse(cb->nlh, hdrlen, tb, IFLA_MAX,\n\t\t\tifla_policy, NULL) >= 0) {\n\t\tif (tb[IFLA_IF_NETNSID]) {\n\t\t\tnetnsid = nla_get_s32(tb[IFLA_IF_NETNSID]);\n\t\t\ttgt_net = get_target_net(skb, netnsid);\n\t\t\tif (IS_ERR(tgt_net)) {\n\t\t\t\ttgt_net = net;\n\t\t\t\tnetnsid = -1;\n\t\t\t}\n\t\t}\n\n\t\tif (tb[IFLA_EXT_MASK])\n\t\t\text_filter_mask = nla_get_u32(tb[IFLA_EXT_MASK]);\n\n\t\tif (tb[IFLA_MASTER])\n\t\t\tmaster_idx = nla_get_u32(tb[IFLA_MASTER]);\n\n\t\tif (tb[IFLA_LINKINFO])\n\t\t\tkind_ops = linkinfo_to_kind_ops(tb[IFLA_LINKINFO]);\n\n\t\tif (master_idx || kind_ops)\n\t\t\tflags |= NLM_F_DUMP_FILTERED;\n\t}\n\n\tfor (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {\n\t\tidx = 0;\n\t\thead = &tgt_net->dev_index_head[h];\n\t\thlist_for_each_entry(dev, head, index_hlist) {\n\t\t\tif (link_dump_filtered(dev, master_idx, kind_ops))\n\t\t\t\tgoto cont;\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto cont;\n\t\t\terr = rtnl_fill_ifinfo(skb, dev, net,\n\t\t\t\t\t       RTM_NEWLINK,\n\t\t\t\t\t       NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t       cb->nlh->nlmsg_seq, 0,\n\t\t\t\t\t       flags,\n\t\t\t\t\t       ext_filter_mask, 0, NULL,\n\t\t\t\t\t       netnsid);\n\n\t\t\tif (err < 0) {\n\t\t\t\tif (likely(skb->len))\n\t\t\t\t\tgoto out;\n\n\t\t\t\tgoto out_err;\n\t\t\t}\ncont:\n\t\t\tidx++;\n\t\t}\n\t}\nout:\n\terr = skb->len;\nout_err:\n\tcb->args[1] = idx;\n\tcb->args[0] = h;\n\tcb->seq = net->dev_base_seq;\n\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\n\tif (netnsid >= 0)\n\t\tput_net(tgt_net);\n\n\treturn err;\n}",
        "code_after_change": "static int rtnl_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net *tgt_net = net;\n\tint h, s_h;\n\tint idx = 0, s_idx;\n\tstruct net_device *dev;\n\tstruct hlist_head *head;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tu32 ext_filter_mask = 0;\n\tconst struct rtnl_link_ops *kind_ops = NULL;\n\tunsigned int flags = NLM_F_MULTI;\n\tint master_idx = 0;\n\tint netnsid = -1;\n\tint err;\n\tint hdrlen;\n\n\ts_h = cb->args[0];\n\ts_idx = cb->args[1];\n\n\t/* A hack to preserve kernel<->userspace interface.\n\t * The correct header is ifinfomsg. It is consistent with rtnl_getlink.\n\t * However, before Linux v3.9 the code here assumed rtgenmsg and that's\n\t * what iproute2 < v3.9.0 used.\n\t * We can detect the old iproute2. Even including the IFLA_EXT_MASK\n\t * attribute, its netlink message is shorter than struct ifinfomsg.\n\t */\n\thdrlen = nlmsg_len(cb->nlh) < sizeof(struct ifinfomsg) ?\n\t\t sizeof(struct rtgenmsg) : sizeof(struct ifinfomsg);\n\n\tif (nlmsg_parse(cb->nlh, hdrlen, tb, IFLA_MAX,\n\t\t\tifla_policy, NULL) >= 0) {\n\t\tif (tb[IFLA_IF_NETNSID]) {\n\t\t\tnetnsid = nla_get_s32(tb[IFLA_IF_NETNSID]);\n\t\t\ttgt_net = get_target_net(skb->sk, netnsid);\n\t\t\tif (IS_ERR(tgt_net)) {\n\t\t\t\ttgt_net = net;\n\t\t\t\tnetnsid = -1;\n\t\t\t}\n\t\t}\n\n\t\tif (tb[IFLA_EXT_MASK])\n\t\t\text_filter_mask = nla_get_u32(tb[IFLA_EXT_MASK]);\n\n\t\tif (tb[IFLA_MASTER])\n\t\t\tmaster_idx = nla_get_u32(tb[IFLA_MASTER]);\n\n\t\tif (tb[IFLA_LINKINFO])\n\t\t\tkind_ops = linkinfo_to_kind_ops(tb[IFLA_LINKINFO]);\n\n\t\tif (master_idx || kind_ops)\n\t\t\tflags |= NLM_F_DUMP_FILTERED;\n\t}\n\n\tfor (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {\n\t\tidx = 0;\n\t\thead = &tgt_net->dev_index_head[h];\n\t\thlist_for_each_entry(dev, head, index_hlist) {\n\t\t\tif (link_dump_filtered(dev, master_idx, kind_ops))\n\t\t\t\tgoto cont;\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto cont;\n\t\t\terr = rtnl_fill_ifinfo(skb, dev, net,\n\t\t\t\t\t       RTM_NEWLINK,\n\t\t\t\t\t       NETLINK_CB(cb->skb).portid,\n\t\t\t\t\t       cb->nlh->nlmsg_seq, 0,\n\t\t\t\t\t       flags,\n\t\t\t\t\t       ext_filter_mask, 0, NULL,\n\t\t\t\t\t       netnsid);\n\n\t\t\tif (err < 0) {\n\t\t\t\tif (likely(skb->len))\n\t\t\t\t\tgoto out;\n\n\t\t\t\tgoto out_err;\n\t\t\t}\ncont:\n\t\t\tidx++;\n\t\t}\n\t}\nout:\n\terr = skb->len;\nout_err:\n\tcb->args[1] = idx;\n\tcb->args[0] = h;\n\tcb->seq = net->dev_base_seq;\n\tnl_dump_check_consistent(cb, nlmsg_hdr(skb));\n\tif (netnsid >= 0)\n\t\tput_net(tgt_net);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,7 +32,7 @@\n \t\t\tifla_policy, NULL) >= 0) {\n \t\tif (tb[IFLA_IF_NETNSID]) {\n \t\t\tnetnsid = nla_get_s32(tb[IFLA_IF_NETNSID]);\n-\t\t\ttgt_net = get_target_net(skb, netnsid);\n+\t\t\ttgt_net = get_target_net(skb->sk, netnsid);\n \t\t\tif (IS_ERR(tgt_net)) {\n \t\t\t\ttgt_net = net;\n \t\t\t\tnetnsid = -1;",
        "function_modified_lines": {
            "added": [
                "\t\t\ttgt_net = get_target_net(skb->sk, netnsid);"
            ],
            "deleted": [
                "\t\t\ttgt_net = get_target_net(skb, netnsid);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The Linux kernel before 4.15-rc8 was found to be vulnerable to a NULL pointer dereference bug in the __netlink_ns_capable() function in the net/netlink/af_netlink.c file. A local attacker could exploit this when a net namespace with a netnsid is assigned to cause a kernel panic and a denial of service.",
        "id": 1702
    },
    {
        "cve_id": "CVE-2016-6327",
        "code_before_change": "static void srpt_handle_tsk_mgmt(struct srpt_rdma_ch *ch,\n\t\t\t\t struct srpt_recv_ioctx *recv_ioctx,\n\t\t\t\t struct srpt_send_ioctx *send_ioctx)\n{\n\tstruct srp_tsk_mgmt *srp_tsk;\n\tstruct se_cmd *cmd;\n\tstruct se_session *sess = ch->sess;\n\tuint64_t unpacked_lun;\n\tuint32_t tag = 0;\n\tint tcm_tmr;\n\tint rc;\n\n\tBUG_ON(!send_ioctx);\n\n\tsrp_tsk = recv_ioctx->ioctx.buf;\n\tcmd = &send_ioctx->cmd;\n\n\tpr_debug(\"recv tsk_mgmt fn %d for task_tag %lld and cmd tag %lld\"\n\t\t \" cm_id %p sess %p\\n\", srp_tsk->tsk_mgmt_func,\n\t\t srp_tsk->task_tag, srp_tsk->tag, ch->cm_id, ch->sess);\n\n\tsrpt_set_cmd_state(send_ioctx, SRPT_STATE_MGMT);\n\tsend_ioctx->cmd.tag = srp_tsk->tag;\n\ttcm_tmr = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func);\n\tif (tcm_tmr < 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response =\n\t\t\tTMR_TASK_MGMT_FUNCTION_NOT_SUPPORTED;\n\t\tgoto fail;\n\t}\n\tunpacked_lun = srpt_unpack_lun((uint8_t *)&srp_tsk->lun,\n\t\t\t\t       sizeof(srp_tsk->lun));\n\n\tif (srp_tsk->tsk_mgmt_func == SRP_TSK_ABORT_TASK) {\n\t\trc = srpt_rx_mgmt_fn_tag(send_ioctx, srp_tsk->task_tag);\n\t\tif (rc < 0) {\n\t\t\tsend_ioctx->cmd.se_tmr_req->response =\n\t\t\t\t\tTMR_TASK_DOES_NOT_EXIST;\n\t\t\tgoto fail;\n\t\t}\n\t\ttag = srp_tsk->task_tag;\n\t}\n\trc = target_submit_tmr(&send_ioctx->cmd, sess, NULL, unpacked_lun,\n\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, tag,\n\t\t\t\tTARGET_SCF_ACK_KREF);\n\tif (rc != 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;\n\t\tgoto fail;\n\t}\n\treturn;\nfail:\n\ttransport_send_check_condition_and_sense(cmd, 0, 0); // XXX:\n}",
        "code_after_change": "static void srpt_handle_tsk_mgmt(struct srpt_rdma_ch *ch,\n\t\t\t\t struct srpt_recv_ioctx *recv_ioctx,\n\t\t\t\t struct srpt_send_ioctx *send_ioctx)\n{\n\tstruct srp_tsk_mgmt *srp_tsk;\n\tstruct se_cmd *cmd;\n\tstruct se_session *sess = ch->sess;\n\tuint64_t unpacked_lun;\n\tint tcm_tmr;\n\tint rc;\n\n\tBUG_ON(!send_ioctx);\n\n\tsrp_tsk = recv_ioctx->ioctx.buf;\n\tcmd = &send_ioctx->cmd;\n\n\tpr_debug(\"recv tsk_mgmt fn %d for task_tag %lld and cmd tag %lld\"\n\t\t \" cm_id %p sess %p\\n\", srp_tsk->tsk_mgmt_func,\n\t\t srp_tsk->task_tag, srp_tsk->tag, ch->cm_id, ch->sess);\n\n\tsrpt_set_cmd_state(send_ioctx, SRPT_STATE_MGMT);\n\tsend_ioctx->cmd.tag = srp_tsk->tag;\n\ttcm_tmr = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func);\n\tunpacked_lun = srpt_unpack_lun((uint8_t *)&srp_tsk->lun,\n\t\t\t\t       sizeof(srp_tsk->lun));\n\trc = target_submit_tmr(&send_ioctx->cmd, sess, NULL, unpacked_lun,\n\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, srp_tsk->task_tag,\n\t\t\t\tTARGET_SCF_ACK_KREF);\n\tif (rc != 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;\n\t\tgoto fail;\n\t}\n\treturn;\nfail:\n\ttransport_send_check_condition_and_sense(cmd, 0, 0); // XXX:\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,6 @@\n \tstruct se_cmd *cmd;\n \tstruct se_session *sess = ch->sess;\n \tuint64_t unpacked_lun;\n-\tuint32_t tag = 0;\n \tint tcm_tmr;\n \tint rc;\n \n@@ -22,25 +21,10 @@\n \tsrpt_set_cmd_state(send_ioctx, SRPT_STATE_MGMT);\n \tsend_ioctx->cmd.tag = srp_tsk->tag;\n \ttcm_tmr = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func);\n-\tif (tcm_tmr < 0) {\n-\t\tsend_ioctx->cmd.se_tmr_req->response =\n-\t\t\tTMR_TASK_MGMT_FUNCTION_NOT_SUPPORTED;\n-\t\tgoto fail;\n-\t}\n \tunpacked_lun = srpt_unpack_lun((uint8_t *)&srp_tsk->lun,\n \t\t\t\t       sizeof(srp_tsk->lun));\n-\n-\tif (srp_tsk->tsk_mgmt_func == SRP_TSK_ABORT_TASK) {\n-\t\trc = srpt_rx_mgmt_fn_tag(send_ioctx, srp_tsk->task_tag);\n-\t\tif (rc < 0) {\n-\t\t\tsend_ioctx->cmd.se_tmr_req->response =\n-\t\t\t\t\tTMR_TASK_DOES_NOT_EXIST;\n-\t\t\tgoto fail;\n-\t\t}\n-\t\ttag = srp_tsk->task_tag;\n-\t}\n \trc = target_submit_tmr(&send_ioctx->cmd, sess, NULL, unpacked_lun,\n-\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, tag,\n+\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, srp_tsk->task_tag,\n \t\t\t\tTARGET_SCF_ACK_KREF);\n \tif (rc != 0) {\n \t\tsend_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, srp_tsk->task_tag,"
            ],
            "deleted": [
                "\tuint32_t tag = 0;",
                "\tif (tcm_tmr < 0) {",
                "\t\tsend_ioctx->cmd.se_tmr_req->response =",
                "\t\t\tTMR_TASK_MGMT_FUNCTION_NOT_SUPPORTED;",
                "\t\tgoto fail;",
                "\t}",
                "",
                "\tif (srp_tsk->tsk_mgmt_func == SRP_TSK_ABORT_TASK) {",
                "\t\trc = srpt_rx_mgmt_fn_tag(send_ioctx, srp_tsk->task_tag);",
                "\t\tif (rc < 0) {",
                "\t\t\tsend_ioctx->cmd.se_tmr_req->response =",
                "\t\t\t\t\tTMR_TASK_DOES_NOT_EXIST;",
                "\t\t\tgoto fail;",
                "\t\t}",
                "\t\ttag = srp_tsk->task_tag;",
                "\t}",
                "\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, tag,"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/infiniband/ulp/srpt/ib_srpt.c in the Linux kernel before 4.5.1 allows local users to cause a denial of service (NULL pointer dereference and system crash) by using an ABORT_TASK command to abort a device write operation.",
        "id": 1075
    },
    {
        "cve_id": "CVE-2023-0394",
        "code_before_change": "static int rawv6_push_pending_frames(struct sock *sk, struct flowi6 *fl6,\n\t\t\t\t     struct raw6_sock *rp)\n{\n\tstruct sk_buff *skb;\n\tint err = 0;\n\tint offset;\n\tint len;\n\tint total_len;\n\t__wsum tmp_csum;\n\t__sum16 csum;\n\n\tif (!rp->checksum)\n\t\tgoto send;\n\n\tskb = skb_peek(&sk->sk_write_queue);\n\tif (!skb)\n\t\tgoto out;\n\n\toffset = rp->offset;\n\ttotal_len = inet_sk(sk)->cork.base.length;\n\tif (offset >= total_len - 1) {\n\t\terr = -EINVAL;\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* should be check HW csum miyazawa */\n\tif (skb_queue_len(&sk->sk_write_queue) == 1) {\n\t\t/*\n\t\t * Only one fragment on the socket.\n\t\t */\n\t\ttmp_csum = skb->csum;\n\t} else {\n\t\tstruct sk_buff *csum_skb = NULL;\n\t\ttmp_csum = 0;\n\n\t\tskb_queue_walk(&sk->sk_write_queue, skb) {\n\t\t\ttmp_csum = csum_add(tmp_csum, skb->csum);\n\n\t\t\tif (csum_skb)\n\t\t\t\tcontinue;\n\n\t\t\tlen = skb->len - skb_transport_offset(skb);\n\t\t\tif (offset >= len) {\n\t\t\t\toffset -= len;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcsum_skb = skb;\n\t\t}\n\n\t\tskb = csum_skb;\n\t}\n\n\toffset += skb_transport_offset(skb);\n\terr = skb_copy_bits(skb, offset, &csum, 2);\n\tif (err < 0) {\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* in case cksum was not initialized */\n\tif (unlikely(csum))\n\t\ttmp_csum = csum_sub(tmp_csum, csum_unfold(csum));\n\n\tcsum = csum_ipv6_magic(&fl6->saddr, &fl6->daddr,\n\t\t\t       total_len, fl6->flowi6_proto, tmp_csum);\n\n\tif (csum == 0 && fl6->flowi6_proto == IPPROTO_UDP)\n\t\tcsum = CSUM_MANGLED_0;\n\n\tBUG_ON(skb_store_bits(skb, offset, &csum, 2));\n\nsend:\n\terr = ip6_push_pending_frames(sk);\nout:\n\treturn err;\n}",
        "code_after_change": "static int rawv6_push_pending_frames(struct sock *sk, struct flowi6 *fl6,\n\t\t\t\t     struct raw6_sock *rp)\n{\n\tstruct ipv6_txoptions *opt;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\tint offset;\n\tint len;\n\tint total_len;\n\t__wsum tmp_csum;\n\t__sum16 csum;\n\n\tif (!rp->checksum)\n\t\tgoto send;\n\n\tskb = skb_peek(&sk->sk_write_queue);\n\tif (!skb)\n\t\tgoto out;\n\n\toffset = rp->offset;\n\ttotal_len = inet_sk(sk)->cork.base.length;\n\topt = inet6_sk(sk)->cork.opt;\n\ttotal_len -= opt ? opt->opt_flen : 0;\n\n\tif (offset >= total_len - 1) {\n\t\terr = -EINVAL;\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* should be check HW csum miyazawa */\n\tif (skb_queue_len(&sk->sk_write_queue) == 1) {\n\t\t/*\n\t\t * Only one fragment on the socket.\n\t\t */\n\t\ttmp_csum = skb->csum;\n\t} else {\n\t\tstruct sk_buff *csum_skb = NULL;\n\t\ttmp_csum = 0;\n\n\t\tskb_queue_walk(&sk->sk_write_queue, skb) {\n\t\t\ttmp_csum = csum_add(tmp_csum, skb->csum);\n\n\t\t\tif (csum_skb)\n\t\t\t\tcontinue;\n\n\t\t\tlen = skb->len - skb_transport_offset(skb);\n\t\t\tif (offset >= len) {\n\t\t\t\toffset -= len;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcsum_skb = skb;\n\t\t}\n\n\t\tskb = csum_skb;\n\t}\n\n\toffset += skb_transport_offset(skb);\n\terr = skb_copy_bits(skb, offset, &csum, 2);\n\tif (err < 0) {\n\t\tip6_flush_pending_frames(sk);\n\t\tgoto out;\n\t}\n\n\t/* in case cksum was not initialized */\n\tif (unlikely(csum))\n\t\ttmp_csum = csum_sub(tmp_csum, csum_unfold(csum));\n\n\tcsum = csum_ipv6_magic(&fl6->saddr, &fl6->daddr,\n\t\t\t       total_len, fl6->flowi6_proto, tmp_csum);\n\n\tif (csum == 0 && fl6->flowi6_proto == IPPROTO_UDP)\n\t\tcsum = CSUM_MANGLED_0;\n\n\tBUG_ON(skb_store_bits(skb, offset, &csum, 2));\n\nsend:\n\terr = ip6_push_pending_frames(sk);\nout:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,7 @@\n static int rawv6_push_pending_frames(struct sock *sk, struct flowi6 *fl6,\n \t\t\t\t     struct raw6_sock *rp)\n {\n+\tstruct ipv6_txoptions *opt;\n \tstruct sk_buff *skb;\n \tint err = 0;\n \tint offset;\n@@ -18,6 +19,9 @@\n \n \toffset = rp->offset;\n \ttotal_len = inet_sk(sk)->cork.base.length;\n+\topt = inet6_sk(sk)->cork.opt;\n+\ttotal_len -= opt ? opt->opt_flen : 0;\n+\n \tif (offset >= total_len - 1) {\n \t\terr = -EINVAL;\n \t\tip6_flush_pending_frames(sk);",
        "function_modified_lines": {
            "added": [
                "\tstruct ipv6_txoptions *opt;",
                "\topt = inet6_sk(sk)->cork.opt;",
                "\ttotal_len -= opt ? opt->opt_flen : 0;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "A NULL pointer dereference flaw was found in rawv6_push_pending_frames in net/ipv6/raw.c in the network subcomponent in the Linux kernel. This flaw causes the system to crash.",
        "id": 3824
    },
    {
        "cve_id": "CVE-2022-3115",
        "code_before_change": "static void malidp_crtc_reset(struct drm_crtc *crtc)\n{\n\tstruct malidp_crtc_state *state =\n\t\tkzalloc(sizeof(*state), GFP_KERNEL);\n\n\tif (crtc->state)\n\t\tmalidp_crtc_destroy_state(crtc, crtc->state);\n\n\t__drm_atomic_helper_crtc_reset(crtc, &state->base);\n}",
        "code_after_change": "static void malidp_crtc_reset(struct drm_crtc *crtc)\n{\n\tstruct malidp_crtc_state *state =\n\t\tkzalloc(sizeof(*state), GFP_KERNEL);\n\n\tif (crtc->state)\n\t\tmalidp_crtc_destroy_state(crtc, crtc->state);\n\n\tif (state)\n\t\t__drm_atomic_helper_crtc_reset(crtc, &state->base);\n\telse\n\t\t__drm_atomic_helper_crtc_reset(crtc, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,5 +6,8 @@\n \tif (crtc->state)\n \t\tmalidp_crtc_destroy_state(crtc, crtc->state);\n \n-\t__drm_atomic_helper_crtc_reset(crtc, &state->base);\n+\tif (state)\n+\t\t__drm_atomic_helper_crtc_reset(crtc, &state->base);\n+\telse\n+\t\t__drm_atomic_helper_crtc_reset(crtc, NULL);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (state)",
                "\t\t__drm_atomic_helper_crtc_reset(crtc, &state->base);",
                "\telse",
                "\t\t__drm_atomic_helper_crtc_reset(crtc, NULL);"
            ],
            "deleted": [
                "\t__drm_atomic_helper_crtc_reset(crtc, &state->base);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in the Linux kernel through 5.16-rc6. malidp_crtc_reset in drivers/gpu/drm/arm/malidp_crtc.c lacks check of the return value of kzalloc() and will cause the null pointer dereference.",
        "id": 3561
    },
    {
        "cve_id": "CVE-2017-18079",
        "code_before_change": "static irqreturn_t i8042_interrupt(int irq, void *dev_id)\n{\n\tstruct i8042_port *port;\n\tstruct serio *serio;\n\tunsigned long flags;\n\tunsigned char str, data;\n\tunsigned int dfl;\n\tunsigned int port_no;\n\tbool filtered;\n\tint ret = 1;\n\n\tspin_lock_irqsave(&i8042_lock, flags);\n\n\tstr = i8042_read_status();\n\tif (unlikely(~str & I8042_STR_OBF)) {\n\t\tspin_unlock_irqrestore(&i8042_lock, flags);\n\t\tif (irq)\n\t\t\tdbg(\"Interrupt %d, without any data\\n\", irq);\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tdata = i8042_read_data();\n\n\tif (i8042_mux_present && (str & I8042_STR_AUXDATA)) {\n\t\tstatic unsigned long last_transmit;\n\t\tstatic unsigned char last_str;\n\n\t\tdfl = 0;\n\t\tif (str & I8042_STR_MUXERR) {\n\t\t\tdbg(\"MUX error, status is %02x, data is %02x\\n\",\n\t\t\t    str, data);\n/*\n * When MUXERR condition is signalled the data register can only contain\n * 0xfd, 0xfe or 0xff if implementation follows the spec. Unfortunately\n * it is not always the case. Some KBCs also report 0xfc when there is\n * nothing connected to the port while others sometimes get confused which\n * port the data came from and signal error leaving the data intact. They\n * _do not_ revert to legacy mode (actually I've never seen KBC reverting\n * to legacy mode yet, when we see one we'll add proper handling).\n * Anyway, we process 0xfc, 0xfd, 0xfe and 0xff as timeouts, and for the\n * rest assume that the data came from the same serio last byte\n * was transmitted (if transmission happened not too long ago).\n */\n\n\t\t\tswitch (data) {\n\t\t\t\tdefault:\n\t\t\t\t\tif (time_before(jiffies, last_transmit + HZ/10)) {\n\t\t\t\t\t\tstr = last_str;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\t/* fall through - report timeout */\n\t\t\t\tcase 0xfc:\n\t\t\t\tcase 0xfd:\n\t\t\t\tcase 0xfe: dfl = SERIO_TIMEOUT; data = 0xfe; break;\n\t\t\t\tcase 0xff: dfl = SERIO_PARITY;  data = 0xfe; break;\n\t\t\t}\n\t\t}\n\n\t\tport_no = I8042_MUX_PORT_NO + ((str >> 6) & 3);\n\t\tlast_str = str;\n\t\tlast_transmit = jiffies;\n\t} else {\n\n\t\tdfl = ((str & I8042_STR_PARITY) ? SERIO_PARITY : 0) |\n\t\t      ((str & I8042_STR_TIMEOUT && !i8042_notimeout) ? SERIO_TIMEOUT : 0);\n\n\t\tport_no = (str & I8042_STR_AUXDATA) ?\n\t\t\t\tI8042_AUX_PORT_NO : I8042_KBD_PORT_NO;\n\t}\n\n\tport = &i8042_ports[port_no];\n\tserio = port->exists ? port->serio : NULL;\n\n\tfilter_dbg(port->driver_bound, data, \"<- i8042 (interrupt, %d, %d%s%s)\\n\",\n\t\t   port_no, irq,\n\t\t   dfl & SERIO_PARITY ? \", bad parity\" : \"\",\n\t\t   dfl & SERIO_TIMEOUT ? \", timeout\" : \"\");\n\n\tfiltered = i8042_filter(data, str, serio);\n\n\tspin_unlock_irqrestore(&i8042_lock, flags);\n\n\tif (likely(port->exists && !filtered))\n\t\tserio_interrupt(serio, data, dfl);\n\n out:\n\treturn IRQ_RETVAL(ret);\n}",
        "code_after_change": "static irqreturn_t i8042_interrupt(int irq, void *dev_id)\n{\n\tstruct i8042_port *port;\n\tstruct serio *serio;\n\tunsigned long flags;\n\tunsigned char str, data;\n\tunsigned int dfl;\n\tunsigned int port_no;\n\tbool filtered;\n\tint ret = 1;\n\n\tspin_lock_irqsave(&i8042_lock, flags);\n\n\tstr = i8042_read_status();\n\tif (unlikely(~str & I8042_STR_OBF)) {\n\t\tspin_unlock_irqrestore(&i8042_lock, flags);\n\t\tif (irq)\n\t\t\tdbg(\"Interrupt %d, without any data\\n\", irq);\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tdata = i8042_read_data();\n\n\tif (i8042_mux_present && (str & I8042_STR_AUXDATA)) {\n\t\tstatic unsigned long last_transmit;\n\t\tstatic unsigned char last_str;\n\n\t\tdfl = 0;\n\t\tif (str & I8042_STR_MUXERR) {\n\t\t\tdbg(\"MUX error, status is %02x, data is %02x\\n\",\n\t\t\t    str, data);\n/*\n * When MUXERR condition is signalled the data register can only contain\n * 0xfd, 0xfe or 0xff if implementation follows the spec. Unfortunately\n * it is not always the case. Some KBCs also report 0xfc when there is\n * nothing connected to the port while others sometimes get confused which\n * port the data came from and signal error leaving the data intact. They\n * _do not_ revert to legacy mode (actually I've never seen KBC reverting\n * to legacy mode yet, when we see one we'll add proper handling).\n * Anyway, we process 0xfc, 0xfd, 0xfe and 0xff as timeouts, and for the\n * rest assume that the data came from the same serio last byte\n * was transmitted (if transmission happened not too long ago).\n */\n\n\t\t\tswitch (data) {\n\t\t\t\tdefault:\n\t\t\t\t\tif (time_before(jiffies, last_transmit + HZ/10)) {\n\t\t\t\t\t\tstr = last_str;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\t/* fall through - report timeout */\n\t\t\t\tcase 0xfc:\n\t\t\t\tcase 0xfd:\n\t\t\t\tcase 0xfe: dfl = SERIO_TIMEOUT; data = 0xfe; break;\n\t\t\t\tcase 0xff: dfl = SERIO_PARITY;  data = 0xfe; break;\n\t\t\t}\n\t\t}\n\n\t\tport_no = I8042_MUX_PORT_NO + ((str >> 6) & 3);\n\t\tlast_str = str;\n\t\tlast_transmit = jiffies;\n\t} else {\n\n\t\tdfl = ((str & I8042_STR_PARITY) ? SERIO_PARITY : 0) |\n\t\t      ((str & I8042_STR_TIMEOUT && !i8042_notimeout) ? SERIO_TIMEOUT : 0);\n\n\t\tport_no = (str & I8042_STR_AUXDATA) ?\n\t\t\t\tI8042_AUX_PORT_NO : I8042_KBD_PORT_NO;\n\t}\n\n\tport = &i8042_ports[port_no];\n\tserio = port->exists ? port->serio : NULL;\n\n\tfilter_dbg(port->driver_bound, data, \"<- i8042 (interrupt, %d, %d%s%s)\\n\",\n\t\t   port_no, irq,\n\t\t   dfl & SERIO_PARITY ? \", bad parity\" : \"\",\n\t\t   dfl & SERIO_TIMEOUT ? \", timeout\" : \"\");\n\n\tfiltered = i8042_filter(data, str, serio);\n\n\tspin_unlock_irqrestore(&i8042_lock, flags);\n\n\tif (likely(serio && !filtered))\n\t\tserio_interrupt(serio, data, dfl);\n\n out:\n\treturn IRQ_RETVAL(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -81,7 +81,7 @@\n \n \tspin_unlock_irqrestore(&i8042_lock, flags);\n \n-\tif (likely(port->exists && !filtered))\n+\tif (likely(serio && !filtered))\n \t\tserio_interrupt(serio, data, dfl);\n \n  out:",
        "function_modified_lines": {
            "added": [
                "\tif (likely(serio && !filtered))"
            ],
            "deleted": [
                "\tif (likely(port->exists && !filtered))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "drivers/input/serio/i8042.c in the Linux kernel before 4.12.4 allows attackers to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact because the port->exists value can change after it is validated.",
        "id": 1389
    },
    {
        "cve_id": "CVE-2019-18885",
        "code_before_change": "static long btrfs_ioctl_dev_info(struct btrfs_fs_info *fs_info,\n\t\t\t\t void __user *arg)\n{\n\tstruct btrfs_ioctl_dev_info_args *di_args;\n\tstruct btrfs_device *dev;\n\tint ret = 0;\n\tchar *s_uuid = NULL;\n\n\tdi_args = memdup_user(arg, sizeof(*di_args));\n\tif (IS_ERR(di_args))\n\t\treturn PTR_ERR(di_args);\n\n\tif (!btrfs_is_empty_uuid(di_args->uuid))\n\t\ts_uuid = di_args->uuid;\n\n\trcu_read_lock();\n\tdev = btrfs_find_device(fs_info->fs_devices, di_args->devid, s_uuid,\n\t\t\t\tNULL);\n\n\tif (!dev) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tdi_args->devid = dev->devid;\n\tdi_args->bytes_used = btrfs_device_get_bytes_used(dev);\n\tdi_args->total_bytes = btrfs_device_get_total_bytes(dev);\n\tmemcpy(di_args->uuid, dev->uuid, sizeof(di_args->uuid));\n\tif (dev->name) {\n\t\tstrncpy(di_args->path, rcu_str_deref(dev->name),\n\t\t\t\tsizeof(di_args->path) - 1);\n\t\tdi_args->path[sizeof(di_args->path) - 1] = 0;\n\t} else {\n\t\tdi_args->path[0] = '\\0';\n\t}\n\nout:\n\trcu_read_unlock();\n\tif (ret == 0 && copy_to_user(arg, di_args, sizeof(*di_args)))\n\t\tret = -EFAULT;\n\n\tkfree(di_args);\n\treturn ret;\n}",
        "code_after_change": "static long btrfs_ioctl_dev_info(struct btrfs_fs_info *fs_info,\n\t\t\t\t void __user *arg)\n{\n\tstruct btrfs_ioctl_dev_info_args *di_args;\n\tstruct btrfs_device *dev;\n\tint ret = 0;\n\tchar *s_uuid = NULL;\n\n\tdi_args = memdup_user(arg, sizeof(*di_args));\n\tif (IS_ERR(di_args))\n\t\treturn PTR_ERR(di_args);\n\n\tif (!btrfs_is_empty_uuid(di_args->uuid))\n\t\ts_uuid = di_args->uuid;\n\n\trcu_read_lock();\n\tdev = btrfs_find_device(fs_info->fs_devices, di_args->devid, s_uuid,\n\t\t\t\tNULL, true);\n\n\tif (!dev) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tdi_args->devid = dev->devid;\n\tdi_args->bytes_used = btrfs_device_get_bytes_used(dev);\n\tdi_args->total_bytes = btrfs_device_get_total_bytes(dev);\n\tmemcpy(di_args->uuid, dev->uuid, sizeof(di_args->uuid));\n\tif (dev->name) {\n\t\tstrncpy(di_args->path, rcu_str_deref(dev->name),\n\t\t\t\tsizeof(di_args->path) - 1);\n\t\tdi_args->path[sizeof(di_args->path) - 1] = 0;\n\t} else {\n\t\tdi_args->path[0] = '\\0';\n\t}\n\nout:\n\trcu_read_unlock();\n\tif (ret == 0 && copy_to_user(arg, di_args, sizeof(*di_args)))\n\t\tret = -EFAULT;\n\n\tkfree(di_args);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,7 +15,7 @@\n \n \trcu_read_lock();\n \tdev = btrfs_find_device(fs_info->fs_devices, di_args->devid, s_uuid,\n-\t\t\t\tNULL);\n+\t\t\t\tNULL, true);\n \n \tif (!dev) {\n \t\tret = -ENODEV;",
        "function_modified_lines": {
            "added": [
                "\t\t\t\tNULL, true);"
            ],
            "deleted": [
                "\t\t\t\tNULL);"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "fs/btrfs/volumes.c in the Linux kernel before 5.1 allows a btrfs_verify_dev_extents NULL pointer dereference via a crafted btrfs image because fs_devices->devices is mishandled within find_device, aka CID-09ba3bc9dd15.",
        "id": 2109
    },
    {
        "cve_id": "CVE-2018-1065",
        "code_before_change": "unsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.state   = state;\n\n\tWARN_ON(!(table->valid_hooks & (1 << hook)));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = READ_ONCE(table->private); /* Address dependency. */\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tWARN_ON(!e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target(e);\n\t\tWARN_ON(!t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO))\n\t\t\t\tjumpstack[stackidx++] = e;\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE) {\n\t\t\t/* Target might have changed stuff. */\n\t\t\tip = ip_hdr(skb);\n\t\t\te = ipt_next_entry(e);\n\t\t} else {\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t\t}\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n}",
        "code_after_change": "unsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.state   = state;\n\n\tWARN_ON(!(table->valid_hooks & (1 << hook)));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = READ_ONCE(table->private); /* Address dependency. */\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tWARN_ON(!e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target(e);\n\t\tWARN_ON(!t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n\t\t\t\tif (unlikely(stackidx >= private->stacksize)) {\n\t\t\t\t\tverdict = NF_DROP;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE) {\n\t\t\t/* Target might have changed stuff. */\n\t\t\tip = ip_hdr(skb);\n\t\t\te = ipt_next_entry(e);\n\t\t} else {\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t\t}\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n}",
        "patch": "--- code before\n+++ code after\n@@ -105,8 +105,13 @@\n \t\t\t\tcontinue;\n \t\t\t}\n \t\t\tif (table_base + v != ipt_next_entry(e) &&\n-\t\t\t    !(e->ip.flags & IPT_F_GOTO))\n+\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n+\t\t\t\tif (unlikely(stackidx >= private->stacksize)) {\n+\t\t\t\t\tverdict = NF_DROP;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n \t\t\t\tjumpstack[stackidx++] = e;\n+\t\t\t}\n \n \t\t\te = get_entry(table_base, v);\n \t\t\tcontinue;",
        "function_modified_lines": {
            "added": [
                "\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {",
                "\t\t\t\tif (unlikely(stackidx >= private->stacksize)) {",
                "\t\t\t\t\tverdict = NF_DROP;",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}",
                "\t\t\t}"
            ],
            "deleted": [
                "\t\t\t    !(e->ip.flags & IPT_F_GOTO))"
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The netfilter subsystem in the Linux kernel through 4.15.7 mishandles the case of a rule blob that contains a jump but lacks a user-defined chain, which allows local users to cause a denial of service (NULL pointer dereference) by leveraging the CAP_NET_RAW or CAP_NET_ADMIN capability, related to arpt_do_table in net/ipv4/netfilter/arp_tables.c, ipt_do_table in net/ipv4/netfilter/ip_tables.c, and ip6t_do_table in net/ipv6/netfilter/ip6_tables.c.",
        "id": 1589
    },
    {
        "cve_id": "CVE-2017-15102",
        "code_before_change": "static int tower_probe (struct usb_interface *interface, const struct usb_device_id *id)\n{\n\tstruct device *idev = &interface->dev;\n\tstruct usb_device *udev = interface_to_usbdev(interface);\n\tstruct lego_usb_tower *dev = NULL;\n\tstruct usb_host_interface *iface_desc;\n\tstruct usb_endpoint_descriptor* endpoint;\n\tstruct tower_get_version_reply get_version_reply;\n\tint i;\n\tint retval = -ENOMEM;\n\tint result;\n\n\t/* allocate memory for our device state and initialize it */\n\n\tdev = kmalloc (sizeof(struct lego_usb_tower), GFP_KERNEL);\n\n\tif (!dev)\n\t\tgoto exit;\n\n\tmutex_init(&dev->lock);\n\n\tdev->udev = udev;\n\tdev->open_count = 0;\n\n\tdev->read_buffer = NULL;\n\tdev->read_buffer_length = 0;\n\tdev->read_packet_length = 0;\n\tspin_lock_init (&dev->read_buffer_lock);\n\tdev->packet_timeout_jiffies = msecs_to_jiffies(packet_timeout);\n\tdev->read_last_arrival = jiffies;\n\n\tinit_waitqueue_head (&dev->read_wait);\n\tinit_waitqueue_head (&dev->write_wait);\n\n\tdev->interrupt_in_buffer = NULL;\n\tdev->interrupt_in_endpoint = NULL;\n\tdev->interrupt_in_urb = NULL;\n\tdev->interrupt_in_running = 0;\n\tdev->interrupt_in_done = 0;\n\n\tdev->interrupt_out_buffer = NULL;\n\tdev->interrupt_out_endpoint = NULL;\n\tdev->interrupt_out_urb = NULL;\n\tdev->interrupt_out_busy = 0;\n\n\tiface_desc = interface->cur_altsetting;\n\n\t/* set up the endpoint information */\n\tfor (i = 0; i < iface_desc->desc.bNumEndpoints; ++i) {\n\t\tendpoint = &iface_desc->endpoint[i].desc;\n\n\t\tif (usb_endpoint_xfer_int(endpoint)) {\n\t\t\tif (usb_endpoint_dir_in(endpoint))\n\t\t\t\tdev->interrupt_in_endpoint = endpoint;\n\t\t\telse\n\t\t\t\tdev->interrupt_out_endpoint = endpoint;\n\t\t}\n\t}\n\tif(dev->interrupt_in_endpoint == NULL) {\n\t\tdev_err(idev, \"interrupt in endpoint not found\\n\");\n\t\tgoto error;\n\t}\n\tif (dev->interrupt_out_endpoint == NULL) {\n\t\tdev_err(idev, \"interrupt out endpoint not found\\n\");\n\t\tgoto error;\n\t}\n\n\tdev->read_buffer = kmalloc (read_buffer_size, GFP_KERNEL);\n\tif (!dev->read_buffer)\n\t\tgoto error;\n\tdev->interrupt_in_buffer = kmalloc (usb_endpoint_maxp(dev->interrupt_in_endpoint), GFP_KERNEL);\n\tif (!dev->interrupt_in_buffer)\n\t\tgoto error;\n\tdev->interrupt_in_urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->interrupt_in_urb)\n\t\tgoto error;\n\tdev->interrupt_out_buffer = kmalloc (write_buffer_size, GFP_KERNEL);\n\tif (!dev->interrupt_out_buffer)\n\t\tgoto error;\n\tdev->interrupt_out_urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->interrupt_out_urb)\n\t\tgoto error;\n\tdev->interrupt_in_interval = interrupt_in_interval ? interrupt_in_interval : dev->interrupt_in_endpoint->bInterval;\n\tdev->interrupt_out_interval = interrupt_out_interval ? interrupt_out_interval : dev->interrupt_out_endpoint->bInterval;\n\n\t/* we can register the device now, as it is ready */\n\tusb_set_intfdata (interface, dev);\n\n\tretval = usb_register_dev (interface, &tower_class);\n\n\tif (retval) {\n\t\t/* something prevented us from registering this driver */\n\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");\n\t\tusb_set_intfdata (interface, NULL);\n\t\tgoto error;\n\t}\n\tdev->minor = interface->minor;\n\n\t/* let the user know what node this device is now attached to */\n\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"\n\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),\n\t\t USB_MAJOR, dev->minor);\n\n\t/* get the firmware version and log it */\n\tresult = usb_control_msg (udev,\n\t\t\t\t  usb_rcvctrlpipe(udev, 0),\n\t\t\t\t  LEGO_USB_TOWER_REQUEST_GET_VERSION,\n\t\t\t\t  USB_TYPE_VENDOR | USB_DIR_IN | USB_RECIP_DEVICE,\n\t\t\t\t  0,\n\t\t\t\t  0,\n\t\t\t\t  &get_version_reply,\n\t\t\t\t  sizeof(get_version_reply),\n\t\t\t\t  1000);\n\tif (result < 0) {\n\t\tdev_err(idev, \"LEGO USB Tower get version control request failed\\n\");\n\t\tretval = result;\n\t\tgoto error;\n\t}\n\tdev_info(&interface->dev, \"LEGO USB Tower firmware version is %d.%d \"\n\t\t \"build %d\\n\", get_version_reply.major,\n\t\t get_version_reply.minor,\n\t\t le16_to_cpu(get_version_reply.build_no));\n\n\nexit:\n\treturn retval;\n\nerror:\n\ttower_delete(dev);\n\treturn retval;\n}",
        "code_after_change": "static int tower_probe (struct usb_interface *interface, const struct usb_device_id *id)\n{\n\tstruct device *idev = &interface->dev;\n\tstruct usb_device *udev = interface_to_usbdev(interface);\n\tstruct lego_usb_tower *dev = NULL;\n\tstruct usb_host_interface *iface_desc;\n\tstruct usb_endpoint_descriptor* endpoint;\n\tstruct tower_get_version_reply get_version_reply;\n\tint i;\n\tint retval = -ENOMEM;\n\tint result;\n\n\t/* allocate memory for our device state and initialize it */\n\n\tdev = kmalloc (sizeof(struct lego_usb_tower), GFP_KERNEL);\n\n\tif (!dev)\n\t\tgoto exit;\n\n\tmutex_init(&dev->lock);\n\n\tdev->udev = udev;\n\tdev->open_count = 0;\n\n\tdev->read_buffer = NULL;\n\tdev->read_buffer_length = 0;\n\tdev->read_packet_length = 0;\n\tspin_lock_init (&dev->read_buffer_lock);\n\tdev->packet_timeout_jiffies = msecs_to_jiffies(packet_timeout);\n\tdev->read_last_arrival = jiffies;\n\n\tinit_waitqueue_head (&dev->read_wait);\n\tinit_waitqueue_head (&dev->write_wait);\n\n\tdev->interrupt_in_buffer = NULL;\n\tdev->interrupt_in_endpoint = NULL;\n\tdev->interrupt_in_urb = NULL;\n\tdev->interrupt_in_running = 0;\n\tdev->interrupt_in_done = 0;\n\n\tdev->interrupt_out_buffer = NULL;\n\tdev->interrupt_out_endpoint = NULL;\n\tdev->interrupt_out_urb = NULL;\n\tdev->interrupt_out_busy = 0;\n\n\tiface_desc = interface->cur_altsetting;\n\n\t/* set up the endpoint information */\n\tfor (i = 0; i < iface_desc->desc.bNumEndpoints; ++i) {\n\t\tendpoint = &iface_desc->endpoint[i].desc;\n\n\t\tif (usb_endpoint_xfer_int(endpoint)) {\n\t\t\tif (usb_endpoint_dir_in(endpoint))\n\t\t\t\tdev->interrupt_in_endpoint = endpoint;\n\t\t\telse\n\t\t\t\tdev->interrupt_out_endpoint = endpoint;\n\t\t}\n\t}\n\tif(dev->interrupt_in_endpoint == NULL) {\n\t\tdev_err(idev, \"interrupt in endpoint not found\\n\");\n\t\tgoto error;\n\t}\n\tif (dev->interrupt_out_endpoint == NULL) {\n\t\tdev_err(idev, \"interrupt out endpoint not found\\n\");\n\t\tgoto error;\n\t}\n\n\tdev->read_buffer = kmalloc (read_buffer_size, GFP_KERNEL);\n\tif (!dev->read_buffer)\n\t\tgoto error;\n\tdev->interrupt_in_buffer = kmalloc (usb_endpoint_maxp(dev->interrupt_in_endpoint), GFP_KERNEL);\n\tif (!dev->interrupt_in_buffer)\n\t\tgoto error;\n\tdev->interrupt_in_urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->interrupt_in_urb)\n\t\tgoto error;\n\tdev->interrupt_out_buffer = kmalloc (write_buffer_size, GFP_KERNEL);\n\tif (!dev->interrupt_out_buffer)\n\t\tgoto error;\n\tdev->interrupt_out_urb = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->interrupt_out_urb)\n\t\tgoto error;\n\tdev->interrupt_in_interval = interrupt_in_interval ? interrupt_in_interval : dev->interrupt_in_endpoint->bInterval;\n\tdev->interrupt_out_interval = interrupt_out_interval ? interrupt_out_interval : dev->interrupt_out_endpoint->bInterval;\n\n\t/* get the firmware version and log it */\n\tresult = usb_control_msg (udev,\n\t\t\t\t  usb_rcvctrlpipe(udev, 0),\n\t\t\t\t  LEGO_USB_TOWER_REQUEST_GET_VERSION,\n\t\t\t\t  USB_TYPE_VENDOR | USB_DIR_IN | USB_RECIP_DEVICE,\n\t\t\t\t  0,\n\t\t\t\t  0,\n\t\t\t\t  &get_version_reply,\n\t\t\t\t  sizeof(get_version_reply),\n\t\t\t\t  1000);\n\tif (result < 0) {\n\t\tdev_err(idev, \"LEGO USB Tower get version control request failed\\n\");\n\t\tretval = result;\n\t\tgoto error;\n\t}\n\tdev_info(&interface->dev, \"LEGO USB Tower firmware version is %d.%d \"\n\t\t \"build %d\\n\", get_version_reply.major,\n\t\t get_version_reply.minor,\n\t\t le16_to_cpu(get_version_reply.build_no));\n\n\t/* we can register the device now, as it is ready */\n\tusb_set_intfdata (interface, dev);\n\n\tretval = usb_register_dev (interface, &tower_class);\n\n\tif (retval) {\n\t\t/* something prevented us from registering this driver */\n\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");\n\t\tusb_set_intfdata (interface, NULL);\n\t\tgoto error;\n\t}\n\tdev->minor = interface->minor;\n\n\t/* let the user know what node this device is now attached to */\n\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"\n\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),\n\t\t USB_MAJOR, dev->minor);\n\nexit:\n\treturn retval;\n\nerror:\n\ttower_delete(dev);\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -83,24 +83,6 @@\n \tdev->interrupt_in_interval = interrupt_in_interval ? interrupt_in_interval : dev->interrupt_in_endpoint->bInterval;\n \tdev->interrupt_out_interval = interrupt_out_interval ? interrupt_out_interval : dev->interrupt_out_endpoint->bInterval;\n \n-\t/* we can register the device now, as it is ready */\n-\tusb_set_intfdata (interface, dev);\n-\n-\tretval = usb_register_dev (interface, &tower_class);\n-\n-\tif (retval) {\n-\t\t/* something prevented us from registering this driver */\n-\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");\n-\t\tusb_set_intfdata (interface, NULL);\n-\t\tgoto error;\n-\t}\n-\tdev->minor = interface->minor;\n-\n-\t/* let the user know what node this device is now attached to */\n-\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"\n-\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),\n-\t\t USB_MAJOR, dev->minor);\n-\n \t/* get the firmware version and log it */\n \tresult = usb_control_msg (udev,\n \t\t\t\t  usb_rcvctrlpipe(udev, 0),\n@@ -121,6 +103,23 @@\n \t\t get_version_reply.minor,\n \t\t le16_to_cpu(get_version_reply.build_no));\n \n+\t/* we can register the device now, as it is ready */\n+\tusb_set_intfdata (interface, dev);\n+\n+\tretval = usb_register_dev (interface, &tower_class);\n+\n+\tif (retval) {\n+\t\t/* something prevented us from registering this driver */\n+\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");\n+\t\tusb_set_intfdata (interface, NULL);\n+\t\tgoto error;\n+\t}\n+\tdev->minor = interface->minor;\n+\n+\t/* let the user know what node this device is now attached to */\n+\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"\n+\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),\n+\t\t USB_MAJOR, dev->minor);\n \n exit:\n \treturn retval;",
        "function_modified_lines": {
            "added": [
                "\t/* we can register the device now, as it is ready */",
                "\tusb_set_intfdata (interface, dev);",
                "",
                "\tretval = usb_register_dev (interface, &tower_class);",
                "",
                "\tif (retval) {",
                "\t\t/* something prevented us from registering this driver */",
                "\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");",
                "\t\tusb_set_intfdata (interface, NULL);",
                "\t\tgoto error;",
                "\t}",
                "\tdev->minor = interface->minor;",
                "",
                "\t/* let the user know what node this device is now attached to */",
                "\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"",
                "\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),",
                "\t\t USB_MAJOR, dev->minor);"
            ],
            "deleted": [
                "\t/* we can register the device now, as it is ready */",
                "\tusb_set_intfdata (interface, dev);",
                "",
                "\tretval = usb_register_dev (interface, &tower_class);",
                "",
                "\tif (retval) {",
                "\t\t/* something prevented us from registering this driver */",
                "\t\tdev_err(idev, \"Not able to get a minor for this device.\\n\");",
                "\t\tusb_set_intfdata (interface, NULL);",
                "\t\tgoto error;",
                "\t}",
                "\tdev->minor = interface->minor;",
                "",
                "\t/* let the user know what node this device is now attached to */",
                "\tdev_info(&interface->dev, \"LEGO USB Tower #%d now attached to major \"",
                "\t\t \"%d minor %d\\n\", (dev->minor - LEGO_USB_TOWER_MINOR_BASE),",
                "\t\t USB_MAJOR, dev->minor);",
                ""
            ]
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "The tower_probe function in drivers/usb/misc/legousbtower.c in the Linux kernel before 4.8.1 allows local users (who are physically proximate for inserting a crafted USB device) to gain privileges by leveraging a write-what-where condition that occurs after a race condition and a NULL pointer dereference.",
        "id": 1288
    },
    {
        "cve_id": "CVE-2019-12615",
        "code_before_change": "static int get_vdev_port_node_info(struct mdesc_handle *md, u64 node,\n\t\t\t\t   union md_node_info *node_info)\n{\n\tconst u64 *parent_cfg_hdlp;\n\tconst char *name;\n\tconst u64 *idp;\n\n\t/*\n\t * Virtual device nodes are distinguished by:\n\t * 1. \"id\" property\n\t * 2. \"name\" property\n\t * 3. parent node \"cfg-handle\" property\n\t */\n\tidp = mdesc_get_property(md, node, \"id\", NULL);\n\tname = mdesc_get_property(md, node, \"name\", NULL);\n\tparent_cfg_hdlp = parent_cfg_handle(md, node);\n\n\tif (!idp || !name || !parent_cfg_hdlp)\n\t\treturn -1;\n\n\tnode_info->vdev_port.id = *idp;\n\tnode_info->vdev_port.name = kstrdup_const(name, GFP_KERNEL);\n\tnode_info->vdev_port.parent_cfg_hdl = *parent_cfg_hdlp;\n\n\treturn 0;\n}",
        "code_after_change": "static int get_vdev_port_node_info(struct mdesc_handle *md, u64 node,\n\t\t\t\t   union md_node_info *node_info)\n{\n\tconst u64 *parent_cfg_hdlp;\n\tconst char *name;\n\tconst u64 *idp;\n\n\t/*\n\t * Virtual device nodes are distinguished by:\n\t * 1. \"id\" property\n\t * 2. \"name\" property\n\t * 3. parent node \"cfg-handle\" property\n\t */\n\tidp = mdesc_get_property(md, node, \"id\", NULL);\n\tname = mdesc_get_property(md, node, \"name\", NULL);\n\tparent_cfg_hdlp = parent_cfg_handle(md, node);\n\n\tif (!idp || !name || !parent_cfg_hdlp)\n\t\treturn -1;\n\n\tnode_info->vdev_port.id = *idp;\n\tnode_info->vdev_port.name = kstrdup_const(name, GFP_KERNEL);\n\tif (!node_info->vdev_port.name)\n\t\treturn -1;\n\tnode_info->vdev_port.parent_cfg_hdl = *parent_cfg_hdlp;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,6 +20,8 @@\n \n \tnode_info->vdev_port.id = *idp;\n \tnode_info->vdev_port.name = kstrdup_const(name, GFP_KERNEL);\n+\tif (!node_info->vdev_port.name)\n+\t\treturn -1;\n \tnode_info->vdev_port.parent_cfg_hdl = *parent_cfg_hdlp;\n \n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tif (!node_info->vdev_port.name)",
                "\t\treturn -1;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-476"
        ],
        "cve_description": "An issue was discovered in get_vdev_port_node_info in arch/sparc/kernel/mdesc.c in the Linux kernel through 5.1.6. There is an unchecked kstrdup_const of node_info->vdev_port.name, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash).",
        "id": 1949
    }
]