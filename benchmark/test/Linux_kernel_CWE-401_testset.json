[
    {
        "cve_id": "CVE-2022-3624",
        "code_before_change": "static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)\n{\n\tstruct slave *tx_slave = NULL;\n\tstruct net_device *dev;\n\tstruct arp_pkt *arp;\n\n\tif (!pskb_network_may_pull(skb, sizeof(*arp)))\n\t\treturn NULL;\n\tarp = (struct arp_pkt *)skb_network_header(skb);\n\n\t/* Don't modify or load balance ARPs that do not originate locally\n\t * (e.g.,arrive via a bridge).\n\t */\n\tif (!bond_slave_has_mac_rx(bond, arp->mac_src))\n\t\treturn NULL;\n\n\tdev = ip_dev_find(dev_net(bond->dev), arp->ip_src);\n\tif (dev) {\n\t\tif (netif_is_bridge_master(dev))\n\t\t\treturn NULL;\n\t}\n\n\tif (arp->op_code == htons(ARPOP_REPLY)) {\n\t\t/* the arp must be sent on the selected rx channel */\n\t\ttx_slave = rlb_choose_channel(skb, bond, arp);\n\t\tif (tx_slave)\n\t\t\tbond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,\n\t\t\t\t\t  tx_slave->dev->addr_len);\n\t\tnetdev_dbg(bond->dev, \"(slave %s): Server sent ARP Reply packet\\n\",\n\t\t\t   tx_slave ? tx_slave->dev->name : \"NULL\");\n\t} else if (arp->op_code == htons(ARPOP_REQUEST)) {\n\t\t/* Create an entry in the rx_hashtbl for this client as a\n\t\t * place holder.\n\t\t * When the arp reply is received the entry will be updated\n\t\t * with the correct unicast address of the client.\n\t\t */\n\t\ttx_slave = rlb_choose_channel(skb, bond, arp);\n\n\t\t/* The ARP reply packets must be delayed so that\n\t\t * they can cancel out the influence of the ARP request.\n\t\t */\n\t\tbond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;\n\n\t\t/* arp requests are broadcast and are sent on the primary\n\t\t * the arp request will collapse all clients on the subnet to\n\t\t * the primary slave. We must register these clients to be\n\t\t * updated with their assigned mac.\n\t\t */\n\t\trlb_req_update_subnet_clients(bond, arp->ip_src);\n\t\tnetdev_dbg(bond->dev, \"(slave %s): Server sent ARP Request packet\\n\",\n\t\t\t   tx_slave ? tx_slave->dev->name : \"NULL\");\n\t}\n\n\treturn tx_slave;\n}",
        "code_after_change": "static struct slave *rlb_arp_xmit(struct sk_buff *skb, struct bonding *bond)\n{\n\tstruct slave *tx_slave = NULL;\n\tstruct net_device *dev;\n\tstruct arp_pkt *arp;\n\n\tif (!pskb_network_may_pull(skb, sizeof(*arp)))\n\t\treturn NULL;\n\tarp = (struct arp_pkt *)skb_network_header(skb);\n\n\t/* Don't modify or load balance ARPs that do not originate locally\n\t * (e.g.,arrive via a bridge).\n\t */\n\tif (!bond_slave_has_mac_rx(bond, arp->mac_src))\n\t\treturn NULL;\n\n\tdev = ip_dev_find(dev_net(bond->dev), arp->ip_src);\n\tif (dev) {\n\t\tif (netif_is_bridge_master(dev)) {\n\t\t\tdev_put(dev);\n\t\t\treturn NULL;\n\t\t}\n\t\tdev_put(dev);\n\t}\n\n\tif (arp->op_code == htons(ARPOP_REPLY)) {\n\t\t/* the arp must be sent on the selected rx channel */\n\t\ttx_slave = rlb_choose_channel(skb, bond, arp);\n\t\tif (tx_slave)\n\t\t\tbond_hw_addr_copy(arp->mac_src, tx_slave->dev->dev_addr,\n\t\t\t\t\t  tx_slave->dev->addr_len);\n\t\tnetdev_dbg(bond->dev, \"(slave %s): Server sent ARP Reply packet\\n\",\n\t\t\t   tx_slave ? tx_slave->dev->name : \"NULL\");\n\t} else if (arp->op_code == htons(ARPOP_REQUEST)) {\n\t\t/* Create an entry in the rx_hashtbl for this client as a\n\t\t * place holder.\n\t\t * When the arp reply is received the entry will be updated\n\t\t * with the correct unicast address of the client.\n\t\t */\n\t\ttx_slave = rlb_choose_channel(skb, bond, arp);\n\n\t\t/* The ARP reply packets must be delayed so that\n\t\t * they can cancel out the influence of the ARP request.\n\t\t */\n\t\tbond->alb_info.rlb_update_delay_counter = RLB_UPDATE_DELAY;\n\n\t\t/* arp requests are broadcast and are sent on the primary\n\t\t * the arp request will collapse all clients on the subnet to\n\t\t * the primary slave. We must register these clients to be\n\t\t * updated with their assigned mac.\n\t\t */\n\t\trlb_req_update_subnet_clients(bond, arp->ip_src);\n\t\tnetdev_dbg(bond->dev, \"(slave %s): Server sent ARP Request packet\\n\",\n\t\t\t   tx_slave ? tx_slave->dev->name : \"NULL\");\n\t}\n\n\treturn tx_slave;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,8 +16,11 @@\n \n \tdev = ip_dev_find(dev_net(bond->dev), arp->ip_src);\n \tif (dev) {\n-\t\tif (netif_is_bridge_master(dev))\n+\t\tif (netif_is_bridge_master(dev)) {\n+\t\t\tdev_put(dev);\n \t\t\treturn NULL;\n+\t\t}\n+\t\tdev_put(dev);\n \t}\n \n \tif (arp->op_code == htons(ARPOP_REPLY)) {",
        "function_modified_lines": {
            "added": [
                "\t\tif (netif_is_bridge_master(dev)) {",
                "\t\t\tdev_put(dev);",
                "\t\t}",
                "\t\tdev_put(dev);"
            ],
            "deleted": [
                "\t\tif (netif_is_bridge_master(dev))"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel and classified as problematic. Affected by this issue is the function rlb_arp_xmit of the file drivers/net/bonding/bond_alb.c of the component IPsec. The manipulation leads to memory leak. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211928.",
        "id": 3659
    },
    {
        "cve_id": "CVE-2019-19063",
        "code_before_change": "int rtl_usb_probe(struct usb_interface *intf,\n\t\t  const struct usb_device_id *id,\n\t\t  struct rtl_hal_cfg *rtl_hal_cfg)\n{\n\tint err;\n\tstruct ieee80211_hw *hw = NULL;\n\tstruct rtl_priv *rtlpriv = NULL;\n\tstruct usb_device\t*udev;\n\tstruct rtl_usb_priv *usb_priv;\n\n\thw = ieee80211_alloc_hw(sizeof(struct rtl_priv) +\n\t\t\t\tsizeof(struct rtl_usb_priv), &rtl_ops);\n\tif (!hw) {\n\t\tWARN_ONCE(true, \"rtl_usb: ieee80211 alloc failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\trtlpriv = hw->priv;\n\trtlpriv->hw = hw;\n\trtlpriv->usb_data = kcalloc(RTL_USB_MAX_RX_COUNT, sizeof(u32),\n\t\t\t\t    GFP_KERNEL);\n\tif (!rtlpriv->usb_data)\n\t\treturn -ENOMEM;\n\n\t/* this spin lock must be initialized early */\n\tspin_lock_init(&rtlpriv->locks.usb_lock);\n\tINIT_WORK(&rtlpriv->works.fill_h2c_cmd,\n\t\t  rtl_fill_h2c_cmd_work_callback);\n\tINIT_WORK(&rtlpriv->works.lps_change_work,\n\t\t  rtl_lps_change_work_callback);\n\n\trtlpriv->usb_data_index = 0;\n\tinit_completion(&rtlpriv->firmware_loading_complete);\n\tSET_IEEE80211_DEV(hw, &intf->dev);\n\tudev = interface_to_usbdev(intf);\n\tusb_get_dev(udev);\n\tusb_priv = rtl_usbpriv(hw);\n\tmemset(usb_priv, 0, sizeof(*usb_priv));\n\tusb_priv->dev.intf = intf;\n\tusb_priv->dev.udev = udev;\n\tusb_set_intfdata(intf, hw);\n\t/* init cfg & intf_ops */\n\trtlpriv->rtlhal.interface = INTF_USB;\n\trtlpriv->cfg = rtl_hal_cfg;\n\trtlpriv->intf_ops = &rtl_usb_ops;\n\t/* Init IO handler */\n\t_rtl_usb_io_handler_init(&udev->dev, hw);\n\trtlpriv->cfg->ops->read_chip_version(hw);\n\t/*like read eeprom and so on */\n\trtlpriv->cfg->ops->read_eeprom_info(hw);\n\terr = _rtl_usb_init(hw);\n\tif (err)\n\t\tgoto error_out2;\n\trtl_usb_init_sw(hw);\n\t/* Init mac80211 sw */\n\terr = rtl_init_core(hw);\n\tif (err) {\n\t\tpr_err(\"Can't allocate sw for mac80211\\n\");\n\t\tgoto error_out2;\n\t}\n\tif (rtlpriv->cfg->ops->init_sw_vars(hw)) {\n\t\tpr_err(\"Can't init_sw_vars\\n\");\n\t\tgoto error_out;\n\t}\n\trtlpriv->cfg->ops->init_sw_leds(hw);\n\n\terr = ieee80211_register_hw(hw);\n\tif (err) {\n\t\tpr_err(\"Can't register mac80211 hw.\\n\");\n\t\terr = -ENODEV;\n\t\tgoto error_out;\n\t}\n\trtlpriv->mac80211.mac80211_registered = 1;\n\n\tset_bit(RTL_STATUS_INTERFACE_START, &rtlpriv->status);\n\treturn 0;\n\nerror_out:\n\trtl_deinit_core(hw);\nerror_out2:\n\t_rtl_usb_io_handler_release(hw);\n\tusb_put_dev(udev);\n\tcomplete(&rtlpriv->firmware_loading_complete);\n\treturn -ENODEV;\n}",
        "code_after_change": "int rtl_usb_probe(struct usb_interface *intf,\n\t\t  const struct usb_device_id *id,\n\t\t  struct rtl_hal_cfg *rtl_hal_cfg)\n{\n\tint err;\n\tstruct ieee80211_hw *hw = NULL;\n\tstruct rtl_priv *rtlpriv = NULL;\n\tstruct usb_device\t*udev;\n\tstruct rtl_usb_priv *usb_priv;\n\n\thw = ieee80211_alloc_hw(sizeof(struct rtl_priv) +\n\t\t\t\tsizeof(struct rtl_usb_priv), &rtl_ops);\n\tif (!hw) {\n\t\tWARN_ONCE(true, \"rtl_usb: ieee80211 alloc failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\trtlpriv = hw->priv;\n\trtlpriv->hw = hw;\n\trtlpriv->usb_data = kcalloc(RTL_USB_MAX_RX_COUNT, sizeof(u32),\n\t\t\t\t    GFP_KERNEL);\n\tif (!rtlpriv->usb_data) {\n\t\tieee80211_free_hw(hw);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* this spin lock must be initialized early */\n\tspin_lock_init(&rtlpriv->locks.usb_lock);\n\tINIT_WORK(&rtlpriv->works.fill_h2c_cmd,\n\t\t  rtl_fill_h2c_cmd_work_callback);\n\tINIT_WORK(&rtlpriv->works.lps_change_work,\n\t\t  rtl_lps_change_work_callback);\n\n\trtlpriv->usb_data_index = 0;\n\tinit_completion(&rtlpriv->firmware_loading_complete);\n\tSET_IEEE80211_DEV(hw, &intf->dev);\n\tudev = interface_to_usbdev(intf);\n\tusb_get_dev(udev);\n\tusb_priv = rtl_usbpriv(hw);\n\tmemset(usb_priv, 0, sizeof(*usb_priv));\n\tusb_priv->dev.intf = intf;\n\tusb_priv->dev.udev = udev;\n\tusb_set_intfdata(intf, hw);\n\t/* init cfg & intf_ops */\n\trtlpriv->rtlhal.interface = INTF_USB;\n\trtlpriv->cfg = rtl_hal_cfg;\n\trtlpriv->intf_ops = &rtl_usb_ops;\n\t/* Init IO handler */\n\t_rtl_usb_io_handler_init(&udev->dev, hw);\n\trtlpriv->cfg->ops->read_chip_version(hw);\n\t/*like read eeprom and so on */\n\trtlpriv->cfg->ops->read_eeprom_info(hw);\n\terr = _rtl_usb_init(hw);\n\tif (err)\n\t\tgoto error_out2;\n\trtl_usb_init_sw(hw);\n\t/* Init mac80211 sw */\n\terr = rtl_init_core(hw);\n\tif (err) {\n\t\tpr_err(\"Can't allocate sw for mac80211\\n\");\n\t\tgoto error_out2;\n\t}\n\tif (rtlpriv->cfg->ops->init_sw_vars(hw)) {\n\t\tpr_err(\"Can't init_sw_vars\\n\");\n\t\tgoto error_out;\n\t}\n\trtlpriv->cfg->ops->init_sw_leds(hw);\n\n\terr = ieee80211_register_hw(hw);\n\tif (err) {\n\t\tpr_err(\"Can't register mac80211 hw.\\n\");\n\t\terr = -ENODEV;\n\t\tgoto error_out;\n\t}\n\trtlpriv->mac80211.mac80211_registered = 1;\n\n\tset_bit(RTL_STATUS_INTERFACE_START, &rtlpriv->status);\n\treturn 0;\n\nerror_out:\n\trtl_deinit_core(hw);\nerror_out2:\n\t_rtl_usb_io_handler_release(hw);\n\tusb_put_dev(udev);\n\tcomplete(&rtlpriv->firmware_loading_complete);\n\tkfree(rtlpriv->usb_data);\n\treturn -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,8 +18,10 @@\n \trtlpriv->hw = hw;\n \trtlpriv->usb_data = kcalloc(RTL_USB_MAX_RX_COUNT, sizeof(u32),\n \t\t\t\t    GFP_KERNEL);\n-\tif (!rtlpriv->usb_data)\n+\tif (!rtlpriv->usb_data) {\n+\t\tieee80211_free_hw(hw);\n \t\treturn -ENOMEM;\n+\t}\n \n \t/* this spin lock must be initialized early */\n \tspin_lock_init(&rtlpriv->locks.usb_lock);\n@@ -80,5 +82,6 @@\n \t_rtl_usb_io_handler_release(hw);\n \tusb_put_dev(udev);\n \tcomplete(&rtlpriv->firmware_loading_complete);\n+\tkfree(rtlpriv->usb_data);\n \treturn -ENODEV;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!rtlpriv->usb_data) {",
                "\t\tieee80211_free_hw(hw);",
                "\t}",
                "\tkfree(rtlpriv->usb_data);"
            ],
            "deleted": [
                "\tif (!rtlpriv->usb_data)"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Two memory leaks in the rtl_usb_probe() function in drivers/net/wireless/realtek/rtlwifi/usb.c in the Linux kernel through 5.3.11 allow attackers to cause a denial of service (memory consumption), aka CID-3f9361695113.",
        "id": 2144
    },
    {
        "cve_id": "CVE-2019-18810",
        "code_before_change": "static int komeda_wb_connector_add(struct komeda_kms_dev *kms,\n\t\t\t\t   struct komeda_crtc *kcrtc)\n{\n\tstruct komeda_dev *mdev = kms->base.dev_private;\n\tstruct komeda_wb_connector *kwb_conn;\n\tstruct drm_writeback_connector *wb_conn;\n\tu32 *formats, n_formats = 0;\n\tint err;\n\n\tif (!kcrtc->master->wb_layer)\n\t\treturn 0;\n\n\tkwb_conn = kzalloc(sizeof(*kwb_conn), GFP_KERNEL);\n\tif (!kwb_conn)\n\t\treturn -ENOMEM;\n\n\tkwb_conn->wb_layer = kcrtc->master->wb_layer;\n\n\twb_conn = &kwb_conn->base;\n\twb_conn->encoder.possible_crtcs = BIT(drm_crtc_index(&kcrtc->base));\n\n\tformats = komeda_get_layer_fourcc_list(&mdev->fmt_tbl,\n\t\t\t\t\t       kwb_conn->wb_layer->layer_type,\n\t\t\t\t\t       &n_formats);\n\n\terr = drm_writeback_connector_init(&kms->base, wb_conn,\n\t\t\t\t\t   &komeda_wb_connector_funcs,\n\t\t\t\t\t   &komeda_wb_encoder_helper_funcs,\n\t\t\t\t\t   formats, n_formats);\n\tkomeda_put_fourcc_list(formats);\n\tif (err)\n\t\treturn err;\n\n\tdrm_connector_helper_add(&wb_conn->base, &komeda_wb_conn_helper_funcs);\n\n\tkcrtc->wb_conn = kwb_conn;\n\n\treturn 0;\n}",
        "code_after_change": "static int komeda_wb_connector_add(struct komeda_kms_dev *kms,\n\t\t\t\t   struct komeda_crtc *kcrtc)\n{\n\tstruct komeda_dev *mdev = kms->base.dev_private;\n\tstruct komeda_wb_connector *kwb_conn;\n\tstruct drm_writeback_connector *wb_conn;\n\tu32 *formats, n_formats = 0;\n\tint err;\n\n\tif (!kcrtc->master->wb_layer)\n\t\treturn 0;\n\n\tkwb_conn = kzalloc(sizeof(*kwb_conn), GFP_KERNEL);\n\tif (!kwb_conn)\n\t\treturn -ENOMEM;\n\n\tkwb_conn->wb_layer = kcrtc->master->wb_layer;\n\n\twb_conn = &kwb_conn->base;\n\twb_conn->encoder.possible_crtcs = BIT(drm_crtc_index(&kcrtc->base));\n\n\tformats = komeda_get_layer_fourcc_list(&mdev->fmt_tbl,\n\t\t\t\t\t       kwb_conn->wb_layer->layer_type,\n\t\t\t\t\t       &n_formats);\n\n\terr = drm_writeback_connector_init(&kms->base, wb_conn,\n\t\t\t\t\t   &komeda_wb_connector_funcs,\n\t\t\t\t\t   &komeda_wb_encoder_helper_funcs,\n\t\t\t\t\t   formats, n_formats);\n\tkomeda_put_fourcc_list(formats);\n\tif (err) {\n\t\tkfree(kwb_conn);\n\t\treturn err;\n\t}\n\n\tdrm_connector_helper_add(&wb_conn->base, &komeda_wb_conn_helper_funcs);\n\n\tkcrtc->wb_conn = kwb_conn;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -28,8 +28,10 @@\n \t\t\t\t\t   &komeda_wb_encoder_helper_funcs,\n \t\t\t\t\t   formats, n_formats);\n \tkomeda_put_fourcc_list(formats);\n-\tif (err)\n+\tif (err) {\n+\t\tkfree(kwb_conn);\n \t\treturn err;\n+\t}\n \n \tdrm_connector_helper_add(&wb_conn->base, &komeda_wb_conn_helper_funcs);\n ",
        "function_modified_lines": {
            "added": [
                "\tif (err) {",
                "\t\tkfree(kwb_conn);",
                "\t}"
            ],
            "deleted": [
                "\tif (err)"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the komeda_wb_connector_add() function in drivers/gpu/drm/arm/display/komeda/komeda_wb_connector.c in the Linux kernel before 5.3.8 allows attackers to cause a denial of service (memory consumption) by triggering drm_writeback_connector_init() failures, aka CID-a0ecd6fdbf5d.",
        "id": 2102
    },
    {
        "cve_id": "CVE-2019-15916",
        "code_before_change": "static int register_queue_kobjects(struct net_device *dev)\n{\n\tint error = 0, txq = 0, rxq = 0, real_rx = 0, real_tx = 0;\n\n#ifdef CONFIG_SYSFS\n\tdev->queues_kset = kset_create_and_add(\"queues\",\n\t\t\t\t\t       NULL, &dev->dev.kobj);\n\tif (!dev->queues_kset)\n\t\treturn -ENOMEM;\n\treal_rx = dev->real_num_rx_queues;\n#endif\n\treal_tx = dev->real_num_tx_queues;\n\n\terror = net_rx_queue_update_kobjects(dev, 0, real_rx);\n\tif (error)\n\t\tgoto error;\n\trxq = real_rx;\n\n\terror = netdev_queue_update_kobjects(dev, 0, real_tx);\n\tif (error)\n\t\tgoto error;\n\ttxq = real_tx;\n\n\treturn 0;\n\nerror:\n\tnetdev_queue_update_kobjects(dev, txq, 0);\n\tnet_rx_queue_update_kobjects(dev, rxq, 0);\n\treturn error;\n}",
        "code_after_change": "static int register_queue_kobjects(struct net_device *dev)\n{\n\tint error = 0, txq = 0, rxq = 0, real_rx = 0, real_tx = 0;\n\n#ifdef CONFIG_SYSFS\n\tdev->queues_kset = kset_create_and_add(\"queues\",\n\t\t\t\t\t       NULL, &dev->dev.kobj);\n\tif (!dev->queues_kset)\n\t\treturn -ENOMEM;\n\treal_rx = dev->real_num_rx_queues;\n#endif\n\treal_tx = dev->real_num_tx_queues;\n\n\terror = net_rx_queue_update_kobjects(dev, 0, real_rx);\n\tif (error)\n\t\tgoto error;\n\trxq = real_rx;\n\n\terror = netdev_queue_update_kobjects(dev, 0, real_tx);\n\tif (error)\n\t\tgoto error;\n\ttxq = real_tx;\n\n\treturn 0;\n\nerror:\n\tnetdev_queue_update_kobjects(dev, txq, 0);\n\tnet_rx_queue_update_kobjects(dev, rxq, 0);\n#ifdef CONFIG_SYSFS\n\tkset_unregister(dev->queues_kset);\n#endif\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -26,5 +26,8 @@\n error:\n \tnetdev_queue_update_kobjects(dev, txq, 0);\n \tnet_rx_queue_update_kobjects(dev, rxq, 0);\n+#ifdef CONFIG_SYSFS\n+\tkset_unregister(dev->queues_kset);\n+#endif\n \treturn error;\n }",
        "function_modified_lines": {
            "added": [
                "#ifdef CONFIG_SYSFS",
                "\tkset_unregister(dev->queues_kset);",
                "#endif"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.0.1. There is a memory leak in register_queue_kobjects() in net/core/net-sysfs.c, which will cause denial of service.",
        "id": 2023
    },
    {
        "cve_id": "CVE-2019-19046",
        "code_before_change": "static int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num)\n{\n\tint               rv;\n\tstruct bmc_device *bmc;\n\tstruct bmc_device *old_bmc;\n\n\t/*\n\t * platform_device_register() can cause bmc_reg_mutex to\n\t * be claimed because of the is_visible functions of\n\t * the attributes.  Eliminate possible recursion and\n\t * release the lock.\n\t */\n\tintf->in_bmc_register = true;\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\t/*\n\t * Try to find if there is an bmc_device struct\n\t * representing the interfaced BMC already\n\t */\n\tmutex_lock(&ipmidriver_mutex);\n\tif (guid_set)\n\t\told_bmc = ipmi_find_bmc_guid(&ipmidriver.driver, guid);\n\telse\n\t\told_bmc = ipmi_find_bmc_prod_dev_id(&ipmidriver.driver,\n\t\t\t\t\t\t    id->product_id,\n\t\t\t\t\t\t    id->device_id);\n\n\t/*\n\t * If there is already an bmc_device, free the new one,\n\t * otherwise register the new BMC device\n\t */\n\tif (old_bmc) {\n\t\tbmc = old_bmc;\n\t\t/*\n\t\t * Note: old_bmc already has usecount incremented by\n\t\t * the BMC find functions.\n\t\t */\n\t\tintf->bmc = old_bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"interfacing existing BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t} else {\n\t\tbmc = kzalloc(sizeof(*bmc), GFP_KERNEL);\n\t\tif (!bmc) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tINIT_LIST_HEAD(&bmc->intfs);\n\t\tmutex_init(&bmc->dyn_mutex);\n\t\tINIT_WORK(&bmc->remove_work, cleanup_bmc_work);\n\n\t\tbmc->id = *id;\n\t\tbmc->dyn_id_set = 1;\n\t\tbmc->dyn_guid_set = guid_set;\n\t\tbmc->guid = *guid;\n\t\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\n\t\tbmc->pdev.name = \"ipmi_bmc\";\n\n\t\trv = ida_simple_get(&ipmi_bmc_ida, 0, 0, GFP_KERNEL);\n\t\tif (rv < 0)\n\t\t\tgoto out;\n\t\tbmc->pdev.dev.driver = &ipmidriver.driver;\n\t\tbmc->pdev.id = rv;\n\t\tbmc->pdev.dev.release = release_bmc_device;\n\t\tbmc->pdev.dev.type = &bmc_device_type;\n\t\tkref_init(&bmc->usecount);\n\n\t\tintf->bmc = bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\trv = platform_device_register(&bmc->pdev);\n\t\tif (rv) {\n\t\t\tdev_err(intf->si_dev,\n\t\t\t\t\"Unable to register bmc device: %d\\n\",\n\t\t\t\trv);\n\t\t\tgoto out_list_del;\n\t\t}\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"Found new BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t}\n\n\t/*\n\t * create symlink from system interface device to bmc device\n\t * and back.\n\t */\n\trv = sysfs_create_link(&intf->si_dev->kobj, &bmc->pdev.dev.kobj, \"bmc\");\n\tif (rv) {\n\t\tdev_err(intf->si_dev, \"Unable to create bmc symlink: %d\\n\", rv);\n\t\tgoto out_put_bmc;\n\t}\n\n\tif (intf_num == -1)\n\t\tintf_num = intf->intf_num;\n\tintf->my_dev_name = kasprintf(GFP_KERNEL, \"ipmi%d\", intf_num);\n\tif (!intf->my_dev_name) {\n\t\trv = -ENOMEM;\n\t\tdev_err(intf->si_dev, \"Unable to allocate link from BMC: %d\\n\",\n\t\t\trv);\n\t\tgoto out_unlink1;\n\t}\n\n\trv = sysfs_create_link(&bmc->pdev.dev.kobj, &intf->si_dev->kobj,\n\t\t\t       intf->my_dev_name);\n\tif (rv) {\n\t\tkfree(intf->my_dev_name);\n\t\tintf->my_dev_name = NULL;\n\t\tdev_err(intf->si_dev, \"Unable to create symlink to bmc: %d\\n\",\n\t\t\trv);\n\t\tgoto out_free_my_dev_name;\n\t}\n\n\tintf->bmc_registered = true;\n\nout:\n\tmutex_unlock(&ipmidriver_mutex);\n\tmutex_lock(&intf->bmc_reg_mutex);\n\tintf->in_bmc_register = false;\n\treturn rv;\n\n\nout_free_my_dev_name:\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\nout_unlink1:\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\nout_put_bmc:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tgoto out;\n\nout_list_del:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tput_device(&bmc->pdev.dev);\n\tgoto out;\n}",
        "code_after_change": "static int __ipmi_bmc_register(struct ipmi_smi *intf,\n\t\t\t       struct ipmi_device_id *id,\n\t\t\t       bool guid_set, guid_t *guid, int intf_num)\n{\n\tint               rv;\n\tstruct bmc_device *bmc;\n\tstruct bmc_device *old_bmc;\n\n\t/*\n\t * platform_device_register() can cause bmc_reg_mutex to\n\t * be claimed because of the is_visible functions of\n\t * the attributes.  Eliminate possible recursion and\n\t * release the lock.\n\t */\n\tintf->in_bmc_register = true;\n\tmutex_unlock(&intf->bmc_reg_mutex);\n\n\t/*\n\t * Try to find if there is an bmc_device struct\n\t * representing the interfaced BMC already\n\t */\n\tmutex_lock(&ipmidriver_mutex);\n\tif (guid_set)\n\t\told_bmc = ipmi_find_bmc_guid(&ipmidriver.driver, guid);\n\telse\n\t\told_bmc = ipmi_find_bmc_prod_dev_id(&ipmidriver.driver,\n\t\t\t\t\t\t    id->product_id,\n\t\t\t\t\t\t    id->device_id);\n\n\t/*\n\t * If there is already an bmc_device, free the new one,\n\t * otherwise register the new BMC device\n\t */\n\tif (old_bmc) {\n\t\tbmc = old_bmc;\n\t\t/*\n\t\t * Note: old_bmc already has usecount incremented by\n\t\t * the BMC find functions.\n\t\t */\n\t\tintf->bmc = old_bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"interfacing existing BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t} else {\n\t\tbmc = kzalloc(sizeof(*bmc), GFP_KERNEL);\n\t\tif (!bmc) {\n\t\t\trv = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tINIT_LIST_HEAD(&bmc->intfs);\n\t\tmutex_init(&bmc->dyn_mutex);\n\t\tINIT_WORK(&bmc->remove_work, cleanup_bmc_work);\n\n\t\tbmc->id = *id;\n\t\tbmc->dyn_id_set = 1;\n\t\tbmc->dyn_guid_set = guid_set;\n\t\tbmc->guid = *guid;\n\t\tbmc->dyn_id_expiry = jiffies + IPMI_DYN_DEV_ID_EXPIRY;\n\n\t\tbmc->pdev.name = \"ipmi_bmc\";\n\n\t\trv = ida_simple_get(&ipmi_bmc_ida, 0, 0, GFP_KERNEL);\n\t\tif (rv < 0) {\n\t\t\tkfree(bmc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tbmc->pdev.dev.driver = &ipmidriver.driver;\n\t\tbmc->pdev.id = rv;\n\t\tbmc->pdev.dev.release = release_bmc_device;\n\t\tbmc->pdev.dev.type = &bmc_device_type;\n\t\tkref_init(&bmc->usecount);\n\n\t\tintf->bmc = bmc;\n\t\tmutex_lock(&bmc->dyn_mutex);\n\t\tlist_add_tail(&intf->bmc_link, &bmc->intfs);\n\t\tmutex_unlock(&bmc->dyn_mutex);\n\n\t\trv = platform_device_register(&bmc->pdev);\n\t\tif (rv) {\n\t\t\tdev_err(intf->si_dev,\n\t\t\t\t\"Unable to register bmc device: %d\\n\",\n\t\t\t\trv);\n\t\t\tgoto out_list_del;\n\t\t}\n\n\t\tdev_info(intf->si_dev,\n\t\t\t \"Found new BMC (man_id: 0x%6.6x, prod_id: 0x%4.4x, dev_id: 0x%2.2x)\\n\",\n\t\t\t bmc->id.manufacturer_id,\n\t\t\t bmc->id.product_id,\n\t\t\t bmc->id.device_id);\n\t}\n\n\t/*\n\t * create symlink from system interface device to bmc device\n\t * and back.\n\t */\n\trv = sysfs_create_link(&intf->si_dev->kobj, &bmc->pdev.dev.kobj, \"bmc\");\n\tif (rv) {\n\t\tdev_err(intf->si_dev, \"Unable to create bmc symlink: %d\\n\", rv);\n\t\tgoto out_put_bmc;\n\t}\n\n\tif (intf_num == -1)\n\t\tintf_num = intf->intf_num;\n\tintf->my_dev_name = kasprintf(GFP_KERNEL, \"ipmi%d\", intf_num);\n\tif (!intf->my_dev_name) {\n\t\trv = -ENOMEM;\n\t\tdev_err(intf->si_dev, \"Unable to allocate link from BMC: %d\\n\",\n\t\t\trv);\n\t\tgoto out_unlink1;\n\t}\n\n\trv = sysfs_create_link(&bmc->pdev.dev.kobj, &intf->si_dev->kobj,\n\t\t\t       intf->my_dev_name);\n\tif (rv) {\n\t\tkfree(intf->my_dev_name);\n\t\tintf->my_dev_name = NULL;\n\t\tdev_err(intf->si_dev, \"Unable to create symlink to bmc: %d\\n\",\n\t\t\trv);\n\t\tgoto out_free_my_dev_name;\n\t}\n\n\tintf->bmc_registered = true;\n\nout:\n\tmutex_unlock(&ipmidriver_mutex);\n\tmutex_lock(&intf->bmc_reg_mutex);\n\tintf->in_bmc_register = false;\n\treturn rv;\n\n\nout_free_my_dev_name:\n\tkfree(intf->my_dev_name);\n\tintf->my_dev_name = NULL;\n\nout_unlink1:\n\tsysfs_remove_link(&intf->si_dev->kobj, \"bmc\");\n\nout_put_bmc:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tkref_put(&bmc->usecount, cleanup_bmc_device);\n\tgoto out;\n\nout_list_del:\n\tmutex_lock(&bmc->dyn_mutex);\n\tlist_del(&intf->bmc_link);\n\tmutex_unlock(&bmc->dyn_mutex);\n\tintf->bmc = &intf->tmp_bmc;\n\tput_device(&bmc->pdev.dev);\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -66,8 +66,11 @@\n \t\tbmc->pdev.name = \"ipmi_bmc\";\n \n \t\trv = ida_simple_get(&ipmi_bmc_ida, 0, 0, GFP_KERNEL);\n-\t\tif (rv < 0)\n+\t\tif (rv < 0) {\n+\t\t\tkfree(bmc);\n \t\t\tgoto out;\n+\t\t}\n+\n \t\tbmc->pdev.dev.driver = &ipmidriver.driver;\n \t\tbmc->pdev.id = rv;\n \t\tbmc->pdev.dev.release = release_bmc_device;",
        "function_modified_lines": {
            "added": [
                "\t\tif (rv < 0) {",
                "\t\t\tkfree(bmc);",
                "\t\t}",
                ""
            ],
            "deleted": [
                "\t\tif (rv < 0)"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the __ipmi_bmc_register() function in drivers/char/ipmi/ipmi_msghandler.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering ida_simple_get() failure, aka CID-4aa7afb0ee20. NOTE: third parties dispute the relevance of this because an attacker cannot realistically control this failure at probe time",
        "id": 2127
    },
    {
        "cve_id": "CVE-2019-19083",
        "code_before_change": "struct clock_source *dcn10_clock_source_create(\n\tstruct dc_context *ctx,\n\tstruct dc_bios *bios,\n\tenum clock_source_id id,\n\tconst struct dce110_clk_src_regs *regs,\n\tbool dp_clk_src)\n{\n\tstruct dce110_clk_src *clk_src =\n\t\tkzalloc(sizeof(struct dce110_clk_src), GFP_KERNEL);\n\n\tif (!clk_src)\n\t\treturn NULL;\n\n\tif (dce112_clk_src_construct(clk_src, ctx, bios, id,\n\t\t\tregs, &cs_shift, &cs_mask)) {\n\t\tclk_src->base.dp_clk_src = dp_clk_src;\n\t\treturn &clk_src->base;\n\t}\n\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "code_after_change": "struct clock_source *dcn10_clock_source_create(\n\tstruct dc_context *ctx,\n\tstruct dc_bios *bios,\n\tenum clock_source_id id,\n\tconst struct dce110_clk_src_regs *regs,\n\tbool dp_clk_src)\n{\n\tstruct dce110_clk_src *clk_src =\n\t\tkzalloc(sizeof(struct dce110_clk_src), GFP_KERNEL);\n\n\tif (!clk_src)\n\t\treturn NULL;\n\n\tif (dce112_clk_src_construct(clk_src, ctx, bios, id,\n\t\t\tregs, &cs_shift, &cs_mask)) {\n\t\tclk_src->base.dp_clk_src = dp_clk_src;\n\t\treturn &clk_src->base;\n\t}\n\n\tkfree(clk_src);\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,7 @@\n \t\treturn &clk_src->base;\n \t}\n \n+\tkfree(clk_src);\n \tBREAK_TO_DEBUGGER();\n \treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tkfree(clk_src);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Memory leaks in *clock_source_create() functions under drivers/gpu/drm/amd/display/dc in the Linux kernel before 5.3.8 allow attackers to cause a denial of service (memory consumption). This affects the dce112_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c, the dce100_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce100/dce100_resource.c, the dcn10_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c, the dcn20_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dcn20/dcn20_resource.c, the dce120_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce120/dce120_resource.c, the dce110_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce110/dce110_resource.c, and the dce80_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce80/dce80_resource.c, aka CID-055e547478a1.",
        "id": 2175
    },
    {
        "cve_id": "CVE-2019-19083",
        "code_before_change": "struct clock_source *dcn20_clock_source_create(\n\tstruct dc_context *ctx,\n\tstruct dc_bios *bios,\n\tenum clock_source_id id,\n\tconst struct dce110_clk_src_regs *regs,\n\tbool dp_clk_src)\n{\n\tstruct dce110_clk_src *clk_src =\n\t\tkzalloc(sizeof(struct dce110_clk_src), GFP_KERNEL);\n\n\tif (!clk_src)\n\t\treturn NULL;\n\n\tif (dcn20_clk_src_construct(clk_src, ctx, bios, id,\n\t\t\tregs, &cs_shift, &cs_mask)) {\n\t\tclk_src->base.dp_clk_src = dp_clk_src;\n\t\treturn &clk_src->base;\n\t}\n\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "code_after_change": "struct clock_source *dcn20_clock_source_create(\n\tstruct dc_context *ctx,\n\tstruct dc_bios *bios,\n\tenum clock_source_id id,\n\tconst struct dce110_clk_src_regs *regs,\n\tbool dp_clk_src)\n{\n\tstruct dce110_clk_src *clk_src =\n\t\tkzalloc(sizeof(struct dce110_clk_src), GFP_KERNEL);\n\n\tif (!clk_src)\n\t\treturn NULL;\n\n\tif (dcn20_clk_src_construct(clk_src, ctx, bios, id,\n\t\t\tregs, &cs_shift, &cs_mask)) {\n\t\tclk_src->base.dp_clk_src = dp_clk_src;\n\t\treturn &clk_src->base;\n\t}\n\n\tkfree(clk_src);\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,7 @@\n \t\treturn &clk_src->base;\n \t}\n \n+\tkfree(clk_src);\n \tBREAK_TO_DEBUGGER();\n \treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tkfree(clk_src);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Memory leaks in *clock_source_create() functions under drivers/gpu/drm/amd/display/dc in the Linux kernel before 5.3.8 allow attackers to cause a denial of service (memory consumption). This affects the dce112_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c, the dce100_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce100/dce100_resource.c, the dcn10_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c, the dcn20_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dcn20/dcn20_resource.c, the dce120_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce120/dce120_resource.c, the dce110_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce110/dce110_resource.c, and the dce80_clock_source_create() function in drivers/gpu/drm/amd/display/dc/dce80/dce80_resource.c, aka CID-055e547478a1.",
        "id": 2176
    },
    {
        "cve_id": "CVE-2019-19048",
        "code_before_change": "static int hgcm_call_preprocess_linaddr(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tvoid **bounce_buf_ret, size_t *extra)\n{\n\tvoid *buf, *bounce_buf;\n\tbool copy_in;\n\tu32 len;\n\tint ret;\n\n\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\tlen = src_parm->u.pointer.size;\n\tcopy_in = src_parm->type != VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT;\n\n\tif (len > VBG_MAX_HGCM_USER_PARM)\n\t\treturn -E2BIG;\n\n\tbounce_buf = kvmalloc(len, GFP_KERNEL);\n\tif (!bounce_buf)\n\t\treturn -ENOMEM;\n\n\tif (copy_in) {\n\t\tret = copy_from_user(bounce_buf, (void __user *)buf, len);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemset(bounce_buf, 0, len);\n\t}\n\n\t*bounce_buf_ret = bounce_buf;\n\thgcm_call_add_pagelist_size(bounce_buf, len, extra);\n\treturn 0;\n}",
        "code_after_change": "static int hgcm_call_preprocess_linaddr(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tvoid **bounce_buf_ret, size_t *extra)\n{\n\tvoid *buf, *bounce_buf;\n\tbool copy_in;\n\tu32 len;\n\tint ret;\n\n\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\tlen = src_parm->u.pointer.size;\n\tcopy_in = src_parm->type != VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT;\n\n\tif (len > VBG_MAX_HGCM_USER_PARM)\n\t\treturn -E2BIG;\n\n\tbounce_buf = kvmalloc(len, GFP_KERNEL);\n\tif (!bounce_buf)\n\t\treturn -ENOMEM;\n\n\t*bounce_buf_ret = bounce_buf;\n\n\tif (copy_in) {\n\t\tret = copy_from_user(bounce_buf, (void __user *)buf, len);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemset(bounce_buf, 0, len);\n\t}\n\n\thgcm_call_add_pagelist_size(bounce_buf, len, extra);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,6 +18,8 @@\n \tif (!bounce_buf)\n \t\treturn -ENOMEM;\n \n+\t*bounce_buf_ret = bounce_buf;\n+\n \tif (copy_in) {\n \t\tret = copy_from_user(bounce_buf, (void __user *)buf, len);\n \t\tif (ret)\n@@ -26,7 +28,6 @@\n \t\tmemset(bounce_buf, 0, len);\n \t}\n \n-\t*bounce_buf_ret = bounce_buf;\n \thgcm_call_add_pagelist_size(bounce_buf, len, extra);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\t*bounce_buf_ret = bounce_buf;",
                ""
            ],
            "deleted": [
                "\t*bounce_buf_ret = bounce_buf;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the crypto_reportstat() function in drivers/virt/vboxguest/vboxguest_utils.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering copy_form_user() failures, aka CID-e0b0cb938864.",
        "id": 2129
    },
    {
        "cve_id": "CVE-2019-19072",
        "code_before_change": "static struct prog_entry *\npredicate_parse(const char *str, int nr_parens, int nr_preds,\n\t\tparse_pred_fn parse_pred, void *data,\n\t\tstruct filter_parse_error *pe)\n{\n\tstruct prog_entry *prog_stack;\n\tstruct prog_entry *prog;\n\tconst char *ptr = str;\n\tchar *inverts = NULL;\n\tint *op_stack;\n\tint *top;\n\tint invert = 0;\n\tint ret = -ENOMEM;\n\tint len;\n\tint N = 0;\n\tint i;\n\n\tnr_preds += 2; /* For TRUE and FALSE */\n\n\top_stack = kmalloc_array(nr_parens, sizeof(*op_stack), GFP_KERNEL);\n\tif (!op_stack)\n\t\treturn ERR_PTR(-ENOMEM);\n\tprog_stack = kcalloc(nr_preds, sizeof(*prog_stack), GFP_KERNEL);\n\tif (!prog_stack) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\tinverts = kmalloc_array(nr_preds, sizeof(*inverts), GFP_KERNEL);\n\tif (!inverts) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\n\ttop = op_stack;\n\tprog = prog_stack;\n\t*top = 0;\n\n\t/* First pass */\n\twhile (*ptr) {\t\t\t\t\t\t/* #1 */\n\t\tconst char *next = ptr++;\n\n\t\tif (isspace(*next))\n\t\t\tcontinue;\n\n\t\tswitch (*next) {\n\t\tcase '(':\t\t\t\t\t/* #2 */\n\t\t\tif (top - op_stack > nr_parens)\n\t\t\t\treturn ERR_PTR(-EINVAL);\n\t\t\t*(++top) = invert;\n\t\t\tcontinue;\n\t\tcase '!':\t\t\t\t\t/* #3 */\n\t\t\tif (!is_not(next))\n\t\t\t\tbreak;\n\t\t\tinvert = !invert;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (N >= nr_preds) {\n\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS, next - str);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tinverts[N] = invert;\t\t\t\t/* #4 */\n\t\tprog[N].target = N-1;\n\n\t\tlen = parse_pred(next, data, ptr - str, pe, &prog[N].pred);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto out_free;\n\t\t}\n\t\tptr = next + len;\n\n\t\tN++;\n\n\t\tret = -1;\n\t\twhile (1) {\t\t\t\t\t/* #5 */\n\t\t\tnext = ptr++;\n\t\t\tif (isspace(*next))\n\t\t\t\tcontinue;\n\n\t\t\tswitch (*next) {\n\t\t\tcase ')':\n\t\t\tcase '\\0':\n\t\t\t\tbreak;\n\t\t\tcase '&':\n\t\t\tcase '|':\n\t\t\t\t/* accepting only \"&&\" or \"||\" */\n\t\t\t\tif (next[1] == next[0]) {\n\t\t\t\t\tptr++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* fall through */\n\t\t\tdefault:\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS,\n\t\t\t\t\t    next - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tinvert = *top & INVERT;\n\n\t\t\tif (*top & PROCESS_AND) {\t\t/* #7 */\n\t\t\t\tupdate_preds(prog, N - 1, invert);\n\t\t\t\t*top &= ~PROCESS_AND;\n\t\t\t}\n\t\t\tif (*next == '&') {\t\t\t/* #8 */\n\t\t\t\t*top |= PROCESS_AND;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (*top & PROCESS_OR) {\t\t/* #9 */\n\t\t\t\tupdate_preds(prog, N - 1, !invert);\n\t\t\t\t*top &= ~PROCESS_OR;\n\t\t\t}\n\t\t\tif (*next == '|') {\t\t\t/* #10 */\n\t\t\t\t*top |= PROCESS_OR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!*next)\t\t\t\t/* #11 */\n\t\t\t\tgoto out;\n\n\t\t\tif (top == op_stack) {\n\t\t\t\tret = -1;\n\t\t\t\t/* Too few '(' */\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_CLOSE, ptr - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\ttop--;\t\t\t\t\t/* #12 */\n\t\t}\n\t}\n out:\n\tif (top != op_stack) {\n\t\t/* Too many '(' */\n\t\tparse_error(pe, FILT_ERR_TOO_MANY_OPEN, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tif (!N) {\n\t\t/* No program? */\n\t\tret = -EINVAL;\n\t\tparse_error(pe, FILT_ERR_NO_FILTER, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tprog[N].pred = NULL;\t\t\t\t\t/* #13 */\n\tprog[N].target = 1;\t\t/* TRUE */\n\tprog[N+1].pred = NULL;\n\tprog[N+1].target = 0;\t\t/* FALSE */\n\tprog[N-1].target = N;\n\tprog[N-1].when_to_branch = false;\n\n\t/* Second Pass */\n\tfor (i = N-1 ; i--; ) {\n\t\tint target = prog[i].target;\n\t\tif (prog[i].when_to_branch == prog[target].when_to_branch)\n\t\t\tprog[i].target = prog[target].target;\n\t}\n\n\t/* Third Pass */\n\tfor (i = 0; i < N; i++) {\n\t\tinvert = inverts[i] ^ prog[i].when_to_branch;\n\t\tprog[i].when_to_branch = invert;\n\t\t/* Make sure the program always moves forward */\n\t\tif (WARN_ON(prog[i].target <= i)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\tkfree(op_stack);\n\tkfree(inverts);\n\treturn prog;\nout_free:\n\tkfree(op_stack);\n\tkfree(inverts);\n\tif (prog_stack) {\n\t\tfor (i = 0; prog_stack[i].pred; i++)\n\t\t\tkfree(prog_stack[i].pred);\n\t\tkfree(prog_stack);\n\t}\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "static struct prog_entry *\npredicate_parse(const char *str, int nr_parens, int nr_preds,\n\t\tparse_pred_fn parse_pred, void *data,\n\t\tstruct filter_parse_error *pe)\n{\n\tstruct prog_entry *prog_stack;\n\tstruct prog_entry *prog;\n\tconst char *ptr = str;\n\tchar *inverts = NULL;\n\tint *op_stack;\n\tint *top;\n\tint invert = 0;\n\tint ret = -ENOMEM;\n\tint len;\n\tint N = 0;\n\tint i;\n\n\tnr_preds += 2; /* For TRUE and FALSE */\n\n\top_stack = kmalloc_array(nr_parens, sizeof(*op_stack), GFP_KERNEL);\n\tif (!op_stack)\n\t\treturn ERR_PTR(-ENOMEM);\n\tprog_stack = kcalloc(nr_preds, sizeof(*prog_stack), GFP_KERNEL);\n\tif (!prog_stack) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\tinverts = kmalloc_array(nr_preds, sizeof(*inverts), GFP_KERNEL);\n\tif (!inverts) {\n\t\tparse_error(pe, -ENOMEM, 0);\n\t\tgoto out_free;\n\t}\n\n\ttop = op_stack;\n\tprog = prog_stack;\n\t*top = 0;\n\n\t/* First pass */\n\twhile (*ptr) {\t\t\t\t\t\t/* #1 */\n\t\tconst char *next = ptr++;\n\n\t\tif (isspace(*next))\n\t\t\tcontinue;\n\n\t\tswitch (*next) {\n\t\tcase '(':\t\t\t\t\t/* #2 */\n\t\t\tif (top - op_stack > nr_parens) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\t*(++top) = invert;\n\t\t\tcontinue;\n\t\tcase '!':\t\t\t\t\t/* #3 */\n\t\t\tif (!is_not(next))\n\t\t\t\tbreak;\n\t\t\tinvert = !invert;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (N >= nr_preds) {\n\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS, next - str);\n\t\t\tgoto out_free;\n\t\t}\n\n\t\tinverts[N] = invert;\t\t\t\t/* #4 */\n\t\tprog[N].target = N-1;\n\n\t\tlen = parse_pred(next, data, ptr - str, pe, &prog[N].pred);\n\t\tif (len < 0) {\n\t\t\tret = len;\n\t\t\tgoto out_free;\n\t\t}\n\t\tptr = next + len;\n\n\t\tN++;\n\n\t\tret = -1;\n\t\twhile (1) {\t\t\t\t\t/* #5 */\n\t\t\tnext = ptr++;\n\t\t\tif (isspace(*next))\n\t\t\t\tcontinue;\n\n\t\t\tswitch (*next) {\n\t\t\tcase ')':\n\t\t\tcase '\\0':\n\t\t\t\tbreak;\n\t\t\tcase '&':\n\t\t\tcase '|':\n\t\t\t\t/* accepting only \"&&\" or \"||\" */\n\t\t\t\tif (next[1] == next[0]) {\n\t\t\t\t\tptr++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t/* fall through */\n\t\t\tdefault:\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_PREDS,\n\t\t\t\t\t    next - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\n\t\t\tinvert = *top & INVERT;\n\n\t\t\tif (*top & PROCESS_AND) {\t\t/* #7 */\n\t\t\t\tupdate_preds(prog, N - 1, invert);\n\t\t\t\t*top &= ~PROCESS_AND;\n\t\t\t}\n\t\t\tif (*next == '&') {\t\t\t/* #8 */\n\t\t\t\t*top |= PROCESS_AND;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (*top & PROCESS_OR) {\t\t/* #9 */\n\t\t\t\tupdate_preds(prog, N - 1, !invert);\n\t\t\t\t*top &= ~PROCESS_OR;\n\t\t\t}\n\t\t\tif (*next == '|') {\t\t\t/* #10 */\n\t\t\t\t*top |= PROCESS_OR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!*next)\t\t\t\t/* #11 */\n\t\t\t\tgoto out;\n\n\t\t\tif (top == op_stack) {\n\t\t\t\tret = -1;\n\t\t\t\t/* Too few '(' */\n\t\t\t\tparse_error(pe, FILT_ERR_TOO_MANY_CLOSE, ptr - str);\n\t\t\t\tgoto out_free;\n\t\t\t}\n\t\t\ttop--;\t\t\t\t\t/* #12 */\n\t\t}\n\t}\n out:\n\tif (top != op_stack) {\n\t\t/* Too many '(' */\n\t\tparse_error(pe, FILT_ERR_TOO_MANY_OPEN, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tif (!N) {\n\t\t/* No program? */\n\t\tret = -EINVAL;\n\t\tparse_error(pe, FILT_ERR_NO_FILTER, ptr - str);\n\t\tgoto out_free;\n\t}\n\n\tprog[N].pred = NULL;\t\t\t\t\t/* #13 */\n\tprog[N].target = 1;\t\t/* TRUE */\n\tprog[N+1].pred = NULL;\n\tprog[N+1].target = 0;\t\t/* FALSE */\n\tprog[N-1].target = N;\n\tprog[N-1].when_to_branch = false;\n\n\t/* Second Pass */\n\tfor (i = N-1 ; i--; ) {\n\t\tint target = prog[i].target;\n\t\tif (prog[i].when_to_branch == prog[target].when_to_branch)\n\t\t\tprog[i].target = prog[target].target;\n\t}\n\n\t/* Third Pass */\n\tfor (i = 0; i < N; i++) {\n\t\tinvert = inverts[i] ^ prog[i].when_to_branch;\n\t\tprog[i].when_to_branch = invert;\n\t\t/* Make sure the program always moves forward */\n\t\tif (WARN_ON(prog[i].target <= i)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_free;\n\t\t}\n\t}\n\n\tkfree(op_stack);\n\tkfree(inverts);\n\treturn prog;\nout_free:\n\tkfree(op_stack);\n\tkfree(inverts);\n\tif (prog_stack) {\n\t\tfor (i = 0; prog_stack[i].pred; i++)\n\t\t\tkfree(prog_stack[i].pred);\n\t\tkfree(prog_stack);\n\t}\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -44,8 +44,10 @@\n \n \t\tswitch (*next) {\n \t\tcase '(':\t\t\t\t\t/* #2 */\n-\t\t\tif (top - op_stack > nr_parens)\n-\t\t\t\treturn ERR_PTR(-EINVAL);\n+\t\t\tif (top - op_stack > nr_parens) {\n+\t\t\t\tret = -EINVAL;\n+\t\t\t\tgoto out_free;\n+\t\t\t}\n \t\t\t*(++top) = invert;\n \t\t\tcontinue;\n \t\tcase '!':\t\t\t\t\t/* #3 */",
        "function_modified_lines": {
            "added": [
                "\t\t\tif (top - op_stack > nr_parens) {",
                "\t\t\t\tret = -EINVAL;",
                "\t\t\t\tgoto out_free;",
                "\t\t\t}"
            ],
            "deleted": [
                "\t\t\tif (top - op_stack > nr_parens)",
                "\t\t\t\treturn ERR_PTR(-EINVAL);"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the predicate_parse() function in kernel/trace/trace_events_filter.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption), aka CID-96c5c6e6a5b6.",
        "id": 2153
    },
    {
        "cve_id": "CVE-2021-3736",
        "code_before_change": "static ssize_t available_instances_show(struct mdev_type *mtype,\n\t\t\t\t\tstruct mdev_type_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tconst struct mbochs_type *type =\n\t\t&mbochs_types[mtype_get_type_group_id(mtype)];\n\tint count = (max_mbytes - mbochs_used_mbytes) / type->mbytes;\n\n\treturn sprintf(buf, \"%d\\n\", count);\n}",
        "code_after_change": "static ssize_t available_instances_show(struct mdev_type *mtype,\n\t\t\t\t\tstruct mdev_type_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tconst struct mbochs_type *type =\n\t\t&mbochs_types[mtype_get_type_group_id(mtype)];\n\tint count = atomic_read(&mbochs_avail_mbytes) / type->mbytes;\n\n\treturn sprintf(buf, \"%d\\n\", count);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n {\n \tconst struct mbochs_type *type =\n \t\t&mbochs_types[mtype_get_type_group_id(mtype)];\n-\tint count = (max_mbytes - mbochs_used_mbytes) / type->mbytes;\n+\tint count = atomic_read(&mbochs_avail_mbytes) / type->mbytes;\n \n \treturn sprintf(buf, \"%d\\n\", count);\n }",
        "function_modified_lines": {
            "added": [
                "\tint count = atomic_read(&mbochs_avail_mbytes) / type->mbytes;"
            ],
            "deleted": [
                "\tint count = (max_mbytes - mbochs_used_mbytes) / type->mbytes;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A flaw was found in the Linux kernel. A memory leak problem was found in mbochs_ioctl in samples/vfio-mdev/mbochs.c in Virtual Function I/O (VFIO) Mediated devices. This flaw could allow a local attacker to leak internal kernel information.",
        "id": 3046
    },
    {
        "cve_id": "CVE-2021-3736",
        "code_before_change": "static int __init mbochs_dev_init(void)\n{\n\tint ret = 0;\n\n\tret = alloc_chrdev_region(&mbochs_devt, 0, MINORMASK + 1, MBOCHS_NAME);\n\tif (ret < 0) {\n\t\tpr_err(\"Error: failed to register mbochs_dev, err: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tcdev_init(&mbochs_cdev, &vd_fops);\n\tcdev_add(&mbochs_cdev, mbochs_devt, MINORMASK + 1);\n\tpr_info(\"%s: major %d\\n\", __func__, MAJOR(mbochs_devt));\n\n\tret = mdev_register_driver(&mbochs_driver);\n\tif (ret)\n\t\tgoto err_cdev;\n\n\tmbochs_class = class_create(THIS_MODULE, MBOCHS_CLASS_NAME);\n\tif (IS_ERR(mbochs_class)) {\n\t\tpr_err(\"Error: failed to register mbochs_dev class\\n\");\n\t\tret = PTR_ERR(mbochs_class);\n\t\tgoto err_driver;\n\t}\n\tmbochs_dev.class = mbochs_class;\n\tmbochs_dev.release = mbochs_device_release;\n\tdev_set_name(&mbochs_dev, \"%s\", MBOCHS_NAME);\n\n\tret = device_register(&mbochs_dev);\n\tif (ret)\n\t\tgoto err_class;\n\n\tret = mdev_register_device(&mbochs_dev, &mdev_fops);\n\tif (ret)\n\t\tgoto err_device;\n\n\treturn 0;\n\nerr_device:\n\tdevice_unregister(&mbochs_dev);\nerr_class:\n\tclass_destroy(mbochs_class);\nerr_driver:\n\tmdev_unregister_driver(&mbochs_driver);\nerr_cdev:\n\tcdev_del(&mbochs_cdev);\n\tunregister_chrdev_region(mbochs_devt, MINORMASK + 1);\n\treturn ret;\n}",
        "code_after_change": "static int __init mbochs_dev_init(void)\n{\n\tint ret = 0;\n\n\tatomic_set(&mbochs_avail_mbytes, max_mbytes);\n\n\tret = alloc_chrdev_region(&mbochs_devt, 0, MINORMASK + 1, MBOCHS_NAME);\n\tif (ret < 0) {\n\t\tpr_err(\"Error: failed to register mbochs_dev, err: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tcdev_init(&mbochs_cdev, &vd_fops);\n\tcdev_add(&mbochs_cdev, mbochs_devt, MINORMASK + 1);\n\tpr_info(\"%s: major %d\\n\", __func__, MAJOR(mbochs_devt));\n\n\tret = mdev_register_driver(&mbochs_driver);\n\tif (ret)\n\t\tgoto err_cdev;\n\n\tmbochs_class = class_create(THIS_MODULE, MBOCHS_CLASS_NAME);\n\tif (IS_ERR(mbochs_class)) {\n\t\tpr_err(\"Error: failed to register mbochs_dev class\\n\");\n\t\tret = PTR_ERR(mbochs_class);\n\t\tgoto err_driver;\n\t}\n\tmbochs_dev.class = mbochs_class;\n\tmbochs_dev.release = mbochs_device_release;\n\tdev_set_name(&mbochs_dev, \"%s\", MBOCHS_NAME);\n\n\tret = device_register(&mbochs_dev);\n\tif (ret)\n\t\tgoto err_class;\n\n\tret = mdev_register_device(&mbochs_dev, &mdev_fops);\n\tif (ret)\n\t\tgoto err_device;\n\n\treturn 0;\n\nerr_device:\n\tdevice_unregister(&mbochs_dev);\nerr_class:\n\tclass_destroy(mbochs_class);\nerr_driver:\n\tmdev_unregister_driver(&mbochs_driver);\nerr_cdev:\n\tcdev_del(&mbochs_cdev);\n\tunregister_chrdev_region(mbochs_devt, MINORMASK + 1);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,8 @@\n static int __init mbochs_dev_init(void)\n {\n \tint ret = 0;\n+\n+\tatomic_set(&mbochs_avail_mbytes, max_mbytes);\n \n \tret = alloc_chrdev_region(&mbochs_devt, 0, MINORMASK + 1, MBOCHS_NAME);\n \tif (ret < 0) {",
        "function_modified_lines": {
            "added": [
                "",
                "\tatomic_set(&mbochs_avail_mbytes, max_mbytes);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A flaw was found in the Linux kernel. A memory leak problem was found in mbochs_ioctl in samples/vfio-mdev/mbochs.c in Virtual Function I/O (VFIO) Mediated devices. This flaw could allow a local attacker to leak internal kernel information.",
        "id": 3047
    },
    {
        "cve_id": "CVE-2019-19069",
        "code_before_change": "static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}",
        "code_after_change": "static int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\tkfree(a);\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,6 +13,7 @@\n \t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n \tif (ret < 0) {\n \t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n+\t\tkfree(a);\n \t\treturn -EINVAL;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tkfree(a);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.",
        "id": 2150
    },
    {
        "cve_id": "CVE-2022-3630",
        "code_before_change": "void __fscache_invalidate(struct fscache_cookie *cookie,\n\t\t\t  const void *aux_data, loff_t new_size,\n\t\t\t  unsigned int flags)\n{\n\tbool is_caching;\n\n\t_enter(\"c=%x\", cookie->debug_id);\n\n\tfscache_stat(&fscache_n_invalidates);\n\n\tif (WARN(test_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags),\n\t\t \"Trying to invalidate relinquished cookie\\n\"))\n\t\treturn;\n\n\tif ((flags & FSCACHE_INVAL_DIO_WRITE) &&\n\t    test_and_set_bit(FSCACHE_COOKIE_DISABLED, &cookie->flags))\n\t\treturn;\n\n\tspin_lock(&cookie->lock);\n\tset_bit(FSCACHE_COOKIE_NO_DATA_TO_READ, &cookie->flags);\n\tfscache_update_aux(cookie, aux_data, &new_size);\n\tcookie->inval_counter++;\n\ttrace_fscache_invalidate(cookie, new_size);\n\n\tswitch (cookie->state) {\n\tcase FSCACHE_COOKIE_STATE_INVALIDATING: /* is_still_valid will catch it */\n\tdefault:\n\t\tspin_unlock(&cookie->lock);\n\t\t_leave(\" [no %u]\", cookie->state);\n\t\treturn;\n\n\tcase FSCACHE_COOKIE_STATE_LOOKING_UP:\n\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);\n\t\tset_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags);\n\t\tfallthrough;\n\tcase FSCACHE_COOKIE_STATE_CREATING:\n\t\tspin_unlock(&cookie->lock);\n\t\t_leave(\" [look %x]\", cookie->inval_counter);\n\t\treturn;\n\n\tcase FSCACHE_COOKIE_STATE_ACTIVE:\n\t\tis_caching = fscache_begin_cookie_access(\n\t\t\tcookie, fscache_access_invalidate_cookie);\n\t\tif (is_caching)\n\t\t\t__fscache_set_cookie_state(cookie, FSCACHE_COOKIE_STATE_INVALIDATING);\n\t\tspin_unlock(&cookie->lock);\n\t\twake_up_cookie_state(cookie);\n\n\t\tif (is_caching)\n\t\t\tfscache_queue_cookie(cookie, fscache_cookie_get_inval_work);\n\t\t_leave(\" [inv]\");\n\t\treturn;\n\t}\n}",
        "code_after_change": "void __fscache_invalidate(struct fscache_cookie *cookie,\n\t\t\t  const void *aux_data, loff_t new_size,\n\t\t\t  unsigned int flags)\n{\n\tbool is_caching;\n\n\t_enter(\"c=%x\", cookie->debug_id);\n\n\tfscache_stat(&fscache_n_invalidates);\n\n\tif (WARN(test_bit(FSCACHE_COOKIE_RELINQUISHED, &cookie->flags),\n\t\t \"Trying to invalidate relinquished cookie\\n\"))\n\t\treturn;\n\n\tif ((flags & FSCACHE_INVAL_DIO_WRITE) &&\n\t    test_and_set_bit(FSCACHE_COOKIE_DISABLED, &cookie->flags))\n\t\treturn;\n\n\tspin_lock(&cookie->lock);\n\tset_bit(FSCACHE_COOKIE_NO_DATA_TO_READ, &cookie->flags);\n\tfscache_update_aux(cookie, aux_data, &new_size);\n\tcookie->inval_counter++;\n\ttrace_fscache_invalidate(cookie, new_size);\n\n\tswitch (cookie->state) {\n\tcase FSCACHE_COOKIE_STATE_INVALIDATING: /* is_still_valid will catch it */\n\tdefault:\n\t\tspin_unlock(&cookie->lock);\n\t\t_leave(\" [no %u]\", cookie->state);\n\t\treturn;\n\n\tcase FSCACHE_COOKIE_STATE_LOOKING_UP:\n\t\tif (!test_and_set_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags))\n\t\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);\n\t\tfallthrough;\n\tcase FSCACHE_COOKIE_STATE_CREATING:\n\t\tspin_unlock(&cookie->lock);\n\t\t_leave(\" [look %x]\", cookie->inval_counter);\n\t\treturn;\n\n\tcase FSCACHE_COOKIE_STATE_ACTIVE:\n\t\tis_caching = fscache_begin_cookie_access(\n\t\t\tcookie, fscache_access_invalidate_cookie);\n\t\tif (is_caching)\n\t\t\t__fscache_set_cookie_state(cookie, FSCACHE_COOKIE_STATE_INVALIDATING);\n\t\tspin_unlock(&cookie->lock);\n\t\twake_up_cookie_state(cookie);\n\n\t\tif (is_caching)\n\t\t\tfscache_queue_cookie(cookie, fscache_cookie_get_inval_work);\n\t\t_leave(\" [inv]\");\n\t\treturn;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -30,8 +30,8 @@\n \t\treturn;\n \n \tcase FSCACHE_COOKIE_STATE_LOOKING_UP:\n-\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);\n-\t\tset_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags);\n+\t\tif (!test_and_set_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags))\n+\t\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);\n \t\tfallthrough;\n \tcase FSCACHE_COOKIE_STATE_CREATING:\n \t\tspin_unlock(&cookie->lock);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!test_and_set_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags))",
                "\t\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);"
            ],
            "deleted": [
                "\t\t__fscache_begin_cookie_access(cookie, fscache_access_invalidate_cookie);",
                "\t\tset_bit(FSCACHE_COOKIE_DO_INVALIDATE, &cookie->flags);"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A vulnerability was found in Linux Kernel. It has been rated as problematic. This issue affects some unknown processing of the file fs/fscache/cookie.c of the component IPsec. The manipulation leads to memory leak. It is recommended to apply a patch to fix this issue. The associated identifier of this vulnerability is VDB-211931.",
        "id": 3665
    },
    {
        "cve_id": "CVE-2023-1074",
        "code_before_change": "int sctp_bind_addr_copy(struct net *net, struct sctp_bind_addr *dest,\n\t\t\tconst struct sctp_bind_addr *src,\n\t\t\tenum sctp_scope scope, gfp_t gfp,\n\t\t\tint flags)\n{\n\tstruct sctp_sockaddr_entry *addr;\n\tint error = 0;\n\n\t/* All addresses share the same port.  */\n\tdest->port = src->port;\n\n\t/* Extract the addresses which are relevant for this scope.  */\n\tlist_for_each_entry(addr, &src->address_list, list) {\n\t\terror = sctp_copy_one_addr(net, dest, &addr->a, scope,\n\t\t\t\t\t   gfp, flags);\n\t\tif (error < 0)\n\t\t\tgoto out;\n\t}\n\n\t/* If there are no addresses matching the scope and\n\t * this is global scope, try to get a link scope address, with\n\t * the assumption that we must be sitting behind a NAT.\n\t */\n\tif (list_empty(&dest->address_list) && (SCTP_SCOPE_GLOBAL == scope)) {\n\t\tlist_for_each_entry(addr, &src->address_list, list) {\n\t\t\terror = sctp_copy_one_addr(net, dest, &addr->a,\n\t\t\t\t\t\t   SCTP_SCOPE_LINK, gfp,\n\t\t\t\t\t\t   flags);\n\t\t\tif (error < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tif (error)\n\t\tsctp_bind_addr_clean(dest);\n\n\treturn error;\n}",
        "code_after_change": "int sctp_bind_addr_copy(struct net *net, struct sctp_bind_addr *dest,\n\t\t\tconst struct sctp_bind_addr *src,\n\t\t\tenum sctp_scope scope, gfp_t gfp,\n\t\t\tint flags)\n{\n\tstruct sctp_sockaddr_entry *addr;\n\tint error = 0;\n\n\t/* All addresses share the same port.  */\n\tdest->port = src->port;\n\n\t/* Extract the addresses which are relevant for this scope.  */\n\tlist_for_each_entry(addr, &src->address_list, list) {\n\t\terror = sctp_copy_one_addr(net, dest, &addr->a, scope,\n\t\t\t\t\t   gfp, flags);\n\t\tif (error < 0)\n\t\t\tgoto out;\n\t}\n\n\t/* If there are no addresses matching the scope and\n\t * this is global scope, try to get a link scope address, with\n\t * the assumption that we must be sitting behind a NAT.\n\t */\n\tif (list_empty(&dest->address_list) && (SCTP_SCOPE_GLOBAL == scope)) {\n\t\tlist_for_each_entry(addr, &src->address_list, list) {\n\t\t\terror = sctp_copy_one_addr(net, dest, &addr->a,\n\t\t\t\t\t\t   SCTP_SCOPE_LINK, gfp,\n\t\t\t\t\t\t   flags);\n\t\t\tif (error < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/* If somehow no addresses were found that can be used with this\n\t * scope, it's an error.\n\t */\n\tif (list_empty(&dest->address_list))\n\t\terror = -ENETUNREACH;\n\nout:\n\tif (error)\n\t\tsctp_bind_addr_clean(dest);\n\n\treturn error;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,6 +31,12 @@\n \t\t}\n \t}\n \n+\t/* If somehow no addresses were found that can be used with this\n+\t * scope, it's an error.\n+\t */\n+\tif (list_empty(&dest->address_list))\n+\t\terror = -ENETUNREACH;\n+\n out:\n \tif (error)\n \t\tsctp_bind_addr_clean(dest);",
        "function_modified_lines": {
            "added": [
                "\t/* If somehow no addresses were found that can be used with this",
                "\t * scope, it's an error.",
                "\t */",
                "\tif (list_empty(&dest->address_list))",
                "\t\terror = -ENETUNREACH;",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak flaw was found in the Linux kernel's Stream Control Transmission Protocol. This issue may occur when a user starts a malicious networking service and someone connects to this service. This could allow a local user to starve resources, causing a denial of service.",
        "id": 3841
    },
    {
        "cve_id": "CVE-2019-19080",
        "code_before_change": "static int\nnfp_flower_spawn_phy_reprs(struct nfp_app *app, struct nfp_flower_priv *priv)\n{\n\tstruct nfp_eth_table *eth_tbl = app->pf->eth_tbl;\n\tatomic_t *replies = &priv->reify_replies;\n\tstruct nfp_flower_repr_priv *repr_priv;\n\tstruct nfp_repr *nfp_repr;\n\tstruct sk_buff *ctrl_skb;\n\tstruct nfp_reprs *reprs;\n\tint err, reify_cnt;\n\tunsigned int i;\n\n\tctrl_skb = nfp_flower_cmsg_mac_repr_start(app, eth_tbl->count);\n\tif (!ctrl_skb)\n\t\treturn -ENOMEM;\n\n\treprs = nfp_reprs_alloc(eth_tbl->max_index + 1);\n\tif (!reprs) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_ctrl_skb;\n\t}\n\n\tfor (i = 0; i < eth_tbl->count; i++) {\n\t\tunsigned int phys_port = eth_tbl->ports[i].index;\n\t\tstruct net_device *repr;\n\t\tstruct nfp_port *port;\n\t\tu32 cmsg_port_id;\n\n\t\trepr = nfp_repr_alloc(app);\n\t\tif (!repr) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\trepr_priv = kzalloc(sizeof(*repr_priv), GFP_KERNEL);\n\t\tif (!repr_priv) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tnfp_repr = netdev_priv(repr);\n\t\tnfp_repr->app_priv = repr_priv;\n\t\trepr_priv->nfp_repr = nfp_repr;\n\n\t\tport = nfp_port_alloc(app, NFP_PORT_PHYS_PORT, repr);\n\t\tif (IS_ERR(port)) {\n\t\t\terr = PTR_ERR(port);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\t\terr = nfp_port_init_phy_port(app->pf, app, port, i);\n\t\tif (err) {\n\t\t\tnfp_port_free(port);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tSET_NETDEV_DEV(repr, &priv->nn->pdev->dev);\n\t\tnfp_net_get_mac_addr(app->pf, repr, port);\n\n\t\tcmsg_port_id = nfp_flower_cmsg_phys_port(phys_port);\n\t\terr = nfp_repr_init(app, repr,\n\t\t\t\t    cmsg_port_id, port, priv->nn->dp.netdev);\n\t\tif (err) {\n\t\t\tnfp_port_free(port);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tnfp_flower_cmsg_mac_repr_add(ctrl_skb, i,\n\t\t\t\t\t     eth_tbl->ports[i].nbi,\n\t\t\t\t\t     eth_tbl->ports[i].base,\n\t\t\t\t\t     phys_port);\n\n\t\tRCU_INIT_POINTER(reprs->reprs[phys_port], repr);\n\t\tnfp_info(app->cpp, \"Phys Port %d Representor(%s) created\\n\",\n\t\t\t phys_port, repr->name);\n\t}\n\n\tnfp_app_reprs_set(app, NFP_REPR_TYPE_PHYS_PORT, reprs);\n\n\t/* The REIFY/MAC_REPR control messages should be sent after the MAC\n\t * representors are registered using nfp_app_reprs_set().  This is\n\t * because the firmware may respond with control messages for the\n\t * MAC representors, f.e. to provide the driver with information\n\t * about their state, and without registration the driver will drop\n\t * any such messages.\n\t */\n\tatomic_set(replies, 0);\n\treify_cnt = nfp_flower_reprs_reify(app, NFP_REPR_TYPE_PHYS_PORT, true);\n\tif (reify_cnt < 0) {\n\t\terr = reify_cnt;\n\t\tnfp_warn(app->cpp, \"Failed to notify firmware about repr creation\\n\");\n\t\tgoto err_reprs_remove;\n\t}\n\n\terr = nfp_flower_wait_repr_reify(app, replies, reify_cnt);\n\tif (err)\n\t\tgoto err_reprs_remove;\n\n\tnfp_ctrl_tx(app->ctrl, ctrl_skb);\n\n\treturn 0;\nerr_reprs_remove:\n\treprs = nfp_app_reprs_set(app, NFP_REPR_TYPE_PHYS_PORT, NULL);\nerr_reprs_clean:\n\tnfp_reprs_clean_and_free(app, reprs);\nerr_free_ctrl_skb:\n\tkfree_skb(ctrl_skb);\n\treturn err;\n}",
        "code_after_change": "static int\nnfp_flower_spawn_phy_reprs(struct nfp_app *app, struct nfp_flower_priv *priv)\n{\n\tstruct nfp_eth_table *eth_tbl = app->pf->eth_tbl;\n\tatomic_t *replies = &priv->reify_replies;\n\tstruct nfp_flower_repr_priv *repr_priv;\n\tstruct nfp_repr *nfp_repr;\n\tstruct sk_buff *ctrl_skb;\n\tstruct nfp_reprs *reprs;\n\tint err, reify_cnt;\n\tunsigned int i;\n\n\tctrl_skb = nfp_flower_cmsg_mac_repr_start(app, eth_tbl->count);\n\tif (!ctrl_skb)\n\t\treturn -ENOMEM;\n\n\treprs = nfp_reprs_alloc(eth_tbl->max_index + 1);\n\tif (!reprs) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_ctrl_skb;\n\t}\n\n\tfor (i = 0; i < eth_tbl->count; i++) {\n\t\tunsigned int phys_port = eth_tbl->ports[i].index;\n\t\tstruct net_device *repr;\n\t\tstruct nfp_port *port;\n\t\tu32 cmsg_port_id;\n\n\t\trepr = nfp_repr_alloc(app);\n\t\tif (!repr) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\trepr_priv = kzalloc(sizeof(*repr_priv), GFP_KERNEL);\n\t\tif (!repr_priv) {\n\t\t\terr = -ENOMEM;\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tnfp_repr = netdev_priv(repr);\n\t\tnfp_repr->app_priv = repr_priv;\n\t\trepr_priv->nfp_repr = nfp_repr;\n\n\t\tport = nfp_port_alloc(app, NFP_PORT_PHYS_PORT, repr);\n\t\tif (IS_ERR(port)) {\n\t\t\terr = PTR_ERR(port);\n\t\t\tkfree(repr_priv);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\t\terr = nfp_port_init_phy_port(app->pf, app, port, i);\n\t\tif (err) {\n\t\t\tkfree(repr_priv);\n\t\t\tnfp_port_free(port);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tSET_NETDEV_DEV(repr, &priv->nn->pdev->dev);\n\t\tnfp_net_get_mac_addr(app->pf, repr, port);\n\n\t\tcmsg_port_id = nfp_flower_cmsg_phys_port(phys_port);\n\t\terr = nfp_repr_init(app, repr,\n\t\t\t\t    cmsg_port_id, port, priv->nn->dp.netdev);\n\t\tif (err) {\n\t\t\tkfree(repr_priv);\n\t\t\tnfp_port_free(port);\n\t\t\tnfp_repr_free(repr);\n\t\t\tgoto err_reprs_clean;\n\t\t}\n\n\t\tnfp_flower_cmsg_mac_repr_add(ctrl_skb, i,\n\t\t\t\t\t     eth_tbl->ports[i].nbi,\n\t\t\t\t\t     eth_tbl->ports[i].base,\n\t\t\t\t\t     phys_port);\n\n\t\tRCU_INIT_POINTER(reprs->reprs[phys_port], repr);\n\t\tnfp_info(app->cpp, \"Phys Port %d Representor(%s) created\\n\",\n\t\t\t phys_port, repr->name);\n\t}\n\n\tnfp_app_reprs_set(app, NFP_REPR_TYPE_PHYS_PORT, reprs);\n\n\t/* The REIFY/MAC_REPR control messages should be sent after the MAC\n\t * representors are registered using nfp_app_reprs_set().  This is\n\t * because the firmware may respond with control messages for the\n\t * MAC representors, f.e. to provide the driver with information\n\t * about their state, and without registration the driver will drop\n\t * any such messages.\n\t */\n\tatomic_set(replies, 0);\n\treify_cnt = nfp_flower_reprs_reify(app, NFP_REPR_TYPE_PHYS_PORT, true);\n\tif (reify_cnt < 0) {\n\t\terr = reify_cnt;\n\t\tnfp_warn(app->cpp, \"Failed to notify firmware about repr creation\\n\");\n\t\tgoto err_reprs_remove;\n\t}\n\n\terr = nfp_flower_wait_repr_reify(app, replies, reify_cnt);\n\tif (err)\n\t\tgoto err_reprs_remove;\n\n\tnfp_ctrl_tx(app->ctrl, ctrl_skb);\n\n\treturn 0;\nerr_reprs_remove:\n\treprs = nfp_app_reprs_set(app, NFP_REPR_TYPE_PHYS_PORT, NULL);\nerr_reprs_clean:\n\tnfp_reprs_clean_and_free(app, reprs);\nerr_free_ctrl_skb:\n\tkfree_skb(ctrl_skb);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,6 +35,7 @@\n \t\trepr_priv = kzalloc(sizeof(*repr_priv), GFP_KERNEL);\n \t\tif (!repr_priv) {\n \t\t\terr = -ENOMEM;\n+\t\t\tnfp_repr_free(repr);\n \t\t\tgoto err_reprs_clean;\n \t\t}\n \n@@ -45,11 +46,13 @@\n \t\tport = nfp_port_alloc(app, NFP_PORT_PHYS_PORT, repr);\n \t\tif (IS_ERR(port)) {\n \t\t\terr = PTR_ERR(port);\n+\t\t\tkfree(repr_priv);\n \t\t\tnfp_repr_free(repr);\n \t\t\tgoto err_reprs_clean;\n \t\t}\n \t\terr = nfp_port_init_phy_port(app->pf, app, port, i);\n \t\tif (err) {\n+\t\t\tkfree(repr_priv);\n \t\t\tnfp_port_free(port);\n \t\t\tnfp_repr_free(repr);\n \t\t\tgoto err_reprs_clean;\n@@ -62,6 +65,7 @@\n \t\terr = nfp_repr_init(app, repr,\n \t\t\t\t    cmsg_port_id, port, priv->nn->dp.netdev);\n \t\tif (err) {\n+\t\t\tkfree(repr_priv);\n \t\t\tnfp_port_free(port);\n \t\t\tnfp_repr_free(repr);\n \t\t\tgoto err_reprs_clean;",
        "function_modified_lines": {
            "added": [
                "\t\t\tnfp_repr_free(repr);",
                "\t\t\tkfree(repr_priv);",
                "\t\t\tkfree(repr_priv);",
                "\t\t\tkfree(repr_priv);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Four memory leaks in the nfp_flower_spawn_phy_reprs() function in drivers/net/ethernet/netronome/nfp/flower/main.c in the Linux kernel before 5.3.4 allow attackers to cause a denial of service (memory consumption), aka CID-8572cea1461a.",
        "id": 2163
    },
    {
        "cve_id": "CVE-2023-0615",
        "code_before_change": "int vivid_vid_cap_s_selection(struct file *file, void *fh, struct v4l2_selection *s)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_rect *crop = &dev->crop_cap;\n\tstruct v4l2_rect *compose = &dev->compose_cap;\n\tunsigned factor = V4L2_FIELD_HAS_T_OR_B(dev->field_cap) ? 2 : 1;\n\tint ret;\n\n\tif (!dev->has_crop_cap && !dev->has_compose_cap)\n\t\treturn -ENOTTY;\n\tif (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\treturn -EINVAL;\n\tif (vivid_is_webcam(dev))\n\t\treturn -ENODATA;\n\n\tswitch (s->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\t\tif (!dev->has_crop_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\tv4l2_rect_map_inside(&s->r, &dev->crop_bounds_cap);\n\t\ts->r.top /= factor;\n\t\ts->r.height /= factor;\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\ts->r.height * MAX_ZOOM\n\t\t\t};\n\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\ts->r.height / MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &min_rect);\n\t\t\tif (!dev->has_compose_cap)\n\t\t\t\tv4l2_rect_set_max_size(&fmt, &max_rect);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tif (dev->has_compose_cap) {\n\t\t\t\tv4l2_rect_set_min_size(compose, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(compose, &max_rect);\n\t\t\t}\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t} else if (dev->has_compose_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &s->r);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t} else {\n\t\t\tif (!v4l2_rect_same_size(&s->r, &dev->fmt_cap_rect) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tv4l2_rect_set_size_to(&dev->fmt_cap_rect, &s->r);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t\ttpg_s_buf_height(&dev->tpg, dev->fmt_cap_rect.height);\n\t\t}\n\t\ts->r.top *= factor;\n\t\ts->r.height *= factor;\n\t\t*crop = s->r;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->fmt_cap_rect);\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\tdev->src_rect.width * MAX_ZOOM,\n\t\t\t\t(dev->src_rect.height / factor) * MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_max_size(&s->r, &max_rect);\n\t\t\tif (dev->has_crop_cap) {\n\t\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) / MAX_ZOOM\n\t\t\t\t};\n\t\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) * MAX_ZOOM\n\t\t\t\t};\n\n\t\t\t\tv4l2_rect_set_min_size(crop, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(crop, &max_rect);\n\t\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\t}\n\t\t} else if (dev->has_crop_cap) {\n\t\t\ts->r.top *= factor;\n\t\t\ts->r.height *= factor;\n\t\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\t\tv4l2_rect_set_size_to(crop, &s->r);\n\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\ts->r.top /= factor;\n\t\t\ts->r.height /= factor;\n\t\t} else {\n\t\t\tv4l2_rect_set_size_to(&s->r, &dev->src_rect);\n\t\t\ts->r.height /= factor;\n\t\t}\n\t\tv4l2_rect_map_inside(&s->r, &dev->fmt_cap_rect);\n\t\tif (dev->bitmap_cap && (compose->width != s->r.width ||\n\t\t\t\t\tcompose->height != s->r.height)) {\n\t\t\tvfree(dev->bitmap_cap);\n\t\t\tdev->bitmap_cap = NULL;\n\t\t}\n\t\t*compose = s->r;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\ttpg_s_crop_compose(&dev->tpg, crop, compose);\n\treturn 0;\n}",
        "code_after_change": "int vivid_vid_cap_s_selection(struct file *file, void *fh, struct v4l2_selection *s)\n{\n\tstruct vivid_dev *dev = video_drvdata(file);\n\tstruct v4l2_rect *crop = &dev->crop_cap;\n\tstruct v4l2_rect *compose = &dev->compose_cap;\n\tunsigned orig_compose_w = compose->width;\n\tunsigned orig_compose_h = compose->height;\n\tunsigned factor = V4L2_FIELD_HAS_T_OR_B(dev->field_cap) ? 2 : 1;\n\tint ret;\n\n\tif (!dev->has_crop_cap && !dev->has_compose_cap)\n\t\treturn -ENOTTY;\n\tif (s->type != V4L2_BUF_TYPE_VIDEO_CAPTURE)\n\t\treturn -EINVAL;\n\tif (vivid_is_webcam(dev))\n\t\treturn -ENODATA;\n\n\tswitch (s->target) {\n\tcase V4L2_SEL_TGT_CROP:\n\t\tif (!dev->has_crop_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\tv4l2_rect_map_inside(&s->r, &dev->crop_bounds_cap);\n\t\ts->r.top /= factor;\n\t\ts->r.height /= factor;\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\ts->r.height * MAX_ZOOM\n\t\t\t};\n\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t0, 0,\n\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\ts->r.height / MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &min_rect);\n\t\t\tif (!dev->has_compose_cap)\n\t\t\t\tv4l2_rect_set_max_size(&fmt, &max_rect);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tif (dev->has_compose_cap) {\n\t\t\t\tv4l2_rect_set_min_size(compose, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(compose, &max_rect);\n\t\t\t}\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t} else if (dev->has_compose_cap) {\n\t\t\tstruct v4l2_rect fmt = dev->fmt_cap_rect;\n\n\t\t\tv4l2_rect_set_min_size(&fmt, &s->r);\n\t\t\tif (!v4l2_rect_same_size(&dev->fmt_cap_rect, &fmt) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tdev->fmt_cap_rect = fmt;\n\t\t\ttpg_s_buf_height(&dev->tpg, fmt.height);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t} else {\n\t\t\tif (!v4l2_rect_same_size(&s->r, &dev->fmt_cap_rect) &&\n\t\t\t    vb2_is_busy(&dev->vb_vid_cap_q))\n\t\t\t\treturn -EBUSY;\n\t\t\tv4l2_rect_set_size_to(&dev->fmt_cap_rect, &s->r);\n\t\t\tv4l2_rect_set_size_to(compose, &s->r);\n\t\t\tv4l2_rect_map_inside(compose, &dev->fmt_cap_rect);\n\t\t\ttpg_s_buf_height(&dev->tpg, dev->fmt_cap_rect.height);\n\t\t}\n\t\ts->r.top *= factor;\n\t\ts->r.height *= factor;\n\t\t*crop = s->r;\n\t\tbreak;\n\tcase V4L2_SEL_TGT_COMPOSE:\n\t\tif (!dev->has_compose_cap)\n\t\t\treturn -EINVAL;\n\t\tret = vivid_vid_adjust_sel(s->flags, &s->r);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tv4l2_rect_set_min_size(&s->r, &vivid_min_rect);\n\t\tv4l2_rect_set_max_size(&s->r, &dev->fmt_cap_rect);\n\t\tif (dev->has_scaler_cap) {\n\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t0, 0,\n\t\t\t\tdev->src_rect.width * MAX_ZOOM,\n\t\t\t\t(dev->src_rect.height / factor) * MAX_ZOOM\n\t\t\t};\n\n\t\t\tv4l2_rect_set_max_size(&s->r, &max_rect);\n\t\t\tif (dev->has_crop_cap) {\n\t\t\t\tstruct v4l2_rect min_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width / MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) / MAX_ZOOM\n\t\t\t\t};\n\t\t\t\tstruct v4l2_rect max_rect = {\n\t\t\t\t\t0, 0,\n\t\t\t\t\ts->r.width * MAX_ZOOM,\n\t\t\t\t\t(s->r.height * factor) * MAX_ZOOM\n\t\t\t\t};\n\n\t\t\t\tv4l2_rect_set_min_size(crop, &min_rect);\n\t\t\t\tv4l2_rect_set_max_size(crop, &max_rect);\n\t\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\t}\n\t\t} else if (dev->has_crop_cap) {\n\t\t\ts->r.top *= factor;\n\t\t\ts->r.height *= factor;\n\t\t\tv4l2_rect_set_max_size(&s->r, &dev->src_rect);\n\t\t\tv4l2_rect_set_size_to(crop, &s->r);\n\t\t\tv4l2_rect_map_inside(crop, &dev->crop_bounds_cap);\n\t\t\ts->r.top /= factor;\n\t\t\ts->r.height /= factor;\n\t\t} else {\n\t\t\tv4l2_rect_set_size_to(&s->r, &dev->src_rect);\n\t\t\ts->r.height /= factor;\n\t\t}\n\t\tv4l2_rect_map_inside(&s->r, &dev->fmt_cap_rect);\n\t\t*compose = s->r;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (dev->bitmap_cap && (compose->width != orig_compose_w ||\n\t\t\t\tcompose->height != orig_compose_h)) {\n\t\tvfree(dev->bitmap_cap);\n\t\tdev->bitmap_cap = NULL;\n\t}\n\ttpg_s_crop_compose(&dev->tpg, crop, compose);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,6 +3,8 @@\n \tstruct vivid_dev *dev = video_drvdata(file);\n \tstruct v4l2_rect *crop = &dev->crop_cap;\n \tstruct v4l2_rect *compose = &dev->compose_cap;\n+\tunsigned orig_compose_w = compose->width;\n+\tunsigned orig_compose_h = compose->height;\n \tunsigned factor = V4L2_FIELD_HAS_T_OR_B(dev->field_cap) ? 2 : 1;\n \tint ret;\n \n@@ -119,17 +121,17 @@\n \t\t\ts->r.height /= factor;\n \t\t}\n \t\tv4l2_rect_map_inside(&s->r, &dev->fmt_cap_rect);\n-\t\tif (dev->bitmap_cap && (compose->width != s->r.width ||\n-\t\t\t\t\tcompose->height != s->r.height)) {\n-\t\t\tvfree(dev->bitmap_cap);\n-\t\t\tdev->bitmap_cap = NULL;\n-\t\t}\n \t\t*compose = s->r;\n \t\tbreak;\n \tdefault:\n \t\treturn -EINVAL;\n \t}\n \n+\tif (dev->bitmap_cap && (compose->width != orig_compose_w ||\n+\t\t\t\tcompose->height != orig_compose_h)) {\n+\t\tvfree(dev->bitmap_cap);\n+\t\tdev->bitmap_cap = NULL;\n+\t}\n \ttpg_s_crop_compose(&dev->tpg, crop, compose);\n \treturn 0;\n }",
        "function_modified_lines": {
            "added": [
                "\tunsigned orig_compose_w = compose->width;",
                "\tunsigned orig_compose_h = compose->height;",
                "\tif (dev->bitmap_cap && (compose->width != orig_compose_w ||",
                "\t\t\t\tcompose->height != orig_compose_h)) {",
                "\t\tvfree(dev->bitmap_cap);",
                "\t\tdev->bitmap_cap = NULL;",
                "\t}"
            ],
            "deleted": [
                "\t\tif (dev->bitmap_cap && (compose->width != s->r.width ||",
                "\t\t\t\t\tcompose->height != s->r.height)) {",
                "\t\t\tvfree(dev->bitmap_cap);",
                "\t\t\tdev->bitmap_cap = NULL;",
                "\t\t}"
            ]
        },
        "cwe": [
            "CWE-369",
            "CWE-190",
            "CWE-401"
        ],
        "cve_description": "A memory leak flaw and potential divide by zero and Integer overflow was found in the Linux kernel V4L2 and vivid test code functionality. This issue occurs when a user triggers ioctls, such as VIDIOC_S_DV_TIMINGS ioctl. This could allow a local user to crash the system if vivid test code enabled.",
        "id": 3838
    },
    {
        "cve_id": "CVE-2019-18809",
        "code_before_change": "static int af9005_identify_state(struct usb_device *udev,\n\t\t\t\t struct dvb_usb_device_properties *props,\n\t\t\t\t struct dvb_usb_device_description **desc,\n\t\t\t\t int *cold)\n{\n\tint ret;\n\tu8 reply, *buf;\n\n\tbuf = kmalloc(FW_BULKOUT_SIZE + 2, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = af9005_boot_packet(udev, FW_CONFIG, &reply,\n\t\t\t\t buf, FW_BULKOUT_SIZE + 2);\n\tif (ret)\n\t\tgoto err;\n\tdeb_info(\"result of FW_CONFIG in identify state %d\\n\", reply);\n\tif (reply == 0x01)\n\t\t*cold = 1;\n\telse if (reply == 0x02)\n\t\t*cold = 0;\n\telse\n\t\treturn -EIO;\n\tdeb_info(\"Identify state cold = %d\\n\", *cold);\n\nerr:\n\tkfree(buf);\n\treturn ret;\n}",
        "code_after_change": "static int af9005_identify_state(struct usb_device *udev,\n\t\t\t\t struct dvb_usb_device_properties *props,\n\t\t\t\t struct dvb_usb_device_description **desc,\n\t\t\t\t int *cold)\n{\n\tint ret;\n\tu8 reply, *buf;\n\n\tbuf = kmalloc(FW_BULKOUT_SIZE + 2, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = af9005_boot_packet(udev, FW_CONFIG, &reply,\n\t\t\t\t buf, FW_BULKOUT_SIZE + 2);\n\tif (ret)\n\t\tgoto err;\n\tdeb_info(\"result of FW_CONFIG in identify state %d\\n\", reply);\n\tif (reply == 0x01)\n\t\t*cold = 1;\n\telse if (reply == 0x02)\n\t\t*cold = 0;\n\telse\n\t\tret = -EIO;\n\tif (!ret)\n\t\tdeb_info(\"Identify state cold = %d\\n\", *cold);\n\nerr:\n\tkfree(buf);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -20,8 +20,9 @@\n \telse if (reply == 0x02)\n \t\t*cold = 0;\n \telse\n-\t\treturn -EIO;\n-\tdeb_info(\"Identify state cold = %d\\n\", *cold);\n+\t\tret = -EIO;\n+\tif (!ret)\n+\t\tdeb_info(\"Identify state cold = %d\\n\", *cold);\n \n err:\n \tkfree(buf);",
        "function_modified_lines": {
            "added": [
                "\t\tret = -EIO;",
                "\tif (!ret)",
                "\t\tdeb_info(\"Identify state cold = %d\\n\", *cold);"
            ],
            "deleted": [
                "\t\treturn -EIO;",
                "\tdeb_info(\"Identify state cold = %d\\n\", *cold);"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the af9005_identify_state() function in drivers/media/usb/dvb-usb/af9005.c in the Linux kernel through 5.3.9 allows attackers to cause a denial of service (memory consumption), aka CID-2289adbfa559.",
        "id": 2101
    },
    {
        "cve_id": "CVE-2019-18812",
        "code_before_change": "static ssize_t sof_dfsentry_write(struct file *file, const char __user *buffer,\n\t\t\t\t  size_t count, loff_t *ppos)\n{\n#if IS_ENABLED(CONFIG_SND_SOC_SOF_DEBUG_IPC_FLOOD_TEST)\n\tstruct snd_sof_dfsentry *dfse = file->private_data;\n\tstruct snd_sof_dev *sdev = dfse->sdev;\n\tunsigned long ipc_duration_ms = 0;\n\tbool flood_duration_test = false;\n\tunsigned long ipc_count = 0;\n\tstruct dentry *dentry;\n\tint err;\n#endif\n\tsize_t size;\n\tchar *string;\n\tint ret;\n\n\tstring = kzalloc(count, GFP_KERNEL);\n\tif (!string)\n\t\treturn -ENOMEM;\n\n\tsize = simple_write_to_buffer(string, count, ppos, buffer, count);\n\tret = size;\n\n#if IS_ENABLED(CONFIG_SND_SOC_SOF_DEBUG_IPC_FLOOD_TEST)\n\t/*\n\t * write op is only supported for ipc_flood_count or\n\t * ipc_flood_duration_ms debugfs entries atm.\n\t * ipc_flood_count floods the DSP with the number of IPC's specified.\n\t * ipc_duration_ms test floods the DSP for the time specified\n\t * in the debugfs entry.\n\t */\n\tdentry = file->f_path.dentry;\n\tif (strcmp(dentry->d_name.name, \"ipc_flood_count\") &&\n\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))\n\t\treturn -EINVAL;\n\n\tif (!strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))\n\t\tflood_duration_test = true;\n\n\t/* test completion criterion */\n\tif (flood_duration_test)\n\t\tret = kstrtoul(string, 0, &ipc_duration_ms);\n\telse\n\t\tret = kstrtoul(string, 0, &ipc_count);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t/* limit max duration/ipc count for flood test */\n\tif (flood_duration_test) {\n\t\tif (!ipc_duration_ms) {\n\t\t\tret = size;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* find the minimum. min() is not used to avoid warnings */\n\t\tif (ipc_duration_ms > MAX_IPC_FLOOD_DURATION_MS)\n\t\t\tipc_duration_ms = MAX_IPC_FLOOD_DURATION_MS;\n\t} else {\n\t\tif (!ipc_count) {\n\t\t\tret = size;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* find the minimum. min() is not used to avoid warnings */\n\t\tif (ipc_count > MAX_IPC_FLOOD_COUNT)\n\t\t\tipc_count = MAX_IPC_FLOOD_COUNT;\n\t}\n\n\tret = pm_runtime_get_sync(sdev->dev);\n\tif (ret < 0) {\n\t\tdev_err_ratelimited(sdev->dev,\n\t\t\t\t    \"error: debugfs write failed to resume %d\\n\",\n\t\t\t\t    ret);\n\t\tpm_runtime_put_noidle(sdev->dev);\n\t\tgoto out;\n\t}\n\n\t/* flood test */\n\tret = sof_debug_ipc_flood_test(sdev, dfse, flood_duration_test,\n\t\t\t\t       ipc_duration_ms, ipc_count);\n\n\tpm_runtime_mark_last_busy(sdev->dev);\n\terr = pm_runtime_put_autosuspend(sdev->dev);\n\tif (err < 0)\n\t\tdev_err_ratelimited(sdev->dev,\n\t\t\t\t    \"error: debugfs write failed to idle %d\\n\",\n\t\t\t\t    err);\n\n\t/* return size if test is successful */\n\tif (ret >= 0)\n\t\tret = size;\nout:\n#endif\n\tkfree(string);\n\treturn ret;\n}",
        "code_after_change": "static ssize_t sof_dfsentry_write(struct file *file, const char __user *buffer,\n\t\t\t\t  size_t count, loff_t *ppos)\n{\n#if IS_ENABLED(CONFIG_SND_SOC_SOF_DEBUG_IPC_FLOOD_TEST)\n\tstruct snd_sof_dfsentry *dfse = file->private_data;\n\tstruct snd_sof_dev *sdev = dfse->sdev;\n\tunsigned long ipc_duration_ms = 0;\n\tbool flood_duration_test = false;\n\tunsigned long ipc_count = 0;\n\tstruct dentry *dentry;\n\tint err;\n#endif\n\tsize_t size;\n\tchar *string;\n\tint ret;\n\n\tstring = kzalloc(count, GFP_KERNEL);\n\tif (!string)\n\t\treturn -ENOMEM;\n\n\tsize = simple_write_to_buffer(string, count, ppos, buffer, count);\n\tret = size;\n\n#if IS_ENABLED(CONFIG_SND_SOC_SOF_DEBUG_IPC_FLOOD_TEST)\n\t/*\n\t * write op is only supported for ipc_flood_count or\n\t * ipc_flood_duration_ms debugfs entries atm.\n\t * ipc_flood_count floods the DSP with the number of IPC's specified.\n\t * ipc_duration_ms test floods the DSP for the time specified\n\t * in the debugfs entry.\n\t */\n\tdentry = file->f_path.dentry;\n\tif (strcmp(dentry->d_name.name, \"ipc_flood_count\") &&\n\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\")) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))\n\t\tflood_duration_test = true;\n\n\t/* test completion criterion */\n\tif (flood_duration_test)\n\t\tret = kstrtoul(string, 0, &ipc_duration_ms);\n\telse\n\t\tret = kstrtoul(string, 0, &ipc_count);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t/* limit max duration/ipc count for flood test */\n\tif (flood_duration_test) {\n\t\tif (!ipc_duration_ms) {\n\t\t\tret = size;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* find the minimum. min() is not used to avoid warnings */\n\t\tif (ipc_duration_ms > MAX_IPC_FLOOD_DURATION_MS)\n\t\t\tipc_duration_ms = MAX_IPC_FLOOD_DURATION_MS;\n\t} else {\n\t\tif (!ipc_count) {\n\t\t\tret = size;\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* find the minimum. min() is not used to avoid warnings */\n\t\tif (ipc_count > MAX_IPC_FLOOD_COUNT)\n\t\t\tipc_count = MAX_IPC_FLOOD_COUNT;\n\t}\n\n\tret = pm_runtime_get_sync(sdev->dev);\n\tif (ret < 0) {\n\t\tdev_err_ratelimited(sdev->dev,\n\t\t\t\t    \"error: debugfs write failed to resume %d\\n\",\n\t\t\t\t    ret);\n\t\tpm_runtime_put_noidle(sdev->dev);\n\t\tgoto out;\n\t}\n\n\t/* flood test */\n\tret = sof_debug_ipc_flood_test(sdev, dfse, flood_duration_test,\n\t\t\t\t       ipc_duration_ms, ipc_count);\n\n\tpm_runtime_mark_last_busy(sdev->dev);\n\terr = pm_runtime_put_autosuspend(sdev->dev);\n\tif (err < 0)\n\t\tdev_err_ratelimited(sdev->dev,\n\t\t\t\t    \"error: debugfs write failed to idle %d\\n\",\n\t\t\t\t    err);\n\n\t/* return size if test is successful */\n\tif (ret >= 0)\n\t\tret = size;\nout:\n#endif\n\tkfree(string);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,8 +31,10 @@\n \t */\n \tdentry = file->f_path.dentry;\n \tif (strcmp(dentry->d_name.name, \"ipc_flood_count\") &&\n-\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))\n-\t\treturn -EINVAL;\n+\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\")) {\n+\t\tret = -EINVAL;\n+\t\tgoto out;\n+\t}\n \n \tif (!strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))\n \t\tflood_duration_test = true;",
        "function_modified_lines": {
            "added": [
                "\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\")) {",
                "\t\tret = -EINVAL;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": [
                "\t    strcmp(dentry->d_name.name, \"ipc_flood_duration_ms\"))",
                "\t\treturn -EINVAL;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the sof_dfsentry_write() function in sound/soc/sof/debug.c in the Linux kernel through 5.3.9 allows attackers to cause a denial of service (memory consumption), aka CID-c0a333d842ef.",
        "id": 2104
    },
    {
        "cve_id": "CVE-2019-19082",
        "code_before_change": "struct resource_pool *dce112_create_resource_pool(\n\tuint8_t num_virtual_links,\n\tstruct dc *dc)\n{\n\tstruct dce110_resource_pool *pool =\n\t\tkzalloc(sizeof(struct dce110_resource_pool), GFP_KERNEL);\n\n\tif (!pool)\n\t\treturn NULL;\n\n\tif (construct(num_virtual_links, dc, pool))\n\t\treturn &pool->base;\n\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "code_after_change": "struct resource_pool *dce112_create_resource_pool(\n\tuint8_t num_virtual_links,\n\tstruct dc *dc)\n{\n\tstruct dce110_resource_pool *pool =\n\t\tkzalloc(sizeof(struct dce110_resource_pool), GFP_KERNEL);\n\n\tif (!pool)\n\t\treturn NULL;\n\n\tif (construct(num_virtual_links, dc, pool))\n\t\treturn &pool->base;\n\n\tkfree(pool);\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,6 +11,7 @@\n \tif (construct(num_virtual_links, dc, pool))\n \t\treturn &pool->base;\n \n+\tkfree(pool);\n \tBREAK_TO_DEBUGGER();\n \treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tkfree(pool);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Memory leaks in *create_resource_pool() functions under drivers/gpu/drm/amd/display/dc in the Linux kernel through 5.3.11 allow attackers to cause a denial of service (memory consumption). This affects the dce120_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce120/dce120_resource.c, the dce110_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce110/dce110_resource.c, the dce100_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce100/dce100_resource.c, the dcn10_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c, and the dce112_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c, aka CID-104c307147ad.",
        "id": 2167
    },
    {
        "cve_id": "CVE-2019-19082",
        "code_before_change": "struct resource_pool *dce110_create_resource_pool(\n\tuint8_t num_virtual_links,\n\tstruct dc *dc,\n\tstruct hw_asic_id asic_id)\n{\n\tstruct dce110_resource_pool *pool =\n\t\tkzalloc(sizeof(struct dce110_resource_pool), GFP_KERNEL);\n\n\tif (!pool)\n\t\treturn NULL;\n\n\tif (construct(num_virtual_links, dc, pool, asic_id))\n\t\treturn &pool->base;\n\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "code_after_change": "struct resource_pool *dce110_create_resource_pool(\n\tuint8_t num_virtual_links,\n\tstruct dc *dc,\n\tstruct hw_asic_id asic_id)\n{\n\tstruct dce110_resource_pool *pool =\n\t\tkzalloc(sizeof(struct dce110_resource_pool), GFP_KERNEL);\n\n\tif (!pool)\n\t\treturn NULL;\n\n\tif (construct(num_virtual_links, dc, pool, asic_id))\n\t\treturn &pool->base;\n\n\tkfree(pool);\n\tBREAK_TO_DEBUGGER();\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -12,6 +12,7 @@\n \tif (construct(num_virtual_links, dc, pool, asic_id))\n \t\treturn &pool->base;\n \n+\tkfree(pool);\n \tBREAK_TO_DEBUGGER();\n \treturn NULL;\n }",
        "function_modified_lines": {
            "added": [
                "\tkfree(pool);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Memory leaks in *create_resource_pool() functions under drivers/gpu/drm/amd/display/dc in the Linux kernel through 5.3.11 allow attackers to cause a denial of service (memory consumption). This affects the dce120_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce120/dce120_resource.c, the dce110_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce110/dce110_resource.c, the dce100_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce100/dce100_resource.c, the dcn10_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dcn10/dcn10_resource.c, and the dce112_create_resource_pool() function in drivers/gpu/drm/amd/display/dc/dce112/dce112_resource.c, aka CID-104c307147ad.",
        "id": 2166
    },
    {
        "cve_id": "CVE-2022-3633",
        "code_before_change": "static void j1939_session_destroy(struct j1939_session *session)\n{\n\tif (session->transmission) {\n\t\tif (session->err)\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_TX_ABORT);\n\t\telse\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_TX_ACK);\n\t} else if (session->err) {\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_RX_ABORT);\n\t}\n\n\tnetdev_dbg(session->priv->ndev, \"%s: 0x%p\\n\", __func__, session);\n\n\tWARN_ON_ONCE(!list_empty(&session->sk_session_queue_entry));\n\tWARN_ON_ONCE(!list_empty(&session->active_session_list_entry));\n\n\tskb_queue_purge(&session->skb_queue);\n\t__j1939_session_drop(session);\n\tj1939_priv_put(session->priv);\n\tkfree(session);\n}",
        "code_after_change": "static void j1939_session_destroy(struct j1939_session *session)\n{\n\tstruct sk_buff *skb;\n\n\tif (session->transmission) {\n\t\tif (session->err)\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_TX_ABORT);\n\t\telse\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_TX_ACK);\n\t} else if (session->err) {\n\t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_RX_ABORT);\n\t}\n\n\tnetdev_dbg(session->priv->ndev, \"%s: 0x%p\\n\", __func__, session);\n\n\tWARN_ON_ONCE(!list_empty(&session->sk_session_queue_entry));\n\tWARN_ON_ONCE(!list_empty(&session->active_session_list_entry));\n\n\twhile ((skb = skb_dequeue(&session->skb_queue)) != NULL) {\n\t\t/* drop ref taken in j1939_session_skb_queue() */\n\t\tskb_unref(skb);\n\t\tkfree_skb(skb);\n\t}\n\t__j1939_session_drop(session);\n\tj1939_priv_put(session->priv);\n\tkfree(session);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,7 @@\n static void j1939_session_destroy(struct j1939_session *session)\n {\n+\tstruct sk_buff *skb;\n+\n \tif (session->transmission) {\n \t\tif (session->err)\n \t\t\tj1939_sk_errqueue(session, J1939_ERRQUEUE_TX_ABORT);\n@@ -14,7 +16,11 @@\n \tWARN_ON_ONCE(!list_empty(&session->sk_session_queue_entry));\n \tWARN_ON_ONCE(!list_empty(&session->active_session_list_entry));\n \n-\tskb_queue_purge(&session->skb_queue);\n+\twhile ((skb = skb_dequeue(&session->skb_queue)) != NULL) {\n+\t\t/* drop ref taken in j1939_session_skb_queue() */\n+\t\tskb_unref(skb);\n+\t\tkfree_skb(skb);\n+\t}\n \t__j1939_session_drop(session);\n \tj1939_priv_put(session->priv);\n \tkfree(session);",
        "function_modified_lines": {
            "added": [
                "\tstruct sk_buff *skb;",
                "",
                "\twhile ((skb = skb_dequeue(&session->skb_queue)) != NULL) {",
                "\t\t/* drop ref taken in j1939_session_skb_queue() */",
                "\t\tskb_unref(skb);",
                "\t\tkfree_skb(skb);",
                "\t}"
            ],
            "deleted": [
                "\tskb_queue_purge(&session->skb_queue);"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A vulnerability classified as problematic has been found in Linux Kernel. Affected is the function j1939_session_destroy of the file net/can/j1939/transport.c. The manipulation leads to memory leak. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211932.",
        "id": 3667
    },
    {
        "cve_id": "CVE-2019-19067",
        "code_before_change": "static int acp_hw_init(void *handle)\n{\n\tint r, i;\n\tuint64_t acp_base;\n\tu32 val = 0;\n\tu32 count = 0;\n\tstruct device *dev;\n\tstruct i2s_platform_data *i2s_pdata;\n\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tconst struct amdgpu_ip_block *ip_block =\n\t\tamdgpu_device_ip_get_ip_block(adev, AMD_IP_BLOCK_TYPE_ACP);\n\n\tif (!ip_block)\n\t\treturn -EINVAL;\n\n\tr = amd_acp_hw_init(adev->acp.cgs_device,\n\t\t\t    ip_block->version->major, ip_block->version->minor);\n\t/* -ENODEV means board uses AZ rather than ACP */\n\tif (r == -ENODEV) {\n\t\tamdgpu_dpm_set_powergating_by_smu(adev, AMD_IP_BLOCK_TYPE_ACP, true);\n\t\treturn 0;\n\t} else if (r) {\n\t\treturn r;\n\t}\n\n\tif (adev->rmmio_size == 0 || adev->rmmio_size < 0x5289)\n\t\treturn -EINVAL;\n\n\tacp_base = adev->rmmio_base;\n\n\n\tadev->acp.acp_genpd = kzalloc(sizeof(struct acp_pm_domain), GFP_KERNEL);\n\tif (adev->acp.acp_genpd == NULL)\n\t\treturn -ENOMEM;\n\n\tadev->acp.acp_genpd->gpd.name = \"ACP_AUDIO\";\n\tadev->acp.acp_genpd->gpd.power_off = acp_poweroff;\n\tadev->acp.acp_genpd->gpd.power_on = acp_poweron;\n\n\n\tadev->acp.acp_genpd->adev = adev;\n\n\tpm_genpd_init(&adev->acp.acp_genpd->gpd, NULL, false);\n\n\tadev->acp.acp_cell = kcalloc(ACP_DEVS, sizeof(struct mfd_cell),\n\t\t\t\t\t\t\tGFP_KERNEL);\n\n\tif (adev->acp.acp_cell == NULL)\n\t\treturn -ENOMEM;\n\n\tadev->acp.acp_res = kcalloc(5, sizeof(struct resource), GFP_KERNEL);\n\tif (adev->acp.acp_res == NULL) {\n\t\tkfree(adev->acp.acp_cell);\n\t\treturn -ENOMEM;\n\t}\n\n\ti2s_pdata = kcalloc(3, sizeof(struct i2s_platform_data), GFP_KERNEL);\n\tif (i2s_pdata == NULL) {\n\t\tkfree(adev->acp.acp_res);\n\t\tkfree(adev->acp.acp_cell);\n\t\treturn -ENOMEM;\n\t}\n\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[0].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\ti2s_pdata[0].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET;\n\t}\n\ti2s_pdata[0].cap = DWC_I2S_PLAY;\n\ti2s_pdata[0].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[0].i2s_reg_comp1 = ACP_I2S_COMP1_PLAY_REG_OFFSET;\n\ti2s_pdata[0].i2s_reg_comp2 = ACP_I2S_COMP2_PLAY_REG_OFFSET;\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[1].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_COMP_PARAM1 |\n\t\t\tDW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\ti2s_pdata[1].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_COMP_PARAM1;\n\t}\n\n\ti2s_pdata[1].cap = DWC_I2S_RECORD;\n\ti2s_pdata[1].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[1].i2s_reg_comp1 = ACP_I2S_COMP1_CAP_REG_OFFSET;\n\ti2s_pdata[1].i2s_reg_comp2 = ACP_I2S_COMP2_CAP_REG_OFFSET;\n\n\ti2s_pdata[2].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET;\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[2].quirks |= DW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ti2s_pdata[2].cap = DWC_I2S_PLAY | DWC_I2S_RECORD;\n\ti2s_pdata[2].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[2].i2s_reg_comp1 = ACP_BT_COMP1_REG_OFFSET;\n\ti2s_pdata[2].i2s_reg_comp2 = ACP_BT_COMP2_REG_OFFSET;\n\n\tadev->acp.acp_res[0].name = \"acp2x_dma\";\n\tadev->acp.acp_res[0].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[0].start = acp_base;\n\tadev->acp.acp_res[0].end = acp_base + ACP_DMA_REGS_END;\n\n\tadev->acp.acp_res[1].name = \"acp2x_dw_i2s_play\";\n\tadev->acp.acp_res[1].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[1].start = acp_base + ACP_I2S_PLAY_REGS_START;\n\tadev->acp.acp_res[1].end = acp_base + ACP_I2S_PLAY_REGS_END;\n\n\tadev->acp.acp_res[2].name = \"acp2x_dw_i2s_cap\";\n\tadev->acp.acp_res[2].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[2].start = acp_base + ACP_I2S_CAP_REGS_START;\n\tadev->acp.acp_res[2].end = acp_base + ACP_I2S_CAP_REGS_END;\n\n\tadev->acp.acp_res[3].name = \"acp2x_dw_bt_i2s_play_cap\";\n\tadev->acp.acp_res[3].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[3].start = acp_base + ACP_BT_PLAY_REGS_START;\n\tadev->acp.acp_res[3].end = acp_base + ACP_BT_PLAY_REGS_END;\n\n\tadev->acp.acp_res[4].name = \"acp2x_dma_irq\";\n\tadev->acp.acp_res[4].flags = IORESOURCE_IRQ;\n\tadev->acp.acp_res[4].start = amdgpu_irq_create_mapping(adev, 162);\n\tadev->acp.acp_res[4].end = adev->acp.acp_res[4].start;\n\n\tadev->acp.acp_cell[0].name = \"acp_audio_dma\";\n\tadev->acp.acp_cell[0].num_resources = 5;\n\tadev->acp.acp_cell[0].resources = &adev->acp.acp_res[0];\n\tadev->acp.acp_cell[0].platform_data = &adev->asic_type;\n\tadev->acp.acp_cell[0].pdata_size = sizeof(adev->asic_type);\n\n\tadev->acp.acp_cell[1].name = \"designware-i2s\";\n\tadev->acp.acp_cell[1].num_resources = 1;\n\tadev->acp.acp_cell[1].resources = &adev->acp.acp_res[1];\n\tadev->acp.acp_cell[1].platform_data = &i2s_pdata[0];\n\tadev->acp.acp_cell[1].pdata_size = sizeof(struct i2s_platform_data);\n\n\tadev->acp.acp_cell[2].name = \"designware-i2s\";\n\tadev->acp.acp_cell[2].num_resources = 1;\n\tadev->acp.acp_cell[2].resources = &adev->acp.acp_res[2];\n\tadev->acp.acp_cell[2].platform_data = &i2s_pdata[1];\n\tadev->acp.acp_cell[2].pdata_size = sizeof(struct i2s_platform_data);\n\n\tadev->acp.acp_cell[3].name = \"designware-i2s\";\n\tadev->acp.acp_cell[3].num_resources = 1;\n\tadev->acp.acp_cell[3].resources = &adev->acp.acp_res[3];\n\tadev->acp.acp_cell[3].platform_data = &i2s_pdata[2];\n\tadev->acp.acp_cell[3].pdata_size = sizeof(struct i2s_platform_data);\n\n\tr = mfd_add_hotplug_devices(adev->acp.parent, adev->acp.acp_cell,\n\t\t\t\t\t\t\t\tACP_DEVS);\n\tif (r)\n\t\treturn r;\n\n\tfor (i = 0; i < ACP_DEVS ; i++) {\n\t\tdev = get_mfd_cell_dev(adev->acp.acp_cell[i].name, i);\n\t\tr = pm_genpd_add_device(&adev->acp.acp_genpd->gpd, dev);\n\t\tif (r) {\n\t\t\tdev_err(dev, \"Failed to add dev to genpd\\n\");\n\t\t\treturn r;\n\t\t}\n\t}\n\n\n\t/* Assert Soft reset of ACP */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\n\tval |= ACP_SOFT_RESET__SoftResetAud_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_SOFT_RESET, val);\n\n\tcount = ACP_SOFT_RESET_DONE_TIME_OUT_VALUE;\n\twhile (true) {\n\t\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\t\tif (ACP_SOFT_RESET__SoftResetAudDone_MASK ==\n\t\t    (val & ACP_SOFT_RESET__SoftResetAudDone_MASK))\n\t\t\tbreak;\n\t\tif (--count == 0) {\n\t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t\tudelay(100);\n\t}\n\t/* Enable clock to ACP and wait until the clock is enabled */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_CONTROL);\n\tval = val | ACP_CONTROL__ClkEn_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_CONTROL, val);\n\n\tcount = ACP_CLOCK_EN_TIME_OUT_VALUE;\n\n\twhile (true) {\n\t\tval = cgs_read_register(adev->acp.cgs_device, mmACP_STATUS);\n\t\tif (val & (u32) 0x1)\n\t\t\tbreak;\n\t\tif (--count == 0) {\n\t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t\tudelay(100);\n\t}\n\t/* Deassert the SOFT RESET flags */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\tval &= ~ACP_SOFT_RESET__SoftResetAud_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_SOFT_RESET, val);\n\treturn 0;\n}",
        "code_after_change": "static int acp_hw_init(void *handle)\n{\n\tint r, i;\n\tuint64_t acp_base;\n\tu32 val = 0;\n\tu32 count = 0;\n\tstruct device *dev;\n\tstruct i2s_platform_data *i2s_pdata = NULL;\n\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tconst struct amdgpu_ip_block *ip_block =\n\t\tamdgpu_device_ip_get_ip_block(adev, AMD_IP_BLOCK_TYPE_ACP);\n\n\tif (!ip_block)\n\t\treturn -EINVAL;\n\n\tr = amd_acp_hw_init(adev->acp.cgs_device,\n\t\t\t    ip_block->version->major, ip_block->version->minor);\n\t/* -ENODEV means board uses AZ rather than ACP */\n\tif (r == -ENODEV) {\n\t\tamdgpu_dpm_set_powergating_by_smu(adev, AMD_IP_BLOCK_TYPE_ACP, true);\n\t\treturn 0;\n\t} else if (r) {\n\t\treturn r;\n\t}\n\n\tif (adev->rmmio_size == 0 || adev->rmmio_size < 0x5289)\n\t\treturn -EINVAL;\n\n\tacp_base = adev->rmmio_base;\n\n\n\tadev->acp.acp_genpd = kzalloc(sizeof(struct acp_pm_domain), GFP_KERNEL);\n\tif (adev->acp.acp_genpd == NULL)\n\t\treturn -ENOMEM;\n\n\tadev->acp.acp_genpd->gpd.name = \"ACP_AUDIO\";\n\tadev->acp.acp_genpd->gpd.power_off = acp_poweroff;\n\tadev->acp.acp_genpd->gpd.power_on = acp_poweron;\n\n\n\tadev->acp.acp_genpd->adev = adev;\n\n\tpm_genpd_init(&adev->acp.acp_genpd->gpd, NULL, false);\n\n\tadev->acp.acp_cell = kcalloc(ACP_DEVS, sizeof(struct mfd_cell),\n\t\t\t\t\t\t\tGFP_KERNEL);\n\n\tif (adev->acp.acp_cell == NULL) {\n\t\tr = -ENOMEM;\n\t\tgoto failure;\n\t}\n\n\tadev->acp.acp_res = kcalloc(5, sizeof(struct resource), GFP_KERNEL);\n\tif (adev->acp.acp_res == NULL) {\n\t\tr = -ENOMEM;\n\t\tgoto failure;\n\t}\n\n\ti2s_pdata = kcalloc(3, sizeof(struct i2s_platform_data), GFP_KERNEL);\n\tif (i2s_pdata == NULL) {\n\t\tr = -ENOMEM;\n\t\tgoto failure;\n\t}\n\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[0].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\ti2s_pdata[0].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET;\n\t}\n\ti2s_pdata[0].cap = DWC_I2S_PLAY;\n\ti2s_pdata[0].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[0].i2s_reg_comp1 = ACP_I2S_COMP1_PLAY_REG_OFFSET;\n\ti2s_pdata[0].i2s_reg_comp2 = ACP_I2S_COMP2_PLAY_REG_OFFSET;\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[1].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_COMP_PARAM1 |\n\t\t\tDW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\ti2s_pdata[1].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET |\n\t\t\tDW_I2S_QUIRK_COMP_PARAM1;\n\t}\n\n\ti2s_pdata[1].cap = DWC_I2S_RECORD;\n\ti2s_pdata[1].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[1].i2s_reg_comp1 = ACP_I2S_COMP1_CAP_REG_OFFSET;\n\ti2s_pdata[1].i2s_reg_comp2 = ACP_I2S_COMP2_CAP_REG_OFFSET;\n\n\ti2s_pdata[2].quirks = DW_I2S_QUIRK_COMP_REG_OFFSET;\n\tswitch (adev->asic_type) {\n\tcase CHIP_STONEY:\n\t\ti2s_pdata[2].quirks |= DW_I2S_QUIRK_16BIT_IDX_OVERRIDE;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ti2s_pdata[2].cap = DWC_I2S_PLAY | DWC_I2S_RECORD;\n\ti2s_pdata[2].snd_rates = SNDRV_PCM_RATE_8000_96000;\n\ti2s_pdata[2].i2s_reg_comp1 = ACP_BT_COMP1_REG_OFFSET;\n\ti2s_pdata[2].i2s_reg_comp2 = ACP_BT_COMP2_REG_OFFSET;\n\n\tadev->acp.acp_res[0].name = \"acp2x_dma\";\n\tadev->acp.acp_res[0].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[0].start = acp_base;\n\tadev->acp.acp_res[0].end = acp_base + ACP_DMA_REGS_END;\n\n\tadev->acp.acp_res[1].name = \"acp2x_dw_i2s_play\";\n\tadev->acp.acp_res[1].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[1].start = acp_base + ACP_I2S_PLAY_REGS_START;\n\tadev->acp.acp_res[1].end = acp_base + ACP_I2S_PLAY_REGS_END;\n\n\tadev->acp.acp_res[2].name = \"acp2x_dw_i2s_cap\";\n\tadev->acp.acp_res[2].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[2].start = acp_base + ACP_I2S_CAP_REGS_START;\n\tadev->acp.acp_res[2].end = acp_base + ACP_I2S_CAP_REGS_END;\n\n\tadev->acp.acp_res[3].name = \"acp2x_dw_bt_i2s_play_cap\";\n\tadev->acp.acp_res[3].flags = IORESOURCE_MEM;\n\tadev->acp.acp_res[3].start = acp_base + ACP_BT_PLAY_REGS_START;\n\tadev->acp.acp_res[3].end = acp_base + ACP_BT_PLAY_REGS_END;\n\n\tadev->acp.acp_res[4].name = \"acp2x_dma_irq\";\n\tadev->acp.acp_res[4].flags = IORESOURCE_IRQ;\n\tadev->acp.acp_res[4].start = amdgpu_irq_create_mapping(adev, 162);\n\tadev->acp.acp_res[4].end = adev->acp.acp_res[4].start;\n\n\tadev->acp.acp_cell[0].name = \"acp_audio_dma\";\n\tadev->acp.acp_cell[0].num_resources = 5;\n\tadev->acp.acp_cell[0].resources = &adev->acp.acp_res[0];\n\tadev->acp.acp_cell[0].platform_data = &adev->asic_type;\n\tadev->acp.acp_cell[0].pdata_size = sizeof(adev->asic_type);\n\n\tadev->acp.acp_cell[1].name = \"designware-i2s\";\n\tadev->acp.acp_cell[1].num_resources = 1;\n\tadev->acp.acp_cell[1].resources = &adev->acp.acp_res[1];\n\tadev->acp.acp_cell[1].platform_data = &i2s_pdata[0];\n\tadev->acp.acp_cell[1].pdata_size = sizeof(struct i2s_platform_data);\n\n\tadev->acp.acp_cell[2].name = \"designware-i2s\";\n\tadev->acp.acp_cell[2].num_resources = 1;\n\tadev->acp.acp_cell[2].resources = &adev->acp.acp_res[2];\n\tadev->acp.acp_cell[2].platform_data = &i2s_pdata[1];\n\tadev->acp.acp_cell[2].pdata_size = sizeof(struct i2s_platform_data);\n\n\tadev->acp.acp_cell[3].name = \"designware-i2s\";\n\tadev->acp.acp_cell[3].num_resources = 1;\n\tadev->acp.acp_cell[3].resources = &adev->acp.acp_res[3];\n\tadev->acp.acp_cell[3].platform_data = &i2s_pdata[2];\n\tadev->acp.acp_cell[3].pdata_size = sizeof(struct i2s_platform_data);\n\n\tr = mfd_add_hotplug_devices(adev->acp.parent, adev->acp.acp_cell,\n\t\t\t\t\t\t\t\tACP_DEVS);\n\tif (r)\n\t\tgoto failure;\n\n\tfor (i = 0; i < ACP_DEVS ; i++) {\n\t\tdev = get_mfd_cell_dev(adev->acp.acp_cell[i].name, i);\n\t\tr = pm_genpd_add_device(&adev->acp.acp_genpd->gpd, dev);\n\t\tif (r) {\n\t\t\tdev_err(dev, \"Failed to add dev to genpd\\n\");\n\t\t\tgoto failure;\n\t\t}\n\t}\n\n\n\t/* Assert Soft reset of ACP */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\n\tval |= ACP_SOFT_RESET__SoftResetAud_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_SOFT_RESET, val);\n\n\tcount = ACP_SOFT_RESET_DONE_TIME_OUT_VALUE;\n\twhile (true) {\n\t\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\t\tif (ACP_SOFT_RESET__SoftResetAudDone_MASK ==\n\t\t    (val & ACP_SOFT_RESET__SoftResetAudDone_MASK))\n\t\t\tbreak;\n\t\tif (--count == 0) {\n\t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n\t\t\tr = -ETIMEDOUT;\n\t\t\tgoto failure;\n\t\t}\n\t\tudelay(100);\n\t}\n\t/* Enable clock to ACP and wait until the clock is enabled */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_CONTROL);\n\tval = val | ACP_CONTROL__ClkEn_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_CONTROL, val);\n\n\tcount = ACP_CLOCK_EN_TIME_OUT_VALUE;\n\n\twhile (true) {\n\t\tval = cgs_read_register(adev->acp.cgs_device, mmACP_STATUS);\n\t\tif (val & (u32) 0x1)\n\t\t\tbreak;\n\t\tif (--count == 0) {\n\t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n\t\t\tr = -ETIMEDOUT;\n\t\t\tgoto failure;\n\t\t}\n\t\tudelay(100);\n\t}\n\t/* Deassert the SOFT RESET flags */\n\tval = cgs_read_register(adev->acp.cgs_device, mmACP_SOFT_RESET);\n\tval &= ~ACP_SOFT_RESET__SoftResetAud_MASK;\n\tcgs_write_register(adev->acp.cgs_device, mmACP_SOFT_RESET, val);\n\treturn 0;\n\nfailure:\n\tkfree(i2s_pdata);\n\tkfree(adev->acp.acp_res);\n\tkfree(adev->acp.acp_cell);\n\tkfree(adev->acp.acp_genpd);\n\treturn r;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tu32 val = 0;\n \tu32 count = 0;\n \tstruct device *dev;\n-\tstruct i2s_platform_data *i2s_pdata;\n+\tstruct i2s_platform_data *i2s_pdata = NULL;\n \n \tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n \n@@ -47,20 +47,21 @@\n \tadev->acp.acp_cell = kcalloc(ACP_DEVS, sizeof(struct mfd_cell),\n \t\t\t\t\t\t\tGFP_KERNEL);\n \n-\tif (adev->acp.acp_cell == NULL)\n-\t\treturn -ENOMEM;\n+\tif (adev->acp.acp_cell == NULL) {\n+\t\tr = -ENOMEM;\n+\t\tgoto failure;\n+\t}\n \n \tadev->acp.acp_res = kcalloc(5, sizeof(struct resource), GFP_KERNEL);\n \tif (adev->acp.acp_res == NULL) {\n-\t\tkfree(adev->acp.acp_cell);\n-\t\treturn -ENOMEM;\n+\t\tr = -ENOMEM;\n+\t\tgoto failure;\n \t}\n \n \ti2s_pdata = kcalloc(3, sizeof(struct i2s_platform_data), GFP_KERNEL);\n \tif (i2s_pdata == NULL) {\n-\t\tkfree(adev->acp.acp_res);\n-\t\tkfree(adev->acp.acp_cell);\n-\t\treturn -ENOMEM;\n+\t\tr = -ENOMEM;\n+\t\tgoto failure;\n \t}\n \n \tswitch (adev->asic_type) {\n@@ -157,14 +158,14 @@\n \tr = mfd_add_hotplug_devices(adev->acp.parent, adev->acp.acp_cell,\n \t\t\t\t\t\t\t\tACP_DEVS);\n \tif (r)\n-\t\treturn r;\n+\t\tgoto failure;\n \n \tfor (i = 0; i < ACP_DEVS ; i++) {\n \t\tdev = get_mfd_cell_dev(adev->acp.acp_cell[i].name, i);\n \t\tr = pm_genpd_add_device(&adev->acp.acp_genpd->gpd, dev);\n \t\tif (r) {\n \t\t\tdev_err(dev, \"Failed to add dev to genpd\\n\");\n-\t\t\treturn r;\n+\t\t\tgoto failure;\n \t\t}\n \t}\n \n@@ -183,7 +184,8 @@\n \t\t\tbreak;\n \t\tif (--count == 0) {\n \t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n-\t\t\treturn -ETIMEDOUT;\n+\t\t\tr = -ETIMEDOUT;\n+\t\t\tgoto failure;\n \t\t}\n \t\tudelay(100);\n \t}\n@@ -200,7 +202,8 @@\n \t\t\tbreak;\n \t\tif (--count == 0) {\n \t\t\tdev_err(&adev->pdev->dev, \"Failed to reset ACP\\n\");\n-\t\t\treturn -ETIMEDOUT;\n+\t\t\tr = -ETIMEDOUT;\n+\t\t\tgoto failure;\n \t\t}\n \t\tudelay(100);\n \t}\n@@ -209,4 +212,11 @@\n \tval &= ~ACP_SOFT_RESET__SoftResetAud_MASK;\n \tcgs_write_register(adev->acp.cgs_device, mmACP_SOFT_RESET, val);\n \treturn 0;\n+\n+failure:\n+\tkfree(i2s_pdata);\n+\tkfree(adev->acp.acp_res);\n+\tkfree(adev->acp.acp_cell);\n+\tkfree(adev->acp.acp_genpd);\n+\treturn r;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct i2s_platform_data *i2s_pdata = NULL;",
                "\tif (adev->acp.acp_cell == NULL) {",
                "\t\tr = -ENOMEM;",
                "\t\tgoto failure;",
                "\t}",
                "\t\tr = -ENOMEM;",
                "\t\tgoto failure;",
                "\t\tr = -ENOMEM;",
                "\t\tgoto failure;",
                "\t\tgoto failure;",
                "\t\t\tgoto failure;",
                "\t\t\tr = -ETIMEDOUT;",
                "\t\t\tgoto failure;",
                "\t\t\tr = -ETIMEDOUT;",
                "\t\t\tgoto failure;",
                "",
                "failure:",
                "\tkfree(i2s_pdata);",
                "\tkfree(adev->acp.acp_res);",
                "\tkfree(adev->acp.acp_cell);",
                "\tkfree(adev->acp.acp_genpd);",
                "\treturn r;"
            ],
            "deleted": [
                "\tstruct i2s_platform_data *i2s_pdata;",
                "\tif (adev->acp.acp_cell == NULL)",
                "\t\treturn -ENOMEM;",
                "\t\tkfree(adev->acp.acp_cell);",
                "\t\treturn -ENOMEM;",
                "\t\tkfree(adev->acp.acp_res);",
                "\t\tkfree(adev->acp.acp_cell);",
                "\t\treturn -ENOMEM;",
                "\t\treturn r;",
                "\t\t\treturn r;",
                "\t\t\treturn -ETIMEDOUT;",
                "\t\t\treturn -ETIMEDOUT;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Four memory leaks in the acp_hw_init() function in drivers/gpu/drm/amd/amdgpu/amdgpu_acp.c in the Linux kernel before 5.3.8 allow attackers to cause a denial of service (memory consumption) by triggering mfd_add_hotplug_devices() or pm_genpd_add_device() failures, aka CID-57be09c6e874. NOTE: third parties dispute the relevance of this because the attacker must already have privileges for module loading",
        "id": 2148
    },
    {
        "cve_id": "CVE-2019-19044",
        "code_before_change": "int\nv3d_submit_cl_ioctl(struct drm_device *dev, void *data,\n\t\t    struct drm_file *file_priv)\n{\n\tstruct v3d_dev *v3d = to_v3d_dev(dev);\n\tstruct v3d_file_priv *v3d_priv = file_priv->driver_priv;\n\tstruct drm_v3d_submit_cl *args = data;\n\tstruct v3d_bin_job *bin = NULL;\n\tstruct v3d_render_job *render;\n\tstruct ww_acquire_ctx acquire_ctx;\n\tint ret = 0;\n\n\ttrace_v3d_submit_cl_ioctl(&v3d->drm, args->rcl_start, args->rcl_end);\n\n\tif (args->pad != 0) {\n\t\tDRM_INFO(\"pad must be zero: %d\\n\", args->pad);\n\t\treturn -EINVAL;\n\t}\n\n\trender = kcalloc(1, sizeof(*render), GFP_KERNEL);\n\tif (!render)\n\t\treturn -ENOMEM;\n\n\trender->start = args->rcl_start;\n\trender->end = args->rcl_end;\n\tINIT_LIST_HEAD(&render->unref_list);\n\n\tret = v3d_job_init(v3d, file_priv, &render->base,\n\t\t\t   v3d_render_job_free, args->in_sync_rcl);\n\tif (ret) {\n\t\tkfree(render);\n\t\treturn ret;\n\t}\n\n\tif (args->bcl_start != args->bcl_end) {\n\t\tbin = kcalloc(1, sizeof(*bin), GFP_KERNEL);\n\t\tif (!bin)\n\t\t\treturn -ENOMEM;\n\n\t\tret = v3d_job_init(v3d, file_priv, &bin->base,\n\t\t\t\t   v3d_job_free, args->in_sync_bcl);\n\t\tif (ret) {\n\t\t\tv3d_job_put(&render->base);\n\t\t\treturn ret;\n\t\t}\n\n\t\tbin->start = args->bcl_start;\n\t\tbin->end = args->bcl_end;\n\t\tbin->qma = args->qma;\n\t\tbin->qms = args->qms;\n\t\tbin->qts = args->qts;\n\t\tbin->render = render;\n\t}\n\n\tret = v3d_lookup_bos(dev, file_priv, &render->base,\n\t\t\t     args->bo_handles, args->bo_handle_count);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = v3d_lock_bo_reservations(&render->base, &acquire_ctx);\n\tif (ret)\n\t\tgoto fail;\n\n\tmutex_lock(&v3d->sched_lock);\n\tif (bin) {\n\t\tret = v3d_push_job(v3d_priv, &bin->base, V3D_BIN);\n\t\tif (ret)\n\t\t\tgoto fail_unreserve;\n\n\t\tret = drm_gem_fence_array_add(&render->base.deps,\n\t\t\t\t\t      dma_fence_get(bin->base.done_fence));\n\t\tif (ret)\n\t\t\tgoto fail_unreserve;\n\t}\n\n\tret = v3d_push_job(v3d_priv, &render->base, V3D_RENDER);\n\tif (ret)\n\t\tgoto fail_unreserve;\n\tmutex_unlock(&v3d->sched_lock);\n\n\tv3d_attach_fences_and_unlock_reservation(file_priv,\n\t\t\t\t\t\t &render->base,\n\t\t\t\t\t\t &acquire_ctx,\n\t\t\t\t\t\t args->out_sync,\n\t\t\t\t\t\t render->base.done_fence);\n\n\tif (bin)\n\t\tv3d_job_put(&bin->base);\n\tv3d_job_put(&render->base);\n\n\treturn 0;\n\nfail_unreserve:\n\tmutex_unlock(&v3d->sched_lock);\n\tdrm_gem_unlock_reservations(render->base.bo,\n\t\t\t\t    render->base.bo_count, &acquire_ctx);\nfail:\n\tif (bin)\n\t\tv3d_job_put(&bin->base);\n\tv3d_job_put(&render->base);\n\n\treturn ret;\n}",
        "code_after_change": "int\nv3d_submit_cl_ioctl(struct drm_device *dev, void *data,\n\t\t    struct drm_file *file_priv)\n{\n\tstruct v3d_dev *v3d = to_v3d_dev(dev);\n\tstruct v3d_file_priv *v3d_priv = file_priv->driver_priv;\n\tstruct drm_v3d_submit_cl *args = data;\n\tstruct v3d_bin_job *bin = NULL;\n\tstruct v3d_render_job *render;\n\tstruct ww_acquire_ctx acquire_ctx;\n\tint ret = 0;\n\n\ttrace_v3d_submit_cl_ioctl(&v3d->drm, args->rcl_start, args->rcl_end);\n\n\tif (args->pad != 0) {\n\t\tDRM_INFO(\"pad must be zero: %d\\n\", args->pad);\n\t\treturn -EINVAL;\n\t}\n\n\trender = kcalloc(1, sizeof(*render), GFP_KERNEL);\n\tif (!render)\n\t\treturn -ENOMEM;\n\n\trender->start = args->rcl_start;\n\trender->end = args->rcl_end;\n\tINIT_LIST_HEAD(&render->unref_list);\n\n\tret = v3d_job_init(v3d, file_priv, &render->base,\n\t\t\t   v3d_render_job_free, args->in_sync_rcl);\n\tif (ret) {\n\t\tkfree(render);\n\t\treturn ret;\n\t}\n\n\tif (args->bcl_start != args->bcl_end) {\n\t\tbin = kcalloc(1, sizeof(*bin), GFP_KERNEL);\n\t\tif (!bin) {\n\t\t\tv3d_job_put(&render->base);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tret = v3d_job_init(v3d, file_priv, &bin->base,\n\t\t\t\t   v3d_job_free, args->in_sync_bcl);\n\t\tif (ret) {\n\t\t\tv3d_job_put(&render->base);\n\t\t\tkfree(bin);\n\t\t\treturn ret;\n\t\t}\n\n\t\tbin->start = args->bcl_start;\n\t\tbin->end = args->bcl_end;\n\t\tbin->qma = args->qma;\n\t\tbin->qms = args->qms;\n\t\tbin->qts = args->qts;\n\t\tbin->render = render;\n\t}\n\n\tret = v3d_lookup_bos(dev, file_priv, &render->base,\n\t\t\t     args->bo_handles, args->bo_handle_count);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = v3d_lock_bo_reservations(&render->base, &acquire_ctx);\n\tif (ret)\n\t\tgoto fail;\n\n\tmutex_lock(&v3d->sched_lock);\n\tif (bin) {\n\t\tret = v3d_push_job(v3d_priv, &bin->base, V3D_BIN);\n\t\tif (ret)\n\t\t\tgoto fail_unreserve;\n\n\t\tret = drm_gem_fence_array_add(&render->base.deps,\n\t\t\t\t\t      dma_fence_get(bin->base.done_fence));\n\t\tif (ret)\n\t\t\tgoto fail_unreserve;\n\t}\n\n\tret = v3d_push_job(v3d_priv, &render->base, V3D_RENDER);\n\tif (ret)\n\t\tgoto fail_unreserve;\n\tmutex_unlock(&v3d->sched_lock);\n\n\tv3d_attach_fences_and_unlock_reservation(file_priv,\n\t\t\t\t\t\t &render->base,\n\t\t\t\t\t\t &acquire_ctx,\n\t\t\t\t\t\t args->out_sync,\n\t\t\t\t\t\t render->base.done_fence);\n\n\tif (bin)\n\t\tv3d_job_put(&bin->base);\n\tv3d_job_put(&render->base);\n\n\treturn 0;\n\nfail_unreserve:\n\tmutex_unlock(&v3d->sched_lock);\n\tdrm_gem_unlock_reservations(render->base.bo,\n\t\t\t\t    render->base.bo_count, &acquire_ctx);\nfail:\n\tif (bin)\n\t\tv3d_job_put(&bin->base);\n\tv3d_job_put(&render->base);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -34,13 +34,16 @@\n \n \tif (args->bcl_start != args->bcl_end) {\n \t\tbin = kcalloc(1, sizeof(*bin), GFP_KERNEL);\n-\t\tif (!bin)\n+\t\tif (!bin) {\n+\t\t\tv3d_job_put(&render->base);\n \t\t\treturn -ENOMEM;\n+\t\t}\n \n \t\tret = v3d_job_init(v3d, file_priv, &bin->base,\n \t\t\t\t   v3d_job_free, args->in_sync_bcl);\n \t\tif (ret) {\n \t\t\tv3d_job_put(&render->base);\n+\t\t\tkfree(bin);\n \t\t\treturn ret;\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tif (!bin) {",
                "\t\t\tv3d_job_put(&render->base);",
                "\t\t}",
                "\t\t\tkfree(bin);"
            ],
            "deleted": [
                "\t\tif (!bin)"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "Two memory leaks in the v3d_submit_cl_ioctl() function in drivers/gpu/drm/v3d/v3d_gem.c in the Linux kernel before 5.3.11 allow attackers to cause a denial of service (memory consumption) by triggering kcalloc() or v3d_job_init() failures, aka CID-29cd13cfd762.",
        "id": 2125
    },
    {
        "cve_id": "CVE-2023-32247",
        "code_before_change": "int smb2_sess_setup(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct smb2_sess_setup_req *req = smb2_get_msg(work->request_buf);\n\tstruct smb2_sess_setup_rsp *rsp = smb2_get_msg(work->response_buf);\n\tstruct ksmbd_session *sess;\n\tstruct negotiate_message *negblob;\n\tunsigned int negblob_len, negblob_off;\n\tint rc = 0;\n\n\tksmbd_debug(SMB, \"Received request for session setup\\n\");\n\n\trsp->StructureSize = cpu_to_le16(9);\n\trsp->SessionFlags = 0;\n\trsp->SecurityBufferOffset = cpu_to_le16(72);\n\trsp->SecurityBufferLength = 0;\n\tinc_rfc1001_len(work->response_buf, 9);\n\n\tksmbd_conn_lock(conn);\n\tif (!req->hdr.SessionId) {\n\t\tsess = ksmbd_smb2_session_create();\n\t\tif (!sess) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\t\trsp->hdr.SessionId = cpu_to_le64(sess->id);\n\t\trc = ksmbd_session_register(conn, sess);\n\t\tif (rc)\n\t\t\tgoto out_err;\n\t} else if (conn->dialect >= SMB30_PROT_ID &&\n\t\t   (server_conf.flags & KSMBD_GLOBAL_FLAG_SMB3_MULTICHANNEL) &&\n\t\t   req->Flags & SMB2_SESSION_REQ_FLAG_BINDING) {\n\t\tu64 sess_id = le64_to_cpu(req->hdr.SessionId);\n\n\t\tsess = ksmbd_session_lookup_slowpath(sess_id);\n\t\tif (!sess) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (conn->dialect != sess->dialect) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (!(req->hdr.Flags & SMB2_FLAGS_SIGNED)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (strncmp(conn->ClientGUID, sess->ClientGUID,\n\t\t\t    SMB2_CLIENT_GUID_SIZE)) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_IN_PROGRESS) {\n\t\t\trc = -EACCES;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_EXPIRED) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_conn_need_reconnect(conn)) {\n\t\t\trc = -EFAULT;\n\t\t\tsess = NULL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_session_lookup(conn, sess_id)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tconn->binding = true;\n\t} else if ((conn->dialect < SMB30_PROT_ID ||\n\t\t    server_conf.flags & KSMBD_GLOBAL_FLAG_SMB3_MULTICHANNEL) &&\n\t\t   (req->Flags & SMB2_SESSION_REQ_FLAG_BINDING)) {\n\t\tsess = NULL;\n\t\trc = -EACCES;\n\t\tgoto out_err;\n\t} else {\n\t\tsess = ksmbd_session_lookup(conn,\n\t\t\t\t\t    le64_to_cpu(req->hdr.SessionId));\n\t\tif (!sess) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_EXPIRED) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_conn_need_reconnect(conn)) {\n\t\t\trc = -EFAULT;\n\t\t\tsess = NULL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\twork->sess = sess;\n\n\tnegblob_off = le16_to_cpu(req->SecurityBufferOffset);\n\tnegblob_len = le16_to_cpu(req->SecurityBufferLength);\n\tif (negblob_off < offsetof(struct smb2_sess_setup_req, Buffer) ||\n\t    negblob_len < offsetof(struct negotiate_message, NegotiateFlags)) {\n\t\trc = -EINVAL;\n\t\tgoto out_err;\n\t}\n\n\tnegblob = (struct negotiate_message *)((char *)&req->hdr.ProtocolId +\n\t\t\tnegblob_off);\n\n\tif (decode_negotiation_token(conn, negblob, negblob_len) == 0) {\n\t\tif (conn->mechToken)\n\t\t\tnegblob = (struct negotiate_message *)conn->mechToken;\n\t}\n\n\tif (server_conf.auth_mechs & conn->auth_mechs) {\n\t\trc = generate_preauth_hash(work);\n\t\tif (rc)\n\t\t\tgoto out_err;\n\n\t\tif (conn->preferred_auth_mech &\n\t\t\t\t(KSMBD_AUTH_KRB5 | KSMBD_AUTH_MSKRB5)) {\n\t\t\trc = krb5_authenticate(work);\n\t\t\tif (rc) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\n\t\t\tif (!ksmbd_conn_need_reconnect(conn)) {\n\t\t\t\tksmbd_conn_set_good(conn);\n\t\t\t\tsess->state = SMB2_SESSION_VALID;\n\t\t\t}\n\t\t\tkfree(sess->Preauth_HashValue);\n\t\t\tsess->Preauth_HashValue = NULL;\n\t\t} else if (conn->preferred_auth_mech == KSMBD_AUTH_NTLMSSP) {\n\t\t\tif (negblob->MessageType == NtLmNegotiate) {\n\t\t\t\trc = ntlm_negotiate(work, negblob, negblob_len);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto out_err;\n\t\t\t\trsp->hdr.Status =\n\t\t\t\t\tSTATUS_MORE_PROCESSING_REQUIRED;\n\t\t\t\t/*\n\t\t\t\t * Note: here total size -1 is done as an\n\t\t\t\t * adjustment for 0 size blob\n\t\t\t\t */\n\t\t\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\t\t\tle16_to_cpu(rsp->SecurityBufferLength) - 1);\n\n\t\t\t} else if (negblob->MessageType == NtLmAuthenticate) {\n\t\t\t\trc = ntlm_authenticate(work);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto out_err;\n\n\t\t\t\tif (!ksmbd_conn_need_reconnect(conn)) {\n\t\t\t\t\tksmbd_conn_set_good(conn);\n\t\t\t\t\tsess->state = SMB2_SESSION_VALID;\n\t\t\t\t}\n\t\t\t\tif (conn->binding) {\n\t\t\t\t\tstruct preauth_session *preauth_sess;\n\n\t\t\t\t\tpreauth_sess =\n\t\t\t\t\t\tksmbd_preauth_session_lookup(conn, sess->id);\n\t\t\t\t\tif (preauth_sess) {\n\t\t\t\t\t\tlist_del(&preauth_sess->preauth_entry);\n\t\t\t\t\t\tkfree(preauth_sess);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tkfree(sess->Preauth_HashValue);\n\t\t\t\tsess->Preauth_HashValue = NULL;\n\t\t\t} else {\n\t\t\t\tpr_info_ratelimited(\"Unknown NTLMSSP message type : 0x%x\\n\",\n\t\t\t\t\t\tle32_to_cpu(negblob->MessageType));\n\t\t\t\trc = -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\t/* TODO: need one more negotiation */\n\t\t\tpr_err(\"Not support the preferred authentication\\n\");\n\t\t\trc = -EINVAL;\n\t\t}\n\t} else {\n\t\tpr_err(\"Not support authentication\\n\");\n\t\trc = -EINVAL;\n\t}\n\nout_err:\n\tif (rc == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse if (rc == -ENOENT)\n\t\trsp->hdr.Status = STATUS_USER_SESSION_DELETED;\n\telse if (rc == -EACCES)\n\t\trsp->hdr.Status = STATUS_REQUEST_NOT_ACCEPTED;\n\telse if (rc == -EFAULT)\n\t\trsp->hdr.Status = STATUS_NETWORK_SESSION_EXPIRED;\n\telse if (rc == -ENOMEM)\n\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\telse if (rc)\n\t\trsp->hdr.Status = STATUS_LOGON_FAILURE;\n\n\tif (conn->use_spnego && conn->mechToken) {\n\t\tkfree(conn->mechToken);\n\t\tconn->mechToken = NULL;\n\t}\n\n\tif (rc < 0) {\n\t\t/*\n\t\t * SecurityBufferOffset should be set to zero\n\t\t * in session setup error response.\n\t\t */\n\t\trsp->SecurityBufferOffset = 0;\n\n\t\tif (sess) {\n\t\t\tbool try_delay = false;\n\n\t\t\t/*\n\t\t\t * To avoid dictionary attacks (repeated session setups rapidly sent) to\n\t\t\t * connect to server, ksmbd make a delay of a 5 seconds on session setup\n\t\t\t * failure to make it harder to send enough random connection requests\n\t\t\t * to break into a server.\n\t\t\t */\n\t\t\tif (sess->user && sess->user->flags & KSMBD_USER_FLAG_DELAY_SESSION)\n\t\t\t\ttry_delay = true;\n\n\t\t\tsess->state = SMB2_SESSION_EXPIRED;\n\t\t\tif (try_delay)\n\t\t\t\tssleep(5);\n\t\t}\n\t}\n\n\tksmbd_conn_unlock(conn);\n\treturn rc;\n}",
        "code_after_change": "int smb2_sess_setup(struct ksmbd_work *work)\n{\n\tstruct ksmbd_conn *conn = work->conn;\n\tstruct smb2_sess_setup_req *req = smb2_get_msg(work->request_buf);\n\tstruct smb2_sess_setup_rsp *rsp = smb2_get_msg(work->response_buf);\n\tstruct ksmbd_session *sess;\n\tstruct negotiate_message *negblob;\n\tunsigned int negblob_len, negblob_off;\n\tint rc = 0;\n\n\tksmbd_debug(SMB, \"Received request for session setup\\n\");\n\n\trsp->StructureSize = cpu_to_le16(9);\n\trsp->SessionFlags = 0;\n\trsp->SecurityBufferOffset = cpu_to_le16(72);\n\trsp->SecurityBufferLength = 0;\n\tinc_rfc1001_len(work->response_buf, 9);\n\n\tksmbd_conn_lock(conn);\n\tif (!req->hdr.SessionId) {\n\t\tsess = ksmbd_smb2_session_create();\n\t\tif (!sess) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\t\trsp->hdr.SessionId = cpu_to_le64(sess->id);\n\t\trc = ksmbd_session_register(conn, sess);\n\t\tif (rc)\n\t\t\tgoto out_err;\n\t} else if (conn->dialect >= SMB30_PROT_ID &&\n\t\t   (server_conf.flags & KSMBD_GLOBAL_FLAG_SMB3_MULTICHANNEL) &&\n\t\t   req->Flags & SMB2_SESSION_REQ_FLAG_BINDING) {\n\t\tu64 sess_id = le64_to_cpu(req->hdr.SessionId);\n\n\t\tsess = ksmbd_session_lookup_slowpath(sess_id);\n\t\tif (!sess) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (conn->dialect != sess->dialect) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (!(req->hdr.Flags & SMB2_FLAGS_SIGNED)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (strncmp(conn->ClientGUID, sess->ClientGUID,\n\t\t\t    SMB2_CLIENT_GUID_SIZE)) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_IN_PROGRESS) {\n\t\t\trc = -EACCES;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_EXPIRED) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_conn_need_reconnect(conn)) {\n\t\t\trc = -EFAULT;\n\t\t\tsess = NULL;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_session_lookup(conn, sess_id)) {\n\t\t\trc = -EACCES;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tconn->binding = true;\n\t} else if ((conn->dialect < SMB30_PROT_ID ||\n\t\t    server_conf.flags & KSMBD_GLOBAL_FLAG_SMB3_MULTICHANNEL) &&\n\t\t   (req->Flags & SMB2_SESSION_REQ_FLAG_BINDING)) {\n\t\tsess = NULL;\n\t\trc = -EACCES;\n\t\tgoto out_err;\n\t} else {\n\t\tsess = ksmbd_session_lookup(conn,\n\t\t\t\t\t    le64_to_cpu(req->hdr.SessionId));\n\t\tif (!sess) {\n\t\t\trc = -ENOENT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (sess->state == SMB2_SESSION_EXPIRED) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tif (ksmbd_conn_need_reconnect(conn)) {\n\t\t\trc = -EFAULT;\n\t\t\tsess = NULL;\n\t\t\tgoto out_err;\n\t\t}\n\t}\n\twork->sess = sess;\n\n\tnegblob_off = le16_to_cpu(req->SecurityBufferOffset);\n\tnegblob_len = le16_to_cpu(req->SecurityBufferLength);\n\tif (negblob_off < offsetof(struct smb2_sess_setup_req, Buffer) ||\n\t    negblob_len < offsetof(struct negotiate_message, NegotiateFlags)) {\n\t\trc = -EINVAL;\n\t\tgoto out_err;\n\t}\n\n\tnegblob = (struct negotiate_message *)((char *)&req->hdr.ProtocolId +\n\t\t\tnegblob_off);\n\n\tif (decode_negotiation_token(conn, negblob, negblob_len) == 0) {\n\t\tif (conn->mechToken)\n\t\t\tnegblob = (struct negotiate_message *)conn->mechToken;\n\t}\n\n\tif (server_conf.auth_mechs & conn->auth_mechs) {\n\t\trc = generate_preauth_hash(work);\n\t\tif (rc)\n\t\t\tgoto out_err;\n\n\t\tif (conn->preferred_auth_mech &\n\t\t\t\t(KSMBD_AUTH_KRB5 | KSMBD_AUTH_MSKRB5)) {\n\t\t\trc = krb5_authenticate(work);\n\t\t\tif (rc) {\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\n\t\t\tif (!ksmbd_conn_need_reconnect(conn)) {\n\t\t\t\tksmbd_conn_set_good(conn);\n\t\t\t\tsess->state = SMB2_SESSION_VALID;\n\t\t\t}\n\t\t\tkfree(sess->Preauth_HashValue);\n\t\t\tsess->Preauth_HashValue = NULL;\n\t\t} else if (conn->preferred_auth_mech == KSMBD_AUTH_NTLMSSP) {\n\t\t\tif (negblob->MessageType == NtLmNegotiate) {\n\t\t\t\trc = ntlm_negotiate(work, negblob, negblob_len);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto out_err;\n\t\t\t\trsp->hdr.Status =\n\t\t\t\t\tSTATUS_MORE_PROCESSING_REQUIRED;\n\t\t\t\t/*\n\t\t\t\t * Note: here total size -1 is done as an\n\t\t\t\t * adjustment for 0 size blob\n\t\t\t\t */\n\t\t\t\tinc_rfc1001_len(work->response_buf,\n\t\t\t\t\t\tle16_to_cpu(rsp->SecurityBufferLength) - 1);\n\n\t\t\t} else if (negblob->MessageType == NtLmAuthenticate) {\n\t\t\t\trc = ntlm_authenticate(work);\n\t\t\t\tif (rc)\n\t\t\t\t\tgoto out_err;\n\n\t\t\t\tif (!ksmbd_conn_need_reconnect(conn)) {\n\t\t\t\t\tksmbd_conn_set_good(conn);\n\t\t\t\t\tsess->state = SMB2_SESSION_VALID;\n\t\t\t\t}\n\t\t\t\tif (conn->binding) {\n\t\t\t\t\tstruct preauth_session *preauth_sess;\n\n\t\t\t\t\tpreauth_sess =\n\t\t\t\t\t\tksmbd_preauth_session_lookup(conn, sess->id);\n\t\t\t\t\tif (preauth_sess) {\n\t\t\t\t\t\tlist_del(&preauth_sess->preauth_entry);\n\t\t\t\t\t\tkfree(preauth_sess);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tkfree(sess->Preauth_HashValue);\n\t\t\t\tsess->Preauth_HashValue = NULL;\n\t\t\t} else {\n\t\t\t\tpr_info_ratelimited(\"Unknown NTLMSSP message type : 0x%x\\n\",\n\t\t\t\t\t\tle32_to_cpu(negblob->MessageType));\n\t\t\t\trc = -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\t/* TODO: need one more negotiation */\n\t\t\tpr_err(\"Not support the preferred authentication\\n\");\n\t\t\trc = -EINVAL;\n\t\t}\n\t} else {\n\t\tpr_err(\"Not support authentication\\n\");\n\t\trc = -EINVAL;\n\t}\n\nout_err:\n\tif (rc == -EINVAL)\n\t\trsp->hdr.Status = STATUS_INVALID_PARAMETER;\n\telse if (rc == -ENOENT)\n\t\trsp->hdr.Status = STATUS_USER_SESSION_DELETED;\n\telse if (rc == -EACCES)\n\t\trsp->hdr.Status = STATUS_REQUEST_NOT_ACCEPTED;\n\telse if (rc == -EFAULT)\n\t\trsp->hdr.Status = STATUS_NETWORK_SESSION_EXPIRED;\n\telse if (rc == -ENOMEM)\n\t\trsp->hdr.Status = STATUS_INSUFFICIENT_RESOURCES;\n\telse if (rc)\n\t\trsp->hdr.Status = STATUS_LOGON_FAILURE;\n\n\tif (conn->use_spnego && conn->mechToken) {\n\t\tkfree(conn->mechToken);\n\t\tconn->mechToken = NULL;\n\t}\n\n\tif (rc < 0) {\n\t\t/*\n\t\t * SecurityBufferOffset should be set to zero\n\t\t * in session setup error response.\n\t\t */\n\t\trsp->SecurityBufferOffset = 0;\n\n\t\tif (sess) {\n\t\t\tbool try_delay = false;\n\n\t\t\t/*\n\t\t\t * To avoid dictionary attacks (repeated session setups rapidly sent) to\n\t\t\t * connect to server, ksmbd make a delay of a 5 seconds on session setup\n\t\t\t * failure to make it harder to send enough random connection requests\n\t\t\t * to break into a server.\n\t\t\t */\n\t\t\tif (sess->user && sess->user->flags & KSMBD_USER_FLAG_DELAY_SESSION)\n\t\t\t\ttry_delay = true;\n\n\t\t\tsess->last_active = jiffies;\n\t\t\tsess->state = SMB2_SESSION_EXPIRED;\n\t\t\tif (try_delay)\n\t\t\t\tssleep(5);\n\t\t}\n\t}\n\n\tksmbd_conn_unlock(conn);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -226,6 +226,7 @@\n \t\t\tif (sess->user && sess->user->flags & KSMBD_USER_FLAG_DELAY_SESSION)\n \t\t\t\ttry_delay = true;\n \n+\t\t\tsess->last_active = jiffies;\n \t\t\tsess->state = SMB2_SESSION_EXPIRED;\n \t\t\tif (try_delay)\n \t\t\t\tssleep(5);",
        "function_modified_lines": {
            "added": [
                "\t\t\tsess->last_active = jiffies;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A flaw was found in the Linux kernel's ksmbd, a high-performance in-kernel SMB server. The specific flaw exists within the handling of SMB2_SESSION_SETUP commands. The issue results from the lack of control of resource consumption. An attacker can leverage this vulnerability to create a denial-of-service condition on the system.",
        "id": 4015
    },
    {
        "cve_id": "CVE-2019-19064",
        "code_before_change": "static int fsl_lpspi_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct fsl_lpspi_data *fsl_lpspi;\n\tstruct spi_controller *controller;\n\tstruct spi_imx_master *lpspi_platform_info =\n\t\tdev_get_platdata(&pdev->dev);\n\tstruct resource *res;\n\tint i, ret, irq;\n\tu32 temp;\n\tbool is_slave;\n\n\tis_slave = of_property_read_bool((&pdev->dev)->of_node, \"spi-slave\");\n\tif (is_slave)\n\t\tcontroller = spi_alloc_slave(&pdev->dev,\n\t\t\t\t\tsizeof(struct fsl_lpspi_data));\n\telse\n\t\tcontroller = spi_alloc_master(&pdev->dev,\n\t\t\t\t\tsizeof(struct fsl_lpspi_data));\n\n\tif (!controller)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, controller);\n\n\tfsl_lpspi = spi_controller_get_devdata(controller);\n\tfsl_lpspi->dev = &pdev->dev;\n\tfsl_lpspi->is_slave = is_slave;\n\n\tif (!fsl_lpspi->is_slave) {\n\t\tfor (i = 0; i < controller->num_chipselect; i++) {\n\t\t\tint cs_gpio = of_get_named_gpio(np, \"cs-gpios\", i);\n\n\t\t\tif (!gpio_is_valid(cs_gpio) && lpspi_platform_info)\n\t\t\t\tcs_gpio = lpspi_platform_info->chipselect[i];\n\n\t\t\tfsl_lpspi->chipselect[i] = cs_gpio;\n\t\t\tif (!gpio_is_valid(cs_gpio))\n\t\t\t\tcontinue;\n\n\t\t\tret = devm_gpio_request(&pdev->dev,\n\t\t\t\t\t\tfsl_lpspi->chipselect[i],\n\t\t\t\t\t\tDRIVER_NAME);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&pdev->dev, \"can't get cs gpios\\n\");\n\t\t\t\tgoto out_controller_put;\n\t\t\t}\n\t\t}\n\t\tcontroller->cs_gpios = fsl_lpspi->chipselect;\n\t\tcontroller->prepare_message = fsl_lpspi_prepare_message;\n\t}\n\n\tcontroller->bits_per_word_mask = SPI_BPW_RANGE_MASK(8, 32);\n\tcontroller->transfer_one = fsl_lpspi_transfer_one;\n\tcontroller->prepare_transfer_hardware = lpspi_prepare_xfer_hardware;\n\tcontroller->unprepare_transfer_hardware = lpspi_unprepare_xfer_hardware;\n\tcontroller->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;\n\tcontroller->flags = SPI_MASTER_MUST_RX | SPI_MASTER_MUST_TX;\n\tcontroller->dev.of_node = pdev->dev.of_node;\n\tcontroller->bus_num = pdev->id;\n\tcontroller->slave_abort = fsl_lpspi_slave_abort;\n\n\tinit_completion(&fsl_lpspi->xfer_done);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tfsl_lpspi->base = devm_ioremap_resource(&pdev->dev, res);\n\tif (IS_ERR(fsl_lpspi->base)) {\n\t\tret = PTR_ERR(fsl_lpspi->base);\n\t\tgoto out_controller_put;\n\t}\n\tfsl_lpspi->base_phys = res->start;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0) {\n\t\tret = irq;\n\t\tgoto out_controller_put;\n\t}\n\n\tret = devm_request_irq(&pdev->dev, irq, fsl_lpspi_isr, 0,\n\t\t\t       dev_name(&pdev->dev), fsl_lpspi);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"can't get irq%d: %d\\n\", irq, ret);\n\t\tgoto out_controller_put;\n\t}\n\n\tfsl_lpspi->clk_per = devm_clk_get(&pdev->dev, \"per\");\n\tif (IS_ERR(fsl_lpspi->clk_per)) {\n\t\tret = PTR_ERR(fsl_lpspi->clk_per);\n\t\tgoto out_controller_put;\n\t}\n\n\tfsl_lpspi->clk_ipg = devm_clk_get(&pdev->dev, \"ipg\");\n\tif (IS_ERR(fsl_lpspi->clk_ipg)) {\n\t\tret = PTR_ERR(fsl_lpspi->clk_ipg);\n\t\tgoto out_controller_put;\n\t}\n\n\t/* enable the clock */\n\tret = fsl_lpspi_init_rpm(fsl_lpspi);\n\tif (ret)\n\t\tgoto out_controller_put;\n\n\tret = pm_runtime_get_sync(fsl_lpspi->dev);\n\tif (ret < 0) {\n\t\tdev_err(fsl_lpspi->dev, \"failed to enable clock\\n\");\n\t\treturn ret;\n\t}\n\n\ttemp = readl(fsl_lpspi->base + IMX7ULP_PARAM);\n\tfsl_lpspi->txfifosize = 1 << (temp & 0x0f);\n\tfsl_lpspi->rxfifosize = 1 << ((temp >> 8) & 0x0f);\n\n\tret = fsl_lpspi_dma_init(&pdev->dev, fsl_lpspi, controller);\n\tif (ret == -EPROBE_DEFER)\n\t\tgoto out_controller_put;\n\n\tif (ret < 0)\n\t\tdev_err(&pdev->dev, \"dma setup error %d, use pio\\n\", ret);\n\n\tret = devm_spi_register_controller(&pdev->dev, controller);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"spi_register_controller error.\\n\");\n\t\tgoto out_controller_put;\n\t}\n\n\treturn 0;\n\nout_controller_put:\n\tspi_controller_put(controller);\n\n\treturn ret;\n}",
        "code_after_change": "static int fsl_lpspi_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct fsl_lpspi_data *fsl_lpspi;\n\tstruct spi_controller *controller;\n\tstruct spi_imx_master *lpspi_platform_info =\n\t\tdev_get_platdata(&pdev->dev);\n\tstruct resource *res;\n\tint i, ret, irq;\n\tu32 temp;\n\tbool is_slave;\n\n\tis_slave = of_property_read_bool((&pdev->dev)->of_node, \"spi-slave\");\n\tif (is_slave)\n\t\tcontroller = spi_alloc_slave(&pdev->dev,\n\t\t\t\t\tsizeof(struct fsl_lpspi_data));\n\telse\n\t\tcontroller = spi_alloc_master(&pdev->dev,\n\t\t\t\t\tsizeof(struct fsl_lpspi_data));\n\n\tif (!controller)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, controller);\n\n\tfsl_lpspi = spi_controller_get_devdata(controller);\n\tfsl_lpspi->dev = &pdev->dev;\n\tfsl_lpspi->is_slave = is_slave;\n\n\tif (!fsl_lpspi->is_slave) {\n\t\tfor (i = 0; i < controller->num_chipselect; i++) {\n\t\t\tint cs_gpio = of_get_named_gpio(np, \"cs-gpios\", i);\n\n\t\t\tif (!gpio_is_valid(cs_gpio) && lpspi_platform_info)\n\t\t\t\tcs_gpio = lpspi_platform_info->chipselect[i];\n\n\t\t\tfsl_lpspi->chipselect[i] = cs_gpio;\n\t\t\tif (!gpio_is_valid(cs_gpio))\n\t\t\t\tcontinue;\n\n\t\t\tret = devm_gpio_request(&pdev->dev,\n\t\t\t\t\t\tfsl_lpspi->chipselect[i],\n\t\t\t\t\t\tDRIVER_NAME);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(&pdev->dev, \"can't get cs gpios\\n\");\n\t\t\t\tgoto out_controller_put;\n\t\t\t}\n\t\t}\n\t\tcontroller->cs_gpios = fsl_lpspi->chipselect;\n\t\tcontroller->prepare_message = fsl_lpspi_prepare_message;\n\t}\n\n\tcontroller->bits_per_word_mask = SPI_BPW_RANGE_MASK(8, 32);\n\tcontroller->transfer_one = fsl_lpspi_transfer_one;\n\tcontroller->prepare_transfer_hardware = lpspi_prepare_xfer_hardware;\n\tcontroller->unprepare_transfer_hardware = lpspi_unprepare_xfer_hardware;\n\tcontroller->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;\n\tcontroller->flags = SPI_MASTER_MUST_RX | SPI_MASTER_MUST_TX;\n\tcontroller->dev.of_node = pdev->dev.of_node;\n\tcontroller->bus_num = pdev->id;\n\tcontroller->slave_abort = fsl_lpspi_slave_abort;\n\n\tinit_completion(&fsl_lpspi->xfer_done);\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tfsl_lpspi->base = devm_ioremap_resource(&pdev->dev, res);\n\tif (IS_ERR(fsl_lpspi->base)) {\n\t\tret = PTR_ERR(fsl_lpspi->base);\n\t\tgoto out_controller_put;\n\t}\n\tfsl_lpspi->base_phys = res->start;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0) {\n\t\tret = irq;\n\t\tgoto out_controller_put;\n\t}\n\n\tret = devm_request_irq(&pdev->dev, irq, fsl_lpspi_isr, 0,\n\t\t\t       dev_name(&pdev->dev), fsl_lpspi);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"can't get irq%d: %d\\n\", irq, ret);\n\t\tgoto out_controller_put;\n\t}\n\n\tfsl_lpspi->clk_per = devm_clk_get(&pdev->dev, \"per\");\n\tif (IS_ERR(fsl_lpspi->clk_per)) {\n\t\tret = PTR_ERR(fsl_lpspi->clk_per);\n\t\tgoto out_controller_put;\n\t}\n\n\tfsl_lpspi->clk_ipg = devm_clk_get(&pdev->dev, \"ipg\");\n\tif (IS_ERR(fsl_lpspi->clk_ipg)) {\n\t\tret = PTR_ERR(fsl_lpspi->clk_ipg);\n\t\tgoto out_controller_put;\n\t}\n\n\t/* enable the clock */\n\tret = fsl_lpspi_init_rpm(fsl_lpspi);\n\tif (ret)\n\t\tgoto out_controller_put;\n\n\tret = pm_runtime_get_sync(fsl_lpspi->dev);\n\tif (ret < 0) {\n\t\tdev_err(fsl_lpspi->dev, \"failed to enable clock\\n\");\n\t\tgoto out_controller_put;\n\t}\n\n\ttemp = readl(fsl_lpspi->base + IMX7ULP_PARAM);\n\tfsl_lpspi->txfifosize = 1 << (temp & 0x0f);\n\tfsl_lpspi->rxfifosize = 1 << ((temp >> 8) & 0x0f);\n\n\tret = fsl_lpspi_dma_init(&pdev->dev, fsl_lpspi, controller);\n\tif (ret == -EPROBE_DEFER)\n\t\tgoto out_controller_put;\n\n\tif (ret < 0)\n\t\tdev_err(&pdev->dev, \"dma setup error %d, use pio\\n\", ret);\n\n\tret = devm_spi_register_controller(&pdev->dev, controller);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"spi_register_controller error.\\n\");\n\t\tgoto out_controller_put;\n\t}\n\n\treturn 0;\n\nout_controller_put:\n\tspi_controller_put(controller);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -103,7 +103,7 @@\n \tret = pm_runtime_get_sync(fsl_lpspi->dev);\n \tif (ret < 0) {\n \t\tdev_err(fsl_lpspi->dev, \"failed to enable clock\\n\");\n-\t\treturn ret;\n+\t\tgoto out_controller_put;\n \t}\n \n \ttemp = readl(fsl_lpspi->base + IMX7ULP_PARAM);",
        "function_modified_lines": {
            "added": [
                "\t\tgoto out_controller_put;"
            ],
            "deleted": [
                "\t\treturn ret;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the fsl_lpspi_probe() function in drivers/spi/spi-fsl-lpspi.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering pm_runtime_get_sync() failures, aka CID-057b8945f78f. NOTE: third parties dispute the relevance of this because an attacker cannot realistically control these failures at probe time",
        "id": 2145
    },
    {
        "cve_id": "CVE-2019-18808",
        "code_before_change": "static noinline_for_stack int\nccp_run_sha_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n{\n\tstruct ccp_sha_engine *sha = &cmd->u.sha;\n\tstruct ccp_dm_workarea ctx;\n\tstruct ccp_data src;\n\tstruct ccp_op op;\n\tunsigned int ioffset, ooffset;\n\tunsigned int digest_size;\n\tint sb_count;\n\tconst void *init;\n\tu64 block_size;\n\tint ctx_size;\n\tint ret;\n\n\tswitch (sha->type) {\n\tcase CCP_SHA_TYPE_1:\n\t\tif (sha->ctx_len < SHA1_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA1_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_224:\n\t\tif (sha->ctx_len < SHA224_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA224_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_256:\n\t\tif (sha->ctx_len < SHA256_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA256_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_384:\n\t\tif (cmd_q->ccp->vdata->version < CCP_VERSION(4, 0)\n\t\t    || sha->ctx_len < SHA384_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA384_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_512:\n\t\tif (cmd_q->ccp->vdata->version < CCP_VERSION(4, 0)\n\t\t    || sha->ctx_len < SHA512_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA512_BLOCK_SIZE;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (!sha->ctx)\n\t\treturn -EINVAL;\n\n\tif (!sha->final && (sha->src_len & (block_size - 1)))\n\t\treturn -EINVAL;\n\n\t/* The version 3 device can't handle zero-length input */\n\tif (cmd_q->ccp->vdata->version == CCP_VERSION(3, 0)) {\n\n\t\tif (!sha->src_len) {\n\t\t\tunsigned int digest_len;\n\t\t\tconst u8 *sha_zero;\n\n\t\t\t/* Not final, just return */\n\t\t\tif (!sha->final)\n\t\t\t\treturn 0;\n\n\t\t\t/* CCP can't do a zero length sha operation so the\n\t\t\t * caller must buffer the data.\n\t\t\t */\n\t\t\tif (sha->msg_bits)\n\t\t\t\treturn -EINVAL;\n\n\t\t\t/* The CCP cannot perform zero-length sha operations\n\t\t\t * so the caller is required to buffer data for the\n\t\t\t * final operation. However, a sha operation for a\n\t\t\t * message with a total length of zero is valid so\n\t\t\t * known values are required to supply the result.\n\t\t\t */\n\t\t\tswitch (sha->type) {\n\t\t\tcase CCP_SHA_TYPE_1:\n\t\t\t\tsha_zero = sha1_zero_message_hash;\n\t\t\t\tdigest_len = SHA1_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tcase CCP_SHA_TYPE_224:\n\t\t\t\tsha_zero = sha224_zero_message_hash;\n\t\t\t\tdigest_len = SHA224_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tcase CCP_SHA_TYPE_256:\n\t\t\t\tsha_zero = sha256_zero_message_hash;\n\t\t\t\tdigest_len = SHA256_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tscatterwalk_map_and_copy((void *)sha_zero, sha->ctx, 0,\n\t\t\t\t\t\t digest_len, 1);\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* Set variables used throughout */\n\tswitch (sha->type) {\n\tcase CCP_SHA_TYPE_1:\n\t\tdigest_size = SHA1_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha1_init;\n\t\tctx_size = SHA1_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tif (cmd_q->ccp->vdata->version != CCP_VERSION(3, 0))\n\t\t\tooffset = ioffset = CCP_SB_BYTES - SHA1_DIGEST_SIZE;\n\t\telse\n\t\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_224:\n\t\tdigest_size = SHA224_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha224_init;\n\t\tctx_size = SHA256_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tioffset = 0;\n\t\tif (cmd_q->ccp->vdata->version != CCP_VERSION(3, 0))\n\t\t\tooffset = CCP_SB_BYTES - SHA224_DIGEST_SIZE;\n\t\telse\n\t\t\tooffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_256:\n\t\tdigest_size = SHA256_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha256_init;\n\t\tctx_size = SHA256_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_384:\n\t\tdigest_size = SHA384_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha384_init;\n\t\tctx_size = SHA512_DIGEST_SIZE;\n\t\tsb_count = 2;\n\t\tioffset = 0;\n\t\tooffset = 2 * CCP_SB_BYTES - SHA384_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_512:\n\t\tdigest_size = SHA512_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha512_init;\n\t\tctx_size = SHA512_DIGEST_SIZE;\n\t\tsb_count = 2;\n\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto e_data;\n\t}\n\n\t/* For zero-length plaintext the src pointer is ignored;\n\t * otherwise both parts must be valid\n\t */\n\tif (sha->src_len && !sha->src)\n\t\treturn -EINVAL;\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = CCP_NEW_JOBID(cmd_q->ccp);\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.u.sha.type = sha->type;\n\top.u.sha.msg_bits = sha->msg_bits;\n\n\t/* For SHA1/224/256 the context fits in a single (32-byte) SB entry;\n\t * SHA384/512 require 2 adjacent SB slots, with the right half in the\n\t * first slot, and the left half in the second. Each portion must then\n\t * be in little endian format: use the 256-bit byte swap option.\n\t */\n\tret = ccp_init_dm_workarea(&ctx, cmd_q, sb_count * CCP_SB_BYTES,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\treturn ret;\n\tif (sha->first) {\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tmemcpy(ctx.address + ioffset, init, ctx_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tmemcpy(ctx.address + ctx_size / 2, init,\n\t\t\t       ctx_size / 2);\n\t\t\tmemcpy(ctx.address, init + ctx_size / 2,\n\t\t\t       ctx_size / 2);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_ctx;\n\t\t}\n\t} else {\n\t\t/* Restore the context */\n\t\tret = ccp_set_dm_area(&ctx, 0, sha->ctx, 0,\n\t\t\t\t      sb_count * CCP_SB_BYTES);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\t}\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_ctx;\n\t}\n\n\tif (sha->src) {\n\t\t/* Send data to the CCP SHA engine; block_size is set above */\n\t\tret = ccp_init_data(&src, cmd_q, sha->src, sha->src_len,\n\t\t\t\t    block_size, DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\twhile (src.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&src, NULL, &op, block_size, false);\n\t\t\tif (sha->final && !src.sg_wa.bytes_left)\n\t\t\t\top.eom = 1;\n\n\t\t\tret = cmd_q->ccp->vdata->perform->sha(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_data;\n\t\t\t}\n\n\t\t\tccp_process_data(&src, NULL, &op);\n\t\t}\n\t} else {\n\t\top.eom = 1;\n\t\tret = cmd_q->ccp->vdata->perform->sha(&op);\n\t\tif (ret) {\n\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\tgoto e_data;\n\t\t}\n\t}\n\n\t/* Retrieve the SHA context - convert from LE to BE using\n\t * 32-byte (256-bit) byteswapping to BE\n\t */\n\tret = ccp_copy_from_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t       CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_data;\n\t}\n\n\tif (sha->final) {\n\t\t/* Finishing up, so get the digest */\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tccp_get_dm_area(&ctx, ooffset,\n\t\t\t\t\tsha->ctx, 0,\n\t\t\t\t\tdigest_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tccp_get_dm_area(&ctx, 0,\n\t\t\t\t\tsha->ctx, LSB_ITEM_SIZE - ooffset,\n\t\t\t\t\tLSB_ITEM_SIZE);\n\t\t\tccp_get_dm_area(&ctx, LSB_ITEM_SIZE + ooffset,\n\t\t\t\t\tsha->ctx, 0,\n\t\t\t\t\tLSB_ITEM_SIZE - ooffset);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_ctx;\n\t\t}\n\t} else {\n\t\t/* Stash the context */\n\t\tccp_get_dm_area(&ctx, 0, sha->ctx, 0,\n\t\t\t\tsb_count * CCP_SB_BYTES);\n\t}\n\n\tif (sha->final && sha->opad) {\n\t\t/* HMAC operation, recursively perform final SHA */\n\t\tstruct ccp_cmd hmac_cmd;\n\t\tstruct scatterlist sg;\n\t\tu8 *hmac_buf;\n\n\t\tif (sha->opad_len != block_size) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_data;\n\t\t}\n\n\t\thmac_buf = kmalloc(block_size + digest_size, GFP_KERNEL);\n\t\tif (!hmac_buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto e_data;\n\t\t}\n\t\tsg_init_one(&sg, hmac_buf, block_size + digest_size);\n\n\t\tscatterwalk_map_and_copy(hmac_buf, sha->opad, 0, block_size, 0);\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tmemcpy(hmac_buf + block_size,\n\t\t\t       ctx.address + ooffset,\n\t\t\t       digest_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tmemcpy(hmac_buf + block_size,\n\t\t\t       ctx.address + LSB_ITEM_SIZE + ooffset,\n\t\t\t       LSB_ITEM_SIZE);\n\t\t\tmemcpy(hmac_buf + block_size +\n\t\t\t       (LSB_ITEM_SIZE - ooffset),\n\t\t\t       ctx.address,\n\t\t\t       LSB_ITEM_SIZE);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_ctx;\n\t\t}\n\n\t\tmemset(&hmac_cmd, 0, sizeof(hmac_cmd));\n\t\thmac_cmd.engine = CCP_ENGINE_SHA;\n\t\thmac_cmd.u.sha.type = sha->type;\n\t\thmac_cmd.u.sha.ctx = sha->ctx;\n\t\thmac_cmd.u.sha.ctx_len = sha->ctx_len;\n\t\thmac_cmd.u.sha.src = &sg;\n\t\thmac_cmd.u.sha.src_len = block_size + digest_size;\n\t\thmac_cmd.u.sha.opad = NULL;\n\t\thmac_cmd.u.sha.opad_len = 0;\n\t\thmac_cmd.u.sha.first = 1;\n\t\thmac_cmd.u.sha.final = 1;\n\t\thmac_cmd.u.sha.msg_bits = (block_size + digest_size) << 3;\n\n\t\tret = ccp_run_sha_cmd(cmd_q, &hmac_cmd);\n\t\tif (ret)\n\t\t\tcmd->engine_error = hmac_cmd.engine_error;\n\n\t\tkfree(hmac_buf);\n\t}\n\ne_data:\n\tif (sha->src)\n\t\tccp_free_data(&src, cmd_q);\n\ne_ctx:\n\tccp_dm_free(&ctx);\n\n\treturn ret;\n}",
        "code_after_change": "static noinline_for_stack int\nccp_run_sha_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)\n{\n\tstruct ccp_sha_engine *sha = &cmd->u.sha;\n\tstruct ccp_dm_workarea ctx;\n\tstruct ccp_data src;\n\tstruct ccp_op op;\n\tunsigned int ioffset, ooffset;\n\tunsigned int digest_size;\n\tint sb_count;\n\tconst void *init;\n\tu64 block_size;\n\tint ctx_size;\n\tint ret;\n\n\tswitch (sha->type) {\n\tcase CCP_SHA_TYPE_1:\n\t\tif (sha->ctx_len < SHA1_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA1_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_224:\n\t\tif (sha->ctx_len < SHA224_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA224_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_256:\n\t\tif (sha->ctx_len < SHA256_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA256_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_384:\n\t\tif (cmd_q->ccp->vdata->version < CCP_VERSION(4, 0)\n\t\t    || sha->ctx_len < SHA384_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA384_BLOCK_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_512:\n\t\tif (cmd_q->ccp->vdata->version < CCP_VERSION(4, 0)\n\t\t    || sha->ctx_len < SHA512_DIGEST_SIZE)\n\t\t\treturn -EINVAL;\n\t\tblock_size = SHA512_BLOCK_SIZE;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (!sha->ctx)\n\t\treturn -EINVAL;\n\n\tif (!sha->final && (sha->src_len & (block_size - 1)))\n\t\treturn -EINVAL;\n\n\t/* The version 3 device can't handle zero-length input */\n\tif (cmd_q->ccp->vdata->version == CCP_VERSION(3, 0)) {\n\n\t\tif (!sha->src_len) {\n\t\t\tunsigned int digest_len;\n\t\t\tconst u8 *sha_zero;\n\n\t\t\t/* Not final, just return */\n\t\t\tif (!sha->final)\n\t\t\t\treturn 0;\n\n\t\t\t/* CCP can't do a zero length sha operation so the\n\t\t\t * caller must buffer the data.\n\t\t\t */\n\t\t\tif (sha->msg_bits)\n\t\t\t\treturn -EINVAL;\n\n\t\t\t/* The CCP cannot perform zero-length sha operations\n\t\t\t * so the caller is required to buffer data for the\n\t\t\t * final operation. However, a sha operation for a\n\t\t\t * message with a total length of zero is valid so\n\t\t\t * known values are required to supply the result.\n\t\t\t */\n\t\t\tswitch (sha->type) {\n\t\t\tcase CCP_SHA_TYPE_1:\n\t\t\t\tsha_zero = sha1_zero_message_hash;\n\t\t\t\tdigest_len = SHA1_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tcase CCP_SHA_TYPE_224:\n\t\t\t\tsha_zero = sha224_zero_message_hash;\n\t\t\t\tdigest_len = SHA224_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tcase CCP_SHA_TYPE_256:\n\t\t\t\tsha_zero = sha256_zero_message_hash;\n\t\t\t\tdigest_len = SHA256_DIGEST_SIZE;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tscatterwalk_map_and_copy((void *)sha_zero, sha->ctx, 0,\n\t\t\t\t\t\t digest_len, 1);\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* Set variables used throughout */\n\tswitch (sha->type) {\n\tcase CCP_SHA_TYPE_1:\n\t\tdigest_size = SHA1_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha1_init;\n\t\tctx_size = SHA1_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tif (cmd_q->ccp->vdata->version != CCP_VERSION(3, 0))\n\t\t\tooffset = ioffset = CCP_SB_BYTES - SHA1_DIGEST_SIZE;\n\t\telse\n\t\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_224:\n\t\tdigest_size = SHA224_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha224_init;\n\t\tctx_size = SHA256_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tioffset = 0;\n\t\tif (cmd_q->ccp->vdata->version != CCP_VERSION(3, 0))\n\t\t\tooffset = CCP_SB_BYTES - SHA224_DIGEST_SIZE;\n\t\telse\n\t\t\tooffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_256:\n\t\tdigest_size = SHA256_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha256_init;\n\t\tctx_size = SHA256_DIGEST_SIZE;\n\t\tsb_count = 1;\n\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_384:\n\t\tdigest_size = SHA384_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha384_init;\n\t\tctx_size = SHA512_DIGEST_SIZE;\n\t\tsb_count = 2;\n\t\tioffset = 0;\n\t\tooffset = 2 * CCP_SB_BYTES - SHA384_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_512:\n\t\tdigest_size = SHA512_DIGEST_SIZE;\n\t\tinit = (void *) ccp_sha512_init;\n\t\tctx_size = SHA512_DIGEST_SIZE;\n\t\tsb_count = 2;\n\t\tooffset = ioffset = 0;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto e_data;\n\t}\n\n\t/* For zero-length plaintext the src pointer is ignored;\n\t * otherwise both parts must be valid\n\t */\n\tif (sha->src_len && !sha->src)\n\t\treturn -EINVAL;\n\n\tmemset(&op, 0, sizeof(op));\n\top.cmd_q = cmd_q;\n\top.jobid = CCP_NEW_JOBID(cmd_q->ccp);\n\top.sb_ctx = cmd_q->sb_ctx; /* Pre-allocated */\n\top.u.sha.type = sha->type;\n\top.u.sha.msg_bits = sha->msg_bits;\n\n\t/* For SHA1/224/256 the context fits in a single (32-byte) SB entry;\n\t * SHA384/512 require 2 adjacent SB slots, with the right half in the\n\t * first slot, and the left half in the second. Each portion must then\n\t * be in little endian format: use the 256-bit byte swap option.\n\t */\n\tret = ccp_init_dm_workarea(&ctx, cmd_q, sb_count * CCP_SB_BYTES,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (ret)\n\t\treturn ret;\n\tif (sha->first) {\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tmemcpy(ctx.address + ioffset, init, ctx_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tmemcpy(ctx.address + ctx_size / 2, init,\n\t\t\t       ctx_size / 2);\n\t\t\tmemcpy(ctx.address, init + ctx_size / 2,\n\t\t\t       ctx_size / 2);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_ctx;\n\t\t}\n\t} else {\n\t\t/* Restore the context */\n\t\tret = ccp_set_dm_area(&ctx, 0, sha->ctx, 0,\n\t\t\t\t      sb_count * CCP_SB_BYTES);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\t}\n\n\tret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t     CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_ctx;\n\t}\n\n\tif (sha->src) {\n\t\t/* Send data to the CCP SHA engine; block_size is set above */\n\t\tret = ccp_init_data(&src, cmd_q, sha->src, sha->src_len,\n\t\t\t\t    block_size, DMA_TO_DEVICE);\n\t\tif (ret)\n\t\t\tgoto e_ctx;\n\n\t\twhile (src.sg_wa.bytes_left) {\n\t\t\tccp_prepare_data(&src, NULL, &op, block_size, false);\n\t\t\tif (sha->final && !src.sg_wa.bytes_left)\n\t\t\t\top.eom = 1;\n\n\t\t\tret = cmd_q->ccp->vdata->perform->sha(&op);\n\t\t\tif (ret) {\n\t\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\t\tgoto e_data;\n\t\t\t}\n\n\t\t\tccp_process_data(&src, NULL, &op);\n\t\t}\n\t} else {\n\t\top.eom = 1;\n\t\tret = cmd_q->ccp->vdata->perform->sha(&op);\n\t\tif (ret) {\n\t\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\t\tgoto e_data;\n\t\t}\n\t}\n\n\t/* Retrieve the SHA context - convert from LE to BE using\n\t * 32-byte (256-bit) byteswapping to BE\n\t */\n\tret = ccp_copy_from_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,\n\t\t\t       CCP_PASSTHRU_BYTESWAP_256BIT);\n\tif (ret) {\n\t\tcmd->engine_error = cmd_q->cmd_error;\n\t\tgoto e_data;\n\t}\n\n\tif (sha->final) {\n\t\t/* Finishing up, so get the digest */\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tccp_get_dm_area(&ctx, ooffset,\n\t\t\t\t\tsha->ctx, 0,\n\t\t\t\t\tdigest_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tccp_get_dm_area(&ctx, 0,\n\t\t\t\t\tsha->ctx, LSB_ITEM_SIZE - ooffset,\n\t\t\t\t\tLSB_ITEM_SIZE);\n\t\t\tccp_get_dm_area(&ctx, LSB_ITEM_SIZE + ooffset,\n\t\t\t\t\tsha->ctx, 0,\n\t\t\t\t\tLSB_ITEM_SIZE - ooffset);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_ctx;\n\t\t}\n\t} else {\n\t\t/* Stash the context */\n\t\tccp_get_dm_area(&ctx, 0, sha->ctx, 0,\n\t\t\t\tsb_count * CCP_SB_BYTES);\n\t}\n\n\tif (sha->final && sha->opad) {\n\t\t/* HMAC operation, recursively perform final SHA */\n\t\tstruct ccp_cmd hmac_cmd;\n\t\tstruct scatterlist sg;\n\t\tu8 *hmac_buf;\n\n\t\tif (sha->opad_len != block_size) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_data;\n\t\t}\n\n\t\thmac_buf = kmalloc(block_size + digest_size, GFP_KERNEL);\n\t\tif (!hmac_buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto e_data;\n\t\t}\n\t\tsg_init_one(&sg, hmac_buf, block_size + digest_size);\n\n\t\tscatterwalk_map_and_copy(hmac_buf, sha->opad, 0, block_size, 0);\n\t\tswitch (sha->type) {\n\t\tcase CCP_SHA_TYPE_1:\n\t\tcase CCP_SHA_TYPE_224:\n\t\tcase CCP_SHA_TYPE_256:\n\t\t\tmemcpy(hmac_buf + block_size,\n\t\t\t       ctx.address + ooffset,\n\t\t\t       digest_size);\n\t\t\tbreak;\n\t\tcase CCP_SHA_TYPE_384:\n\t\tcase CCP_SHA_TYPE_512:\n\t\t\tmemcpy(hmac_buf + block_size,\n\t\t\t       ctx.address + LSB_ITEM_SIZE + ooffset,\n\t\t\t       LSB_ITEM_SIZE);\n\t\t\tmemcpy(hmac_buf + block_size +\n\t\t\t       (LSB_ITEM_SIZE - ooffset),\n\t\t\t       ctx.address,\n\t\t\t       LSB_ITEM_SIZE);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tkfree(hmac_buf);\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_data;\n\t\t}\n\n\t\tmemset(&hmac_cmd, 0, sizeof(hmac_cmd));\n\t\thmac_cmd.engine = CCP_ENGINE_SHA;\n\t\thmac_cmd.u.sha.type = sha->type;\n\t\thmac_cmd.u.sha.ctx = sha->ctx;\n\t\thmac_cmd.u.sha.ctx_len = sha->ctx_len;\n\t\thmac_cmd.u.sha.src = &sg;\n\t\thmac_cmd.u.sha.src_len = block_size + digest_size;\n\t\thmac_cmd.u.sha.opad = NULL;\n\t\thmac_cmd.u.sha.opad_len = 0;\n\t\thmac_cmd.u.sha.first = 1;\n\t\thmac_cmd.u.sha.final = 1;\n\t\thmac_cmd.u.sha.msg_bits = (block_size + digest_size) << 3;\n\n\t\tret = ccp_run_sha_cmd(cmd_q, &hmac_cmd);\n\t\tif (ret)\n\t\t\tcmd->engine_error = hmac_cmd.engine_error;\n\n\t\tkfree(hmac_buf);\n\t}\n\ne_data:\n\tif (sha->src)\n\t\tccp_free_data(&src, cmd_q);\n\ne_ctx:\n\tccp_dm_free(&ctx);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -309,8 +309,9 @@\n \t\t\t       LSB_ITEM_SIZE);\n \t\t\tbreak;\n \t\tdefault:\n+\t\t\tkfree(hmac_buf);\n \t\t\tret = -EINVAL;\n-\t\t\tgoto e_ctx;\n+\t\t\tgoto e_data;\n \t\t}\n \n \t\tmemset(&hmac_cmd, 0, sizeof(hmac_cmd));",
        "function_modified_lines": {
            "added": [
                "\t\t\tkfree(hmac_buf);",
                "\t\t\tgoto e_data;"
            ],
            "deleted": [
                "\t\t\tgoto e_ctx;"
            ]
        },
        "cwe": [
            "CWE-401"
        ],
        "cve_description": "A memory leak in the ccp_run_sha_cmd() function in drivers/crypto/ccp/ccp-ops.c in the Linux kernel through 5.3.9 allows attackers to cause a denial of service (memory consumption), aka CID-128c66429247.",
        "id": 2100
    }
]