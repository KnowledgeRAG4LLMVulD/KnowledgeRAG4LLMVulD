[
    {
        "cve_id": "CVE-2016-3841",
        "code_before_change": "struct ipv6_txoptions *\nipv6_dup_options(struct sock *sk, struct ipv6_txoptions *opt)\n{\n\tstruct ipv6_txoptions *opt2;\n\n\topt2 = sock_kmalloc(sk, opt->tot_len, GFP_ATOMIC);\n\tif (opt2) {\n\t\tlong dif = (char *)opt2 - (char *)opt;\n\t\tmemcpy(opt2, opt, opt->tot_len);\n\t\tif (opt2->hopopt)\n\t\t\t*((char **)&opt2->hopopt) += dif;\n\t\tif (opt2->dst0opt)\n\t\t\t*((char **)&opt2->dst0opt) += dif;\n\t\tif (opt2->dst1opt)\n\t\t\t*((char **)&opt2->dst1opt) += dif;\n\t\tif (opt2->srcrt)\n\t\t\t*((char **)&opt2->srcrt) += dif;\n\t}\n\treturn opt2;\n}",
        "code_after_change": "struct ipv6_txoptions *\nipv6_dup_options(struct sock *sk, struct ipv6_txoptions *opt)\n{\n\tstruct ipv6_txoptions *opt2;\n\n\topt2 = sock_kmalloc(sk, opt->tot_len, GFP_ATOMIC);\n\tif (opt2) {\n\t\tlong dif = (char *)opt2 - (char *)opt;\n\t\tmemcpy(opt2, opt, opt->tot_len);\n\t\tif (opt2->hopopt)\n\t\t\t*((char **)&opt2->hopopt) += dif;\n\t\tif (opt2->dst0opt)\n\t\t\t*((char **)&opt2->dst0opt) += dif;\n\t\tif (opt2->dst1opt)\n\t\t\t*((char **)&opt2->dst1opt) += dif;\n\t\tif (opt2->srcrt)\n\t\t\t*((char **)&opt2->srcrt) += dif;\n\t\tatomic_set(&opt2->refcnt, 1);\n\t}\n\treturn opt2;\n}",
        "patch": "--- code before\n+++ code after\n@@ -15,6 +15,7 @@\n \t\t\t*((char **)&opt2->dst1opt) += dif;\n \t\tif (opt2->srcrt)\n \t\t\t*((char **)&opt2->srcrt) += dif;\n+\t\tatomic_set(&opt2->refcnt, 1);\n \t}\n \treturn opt2;\n }",
        "function_modified_lines": {
            "added": [
                "\t\tatomic_set(&opt2->refcnt, 1);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264",
            "CWE-416"
        ],
        "cve_description": "The IPv6 stack in the Linux kernel before 4.3.3 mishandles options data, which allows local users to gain privileges or cause a denial of service (use-after-free and system crash) via a crafted sendmsg system call.",
        "id": 995
    },
    {
        "cve_id": "CVE-2016-3841",
        "code_before_change": "struct sock *cookie_v6_check(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tcp_options_received tcp_opt;\n\tstruct inet_request_sock *ireq;\n\tstruct tcp_request_sock *treq;\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tconst struct tcphdr *th = tcp_hdr(skb);\n\t__u32 cookie = ntohl(th->ack_seq) - 1;\n\tstruct sock *ret = sk;\n\tstruct request_sock *req;\n\tint mss;\n\tstruct dst_entry *dst;\n\t__u8 rcv_wscale;\n\n\tif (!sysctl_tcp_syncookies || !th->ack || th->rst)\n\t\tgoto out;\n\n\tif (tcp_synq_no_recent_overflow(sk))\n\t\tgoto out;\n\n\tmss = __cookie_v6_check(ipv6_hdr(skb), th, cookie);\n\tif (mss == 0) {\n\t\tNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SYNCOOKIESFAILED);\n\t\tgoto out;\n\t}\n\n\tNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SYNCOOKIESRECV);\n\n\t/* check for timestamp cookie support */\n\tmemset(&tcp_opt, 0, sizeof(tcp_opt));\n\ttcp_parse_options(skb, &tcp_opt, 0, NULL);\n\n\tif (!cookie_timestamp_decode(&tcp_opt))\n\t\tgoto out;\n\n\tret = NULL;\n\treq = inet_reqsk_alloc(&tcp6_request_sock_ops, sk, false);\n\tif (!req)\n\t\tgoto out;\n\n\tireq = inet_rsk(req);\n\ttreq = tcp_rsk(req);\n\ttreq->tfo_listener = false;\n\n\tif (security_inet_conn_request(sk, skb, req))\n\t\tgoto out_free;\n\n\treq->mss = mss;\n\tireq->ir_rmt_port = th->source;\n\tireq->ir_num = ntohs(th->dest);\n\tireq->ir_v6_rmt_addr = ipv6_hdr(skb)->saddr;\n\tireq->ir_v6_loc_addr = ipv6_hdr(skb)->daddr;\n\tif (ipv6_opt_accepted(sk, skb, &TCP_SKB_CB(skb)->header.h6) ||\n\t    np->rxopt.bits.rxinfo || np->rxopt.bits.rxoinfo ||\n\t    np->rxopt.bits.rxhlim || np->rxopt.bits.rxohlim) {\n\t\tatomic_inc(&skb->users);\n\t\tireq->pktopts = skb;\n\t}\n\n\tireq->ir_iif = sk->sk_bound_dev_if;\n\t/* So that link locals have meaning */\n\tif (!sk->sk_bound_dev_if &&\n\t    ipv6_addr_type(&ireq->ir_v6_rmt_addr) & IPV6_ADDR_LINKLOCAL)\n\t\tireq->ir_iif = tcp_v6_iif(skb);\n\n\tireq->ir_mark = inet_request_mark(sk, skb);\n\n\treq->num_retrans = 0;\n\tireq->snd_wscale\t= tcp_opt.snd_wscale;\n\tireq->sack_ok\t\t= tcp_opt.sack_ok;\n\tireq->wscale_ok\t\t= tcp_opt.wscale_ok;\n\tireq->tstamp_ok\t\t= tcp_opt.saw_tstamp;\n\treq->ts_recent\t\t= tcp_opt.saw_tstamp ? tcp_opt.rcv_tsval : 0;\n\ttreq->snt_synack.v64\t= 0;\n\ttreq->rcv_isn = ntohl(th->seq) - 1;\n\ttreq->snt_isn = cookie;\n\n\t/*\n\t * We need to lookup the dst_entry to get the correct window size.\n\t * This is taken from tcp_v6_syn_recv_sock.  Somebody please enlighten\n\t * me if there is a preferred way.\n\t */\n\t{\n\t\tstruct in6_addr *final_p, final;\n\t\tstruct flowi6 fl6;\n\t\tmemset(&fl6, 0, sizeof(fl6));\n\t\tfl6.flowi6_proto = IPPROTO_TCP;\n\t\tfl6.daddr = ireq->ir_v6_rmt_addr;\n\t\tfinal_p = fl6_update_dst(&fl6, np->opt, &final);\n\t\tfl6.saddr = ireq->ir_v6_loc_addr;\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\t\tfl6.flowi6_mark = ireq->ir_mark;\n\t\tfl6.fl6_dport = ireq->ir_rmt_port;\n\t\tfl6.fl6_sport = inet_sk(sk)->inet_sport;\n\t\tsecurity_req_classify_flow(req, flowi6_to_flowi(&fl6));\n\n\t\tdst = ip6_dst_lookup_flow(sk, &fl6, final_p);\n\t\tif (IS_ERR(dst))\n\t\t\tgoto out_free;\n\t}\n\n\treq->rsk_window_clamp = tp->window_clamp ? :dst_metric(dst, RTAX_WINDOW);\n\ttcp_select_initial_window(tcp_full_space(sk), req->mss,\n\t\t\t\t  &req->rsk_rcv_wnd, &req->rsk_window_clamp,\n\t\t\t\t  ireq->wscale_ok, &rcv_wscale,\n\t\t\t\t  dst_metric(dst, RTAX_INITRWND));\n\n\tireq->rcv_wscale = rcv_wscale;\n\tireq->ecn_ok = cookie_ecn_ok(&tcp_opt, sock_net(sk), dst);\n\n\tret = tcp_get_cookie_sock(sk, skb, req, dst);\nout:\n\treturn ret;\nout_free:\n\treqsk_free(req);\n\treturn NULL;\n}",
        "code_after_change": "struct sock *cookie_v6_check(struct sock *sk, struct sk_buff *skb)\n{\n\tstruct tcp_options_received tcp_opt;\n\tstruct inet_request_sock *ireq;\n\tstruct tcp_request_sock *treq;\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tconst struct tcphdr *th = tcp_hdr(skb);\n\t__u32 cookie = ntohl(th->ack_seq) - 1;\n\tstruct sock *ret = sk;\n\tstruct request_sock *req;\n\tint mss;\n\tstruct dst_entry *dst;\n\t__u8 rcv_wscale;\n\n\tif (!sysctl_tcp_syncookies || !th->ack || th->rst)\n\t\tgoto out;\n\n\tif (tcp_synq_no_recent_overflow(sk))\n\t\tgoto out;\n\n\tmss = __cookie_v6_check(ipv6_hdr(skb), th, cookie);\n\tif (mss == 0) {\n\t\tNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SYNCOOKIESFAILED);\n\t\tgoto out;\n\t}\n\n\tNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SYNCOOKIESRECV);\n\n\t/* check for timestamp cookie support */\n\tmemset(&tcp_opt, 0, sizeof(tcp_opt));\n\ttcp_parse_options(skb, &tcp_opt, 0, NULL);\n\n\tif (!cookie_timestamp_decode(&tcp_opt))\n\t\tgoto out;\n\n\tret = NULL;\n\treq = inet_reqsk_alloc(&tcp6_request_sock_ops, sk, false);\n\tif (!req)\n\t\tgoto out;\n\n\tireq = inet_rsk(req);\n\ttreq = tcp_rsk(req);\n\ttreq->tfo_listener = false;\n\n\tif (security_inet_conn_request(sk, skb, req))\n\t\tgoto out_free;\n\n\treq->mss = mss;\n\tireq->ir_rmt_port = th->source;\n\tireq->ir_num = ntohs(th->dest);\n\tireq->ir_v6_rmt_addr = ipv6_hdr(skb)->saddr;\n\tireq->ir_v6_loc_addr = ipv6_hdr(skb)->daddr;\n\tif (ipv6_opt_accepted(sk, skb, &TCP_SKB_CB(skb)->header.h6) ||\n\t    np->rxopt.bits.rxinfo || np->rxopt.bits.rxoinfo ||\n\t    np->rxopt.bits.rxhlim || np->rxopt.bits.rxohlim) {\n\t\tatomic_inc(&skb->users);\n\t\tireq->pktopts = skb;\n\t}\n\n\tireq->ir_iif = sk->sk_bound_dev_if;\n\t/* So that link locals have meaning */\n\tif (!sk->sk_bound_dev_if &&\n\t    ipv6_addr_type(&ireq->ir_v6_rmt_addr) & IPV6_ADDR_LINKLOCAL)\n\t\tireq->ir_iif = tcp_v6_iif(skb);\n\n\tireq->ir_mark = inet_request_mark(sk, skb);\n\n\treq->num_retrans = 0;\n\tireq->snd_wscale\t= tcp_opt.snd_wscale;\n\tireq->sack_ok\t\t= tcp_opt.sack_ok;\n\tireq->wscale_ok\t\t= tcp_opt.wscale_ok;\n\tireq->tstamp_ok\t\t= tcp_opt.saw_tstamp;\n\treq->ts_recent\t\t= tcp_opt.saw_tstamp ? tcp_opt.rcv_tsval : 0;\n\ttreq->snt_synack.v64\t= 0;\n\ttreq->rcv_isn = ntohl(th->seq) - 1;\n\ttreq->snt_isn = cookie;\n\n\t/*\n\t * We need to lookup the dst_entry to get the correct window size.\n\t * This is taken from tcp_v6_syn_recv_sock.  Somebody please enlighten\n\t * me if there is a preferred way.\n\t */\n\t{\n\t\tstruct in6_addr *final_p, final;\n\t\tstruct flowi6 fl6;\n\t\tmemset(&fl6, 0, sizeof(fl6));\n\t\tfl6.flowi6_proto = IPPROTO_TCP;\n\t\tfl6.daddr = ireq->ir_v6_rmt_addr;\n\t\tfinal_p = fl6_update_dst(&fl6, rcu_dereference(np->opt), &final);\n\t\tfl6.saddr = ireq->ir_v6_loc_addr;\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\t\tfl6.flowi6_mark = ireq->ir_mark;\n\t\tfl6.fl6_dport = ireq->ir_rmt_port;\n\t\tfl6.fl6_sport = inet_sk(sk)->inet_sport;\n\t\tsecurity_req_classify_flow(req, flowi6_to_flowi(&fl6));\n\n\t\tdst = ip6_dst_lookup_flow(sk, &fl6, final_p);\n\t\tif (IS_ERR(dst))\n\t\t\tgoto out_free;\n\t}\n\n\treq->rsk_window_clamp = tp->window_clamp ? :dst_metric(dst, RTAX_WINDOW);\n\ttcp_select_initial_window(tcp_full_space(sk), req->mss,\n\t\t\t\t  &req->rsk_rcv_wnd, &req->rsk_window_clamp,\n\t\t\t\t  ireq->wscale_ok, &rcv_wscale,\n\t\t\t\t  dst_metric(dst, RTAX_INITRWND));\n\n\tireq->rcv_wscale = rcv_wscale;\n\tireq->ecn_ok = cookie_ecn_ok(&tcp_opt, sock_net(sk), dst);\n\n\tret = tcp_get_cookie_sock(sk, skb, req, dst);\nout:\n\treturn ret;\nout_free:\n\treqsk_free(req);\n\treturn NULL;\n}",
        "patch": "--- code before\n+++ code after\n@@ -87,7 +87,7 @@\n \t\tmemset(&fl6, 0, sizeof(fl6));\n \t\tfl6.flowi6_proto = IPPROTO_TCP;\n \t\tfl6.daddr = ireq->ir_v6_rmt_addr;\n-\t\tfinal_p = fl6_update_dst(&fl6, np->opt, &final);\n+\t\tfinal_p = fl6_update_dst(&fl6, rcu_dereference(np->opt), &final);\n \t\tfl6.saddr = ireq->ir_v6_loc_addr;\n \t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n \t\tfl6.flowi6_mark = ireq->ir_mark;",
        "function_modified_lines": {
            "added": [
                "\t\tfinal_p = fl6_update_dst(&fl6, rcu_dereference(np->opt), &final);"
            ],
            "deleted": [
                "\t\tfinal_p = fl6_update_dst(&fl6, np->opt, &final);"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-416"
        ],
        "cve_description": "The IPv6 stack in the Linux kernel before 4.3.3 mishandles options data, which allows local users to gain privileges or cause a denial of service (use-after-free and system crash) via a crafted sendmsg system call.",
        "id": 1004
    },
    {
        "cve_id": "CVE-2016-3841",
        "code_before_change": "static int rawv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct ipv6_txoptions opt_space;\n\tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n\tstruct in6_addr *daddr, *final_p, final;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct raw6_sock *rp = raw6_sk(sk);\n\tstruct ipv6_txoptions *opt = NULL;\n\tstruct ip6_flowlabel *flowlabel = NULL;\n\tstruct dst_entry *dst = NULL;\n\tstruct raw6_frag_vec rfv;\n\tstruct flowi6 fl6;\n\tint addr_len = msg->msg_namelen;\n\tint hlimit = -1;\n\tint tclass = -1;\n\tint dontfrag = -1;\n\tu16 proto;\n\tint err;\n\n\t/* Rough check on arithmetic overflow,\n\t   better check is made in ip6_append_data().\n\t */\n\tif (len > INT_MAX)\n\t\treturn -EMSGSIZE;\n\n\t/* Mirror BSD error message compatibility */\n\tif (msg->msg_flags & MSG_OOB)\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\tmemset(&fl6, 0, sizeof(fl6));\n\n\tfl6.flowi6_mark = sk->sk_mark;\n\n\tif (sin6) {\n\t\tif (addr_len < SIN6_LEN_RFC2133)\n\t\t\treturn -EINVAL;\n\n\t\tif (sin6->sin6_family && sin6->sin6_family != AF_INET6)\n\t\t\treturn -EAFNOSUPPORT;\n\n\t\t/* port is the proto value [0..255] carried in nexthdr */\n\t\tproto = ntohs(sin6->sin6_port);\n\n\t\tif (!proto)\n\t\t\tproto = inet->inet_num;\n\t\telse if (proto != inet->inet_num)\n\t\t\treturn -EINVAL;\n\n\t\tif (proto > 255)\n\t\t\treturn -EINVAL;\n\n\t\tdaddr = &sin6->sin6_addr;\n\t\tif (np->sndflow) {\n\t\t\tfl6.flowlabel = sin6->sin6_flowinfo&IPV6_FLOWINFO_MASK;\n\t\t\tif (fl6.flowlabel&IPV6_FLOWLABEL_MASK) {\n\t\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\t\tif (!flowlabel)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Otherwise it will be difficult to maintain\n\t\t * sk->sk_dst_cache.\n\t\t */\n\t\tif (sk->sk_state == TCP_ESTABLISHED &&\n\t\t    ipv6_addr_equal(daddr, &sk->sk_v6_daddr))\n\t\t\tdaddr = &sk->sk_v6_daddr;\n\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    sin6->sin6_scope_id &&\n\t\t    __ipv6_addr_needs_scope_id(__ipv6_addr_type(daddr)))\n\t\t\tfl6.flowi6_oif = sin6->sin6_scope_id;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\n\t\tproto = inet->inet_num;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t\tfl6.flowlabel = np->flow_label;\n\t}\n\n\tif (fl6.flowi6_oif == 0)\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\n\tif (msg->msg_controllen) {\n\t\topt = &opt_space;\n\t\tmemset(opt, 0, sizeof(struct ipv6_txoptions));\n\t\topt->tot_len = sizeof(struct ipv6_txoptions);\n\n\t\terr = ip6_datagram_send_ctl(sock_net(sk), sk, msg, &fl6, opt,\n\t\t\t\t\t    &hlimit, &tclass, &dontfrag);\n\t\tif (err < 0) {\n\t\t\tfl6_sock_release(flowlabel);\n\t\t\treturn err;\n\t\t}\n\t\tif ((fl6.flowlabel&IPV6_FLOWLABEL_MASK) && !flowlabel) {\n\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\tif (!flowlabel)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!(opt->opt_nflen|opt->opt_flen))\n\t\t\topt = NULL;\n\t}\n\tif (!opt)\n\t\topt = np->opt;\n\tif (flowlabel)\n\t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n\topt = ipv6_fixup_options(&opt_space, opt);\n\n\tfl6.flowi6_proto = proto;\n\trfv.msg = msg;\n\trfv.hlen = 0;\n\terr = rawv6_probe_proto_opt(&rfv, &fl6);\n\tif (err)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(daddr))\n\t\tfl6.daddr = *daddr;\n\telse\n\t\tfl6.daddr.s6_addr[15] = 0x1; /* :: means loopback (BSD'ism) */\n\tif (ipv6_addr_any(&fl6.saddr) && !ipv6_addr_any(&np->saddr))\n\t\tfl6.saddr = np->saddr;\n\n\tfinal_p = fl6_update_dst(&fl6, opt, &final);\n\n\tif (!fl6.flowi6_oif && ipv6_addr_is_multicast(&fl6.daddr))\n\t\tfl6.flowi6_oif = np->mcast_oif;\n\telse if (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->ucast_oif;\n\tsecurity_sk_classify_flow(sk, flowi6_to_flowi(&fl6));\n\n\tif (inet->hdrincl)\n\t\tfl6.flowi6_flags |= FLOWI_FLAG_KNOWN_NH;\n\n\tdst = ip6_dst_lookup_flow(sk, &fl6, final_p);\n\tif (IS_ERR(dst)) {\n\t\terr = PTR_ERR(dst);\n\t\tgoto out;\n\t}\n\tif (hlimit < 0)\n\t\thlimit = ip6_sk_dst_hoplimit(np, &fl6, dst);\n\n\tif (tclass < 0)\n\t\ttclass = np->tclass;\n\n\tif (dontfrag < 0)\n\t\tdontfrag = np->dontfrag;\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\n\nback_from_confirm:\n\tif (inet->hdrincl)\n\t\terr = rawv6_send_hdrinc(sk, msg, len, &fl6, &dst, msg->msg_flags);\n\telse {\n\t\tlock_sock(sk);\n\t\terr = ip6_append_data(sk, raw6_getfrag, &rfv,\n\t\t\tlen, 0, hlimit, tclass, opt, &fl6, (struct rt6_info *)dst,\n\t\t\tmsg->msg_flags, dontfrag);\n\n\t\tif (err)\n\t\t\tip6_flush_pending_frames(sk);\n\t\telse if (!(msg->msg_flags & MSG_MORE))\n\t\t\terr = rawv6_push_pending_frames(sk, &fl6, rp);\n\t\trelease_sock(sk);\n\t}\ndone:\n\tdst_release(dst);\nout:\n\tfl6_sock_release(flowlabel);\n\treturn err < 0 ? err : len;\ndo_confirm:\n\tdst_confirm(dst);\n\tif (!(msg->msg_flags & MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto done;\n}",
        "code_after_change": "static int rawv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct ipv6_txoptions *opt_to_free = NULL;\n\tstruct ipv6_txoptions opt_space;\n\tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n\tstruct in6_addr *daddr, *final_p, final;\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct raw6_sock *rp = raw6_sk(sk);\n\tstruct ipv6_txoptions *opt = NULL;\n\tstruct ip6_flowlabel *flowlabel = NULL;\n\tstruct dst_entry *dst = NULL;\n\tstruct raw6_frag_vec rfv;\n\tstruct flowi6 fl6;\n\tint addr_len = msg->msg_namelen;\n\tint hlimit = -1;\n\tint tclass = -1;\n\tint dontfrag = -1;\n\tu16 proto;\n\tint err;\n\n\t/* Rough check on arithmetic overflow,\n\t   better check is made in ip6_append_data().\n\t */\n\tif (len > INT_MAX)\n\t\treturn -EMSGSIZE;\n\n\t/* Mirror BSD error message compatibility */\n\tif (msg->msg_flags & MSG_OOB)\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t *\tGet and verify the address.\n\t */\n\tmemset(&fl6, 0, sizeof(fl6));\n\n\tfl6.flowi6_mark = sk->sk_mark;\n\n\tif (sin6) {\n\t\tif (addr_len < SIN6_LEN_RFC2133)\n\t\t\treturn -EINVAL;\n\n\t\tif (sin6->sin6_family && sin6->sin6_family != AF_INET6)\n\t\t\treturn -EAFNOSUPPORT;\n\n\t\t/* port is the proto value [0..255] carried in nexthdr */\n\t\tproto = ntohs(sin6->sin6_port);\n\n\t\tif (!proto)\n\t\t\tproto = inet->inet_num;\n\t\telse if (proto != inet->inet_num)\n\t\t\treturn -EINVAL;\n\n\t\tif (proto > 255)\n\t\t\treturn -EINVAL;\n\n\t\tdaddr = &sin6->sin6_addr;\n\t\tif (np->sndflow) {\n\t\t\tfl6.flowlabel = sin6->sin6_flowinfo&IPV6_FLOWINFO_MASK;\n\t\t\tif (fl6.flowlabel&IPV6_FLOWLABEL_MASK) {\n\t\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\t\tif (!flowlabel)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Otherwise it will be difficult to maintain\n\t\t * sk->sk_dst_cache.\n\t\t */\n\t\tif (sk->sk_state == TCP_ESTABLISHED &&\n\t\t    ipv6_addr_equal(daddr, &sk->sk_v6_daddr))\n\t\t\tdaddr = &sk->sk_v6_daddr;\n\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    sin6->sin6_scope_id &&\n\t\t    __ipv6_addr_needs_scope_id(__ipv6_addr_type(daddr)))\n\t\t\tfl6.flowi6_oif = sin6->sin6_scope_id;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\n\t\tproto = inet->inet_num;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t\tfl6.flowlabel = np->flow_label;\n\t}\n\n\tif (fl6.flowi6_oif == 0)\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\n\tif (msg->msg_controllen) {\n\t\topt = &opt_space;\n\t\tmemset(opt, 0, sizeof(struct ipv6_txoptions));\n\t\topt->tot_len = sizeof(struct ipv6_txoptions);\n\n\t\terr = ip6_datagram_send_ctl(sock_net(sk), sk, msg, &fl6, opt,\n\t\t\t\t\t    &hlimit, &tclass, &dontfrag);\n\t\tif (err < 0) {\n\t\t\tfl6_sock_release(flowlabel);\n\t\t\treturn err;\n\t\t}\n\t\tif ((fl6.flowlabel&IPV6_FLOWLABEL_MASK) && !flowlabel) {\n\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\tif (!flowlabel)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!(opt->opt_nflen|opt->opt_flen))\n\t\t\topt = NULL;\n\t}\n\tif (!opt) {\n\t\topt = txopt_get(np);\n\t\topt_to_free = opt;\n\t\t}\n\tif (flowlabel)\n\t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n\topt = ipv6_fixup_options(&opt_space, opt);\n\n\tfl6.flowi6_proto = proto;\n\trfv.msg = msg;\n\trfv.hlen = 0;\n\terr = rawv6_probe_proto_opt(&rfv, &fl6);\n\tif (err)\n\t\tgoto out;\n\n\tif (!ipv6_addr_any(daddr))\n\t\tfl6.daddr = *daddr;\n\telse\n\t\tfl6.daddr.s6_addr[15] = 0x1; /* :: means loopback (BSD'ism) */\n\tif (ipv6_addr_any(&fl6.saddr) && !ipv6_addr_any(&np->saddr))\n\t\tfl6.saddr = np->saddr;\n\n\tfinal_p = fl6_update_dst(&fl6, opt, &final);\n\n\tif (!fl6.flowi6_oif && ipv6_addr_is_multicast(&fl6.daddr))\n\t\tfl6.flowi6_oif = np->mcast_oif;\n\telse if (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->ucast_oif;\n\tsecurity_sk_classify_flow(sk, flowi6_to_flowi(&fl6));\n\n\tif (inet->hdrincl)\n\t\tfl6.flowi6_flags |= FLOWI_FLAG_KNOWN_NH;\n\n\tdst = ip6_dst_lookup_flow(sk, &fl6, final_p);\n\tif (IS_ERR(dst)) {\n\t\terr = PTR_ERR(dst);\n\t\tgoto out;\n\t}\n\tif (hlimit < 0)\n\t\thlimit = ip6_sk_dst_hoplimit(np, &fl6, dst);\n\n\tif (tclass < 0)\n\t\ttclass = np->tclass;\n\n\tif (dontfrag < 0)\n\t\tdontfrag = np->dontfrag;\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\n\nback_from_confirm:\n\tif (inet->hdrincl)\n\t\terr = rawv6_send_hdrinc(sk, msg, len, &fl6, &dst, msg->msg_flags);\n\telse {\n\t\tlock_sock(sk);\n\t\terr = ip6_append_data(sk, raw6_getfrag, &rfv,\n\t\t\tlen, 0, hlimit, tclass, opt, &fl6, (struct rt6_info *)dst,\n\t\t\tmsg->msg_flags, dontfrag);\n\n\t\tif (err)\n\t\t\tip6_flush_pending_frames(sk);\n\t\telse if (!(msg->msg_flags & MSG_MORE))\n\t\t\terr = rawv6_push_pending_frames(sk, &fl6, rp);\n\t\trelease_sock(sk);\n\t}\ndone:\n\tdst_release(dst);\nout:\n\tfl6_sock_release(flowlabel);\n\ttxopt_put(opt_to_free);\n\treturn err < 0 ? err : len;\ndo_confirm:\n\tdst_confirm(dst);\n\tif (!(msg->msg_flags & MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto done;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,6 @@\n static int rawv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n {\n+\tstruct ipv6_txoptions *opt_to_free = NULL;\n \tstruct ipv6_txoptions opt_space;\n \tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n \tstruct in6_addr *daddr, *final_p, final;\n@@ -106,8 +107,10 @@\n \t\tif (!(opt->opt_nflen|opt->opt_flen))\n \t\t\topt = NULL;\n \t}\n-\tif (!opt)\n-\t\topt = np->opt;\n+\tif (!opt) {\n+\t\topt = txopt_get(np);\n+\t\topt_to_free = opt;\n+\t\t}\n \tif (flowlabel)\n \t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n \topt = ipv6_fixup_options(&opt_space, opt);\n@@ -173,6 +176,7 @@\n \tdst_release(dst);\n out:\n \tfl6_sock_release(flowlabel);\n+\ttxopt_put(opt_to_free);\n \treturn err < 0 ? err : len;\n do_confirm:\n \tdst_confirm(dst);",
        "function_modified_lines": {
            "added": [
                "\tstruct ipv6_txoptions *opt_to_free = NULL;",
                "\tif (!opt) {",
                "\t\topt = txopt_get(np);",
                "\t\topt_to_free = opt;",
                "\t\t}",
                "\ttxopt_put(opt_to_free);"
            ],
            "deleted": [
                "\tif (!opt)",
                "\t\topt = np->opt;"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-416"
        ],
        "cve_description": "The IPv6 stack in the Linux kernel before 4.3.3 mishandles options data, which allows local users to gain privileges or cause a denial of service (use-after-free and system crash) via a crafted sendmsg system call.",
        "id": 1003
    },
    {
        "cve_id": "CVE-2016-3841",
        "code_before_change": "int udpv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct ipv6_txoptions opt_space;\n\tstruct udp_sock *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n\tstruct in6_addr *daddr, *final_p, final;\n\tstruct ipv6_txoptions *opt = NULL;\n\tstruct ip6_flowlabel *flowlabel = NULL;\n\tstruct flowi6 fl6;\n\tstruct dst_entry *dst;\n\tint addr_len = msg->msg_namelen;\n\tint ulen = len;\n\tint hlimit = -1;\n\tint tclass = -1;\n\tint dontfrag = -1;\n\tint corkreq = up->corkflag || msg->msg_flags&MSG_MORE;\n\tint err;\n\tint connected = 0;\n\tint is_udplite = IS_UDPLITE(sk);\n\tint (*getfrag)(void *, char *, int, int, int, struct sk_buff *);\n\n\t/* destination address check */\n\tif (sin6) {\n\t\tif (addr_len < offsetof(struct sockaddr, sa_data))\n\t\t\treturn -EINVAL;\n\n\t\tswitch (sin6->sin6_family) {\n\t\tcase AF_INET6:\n\t\t\tif (addr_len < SIN6_LEN_RFC2133)\n\t\t\t\treturn -EINVAL;\n\t\t\tdaddr = &sin6->sin6_addr;\n\t\t\tbreak;\n\t\tcase AF_INET:\n\t\t\tgoto do_udp_sendmsg;\n\t\tcase AF_UNSPEC:\n\t\t\tmsg->msg_name = sin6 = NULL;\n\t\t\tmsg->msg_namelen = addr_len = 0;\n\t\t\tdaddr = NULL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (!up->pending) {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t} else\n\t\tdaddr = NULL;\n\n\tif (daddr) {\n\t\tif (ipv6_addr_v4mapped(daddr)) {\n\t\t\tstruct sockaddr_in sin;\n\t\t\tsin.sin_family = AF_INET;\n\t\t\tsin.sin_port = sin6 ? sin6->sin6_port : inet->inet_dport;\n\t\t\tsin.sin_addr.s_addr = daddr->s6_addr32[3];\n\t\t\tmsg->msg_name = &sin;\n\t\t\tmsg->msg_namelen = sizeof(sin);\ndo_udp_sendmsg:\n\t\t\tif (__ipv6_only_sock(sk))\n\t\t\t\treturn -ENETUNREACH;\n\t\t\treturn udp_sendmsg(sk, msg, len);\n\t\t}\n\t}\n\n\tif (up->pending == AF_INET)\n\t\treturn udp_sendmsg(sk, msg, len);\n\n\t/* Rough check on arithmetic overflow,\n\t   better check is made in ip6_append_data().\n\t   */\n\tif (len > INT_MAX - sizeof(struct udphdr))\n\t\treturn -EMSGSIZE;\n\n\tgetfrag  =  is_udplite ?  udplite_getfrag : ip_generic_getfrag;\n\tif (up->pending) {\n\t\t/*\n\t\t * There are pending frames.\n\t\t * The socket lock must be held while it's corked.\n\t\t */\n\t\tlock_sock(sk);\n\t\tif (likely(up->pending)) {\n\t\t\tif (unlikely(up->pending != AF_INET6)) {\n\t\t\t\trelease_sock(sk);\n\t\t\t\treturn -EAFNOSUPPORT;\n\t\t\t}\n\t\t\tdst = NULL;\n\t\t\tgoto do_append_data;\n\t\t}\n\t\trelease_sock(sk);\n\t}\n\tulen += sizeof(struct udphdr);\n\n\tmemset(&fl6, 0, sizeof(fl6));\n\n\tif (sin6) {\n\t\tif (sin6->sin6_port == 0)\n\t\t\treturn -EINVAL;\n\n\t\tfl6.fl6_dport = sin6->sin6_port;\n\t\tdaddr = &sin6->sin6_addr;\n\n\t\tif (np->sndflow) {\n\t\t\tfl6.flowlabel = sin6->sin6_flowinfo&IPV6_FLOWINFO_MASK;\n\t\t\tif (fl6.flowlabel&IPV6_FLOWLABEL_MASK) {\n\t\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\t\tif (!flowlabel)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Otherwise it will be difficult to maintain\n\t\t * sk->sk_dst_cache.\n\t\t */\n\t\tif (sk->sk_state == TCP_ESTABLISHED &&\n\t\t    ipv6_addr_equal(daddr, &sk->sk_v6_daddr))\n\t\t\tdaddr = &sk->sk_v6_daddr;\n\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    sin6->sin6_scope_id &&\n\t\t    __ipv6_addr_needs_scope_id(__ipv6_addr_type(daddr)))\n\t\t\tfl6.flowi6_oif = sin6->sin6_scope_id;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\n\t\tfl6.fl6_dport = inet->inet_dport;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t\tfl6.flowlabel = np->flow_label;\n\t\tconnected = 1;\n\t}\n\n\tif (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\n\tif (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->sticky_pktinfo.ipi6_ifindex;\n\n\tfl6.flowi6_mark = sk->sk_mark;\n\n\tif (msg->msg_controllen) {\n\t\topt = &opt_space;\n\t\tmemset(opt, 0, sizeof(struct ipv6_txoptions));\n\t\topt->tot_len = sizeof(*opt);\n\n\t\terr = ip6_datagram_send_ctl(sock_net(sk), sk, msg, &fl6, opt,\n\t\t\t\t\t    &hlimit, &tclass, &dontfrag);\n\t\tif (err < 0) {\n\t\t\tfl6_sock_release(flowlabel);\n\t\t\treturn err;\n\t\t}\n\t\tif ((fl6.flowlabel&IPV6_FLOWLABEL_MASK) && !flowlabel) {\n\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\tif (!flowlabel)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!(opt->opt_nflen|opt->opt_flen))\n\t\t\topt = NULL;\n\t\tconnected = 0;\n\t}\n\tif (!opt)\n\t\topt = np->opt;\n\tif (flowlabel)\n\t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n\topt = ipv6_fixup_options(&opt_space, opt);\n\n\tfl6.flowi6_proto = sk->sk_protocol;\n\tif (!ipv6_addr_any(daddr))\n\t\tfl6.daddr = *daddr;\n\telse\n\t\tfl6.daddr.s6_addr[15] = 0x1; /* :: means loopback (BSD'ism) */\n\tif (ipv6_addr_any(&fl6.saddr) && !ipv6_addr_any(&np->saddr))\n\t\tfl6.saddr = np->saddr;\n\tfl6.fl6_sport = inet->inet_sport;\n\n\tfinal_p = fl6_update_dst(&fl6, opt, &final);\n\tif (final_p)\n\t\tconnected = 0;\n\n\tif (!fl6.flowi6_oif && ipv6_addr_is_multicast(&fl6.daddr)) {\n\t\tfl6.flowi6_oif = np->mcast_oif;\n\t\tconnected = 0;\n\t} else if (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->ucast_oif;\n\n\tsecurity_sk_classify_flow(sk, flowi6_to_flowi(&fl6));\n\n\tdst = ip6_sk_dst_lookup_flow(sk, &fl6, final_p);\n\tif (IS_ERR(dst)) {\n\t\terr = PTR_ERR(dst);\n\t\tdst = NULL;\n\t\tgoto out;\n\t}\n\n\tif (hlimit < 0)\n\t\thlimit = ip6_sk_dst_hoplimit(np, &fl6, dst);\n\n\tif (tclass < 0)\n\t\ttclass = np->tclass;\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\t/* Lockless fast path for the non-corking case */\n\tif (!corkreq) {\n\t\tstruct sk_buff *skb;\n\n\t\tskb = ip6_make_skb(sk, getfrag, msg, ulen,\n\t\t\t\t   sizeof(struct udphdr), hlimit, tclass, opt,\n\t\t\t\t   &fl6, (struct rt6_info *)dst,\n\t\t\t\t   msg->msg_flags, dontfrag);\n\t\terr = PTR_ERR(skb);\n\t\tif (!IS_ERR_OR_NULL(skb))\n\t\t\terr = udp_v6_send_skb(skb, &fl6);\n\t\tgoto release_dst;\n\t}\n\n\tlock_sock(sk);\n\tif (unlikely(up->pending)) {\n\t\t/* The socket is already corked while preparing it. */\n\t\t/* ... which is an evident application bug. --ANK */\n\t\trelease_sock(sk);\n\n\t\tnet_dbg_ratelimited(\"udp cork app bug 2\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tup->pending = AF_INET6;\n\ndo_append_data:\n\tif (dontfrag < 0)\n\t\tdontfrag = np->dontfrag;\n\tup->len += ulen;\n\terr = ip6_append_data(sk, getfrag, msg, ulen,\n\t\tsizeof(struct udphdr), hlimit, tclass, opt, &fl6,\n\t\t(struct rt6_info *)dst,\n\t\tcorkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags, dontfrag);\n\tif (err)\n\t\tudp_v6_flush_pending_frames(sk);\n\telse if (!corkreq)\n\t\terr = udp_v6_push_pending_frames(sk);\n\telse if (unlikely(skb_queue_empty(&sk->sk_write_queue)))\n\t\tup->pending = 0;\n\n\tif (err > 0)\n\t\terr = np->recverr ? net_xmit_errno(err) : 0;\n\trelease_sock(sk);\n\nrelease_dst:\n\tif (dst) {\n\t\tif (connected) {\n\t\t\tip6_dst_store(sk, dst,\n\t\t\t\t      ipv6_addr_equal(&fl6.daddr, &sk->sk_v6_daddr) ?\n\t\t\t\t      &sk->sk_v6_daddr : NULL,\n#ifdef CONFIG_IPV6_SUBTREES\n\t\t\t\t      ipv6_addr_equal(&fl6.saddr, &np->saddr) ?\n\t\t\t\t      &np->saddr :\n#endif\n\t\t\t\t      NULL);\n\t\t} else {\n\t\t\tdst_release(dst);\n\t\t}\n\t\tdst = NULL;\n\t}\n\nout:\n\tdst_release(dst);\n\tfl6_sock_release(flowlabel);\n\tif (!err)\n\t\treturn len;\n\t/*\n\t * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting\n\t * ENOBUFS might not be good (it's not tunable per se), but otherwise\n\t * we don't have a good statistic (IpOutDiscards but it can be too many\n\t * things).  We could add another new stat but at least for now that\n\t * seems like overkill.\n\t */\n\tif (err == -ENOBUFS || test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tUDP6_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_SNDBUFERRORS, is_udplite);\n\t}\n\treturn err;\n\ndo_confirm:\n\tdst_confirm(dst);\n\tif (!(msg->msg_flags&MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
        "code_after_change": "int udpv6_sendmsg(struct sock *sk, struct msghdr *msg, size_t len)\n{\n\tstruct ipv6_txoptions opt_space;\n\tstruct udp_sock *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n\tstruct in6_addr *daddr, *final_p, final;\n\tstruct ipv6_txoptions *opt = NULL;\n\tstruct ipv6_txoptions *opt_to_free = NULL;\n\tstruct ip6_flowlabel *flowlabel = NULL;\n\tstruct flowi6 fl6;\n\tstruct dst_entry *dst;\n\tint addr_len = msg->msg_namelen;\n\tint ulen = len;\n\tint hlimit = -1;\n\tint tclass = -1;\n\tint dontfrag = -1;\n\tint corkreq = up->corkflag || msg->msg_flags&MSG_MORE;\n\tint err;\n\tint connected = 0;\n\tint is_udplite = IS_UDPLITE(sk);\n\tint (*getfrag)(void *, char *, int, int, int, struct sk_buff *);\n\n\t/* destination address check */\n\tif (sin6) {\n\t\tif (addr_len < offsetof(struct sockaddr, sa_data))\n\t\t\treturn -EINVAL;\n\n\t\tswitch (sin6->sin6_family) {\n\t\tcase AF_INET6:\n\t\t\tif (addr_len < SIN6_LEN_RFC2133)\n\t\t\t\treturn -EINVAL;\n\t\t\tdaddr = &sin6->sin6_addr;\n\t\t\tbreak;\n\t\tcase AF_INET:\n\t\t\tgoto do_udp_sendmsg;\n\t\tcase AF_UNSPEC:\n\t\t\tmsg->msg_name = sin6 = NULL;\n\t\t\tmsg->msg_namelen = addr_len = 0;\n\t\t\tdaddr = NULL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (!up->pending) {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t} else\n\t\tdaddr = NULL;\n\n\tif (daddr) {\n\t\tif (ipv6_addr_v4mapped(daddr)) {\n\t\t\tstruct sockaddr_in sin;\n\t\t\tsin.sin_family = AF_INET;\n\t\t\tsin.sin_port = sin6 ? sin6->sin6_port : inet->inet_dport;\n\t\t\tsin.sin_addr.s_addr = daddr->s6_addr32[3];\n\t\t\tmsg->msg_name = &sin;\n\t\t\tmsg->msg_namelen = sizeof(sin);\ndo_udp_sendmsg:\n\t\t\tif (__ipv6_only_sock(sk))\n\t\t\t\treturn -ENETUNREACH;\n\t\t\treturn udp_sendmsg(sk, msg, len);\n\t\t}\n\t}\n\n\tif (up->pending == AF_INET)\n\t\treturn udp_sendmsg(sk, msg, len);\n\n\t/* Rough check on arithmetic overflow,\n\t   better check is made in ip6_append_data().\n\t   */\n\tif (len > INT_MAX - sizeof(struct udphdr))\n\t\treturn -EMSGSIZE;\n\n\tgetfrag  =  is_udplite ?  udplite_getfrag : ip_generic_getfrag;\n\tif (up->pending) {\n\t\t/*\n\t\t * There are pending frames.\n\t\t * The socket lock must be held while it's corked.\n\t\t */\n\t\tlock_sock(sk);\n\t\tif (likely(up->pending)) {\n\t\t\tif (unlikely(up->pending != AF_INET6)) {\n\t\t\t\trelease_sock(sk);\n\t\t\t\treturn -EAFNOSUPPORT;\n\t\t\t}\n\t\t\tdst = NULL;\n\t\t\tgoto do_append_data;\n\t\t}\n\t\trelease_sock(sk);\n\t}\n\tulen += sizeof(struct udphdr);\n\n\tmemset(&fl6, 0, sizeof(fl6));\n\n\tif (sin6) {\n\t\tif (sin6->sin6_port == 0)\n\t\t\treturn -EINVAL;\n\n\t\tfl6.fl6_dport = sin6->sin6_port;\n\t\tdaddr = &sin6->sin6_addr;\n\n\t\tif (np->sndflow) {\n\t\t\tfl6.flowlabel = sin6->sin6_flowinfo&IPV6_FLOWINFO_MASK;\n\t\t\tif (fl6.flowlabel&IPV6_FLOWLABEL_MASK) {\n\t\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\t\tif (!flowlabel)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Otherwise it will be difficult to maintain\n\t\t * sk->sk_dst_cache.\n\t\t */\n\t\tif (sk->sk_state == TCP_ESTABLISHED &&\n\t\t    ipv6_addr_equal(daddr, &sk->sk_v6_daddr))\n\t\t\tdaddr = &sk->sk_v6_daddr;\n\n\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t    sin6->sin6_scope_id &&\n\t\t    __ipv6_addr_needs_scope_id(__ipv6_addr_type(daddr)))\n\t\t\tfl6.flowi6_oif = sin6->sin6_scope_id;\n\t} else {\n\t\tif (sk->sk_state != TCP_ESTABLISHED)\n\t\t\treturn -EDESTADDRREQ;\n\n\t\tfl6.fl6_dport = inet->inet_dport;\n\t\tdaddr = &sk->sk_v6_daddr;\n\t\tfl6.flowlabel = np->flow_label;\n\t\tconnected = 1;\n\t}\n\n\tif (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = sk->sk_bound_dev_if;\n\n\tif (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->sticky_pktinfo.ipi6_ifindex;\n\n\tfl6.flowi6_mark = sk->sk_mark;\n\n\tif (msg->msg_controllen) {\n\t\topt = &opt_space;\n\t\tmemset(opt, 0, sizeof(struct ipv6_txoptions));\n\t\topt->tot_len = sizeof(*opt);\n\n\t\terr = ip6_datagram_send_ctl(sock_net(sk), sk, msg, &fl6, opt,\n\t\t\t\t\t    &hlimit, &tclass, &dontfrag);\n\t\tif (err < 0) {\n\t\t\tfl6_sock_release(flowlabel);\n\t\t\treturn err;\n\t\t}\n\t\tif ((fl6.flowlabel&IPV6_FLOWLABEL_MASK) && !flowlabel) {\n\t\t\tflowlabel = fl6_sock_lookup(sk, fl6.flowlabel);\n\t\t\tif (!flowlabel)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!(opt->opt_nflen|opt->opt_flen))\n\t\t\topt = NULL;\n\t\tconnected = 0;\n\t}\n\tif (!opt) {\n\t\topt = txopt_get(np);\n\t\topt_to_free = opt;\n\t}\n\tif (flowlabel)\n\t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n\topt = ipv6_fixup_options(&opt_space, opt);\n\n\tfl6.flowi6_proto = sk->sk_protocol;\n\tif (!ipv6_addr_any(daddr))\n\t\tfl6.daddr = *daddr;\n\telse\n\t\tfl6.daddr.s6_addr[15] = 0x1; /* :: means loopback (BSD'ism) */\n\tif (ipv6_addr_any(&fl6.saddr) && !ipv6_addr_any(&np->saddr))\n\t\tfl6.saddr = np->saddr;\n\tfl6.fl6_sport = inet->inet_sport;\n\n\tfinal_p = fl6_update_dst(&fl6, opt, &final);\n\tif (final_p)\n\t\tconnected = 0;\n\n\tif (!fl6.flowi6_oif && ipv6_addr_is_multicast(&fl6.daddr)) {\n\t\tfl6.flowi6_oif = np->mcast_oif;\n\t\tconnected = 0;\n\t} else if (!fl6.flowi6_oif)\n\t\tfl6.flowi6_oif = np->ucast_oif;\n\n\tsecurity_sk_classify_flow(sk, flowi6_to_flowi(&fl6));\n\n\tdst = ip6_sk_dst_lookup_flow(sk, &fl6, final_p);\n\tif (IS_ERR(dst)) {\n\t\terr = PTR_ERR(dst);\n\t\tdst = NULL;\n\t\tgoto out;\n\t}\n\n\tif (hlimit < 0)\n\t\thlimit = ip6_sk_dst_hoplimit(np, &fl6, dst);\n\n\tif (tclass < 0)\n\t\ttclass = np->tclass;\n\n\tif (msg->msg_flags&MSG_CONFIRM)\n\t\tgoto do_confirm;\nback_from_confirm:\n\n\t/* Lockless fast path for the non-corking case */\n\tif (!corkreq) {\n\t\tstruct sk_buff *skb;\n\n\t\tskb = ip6_make_skb(sk, getfrag, msg, ulen,\n\t\t\t\t   sizeof(struct udphdr), hlimit, tclass, opt,\n\t\t\t\t   &fl6, (struct rt6_info *)dst,\n\t\t\t\t   msg->msg_flags, dontfrag);\n\t\terr = PTR_ERR(skb);\n\t\tif (!IS_ERR_OR_NULL(skb))\n\t\t\terr = udp_v6_send_skb(skb, &fl6);\n\t\tgoto release_dst;\n\t}\n\n\tlock_sock(sk);\n\tif (unlikely(up->pending)) {\n\t\t/* The socket is already corked while preparing it. */\n\t\t/* ... which is an evident application bug. --ANK */\n\t\trelease_sock(sk);\n\n\t\tnet_dbg_ratelimited(\"udp cork app bug 2\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tup->pending = AF_INET6;\n\ndo_append_data:\n\tif (dontfrag < 0)\n\t\tdontfrag = np->dontfrag;\n\tup->len += ulen;\n\terr = ip6_append_data(sk, getfrag, msg, ulen,\n\t\tsizeof(struct udphdr), hlimit, tclass, opt, &fl6,\n\t\t(struct rt6_info *)dst,\n\t\tcorkreq ? msg->msg_flags|MSG_MORE : msg->msg_flags, dontfrag);\n\tif (err)\n\t\tudp_v6_flush_pending_frames(sk);\n\telse if (!corkreq)\n\t\terr = udp_v6_push_pending_frames(sk);\n\telse if (unlikely(skb_queue_empty(&sk->sk_write_queue)))\n\t\tup->pending = 0;\n\n\tif (err > 0)\n\t\terr = np->recverr ? net_xmit_errno(err) : 0;\n\trelease_sock(sk);\n\nrelease_dst:\n\tif (dst) {\n\t\tif (connected) {\n\t\t\tip6_dst_store(sk, dst,\n\t\t\t\t      ipv6_addr_equal(&fl6.daddr, &sk->sk_v6_daddr) ?\n\t\t\t\t      &sk->sk_v6_daddr : NULL,\n#ifdef CONFIG_IPV6_SUBTREES\n\t\t\t\t      ipv6_addr_equal(&fl6.saddr, &np->saddr) ?\n\t\t\t\t      &np->saddr :\n#endif\n\t\t\t\t      NULL);\n\t\t} else {\n\t\t\tdst_release(dst);\n\t\t}\n\t\tdst = NULL;\n\t}\n\nout:\n\tdst_release(dst);\n\tfl6_sock_release(flowlabel);\n\ttxopt_put(opt_to_free);\n\tif (!err)\n\t\treturn len;\n\t/*\n\t * ENOBUFS = no kernel mem, SOCK_NOSPACE = no sndbuf space.  Reporting\n\t * ENOBUFS might not be good (it's not tunable per se), but otherwise\n\t * we don't have a good statistic (IpOutDiscards but it can be too many\n\t * things).  We could add another new stat but at least for now that\n\t * seems like overkill.\n\t */\n\tif (err == -ENOBUFS || test_bit(SOCK_NOSPACE, &sk->sk_socket->flags)) {\n\t\tUDP6_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_SNDBUFERRORS, is_udplite);\n\t}\n\treturn err;\n\ndo_confirm:\n\tdst_confirm(dst);\n\tif (!(msg->msg_flags&MSG_PROBE) || len)\n\t\tgoto back_from_confirm;\n\terr = 0;\n\tgoto out;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,7 @@\n \tDECLARE_SOCKADDR(struct sockaddr_in6 *, sin6, msg->msg_name);\n \tstruct in6_addr *daddr, *final_p, final;\n \tstruct ipv6_txoptions *opt = NULL;\n+\tstruct ipv6_txoptions *opt_to_free = NULL;\n \tstruct ip6_flowlabel *flowlabel = NULL;\n \tstruct flowi6 fl6;\n \tstruct dst_entry *dst;\n@@ -160,8 +161,10 @@\n \t\t\topt = NULL;\n \t\tconnected = 0;\n \t}\n-\tif (!opt)\n-\t\topt = np->opt;\n+\tif (!opt) {\n+\t\topt = txopt_get(np);\n+\t\topt_to_free = opt;\n+\t}\n \tif (flowlabel)\n \t\topt = fl6_merge_options(&opt_space, flowlabel, opt);\n \topt = ipv6_fixup_options(&opt_space, opt);\n@@ -270,6 +273,7 @@\n out:\n \tdst_release(dst);\n \tfl6_sock_release(flowlabel);\n+\ttxopt_put(opt_to_free);\n \tif (!err)\n \t\treturn len;\n \t/*",
        "function_modified_lines": {
            "added": [
                "\tstruct ipv6_txoptions *opt_to_free = NULL;",
                "\tif (!opt) {",
                "\t\topt = txopt_get(np);",
                "\t\topt_to_free = opt;",
                "\t}",
                "\ttxopt_put(opt_to_free);"
            ],
            "deleted": [
                "\tif (!opt)",
                "\t\topt = np->opt;"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-416"
        ],
        "cve_description": "The IPv6 stack in the Linux kernel before 4.3.3 mishandles options data, which allows local users to gain privileges or cause a denial of service (use-after-free and system crash) via a crafted sendmsg system call.",
        "id": 1008
    },
    {
        "cve_id": "CVE-2012-6657",
        "code_before_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_bindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) || capable(CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RX_HARDWARE);\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SYS_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RAW_HARDWARE);\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\t\t/* We implement the SO_SNDLOWAT etc to\n\t\t   not be settable (1003.1g 5.3) */\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tsock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "code_after_change": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_bindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) || capable(CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RX_HARDWARE);\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SYS_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RAW_HARDWARE);\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\t\t/* We implement the SO_SNDLOWAT etc to\n\t\t   not be settable (1003.1g 5.3) */\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tsock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -103,7 +103,8 @@\n \n \tcase SO_KEEPALIVE:\n #ifdef CONFIG_INET\n-\t\tif (sk->sk_protocol == IPPROTO_TCP)\n+\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n+\t\t    sk->sk_type == SOCK_STREAM)\n \t\t\ttcp_set_keepalive(sk, valbool);\n #endif\n \t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);",
        "function_modified_lines": {
            "added": [
                "\t\tif (sk->sk_protocol == IPPROTO_TCP &&",
                "\t\t    sk->sk_type == SOCK_STREAM)"
            ],
            "deleted": [
                "\t\tif (sk->sk_protocol == IPPROTO_TCP)"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The sock_setsockopt function in net/core/sock.c in the Linux kernel before 3.5.7 does not ensure that a keepalive action is associated with a stream socket, which allows local users to cause a denial of service (system crash) by leveraging the ability to create a raw socket.",
        "id": 136
    },
    {
        "cve_id": "CVE-2016-8632",
        "code_before_change": "int tipc_enable_l2_media(struct net *net, struct tipc_bearer *b,\n\t\t\t struct nlattr *attr[])\n{\n\tstruct net_device *dev;\n\tchar *driver_name = strchr((const char *)b->name, ':') + 1;\n\n\t/* Find device with specified name */\n\tdev = dev_get_by_name(net, driver_name);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\t/* Associate TIPC bearer with L2 bearer */\n\trcu_assign_pointer(b->media_ptr, dev);\n\tmemset(&b->bcast_addr, 0, sizeof(b->bcast_addr));\n\tmemcpy(b->bcast_addr.value, dev->broadcast, b->media->hwaddr_len);\n\tb->bcast_addr.media_id = b->media->type_id;\n\tb->bcast_addr.broadcast = 1;\n\tb->mtu = dev->mtu;\n\tb->media->raw2addr(b, &b->addr, (char *)dev->dev_addr);\n\trcu_assign_pointer(dev->tipc_ptr, b);\n\treturn 0;\n}",
        "code_after_change": "int tipc_enable_l2_media(struct net *net, struct tipc_bearer *b,\n\t\t\t struct nlattr *attr[])\n{\n\tstruct net_device *dev;\n\tchar *driver_name = strchr((const char *)b->name, ':') + 1;\n\n\t/* Find device with specified name */\n\tdev = dev_get_by_name(net, driver_name);\n\tif (!dev)\n\t\treturn -ENODEV;\n\tif (tipc_mtu_bad(dev, 0)) {\n\t\tdev_put(dev);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Associate TIPC bearer with L2 bearer */\n\trcu_assign_pointer(b->media_ptr, dev);\n\tmemset(&b->bcast_addr, 0, sizeof(b->bcast_addr));\n\tmemcpy(b->bcast_addr.value, dev->broadcast, b->media->hwaddr_len);\n\tb->bcast_addr.media_id = b->media->type_id;\n\tb->bcast_addr.broadcast = 1;\n\tb->mtu = dev->mtu;\n\tb->media->raw2addr(b, &b->addr, (char *)dev->dev_addr);\n\trcu_assign_pointer(dev->tipc_ptr, b);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,6 +8,10 @@\n \tdev = dev_get_by_name(net, driver_name);\n \tif (!dev)\n \t\treturn -ENODEV;\n+\tif (tipc_mtu_bad(dev, 0)) {\n+\t\tdev_put(dev);\n+\t\treturn -EINVAL;\n+\t}\n \n \t/* Associate TIPC bearer with L2 bearer */\n \trcu_assign_pointer(b->media_ptr, dev);",
        "function_modified_lines": {
            "added": [
                "\tif (tipc_mtu_bad(dev, 0)) {",
                "\t\tdev_put(dev);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264",
            "CWE-119"
        ],
        "cve_description": "The tipc_msg_build function in net/tipc/msg.c in the Linux kernel through 4.8.11 does not validate the relationship between the minimum fragment length and the maximum packet size, which allows local users to gain privileges or cause a denial of service (heap-based buffer overflow) by leveraging the CAP_NET_ADMIN capability.",
        "id": 1121
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int tc_ctl_action(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_ACT_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = 0, ovr = 0;\n\n\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tca[TCA_ACT_TAB] == NULL) {\n\t\tpr_notice(\"tc_ctl_action: received NO action attribs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* n->nlmsg_flags & NLM_F_CREATE */\n\tswitch (n->nlmsg_type) {\n\tcase RTM_NEWACTION:\n\t\t/* we are going to assume all other flags\n\t\t * imply create only if it doesn't exist\n\t\t * Note that CREATE | EXCL implies that\n\t\t * but since we want avoid ambiguity (eg when flags\n\t\t * is zero) then just set this\n\t\t */\n\t\tif (n->nlmsg_flags & NLM_F_REPLACE)\n\t\t\tovr = 1;\nreplay:\n\t\tret = tcf_action_add(net, tca[TCA_ACT_TAB], n, portid, ovr);\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto replay;\n\t\tbreak;\n\tcase RTM_DELACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_DELACTION);\n\t\tbreak;\n\tcase RTM_GETACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_GETACTION);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "static int tc_ctl_action(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_ACT_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = 0, ovr = 0;\n\n\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tca[TCA_ACT_TAB] == NULL) {\n\t\tpr_notice(\"tc_ctl_action: received NO action attribs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* n->nlmsg_flags & NLM_F_CREATE */\n\tswitch (n->nlmsg_type) {\n\tcase RTM_NEWACTION:\n\t\t/* we are going to assume all other flags\n\t\t * imply create only if it doesn't exist\n\t\t * Note that CREATE | EXCL implies that\n\t\t * but since we want avoid ambiguity (eg when flags\n\t\t * is zero) then just set this\n\t\t */\n\t\tif (n->nlmsg_flags & NLM_F_REPLACE)\n\t\t\tovr = 1;\nreplay:\n\t\tret = tcf_action_add(net, tca[TCA_ACT_TAB], n, portid, ovr);\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto replay;\n\t\tbreak;\n\tcase RTM_DELACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_DELACTION);\n\t\tbreak;\n\tcase RTM_GETACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_GETACTION);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n \tint ret = 0, ovr = 0;\n \n-\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);",
        "function_modified_lines": {
            "added": [
                "\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 454
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int addr_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct ifaddrmsg *ifm;\n\tint err;\n\tu8 pnaddr;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, ifa_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tifm = nlmsg_data(nlh);\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\tpnaddr = nla_get_u8(tb[IFA_LOCAL]);\n\tif (pnaddr & 3)\n\t\t/* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifm->ifa_index);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWADDR)\n\t\terr = phonet_address_add(dev, pnaddr);\n\telse\n\t\terr = phonet_address_del(dev, pnaddr);\n\tif (!err)\n\t\tphonet_address_notify(nlh->nlmsg_type, dev, pnaddr);\n\treturn err;\n}",
        "code_after_change": "static int addr_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct ifaddrmsg *ifm;\n\tint err;\n\tu8 pnaddr;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, ifa_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tifm = nlmsg_data(nlh);\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\tpnaddr = nla_get_u8(tb[IFA_LOCAL]);\n\tif (pnaddr & 3)\n\t\t/* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifm->ifa_index);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWADDR)\n\t\terr = phonet_address_add(dev, pnaddr);\n\telse\n\t\terr = phonet_address_del(dev, pnaddr);\n\tif (!err)\n\t\tphonet_address_notify(nlh->nlmsg_type, dev, pnaddr);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,10 +7,10 @@\n \tint err;\n \tu8 pnaddr;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n-\tif (!capable(CAP_SYS_ADMIN))\n+\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \tASSERT_RTNL();",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))",
                "\tif (!netlink_capable(skb, CAP_SYS_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))",
                "\tif (!capable(CAP_SYS_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 452
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int rtnl_fdb_del(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ndmsg *ndm;\n\tstruct nlattr *tb[NDA_MAX+1];\n\tstruct net_device *dev;\n\tint err = -EINVAL;\n\t__u8 *addr;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tndm = nlmsg_data(nlh);\n\tif (ndm->ndm_ifindex == 0) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid ifindex\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = __dev_get_by_index(net, ndm->ndm_ifindex);\n\tif (dev == NULL) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with unknown ifindex\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!tb[NDA_LLADDR] || nla_len(tb[NDA_LLADDR]) != ETH_ALEN) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid address\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\taddr = nla_data(tb[NDA_LLADDR]);\n\n\terr = -EOPNOTSUPP;\n\n\t/* Support fdb on master device the net/bridge default case */\n\tif ((!ndm->ndm_flags || ndm->ndm_flags & NTF_MASTER) &&\n\t    (dev->priv_flags & IFF_BRIDGE_PORT)) {\n\t\tstruct net_device *br_dev = netdev_master_upper_dev_get(dev);\n\t\tconst struct net_device_ops *ops = br_dev->netdev_ops;\n\n\t\tif (ops->ndo_fdb_del)\n\t\t\terr = ops->ndo_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (err)\n\t\t\tgoto out;\n\t\telse\n\t\t\tndm->ndm_flags &= ~NTF_MASTER;\n\t}\n\n\t/* Embedded bridge, macvlan, and any other device support */\n\tif (ndm->ndm_flags & NTF_SELF) {\n\t\tif (dev->netdev_ops->ndo_fdb_del)\n\t\t\terr = dev->netdev_ops->ndo_fdb_del(ndm, tb, dev, addr);\n\t\telse\n\t\t\terr = ndo_dflt_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (!err) {\n\t\t\trtnl_fdb_notify(dev, addr, RTM_DELNEIGH);\n\t\t\tndm->ndm_flags &= ~NTF_SELF;\n\t\t}\n\t}\nout:\n\treturn err;\n}",
        "code_after_change": "static int rtnl_fdb_del(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ndmsg *ndm;\n\tstruct nlattr *tb[NDA_MAX+1];\n\tstruct net_device *dev;\n\tint err = -EINVAL;\n\t__u8 *addr;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tndm = nlmsg_data(nlh);\n\tif (ndm->ndm_ifindex == 0) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid ifindex\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = __dev_get_by_index(net, ndm->ndm_ifindex);\n\tif (dev == NULL) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with unknown ifindex\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!tb[NDA_LLADDR] || nla_len(tb[NDA_LLADDR]) != ETH_ALEN) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid address\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\taddr = nla_data(tb[NDA_LLADDR]);\n\n\terr = -EOPNOTSUPP;\n\n\t/* Support fdb on master device the net/bridge default case */\n\tif ((!ndm->ndm_flags || ndm->ndm_flags & NTF_MASTER) &&\n\t    (dev->priv_flags & IFF_BRIDGE_PORT)) {\n\t\tstruct net_device *br_dev = netdev_master_upper_dev_get(dev);\n\t\tconst struct net_device_ops *ops = br_dev->netdev_ops;\n\n\t\tif (ops->ndo_fdb_del)\n\t\t\terr = ops->ndo_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (err)\n\t\t\tgoto out;\n\t\telse\n\t\t\tndm->ndm_flags &= ~NTF_MASTER;\n\t}\n\n\t/* Embedded bridge, macvlan, and any other device support */\n\tif (ndm->ndm_flags & NTF_SELF) {\n\t\tif (dev->netdev_ops->ndo_fdb_del)\n\t\t\terr = dev->netdev_ops->ndo_fdb_del(ndm, tb, dev, addr);\n\t\telse\n\t\t\terr = ndo_dflt_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (!err) {\n\t\t\trtnl_fdb_notify(dev, addr, RTM_DELNEIGH);\n\t\t\tndm->ndm_flags &= ~NTF_SELF;\n\t\t}\n\t}\nout:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,7 @@\n \tint err = -EINVAL;\n \t__u8 *addr;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 441
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int dcb_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net_device *netdev;\n\tstruct dcbmsg *dcb = nlmsg_data(nlh);\n\tstruct nlattr *tb[DCB_ATTR_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = -EINVAL;\n\tstruct sk_buff *reply_skb;\n\tstruct nlmsghdr *reply_nlh = NULL;\n\tconst struct reply_func *fn;\n\n\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,\n\t\t\t  dcbnl_rtnl_policy);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (dcb->cmd > DCB_CMD_MAX)\n\t\treturn -EINVAL;\n\n\t/* check if a reply function has been defined for the command */\n\tfn = &reply_funcs[dcb->cmd];\n\tif (!fn->cb)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!tb[DCB_ATTR_IFNAME])\n\t\treturn -EINVAL;\n\n\tnetdev = __dev_get_by_name(net, nla_data(tb[DCB_ATTR_IFNAME]));\n\tif (!netdev)\n\t\treturn -ENODEV;\n\n\tif (!netdev->dcbnl_ops)\n\t\treturn -EOPNOTSUPP;\n\n\treply_skb = dcbnl_newmsg(fn->type, dcb->cmd, portid, nlh->nlmsg_seq,\n\t\t\t\t nlh->nlmsg_flags, &reply_nlh);\n\tif (!reply_skb)\n\t\treturn -ENOBUFS;\n\n\tret = fn->cb(netdev, nlh, nlh->nlmsg_seq, tb, reply_skb);\n\tif (ret < 0) {\n\t\tnlmsg_free(reply_skb);\n\t\tgoto out;\n\t}\n\n\tnlmsg_end(reply_skb, reply_nlh);\n\n\tret = rtnl_unicast(reply_skb, net, portid);\nout:\n\treturn ret;\n}",
        "code_after_change": "static int dcb_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net_device *netdev;\n\tstruct dcbmsg *dcb = nlmsg_data(nlh);\n\tstruct nlattr *tb[DCB_ATTR_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = -EINVAL;\n\tstruct sk_buff *reply_skb;\n\tstruct nlmsghdr *reply_nlh = NULL;\n\tconst struct reply_func *fn;\n\n\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,\n\t\t\t  dcbnl_rtnl_policy);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (dcb->cmd > DCB_CMD_MAX)\n\t\treturn -EINVAL;\n\n\t/* check if a reply function has been defined for the command */\n\tfn = &reply_funcs[dcb->cmd];\n\tif (!fn->cb)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!tb[DCB_ATTR_IFNAME])\n\t\treturn -EINVAL;\n\n\tnetdev = __dev_get_by_name(net, nla_data(tb[DCB_ATTR_IFNAME]));\n\tif (!netdev)\n\t\treturn -ENODEV;\n\n\tif (!netdev->dcbnl_ops)\n\t\treturn -EOPNOTSUPP;\n\n\treply_skb = dcbnl_newmsg(fn->type, dcb->cmd, portid, nlh->nlmsg_seq,\n\t\t\t\t nlh->nlmsg_flags, &reply_nlh);\n\tif (!reply_skb)\n\t\treturn -ENOBUFS;\n\n\tret = fn->cb(netdev, nlh, nlh->nlmsg_seq, tb, reply_skb);\n\tif (ret < 0) {\n\t\tnlmsg_free(reply_skb);\n\t\tgoto out;\n\t}\n\n\tnlmsg_end(reply_skb, reply_nlh);\n\n\tret = rtnl_unicast(reply_skb, net, portid);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -10,7 +10,7 @@\n \tstruct nlmsghdr *reply_nlh = NULL;\n \tconst struct reply_func *fn;\n \n-\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))\n+\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,",
        "function_modified_lines": {
            "added": [
                "\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 443
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int route_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct net_device *dev;\n\tstruct rtmsg *rtm;\n\tint err;\n\tu8 dst;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\trtm = nlmsg_data(nlh);\n\tif (rtm->rtm_table != RT_TABLE_MAIN || rtm->rtm_type != RTN_UNICAST)\n\t\treturn -EINVAL;\n\tif (tb[RTA_DST] == NULL || tb[RTA_OIF] == NULL)\n\t\treturn -EINVAL;\n\tdst = nla_get_u8(tb[RTA_DST]);\n\tif (dst & 3) /* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, nla_get_u32(tb[RTA_OIF]));\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWROUTE)\n\t\terr = phonet_route_add(dev, dst);\n\telse\n\t\terr = phonet_route_del(dev, dst);\n\tif (!err)\n\t\trtm_phonet_notify(nlh->nlmsg_type, dev, dst);\n\treturn err;\n}",
        "code_after_change": "static int route_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct net_device *dev;\n\tstruct rtmsg *rtm;\n\tint err;\n\tu8 dst;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\trtm = nlmsg_data(nlh);\n\tif (rtm->rtm_table != RT_TABLE_MAIN || rtm->rtm_type != RTN_UNICAST)\n\t\treturn -EINVAL;\n\tif (tb[RTA_DST] == NULL || tb[RTA_OIF] == NULL)\n\t\treturn -EINVAL;\n\tdst = nla_get_u8(tb[RTA_DST]);\n\tif (dst & 3) /* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, nla_get_u32(tb[RTA_OIF]));\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWROUTE)\n\t\terr = phonet_route_add(dev, dst);\n\telse\n\t\terr = phonet_route_del(dev, dst);\n\tif (!err)\n\t\trtm_phonet_notify(nlh->nlmsg_type, dev, dst);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,10 +7,10 @@\n \tint err;\n \tu8 dst;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n-\tif (!capable(CAP_SYS_ADMIN))\n+\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \tASSERT_RTNL();",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))",
                "\tif (!netlink_capable(skb, CAP_SYS_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))",
                "\tif (!capable(CAP_SYS_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 453
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)\n{\n\tint err = 0;\n\n\t/* Only support initial user namespace for now. */\n\t/*\n\t * We return ECONNREFUSED because it tricks userspace into thinking\n\t * that audit was not configured into the kernel.  Lots of users\n\t * configure their PAM stack (because that's what the distro does)\n\t * to reject login if unable to send messages to audit.  If we return\n\t * ECONNREFUSED the PAM stack thinks the kernel does not have audit\n\t * configured in and will let login proceed.  If we return EPERM\n\t * userspace will reject all logins.  This should be removed when we\n\t * support non init namespaces!!\n\t */\n\tif (current_user_ns() != &init_user_ns)\n\t\treturn -ECONNREFUSED;\n\n\tswitch (msg_type) {\n\tcase AUDIT_LIST:\n\tcase AUDIT_ADD:\n\tcase AUDIT_DEL:\n\t\treturn -EOPNOTSUPP;\n\tcase AUDIT_GET:\n\tcase AUDIT_SET:\n\tcase AUDIT_GET_FEATURE:\n\tcase AUDIT_SET_FEATURE:\n\tcase AUDIT_LIST_RULES:\n\tcase AUDIT_ADD_RULE:\n\tcase AUDIT_DEL_RULE:\n\tcase AUDIT_SIGNAL_INFO:\n\tcase AUDIT_TTY_GET:\n\tcase AUDIT_TTY_SET:\n\tcase AUDIT_TRIM:\n\tcase AUDIT_MAKE_EQUIV:\n\t\t/* Only support auditd and auditctl in initial pid namespace\n\t\t * for now. */\n\t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n\t\t\treturn -EPERM;\n\n\t\tif (!capable(CAP_AUDIT_CONTROL))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tcase AUDIT_USER:\n\tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n\tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n\t\tif (!capable(CAP_AUDIT_WRITE))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tdefault:  /* bad msg */\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)\n{\n\tint err = 0;\n\n\t/* Only support initial user namespace for now. */\n\t/*\n\t * We return ECONNREFUSED because it tricks userspace into thinking\n\t * that audit was not configured into the kernel.  Lots of users\n\t * configure their PAM stack (because that's what the distro does)\n\t * to reject login if unable to send messages to audit.  If we return\n\t * ECONNREFUSED the PAM stack thinks the kernel does not have audit\n\t * configured in and will let login proceed.  If we return EPERM\n\t * userspace will reject all logins.  This should be removed when we\n\t * support non init namespaces!!\n\t */\n\tif (current_user_ns() != &init_user_ns)\n\t\treturn -ECONNREFUSED;\n\n\tswitch (msg_type) {\n\tcase AUDIT_LIST:\n\tcase AUDIT_ADD:\n\tcase AUDIT_DEL:\n\t\treturn -EOPNOTSUPP;\n\tcase AUDIT_GET:\n\tcase AUDIT_SET:\n\tcase AUDIT_GET_FEATURE:\n\tcase AUDIT_SET_FEATURE:\n\tcase AUDIT_LIST_RULES:\n\tcase AUDIT_ADD_RULE:\n\tcase AUDIT_DEL_RULE:\n\tcase AUDIT_SIGNAL_INFO:\n\tcase AUDIT_TTY_GET:\n\tcase AUDIT_TTY_SET:\n\tcase AUDIT_TRIM:\n\tcase AUDIT_MAKE_EQUIV:\n\t\t/* Only support auditd and auditctl in initial pid namespace\n\t\t * for now. */\n\t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n\t\t\treturn -EPERM;\n\n\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tcase AUDIT_USER:\n\tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n\tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tdefault:  /* bad msg */\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,13 +38,13 @@\n \t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n \t\t\treturn -EPERM;\n \n-\t\tif (!capable(CAP_AUDIT_CONTROL))\n+\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))\n \t\t\terr = -EPERM;\n \t\tbreak;\n \tcase AUDIT_USER:\n \tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n \tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n-\t\tif (!capable(CAP_AUDIT_WRITE))\n+\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))\n \t\t\terr = -EPERM;\n \t\tbreak;\n \tdefault:  /* bad msg */",
        "function_modified_lines": {
            "added": [
                "\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))",
                "\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))"
            ],
            "deleted": [
                "\t\tif (!capable(CAP_AUDIT_CONTROL))",
                "\t\tif (!capable(CAP_AUDIT_WRITE))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 436
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int tc_modify_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm;\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q, *p;\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\t/* Reinit, just in case something touches this. */\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\ttcm = nlmsg_data(n);\n\tclid = tcm->tcm_parent;\n\tq = p = NULL;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (clid != TC_H_INGRESS) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue_create(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\n\t\t/* It may be default qdisc, ignore it */\n\t\tif (q && q->handle == 0)\n\t\t\tq = NULL;\n\n\t\tif (!q || !tcm->tcm_handle || q->handle != tcm->tcm_handle) {\n\t\t\tif (tcm->tcm_handle) {\n\t\t\t\tif (q && !(n->nlmsg_flags & NLM_F_REPLACE))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (TC_H_MIN(tcm->tcm_handle))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (q == p ||\n\t\t\t\t    (p && check_loop(q, p, 0)))\n\t\t\t\t\treturn -ELOOP;\n\t\t\t\tatomic_inc(&q->refcnt);\n\t\t\t\tgoto graft;\n\t\t\t} else {\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\n\t\t\t\t/* This magic test requires explanation.\n\t\t\t\t *\n\t\t\t\t *   We know, that some child q is already\n\t\t\t\t *   attached to this parent and have choice:\n\t\t\t\t *   either to change it or to create/graft new one.\n\t\t\t\t *\n\t\t\t\t *   1. We are allowed to create/graft only\n\t\t\t\t *   if CREATE and REPLACE flags are set.\n\t\t\t\t *\n\t\t\t\t *   2. If EXCL is set, requestor wanted to say,\n\t\t\t\t *   that qdisc tcm_handle is not expected\n\t\t\t\t *   to exist, so that we choose create/graft too.\n\t\t\t\t *\n\t\t\t\t *   3. The last case is when no flags are set.\n\t\t\t\t *   Alas, it is sort of hole in API, we\n\t\t\t\t *   cannot decide what to do unambiguously.\n\t\t\t\t *   For now we select create/graft, if\n\t\t\t\t *   user gave KIND, which does not match existing.\n\t\t\t\t */\n\t\t\t\tif ((n->nlmsg_flags & NLM_F_CREATE) &&\n\t\t\t\t    (n->nlmsg_flags & NLM_F_REPLACE) &&\n\t\t\t\t    ((n->nlmsg_flags & NLM_F_EXCL) ||\n\t\t\t\t     (tca[TCA_KIND] &&\n\t\t\t\t      nla_strcmp(tca[TCA_KIND], q->ops->id))))\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (!tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t}\n\n\t/* Change qdisc parameters */\n\tif (q == NULL)\n\t\treturn -ENOENT;\n\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\treturn -EEXIST;\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\terr = qdisc_change(q, tca);\n\tif (err == 0)\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\treturn err;\n\ncreate_n_graft:\n\tif (!(n->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -ENOENT;\n\tif (clid == TC_H_INGRESS) {\n\t\tif (dev_ingress_queue(dev))\n\t\t\tq = qdisc_create(dev, dev_ingress_queue(dev), p,\n\t\t\t\t\t tcm->tcm_parent, tcm->tcm_parent,\n\t\t\t\t\t tca, &err);\n\t\telse\n\t\t\terr = -ENOENT;\n\t} else {\n\t\tstruct netdev_queue *dev_queue;\n\n\t\tif (p && p->ops->cl_ops && p->ops->cl_ops->select_queue)\n\t\t\tdev_queue = p->ops->cl_ops->select_queue(p, tcm);\n\t\telse if (p)\n\t\t\tdev_queue = p->dev_queue;\n\t\telse\n\t\t\tdev_queue = netdev_get_tx_queue(dev, 0);\n\n\t\tq = qdisc_create(dev, dev_queue, p,\n\t\t\t\t tcm->tcm_parent, tcm->tcm_handle,\n\t\t\t\t tca, &err);\n\t}\n\tif (q == NULL) {\n\t\tif (err == -EAGAIN)\n\t\t\tgoto replay;\n\t\treturn err;\n\t}\n\ngraft:\n\terr = qdisc_graft(dev, p, skb, n, clid, q, NULL);\n\tif (err) {\n\t\tif (q)\n\t\t\tqdisc_destroy(q);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int tc_modify_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm;\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q, *p;\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\t/* Reinit, just in case something touches this. */\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\ttcm = nlmsg_data(n);\n\tclid = tcm->tcm_parent;\n\tq = p = NULL;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (clid != TC_H_INGRESS) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue_create(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\n\t\t/* It may be default qdisc, ignore it */\n\t\tif (q && q->handle == 0)\n\t\t\tq = NULL;\n\n\t\tif (!q || !tcm->tcm_handle || q->handle != tcm->tcm_handle) {\n\t\t\tif (tcm->tcm_handle) {\n\t\t\t\tif (q && !(n->nlmsg_flags & NLM_F_REPLACE))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (TC_H_MIN(tcm->tcm_handle))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (q == p ||\n\t\t\t\t    (p && check_loop(q, p, 0)))\n\t\t\t\t\treturn -ELOOP;\n\t\t\t\tatomic_inc(&q->refcnt);\n\t\t\t\tgoto graft;\n\t\t\t} else {\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\n\t\t\t\t/* This magic test requires explanation.\n\t\t\t\t *\n\t\t\t\t *   We know, that some child q is already\n\t\t\t\t *   attached to this parent and have choice:\n\t\t\t\t *   either to change it or to create/graft new one.\n\t\t\t\t *\n\t\t\t\t *   1. We are allowed to create/graft only\n\t\t\t\t *   if CREATE and REPLACE flags are set.\n\t\t\t\t *\n\t\t\t\t *   2. If EXCL is set, requestor wanted to say,\n\t\t\t\t *   that qdisc tcm_handle is not expected\n\t\t\t\t *   to exist, so that we choose create/graft too.\n\t\t\t\t *\n\t\t\t\t *   3. The last case is when no flags are set.\n\t\t\t\t *   Alas, it is sort of hole in API, we\n\t\t\t\t *   cannot decide what to do unambiguously.\n\t\t\t\t *   For now we select create/graft, if\n\t\t\t\t *   user gave KIND, which does not match existing.\n\t\t\t\t */\n\t\t\t\tif ((n->nlmsg_flags & NLM_F_CREATE) &&\n\t\t\t\t    (n->nlmsg_flags & NLM_F_REPLACE) &&\n\t\t\t\t    ((n->nlmsg_flags & NLM_F_EXCL) ||\n\t\t\t\t     (tca[TCA_KIND] &&\n\t\t\t\t      nla_strcmp(tca[TCA_KIND], q->ops->id))))\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (!tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t}\n\n\t/* Change qdisc parameters */\n\tif (q == NULL)\n\t\treturn -ENOENT;\n\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\treturn -EEXIST;\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\terr = qdisc_change(q, tca);\n\tif (err == 0)\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\treturn err;\n\ncreate_n_graft:\n\tif (!(n->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -ENOENT;\n\tif (clid == TC_H_INGRESS) {\n\t\tif (dev_ingress_queue(dev))\n\t\t\tq = qdisc_create(dev, dev_ingress_queue(dev), p,\n\t\t\t\t\t tcm->tcm_parent, tcm->tcm_parent,\n\t\t\t\t\t tca, &err);\n\t\telse\n\t\t\terr = -ENOENT;\n\t} else {\n\t\tstruct netdev_queue *dev_queue;\n\n\t\tif (p && p->ops->cl_ops && p->ops->cl_ops->select_queue)\n\t\t\tdev_queue = p->ops->cl_ops->select_queue(p, tcm);\n\t\telse if (p)\n\t\t\tdev_queue = p->dev_queue;\n\t\telse\n\t\t\tdev_queue = netdev_get_tx_queue(dev, 0);\n\n\t\tq = qdisc_create(dev, dev_queue, p,\n\t\t\t\t tcm->tcm_parent, tcm->tcm_handle,\n\t\t\t\t tca, &err);\n\t}\n\tif (q == NULL) {\n\t\tif (err == -EAGAIN)\n\t\t\tgoto replay;\n\t\treturn err;\n\t}\n\ngraft:\n\terr = qdisc_graft(dev, p, skb, n, clid, q, NULL);\n\tif (err) {\n\t\tif (q)\n\t\t\tqdisc_destroy(q);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tstruct Qdisc *q, *p;\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n replay:",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 456
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int cgw_create_job(struct sk_buff *skb,  struct nlmsghdr *nlh)\n{\n\tstruct rtcanmsg *r;\n\tstruct cgw_job *gwj;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\tgwj = kmem_cache_alloc(cgw_cache, GFP_KERNEL);\n\tif (!gwj)\n\t\treturn -ENOMEM;\n\n\tgwj->handled_frames = 0;\n\tgwj->dropped_frames = 0;\n\tgwj->deleted_frames = 0;\n\tgwj->flags = r->flags;\n\tgwj->gwtype = r->gwtype;\n\n\terr = cgw_parse_attr(nlh, &gwj->mod, CGW_TYPE_CAN_CAN, &gwj->ccgw,\n\t\t\t     &limhops);\n\tif (err < 0)\n\t\tgoto out;\n\n\terr = -ENODEV;\n\n\t/* ifindex == 0 is not allowed for job creation */\n\tif (!gwj->ccgw.src_idx || !gwj->ccgw.dst_idx)\n\t\tgoto out;\n\n\tgwj->src.dev = __dev_get_by_index(&init_net, gwj->ccgw.src_idx);\n\n\tif (!gwj->src.dev)\n\t\tgoto out;\n\n\tif (gwj->src.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->dst.dev = __dev_get_by_index(&init_net, gwj->ccgw.dst_idx);\n\n\tif (!gwj->dst.dev)\n\t\tgoto out;\n\n\tif (gwj->dst.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->limit_hops = limhops;\n\n\tASSERT_RTNL();\n\n\terr = cgw_register_filter(gwj);\n\tif (!err)\n\t\thlist_add_head_rcu(&gwj->list, &cgw_list);\nout:\n\tif (err)\n\t\tkmem_cache_free(cgw_cache, gwj);\n\n\treturn err;\n}",
        "code_after_change": "static int cgw_create_job(struct sk_buff *skb,  struct nlmsghdr *nlh)\n{\n\tstruct rtcanmsg *r;\n\tstruct cgw_job *gwj;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\tgwj = kmem_cache_alloc(cgw_cache, GFP_KERNEL);\n\tif (!gwj)\n\t\treturn -ENOMEM;\n\n\tgwj->handled_frames = 0;\n\tgwj->dropped_frames = 0;\n\tgwj->deleted_frames = 0;\n\tgwj->flags = r->flags;\n\tgwj->gwtype = r->gwtype;\n\n\terr = cgw_parse_attr(nlh, &gwj->mod, CGW_TYPE_CAN_CAN, &gwj->ccgw,\n\t\t\t     &limhops);\n\tif (err < 0)\n\t\tgoto out;\n\n\terr = -ENODEV;\n\n\t/* ifindex == 0 is not allowed for job creation */\n\tif (!gwj->ccgw.src_idx || !gwj->ccgw.dst_idx)\n\t\tgoto out;\n\n\tgwj->src.dev = __dev_get_by_index(&init_net, gwj->ccgw.src_idx);\n\n\tif (!gwj->src.dev)\n\t\tgoto out;\n\n\tif (gwj->src.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->dst.dev = __dev_get_by_index(&init_net, gwj->ccgw.dst_idx);\n\n\tif (!gwj->dst.dev)\n\t\tgoto out;\n\n\tif (gwj->dst.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->limit_hops = limhops;\n\n\tASSERT_RTNL();\n\n\terr = cgw_register_filter(gwj);\n\tif (!err)\n\t\thlist_add_head_rcu(&gwj->list, &cgw_list);\nout:\n\tif (err)\n\t\tkmem_cache_free(cgw_cache, gwj);\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -5,7 +5,7 @@\n \tu8 limhops = 0;\n \tint err = 0;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (nlmsg_len(nlh) < sizeof(*r))",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 437
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int rtnl_setlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifinfomsg *ifm;\n\tstruct net_device *dev;\n\tint err;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tchar ifname[IFNAMSIZ];\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\terr = -EINVAL;\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse if (tb[IFLA_IFNAME])\n\t\tdev = __dev_get_by_name(net, ifname);\n\telse\n\t\tgoto errout;\n\n\tif (dev == NULL) {\n\t\terr = -ENODEV;\n\t\tgoto errout;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = do_setlink(dev, ifm, tb, ifname, 0);\nerrout:\n\treturn err;\n}",
        "code_after_change": "static int rtnl_setlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifinfomsg *ifm;\n\tstruct net_device *dev;\n\tint err;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tchar ifname[IFNAMSIZ];\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\terr = -EINVAL;\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse if (tb[IFLA_IFNAME])\n\t\tdev = __dev_get_by_name(net, ifname);\n\telse\n\t\tgoto errout;\n\n\tif (dev == NULL) {\n\t\terr = -ENODEV;\n\t\tgoto errout;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);\nerrout:\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -34,7 +34,7 @@\n \tif (err < 0)\n \t\tgoto errout;\n \n-\terr = do_setlink(dev, ifm, tb, ifname, 0);\n+\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);\n errout:\n \treturn err;\n }",
        "function_modified_lines": {
            "added": [
                "\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);"
            ],
            "deleted": [
                "\terr = do_setlink(dev, ifm, tb, ifname, 0);"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 442
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int tc_ctl_tfilter(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tspinlock_t *root_lock;\n\tstruct tcmsg *t;\n\tu32 protocol;\n\tu32 prio;\n\tu32 nprio;\n\tu32 parent;\n\tstruct net_device *dev;\n\tstruct Qdisc  *q;\n\tstruct tcf_proto **back, **chain;\n\tstruct tcf_proto *tp;\n\tconst struct tcf_proto_ops *tp_ops;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl;\n\tunsigned long fh;\n\tint err;\n\tint tp_created = 0;\n\n\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\terr = nlmsg_parse(n, sizeof(*t), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tt = nlmsg_data(n);\n\tprotocol = TC_H_MIN(t->tcm_info);\n\tprio = TC_H_MAJ(t->tcm_info);\n\tnprio = prio;\n\tparent = t->tcm_parent;\n\tcl = 0;\n\n\tif (prio == 0) {\n\t\t/* If no priority is given, user wants we allocated it. */\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\treturn -ENOENT;\n\t\tprio = TC_H_MAKE(0x80000000U, 0U);\n\t}\n\n\t/* Find head of filter chain. */\n\n\t/* Find link */\n\tdev = __dev_get_by_index(net, t->tcm_ifindex);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\t/* Find qdisc */\n\tif (!parent) {\n\t\tq = dev->qdisc;\n\t\tparent = q->handle;\n\t} else {\n\t\tq = qdisc_lookup(dev, TC_H_MAJ(t->tcm_parent));\n\t\tif (q == NULL)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/* Is it classful? */\n\tcops = q->ops->cl_ops;\n\tif (!cops)\n\t\treturn -EINVAL;\n\n\tif (cops->tcf_chain == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Do we search for filter, attached to class? */\n\tif (TC_H_MIN(parent)) {\n\t\tcl = cops->get(q, parent);\n\t\tif (cl == 0)\n\t\t\treturn -ENOENT;\n\t}\n\n\t/* And the last stroke */\n\tchain = cops->tcf_chain(q, cl);\n\terr = -EINVAL;\n\tif (chain == NULL)\n\t\tgoto errout;\n\n\t/* Check the chain for existence of proto-tcf with this priority */\n\tfor (back = chain; (tp = *back) != NULL; back = &tp->next) {\n\t\tif (tp->prio >= prio) {\n\t\t\tif (tp->prio == prio) {\n\t\t\t\tif (!nprio ||\n\t\t\t\t    (tp->protocol != protocol && protocol))\n\t\t\t\t\tgoto errout;\n\t\t\t} else\n\t\t\t\ttp = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\troot_lock = qdisc_root_sleeping_lock(q);\n\n\tif (tp == NULL) {\n\t\t/* Proto-tcf does not exist, create new one */\n\n\t\tif (tca[TCA_KIND] == NULL || !protocol)\n\t\t\tgoto errout;\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\n\n\t\t/* Create new proto tcf */\n\n\t\terr = -ENOBUFS;\n\t\ttp = kzalloc(sizeof(*tp), GFP_KERNEL);\n\t\tif (tp == NULL)\n\t\t\tgoto errout;\n\t\terr = -ENOENT;\n\t\ttp_ops = tcf_proto_lookup_ops(tca[TCA_KIND]);\n\t\tif (tp_ops == NULL) {\n#ifdef CONFIG_MODULES\n\t\t\tstruct nlattr *kind = tca[TCA_KIND];\n\t\t\tchar name[IFNAMSIZ];\n\n\t\t\tif (kind != NULL &&\n\t\t\t    nla_strlcpy(name, kind, IFNAMSIZ) < IFNAMSIZ) {\n\t\t\t\trtnl_unlock();\n\t\t\t\trequest_module(\"cls_%s\", name);\n\t\t\t\trtnl_lock();\n\t\t\t\ttp_ops = tcf_proto_lookup_ops(kind);\n\t\t\t\t/* We dropped the RTNL semaphore in order to\n\t\t\t\t * perform the module load.  So, even if we\n\t\t\t\t * succeeded in loading the module we have to\n\t\t\t\t * replay the request.  We indicate this using\n\t\t\t\t * -EAGAIN.\n\t\t\t\t */\n\t\t\t\tif (tp_ops != NULL) {\n\t\t\t\t\tmodule_put(tp_ops->owner);\n\t\t\t\t\terr = -EAGAIN;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\t\ttp->ops = tp_ops;\n\t\ttp->protocol = protocol;\n\t\ttp->prio = nprio ? : TC_H_MAJ(tcf_auto_prio(*back));\n\t\ttp->q = q;\n\t\ttp->classify = tp_ops->classify;\n\t\ttp->classid = parent;\n\n\t\terr = tp_ops->init(tp);\n\t\tif (err != 0) {\n\t\t\tmodule_put(tp_ops->owner);\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\n\t\ttp_created = 1;\n\n\t} else if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind))\n\t\tgoto errout;\n\n\tfh = tp->ops->get(tp, t->tcm_handle);\n\n\tif (fh == 0) {\n\t\tif (n->nlmsg_type == RTM_DELTFILTER && t->tcm_handle == 0) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\t*back = tp->next;\n\t\t\tspin_unlock_bh(root_lock);\n\n\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\ttcf_destroy(tp);\n\t\t\terr = 0;\n\t\t\tgoto errout;\n\t\t}\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTFILTER:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL) {\n\t\t\t\tif (tp_created)\n\t\t\t\t\ttcf_destroy(tp);\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTM_DELTFILTER:\n\t\t\terr = tp->ops->delete(tp, fh);\n\t\t\tif (err == 0)\n\t\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\tgoto errout;\n\t\tcase RTM_GETTFILTER:\n\t\t\terr = tfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t\t\tgoto errout;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto errout;\n\t\t}\n\t}\n\n\terr = tp->ops->change(net, skb, tp, cl, t->tcm_handle, tca, &fh);\n\tif (err == 0) {\n\t\tif (tp_created) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\ttp->next = *back;\n\t\t\t*back = tp;\n\t\t\tspin_unlock_bh(root_lock);\n\t\t}\n\t\ttfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t} else {\n\t\tif (tp_created)\n\t\t\ttcf_destroy(tp);\n\t}\n\nerrout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\tif (err == -EAGAIN)\n\t\t/* Replay the request. */\n\t\tgoto replay;\n\treturn err;\n}",
        "code_after_change": "static int tc_ctl_tfilter(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tspinlock_t *root_lock;\n\tstruct tcmsg *t;\n\tu32 protocol;\n\tu32 prio;\n\tu32 nprio;\n\tu32 parent;\n\tstruct net_device *dev;\n\tstruct Qdisc  *q;\n\tstruct tcf_proto **back, **chain;\n\tstruct tcf_proto *tp;\n\tconst struct tcf_proto_ops *tp_ops;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl;\n\tunsigned long fh;\n\tint err;\n\tint tp_created = 0;\n\n\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\terr = nlmsg_parse(n, sizeof(*t), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tt = nlmsg_data(n);\n\tprotocol = TC_H_MIN(t->tcm_info);\n\tprio = TC_H_MAJ(t->tcm_info);\n\tnprio = prio;\n\tparent = t->tcm_parent;\n\tcl = 0;\n\n\tif (prio == 0) {\n\t\t/* If no priority is given, user wants we allocated it. */\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\treturn -ENOENT;\n\t\tprio = TC_H_MAKE(0x80000000U, 0U);\n\t}\n\n\t/* Find head of filter chain. */\n\n\t/* Find link */\n\tdev = __dev_get_by_index(net, t->tcm_ifindex);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\t/* Find qdisc */\n\tif (!parent) {\n\t\tq = dev->qdisc;\n\t\tparent = q->handle;\n\t} else {\n\t\tq = qdisc_lookup(dev, TC_H_MAJ(t->tcm_parent));\n\t\tif (q == NULL)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/* Is it classful? */\n\tcops = q->ops->cl_ops;\n\tif (!cops)\n\t\treturn -EINVAL;\n\n\tif (cops->tcf_chain == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Do we search for filter, attached to class? */\n\tif (TC_H_MIN(parent)) {\n\t\tcl = cops->get(q, parent);\n\t\tif (cl == 0)\n\t\t\treturn -ENOENT;\n\t}\n\n\t/* And the last stroke */\n\tchain = cops->tcf_chain(q, cl);\n\terr = -EINVAL;\n\tif (chain == NULL)\n\t\tgoto errout;\n\n\t/* Check the chain for existence of proto-tcf with this priority */\n\tfor (back = chain; (tp = *back) != NULL; back = &tp->next) {\n\t\tif (tp->prio >= prio) {\n\t\t\tif (tp->prio == prio) {\n\t\t\t\tif (!nprio ||\n\t\t\t\t    (tp->protocol != protocol && protocol))\n\t\t\t\t\tgoto errout;\n\t\t\t} else\n\t\t\t\ttp = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\troot_lock = qdisc_root_sleeping_lock(q);\n\n\tif (tp == NULL) {\n\t\t/* Proto-tcf does not exist, create new one */\n\n\t\tif (tca[TCA_KIND] == NULL || !protocol)\n\t\t\tgoto errout;\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\n\n\t\t/* Create new proto tcf */\n\n\t\terr = -ENOBUFS;\n\t\ttp = kzalloc(sizeof(*tp), GFP_KERNEL);\n\t\tif (tp == NULL)\n\t\t\tgoto errout;\n\t\terr = -ENOENT;\n\t\ttp_ops = tcf_proto_lookup_ops(tca[TCA_KIND]);\n\t\tif (tp_ops == NULL) {\n#ifdef CONFIG_MODULES\n\t\t\tstruct nlattr *kind = tca[TCA_KIND];\n\t\t\tchar name[IFNAMSIZ];\n\n\t\t\tif (kind != NULL &&\n\t\t\t    nla_strlcpy(name, kind, IFNAMSIZ) < IFNAMSIZ) {\n\t\t\t\trtnl_unlock();\n\t\t\t\trequest_module(\"cls_%s\", name);\n\t\t\t\trtnl_lock();\n\t\t\t\ttp_ops = tcf_proto_lookup_ops(kind);\n\t\t\t\t/* We dropped the RTNL semaphore in order to\n\t\t\t\t * perform the module load.  So, even if we\n\t\t\t\t * succeeded in loading the module we have to\n\t\t\t\t * replay the request.  We indicate this using\n\t\t\t\t * -EAGAIN.\n\t\t\t\t */\n\t\t\t\tif (tp_ops != NULL) {\n\t\t\t\t\tmodule_put(tp_ops->owner);\n\t\t\t\t\terr = -EAGAIN;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\t\ttp->ops = tp_ops;\n\t\ttp->protocol = protocol;\n\t\ttp->prio = nprio ? : TC_H_MAJ(tcf_auto_prio(*back));\n\t\ttp->q = q;\n\t\ttp->classify = tp_ops->classify;\n\t\ttp->classid = parent;\n\n\t\terr = tp_ops->init(tp);\n\t\tif (err != 0) {\n\t\t\tmodule_put(tp_ops->owner);\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\n\t\ttp_created = 1;\n\n\t} else if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind))\n\t\tgoto errout;\n\n\tfh = tp->ops->get(tp, t->tcm_handle);\n\n\tif (fh == 0) {\n\t\tif (n->nlmsg_type == RTM_DELTFILTER && t->tcm_handle == 0) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\t*back = tp->next;\n\t\t\tspin_unlock_bh(root_lock);\n\n\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\ttcf_destroy(tp);\n\t\t\terr = 0;\n\t\t\tgoto errout;\n\t\t}\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTFILTER:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL) {\n\t\t\t\tif (tp_created)\n\t\t\t\t\ttcf_destroy(tp);\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTM_DELTFILTER:\n\t\t\terr = tp->ops->delete(tp, fh);\n\t\t\tif (err == 0)\n\t\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\tgoto errout;\n\t\tcase RTM_GETTFILTER:\n\t\t\terr = tfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t\t\tgoto errout;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto errout;\n\t\t}\n\t}\n\n\terr = tp->ops->change(net, skb, tp, cl, t->tcm_handle, tca, &fh);\n\tif (err == 0) {\n\t\tif (tp_created) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\ttp->next = *back;\n\t\t\t*back = tp;\n\t\t\tspin_unlock_bh(root_lock);\n\t\t}\n\t\ttfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t} else {\n\t\tif (tp_created)\n\t\t\ttcf_destroy(tp);\n\t}\n\nerrout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\tif (err == -EAGAIN)\n\t\t/* Replay the request. */\n\t\tgoto replay;\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,7 @@\n \tint err;\n \tint tp_created = 0;\n \n-\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n replay:",
        "function_modified_lines": {
            "added": [
                "\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 455
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int dn_fib_rtm_delroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 0);\n\tif (!tb)\n\t\treturn -ESRCH;\n\n\treturn tb->delete(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "code_after_change": "static int dn_fib_rtm_delroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 0);\n\tif (!tb)\n\t\treturn -ESRCH;\n\n\treturn tb->delete(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,7 +6,7 @@\n \tstruct nlattr *attrs[RTA_MAX+1];\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (!net_eq(net, &init_net))",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 447
    },
    {
        "cve_id": "CVE-2014-0181",
        "code_before_change": "static int cgw_remove_job(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct cgw_job *gwj = NULL;\n\tstruct hlist_node *nx;\n\tstruct rtcanmsg *r;\n\tstruct cf_mod mod;\n\tstruct can_can_gw ccgw;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\terr = cgw_parse_attr(nlh, &mod, CGW_TYPE_CAN_CAN, &ccgw, &limhops);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* two interface indices both set to 0 => remove all entries */\n\tif (!ccgw.src_idx && !ccgw.dst_idx) {\n\t\tcgw_remove_all_jobs();\n\t\treturn 0;\n\t}\n\n\terr = -EINVAL;\n\n\tASSERT_RTNL();\n\n\t/* remove only the first matching entry */\n\thlist_for_each_entry_safe(gwj, nx, &cgw_list, list) {\n\n\t\tif (gwj->flags != r->flags)\n\t\t\tcontinue;\n\n\t\tif (gwj->limit_hops != limhops)\n\t\t\tcontinue;\n\n\t\tif (memcmp(&gwj->mod, &mod, sizeof(mod)))\n\t\t\tcontinue;\n\n\t\t/* if (r->gwtype == CGW_TYPE_CAN_CAN) - is made sure here */\n\t\tif (memcmp(&gwj->ccgw, &ccgw, sizeof(ccgw)))\n\t\t\tcontinue;\n\n\t\thlist_del(&gwj->list);\n\t\tcgw_unregister_filter(gwj);\n\t\tkmem_cache_free(cgw_cache, gwj);\n\t\terr = 0;\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "code_after_change": "static int cgw_remove_job(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct cgw_job *gwj = NULL;\n\tstruct hlist_node *nx;\n\tstruct rtcanmsg *r;\n\tstruct cf_mod mod;\n\tstruct can_can_gw ccgw;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\terr = cgw_parse_attr(nlh, &mod, CGW_TYPE_CAN_CAN, &ccgw, &limhops);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* two interface indices both set to 0 => remove all entries */\n\tif (!ccgw.src_idx && !ccgw.dst_idx) {\n\t\tcgw_remove_all_jobs();\n\t\treturn 0;\n\t}\n\n\terr = -EINVAL;\n\n\tASSERT_RTNL();\n\n\t/* remove only the first matching entry */\n\thlist_for_each_entry_safe(gwj, nx, &cgw_list, list) {\n\n\t\tif (gwj->flags != r->flags)\n\t\t\tcontinue;\n\n\t\tif (gwj->limit_hops != limhops)\n\t\t\tcontinue;\n\n\t\tif (memcmp(&gwj->mod, &mod, sizeof(mod)))\n\t\t\tcontinue;\n\n\t\t/* if (r->gwtype == CGW_TYPE_CAN_CAN) - is made sure here */\n\t\tif (memcmp(&gwj->ccgw, &ccgw, sizeof(ccgw)))\n\t\t\tcontinue;\n\n\t\thlist_del(&gwj->list);\n\t\tcgw_unregister_filter(gwj);\n\t\tkmem_cache_free(cgw_cache, gwj);\n\t\terr = 0;\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tu8 limhops = 0;\n \tint err = 0;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (nlmsg_len(nlh) < sizeof(*r))",
        "function_modified_lines": {
            "added": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ],
            "deleted": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "id": 438
    },
    {
        "cve_id": "CVE-2016-6786",
        "code_before_change": "void perf_pmu_migrate_context(struct pmu *pmu, int src_cpu, int dst_cpu)\n{\n\tstruct perf_event_context *src_ctx;\n\tstruct perf_event_context *dst_ctx;\n\tstruct perf_event *event, *tmp;\n\tLIST_HEAD(events);\n\n\tsrc_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, src_cpu)->ctx;\n\tdst_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, dst_cpu)->ctx;\n\n\tmutex_lock(&src_ctx->mutex);\n\tlist_for_each_entry_safe(event, tmp, &src_ctx->event_list,\n\t\t\t\t event_entry) {\n\t\tperf_remove_from_context(event, false);\n\t\tunaccount_event_cpu(event, src_cpu);\n\t\tput_ctx(src_ctx);\n\t\tlist_add(&event->migrate_entry, &events);\n\t}\n\tmutex_unlock(&src_ctx->mutex);\n\n\tsynchronize_rcu();\n\n\tmutex_lock(&dst_ctx->mutex);\n\tlist_for_each_entry_safe(event, tmp, &events, migrate_entry) {\n\t\tlist_del(&event->migrate_entry);\n\t\tif (event->state >= PERF_EVENT_STATE_OFF)\n\t\t\tevent->state = PERF_EVENT_STATE_INACTIVE;\n\t\taccount_event_cpu(event, dst_cpu);\n\t\tperf_install_in_context(dst_ctx, event, dst_cpu);\n\t\tget_ctx(dst_ctx);\n\t}\n\tmutex_unlock(&dst_ctx->mutex);\n}",
        "code_after_change": "void perf_pmu_migrate_context(struct pmu *pmu, int src_cpu, int dst_cpu)\n{\n\tstruct perf_event_context *src_ctx;\n\tstruct perf_event_context *dst_ctx;\n\tstruct perf_event *event, *tmp;\n\tLIST_HEAD(events);\n\n\tsrc_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, src_cpu)->ctx;\n\tdst_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, dst_cpu)->ctx;\n\n\t/*\n\t * See perf_event_ctx_lock() for comments on the details\n\t * of swizzling perf_event::ctx.\n\t */\n\tmutex_lock_double(&src_ctx->mutex, &dst_ctx->mutex);\n\tlist_for_each_entry_safe(event, tmp, &src_ctx->event_list,\n\t\t\t\t event_entry) {\n\t\tperf_remove_from_context(event, false);\n\t\tunaccount_event_cpu(event, src_cpu);\n\t\tput_ctx(src_ctx);\n\t\tlist_add(&event->migrate_entry, &events);\n\t}\n\n\tsynchronize_rcu();\n\n\tlist_for_each_entry_safe(event, tmp, &events, migrate_entry) {\n\t\tlist_del(&event->migrate_entry);\n\t\tif (event->state >= PERF_EVENT_STATE_OFF)\n\t\t\tevent->state = PERF_EVENT_STATE_INACTIVE;\n\t\taccount_event_cpu(event, dst_cpu);\n\t\tperf_install_in_context(dst_ctx, event, dst_cpu);\n\t\tget_ctx(dst_ctx);\n\t}\n\tmutex_unlock(&dst_ctx->mutex);\n\tmutex_unlock(&src_ctx->mutex);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,11 @@\n \tsrc_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, src_cpu)->ctx;\n \tdst_ctx = &per_cpu_ptr(pmu->pmu_cpu_context, dst_cpu)->ctx;\n \n-\tmutex_lock(&src_ctx->mutex);\n+\t/*\n+\t * See perf_event_ctx_lock() for comments on the details\n+\t * of swizzling perf_event::ctx.\n+\t */\n+\tmutex_lock_double(&src_ctx->mutex, &dst_ctx->mutex);\n \tlist_for_each_entry_safe(event, tmp, &src_ctx->event_list,\n \t\t\t\t event_entry) {\n \t\tperf_remove_from_context(event, false);\n@@ -16,11 +20,9 @@\n \t\tput_ctx(src_ctx);\n \t\tlist_add(&event->migrate_entry, &events);\n \t}\n-\tmutex_unlock(&src_ctx->mutex);\n \n \tsynchronize_rcu();\n \n-\tmutex_lock(&dst_ctx->mutex);\n \tlist_for_each_entry_safe(event, tmp, &events, migrate_entry) {\n \t\tlist_del(&event->migrate_entry);\n \t\tif (event->state >= PERF_EVENT_STATE_OFF)\n@@ -30,4 +32,5 @@\n \t\tget_ctx(dst_ctx);\n \t}\n \tmutex_unlock(&dst_ctx->mutex);\n+\tmutex_unlock(&src_ctx->mutex);\n }",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * See perf_event_ctx_lock() for comments on the details",
                "\t * of swizzling perf_event::ctx.",
                "\t */",
                "\tmutex_lock_double(&src_ctx->mutex, &dst_ctx->mutex);",
                "\tmutex_unlock(&src_ctx->mutex);"
            ],
            "deleted": [
                "\tmutex_lock(&src_ctx->mutex);",
                "\tmutex_unlock(&src_ctx->mutex);",
                "\tmutex_lock(&dst_ctx->mutex);"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "kernel/events/core.c in the performance subsystem in the Linux kernel before 4.0 mismanages locks during certain migrations, which allows local users to gain privileges via a crafted application, aka Android internal bug 30955111.",
        "id": 1081
    },
    {
        "cve_id": "CVE-2016-6786",
        "code_before_change": "static long perf_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct perf_event *event = file->private_data;\n\tvoid (*func)(struct perf_event *);\n\tu32 flags = arg;\n\n\tswitch (cmd) {\n\tcase PERF_EVENT_IOC_ENABLE:\n\t\tfunc = perf_event_enable;\n\t\tbreak;\n\tcase PERF_EVENT_IOC_DISABLE:\n\t\tfunc = perf_event_disable;\n\t\tbreak;\n\tcase PERF_EVENT_IOC_RESET:\n\t\tfunc = perf_event_reset;\n\t\tbreak;\n\n\tcase PERF_EVENT_IOC_REFRESH:\n\t\treturn perf_event_refresh(event, arg);\n\n\tcase PERF_EVENT_IOC_PERIOD:\n\t\treturn perf_event_period(event, (u64 __user *)arg);\n\n\tcase PERF_EVENT_IOC_ID:\n\t{\n\t\tu64 id = primary_event_id(event);\n\n\t\tif (copy_to_user((void __user *)arg, &id, sizeof(id)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\n\tcase PERF_EVENT_IOC_SET_OUTPUT:\n\t{\n\t\tint ret;\n\t\tif (arg != -1) {\n\t\t\tstruct perf_event *output_event;\n\t\t\tstruct fd output;\n\t\t\tret = perf_fget_light(arg, &output);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\toutput_event = output.file->private_data;\n\t\t\tret = perf_event_set_output(event, output_event);\n\t\t\tfdput(output);\n\t\t} else {\n\t\t\tret = perf_event_set_output(event, NULL);\n\t\t}\n\t\treturn ret;\n\t}\n\n\tcase PERF_EVENT_IOC_SET_FILTER:\n\t\treturn perf_event_set_filter(event, (void __user *)arg);\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\tif (flags & PERF_IOC_FLAG_GROUP)\n\t\tperf_event_for_each(event, func);\n\telse\n\t\tperf_event_for_each_child(event, func);\n\n\treturn 0;\n}",
        "code_after_change": "static long perf_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct perf_event *event = file->private_data;\n\tstruct perf_event_context *ctx;\n\tlong ret;\n\n\tctx = perf_event_ctx_lock(event);\n\tret = _perf_ioctl(event, cmd, arg);\n\tperf_event_ctx_unlock(event, ctx);\n\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,64 +1,12 @@\n static long perf_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n {\n \tstruct perf_event *event = file->private_data;\n-\tvoid (*func)(struct perf_event *);\n-\tu32 flags = arg;\n+\tstruct perf_event_context *ctx;\n+\tlong ret;\n \n-\tswitch (cmd) {\n-\tcase PERF_EVENT_IOC_ENABLE:\n-\t\tfunc = perf_event_enable;\n-\t\tbreak;\n-\tcase PERF_EVENT_IOC_DISABLE:\n-\t\tfunc = perf_event_disable;\n-\t\tbreak;\n-\tcase PERF_EVENT_IOC_RESET:\n-\t\tfunc = perf_event_reset;\n-\t\tbreak;\n+\tctx = perf_event_ctx_lock(event);\n+\tret = _perf_ioctl(event, cmd, arg);\n+\tperf_event_ctx_unlock(event, ctx);\n \n-\tcase PERF_EVENT_IOC_REFRESH:\n-\t\treturn perf_event_refresh(event, arg);\n-\n-\tcase PERF_EVENT_IOC_PERIOD:\n-\t\treturn perf_event_period(event, (u64 __user *)arg);\n-\n-\tcase PERF_EVENT_IOC_ID:\n-\t{\n-\t\tu64 id = primary_event_id(event);\n-\n-\t\tif (copy_to_user((void __user *)arg, &id, sizeof(id)))\n-\t\t\treturn -EFAULT;\n-\t\treturn 0;\n-\t}\n-\n-\tcase PERF_EVENT_IOC_SET_OUTPUT:\n-\t{\n-\t\tint ret;\n-\t\tif (arg != -1) {\n-\t\t\tstruct perf_event *output_event;\n-\t\t\tstruct fd output;\n-\t\t\tret = perf_fget_light(arg, &output);\n-\t\t\tif (ret)\n-\t\t\t\treturn ret;\n-\t\t\toutput_event = output.file->private_data;\n-\t\t\tret = perf_event_set_output(event, output_event);\n-\t\t\tfdput(output);\n-\t\t} else {\n-\t\t\tret = perf_event_set_output(event, NULL);\n-\t\t}\n-\t\treturn ret;\n-\t}\n-\n-\tcase PERF_EVENT_IOC_SET_FILTER:\n-\t\treturn perf_event_set_filter(event, (void __user *)arg);\n-\n-\tdefault:\n-\t\treturn -ENOTTY;\n-\t}\n-\n-\tif (flags & PERF_IOC_FLAG_GROUP)\n-\t\tperf_event_for_each(event, func);\n-\telse\n-\t\tperf_event_for_each_child(event, func);\n-\n-\treturn 0;\n+\treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct perf_event_context *ctx;",
                "\tlong ret;",
                "\tctx = perf_event_ctx_lock(event);",
                "\tret = _perf_ioctl(event, cmd, arg);",
                "\tperf_event_ctx_unlock(event, ctx);",
                "\treturn ret;"
            ],
            "deleted": [
                "\tvoid (*func)(struct perf_event *);",
                "\tu32 flags = arg;",
                "\tswitch (cmd) {",
                "\tcase PERF_EVENT_IOC_ENABLE:",
                "\t\tfunc = perf_event_enable;",
                "\t\tbreak;",
                "\tcase PERF_EVENT_IOC_DISABLE:",
                "\t\tfunc = perf_event_disable;",
                "\t\tbreak;",
                "\tcase PERF_EVENT_IOC_RESET:",
                "\t\tfunc = perf_event_reset;",
                "\t\tbreak;",
                "\tcase PERF_EVENT_IOC_REFRESH:",
                "\t\treturn perf_event_refresh(event, arg);",
                "",
                "\tcase PERF_EVENT_IOC_PERIOD:",
                "\t\treturn perf_event_period(event, (u64 __user *)arg);",
                "",
                "\tcase PERF_EVENT_IOC_ID:",
                "\t{",
                "\t\tu64 id = primary_event_id(event);",
                "",
                "\t\tif (copy_to_user((void __user *)arg, &id, sizeof(id)))",
                "\t\t\treturn -EFAULT;",
                "\t\treturn 0;",
                "\t}",
                "",
                "\tcase PERF_EVENT_IOC_SET_OUTPUT:",
                "\t{",
                "\t\tint ret;",
                "\t\tif (arg != -1) {",
                "\t\t\tstruct perf_event *output_event;",
                "\t\t\tstruct fd output;",
                "\t\t\tret = perf_fget_light(arg, &output);",
                "\t\t\tif (ret)",
                "\t\t\t\treturn ret;",
                "\t\t\toutput_event = output.file->private_data;",
                "\t\t\tret = perf_event_set_output(event, output_event);",
                "\t\t\tfdput(output);",
                "\t\t} else {",
                "\t\t\tret = perf_event_set_output(event, NULL);",
                "\t\t}",
                "\t\treturn ret;",
                "\t}",
                "",
                "\tcase PERF_EVENT_IOC_SET_FILTER:",
                "\t\treturn perf_event_set_filter(event, (void __user *)arg);",
                "",
                "\tdefault:",
                "\t\treturn -ENOTTY;",
                "\t}",
                "",
                "\tif (flags & PERF_IOC_FLAG_GROUP)",
                "\t\tperf_event_for_each(event, func);",
                "\telse",
                "\t\tperf_event_for_each_child(event, func);",
                "",
                "\treturn 0;"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "kernel/events/core.c in the performance subsystem in the Linux kernel before 4.0 mismanages locks during certain migrations, which allows local users to gain privileges via a crafted application, aka Android internal bug 30955111.",
        "id": 1089
    },
    {
        "cve_id": "CVE-2016-6786",
        "code_before_change": "static void perf_remove_from_owner(struct perf_event *event)\n{\n\tstruct task_struct *owner;\n\n\trcu_read_lock();\n\towner = ACCESS_ONCE(event->owner);\n\t/*\n\t * Matches the smp_wmb() in perf_event_exit_task(). If we observe\n\t * !owner it means the list deletion is complete and we can indeed\n\t * free this event, otherwise we need to serialize on\n\t * owner->perf_event_mutex.\n\t */\n\tsmp_read_barrier_depends();\n\tif (owner) {\n\t\t/*\n\t\t * Since delayed_put_task_struct() also drops the last\n\t\t * task reference we can safely take a new reference\n\t\t * while holding the rcu_read_lock().\n\t\t */\n\t\tget_task_struct(owner);\n\t}\n\trcu_read_unlock();\n\n\tif (owner) {\n\t\tmutex_lock(&owner->perf_event_mutex);\n\t\t/*\n\t\t * We have to re-check the event->owner field, if it is cleared\n\t\t * we raced with perf_event_exit_task(), acquiring the mutex\n\t\t * ensured they're done, and we can proceed with freeing the\n\t\t * event.\n\t\t */\n\t\tif (event->owner)\n\t\t\tlist_del_init(&event->owner_entry);\n\t\tmutex_unlock(&owner->perf_event_mutex);\n\t\tput_task_struct(owner);\n\t}\n}",
        "code_after_change": "static void perf_remove_from_owner(struct perf_event *event)\n{\n\tstruct task_struct *owner;\n\n\trcu_read_lock();\n\towner = ACCESS_ONCE(event->owner);\n\t/*\n\t * Matches the smp_wmb() in perf_event_exit_task(). If we observe\n\t * !owner it means the list deletion is complete and we can indeed\n\t * free this event, otherwise we need to serialize on\n\t * owner->perf_event_mutex.\n\t */\n\tsmp_read_barrier_depends();\n\tif (owner) {\n\t\t/*\n\t\t * Since delayed_put_task_struct() also drops the last\n\t\t * task reference we can safely take a new reference\n\t\t * while holding the rcu_read_lock().\n\t\t */\n\t\tget_task_struct(owner);\n\t}\n\trcu_read_unlock();\n\n\tif (owner) {\n\t\t/*\n\t\t * If we're here through perf_event_exit_task() we're already\n\t\t * holding ctx->mutex which would be an inversion wrt. the\n\t\t * normal lock order.\n\t\t *\n\t\t * However we can safely take this lock because its the child\n\t\t * ctx->mutex.\n\t\t */\n\t\tmutex_lock_nested(&owner->perf_event_mutex, SINGLE_DEPTH_NESTING);\n\n\t\t/*\n\t\t * We have to re-check the event->owner field, if it is cleared\n\t\t * we raced with perf_event_exit_task(), acquiring the mutex\n\t\t * ensured they're done, and we can proceed with freeing the\n\t\t * event.\n\t\t */\n\t\tif (event->owner)\n\t\t\tlist_del_init(&event->owner_entry);\n\t\tmutex_unlock(&owner->perf_event_mutex);\n\t\tput_task_struct(owner);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -22,7 +22,16 @@\n \trcu_read_unlock();\n \n \tif (owner) {\n-\t\tmutex_lock(&owner->perf_event_mutex);\n+\t\t/*\n+\t\t * If we're here through perf_event_exit_task() we're already\n+\t\t * holding ctx->mutex which would be an inversion wrt. the\n+\t\t * normal lock order.\n+\t\t *\n+\t\t * However we can safely take this lock because its the child\n+\t\t * ctx->mutex.\n+\t\t */\n+\t\tmutex_lock_nested(&owner->perf_event_mutex, SINGLE_DEPTH_NESTING);\n+\n \t\t/*\n \t\t * We have to re-check the event->owner field, if it is cleared\n \t\t * we raced with perf_event_exit_task(), acquiring the mutex",
        "function_modified_lines": {
            "added": [
                "\t\t/*",
                "\t\t * If we're here through perf_event_exit_task() we're already",
                "\t\t * holding ctx->mutex which would be an inversion wrt. the",
                "\t\t * normal lock order.",
                "\t\t *",
                "\t\t * However we can safely take this lock because its the child",
                "\t\t * ctx->mutex.",
                "\t\t */",
                "\t\tmutex_lock_nested(&owner->perf_event_mutex, SINGLE_DEPTH_NESTING);",
                ""
            ],
            "deleted": [
                "\t\tmutex_lock(&owner->perf_event_mutex);"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "kernel/events/core.c in the performance subsystem in the Linux kernel before 4.0 mismanages locks during certain migrations, which allows local users to gain privileges via a crafted application, aka Android internal bug 30955111.",
        "id": 1078
    },
    {
        "cve_id": "CVE-2013-2930",
        "code_before_change": "static int perf_trace_event_perm(struct ftrace_event_call *tp_event,\n\t\t\t\t struct perf_event *p_event)\n{\n\t/* The ftrace function trace is allowed only for root. */\n\tif (ftrace_event_is_function(tp_event) &&\n\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\t/* No tracing, just counting, so no obvious leak */\n\tif (!(p_event->attr.sample_type & PERF_SAMPLE_RAW))\n\t\treturn 0;\n\n\t/* Some events are ok to be traced by non-root users... */\n\tif (p_event->attach_state == PERF_ATTACH_TASK) {\n\t\tif (tp_event->flags & TRACE_EVENT_FL_CAP_ANY)\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * ...otherwise raw tracepoint data can be a severe data leak,\n\t * only allow root to have these.\n\t */\n\tif (perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\treturn 0;\n}",
        "code_after_change": "static int perf_trace_event_perm(struct ftrace_event_call *tp_event,\n\t\t\t\t struct perf_event *p_event)\n{\n\t/* The ftrace function trace is allowed only for root. */\n\tif (ftrace_event_is_function(tp_event) &&\n\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\t/* No tracing, just counting, so no obvious leak */\n\tif (!(p_event->attr.sample_type & PERF_SAMPLE_RAW))\n\t\treturn 0;\n\n\t/* Some events are ok to be traced by non-root users... */\n\tif (p_event->attach_state == PERF_ATTACH_TASK) {\n\t\tif (tp_event->flags & TRACE_EVENT_FL_CAP_ANY)\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * ...otherwise raw tracepoint data can be a severe data leak,\n\t * only allow root to have these.\n\t */\n\tif (perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n {\n \t/* The ftrace function trace is allowed only for root. */\n \tif (ftrace_event_is_function(tp_event) &&\n-\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))\n+\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \t/* No tracing, just counting, so no obvious leak */",
        "function_modified_lines": {
            "added": [
                "\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))"
            ],
            "deleted": [
                "\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The perf_trace_event_perm function in kernel/trace/trace_event_perf.c in the Linux kernel before 3.12.2 does not properly restrict access to the perf subsystem, which allows local users to enable function tracing via a crafted application.",
        "id": 260
    },
    {
        "cve_id": "CVE-2015-8709",
        "code_before_change": "struct mm_struct *mm_alloc(void)\n{\n\tstruct mm_struct *mm;\n\n\tmm = allocate_mm();\n\tif (!mm)\n\t\treturn NULL;\n\n\tmemset(mm, 0, sizeof(*mm));\n\treturn mm_init(mm, current);\n}",
        "code_after_change": "struct mm_struct *mm_alloc(void)\n{\n\tstruct mm_struct *mm;\n\n\tmm = allocate_mm();\n\tif (!mm)\n\t\treturn NULL;\n\n\tmemset(mm, 0, sizeof(*mm));\n\treturn mm_init(mm, current, current_user_ns());\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,5 +7,5 @@\n \t\treturn NULL;\n \n \tmemset(mm, 0, sizeof(*mm));\n-\treturn mm_init(mm, current);\n+\treturn mm_init(mm, current, current_user_ns());\n }",
        "function_modified_lines": {
            "added": [
                "\treturn mm_init(mm, current, current_user_ns());"
            ],
            "deleted": [
                "\treturn mm_init(mm, current);"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "kernel/ptrace.c in the Linux kernel through 4.4.1 mishandles uid and gid mappings, which allows local users to gain privileges by establishing a user namespace, waiting for a root process to enter that namespace with an unsafe uid or gid, and then using the ptrace system call.  NOTE: the vendor states \"there is no kernel bug here.",
        "id": 836
    },
    {
        "cve_id": "CVE-2015-8709",
        "code_before_change": "static int ptrace_attach(struct task_struct *task, long request,\n\t\t\t unsigned long addr,\n\t\t\t unsigned long flags)\n{\n\tbool seize = (request == PTRACE_SEIZE);\n\tint retval;\n\n\tretval = -EIO;\n\tif (seize) {\n\t\tif (addr != 0)\n\t\t\tgoto out;\n\t\tif (flags & ~(unsigned long)PTRACE_O_MASK)\n\t\t\tgoto out;\n\t\tflags = PT_PTRACED | PT_SEIZED | (flags << PT_OPT_FLAG_SHIFT);\n\t} else {\n\t\tflags = PT_PTRACED;\n\t}\n\n\taudit_ptrace(task);\n\n\tretval = -EPERM;\n\tif (unlikely(task->flags & PF_KTHREAD))\n\t\tgoto out;\n\tif (same_thread_group(task, current))\n\t\tgoto out;\n\n\t/*\n\t * Protect exec's credential calculations against our interference;\n\t * SUID, SGID and LSM creds get determined differently\n\t * under ptrace.\n\t */\n\tretval = -ERESTARTNOINTR;\n\tif (mutex_lock_interruptible(&task->signal->cred_guard_mutex))\n\t\tgoto out;\n\n\ttask_lock(task);\n\tretval = __ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS);\n\ttask_unlock(task);\n\tif (retval)\n\t\tgoto unlock_creds;\n\n\twrite_lock_irq(&tasklist_lock);\n\tretval = -EPERM;\n\tif (unlikely(task->exit_state))\n\t\tgoto unlock_tasklist;\n\tif (task->ptrace)\n\t\tgoto unlock_tasklist;\n\n\tif (seize)\n\t\tflags |= PT_SEIZED;\n\trcu_read_lock();\n\tif (ns_capable(__task_cred(task)->user_ns, CAP_SYS_PTRACE))\n\t\tflags |= PT_PTRACE_CAP;\n\trcu_read_unlock();\n\ttask->ptrace = flags;\n\n\t__ptrace_link(task, current);\n\n\t/* SEIZE doesn't trap tracee on attach */\n\tif (!seize)\n\t\tsend_sig_info(SIGSTOP, SEND_SIG_FORCED, task);\n\n\tspin_lock(&task->sighand->siglock);\n\n\t/*\n\t * If the task is already STOPPED, set JOBCTL_TRAP_STOP and\n\t * TRAPPING, and kick it so that it transits to TRACED.  TRAPPING\n\t * will be cleared if the child completes the transition or any\n\t * event which clears the group stop states happens.  We'll wait\n\t * for the transition to complete before returning from this\n\t * function.\n\t *\n\t * This hides STOPPED -> RUNNING -> TRACED transition from the\n\t * attaching thread but a different thread in the same group can\n\t * still observe the transient RUNNING state.  IOW, if another\n\t * thread's WNOHANG wait(2) on the stopped tracee races against\n\t * ATTACH, the wait(2) may fail due to the transient RUNNING.\n\t *\n\t * The following task_is_stopped() test is safe as both transitions\n\t * in and out of STOPPED are protected by siglock.\n\t */\n\tif (task_is_stopped(task) &&\n\t    task_set_jobctl_pending(task, JOBCTL_TRAP_STOP | JOBCTL_TRAPPING))\n\t\tsignal_wake_up_state(task, __TASK_STOPPED);\n\n\tspin_unlock(&task->sighand->siglock);\n\n\tretval = 0;\nunlock_tasklist:\n\twrite_unlock_irq(&tasklist_lock);\nunlock_creds:\n\tmutex_unlock(&task->signal->cred_guard_mutex);\nout:\n\tif (!retval) {\n\t\t/*\n\t\t * We do not bother to change retval or clear JOBCTL_TRAPPING\n\t\t * if wait_on_bit() was interrupted by SIGKILL. The tracer will\n\t\t * not return to user-mode, it will exit and clear this bit in\n\t\t * __ptrace_unlink() if it wasn't already cleared by the tracee;\n\t\t * and until then nobody can ptrace this task.\n\t\t */\n\t\twait_on_bit(&task->jobctl, JOBCTL_TRAPPING_BIT, TASK_KILLABLE);\n\t\tproc_ptrace_connector(task, PTRACE_ATTACH);\n\t}\n\n\treturn retval;\n}",
        "code_after_change": "static int ptrace_attach(struct task_struct *task, long request,\n\t\t\t unsigned long addr,\n\t\t\t unsigned long flags)\n{\n\tbool seize = (request == PTRACE_SEIZE);\n\tint retval;\n\n\tretval = -EIO;\n\tif (seize) {\n\t\tif (addr != 0)\n\t\t\tgoto out;\n\t\tif (flags & ~(unsigned long)PTRACE_O_MASK)\n\t\t\tgoto out;\n\t\tflags = PT_PTRACED | PT_SEIZED | (flags << PT_OPT_FLAG_SHIFT);\n\t} else {\n\t\tflags = PT_PTRACED;\n\t}\n\n\taudit_ptrace(task);\n\n\tretval = -EPERM;\n\tif (unlikely(task->flags & PF_KTHREAD))\n\t\tgoto out;\n\tif (same_thread_group(task, current))\n\t\tgoto out;\n\n\t/*\n\t * Protect exec's credential calculations against our interference;\n\t * SUID, SGID and LSM creds get determined differently\n\t * under ptrace.\n\t */\n\tretval = -ERESTARTNOINTR;\n\tif (mutex_lock_interruptible(&task->signal->cred_guard_mutex))\n\t\tgoto out;\n\n\ttask_lock(task);\n\tretval = __ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS);\n\tif (!retval) {\n\t\tstruct mm_struct *mm = task->mm;\n\t\tif (mm && ns_capable(mm->user_ns, CAP_SYS_PTRACE))\n\t\t\tflags |= PT_PTRACE_CAP;\n\t}\n\ttask_unlock(task);\n\tif (retval)\n\t\tgoto unlock_creds;\n\n\twrite_lock_irq(&tasklist_lock);\n\tretval = -EPERM;\n\tif (unlikely(task->exit_state))\n\t\tgoto unlock_tasklist;\n\tif (task->ptrace)\n\t\tgoto unlock_tasklist;\n\n\tif (seize)\n\t\tflags |= PT_SEIZED;\n\ttask->ptrace = flags;\n\n\t__ptrace_link(task, current);\n\n\t/* SEIZE doesn't trap tracee on attach */\n\tif (!seize)\n\t\tsend_sig_info(SIGSTOP, SEND_SIG_FORCED, task);\n\n\tspin_lock(&task->sighand->siglock);\n\n\t/*\n\t * If the task is already STOPPED, set JOBCTL_TRAP_STOP and\n\t * TRAPPING, and kick it so that it transits to TRACED.  TRAPPING\n\t * will be cleared if the child completes the transition or any\n\t * event which clears the group stop states happens.  We'll wait\n\t * for the transition to complete before returning from this\n\t * function.\n\t *\n\t * This hides STOPPED -> RUNNING -> TRACED transition from the\n\t * attaching thread but a different thread in the same group can\n\t * still observe the transient RUNNING state.  IOW, if another\n\t * thread's WNOHANG wait(2) on the stopped tracee races against\n\t * ATTACH, the wait(2) may fail due to the transient RUNNING.\n\t *\n\t * The following task_is_stopped() test is safe as both transitions\n\t * in and out of STOPPED are protected by siglock.\n\t */\n\tif (task_is_stopped(task) &&\n\t    task_set_jobctl_pending(task, JOBCTL_TRAP_STOP | JOBCTL_TRAPPING))\n\t\tsignal_wake_up_state(task, __TASK_STOPPED);\n\n\tspin_unlock(&task->sighand->siglock);\n\n\tretval = 0;\nunlock_tasklist:\n\twrite_unlock_irq(&tasklist_lock);\nunlock_creds:\n\tmutex_unlock(&task->signal->cred_guard_mutex);\nout:\n\tif (!retval) {\n\t\t/*\n\t\t * We do not bother to change retval or clear JOBCTL_TRAPPING\n\t\t * if wait_on_bit() was interrupted by SIGKILL. The tracer will\n\t\t * not return to user-mode, it will exit and clear this bit in\n\t\t * __ptrace_unlink() if it wasn't already cleared by the tracee;\n\t\t * and until then nobody can ptrace this task.\n\t\t */\n\t\twait_on_bit(&task->jobctl, JOBCTL_TRAPPING_BIT, TASK_KILLABLE);\n\t\tproc_ptrace_connector(task, PTRACE_ATTACH);\n\t}\n\n\treturn retval;\n}",
        "patch": "--- code before\n+++ code after\n@@ -35,6 +35,11 @@\n \n \ttask_lock(task);\n \tretval = __ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS);\n+\tif (!retval) {\n+\t\tstruct mm_struct *mm = task->mm;\n+\t\tif (mm && ns_capable(mm->user_ns, CAP_SYS_PTRACE))\n+\t\t\tflags |= PT_PTRACE_CAP;\n+\t}\n \ttask_unlock(task);\n \tif (retval)\n \t\tgoto unlock_creds;\n@@ -48,10 +53,6 @@\n \n \tif (seize)\n \t\tflags |= PT_SEIZED;\n-\trcu_read_lock();\n-\tif (ns_capable(__task_cred(task)->user_ns, CAP_SYS_PTRACE))\n-\t\tflags |= PT_PTRACE_CAP;\n-\trcu_read_unlock();\n \ttask->ptrace = flags;\n \n \t__ptrace_link(task, current);",
        "function_modified_lines": {
            "added": [
                "\tif (!retval) {",
                "\t\tstruct mm_struct *mm = task->mm;",
                "\t\tif (mm && ns_capable(mm->user_ns, CAP_SYS_PTRACE))",
                "\t\t\tflags |= PT_PTRACE_CAP;",
                "\t}"
            ],
            "deleted": [
                "\trcu_read_lock();",
                "\tif (ns_capable(__task_cred(task)->user_ns, CAP_SYS_PTRACE))",
                "\t\tflags |= PT_PTRACE_CAP;",
                "\trcu_read_unlock();"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "kernel/ptrace.c in the Linux kernel through 4.4.1 mishandles uid and gid mappings, which allows local users to gain privileges by establishing a user namespace, waiting for a root process to enter that namespace with an unsafe uid or gid, and then using the ptrace system call.  NOTE: the vendor states \"there is no kernel bug here.",
        "id": 839
    },
    {
        "cve_id": "CVE-2016-4997",
        "code_before_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "code_after_change": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -27,7 +27,8 @@\n \tif (!ip_checkentry(&e->ip))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "function_modified_lines": {
            "added": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ],
            "deleted": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "id": 1041
    },
    {
        "cve_id": "CVE-2016-4997",
        "code_before_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "code_after_change": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -31,7 +31,7 @@\n \tif (!arp_checkentry(&e->arp))\n \t\treturn -EINVAL;\n \n-\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n+\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n \t\t\t\t\t    e->next_offset);\n \tif (ret)\n \t\treturn ret;",
        "function_modified_lines": {
            "added": [
                "\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,"
            ],
            "deleted": [
                "\tret = xt_compat_check_entry_offsets(e, e->target_offset,"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "id": 1039
    },
    {
        "cve_id": "CVE-2016-9644",
        "code_before_change": "static void math_error(struct pt_regs *regs, int error_code, int trapnr)\n{\n\tstruct task_struct *task = current;\n\tstruct fpu *fpu = &task->thread.fpu;\n\tsiginfo_t info;\n\tchar *str = (trapnr == X86_TRAP_MF) ? \"fpu exception\" :\n\t\t\t\t\t\t\"simd exception\";\n\n\tif (notify_die(DIE_TRAP, str, regs, error_code, trapnr, SIGFPE) == NOTIFY_STOP)\n\t\treturn;\n\tconditional_sti(regs);\n\n\tif (!user_mode(regs)) {\n\t\tif (!fixup_exception(regs)) {\n\t\t\ttask->thread.error_code = error_code;\n\t\t\ttask->thread.trap_nr = trapnr;\n\t\t\tdie(str, regs, error_code);\n\t\t}\n\t\treturn;\n\t}\n\n\t/*\n\t * Save the info for the exception handler and clear the error.\n\t */\n\tfpu__save(fpu);\n\n\ttask->thread.trap_nr\t= trapnr;\n\ttask->thread.error_code = error_code;\n\tinfo.si_signo\t\t= SIGFPE;\n\tinfo.si_errno\t\t= 0;\n\tinfo.si_addr\t\t= (void __user *)uprobe_get_trap_addr(regs);\n\n\tinfo.si_code = fpu__exception_code(fpu, trapnr);\n\n\t/* Retry when we get spurious exceptions: */\n\tif (!info.si_code)\n\t\treturn;\n\n\tforce_sig_info(SIGFPE, &info, task);\n}",
        "code_after_change": "static void math_error(struct pt_regs *regs, int error_code, int trapnr)\n{\n\tstruct task_struct *task = current;\n\tstruct fpu *fpu = &task->thread.fpu;\n\tsiginfo_t info;\n\tchar *str = (trapnr == X86_TRAP_MF) ? \"fpu exception\" :\n\t\t\t\t\t\t\"simd exception\";\n\n\tif (notify_die(DIE_TRAP, str, regs, error_code, trapnr, SIGFPE) == NOTIFY_STOP)\n\t\treturn;\n\tconditional_sti(regs);\n\n\tif (!user_mode(regs)) {\n\t\tif (!fixup_exception(regs, trapnr)) {\n\t\t\ttask->thread.error_code = error_code;\n\t\t\ttask->thread.trap_nr = trapnr;\n\t\t\tdie(str, regs, error_code);\n\t\t}\n\t\treturn;\n\t}\n\n\t/*\n\t * Save the info for the exception handler and clear the error.\n\t */\n\tfpu__save(fpu);\n\n\ttask->thread.trap_nr\t= trapnr;\n\ttask->thread.error_code = error_code;\n\tinfo.si_signo\t\t= SIGFPE;\n\tinfo.si_errno\t\t= 0;\n\tinfo.si_addr\t\t= (void __user *)uprobe_get_trap_addr(regs);\n\n\tinfo.si_code = fpu__exception_code(fpu, trapnr);\n\n\t/* Retry when we get spurious exceptions: */\n\tif (!info.si_code)\n\t\treturn;\n\n\tforce_sig_info(SIGFPE, &info, task);\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \tconditional_sti(regs);\n \n \tif (!user_mode(regs)) {\n-\t\tif (!fixup_exception(regs)) {\n+\t\tif (!fixup_exception(regs, trapnr)) {\n \t\t\ttask->thread.error_code = error_code;\n \t\t\ttask->thread.trap_nr = trapnr;\n \t\t\tdie(str, regs, error_code);",
        "function_modified_lines": {
            "added": [
                "\t\tif (!fixup_exception(regs, trapnr)) {"
            ],
            "deleted": [
                "\t\tif (!fixup_exception(regs)) {"
            ]
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The __get_user_asm_ex macro in arch/x86/include/asm/uaccess.h in the Linux kernel 4.4.22 through 4.4.28 contains extended asm statements that are incompatible with the exception table, which allows local users to obtain root access on non-SMEP platforms via a crafted application.  NOTE: this vulnerability exists because of incorrect backporting of the CVE-2016-9178 patch to older kernels.",
        "id": 1154
    },
    {
        "cve_id": "CVE-2013-6383",
        "code_before_change": "static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n{\n\tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n\treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n}",
        "code_after_change": "static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n{\n\tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,5 +1,7 @@\n static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n {\n \tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n+\tif (!capable(CAP_SYS_RAWIO))\n+\t\treturn -EPERM;\n \treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n }",
        "function_modified_lines": {
            "added": [
                "\tif (!capable(CAP_SYS_RAWIO))",
                "\t\treturn -EPERM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The aac_compat_ioctl function in drivers/scsi/aacraid/linit.c in the Linux kernel before 3.11.8 does not require the CAP_SYS_RAWIO capability, which allows local users to bypass intended access restrictions via a crafted ioctl call.",
        "id": 351
    },
    {
        "cve_id": "CVE-2013-0268",
        "code_before_change": "static int msr_open(struct inode *inode, struct file *file)\n{\n\tunsigned int cpu;\n\tstruct cpuinfo_x86 *c;\n\n\tcpu = iminor(file->f_path.dentry->d_inode);\n\tif (cpu >= nr_cpu_ids || !cpu_online(cpu))\n\t\treturn -ENXIO;\t/* No such CPU */\n\n\tc = &cpu_data(cpu);\n\tif (!cpu_has(c, X86_FEATURE_MSR))\n\t\treturn -EIO;\t/* MSR not supported */\n\n\treturn 0;\n}",
        "code_after_change": "static int msr_open(struct inode *inode, struct file *file)\n{\n\tunsigned int cpu;\n\tstruct cpuinfo_x86 *c;\n\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\tcpu = iminor(file->f_path.dentry->d_inode);\n\tif (cpu >= nr_cpu_ids || !cpu_online(cpu))\n\t\treturn -ENXIO;\t/* No such CPU */\n\n\tc = &cpu_data(cpu);\n\tif (!cpu_has(c, X86_FEATURE_MSR))\n\t\treturn -EIO;\t/* MSR not supported */\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,9 @@\n {\n \tunsigned int cpu;\n \tstruct cpuinfo_x86 *c;\n+\n+\tif (!capable(CAP_SYS_RAWIO))\n+\t\treturn -EPERM;\n \n \tcpu = iminor(file->f_path.dentry->d_inode);\n \tif (cpu >= nr_cpu_ids || !cpu_online(cpu))",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (!capable(CAP_SYS_RAWIO))",
                "\t\treturn -EPERM;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-264"
        ],
        "cve_description": "The msr_open function in arch/x86/kernel/msr.c in the Linux kernel before 3.7.6 allows local users to bypass intended capability restrictions by executing a crafted application as root, as demonstrated by msr32.c.",
        "id": 153
    },
    {
        "cve_id": "CVE-2015-9016",
        "code_before_change": "static void bt_tags_for_each(struct blk_mq_tags *tags,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_tag_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tif (!tags->rqs)\n\t\treturn;\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);\n\t\t\tfn(rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "code_after_change": "static void bt_tags_for_each(struct blk_mq_tags *tags,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_tag_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tif (!tags->rqs)\n\t\treturn;\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = tags->rqs[off + bit];\n\t\t\tfn(rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,7 +13,7 @@\n \t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n \t\t     bit < bm->depth;\n \t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n-\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);\n+\t\t\trq = tags->rqs[off + bit];\n \t\t\tfn(rq, data, reserved);\n \t\t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\t\trq = tags->rqs[off + bit];"
            ],
            "deleted": [
                "\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-362"
        ],
        "cve_description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "id": 884
    },
    {
        "cve_id": "CVE-2013-4299",
        "code_before_change": "static int persistent_prepare_exception(struct dm_exception_store *store,\n\t\t\t\t\tstruct dm_exception *e)\n{\n\tstruct pstore *ps = get_info(store);\n\tuint32_t stride;\n\tchunk_t next_free;\n\tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n\n\t/* Is there enough room ? */\n\tif (size < ((ps->next_free + 1) * store->chunk_size))\n\t\treturn -ENOSPC;\n\n\te->new_chunk = ps->next_free;\n\n\t/*\n\t * Move onto the next free pending, making sure to take\n\t * into account the location of the metadata chunks.\n\t */\n\tstride = (ps->exceptions_per_area + 1);\n\tnext_free = ++ps->next_free;\n\tif (sector_div(next_free, stride) == 1)\n\t\tps->next_free++;\n\n\tatomic_inc(&ps->pending_count);\n\treturn 0;\n}",
        "code_after_change": "static int persistent_prepare_exception(struct dm_exception_store *store,\n\t\t\t\t\tstruct dm_exception *e)\n{\n\tstruct pstore *ps = get_info(store);\n\tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n\n\t/* Is there enough room ? */\n\tif (size < ((ps->next_free + 1) * store->chunk_size))\n\t\treturn -ENOSPC;\n\n\te->new_chunk = ps->next_free;\n\n\t/*\n\t * Move onto the next free pending, making sure to take\n\t * into account the location of the metadata chunks.\n\t */\n\tps->next_free++;\n\tskip_metadata(ps);\n\n\tatomic_inc(&ps->pending_count);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,8 +2,6 @@\n \t\t\t\t\tstruct dm_exception *e)\n {\n \tstruct pstore *ps = get_info(store);\n-\tuint32_t stride;\n-\tchunk_t next_free;\n \tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n \n \t/* Is there enough room ? */\n@@ -16,10 +14,8 @@\n \t * Move onto the next free pending, making sure to take\n \t * into account the location of the metadata chunks.\n \t */\n-\tstride = (ps->exceptions_per_area + 1);\n-\tnext_free = ++ps->next_free;\n-\tif (sector_div(next_free, stride) == 1)\n-\t\tps->next_free++;\n+\tps->next_free++;\n+\tskip_metadata(ps);\n \n \tatomic_inc(&ps->pending_count);\n \treturn 0;",
        "function_modified_lines": {
            "added": [
                "\tps->next_free++;",
                "\tskip_metadata(ps);"
            ],
            "deleted": [
                "\tuint32_t stride;",
                "\tchunk_t next_free;",
                "\tstride = (ps->exceptions_per_area + 1);",
                "\tnext_free = ++ps->next_free;",
                "\tif (sector_div(next_free, stride) == 1)",
                "\t\tps->next_free++;"
            ]
        },
        "cwe": [
            "CWE-264",
            "CWE-200"
        ],
        "cve_description": "Interpretation conflict in drivers/md/dm-snap-persistent.c in the Linux kernel through 3.11.6 allows remote authenticated users to obtain sensitive information or modify data via a crafted mapping to a snapshot block device.",
        "id": 293
    }
]